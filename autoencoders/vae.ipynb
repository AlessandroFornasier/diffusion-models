{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "95c339d581964b08b5819aa4166223a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9cf001f1a8a414a86ac82e06d76966c",
              "IPY_MODEL_b67c256b3bfc4f8cac3f33a7e8dc8407",
              "IPY_MODEL_939e698473e2489e8c189a7e8e6c63c7"
            ],
            "layout": "IPY_MODEL_be359f22c80b405586dce9208db89884"
          }
        },
        "c9cf001f1a8a414a86ac82e06d76966c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7301ee9250c74f67b6f9ddd3cc27aa44",
            "placeholder": "​",
            "style": "IPY_MODEL_19418248cffd4151a2d87bee4768562c",
            "value": "Epoch 1/50: 100%"
          }
        },
        "b67c256b3bfc4f8cac3f33a7e8dc8407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f03434d129b43e7a607a69380efee83",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bad3e9dd4071474e9b7e68883dc994db",
            "value": 469
          }
        },
        "939e698473e2489e8c189a7e8e6c63c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12f4e8a2dae04c91bbdd0f7788664143",
            "placeholder": "​",
            "style": "IPY_MODEL_9488cf22e6f441a6b93516b636ff4975",
            "value": " 469/469 [00:34&lt;00:00, 14.96it/s, loss=188]"
          }
        },
        "be359f22c80b405586dce9208db89884": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7301ee9250c74f67b6f9ddd3cc27aa44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19418248cffd4151a2d87bee4768562c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f03434d129b43e7a607a69380efee83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bad3e9dd4071474e9b7e68883dc994db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12f4e8a2dae04c91bbdd0f7788664143": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9488cf22e6f441a6b93516b636ff4975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "217633b899b6427fa714a0ebcd9e9736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c8fd06d509048f8ac0d6ad7615a5566",
              "IPY_MODEL_04f4ed4d09944e0aad5f8baed33e8f89",
              "IPY_MODEL_e675f9c5490947e795e86a9dc732f653"
            ],
            "layout": "IPY_MODEL_5af1fdc6216e492a890ec2177cc32ae8"
          }
        },
        "9c8fd06d509048f8ac0d6ad7615a5566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_886e302e534b48d0b1da02633058f6a9",
            "placeholder": "​",
            "style": "IPY_MODEL_b6c19e6d74544f1a8ce12f7dee2caeda",
            "value": "Epoch 2/50: 100%"
          }
        },
        "04f4ed4d09944e0aad5f8baed33e8f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7d99f0fdc1743d4b49a772e3307e788",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_096434c528f945e8829222a9bebc871b",
            "value": 469
          }
        },
        "e675f9c5490947e795e86a9dc732f653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f42e7041d754e8d9a986bf357e4aca4",
            "placeholder": "​",
            "style": "IPY_MODEL_2c5dafae74d344669f9048a7dd0c5de7",
            "value": " 469/469 [00:35&lt;00:00, 13.45it/s, loss=186]"
          }
        },
        "5af1fdc6216e492a890ec2177cc32ae8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "886e302e534b48d0b1da02633058f6a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6c19e6d74544f1a8ce12f7dee2caeda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7d99f0fdc1743d4b49a772e3307e788": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "096434c528f945e8829222a9bebc871b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f42e7041d754e8d9a986bf357e4aca4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c5dafae74d344669f9048a7dd0c5de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8686c09d3834d15b56615003482ba68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bf224b0b02d4427aa2b766dcd663822",
              "IPY_MODEL_0c6c7415a2f640538b6e1464300b4288",
              "IPY_MODEL_6a76ca1a7a7942c18f991d36ab108513"
            ],
            "layout": "IPY_MODEL_2cd4b5d538cc41a68bb6b413c0c338e7"
          }
        },
        "7bf224b0b02d4427aa2b766dcd663822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eccec610abff4bd5bc98b8607f8cb484",
            "placeholder": "​",
            "style": "IPY_MODEL_f147f652db7d45d680cac73957e361cd",
            "value": "Epoch 3/50: 100%"
          }
        },
        "0c6c7415a2f640538b6e1464300b4288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7785a65db87c4b23881e6088ada7332e",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5cf80354a6745cd856f50834a479f66",
            "value": 469
          }
        },
        "6a76ca1a7a7942c18f991d36ab108513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b73575aca7b4b95bb9d38b8f1fe2b92",
            "placeholder": "​",
            "style": "IPY_MODEL_94e8c5d98ebb409a92c8caa2e940226d",
            "value": " 469/469 [00:35&lt;00:00, 11.72it/s, loss=168]"
          }
        },
        "2cd4b5d538cc41a68bb6b413c0c338e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eccec610abff4bd5bc98b8607f8cb484": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f147f652db7d45d680cac73957e361cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7785a65db87c4b23881e6088ada7332e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5cf80354a6745cd856f50834a479f66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b73575aca7b4b95bb9d38b8f1fe2b92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94e8c5d98ebb409a92c8caa2e940226d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "870ac42f03db4d45ac3562a676dcda12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16a274499106422c844a23900c05e66d",
              "IPY_MODEL_ce57a5b77bba431eb17a402cfa361698",
              "IPY_MODEL_38ce3b21505b470fb606a688e17e5f74"
            ],
            "layout": "IPY_MODEL_51a9d0a7f7a94f5183e72ffaa2d2e4ee"
          }
        },
        "16a274499106422c844a23900c05e66d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_142d37c9e7634396977235293dae74c2",
            "placeholder": "​",
            "style": "IPY_MODEL_6fde3d853b8d4f9db64fa56c9868bbd9",
            "value": "Epoch 4/50: 100%"
          }
        },
        "ce57a5b77bba431eb17a402cfa361698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60986bec8d3e497886c24441af02fe76",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98c2aca1940c467585162b9ca702421a",
            "value": 469
          }
        },
        "38ce3b21505b470fb606a688e17e5f74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_980f9007651c4f31afc66825c79a3530",
            "placeholder": "​",
            "style": "IPY_MODEL_51585c4b4af847198832add0fc4fc0e4",
            "value": " 469/469 [00:37&lt;00:00, 14.01it/s, loss=175]"
          }
        },
        "51a9d0a7f7a94f5183e72ffaa2d2e4ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "142d37c9e7634396977235293dae74c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fde3d853b8d4f9db64fa56c9868bbd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60986bec8d3e497886c24441af02fe76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98c2aca1940c467585162b9ca702421a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "980f9007651c4f31afc66825c79a3530": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51585c4b4af847198832add0fc4fc0e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "baa072f38975442f9203c327076a9fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7039af3a704f4117b5c096b15da21649",
              "IPY_MODEL_abdd0319286b40f18a944ba275488c48",
              "IPY_MODEL_d6e671c795794bafac25e0410d2bf943"
            ],
            "layout": "IPY_MODEL_c2d0556375c7455a9c9882078e02d0b5"
          }
        },
        "7039af3a704f4117b5c096b15da21649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a30eb4602104097aeb9a212965d1cf6",
            "placeholder": "​",
            "style": "IPY_MODEL_258f23ca46294dc580af749312c3b5ca",
            "value": "Epoch 5/50: 100%"
          }
        },
        "abdd0319286b40f18a944ba275488c48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fddf0ec772834c0db276b7365efef050",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d985e4b8c5534a8d83b21140691d0932",
            "value": 469
          }
        },
        "d6e671c795794bafac25e0410d2bf943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d3eebef04ed49bda5a2d5d2ded6b2b9",
            "placeholder": "​",
            "style": "IPY_MODEL_f6e2097b671741d1ad67bca672af2b98",
            "value": " 469/469 [00:36&lt;00:00, 14.04it/s, loss=161]"
          }
        },
        "c2d0556375c7455a9c9882078e02d0b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a30eb4602104097aeb9a212965d1cf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "258f23ca46294dc580af749312c3b5ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fddf0ec772834c0db276b7365efef050": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d985e4b8c5534a8d83b21140691d0932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d3eebef04ed49bda5a2d5d2ded6b2b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6e2097b671741d1ad67bca672af2b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b936c1256c5a4528a85b23ca549241c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_616d4276388c4c6695fc670933e62c1a",
              "IPY_MODEL_499f25e58f8a4c2097b621f9768c7ce2",
              "IPY_MODEL_421fef854ade4bb48419a5eabb739dd1"
            ],
            "layout": "IPY_MODEL_28178badf490430da0e78948585ebc3d"
          }
        },
        "616d4276388c4c6695fc670933e62c1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_785186aed0ad4205ab5e6c9ee6cce806",
            "placeholder": "​",
            "style": "IPY_MODEL_6ffe27aee8a545c1be14bf83d00b3d28",
            "value": "Epoch 6/50: 100%"
          }
        },
        "499f25e58f8a4c2097b621f9768c7ce2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81ab6d588e8f4251844d46f867cdabb8",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0877f78fb14439fa72f4fbf076747f5",
            "value": 469
          }
        },
        "421fef854ade4bb48419a5eabb739dd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e973369d8b0e4261bf0f24f2a76a908d",
            "placeholder": "​",
            "style": "IPY_MODEL_5079ca0acd0e430d979243727a806f09",
            "value": " 469/469 [00:36&lt;00:00, 14.30it/s, loss=163]"
          }
        },
        "28178badf490430da0e78948585ebc3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "785186aed0ad4205ab5e6c9ee6cce806": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ffe27aee8a545c1be14bf83d00b3d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81ab6d588e8f4251844d46f867cdabb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0877f78fb14439fa72f4fbf076747f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e973369d8b0e4261bf0f24f2a76a908d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5079ca0acd0e430d979243727a806f09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "116baa5f949a48d3899fd4a1b61cce58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd92a16d6bf749bdb4f50eede689e2df",
              "IPY_MODEL_1a18cb5b79db48c2ae404e9be5324982",
              "IPY_MODEL_0b80766078834fd3b3f53400f3bf9dd1"
            ],
            "layout": "IPY_MODEL_6335bde431bf471fa34cef4cf21ae2fc"
          }
        },
        "fd92a16d6bf749bdb4f50eede689e2df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c3d5efe3de44657881583f80a3ace32",
            "placeholder": "​",
            "style": "IPY_MODEL_09917968455541c7a7647d9e694327fa",
            "value": "Epoch 7/50: 100%"
          }
        },
        "1a18cb5b79db48c2ae404e9be5324982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c18376dc56da432ebda0ce6814458097",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d738ce50a2144b1a91e5e0e258a11c7",
            "value": 469
          }
        },
        "0b80766078834fd3b3f53400f3bf9dd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d4a7c73397c4762876e6487990154e3",
            "placeholder": "​",
            "style": "IPY_MODEL_61fed89722b94740a000d53261e387d4",
            "value": " 469/469 [00:36&lt;00:00,  9.68it/s, loss=169]"
          }
        },
        "6335bde431bf471fa34cef4cf21ae2fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c3d5efe3de44657881583f80a3ace32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09917968455541c7a7647d9e694327fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c18376dc56da432ebda0ce6814458097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d738ce50a2144b1a91e5e0e258a11c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d4a7c73397c4762876e6487990154e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61fed89722b94740a000d53261e387d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e23603b159da4e34b1daf5c8a64899aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ac579cd41a94f9abf20e09fc66dc53e",
              "IPY_MODEL_4291a57b3616444ab99898f2d4e142c2",
              "IPY_MODEL_35657f0be6ea4bac8abb3cde0d0fc18c"
            ],
            "layout": "IPY_MODEL_3e2ceae3abc14cdfa92446c4f9eab018"
          }
        },
        "9ac579cd41a94f9abf20e09fc66dc53e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8930fd94892743f7b37d79c6337ab1a7",
            "placeholder": "​",
            "style": "IPY_MODEL_cbfd5f07824c473c9d111c376331e69b",
            "value": "Epoch 8/50: 100%"
          }
        },
        "4291a57b3616444ab99898f2d4e142c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08122bb9df24409a9ee0eecf9e48632f",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71e04fd8e1934242823798d258016c92",
            "value": 469
          }
        },
        "35657f0be6ea4bac8abb3cde0d0fc18c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce946a4064a743abb2705a7c4ce51b8d",
            "placeholder": "​",
            "style": "IPY_MODEL_2ff8a4516a46458881ce3e1d8e356385",
            "value": " 469/469 [00:35&lt;00:00, 13.93it/s, loss=162]"
          }
        },
        "3e2ceae3abc14cdfa92446c4f9eab018": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8930fd94892743f7b37d79c6337ab1a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbfd5f07824c473c9d111c376331e69b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08122bb9df24409a9ee0eecf9e48632f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71e04fd8e1934242823798d258016c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce946a4064a743abb2705a7c4ce51b8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ff8a4516a46458881ce3e1d8e356385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d09dc537ff7458c9aa0196ef43f0556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd5b83cd1159427ca98463a7515fa01e",
              "IPY_MODEL_f9686a62c4844319941878b6d243be52",
              "IPY_MODEL_2bc05a27752e484b95d94691dfd280f0"
            ],
            "layout": "IPY_MODEL_ceb180ecab6e495d957841ae39b98a8d"
          }
        },
        "cd5b83cd1159427ca98463a7515fa01e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36a4134b139d48118517d57400012292",
            "placeholder": "​",
            "style": "IPY_MODEL_a9583ce2867e4c8d86be228fd065a405",
            "value": "Epoch 9/50: 100%"
          }
        },
        "f9686a62c4844319941878b6d243be52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df0612b7881e466caf599d3a1f29c5c5",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a216ad19c224a28a4ff7fbc860763c6",
            "value": 469
          }
        },
        "2bc05a27752e484b95d94691dfd280f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b40c96d1ddf41e0b532bd5d9b5ba570",
            "placeholder": "​",
            "style": "IPY_MODEL_d26f9b77feac4f30b72ac30ad96720a2",
            "value": " 469/469 [00:37&lt;00:00, 14.31it/s, loss=173]"
          }
        },
        "ceb180ecab6e495d957841ae39b98a8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36a4134b139d48118517d57400012292": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9583ce2867e4c8d86be228fd065a405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df0612b7881e466caf599d3a1f29c5c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a216ad19c224a28a4ff7fbc860763c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b40c96d1ddf41e0b532bd5d9b5ba570": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d26f9b77feac4f30b72ac30ad96720a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6aca790fb1ec41379be855f74ad4734b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d6a59a5a49e4fb9baf1818327544d0f",
              "IPY_MODEL_8b0b4eb3033e4d5c964cdd6ed171ea32",
              "IPY_MODEL_f4af6d0fa4cf415386033b1d3243d37f"
            ],
            "layout": "IPY_MODEL_3dcda3ede3034b879f37ad050c070ccd"
          }
        },
        "3d6a59a5a49e4fb9baf1818327544d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_affe348ba1f94543afe616ec85c57309",
            "placeholder": "​",
            "style": "IPY_MODEL_877a31958d494a8390a984de12652a87",
            "value": "Epoch 10/50: 100%"
          }
        },
        "8b0b4eb3033e4d5c964cdd6ed171ea32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa1684d40c264ecdbfd5a98d98dfcf27",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6865c40188fe48199d7933544c89e433",
            "value": 469
          }
        },
        "f4af6d0fa4cf415386033b1d3243d37f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca36e67a195941e5be65f9043e2c19d1",
            "placeholder": "​",
            "style": "IPY_MODEL_06841abea58046238cb2e77d0ae900b9",
            "value": " 469/469 [00:38&lt;00:00, 12.89it/s, loss=165]"
          }
        },
        "3dcda3ede3034b879f37ad050c070ccd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "affe348ba1f94543afe616ec85c57309": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "877a31958d494a8390a984de12652a87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa1684d40c264ecdbfd5a98d98dfcf27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6865c40188fe48199d7933544c89e433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca36e67a195941e5be65f9043e2c19d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06841abea58046238cb2e77d0ae900b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c4a4cc2645a42008f0c7cb2a70e83d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd511c7293e1470e9048e77a2dff4189",
              "IPY_MODEL_2db5d879ef0f4cc497f972242cf08e4c",
              "IPY_MODEL_cd7985fc2ad24b23a9beb87cd092e85c"
            ],
            "layout": "IPY_MODEL_78fbfc21b2d246629f95b7c1eab77b75"
          }
        },
        "fd511c7293e1470e9048e77a2dff4189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5526f3bc65714438993e727dfe7eeae2",
            "placeholder": "​",
            "style": "IPY_MODEL_20a747c0cdaf46ebaa063b7557a0bc93",
            "value": "Epoch 11/50: 100%"
          }
        },
        "2db5d879ef0f4cc497f972242cf08e4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02d3057c0a6049afb94853b229e437e6",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4bcefd5ef9e44ad1af8d734ce148a8b1",
            "value": 469
          }
        },
        "cd7985fc2ad24b23a9beb87cd092e85c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f774a90e74b4b40808e07d3ca98ed2c",
            "placeholder": "​",
            "style": "IPY_MODEL_4ab068d55294400abfdb22cccf7caeda",
            "value": " 469/469 [00:39&lt;00:00, 11.47it/s, loss=168]"
          }
        },
        "78fbfc21b2d246629f95b7c1eab77b75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5526f3bc65714438993e727dfe7eeae2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20a747c0cdaf46ebaa063b7557a0bc93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02d3057c0a6049afb94853b229e437e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bcefd5ef9e44ad1af8d734ce148a8b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f774a90e74b4b40808e07d3ca98ed2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ab068d55294400abfdb22cccf7caeda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca66d113aaad412b81607a209d293720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c706e2d1e87a41f28581179e3370133e",
              "IPY_MODEL_b72c67c0b5dc4e5ea0fcd5eb319df4ea",
              "IPY_MODEL_0ec41d9697e54388bdd52fca0bd78298"
            ],
            "layout": "IPY_MODEL_2378f8b9ab0a4e4599b8720e8a1411fd"
          }
        },
        "c706e2d1e87a41f28581179e3370133e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bb7b89dc721489d932faeecf49133b7",
            "placeholder": "​",
            "style": "IPY_MODEL_88e256853ff04cbd97df189053941d32",
            "value": "Epoch 12/50: 100%"
          }
        },
        "b72c67c0b5dc4e5ea0fcd5eb319df4ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85caa24f8879460f96735f3841c66eb1",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3795741f70bc4aa5851e873e4e8c3eb6",
            "value": 469
          }
        },
        "0ec41d9697e54388bdd52fca0bd78298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_910ba013d75342e6ba19ef1c37cda3fc",
            "placeholder": "​",
            "style": "IPY_MODEL_fc880e430ba94600be36ade1c618adae",
            "value": " 469/469 [00:39&lt;00:00, 12.17it/s, loss=160]"
          }
        },
        "2378f8b9ab0a4e4599b8720e8a1411fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bb7b89dc721489d932faeecf49133b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88e256853ff04cbd97df189053941d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85caa24f8879460f96735f3841c66eb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3795741f70bc4aa5851e873e4e8c3eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "910ba013d75342e6ba19ef1c37cda3fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc880e430ba94600be36ade1c618adae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19e918dd4b2149818701cfaba7e9089e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c83422a3380447293630127bde7a6a8",
              "IPY_MODEL_34c6ffb7d1d248489ec2e8d7824346ce",
              "IPY_MODEL_32531a55b53f4585acabf744496c285e"
            ],
            "layout": "IPY_MODEL_9ad85ce5f75d43f5b7c17933dfdda0fe"
          }
        },
        "3c83422a3380447293630127bde7a6a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_506d2b3bcef44b448c5ac852f2a427b0",
            "placeholder": "​",
            "style": "IPY_MODEL_8eb53965d21e4c45a5010d9149576593",
            "value": "Epoch 13/50: 100%"
          }
        },
        "34c6ffb7d1d248489ec2e8d7824346ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98272ce4a86b437bbde5ec3a161964bf",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_663d9970faf844818cc79fb5eacb1c9f",
            "value": 469
          }
        },
        "32531a55b53f4585acabf744496c285e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfc7c73ae12e4abb815921bcc495d9f6",
            "placeholder": "​",
            "style": "IPY_MODEL_fa6d57bb4da24efcab9b3c127aa998e3",
            "value": " 469/469 [00:39&lt;00:00, 10.21it/s, loss=160]"
          }
        },
        "9ad85ce5f75d43f5b7c17933dfdda0fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "506d2b3bcef44b448c5ac852f2a427b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8eb53965d21e4c45a5010d9149576593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98272ce4a86b437bbde5ec3a161964bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "663d9970faf844818cc79fb5eacb1c9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bfc7c73ae12e4abb815921bcc495d9f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa6d57bb4da24efcab9b3c127aa998e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b22809982fe4d7b96bf517c3d937144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2822828dfeb4c40b225d82c1cc76b9c",
              "IPY_MODEL_454f203b5e364ef9a5fafe41648698a7",
              "IPY_MODEL_adcc6fe62b4745c0aacedd82f7c46809"
            ],
            "layout": "IPY_MODEL_878b9dc364f149798e37a7b8f61d735b"
          }
        },
        "e2822828dfeb4c40b225d82c1cc76b9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbdd6dfd6caf4be6a50ebd10899ec935",
            "placeholder": "​",
            "style": "IPY_MODEL_f1d2d2bd07fa4f64ad6b57be7541ba69",
            "value": "Epoch 14/50: 100%"
          }
        },
        "454f203b5e364ef9a5fafe41648698a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81025d2bbbe848fa80cbe9ac0c2105af",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_014d6b03e57048b68ab4f53ec03ed8aa",
            "value": 469
          }
        },
        "adcc6fe62b4745c0aacedd82f7c46809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_137e6212a368493d96da46c5978af2a6",
            "placeholder": "​",
            "style": "IPY_MODEL_0ffcd420ea0d40299b115604e65288ba",
            "value": " 469/469 [00:39&lt;00:00, 10.15it/s, loss=158]"
          }
        },
        "878b9dc364f149798e37a7b8f61d735b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbdd6dfd6caf4be6a50ebd10899ec935": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1d2d2bd07fa4f64ad6b57be7541ba69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81025d2bbbe848fa80cbe9ac0c2105af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "014d6b03e57048b68ab4f53ec03ed8aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "137e6212a368493d96da46c5978af2a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ffcd420ea0d40299b115604e65288ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7615ac8b74c748d28e5104216b6dc95a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7f5d95f8ac141ff9f73c74e00036426",
              "IPY_MODEL_ca50691a680a4309b8b9b370cc10f4e7",
              "IPY_MODEL_35ae0c97cbe84ac382ae840f3a53a9d1"
            ],
            "layout": "IPY_MODEL_f30cd6e099e04f46a9601d73effb6141"
          }
        },
        "f7f5d95f8ac141ff9f73c74e00036426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f35b9fa7d8fd44dc8c5154ced5549dff",
            "placeholder": "​",
            "style": "IPY_MODEL_380dbd9a36754ffc8d3b93182321d43f",
            "value": "Epoch 15/50: 100%"
          }
        },
        "ca50691a680a4309b8b9b370cc10f4e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59a745cfeeaf4b06b5813a534e5dddc2",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fefb79697fe54683860fd343abed65a8",
            "value": 469
          }
        },
        "35ae0c97cbe84ac382ae840f3a53a9d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd52a236af0e4c93aefaa7313740282d",
            "placeholder": "​",
            "style": "IPY_MODEL_71a349ef48a8437eab9477787bc9a8b4",
            "value": " 469/469 [00:39&lt;00:00, 13.56it/s, loss=154]"
          }
        },
        "f30cd6e099e04f46a9601d73effb6141": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f35b9fa7d8fd44dc8c5154ced5549dff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "380dbd9a36754ffc8d3b93182321d43f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59a745cfeeaf4b06b5813a534e5dddc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fefb79697fe54683860fd343abed65a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd52a236af0e4c93aefaa7313740282d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71a349ef48a8437eab9477787bc9a8b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88ffbf07fd9b453b9a17ef5124dd5cbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c33030cd9ed45a68d0b0ea5e59485ff",
              "IPY_MODEL_3d6123be815741649c6ecf03ad92432f",
              "IPY_MODEL_ea0df509c1f5495a867a8e66fdfe3edd"
            ],
            "layout": "IPY_MODEL_97b2df379913440b88ad497ae1b68942"
          }
        },
        "2c33030cd9ed45a68d0b0ea5e59485ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ac4bfc6c32746979f70b39c911069da",
            "placeholder": "​",
            "style": "IPY_MODEL_571a42b3b4b1468ab4908249adf2bdd2",
            "value": "Epoch 16/50: 100%"
          }
        },
        "3d6123be815741649c6ecf03ad92432f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c730bf8757144388ae4bb14132f3b7c6",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41940c5a120746b7808e52541abd759c",
            "value": 469
          }
        },
        "ea0df509c1f5495a867a8e66fdfe3edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4445a28dffab44009b69323dbd49b2ac",
            "placeholder": "​",
            "style": "IPY_MODEL_6e839774a64546f78092080f911a0938",
            "value": " 469/469 [00:40&lt;00:00, 13.10it/s, loss=160]"
          }
        },
        "97b2df379913440b88ad497ae1b68942": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ac4bfc6c32746979f70b39c911069da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "571a42b3b4b1468ab4908249adf2bdd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c730bf8757144388ae4bb14132f3b7c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41940c5a120746b7808e52541abd759c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4445a28dffab44009b69323dbd49b2ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e839774a64546f78092080f911a0938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3320b9b595e146ada64953f5a232d93a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d34ee07158924dd5be537e63f425ce9a",
              "IPY_MODEL_5977a1bc0ef64bf1b6091649a9d22b36",
              "IPY_MODEL_42adcc4a012c4528a7d40871e0245a62"
            ],
            "layout": "IPY_MODEL_643ce760182f4f138feba3b0cac42657"
          }
        },
        "d34ee07158924dd5be537e63f425ce9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d321bad2e73446d9efce5277a8de80e",
            "placeholder": "​",
            "style": "IPY_MODEL_940d7ce0073d40fb9b4a52579bf9b14f",
            "value": "Epoch 17/50: 100%"
          }
        },
        "5977a1bc0ef64bf1b6091649a9d22b36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33e387c71fb54e12a8f60b7431253aa0",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f9504f845334804ad3147f03fbd8aaf",
            "value": 469
          }
        },
        "42adcc4a012c4528a7d40871e0245a62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76fd4bfdb7894b96829b10825647548e",
            "placeholder": "​",
            "style": "IPY_MODEL_9d1518f8b52c4c1486a6bfd19c9e187b",
            "value": " 469/469 [00:40&lt;00:00, 12.31it/s, loss=168]"
          }
        },
        "643ce760182f4f138feba3b0cac42657": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d321bad2e73446d9efce5277a8de80e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "940d7ce0073d40fb9b4a52579bf9b14f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33e387c71fb54e12a8f60b7431253aa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f9504f845334804ad3147f03fbd8aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76fd4bfdb7894b96829b10825647548e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d1518f8b52c4c1486a6bfd19c9e187b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e70ce8253fa4190ada086ec0f578b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57cdd8f0335c4f4eb8041b6c8c50d053",
              "IPY_MODEL_c2575ee9d79d4ca982676832ce145e70",
              "IPY_MODEL_8abb0675ff2c4dac9cca88ca66e31e94"
            ],
            "layout": "IPY_MODEL_304fe8c90f894202b0d73a618984c6d6"
          }
        },
        "57cdd8f0335c4f4eb8041b6c8c50d053": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_229fdc250eec47e59708b2011bbea0bf",
            "placeholder": "​",
            "style": "IPY_MODEL_31afebceb5af44048f1a0742f983c0e1",
            "value": "Epoch 18/50: 100%"
          }
        },
        "c2575ee9d79d4ca982676832ce145e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b12f009a5d824aef99c82f864a8c0401",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_525c764195b647bfa75f3936fd688e95",
            "value": 469
          }
        },
        "8abb0675ff2c4dac9cca88ca66e31e94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64729ee402784f6d85dd988105c0474e",
            "placeholder": "​",
            "style": "IPY_MODEL_5a94761a9a204948bfe3af8fef294e6e",
            "value": " 469/469 [00:40&lt;00:00, 13.27it/s, loss=157]"
          }
        },
        "304fe8c90f894202b0d73a618984c6d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "229fdc250eec47e59708b2011bbea0bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31afebceb5af44048f1a0742f983c0e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b12f009a5d824aef99c82f864a8c0401": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "525c764195b647bfa75f3936fd688e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64729ee402784f6d85dd988105c0474e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a94761a9a204948bfe3af8fef294e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7738fc61b7d34c4cae34cea1173c28e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cef5f2e48745497fb106e791417fa058",
              "IPY_MODEL_e392bb892e484135a685007bbe9690d0",
              "IPY_MODEL_9234171501ef412cbbf8255dde017e56"
            ],
            "layout": "IPY_MODEL_15a4fe6bf0bd407d84ac5519815c566c"
          }
        },
        "cef5f2e48745497fb106e791417fa058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eda2e20bad144f3c869b74ca67405d6c",
            "placeholder": "​",
            "style": "IPY_MODEL_98d509b910c342278df249722e2177b6",
            "value": "Epoch 19/50: 100%"
          }
        },
        "e392bb892e484135a685007bbe9690d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bd41598137e43e3ba8a08be544b5058",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b4f088790bc4b39b68af7d2b688ee0b",
            "value": 469
          }
        },
        "9234171501ef412cbbf8255dde017e56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4b2ef7ee5ff4f5ea9ffad68aa506b9b",
            "placeholder": "​",
            "style": "IPY_MODEL_f69b8c1737b14428bf91e7c9dcba4bc7",
            "value": " 469/469 [00:40&lt;00:00, 13.05it/s, loss=162]"
          }
        },
        "15a4fe6bf0bd407d84ac5519815c566c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eda2e20bad144f3c869b74ca67405d6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98d509b910c342278df249722e2177b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bd41598137e43e3ba8a08be544b5058": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b4f088790bc4b39b68af7d2b688ee0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4b2ef7ee5ff4f5ea9ffad68aa506b9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f69b8c1737b14428bf91e7c9dcba4bc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87fe475b86494a1c8609762612b317d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_413201d8cef14c9485111e3acbd6fb4f",
              "IPY_MODEL_335ac92aeefd408da81786abcc39773f",
              "IPY_MODEL_be61ad953a5b4c6bb6a5486c2d600f64"
            ],
            "layout": "IPY_MODEL_b0a2ad0016874fbfabe4469f9a3d093a"
          }
        },
        "413201d8cef14c9485111e3acbd6fb4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a2f02ac84684757b5bdcf768753379f",
            "placeholder": "​",
            "style": "IPY_MODEL_63988d69996e445a9102270f3f084a37",
            "value": "Epoch 20/50: 100%"
          }
        },
        "335ac92aeefd408da81786abcc39773f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e32036f8d80481cbbc334a1b410595a",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7dd362c02e0a4d469f4501684e529578",
            "value": 469
          }
        },
        "be61ad953a5b4c6bb6a5486c2d600f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_070114169d8a41219d2adb003410a74c",
            "placeholder": "​",
            "style": "IPY_MODEL_54a7b2cdd1d540caa378719479b7bad4",
            "value": " 469/469 [00:40&lt;00:00,  9.15it/s, loss=162]"
          }
        },
        "b0a2ad0016874fbfabe4469f9a3d093a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a2f02ac84684757b5bdcf768753379f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63988d69996e445a9102270f3f084a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e32036f8d80481cbbc334a1b410595a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dd362c02e0a4d469f4501684e529578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "070114169d8a41219d2adb003410a74c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54a7b2cdd1d540caa378719479b7bad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3fe5addf0df458e979f2da7b30544df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0dcfb90b9eee44c08216e0eaf64253d7",
              "IPY_MODEL_e2853ab6b8394442891852243d0f681d",
              "IPY_MODEL_97541356a20f4000a7a13e94efa85816"
            ],
            "layout": "IPY_MODEL_01506b5a963c4aaaaf07cda46573a43a"
          }
        },
        "0dcfb90b9eee44c08216e0eaf64253d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d20b453b69e34d30ae29c56a9729a5e6",
            "placeholder": "​",
            "style": "IPY_MODEL_4dd4ad3dd68343fea6c652b1c66c8ab5",
            "value": "Epoch 21/50: 100%"
          }
        },
        "e2853ab6b8394442891852243d0f681d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d0cd0e2214b45a68b45ebbdf9a19f10",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4bb96c466c0f460da93cd33cb56882c7",
            "value": 469
          }
        },
        "97541356a20f4000a7a13e94efa85816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b36716b3e9e145fdafe1b04532e580a2",
            "placeholder": "​",
            "style": "IPY_MODEL_6930fa7ba0a145bd97b9b734876fab3d",
            "value": " 469/469 [00:41&lt;00:00, 10.09it/s, loss=166]"
          }
        },
        "01506b5a963c4aaaaf07cda46573a43a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d20b453b69e34d30ae29c56a9729a5e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dd4ad3dd68343fea6c652b1c66c8ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d0cd0e2214b45a68b45ebbdf9a19f10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bb96c466c0f460da93cd33cb56882c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b36716b3e9e145fdafe1b04532e580a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6930fa7ba0a145bd97b9b734876fab3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73c9de68f5be4269b838ad66daf6f227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f511e23171324ad8b94cb30bed463b47",
              "IPY_MODEL_d3e3446819a14cab9064d07504bd5f69",
              "IPY_MODEL_a24e4d4969384fb1a4fea185a8f9bba0"
            ],
            "layout": "IPY_MODEL_c669c574d5ea46cda5e825f8506a3eb9"
          }
        },
        "f511e23171324ad8b94cb30bed463b47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d39a4f53866a40dfa0531d5847cc6896",
            "placeholder": "​",
            "style": "IPY_MODEL_4d5a2607e5844b28a6d85da21cd7ed4f",
            "value": "Epoch 22/50: 100%"
          }
        },
        "d3e3446819a14cab9064d07504bd5f69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff3c5de723884d5b87e1743253038725",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13f7ddfd5ee0423a834ebc84eda8c1e4",
            "value": 469
          }
        },
        "a24e4d4969384fb1a4fea185a8f9bba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f9d1dfbd62647bc9699d06c93c006ec",
            "placeholder": "​",
            "style": "IPY_MODEL_e5ad84c22de247f6924c23658566c6a4",
            "value": " 469/469 [00:41&lt;00:00, 12.22it/s, loss=153]"
          }
        },
        "c669c574d5ea46cda5e825f8506a3eb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d39a4f53866a40dfa0531d5847cc6896": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d5a2607e5844b28a6d85da21cd7ed4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff3c5de723884d5b87e1743253038725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13f7ddfd5ee0423a834ebc84eda8c1e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f9d1dfbd62647bc9699d06c93c006ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5ad84c22de247f6924c23658566c6a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "095da23dda0141e3a64271455c55d866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9515bfec69a84390b06e3059a2bd6b0f",
              "IPY_MODEL_c7b701ef3685484da60978b0f3bd106d",
              "IPY_MODEL_96d243452aef4d65aa98bcf6c2d9aa15"
            ],
            "layout": "IPY_MODEL_9a5e912157834fe08eeebab179271d63"
          }
        },
        "9515bfec69a84390b06e3059a2bd6b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abc7ba33d5054fe683fcaa9e664b113f",
            "placeholder": "​",
            "style": "IPY_MODEL_08f78133816c42419e0370c63f5ce0bd",
            "value": "Epoch 23/50: 100%"
          }
        },
        "c7b701ef3685484da60978b0f3bd106d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7514b47d2b347108e6ad44a5b0ecd5e",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65fb7cc73cc0415782004d3315edb080",
            "value": 469
          }
        },
        "96d243452aef4d65aa98bcf6c2d9aa15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa16dafc7f504195a398b9ca2df8db2d",
            "placeholder": "​",
            "style": "IPY_MODEL_c3f2ec2fcfa04b89a0dfa0e7c1ab4b55",
            "value": " 469/469 [00:42&lt;00:00, 12.35it/s, loss=161]"
          }
        },
        "9a5e912157834fe08eeebab179271d63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abc7ba33d5054fe683fcaa9e664b113f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08f78133816c42419e0370c63f5ce0bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7514b47d2b347108e6ad44a5b0ecd5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65fb7cc73cc0415782004d3315edb080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa16dafc7f504195a398b9ca2df8db2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3f2ec2fcfa04b89a0dfa0e7c1ab4b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "411ce77955d5465b8b0393fb79a648b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_284a798f52ac42049b3f154cb7f89782",
              "IPY_MODEL_666f47a7cc3f4c8eac679a96268f325d",
              "IPY_MODEL_657b13493dea4a41a47ea7837bbe4027"
            ],
            "layout": "IPY_MODEL_ac0f833b42ec48dca966b027622e3871"
          }
        },
        "284a798f52ac42049b3f154cb7f89782": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0ff00b64d334b18a111df40001c59cc",
            "placeholder": "​",
            "style": "IPY_MODEL_46972aa629ee4e33856786f7891946fa",
            "value": "Epoch 24/50: 100%"
          }
        },
        "666f47a7cc3f4c8eac679a96268f325d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f55b271e9a44cf1be9342d3566f3fb6",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4e59f0494b5418e8050afd7eaf2435f",
            "value": 469
          }
        },
        "657b13493dea4a41a47ea7837bbe4027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed566e034222434bbc4eb35422a7e233",
            "placeholder": "​",
            "style": "IPY_MODEL_bc28e863aa8f49728865b18cd7bf5158",
            "value": " 469/469 [00:43&lt;00:00, 12.46it/s, loss=152]"
          }
        },
        "ac0f833b42ec48dca966b027622e3871": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0ff00b64d334b18a111df40001c59cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46972aa629ee4e33856786f7891946fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f55b271e9a44cf1be9342d3566f3fb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4e59f0494b5418e8050afd7eaf2435f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed566e034222434bbc4eb35422a7e233": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc28e863aa8f49728865b18cd7bf5158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3275862e0cd4452a4cdaddd33a1af80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73a3cf9dfdf54e11948e4b579bd7992d",
              "IPY_MODEL_ada69746ec9f4e07b358a6c71cb71727",
              "IPY_MODEL_9bba5118756e41bd9c481d67c474833e"
            ],
            "layout": "IPY_MODEL_aa0c91cf6b5845d797ba981be6897b6f"
          }
        },
        "73a3cf9dfdf54e11948e4b579bd7992d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8e5adba80f544218e8ebf3ecee7f9d4",
            "placeholder": "​",
            "style": "IPY_MODEL_081ab1e0d269467e80dfbd7282668182",
            "value": "Epoch 25/50: 100%"
          }
        },
        "ada69746ec9f4e07b358a6c71cb71727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6156cd6d5db4b95b1f0a1c5367e5fc7",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5466e32e2dbb4f70979da23867cf22df",
            "value": 469
          }
        },
        "9bba5118756e41bd9c481d67c474833e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41f359f703524740bf60b889bfb475d3",
            "placeholder": "​",
            "style": "IPY_MODEL_3cd897cfc339442cb0f641a8d4662830",
            "value": " 469/469 [00:42&lt;00:00, 12.27it/s, loss=163]"
          }
        },
        "aa0c91cf6b5845d797ba981be6897b6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8e5adba80f544218e8ebf3ecee7f9d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "081ab1e0d269467e80dfbd7282668182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6156cd6d5db4b95b1f0a1c5367e5fc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5466e32e2dbb4f70979da23867cf22df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41f359f703524740bf60b889bfb475d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cd897cfc339442cb0f641a8d4662830": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "454a6c4458994d329be9af40606cdf21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75cf5e9e1f8b4890a4011413aac2ac32",
              "IPY_MODEL_46f2350410134475b913ae59696c907e",
              "IPY_MODEL_a3b45b2277d54a8387bede7acd13d76f"
            ],
            "layout": "IPY_MODEL_e6cc7e0d99f64874a7048b09b1f6a193"
          }
        },
        "75cf5e9e1f8b4890a4011413aac2ac32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27b7350be6144686b1dd1c0b1fbad38f",
            "placeholder": "​",
            "style": "IPY_MODEL_2a98ebd1102d4f3c9b3a61ee44f3fcd1",
            "value": "Epoch 26/50: 100%"
          }
        },
        "46f2350410134475b913ae59696c907e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaf3c550fc65428aa90664e0ac637416",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8f39f5f403649b4a61f3607fd537936",
            "value": 469
          }
        },
        "a3b45b2277d54a8387bede7acd13d76f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d631da5eddd479bb087bc3e9ee98d14",
            "placeholder": "​",
            "style": "IPY_MODEL_eeb681c42d9746b8b6b11a8b88180088",
            "value": " 469/469 [00:43&lt;00:00, 12.02it/s, loss=153]"
          }
        },
        "e6cc7e0d99f64874a7048b09b1f6a193": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27b7350be6144686b1dd1c0b1fbad38f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a98ebd1102d4f3c9b3a61ee44f3fcd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aaf3c550fc65428aa90664e0ac637416": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8f39f5f403649b4a61f3607fd537936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d631da5eddd479bb087bc3e9ee98d14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeb681c42d9746b8b6b11a8b88180088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45b41b0e7b7149e1b850f5bbe82ae52e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f13f57cc38d40f1ba67ddf2ea4be121",
              "IPY_MODEL_b241ac11176748d3ab422bb29299771e",
              "IPY_MODEL_be1b66ccc93841938ed281c9f10b7995"
            ],
            "layout": "IPY_MODEL_1549cd77bf3347a28f5ea27283c0b40a"
          }
        },
        "7f13f57cc38d40f1ba67ddf2ea4be121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69f69fe894994f4f897c5b16f4689127",
            "placeholder": "​",
            "style": "IPY_MODEL_fb3c6aa9da824fd68639f206cb9768d7",
            "value": "Epoch 27/50: 100%"
          }
        },
        "b241ac11176748d3ab422bb29299771e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d52a34a1abe54e1daa2a7d1544e3606b",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ba4882cb3304273959b7ed74c655389",
            "value": 469
          }
        },
        "be1b66ccc93841938ed281c9f10b7995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e142b07d38084e658f1442b87f5920d9",
            "placeholder": "​",
            "style": "IPY_MODEL_86fa3296a461406a919ed7d2ee04c2b8",
            "value": " 469/469 [00:42&lt;00:00, 12.48it/s, loss=162]"
          }
        },
        "1549cd77bf3347a28f5ea27283c0b40a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69f69fe894994f4f897c5b16f4689127": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb3c6aa9da824fd68639f206cb9768d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d52a34a1abe54e1daa2a7d1544e3606b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ba4882cb3304273959b7ed74c655389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e142b07d38084e658f1442b87f5920d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86fa3296a461406a919ed7d2ee04c2b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0547caab71064515a84c3b99aeea6b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d51dacb79284b8ab831ecb44a2a8a74",
              "IPY_MODEL_13d55eab4a3448cd90e54944bc75850e",
              "IPY_MODEL_8ef48099f63547afba86393810e4102e"
            ],
            "layout": "IPY_MODEL_9ae63fb10ef1472cb14acb26ecff56c7"
          }
        },
        "9d51dacb79284b8ab831ecb44a2a8a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_303f45515ee44257bc57b122d1f8c6dc",
            "placeholder": "​",
            "style": "IPY_MODEL_a9a9a526a23c4c43a9b50a9c3e8b2a2a",
            "value": "Epoch 28/50: 100%"
          }
        },
        "13d55eab4a3448cd90e54944bc75850e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a341dae5eb8f4f888f2f3b041567921f",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75a5e081453541e1958543448d13e517",
            "value": 469
          }
        },
        "8ef48099f63547afba86393810e4102e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b0f97b8b27644cc801aaf371b130165",
            "placeholder": "​",
            "style": "IPY_MODEL_abeb822c612e49198a255fd982a62b30",
            "value": " 469/469 [00:43&lt;00:00, 10.17it/s, loss=161]"
          }
        },
        "9ae63fb10ef1472cb14acb26ecff56c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "303f45515ee44257bc57b122d1f8c6dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9a9a526a23c4c43a9b50a9c3e8b2a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a341dae5eb8f4f888f2f3b041567921f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75a5e081453541e1958543448d13e517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b0f97b8b27644cc801aaf371b130165": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abeb822c612e49198a255fd982a62b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "543c285d04574e808258b892f977c923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0343dae676eb4e469309eed8ecd0d03c",
              "IPY_MODEL_681e677b49df43118a90c4d137e88293",
              "IPY_MODEL_f44e05c198ef468499ab53889e179fcb"
            ],
            "layout": "IPY_MODEL_e9954604ff984e71a027414b69675390"
          }
        },
        "0343dae676eb4e469309eed8ecd0d03c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a20d2d250e04ecb8f9a798a0ab1925b",
            "placeholder": "​",
            "style": "IPY_MODEL_f8f794f366fb4e1195246b9e7d96b750",
            "value": "Epoch 29/50: 100%"
          }
        },
        "681e677b49df43118a90c4d137e88293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25f926b1d70d421ca7fa0543a15c8505",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ca7c9f77c694a788c7d2c2721a527fe",
            "value": 469
          }
        },
        "f44e05c198ef468499ab53889e179fcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2361810fae454e44b6da7452943c6eab",
            "placeholder": "​",
            "style": "IPY_MODEL_45f3d75a5f14418e9698ed1211315c98",
            "value": " 469/469 [00:43&lt;00:00,  8.77it/s, loss=159]"
          }
        },
        "e9954604ff984e71a027414b69675390": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a20d2d250e04ecb8f9a798a0ab1925b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8f794f366fb4e1195246b9e7d96b750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25f926b1d70d421ca7fa0543a15c8505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ca7c9f77c694a788c7d2c2721a527fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2361810fae454e44b6da7452943c6eab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45f3d75a5f14418e9698ed1211315c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ac3e1695a7246af89d87b2d5a0e3110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d06038bfeb47486fa4e191668a927da5",
              "IPY_MODEL_3bb3cff875de4226a7773c01af0d290f",
              "IPY_MODEL_9c8e881d6ced47f2998ab48e42f433d1"
            ],
            "layout": "IPY_MODEL_22364925e3574b2a93fb43fb6a661f3b"
          }
        },
        "d06038bfeb47486fa4e191668a927da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b90981e1f33744468b6e2b437ec70e9c",
            "placeholder": "​",
            "style": "IPY_MODEL_935c48dd108c4f02823edbe069d98ebb",
            "value": "Epoch 30/50: 100%"
          }
        },
        "3bb3cff875de4226a7773c01af0d290f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ed51952a94a48edbdf94bbbd5ae5418",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e0b4c23e00f497089a61fc0fa8de82c",
            "value": 469
          }
        },
        "9c8e881d6ced47f2998ab48e42f433d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f168f8afaf4442db6e9168d1196f822",
            "placeholder": "​",
            "style": "IPY_MODEL_57a1f8e36651484e8859384f2b48adaa",
            "value": " 469/469 [00:43&lt;00:00,  9.33it/s, loss=160]"
          }
        },
        "22364925e3574b2a93fb43fb6a661f3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b90981e1f33744468b6e2b437ec70e9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "935c48dd108c4f02823edbe069d98ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ed51952a94a48edbdf94bbbd5ae5418": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e0b4c23e00f497089a61fc0fa8de82c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f168f8afaf4442db6e9168d1196f822": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57a1f8e36651484e8859384f2b48adaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99c2e3598cc44090a6aa8475e65cd936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de7ab8b480d84030a2c9c30419e30f8b",
              "IPY_MODEL_b38738be65394ed69803556619ff7b69",
              "IPY_MODEL_ebaf6fb5a77a432ca987df48cf3b2b82"
            ],
            "layout": "IPY_MODEL_6b567a2c7c36453ea38077c981debcf8"
          }
        },
        "de7ab8b480d84030a2c9c30419e30f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bad7e73591ba4585ab1a90fbc06de951",
            "placeholder": "​",
            "style": "IPY_MODEL_bb4b38149e384c31b8e4f3b462132d49",
            "value": "Epoch 31/50: 100%"
          }
        },
        "b38738be65394ed69803556619ff7b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19434913ca524f90b1ba599bc4ffa108",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ea95a90c69441eb8f9688171aa377cf",
            "value": 469
          }
        },
        "ebaf6fb5a77a432ca987df48cf3b2b82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_613dd2eb57ca4d2980deed3441657bd0",
            "placeholder": "​",
            "style": "IPY_MODEL_3d9f633c84fe489c928a25df11a4be93",
            "value": " 469/469 [00:44&lt;00:00,  9.62it/s, loss=154]"
          }
        },
        "6b567a2c7c36453ea38077c981debcf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bad7e73591ba4585ab1a90fbc06de951": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb4b38149e384c31b8e4f3b462132d49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19434913ca524f90b1ba599bc4ffa108": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ea95a90c69441eb8f9688171aa377cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "613dd2eb57ca4d2980deed3441657bd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d9f633c84fe489c928a25df11a4be93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b51cd3bd62914bb3a05b8fb9530c126e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a59f1f097c174e6c99f7502cd15815b2",
              "IPY_MODEL_110eff51469a4a56a83d2799735f9e13",
              "IPY_MODEL_5888287b267b46a2bd8b41eb680eec3b"
            ],
            "layout": "IPY_MODEL_ea5a940732594705952dde2aa1bcf3a9"
          }
        },
        "a59f1f097c174e6c99f7502cd15815b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19142748df3447d29aa472a72500fee8",
            "placeholder": "​",
            "style": "IPY_MODEL_622ef648fcd540a18a97eaea5881c2f9",
            "value": "Epoch 32/50: 100%"
          }
        },
        "110eff51469a4a56a83d2799735f9e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34adb422a9d741458e6134fd41347238",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4968af1520064757a3ba7f09b46031f5",
            "value": 469
          }
        },
        "5888287b267b46a2bd8b41eb680eec3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f69cc95bc91442fb88e9fc4d767a99f",
            "placeholder": "​",
            "style": "IPY_MODEL_572ca8fb5718493fac3dcbec0a752cbf",
            "value": " 469/469 [00:45&lt;00:00,  8.37it/s, loss=160]"
          }
        },
        "ea5a940732594705952dde2aa1bcf3a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19142748df3447d29aa472a72500fee8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "622ef648fcd540a18a97eaea5881c2f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34adb422a9d741458e6134fd41347238": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4968af1520064757a3ba7f09b46031f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f69cc95bc91442fb88e9fc4d767a99f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "572ca8fb5718493fac3dcbec0a752cbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abecedb8556f415db0892ed17e4130ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_980c9a7babb246dcb451faf7a07b9b29",
              "IPY_MODEL_7e2054de32a04142bfeccc14c17190c0",
              "IPY_MODEL_4aafdb9b07eb4ce5a208206a5c84ef19"
            ],
            "layout": "IPY_MODEL_c043957950d84c8ebfdad7c78027fc20"
          }
        },
        "980c9a7babb246dcb451faf7a07b9b29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee582ac6a0bb4c2d814f9d7caebba051",
            "placeholder": "​",
            "style": "IPY_MODEL_7c6e70b88fb446bf9ae9a2e83832f5f6",
            "value": "Epoch 33/50: 100%"
          }
        },
        "7e2054de32a04142bfeccc14c17190c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43eeabee0a214850a5c5de140005dfe6",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bce5f1aa0cba40f9b5666f44db27f0f4",
            "value": 469
          }
        },
        "4aafdb9b07eb4ce5a208206a5c84ef19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65a22d64c21a4a259528dbbb4a7c8b50",
            "placeholder": "​",
            "style": "IPY_MODEL_caeed18a8bc74ccb87364c336a3aa493",
            "value": " 469/469 [00:49&lt;00:00,  8.80it/s, loss=162]"
          }
        },
        "c043957950d84c8ebfdad7c78027fc20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee582ac6a0bb4c2d814f9d7caebba051": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c6e70b88fb446bf9ae9a2e83832f5f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43eeabee0a214850a5c5de140005dfe6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bce5f1aa0cba40f9b5666f44db27f0f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65a22d64c21a4a259528dbbb4a7c8b50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caeed18a8bc74ccb87364c336a3aa493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2bd13063f724e098061d6a52299a54d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a97804dd25c14005b186bf584bb51e24",
              "IPY_MODEL_0f81b73780ac47d9860c93d6960e28b6",
              "IPY_MODEL_f238c0dd2fee43cca956af9758868814"
            ],
            "layout": "IPY_MODEL_a19ce49a9f8f43748fb0b840870c8949"
          }
        },
        "a97804dd25c14005b186bf584bb51e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48197e339d5e4278b2c1219196a26a14",
            "placeholder": "​",
            "style": "IPY_MODEL_2a467b955bf04e54970b27f4b83c1a3a",
            "value": "Epoch 34/50: 100%"
          }
        },
        "0f81b73780ac47d9860c93d6960e28b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f60ad18c25a944d98271b607d216d7a9",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4a9760b32c34ddc8eb17d006c31dc66",
            "value": 469
          }
        },
        "f238c0dd2fee43cca956af9758868814": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2442bac2ecd4211890683424198a37b",
            "placeholder": "​",
            "style": "IPY_MODEL_194f5304c13842d5a9b6596ef0498f8f",
            "value": " 469/469 [00:55&lt;00:00,  8.27it/s, loss=156]"
          }
        },
        "a19ce49a9f8f43748fb0b840870c8949": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48197e339d5e4278b2c1219196a26a14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a467b955bf04e54970b27f4b83c1a3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f60ad18c25a944d98271b607d216d7a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4a9760b32c34ddc8eb17d006c31dc66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2442bac2ecd4211890683424198a37b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "194f5304c13842d5a9b6596ef0498f8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "559c1f9435c542098c57ae5e6fb80f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f67d0b137b1f4d2bb16314d6aa991e72",
              "IPY_MODEL_89661a3e246242a9ae0cac6d19994329",
              "IPY_MODEL_e95a71c3df3c41bfab14de73c83c4214"
            ],
            "layout": "IPY_MODEL_2135b7041d264f12ad9173a502893357"
          }
        },
        "f67d0b137b1f4d2bb16314d6aa991e72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd24c88466a64edfbc24e5acf92ea92c",
            "placeholder": "​",
            "style": "IPY_MODEL_6a71c1998d2c4899acc6c716ad4b60c9",
            "value": "Epoch 35/50: 100%"
          }
        },
        "89661a3e246242a9ae0cac6d19994329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84db6176bc7047649796e82764f374d2",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d99e2db1398544c2bd070e45b51d610a",
            "value": 469
          }
        },
        "e95a71c3df3c41bfab14de73c83c4214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3485555976aa47d8a7bbd1e56e5c3817",
            "placeholder": "​",
            "style": "IPY_MODEL_95630d42e05b47c08f576a6ad01d2f07",
            "value": " 469/469 [00:56&lt;00:00,  8.65it/s, loss=162]"
          }
        },
        "2135b7041d264f12ad9173a502893357": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd24c88466a64edfbc24e5acf92ea92c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a71c1998d2c4899acc6c716ad4b60c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84db6176bc7047649796e82764f374d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d99e2db1398544c2bd070e45b51d610a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3485555976aa47d8a7bbd1e56e5c3817": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95630d42e05b47c08f576a6ad01d2f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d45f9a8ee9e1428d814c6928a977f0dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2806a0e527864264af59b732620b1426",
              "IPY_MODEL_54357e709a4f4209a2ce16cc2f4f4a1b",
              "IPY_MODEL_fdbfdfee3bbf4954a28fca55483b7c2d"
            ],
            "layout": "IPY_MODEL_702a44bdd10041c48463201654d8dce3"
          }
        },
        "2806a0e527864264af59b732620b1426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44caecfe3fce4b9f81ab9255307f20b7",
            "placeholder": "​",
            "style": "IPY_MODEL_bc8f1c488fca42919dc6c79e02181af8",
            "value": "Epoch 36/50: 100%"
          }
        },
        "54357e709a4f4209a2ce16cc2f4f4a1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b25b4fd57bbf4360a73495aaf2e0a703",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d68ccc391d74207a223f51fc4ab4fcb",
            "value": 469
          }
        },
        "fdbfdfee3bbf4954a28fca55483b7c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e88d74b50a77427e8ed91a549c431070",
            "placeholder": "​",
            "style": "IPY_MODEL_2567fe145f98421f97ae16a6c285f99b",
            "value": " 469/469 [00:53&lt;00:00,  9.74it/s, loss=166]"
          }
        },
        "702a44bdd10041c48463201654d8dce3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44caecfe3fce4b9f81ab9255307f20b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc8f1c488fca42919dc6c79e02181af8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b25b4fd57bbf4360a73495aaf2e0a703": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d68ccc391d74207a223f51fc4ab4fcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e88d74b50a77427e8ed91a549c431070": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2567fe145f98421f97ae16a6c285f99b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "615dfa53fde64eff945eb1493c75bd1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2cc5532f7364fa3b576f2a8202cdbc9",
              "IPY_MODEL_89e9dcdd52914ea483fc17d14814cdb3",
              "IPY_MODEL_203b5a00d3964f2f83f39d69d32a94e4"
            ],
            "layout": "IPY_MODEL_e1c53acd72c14a5fb24585dd2d5c7b18"
          }
        },
        "d2cc5532f7364fa3b576f2a8202cdbc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c27f909ca80c498e9debf0238b54beec",
            "placeholder": "​",
            "style": "IPY_MODEL_66bad51a686e404591902b38114d08bd",
            "value": "Epoch 37/50: 100%"
          }
        },
        "89e9dcdd52914ea483fc17d14814cdb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53eee326ed174387a4cd48257ec971a2",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24c15ed9762a4ee8a4d0da2ddb353243",
            "value": 469
          }
        },
        "203b5a00d3964f2f83f39d69d32a94e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_948df7f6ab4647ddb7f7bb6b79da401a",
            "placeholder": "​",
            "style": "IPY_MODEL_f9c520baa9b547b285b5f8beb5f38985",
            "value": " 469/469 [00:54&lt;00:00,  8.43it/s, loss=164]"
          }
        },
        "e1c53acd72c14a5fb24585dd2d5c7b18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c27f909ca80c498e9debf0238b54beec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66bad51a686e404591902b38114d08bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53eee326ed174387a4cd48257ec971a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24c15ed9762a4ee8a4d0da2ddb353243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "948df7f6ab4647ddb7f7bb6b79da401a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9c520baa9b547b285b5f8beb5f38985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90b7b8b99da4445c9a3daabf76ac525d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_335dbcf411dc40d688c002ee0c1e2533",
              "IPY_MODEL_d32bfe8d13c84fab9daa938eae38effa",
              "IPY_MODEL_a7cbc79a1edd4566bb9c0700a31af9ea"
            ],
            "layout": "IPY_MODEL_57787c2c68db40738387c17ef6607bfd"
          }
        },
        "335dbcf411dc40d688c002ee0c1e2533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_967a4fe544934834bc60853b89d9abd7",
            "placeholder": "​",
            "style": "IPY_MODEL_125a4cf30b464a4a9003f17ec26280f0",
            "value": "Epoch 38/50: 100%"
          }
        },
        "d32bfe8d13c84fab9daa938eae38effa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b21cab48b654a94adca092e89697441",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_606f92fc110447ac91109fa02d9c6064",
            "value": 469
          }
        },
        "a7cbc79a1edd4566bb9c0700a31af9ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba2a4bdf2b9d4d7d85210497d62ebf82",
            "placeholder": "​",
            "style": "IPY_MODEL_d952069f26d74ac6a1f54634e136eafb",
            "value": " 469/469 [00:54&lt;00:00,  9.70it/s, loss=162]"
          }
        },
        "57787c2c68db40738387c17ef6607bfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "967a4fe544934834bc60853b89d9abd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "125a4cf30b464a4a9003f17ec26280f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b21cab48b654a94adca092e89697441": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "606f92fc110447ac91109fa02d9c6064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba2a4bdf2b9d4d7d85210497d62ebf82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d952069f26d74ac6a1f54634e136eafb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee3bd314e9ee4d66b0f88080b5869a49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f40167a3f8c4c42ad3be7430cca1f25",
              "IPY_MODEL_00a4ba97e08d4670905a2b5e76499321",
              "IPY_MODEL_97a58baaf28b42d7aa49a2810c14f9b0"
            ],
            "layout": "IPY_MODEL_9d90249c0ef44b79981fe94033fab89e"
          }
        },
        "8f40167a3f8c4c42ad3be7430cca1f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c42200f16fa642ada70426d4acfacaee",
            "placeholder": "​",
            "style": "IPY_MODEL_e588890726364fc4be9501ec71231f12",
            "value": "Epoch 39/50: 100%"
          }
        },
        "00a4ba97e08d4670905a2b5e76499321": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c771c98a7655423486e75a4bd1e98bdf",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a4b4a39cb8e49838f0e28786e3a9e64",
            "value": 469
          }
        },
        "97a58baaf28b42d7aa49a2810c14f9b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a506f239ddd84d80837c96bb3f6a896f",
            "placeholder": "​",
            "style": "IPY_MODEL_81227505873843c9b0c48b1be9611242",
            "value": " 469/469 [00:52&lt;00:00,  8.76it/s, loss=150]"
          }
        },
        "9d90249c0ef44b79981fe94033fab89e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c42200f16fa642ada70426d4acfacaee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e588890726364fc4be9501ec71231f12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c771c98a7655423486e75a4bd1e98bdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a4b4a39cb8e49838f0e28786e3a9e64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a506f239ddd84d80837c96bb3f6a896f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81227505873843c9b0c48b1be9611242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "695fe9aaab0b460d917792809513a6e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c328cadf3d484fc3baf461b193cc1d6b",
              "IPY_MODEL_a6ff1e8bec3c41ecbdd2e1a8c4815c79",
              "IPY_MODEL_cd43b982b3054a95bcdfd712c8534081"
            ],
            "layout": "IPY_MODEL_a37929925ca24ad395b269d96457c73f"
          }
        },
        "c328cadf3d484fc3baf461b193cc1d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3a1ec41639544bcbf76dfa7bbe1995a",
            "placeholder": "​",
            "style": "IPY_MODEL_0b8ad05e0ba345d89ed77027e27f5922",
            "value": "Epoch 40/50: 100%"
          }
        },
        "a6ff1e8bec3c41ecbdd2e1a8c4815c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc494897d7c24826b7e2d86311552b88",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed9c526bc47d49c091ff57fbc87c92fb",
            "value": 469
          }
        },
        "cd43b982b3054a95bcdfd712c8534081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b551dab61094284b2eb497ba2418002",
            "placeholder": "​",
            "style": "IPY_MODEL_f0a800b7ff1a47109b66d476c026c85c",
            "value": " 469/469 [00:48&lt;00:00, 10.36it/s, loss=157]"
          }
        },
        "a37929925ca24ad395b269d96457c73f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3a1ec41639544bcbf76dfa7bbe1995a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b8ad05e0ba345d89ed77027e27f5922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc494897d7c24826b7e2d86311552b88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed9c526bc47d49c091ff57fbc87c92fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b551dab61094284b2eb497ba2418002": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0a800b7ff1a47109b66d476c026c85c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09b8ba6e2ba64fdc869228a01f3da70d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_576078306a4644f2bb394a7138a53fef",
              "IPY_MODEL_1907505d76514b6db1546a043844c3bc",
              "IPY_MODEL_ebd52cc5486949d1825a2ee6e71df634"
            ],
            "layout": "IPY_MODEL_452781fe0a66491d8ba104d0b4a70576"
          }
        },
        "576078306a4644f2bb394a7138a53fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8b3143bccb54aea8bd097e505318cf6",
            "placeholder": "​",
            "style": "IPY_MODEL_19f75995c91a4acd93340f632dccfbd9",
            "value": "Epoch 41/50: 100%"
          }
        },
        "1907505d76514b6db1546a043844c3bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63c60173bff04ec5af009e84a2b9d4bc",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3bb547d23bb4024a8ae5b1753c1d059",
            "value": 469
          }
        },
        "ebd52cc5486949d1825a2ee6e71df634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35b308335abe4a38ad986f0ed07e0839",
            "placeholder": "​",
            "style": "IPY_MODEL_6ab8b424dfde4c5f9a5048e6d9acd122",
            "value": " 469/469 [00:47&lt;00:00, 10.27it/s, loss=160]"
          }
        },
        "452781fe0a66491d8ba104d0b4a70576": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8b3143bccb54aea8bd097e505318cf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19f75995c91a4acd93340f632dccfbd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63c60173bff04ec5af009e84a2b9d4bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3bb547d23bb4024a8ae5b1753c1d059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35b308335abe4a38ad986f0ed07e0839": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ab8b424dfde4c5f9a5048e6d9acd122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c18728d81227403d95338da27e0cd13c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c94e8c375b644f06abb048a26f9fd27e",
              "IPY_MODEL_21ae1f70951448b3a3fa2f711f240b8e",
              "IPY_MODEL_5e4a1f4e910a47b09d9bf30f0314a1cb"
            ],
            "layout": "IPY_MODEL_6290c9b3de274d1392e7c5fefe1c3a51"
          }
        },
        "c94e8c375b644f06abb048a26f9fd27e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4d0eaadd6924996870d746b5bb05ae9",
            "placeholder": "​",
            "style": "IPY_MODEL_c2ac8ca0837e4a51a1ad9916e4627a64",
            "value": "Epoch 42/50: 100%"
          }
        },
        "21ae1f70951448b3a3fa2f711f240b8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be9cf2aef2864b77a23b206baa7cf2d0",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7554395cb5244947a93afea55f9d36a7",
            "value": 469
          }
        },
        "5e4a1f4e910a47b09d9bf30f0314a1cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed886a0eb58641e9a982f07fa08fd4dc",
            "placeholder": "​",
            "style": "IPY_MODEL_558d6ee5b77847579687e0a03addd62e",
            "value": " 469/469 [00:48&lt;00:00,  9.73it/s, loss=156]"
          }
        },
        "6290c9b3de274d1392e7c5fefe1c3a51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4d0eaadd6924996870d746b5bb05ae9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2ac8ca0837e4a51a1ad9916e4627a64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be9cf2aef2864b77a23b206baa7cf2d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7554395cb5244947a93afea55f9d36a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed886a0eb58641e9a982f07fa08fd4dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "558d6ee5b77847579687e0a03addd62e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d45732bf78874e18b20b85ca77955c7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce006def87c6473093b19ac750a9919f",
              "IPY_MODEL_359897c2be8b4f85830a7f01b427707d",
              "IPY_MODEL_797dde04fa5a4f98810bc3cd9011411b"
            ],
            "layout": "IPY_MODEL_7f88f84f9ddd4585a02df952fbf80de3"
          }
        },
        "ce006def87c6473093b19ac750a9919f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3263ea6623742bcb20ac1d401322f11",
            "placeholder": "​",
            "style": "IPY_MODEL_0c7f32bae8a14d42a942efd14aea0caa",
            "value": "Epoch 43/50: 100%"
          }
        },
        "359897c2be8b4f85830a7f01b427707d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cc32142fbc64f1a8a2e37ef57af140b",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0022a1bb17849448860b01902dedbf2",
            "value": 469
          }
        },
        "797dde04fa5a4f98810bc3cd9011411b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a2bd5ee732544daa10d308eaf9de4fb",
            "placeholder": "​",
            "style": "IPY_MODEL_f81209f687ad497688318b7238d76d37",
            "value": " 469/469 [00:48&lt;00:00,  9.93it/s, loss=172]"
          }
        },
        "7f88f84f9ddd4585a02df952fbf80de3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3263ea6623742bcb20ac1d401322f11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c7f32bae8a14d42a942efd14aea0caa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cc32142fbc64f1a8a2e37ef57af140b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0022a1bb17849448860b01902dedbf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a2bd5ee732544daa10d308eaf9de4fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f81209f687ad497688318b7238d76d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebd51b28a1d447da900283d7f82eca1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e158e34b97a44b1495abc276645d17e4",
              "IPY_MODEL_fdc5b4a2f7794b68b4402ee991d17530",
              "IPY_MODEL_144e4c91507a4735b7a5c4bc7a4a2676"
            ],
            "layout": "IPY_MODEL_6472d6b347bf41528a3963dee0698324"
          }
        },
        "e158e34b97a44b1495abc276645d17e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_019428549f074e9ab3f028e4525df7f8",
            "placeholder": "​",
            "style": "IPY_MODEL_f2ef284533a8440e906d32e046cf205b",
            "value": "Epoch 44/50: 100%"
          }
        },
        "fdc5b4a2f7794b68b4402ee991d17530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62dd9e90c87c4aef8e01f2d6877d89b8",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ae2484f3e8f4a748b7182df8553245e",
            "value": 469
          }
        },
        "144e4c91507a4735b7a5c4bc7a4a2676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_467fa81acd104784af928d2207e78f01",
            "placeholder": "​",
            "style": "IPY_MODEL_3e7cc91d8f874250a4976718b715213a",
            "value": " 469/469 [00:47&lt;00:00, 10.54it/s, loss=159]"
          }
        },
        "6472d6b347bf41528a3963dee0698324": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "019428549f074e9ab3f028e4525df7f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2ef284533a8440e906d32e046cf205b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62dd9e90c87c4aef8e01f2d6877d89b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ae2484f3e8f4a748b7182df8553245e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "467fa81acd104784af928d2207e78f01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e7cc91d8f874250a4976718b715213a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a22f01a80e4478f924a99e85389dfe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c75fed1d42554728859351f86d9cdfa4",
              "IPY_MODEL_1000564efb9f424f8d182d0f01af2d4d",
              "IPY_MODEL_789e8be42c8c406aac442332bc431551"
            ],
            "layout": "IPY_MODEL_3a5cd417c2264a1fbf862b96a7cd2a39"
          }
        },
        "c75fed1d42554728859351f86d9cdfa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bad6108d3cf4ca089c67edeb8e67fc2",
            "placeholder": "​",
            "style": "IPY_MODEL_a8132f42f0c5493380ef70ef31b9dc9d",
            "value": "Epoch 45/50: 100%"
          }
        },
        "1000564efb9f424f8d182d0f01af2d4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01c31fd78bd2487199ce426acec7b534",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5e653d899cd437aa5838d6453c50d66",
            "value": 469
          }
        },
        "789e8be42c8c406aac442332bc431551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4d2684fa87944f0a5a950647cb77083",
            "placeholder": "​",
            "style": "IPY_MODEL_552512675593418da34779d2bd2a4391",
            "value": " 469/469 [00:47&lt;00:00, 10.65it/s, loss=155]"
          }
        },
        "3a5cd417c2264a1fbf862b96a7cd2a39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bad6108d3cf4ca089c67edeb8e67fc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8132f42f0c5493380ef70ef31b9dc9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01c31fd78bd2487199ce426acec7b534": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5e653d899cd437aa5838d6453c50d66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4d2684fa87944f0a5a950647cb77083": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "552512675593418da34779d2bd2a4391": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "919bdf3d6f384f92a2808220e6b095bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_205eb37e8a664d3eb404ce96c8451a1e",
              "IPY_MODEL_b9a2f92fb0b348598be38c592272c71a",
              "IPY_MODEL_995cd9dc897a401c824da2c17a1a06d1"
            ],
            "layout": "IPY_MODEL_1f8ccd885ed343feb16842121acb3168"
          }
        },
        "205eb37e8a664d3eb404ce96c8451a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf234b411ee347eb84c56dfb9a30ae80",
            "placeholder": "​",
            "style": "IPY_MODEL_7b39ae66cda04e0d8b06532d652d37c3",
            "value": "Epoch 46/50: 100%"
          }
        },
        "b9a2f92fb0b348598be38c592272c71a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70f8ac9b65ad44e492ea3bb451033b40",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f5ec80d63b84ab5abbf4b439cd4b37a",
            "value": 469
          }
        },
        "995cd9dc897a401c824da2c17a1a06d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2124de624ecb41ba8cc1eb731271328a",
            "placeholder": "​",
            "style": "IPY_MODEL_885fc2bb1fdc449994c75e0a9d7ad4f6",
            "value": " 469/469 [00:47&lt;00:00, 10.61it/s, loss=161]"
          }
        },
        "1f8ccd885ed343feb16842121acb3168": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf234b411ee347eb84c56dfb9a30ae80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b39ae66cda04e0d8b06532d652d37c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70f8ac9b65ad44e492ea3bb451033b40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f5ec80d63b84ab5abbf4b439cd4b37a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2124de624ecb41ba8cc1eb731271328a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "885fc2bb1fdc449994c75e0a9d7ad4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88fd28b3894145b5bcde9a18c355cda4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d295322358d742429fd370e5b9261111",
              "IPY_MODEL_230bddf80a994a85ad306fa51623f5d6",
              "IPY_MODEL_e7e70291687043b8803b4591bcb26f3f"
            ],
            "layout": "IPY_MODEL_bdf0b6154fd145558d96428550276e5f"
          }
        },
        "d295322358d742429fd370e5b9261111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5a3afbdb304407da04b91d86072eaa6",
            "placeholder": "​",
            "style": "IPY_MODEL_f4fbb051e3b34fcbb63db442919db65a",
            "value": "Epoch 47/50: 100%"
          }
        },
        "230bddf80a994a85ad306fa51623f5d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56b220add32b470f8675bed4d2079532",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_645b5ff687914a8c93e0340a494ccec4",
            "value": 469
          }
        },
        "e7e70291687043b8803b4591bcb26f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f9a4185b0d24d24a3debe3915ecefe0",
            "placeholder": "​",
            "style": "IPY_MODEL_9bad788bb342429a8e918b3068e23880",
            "value": " 469/469 [00:47&lt;00:00,  8.61it/s, loss=154]"
          }
        },
        "bdf0b6154fd145558d96428550276e5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5a3afbdb304407da04b91d86072eaa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4fbb051e3b34fcbb63db442919db65a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56b220add32b470f8675bed4d2079532": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "645b5ff687914a8c93e0340a494ccec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f9a4185b0d24d24a3debe3915ecefe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bad788bb342429a8e918b3068e23880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c4e3ec93808490595a38fea46627185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b636cf5b95642039a44a4995ee5ae2d",
              "IPY_MODEL_9d09d4e121204ea284dde800466cac00",
              "IPY_MODEL_c87bbb0ba60c42a7b26ef411165b3e15"
            ],
            "layout": "IPY_MODEL_209a56e92dc84113a05d48969d506e1c"
          }
        },
        "1b636cf5b95642039a44a4995ee5ae2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c8baf42ea9a4529819a1dcf3f9062e4",
            "placeholder": "​",
            "style": "IPY_MODEL_222f4d5d4ff64e98b15ca5df5a1acbaa",
            "value": "Epoch 48/50: 100%"
          }
        },
        "9d09d4e121204ea284dde800466cac00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04517b8843c04c20a7d93042d5dfa1b7",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f42dfbc10df4cca897622c949679a0f",
            "value": 469
          }
        },
        "c87bbb0ba60c42a7b26ef411165b3e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b7702afc2b14f7ab250990f868c8c85",
            "placeholder": "​",
            "style": "IPY_MODEL_dc1f172b7e804e2991b3207cdc5b0268",
            "value": " 469/469 [00:47&lt;00:00, 10.02it/s, loss=159]"
          }
        },
        "209a56e92dc84113a05d48969d506e1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c8baf42ea9a4529819a1dcf3f9062e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "222f4d5d4ff64e98b15ca5df5a1acbaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04517b8843c04c20a7d93042d5dfa1b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f42dfbc10df4cca897622c949679a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b7702afc2b14f7ab250990f868c8c85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc1f172b7e804e2991b3207cdc5b0268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32a45f3155ef461080b101d2a7744d47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e570f6d2af354920ab068efea69cdad7",
              "IPY_MODEL_84121165f43745fe8ac12ef3c45b514f",
              "IPY_MODEL_b99ad78334084c1d9cf50cd7c579a30f"
            ],
            "layout": "IPY_MODEL_4deb8120f00845b7987eb44971555ad6"
          }
        },
        "e570f6d2af354920ab068efea69cdad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccbe8779734e49118e1bf1aa6514e9ec",
            "placeholder": "​",
            "style": "IPY_MODEL_e25ca698b9c448d29387c02b5caef1d4",
            "value": "Epoch 49/50: 100%"
          }
        },
        "84121165f43745fe8ac12ef3c45b514f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18af20861737490e930ebbd31b23c8be",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9fea44c3fda742bf95421245c131ea12",
            "value": 469
          }
        },
        "b99ad78334084c1d9cf50cd7c579a30f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b154ba3e1c54280a9c60b0fe7d08333",
            "placeholder": "​",
            "style": "IPY_MODEL_1fd501740dd0400d827d241889bcf46e",
            "value": " 469/469 [00:47&lt;00:00,  9.95it/s, loss=154]"
          }
        },
        "4deb8120f00845b7987eb44971555ad6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccbe8779734e49118e1bf1aa6514e9ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e25ca698b9c448d29387c02b5caef1d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18af20861737490e930ebbd31b23c8be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fea44c3fda742bf95421245c131ea12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b154ba3e1c54280a9c60b0fe7d08333": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fd501740dd0400d827d241889bcf46e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb7ec754b5fa4f0ea6ea6e24167a2d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c60de2a7e464662b86d5a1c983da3b5",
              "IPY_MODEL_6442f5a944a04f38840fe5365d1bfe29",
              "IPY_MODEL_1693574a40304f5e9dd5a5bec492560b"
            ],
            "layout": "IPY_MODEL_560b9fc71071411697895f067b78996d"
          }
        },
        "2c60de2a7e464662b86d5a1c983da3b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77f542f41711467e99a084ad50693201",
            "placeholder": "​",
            "style": "IPY_MODEL_9ac682dd3da042c78fddb83f730ede1e",
            "value": "Epoch 50/50: 100%"
          }
        },
        "6442f5a944a04f38840fe5365d1bfe29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a1b6eec18d049f4a8730a846c63b2a0",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92b69924dddc44bfafd8be27ec3dada1",
            "value": 469
          }
        },
        "1693574a40304f5e9dd5a5bec492560b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6d12ed1c3144f908123a9ccf55ab33b",
            "placeholder": "​",
            "style": "IPY_MODEL_6d963ec1536441b68b213e3e804b1f7d",
            "value": " 469/469 [00:47&lt;00:00, 10.21it/s, loss=160]"
          }
        },
        "560b9fc71071411697895f067b78996d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77f542f41711467e99a084ad50693201": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ac682dd3da042c78fddb83f730ede1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a1b6eec18d049f4a8730a846c63b2a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92b69924dddc44bfafd8be27ec3dada1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6d12ed1c3144f908123a9ccf55ab33b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d963ec1536441b68b213e3e804b1f7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlessandroFornasier/diffusion-models/blob/main/autoencoders/vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0kwHzd90uOsj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from collections import OrderedDict\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Optional\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class AutoencoderState:\n",
        "  \"\"\"\n",
        "  Autoencoder state.\n",
        "\n",
        "  Attributes:\n",
        "   - x (Optional[torch.Tensor]): Input data\n",
        "   - z (Optional[torch.Tensor]): Latent space sample\n",
        "   - x_hat (Optional[torch.Tensor]): Reconstructed data\n",
        "  \"\"\"\n",
        "  x : Optional[torch.Tensor] = None                         # Input\n",
        "  z : Optional[torch.Tensor] = None                         # Latent space sample\n",
        "  x_hat : Optional[torch.Tensor] = None                     # Reconstructed input\n",
        "\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "  \"\"\"\n",
        "  Autoencoder class.\n",
        "\n",
        "  Args:\n",
        "    encoder (OrderedDict[str, nn.Module]): Ordered dictionary of encoder layers\n",
        "    decoder (OrderedDict[str, nn.Module]): Ordered dictionary of decoder layers\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(\n",
        "    self,\n",
        "    encoder: OrderedDict[str, nn.Module],\n",
        "    decoder: OrderedDict[str, nn.Module]\n",
        "  ) -> None:\n",
        "    super(Autoencoder, self).__init__()\n",
        "\n",
        "    self.encoder = nn.Sequential(encoder)\n",
        "    self.decoder = nn.Sequential(decoder)\n",
        "\n",
        "    def encode(self, x) -> torch.Tensor:\n",
        "      \"\"\"\n",
        "      Encodes the input data into the latent space.\n",
        "\n",
        "      Args:\n",
        "        x (torch.Tensor): Input data.\n",
        "\n",
        "      Returns:\n",
        "        z (torch.Tensor): Encoded data, latent space.\n",
        "      \"\"\"\n",
        "      return self.encoder(x)\n",
        "\n",
        "    def decode(self, z) -> torch.Tensor:\n",
        "      \"\"\"\n",
        "      Decodes the latent space data.\n",
        "\n",
        "      Args:\n",
        "        z (torch.Tensor): Latent space data.\n",
        "\n",
        "      Returns:\n",
        "        x_hat (torch.Tensor): Decoded data, output space.\n",
        "      \"\"\"\n",
        "      return self.decoder(z)\n",
        "\n",
        "    def forward(self, x) -> torch.Tensor:\n",
        "      \"\"\"\n",
        "      Forward pass of the autoencoder\n",
        "      \"\"\"\n",
        "      state = AutoencoderState(x)\n",
        "      state.z = self.encode(x)\n",
        "      state.x_hat = self.decode(state.z)\n",
        "      return state\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class VAEState(AutoencoderState):\n",
        "  \"\"\"\n",
        "  Variational autoencoder state.\n",
        "\n",
        "  Attributes:\n",
        "   - x (Optional[torch.Tensor]): Input data\n",
        "   - z (Optional[torch.Tensor]): Latent space sample\n",
        "   - x_hat (Optional[torch.Tensor]): Reconstructed data\n",
        "   - dist (Optional[torch.distributions.Distribution]): Encoder Gaussian distribution\n",
        "  \"\"\"\n",
        "  dist : Optional[torch.distributions.Distribution] = None  # Latent space distribution\n",
        "\n",
        "\n",
        "class VAE(Autoencoder):\n",
        "  \"\"\"\n",
        "  Variational autoencoder class.\n",
        "\n",
        "  Args:\n",
        "    encoder (OrderedDict[str, nn.Module]): Ordered dictionary of encoder layers\n",
        "    decoder (OrderedDict[str, nn.Module]): Ordered dictionary of decoder layers\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(\n",
        "    self,\n",
        "    encoder: OrderedDict[str, nn.Module],\n",
        "    decoder: OrderedDict[str, nn.Module]\n",
        "  ) -> None:\n",
        "    super().__init__(encoder, decoder)\n",
        "\n",
        "    self.softplus = nn.Softplus()\n",
        "\n",
        "  def encode(self, x, eps: float = 1e-6) -> torch.distributions.Distribution:\n",
        "    \"\"\"\n",
        "    Encodes the input data into the latent space.\n",
        "\n",
        "    Args:\n",
        "      x (torch.Tensor): Input data.\n",
        "      eps (float): Small value to avoid numerical instability.\n",
        "\n",
        "    Returns:\n",
        "      dist (torch.distributions.MultivariateNormal): Normal distribution of the encoded data.\n",
        "\n",
        "    Note:\n",
        "      Learning logvar improves numerical stability since var is smaller than zero and tipically smaller than once. Hence logvar is within (-inf, log(1)).\n",
        "      Softplus + epsilon (softplus(x) = \\log(1 + \\exp(x))) is used to get sigma instead of directly exponentiating while ensuring numerical stability\n",
        "    \"\"\"\n",
        "    e = self.encoder(x)\n",
        "    mu, logvar = torch.tensor_split(e, 2, dim=-1)\n",
        "    var = self.softplus(logvar) + eps\n",
        "    return torch.distributions.MultivariateNormal(mu, scale_tril=torch.diag_embed(var)) # Use scale_tril as it is more efficient\n",
        "\n",
        "  def reparametrize(self, dist) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Perform sampling via the reparametrization trick\n",
        "\n",
        "    Args:\n",
        "      dist (torch.distributions.MultivariateNormal): Normal distribution of the encoded data.\n",
        "\n",
        "    Returns:\n",
        "      z (torch.Tensor): Sampled data from the latent space z = mu + sigma * epsilon. With epsilon ~ N(0,I)\n",
        "    \"\"\"\n",
        "    return dist.rsample()\n",
        "\n",
        "  def decode(self, z) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Decodes the data from the latent space to the original input space.\n",
        "\n",
        "    Args:\n",
        "      z (torch.Tensor): Data in the latent space.\n",
        "\n",
        "    Returns:\n",
        "      x_hat (torch.Tensor): Reconstructed data in the original input space.\n",
        "    \"\"\"\n",
        "    return self.decoder(z)\n",
        "\n",
        "  def forward(self, x) -> VAEState:\n",
        "    \"\"\"\n",
        "    Performs a forward pass of the VAE.\n",
        "\n",
        "    Args:\n",
        "      x (torch.Tensor): Input data.\n",
        "\n",
        "    Returns:\n",
        "      state (VAEState): state of the VAE.\n",
        "    \"\"\"\n",
        "    state = VAEState(x)\n",
        "    state.dist = self.encode(state.x)\n",
        "    state.z = self.reparametrize(state.dist)\n",
        "    state.x_hat = self.decode(state.z)\n",
        "    return state"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from torch.optim import Optimizer\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from typing import Callable, Dict\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "  \"\"\"\n",
        "  Trainer class for training an autoencoder model.\n",
        "\n",
        "  Args:\n",
        "    device (torch.device): The device (CPU or GPU) to run the model on.\n",
        "    model (nn.Module): The autoencoder model to be trained.\n",
        "    loss (Callable[[AutoencoderState], Dict[torch.Tensor]]): A callable loss function that takes the model's state and returns a scalar loss value.\n",
        "    optimizer (Optimizer): The optimizer for training the model.\n",
        "    epochs (int): Number of epochs\n",
        "    writer (Optional[SummaryWriter]): Optional TensorBoard writer for logging training metrics.\n",
        "  \"\"\"\n",
        "  def __init__(\n",
        "    self,\n",
        "    device: torch.device,\n",
        "    model: nn.Module,\n",
        "    loss: Callable[[AutoencoderState], Dict[str, torch.Tensor]],\n",
        "    optimizer: Optimizer,\n",
        "    epochs: int,\n",
        "    writer: Optional[SummaryWriter] = None,\n",
        "  ) -> None:\n",
        "    self.device = device\n",
        "    self.model = model.to(self.device)\n",
        "    self.loss = loss\n",
        "    self.optimizer = optimizer\n",
        "    self.epochs = epochs\n",
        "    self.writer = writer\n",
        "    self.models_folder = './models'\n",
        "\n",
        "  def train(self, dataloader: DataLoader) -> None:\n",
        "    \"\"\"\n",
        "    Trains the autoencoder model on the given dataset.\n",
        "\n",
        "    Args:\n",
        "      dataloader (DataLoader): The DataLoader for loading training data.\n",
        "    \"\"\"\n",
        "    self.model.train()\n",
        "\n",
        "    step = 0\n",
        "    for epoch in range(self.epochs):\n",
        "      epoch_loss = 0.0\n",
        "      progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "      for batch_idx, (data, _) in enumerate(progress_bar):\n",
        "        data = data.to(self.device)\n",
        "\n",
        "        state = self.model(data)\n",
        "        losses = self.loss(state)\n",
        "\n",
        "        loss = sum(losses.values())\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        epoch_loss += batch_loss\n",
        "        average_loss = epoch_loss / (batch_idx + 1)\n",
        "        progress_bar.set_postfix(loss=batch_loss)\n",
        "\n",
        "        if self.writer:\n",
        "          self.writer.add_scalar(\"Train/Loss/Batch\", batch_loss, step)\n",
        "          self.writer.add_scalar(\"Train/Loss/Epoch\", average_loss, step)\n",
        "          for name, loss in losses.items():\n",
        "            self.writer.add_scalar(f\"Train/Loss/{name}\", loss, step)\n",
        "\n",
        "        step += 1\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] - Batch loss: {batch_loss:.4f} - Epoch Loss: {epoch_loss:.4f} - Avg Loss: {average_loss:.4f}\")\n",
        "\n",
        "  def train_and_save(self, dataloader: DataLoader, path: str, name: str):\n",
        "    \"\"\"\n",
        "    Trains the autoencoder model on the given dataset and save the model weight.\n",
        "\n",
        "    Args:\n",
        "      dataloader (DataLoader): The DataLoader for loading training data.\n",
        "      path (str): Path to save the model weights\n",
        "      name (str): name of the model weights\n",
        "    \"\"\"\n",
        "    self.train(dataloader=dataloader)\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    torch.save(self.model.state_dict(), f'{path}/{name}')\n",
        "    print(f'Model saved to: {path}/{name}')\n",
        "\n",
        "  def test(self, dataloader: DataLoader) -> None:\n",
        "    \"\"\"\n",
        "    Test the autoencoder model on the given dataset.\n",
        "\n",
        "    Args:\n",
        "      dataloader (DataLoader): The DataLoader for loading training data.\n",
        "    \"\"\"\n",
        "    self.model.eval()\n",
        "\n",
        "    average_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "      for data, _ in tqdm(dataloader, desc=\"Testing\"):\n",
        "        data = data.to(self.device)\n",
        "\n",
        "        state = self.model(data)\n",
        "        losses = self.loss(state)\n",
        "        loss = sum(losses.values())\n",
        "\n",
        "        average_loss += loss.item()\n",
        "\n",
        "    average_loss /= len(dataloader)\n",
        "    if self.writer:\n",
        "      self.writer.add_scalar(\"Test/Loss/Average\", average_loss)\n",
        "      for name, loss in losses.items():\n",
        "        self.writer.add_scalar(f\"Test/Loss/Average/{name}\", loss / len(dataloader))\n",
        "\n",
        "    print(f\"Average test loss: {average_loss:.4f}\")\n",
        "\n",
        "  def load_and_test(self, dataloader: DataLoader, path: str, name: str):\n",
        "    \"\"\"\n",
        "    Test the autoencoder model on the given dataset.\n",
        "\n",
        "    Args:\n",
        "      dataloader (DataLoader): The DataLoader for loading training data.\n",
        "      path (str): Path relative to the model folder where the model weights are saved\n",
        "      name (str): name of the model weights\n",
        "    \"\"\"\n",
        "    self.model.load_state_dict(torch.load(f'{path}/{name}'))\n",
        "    self.test(dataloader=dataloader)"
      ],
      "metadata": {
        "id": "NuK8mHFr97Pm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "\n",
        "class MNISTLoader:\n",
        "  \"\"\"\n",
        "  A utility class for loading and preprocessing the MNIST dataset using a custom transformation pipeline.\n",
        "\n",
        "  The transformation pipeline includes:\n",
        "    - Conversion to a PyTorch image tensor.\n",
        "    - Scaling pixel values from [0, 255] to [0.0, 1.0].\n",
        "    - Flattening the image into a 1D tensor.\n",
        "\n",
        "  Args:\n",
        "    batch_size (int): Number of samples per batch in the DataLoader.\n",
        "  \"\"\"\n",
        "  def __init__(self, batch_size: int) -> None:\n",
        "    self.batch_size = batch_size\n",
        "    self.transform = v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True), v2.Lambda(lambda x: x.view(-1))])\n",
        "\n",
        "  def get_dataloader(self, train: bool) -> DataLoader:\n",
        "    data = datasets.MNIST('./data/MNIST', download=True, train=train, transform=self.transform)\n",
        "    return DataLoader(data, batch_size=self.batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "i6JIAu-jN0A4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as Func\n",
        "\n",
        "\n",
        "class VAELoss:\n",
        "  \"\"\"\n",
        "  VAE Loss callable class. The VAE loss is given by the ELBO,\n",
        "  which is the the sum of the reconstruction loss and the KL divergence loss\n",
        "\n",
        "  Note:\n",
        "    A VAE is trained by maximizing ELBO:\n",
        "    - Reconstruction loss (MSE ~ cross entropy)\n",
        "    - KL divergence\n",
        "\n",
        "  Refernce:\n",
        "    - https://hunterheidenreich.com/posts/modern-variational-autoencoder-in-pytorch/\n",
        "    - https://github.com/pytorch/examples/blob/main/vae/main.py\n",
        "  \"\"\"\n",
        "  def __init__(self, binary: bool) -> None:\n",
        "    self.binary = binary\n",
        "\n",
        "  def __binary_vae_loss(self, state: VAEState) -> Dict[str, torch.Tensor]:\n",
        "    rl = Func.binary_cross_entropy(state.x_hat, state.x, reduction='none').sum(-1).mean() # Reconstruction loss\n",
        "    target_dist = torch.distributions.MultivariateNormal(\n",
        "      torch.zeros_like(state.z, device=state.z.device),\n",
        "      scale_tril=torch.eye(state.z.shape[-1], device=state.z.device).unsqueeze(0).expand(state.z.shape[0], -1, -1),\n",
        "    )\n",
        "    kll = torch.distributions.kl.kl_divergence(state.dist, target_dist).mean() # KL loss\n",
        "    return {\"Reconstruction\": rl, \"KL\": kll}\n",
        "\n",
        "  def __call__(self, state: VAEState) -> Dict[str, torch.Tensor]:\n",
        "    if self.binary:\n",
        "      return self.__binary_vae_loss(state)\n",
        "    else:\n",
        "      raise NotImplementedError"
      ],
      "metadata": {
        "id": "OpjHiWAXyz2u"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def vae_encoder_decoder(dims: List[int], binary: bool):\n",
        "  \"\"\"\n",
        "  Defines the VAE encoder and decoder structure.\n",
        "\n",
        "  Args:\n",
        "    dims (List[int]): List of dimesions of the autoencoder layers\n",
        "    binary (bool): Flag to indicate whether the autoencoder processes binary data [0, 1]\n",
        "\n",
        "  Note:\n",
        "    The output of the final encoder layer has double the size for mean and variance and no activation.\n",
        "    If binary the activation of the last decoder layer is a Sigmoid to normalize to (0, 1)\n",
        "  \"\"\"\n",
        "  encoder = []\n",
        "  for n, (idim, odim) in enumerate(zip(dims[:-2], dims[1:-1])):\n",
        "    encoder.append((f'Linear_{n}', nn.Linear(idim, odim)))\n",
        "    encoder.append((f'SiLU_{n}', nn.SiLU()))\n",
        "  encoder.append((f'Linear_{len(dims) - 2}', nn.Linear(dims[-2], 2 * dims[-1])))\n",
        "\n",
        "  decoder = []\n",
        "  for n, (idim, odim) in enumerate(zip(dims[-1:1:-1], dims[-2:0:-1])):\n",
        "    decoder.append((f'Linear_{n}', nn.Linear(idim, odim)))\n",
        "    decoder.append((f'SiLU_{n}', nn.SiLU()))\n",
        "  decoder.append((f'Linear_{len(dims) - 2}', nn.Linear(dims[1], dims[0])))\n",
        "\n",
        "  if binary:\n",
        "    decoder.append((f'Sigmoid_{len(dims) - 2}', nn.Sigmoid()))\n",
        "\n",
        "  return encoder, decoder\n",
        "\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "model_path = f'./models/MNIST'\n",
        "model_name = f'VAE_{timestamp}.pt'\n",
        "\n",
        "binary = True\n",
        "dims = [28*28, 512, 128, 64, 24, 12, 6, 2]\n",
        "learning_rate = 1e-3\n",
        "weight_decay = 1e-2\n",
        "epochs = 50\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "encoder, decoder = vae_encoder_decoder(dims=dims, binary=binary)\n",
        "model = VAE(encoder=OrderedDict(encoder), decoder=OrderedDict(decoder))\n",
        "loss = VAELoss(binary=binary)\n",
        "dataloader = MNISTLoader(batch_size=128)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "writer = SummaryWriter(f'./runs/MNIST/VAE_{timestamp}')\n",
        "trainer = Trainer(device=device, model=model, loss=loss, optimizer=optimizer, epochs=epochs, writer=writer)\n",
        "\n",
        "trainer.train_and_save(dataloader.get_dataloader(train=True), model_path, model_name)\n",
        "writer.flush()\n",
        "writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "95c339d581964b08b5819aa4166223a5",
            "c9cf001f1a8a414a86ac82e06d76966c",
            "b67c256b3bfc4f8cac3f33a7e8dc8407",
            "939e698473e2489e8c189a7e8e6c63c7",
            "be359f22c80b405586dce9208db89884",
            "7301ee9250c74f67b6f9ddd3cc27aa44",
            "19418248cffd4151a2d87bee4768562c",
            "2f03434d129b43e7a607a69380efee83",
            "bad3e9dd4071474e9b7e68883dc994db",
            "12f4e8a2dae04c91bbdd0f7788664143",
            "9488cf22e6f441a6b93516b636ff4975",
            "217633b899b6427fa714a0ebcd9e9736",
            "9c8fd06d509048f8ac0d6ad7615a5566",
            "04f4ed4d09944e0aad5f8baed33e8f89",
            "e675f9c5490947e795e86a9dc732f653",
            "5af1fdc6216e492a890ec2177cc32ae8",
            "886e302e534b48d0b1da02633058f6a9",
            "b6c19e6d74544f1a8ce12f7dee2caeda",
            "a7d99f0fdc1743d4b49a772e3307e788",
            "096434c528f945e8829222a9bebc871b",
            "1f42e7041d754e8d9a986bf357e4aca4",
            "2c5dafae74d344669f9048a7dd0c5de7",
            "d8686c09d3834d15b56615003482ba68",
            "7bf224b0b02d4427aa2b766dcd663822",
            "0c6c7415a2f640538b6e1464300b4288",
            "6a76ca1a7a7942c18f991d36ab108513",
            "2cd4b5d538cc41a68bb6b413c0c338e7",
            "eccec610abff4bd5bc98b8607f8cb484",
            "f147f652db7d45d680cac73957e361cd",
            "7785a65db87c4b23881e6088ada7332e",
            "b5cf80354a6745cd856f50834a479f66",
            "8b73575aca7b4b95bb9d38b8f1fe2b92",
            "94e8c5d98ebb409a92c8caa2e940226d",
            "870ac42f03db4d45ac3562a676dcda12",
            "16a274499106422c844a23900c05e66d",
            "ce57a5b77bba431eb17a402cfa361698",
            "38ce3b21505b470fb606a688e17e5f74",
            "51a9d0a7f7a94f5183e72ffaa2d2e4ee",
            "142d37c9e7634396977235293dae74c2",
            "6fde3d853b8d4f9db64fa56c9868bbd9",
            "60986bec8d3e497886c24441af02fe76",
            "98c2aca1940c467585162b9ca702421a",
            "980f9007651c4f31afc66825c79a3530",
            "51585c4b4af847198832add0fc4fc0e4",
            "baa072f38975442f9203c327076a9fe9",
            "7039af3a704f4117b5c096b15da21649",
            "abdd0319286b40f18a944ba275488c48",
            "d6e671c795794bafac25e0410d2bf943",
            "c2d0556375c7455a9c9882078e02d0b5",
            "1a30eb4602104097aeb9a212965d1cf6",
            "258f23ca46294dc580af749312c3b5ca",
            "fddf0ec772834c0db276b7365efef050",
            "d985e4b8c5534a8d83b21140691d0932",
            "3d3eebef04ed49bda5a2d5d2ded6b2b9",
            "f6e2097b671741d1ad67bca672af2b98",
            "b936c1256c5a4528a85b23ca549241c0",
            "616d4276388c4c6695fc670933e62c1a",
            "499f25e58f8a4c2097b621f9768c7ce2",
            "421fef854ade4bb48419a5eabb739dd1",
            "28178badf490430da0e78948585ebc3d",
            "785186aed0ad4205ab5e6c9ee6cce806",
            "6ffe27aee8a545c1be14bf83d00b3d28",
            "81ab6d588e8f4251844d46f867cdabb8",
            "a0877f78fb14439fa72f4fbf076747f5",
            "e973369d8b0e4261bf0f24f2a76a908d",
            "5079ca0acd0e430d979243727a806f09",
            "116baa5f949a48d3899fd4a1b61cce58",
            "fd92a16d6bf749bdb4f50eede689e2df",
            "1a18cb5b79db48c2ae404e9be5324982",
            "0b80766078834fd3b3f53400f3bf9dd1",
            "6335bde431bf471fa34cef4cf21ae2fc",
            "5c3d5efe3de44657881583f80a3ace32",
            "09917968455541c7a7647d9e694327fa",
            "c18376dc56da432ebda0ce6814458097",
            "0d738ce50a2144b1a91e5e0e258a11c7",
            "6d4a7c73397c4762876e6487990154e3",
            "61fed89722b94740a000d53261e387d4",
            "e23603b159da4e34b1daf5c8a64899aa",
            "9ac579cd41a94f9abf20e09fc66dc53e",
            "4291a57b3616444ab99898f2d4e142c2",
            "35657f0be6ea4bac8abb3cde0d0fc18c",
            "3e2ceae3abc14cdfa92446c4f9eab018",
            "8930fd94892743f7b37d79c6337ab1a7",
            "cbfd5f07824c473c9d111c376331e69b",
            "08122bb9df24409a9ee0eecf9e48632f",
            "71e04fd8e1934242823798d258016c92",
            "ce946a4064a743abb2705a7c4ce51b8d",
            "2ff8a4516a46458881ce3e1d8e356385",
            "9d09dc537ff7458c9aa0196ef43f0556",
            "cd5b83cd1159427ca98463a7515fa01e",
            "f9686a62c4844319941878b6d243be52",
            "2bc05a27752e484b95d94691dfd280f0",
            "ceb180ecab6e495d957841ae39b98a8d",
            "36a4134b139d48118517d57400012292",
            "a9583ce2867e4c8d86be228fd065a405",
            "df0612b7881e466caf599d3a1f29c5c5",
            "9a216ad19c224a28a4ff7fbc860763c6",
            "0b40c96d1ddf41e0b532bd5d9b5ba570",
            "d26f9b77feac4f30b72ac30ad96720a2",
            "6aca790fb1ec41379be855f74ad4734b",
            "3d6a59a5a49e4fb9baf1818327544d0f",
            "8b0b4eb3033e4d5c964cdd6ed171ea32",
            "f4af6d0fa4cf415386033b1d3243d37f",
            "3dcda3ede3034b879f37ad050c070ccd",
            "affe348ba1f94543afe616ec85c57309",
            "877a31958d494a8390a984de12652a87",
            "fa1684d40c264ecdbfd5a98d98dfcf27",
            "6865c40188fe48199d7933544c89e433",
            "ca36e67a195941e5be65f9043e2c19d1",
            "06841abea58046238cb2e77d0ae900b9",
            "6c4a4cc2645a42008f0c7cb2a70e83d6",
            "fd511c7293e1470e9048e77a2dff4189",
            "2db5d879ef0f4cc497f972242cf08e4c",
            "cd7985fc2ad24b23a9beb87cd092e85c",
            "78fbfc21b2d246629f95b7c1eab77b75",
            "5526f3bc65714438993e727dfe7eeae2",
            "20a747c0cdaf46ebaa063b7557a0bc93",
            "02d3057c0a6049afb94853b229e437e6",
            "4bcefd5ef9e44ad1af8d734ce148a8b1",
            "4f774a90e74b4b40808e07d3ca98ed2c",
            "4ab068d55294400abfdb22cccf7caeda",
            "ca66d113aaad412b81607a209d293720",
            "c706e2d1e87a41f28581179e3370133e",
            "b72c67c0b5dc4e5ea0fcd5eb319df4ea",
            "0ec41d9697e54388bdd52fca0bd78298",
            "2378f8b9ab0a4e4599b8720e8a1411fd",
            "7bb7b89dc721489d932faeecf49133b7",
            "88e256853ff04cbd97df189053941d32",
            "85caa24f8879460f96735f3841c66eb1",
            "3795741f70bc4aa5851e873e4e8c3eb6",
            "910ba013d75342e6ba19ef1c37cda3fc",
            "fc880e430ba94600be36ade1c618adae",
            "19e918dd4b2149818701cfaba7e9089e",
            "3c83422a3380447293630127bde7a6a8",
            "34c6ffb7d1d248489ec2e8d7824346ce",
            "32531a55b53f4585acabf744496c285e",
            "9ad85ce5f75d43f5b7c17933dfdda0fe",
            "506d2b3bcef44b448c5ac852f2a427b0",
            "8eb53965d21e4c45a5010d9149576593",
            "98272ce4a86b437bbde5ec3a161964bf",
            "663d9970faf844818cc79fb5eacb1c9f",
            "bfc7c73ae12e4abb815921bcc495d9f6",
            "fa6d57bb4da24efcab9b3c127aa998e3",
            "6b22809982fe4d7b96bf517c3d937144",
            "e2822828dfeb4c40b225d82c1cc76b9c",
            "454f203b5e364ef9a5fafe41648698a7",
            "adcc6fe62b4745c0aacedd82f7c46809",
            "878b9dc364f149798e37a7b8f61d735b",
            "dbdd6dfd6caf4be6a50ebd10899ec935",
            "f1d2d2bd07fa4f64ad6b57be7541ba69",
            "81025d2bbbe848fa80cbe9ac0c2105af",
            "014d6b03e57048b68ab4f53ec03ed8aa",
            "137e6212a368493d96da46c5978af2a6",
            "0ffcd420ea0d40299b115604e65288ba",
            "7615ac8b74c748d28e5104216b6dc95a",
            "f7f5d95f8ac141ff9f73c74e00036426",
            "ca50691a680a4309b8b9b370cc10f4e7",
            "35ae0c97cbe84ac382ae840f3a53a9d1",
            "f30cd6e099e04f46a9601d73effb6141",
            "f35b9fa7d8fd44dc8c5154ced5549dff",
            "380dbd9a36754ffc8d3b93182321d43f",
            "59a745cfeeaf4b06b5813a534e5dddc2",
            "fefb79697fe54683860fd343abed65a8",
            "cd52a236af0e4c93aefaa7313740282d",
            "71a349ef48a8437eab9477787bc9a8b4",
            "88ffbf07fd9b453b9a17ef5124dd5cbb",
            "2c33030cd9ed45a68d0b0ea5e59485ff",
            "3d6123be815741649c6ecf03ad92432f",
            "ea0df509c1f5495a867a8e66fdfe3edd",
            "97b2df379913440b88ad497ae1b68942",
            "0ac4bfc6c32746979f70b39c911069da",
            "571a42b3b4b1468ab4908249adf2bdd2",
            "c730bf8757144388ae4bb14132f3b7c6",
            "41940c5a120746b7808e52541abd759c",
            "4445a28dffab44009b69323dbd49b2ac",
            "6e839774a64546f78092080f911a0938",
            "3320b9b595e146ada64953f5a232d93a",
            "d34ee07158924dd5be537e63f425ce9a",
            "5977a1bc0ef64bf1b6091649a9d22b36",
            "42adcc4a012c4528a7d40871e0245a62",
            "643ce760182f4f138feba3b0cac42657",
            "6d321bad2e73446d9efce5277a8de80e",
            "940d7ce0073d40fb9b4a52579bf9b14f",
            "33e387c71fb54e12a8f60b7431253aa0",
            "5f9504f845334804ad3147f03fbd8aaf",
            "76fd4bfdb7894b96829b10825647548e",
            "9d1518f8b52c4c1486a6bfd19c9e187b",
            "4e70ce8253fa4190ada086ec0f578b16",
            "57cdd8f0335c4f4eb8041b6c8c50d053",
            "c2575ee9d79d4ca982676832ce145e70",
            "8abb0675ff2c4dac9cca88ca66e31e94",
            "304fe8c90f894202b0d73a618984c6d6",
            "229fdc250eec47e59708b2011bbea0bf",
            "31afebceb5af44048f1a0742f983c0e1",
            "b12f009a5d824aef99c82f864a8c0401",
            "525c764195b647bfa75f3936fd688e95",
            "64729ee402784f6d85dd988105c0474e",
            "5a94761a9a204948bfe3af8fef294e6e",
            "7738fc61b7d34c4cae34cea1173c28e2",
            "cef5f2e48745497fb106e791417fa058",
            "e392bb892e484135a685007bbe9690d0",
            "9234171501ef412cbbf8255dde017e56",
            "15a4fe6bf0bd407d84ac5519815c566c",
            "eda2e20bad144f3c869b74ca67405d6c",
            "98d509b910c342278df249722e2177b6",
            "4bd41598137e43e3ba8a08be544b5058",
            "2b4f088790bc4b39b68af7d2b688ee0b",
            "f4b2ef7ee5ff4f5ea9ffad68aa506b9b",
            "f69b8c1737b14428bf91e7c9dcba4bc7",
            "87fe475b86494a1c8609762612b317d9",
            "413201d8cef14c9485111e3acbd6fb4f",
            "335ac92aeefd408da81786abcc39773f",
            "be61ad953a5b4c6bb6a5486c2d600f64",
            "b0a2ad0016874fbfabe4469f9a3d093a",
            "8a2f02ac84684757b5bdcf768753379f",
            "63988d69996e445a9102270f3f084a37",
            "2e32036f8d80481cbbc334a1b410595a",
            "7dd362c02e0a4d469f4501684e529578",
            "070114169d8a41219d2adb003410a74c",
            "54a7b2cdd1d540caa378719479b7bad4",
            "c3fe5addf0df458e979f2da7b30544df",
            "0dcfb90b9eee44c08216e0eaf64253d7",
            "e2853ab6b8394442891852243d0f681d",
            "97541356a20f4000a7a13e94efa85816",
            "01506b5a963c4aaaaf07cda46573a43a",
            "d20b453b69e34d30ae29c56a9729a5e6",
            "4dd4ad3dd68343fea6c652b1c66c8ab5",
            "5d0cd0e2214b45a68b45ebbdf9a19f10",
            "4bb96c466c0f460da93cd33cb56882c7",
            "b36716b3e9e145fdafe1b04532e580a2",
            "6930fa7ba0a145bd97b9b734876fab3d",
            "73c9de68f5be4269b838ad66daf6f227",
            "f511e23171324ad8b94cb30bed463b47",
            "d3e3446819a14cab9064d07504bd5f69",
            "a24e4d4969384fb1a4fea185a8f9bba0",
            "c669c574d5ea46cda5e825f8506a3eb9",
            "d39a4f53866a40dfa0531d5847cc6896",
            "4d5a2607e5844b28a6d85da21cd7ed4f",
            "ff3c5de723884d5b87e1743253038725",
            "13f7ddfd5ee0423a834ebc84eda8c1e4",
            "4f9d1dfbd62647bc9699d06c93c006ec",
            "e5ad84c22de247f6924c23658566c6a4",
            "095da23dda0141e3a64271455c55d866",
            "9515bfec69a84390b06e3059a2bd6b0f",
            "c7b701ef3685484da60978b0f3bd106d",
            "96d243452aef4d65aa98bcf6c2d9aa15",
            "9a5e912157834fe08eeebab179271d63",
            "abc7ba33d5054fe683fcaa9e664b113f",
            "08f78133816c42419e0370c63f5ce0bd",
            "a7514b47d2b347108e6ad44a5b0ecd5e",
            "65fb7cc73cc0415782004d3315edb080",
            "aa16dafc7f504195a398b9ca2df8db2d",
            "c3f2ec2fcfa04b89a0dfa0e7c1ab4b55",
            "411ce77955d5465b8b0393fb79a648b6",
            "284a798f52ac42049b3f154cb7f89782",
            "666f47a7cc3f4c8eac679a96268f325d",
            "657b13493dea4a41a47ea7837bbe4027",
            "ac0f833b42ec48dca966b027622e3871",
            "b0ff00b64d334b18a111df40001c59cc",
            "46972aa629ee4e33856786f7891946fa",
            "9f55b271e9a44cf1be9342d3566f3fb6",
            "e4e59f0494b5418e8050afd7eaf2435f",
            "ed566e034222434bbc4eb35422a7e233",
            "bc28e863aa8f49728865b18cd7bf5158",
            "c3275862e0cd4452a4cdaddd33a1af80",
            "73a3cf9dfdf54e11948e4b579bd7992d",
            "ada69746ec9f4e07b358a6c71cb71727",
            "9bba5118756e41bd9c481d67c474833e",
            "aa0c91cf6b5845d797ba981be6897b6f",
            "b8e5adba80f544218e8ebf3ecee7f9d4",
            "081ab1e0d269467e80dfbd7282668182",
            "b6156cd6d5db4b95b1f0a1c5367e5fc7",
            "5466e32e2dbb4f70979da23867cf22df",
            "41f359f703524740bf60b889bfb475d3",
            "3cd897cfc339442cb0f641a8d4662830",
            "454a6c4458994d329be9af40606cdf21",
            "75cf5e9e1f8b4890a4011413aac2ac32",
            "46f2350410134475b913ae59696c907e",
            "a3b45b2277d54a8387bede7acd13d76f",
            "e6cc7e0d99f64874a7048b09b1f6a193",
            "27b7350be6144686b1dd1c0b1fbad38f",
            "2a98ebd1102d4f3c9b3a61ee44f3fcd1",
            "aaf3c550fc65428aa90664e0ac637416",
            "d8f39f5f403649b4a61f3607fd537936",
            "4d631da5eddd479bb087bc3e9ee98d14",
            "eeb681c42d9746b8b6b11a8b88180088",
            "45b41b0e7b7149e1b850f5bbe82ae52e",
            "7f13f57cc38d40f1ba67ddf2ea4be121",
            "b241ac11176748d3ab422bb29299771e",
            "be1b66ccc93841938ed281c9f10b7995",
            "1549cd77bf3347a28f5ea27283c0b40a",
            "69f69fe894994f4f897c5b16f4689127",
            "fb3c6aa9da824fd68639f206cb9768d7",
            "d52a34a1abe54e1daa2a7d1544e3606b",
            "7ba4882cb3304273959b7ed74c655389",
            "e142b07d38084e658f1442b87f5920d9",
            "86fa3296a461406a919ed7d2ee04c2b8",
            "0547caab71064515a84c3b99aeea6b56",
            "9d51dacb79284b8ab831ecb44a2a8a74",
            "13d55eab4a3448cd90e54944bc75850e",
            "8ef48099f63547afba86393810e4102e",
            "9ae63fb10ef1472cb14acb26ecff56c7",
            "303f45515ee44257bc57b122d1f8c6dc",
            "a9a9a526a23c4c43a9b50a9c3e8b2a2a",
            "a341dae5eb8f4f888f2f3b041567921f",
            "75a5e081453541e1958543448d13e517",
            "0b0f97b8b27644cc801aaf371b130165",
            "abeb822c612e49198a255fd982a62b30",
            "543c285d04574e808258b892f977c923",
            "0343dae676eb4e469309eed8ecd0d03c",
            "681e677b49df43118a90c4d137e88293",
            "f44e05c198ef468499ab53889e179fcb",
            "e9954604ff984e71a027414b69675390",
            "2a20d2d250e04ecb8f9a798a0ab1925b",
            "f8f794f366fb4e1195246b9e7d96b750",
            "25f926b1d70d421ca7fa0543a15c8505",
            "9ca7c9f77c694a788c7d2c2721a527fe",
            "2361810fae454e44b6da7452943c6eab",
            "45f3d75a5f14418e9698ed1211315c98",
            "8ac3e1695a7246af89d87b2d5a0e3110",
            "d06038bfeb47486fa4e191668a927da5",
            "3bb3cff875de4226a7773c01af0d290f",
            "9c8e881d6ced47f2998ab48e42f433d1",
            "22364925e3574b2a93fb43fb6a661f3b",
            "b90981e1f33744468b6e2b437ec70e9c",
            "935c48dd108c4f02823edbe069d98ebb",
            "7ed51952a94a48edbdf94bbbd5ae5418",
            "9e0b4c23e00f497089a61fc0fa8de82c",
            "1f168f8afaf4442db6e9168d1196f822",
            "57a1f8e36651484e8859384f2b48adaa",
            "99c2e3598cc44090a6aa8475e65cd936",
            "de7ab8b480d84030a2c9c30419e30f8b",
            "b38738be65394ed69803556619ff7b69",
            "ebaf6fb5a77a432ca987df48cf3b2b82",
            "6b567a2c7c36453ea38077c981debcf8",
            "bad7e73591ba4585ab1a90fbc06de951",
            "bb4b38149e384c31b8e4f3b462132d49",
            "19434913ca524f90b1ba599bc4ffa108",
            "7ea95a90c69441eb8f9688171aa377cf",
            "613dd2eb57ca4d2980deed3441657bd0",
            "3d9f633c84fe489c928a25df11a4be93",
            "b51cd3bd62914bb3a05b8fb9530c126e",
            "a59f1f097c174e6c99f7502cd15815b2",
            "110eff51469a4a56a83d2799735f9e13",
            "5888287b267b46a2bd8b41eb680eec3b",
            "ea5a940732594705952dde2aa1bcf3a9",
            "19142748df3447d29aa472a72500fee8",
            "622ef648fcd540a18a97eaea5881c2f9",
            "34adb422a9d741458e6134fd41347238",
            "4968af1520064757a3ba7f09b46031f5",
            "0f69cc95bc91442fb88e9fc4d767a99f",
            "572ca8fb5718493fac3dcbec0a752cbf",
            "abecedb8556f415db0892ed17e4130ad",
            "980c9a7babb246dcb451faf7a07b9b29",
            "7e2054de32a04142bfeccc14c17190c0",
            "4aafdb9b07eb4ce5a208206a5c84ef19",
            "c043957950d84c8ebfdad7c78027fc20",
            "ee582ac6a0bb4c2d814f9d7caebba051",
            "7c6e70b88fb446bf9ae9a2e83832f5f6",
            "43eeabee0a214850a5c5de140005dfe6",
            "bce5f1aa0cba40f9b5666f44db27f0f4",
            "65a22d64c21a4a259528dbbb4a7c8b50",
            "caeed18a8bc74ccb87364c336a3aa493",
            "f2bd13063f724e098061d6a52299a54d",
            "a97804dd25c14005b186bf584bb51e24",
            "0f81b73780ac47d9860c93d6960e28b6",
            "f238c0dd2fee43cca956af9758868814",
            "a19ce49a9f8f43748fb0b840870c8949",
            "48197e339d5e4278b2c1219196a26a14",
            "2a467b955bf04e54970b27f4b83c1a3a",
            "f60ad18c25a944d98271b607d216d7a9",
            "a4a9760b32c34ddc8eb17d006c31dc66",
            "e2442bac2ecd4211890683424198a37b",
            "194f5304c13842d5a9b6596ef0498f8f",
            "559c1f9435c542098c57ae5e6fb80f72",
            "f67d0b137b1f4d2bb16314d6aa991e72",
            "89661a3e246242a9ae0cac6d19994329",
            "e95a71c3df3c41bfab14de73c83c4214",
            "2135b7041d264f12ad9173a502893357",
            "bd24c88466a64edfbc24e5acf92ea92c",
            "6a71c1998d2c4899acc6c716ad4b60c9",
            "84db6176bc7047649796e82764f374d2",
            "d99e2db1398544c2bd070e45b51d610a",
            "3485555976aa47d8a7bbd1e56e5c3817",
            "95630d42e05b47c08f576a6ad01d2f07",
            "d45f9a8ee9e1428d814c6928a977f0dd",
            "2806a0e527864264af59b732620b1426",
            "54357e709a4f4209a2ce16cc2f4f4a1b",
            "fdbfdfee3bbf4954a28fca55483b7c2d",
            "702a44bdd10041c48463201654d8dce3",
            "44caecfe3fce4b9f81ab9255307f20b7",
            "bc8f1c488fca42919dc6c79e02181af8",
            "b25b4fd57bbf4360a73495aaf2e0a703",
            "6d68ccc391d74207a223f51fc4ab4fcb",
            "e88d74b50a77427e8ed91a549c431070",
            "2567fe145f98421f97ae16a6c285f99b",
            "615dfa53fde64eff945eb1493c75bd1e",
            "d2cc5532f7364fa3b576f2a8202cdbc9",
            "89e9dcdd52914ea483fc17d14814cdb3",
            "203b5a00d3964f2f83f39d69d32a94e4",
            "e1c53acd72c14a5fb24585dd2d5c7b18",
            "c27f909ca80c498e9debf0238b54beec",
            "66bad51a686e404591902b38114d08bd",
            "53eee326ed174387a4cd48257ec971a2",
            "24c15ed9762a4ee8a4d0da2ddb353243",
            "948df7f6ab4647ddb7f7bb6b79da401a",
            "f9c520baa9b547b285b5f8beb5f38985",
            "90b7b8b99da4445c9a3daabf76ac525d",
            "335dbcf411dc40d688c002ee0c1e2533",
            "d32bfe8d13c84fab9daa938eae38effa",
            "a7cbc79a1edd4566bb9c0700a31af9ea",
            "57787c2c68db40738387c17ef6607bfd",
            "967a4fe544934834bc60853b89d9abd7",
            "125a4cf30b464a4a9003f17ec26280f0",
            "7b21cab48b654a94adca092e89697441",
            "606f92fc110447ac91109fa02d9c6064",
            "ba2a4bdf2b9d4d7d85210497d62ebf82",
            "d952069f26d74ac6a1f54634e136eafb",
            "ee3bd314e9ee4d66b0f88080b5869a49",
            "8f40167a3f8c4c42ad3be7430cca1f25",
            "00a4ba97e08d4670905a2b5e76499321",
            "97a58baaf28b42d7aa49a2810c14f9b0",
            "9d90249c0ef44b79981fe94033fab89e",
            "c42200f16fa642ada70426d4acfacaee",
            "e588890726364fc4be9501ec71231f12",
            "c771c98a7655423486e75a4bd1e98bdf",
            "7a4b4a39cb8e49838f0e28786e3a9e64",
            "a506f239ddd84d80837c96bb3f6a896f",
            "81227505873843c9b0c48b1be9611242",
            "695fe9aaab0b460d917792809513a6e8",
            "c328cadf3d484fc3baf461b193cc1d6b",
            "a6ff1e8bec3c41ecbdd2e1a8c4815c79",
            "cd43b982b3054a95bcdfd712c8534081",
            "a37929925ca24ad395b269d96457c73f",
            "e3a1ec41639544bcbf76dfa7bbe1995a",
            "0b8ad05e0ba345d89ed77027e27f5922",
            "bc494897d7c24826b7e2d86311552b88",
            "ed9c526bc47d49c091ff57fbc87c92fb",
            "2b551dab61094284b2eb497ba2418002",
            "f0a800b7ff1a47109b66d476c026c85c",
            "09b8ba6e2ba64fdc869228a01f3da70d",
            "576078306a4644f2bb394a7138a53fef",
            "1907505d76514b6db1546a043844c3bc",
            "ebd52cc5486949d1825a2ee6e71df634",
            "452781fe0a66491d8ba104d0b4a70576",
            "b8b3143bccb54aea8bd097e505318cf6",
            "19f75995c91a4acd93340f632dccfbd9",
            "63c60173bff04ec5af009e84a2b9d4bc",
            "e3bb547d23bb4024a8ae5b1753c1d059",
            "35b308335abe4a38ad986f0ed07e0839",
            "6ab8b424dfde4c5f9a5048e6d9acd122",
            "c18728d81227403d95338da27e0cd13c",
            "c94e8c375b644f06abb048a26f9fd27e",
            "21ae1f70951448b3a3fa2f711f240b8e",
            "5e4a1f4e910a47b09d9bf30f0314a1cb",
            "6290c9b3de274d1392e7c5fefe1c3a51",
            "c4d0eaadd6924996870d746b5bb05ae9",
            "c2ac8ca0837e4a51a1ad9916e4627a64",
            "be9cf2aef2864b77a23b206baa7cf2d0",
            "7554395cb5244947a93afea55f9d36a7",
            "ed886a0eb58641e9a982f07fa08fd4dc",
            "558d6ee5b77847579687e0a03addd62e",
            "d45732bf78874e18b20b85ca77955c7b",
            "ce006def87c6473093b19ac750a9919f",
            "359897c2be8b4f85830a7f01b427707d",
            "797dde04fa5a4f98810bc3cd9011411b",
            "7f88f84f9ddd4585a02df952fbf80de3",
            "f3263ea6623742bcb20ac1d401322f11",
            "0c7f32bae8a14d42a942efd14aea0caa",
            "4cc32142fbc64f1a8a2e37ef57af140b",
            "c0022a1bb17849448860b01902dedbf2",
            "0a2bd5ee732544daa10d308eaf9de4fb",
            "f81209f687ad497688318b7238d76d37",
            "ebd51b28a1d447da900283d7f82eca1e",
            "e158e34b97a44b1495abc276645d17e4",
            "fdc5b4a2f7794b68b4402ee991d17530",
            "144e4c91507a4735b7a5c4bc7a4a2676",
            "6472d6b347bf41528a3963dee0698324",
            "019428549f074e9ab3f028e4525df7f8",
            "f2ef284533a8440e906d32e046cf205b",
            "62dd9e90c87c4aef8e01f2d6877d89b8",
            "6ae2484f3e8f4a748b7182df8553245e",
            "467fa81acd104784af928d2207e78f01",
            "3e7cc91d8f874250a4976718b715213a",
            "9a22f01a80e4478f924a99e85389dfe8",
            "c75fed1d42554728859351f86d9cdfa4",
            "1000564efb9f424f8d182d0f01af2d4d",
            "789e8be42c8c406aac442332bc431551",
            "3a5cd417c2264a1fbf862b96a7cd2a39",
            "7bad6108d3cf4ca089c67edeb8e67fc2",
            "a8132f42f0c5493380ef70ef31b9dc9d",
            "01c31fd78bd2487199ce426acec7b534",
            "e5e653d899cd437aa5838d6453c50d66",
            "b4d2684fa87944f0a5a950647cb77083",
            "552512675593418da34779d2bd2a4391",
            "919bdf3d6f384f92a2808220e6b095bf",
            "205eb37e8a664d3eb404ce96c8451a1e",
            "b9a2f92fb0b348598be38c592272c71a",
            "995cd9dc897a401c824da2c17a1a06d1",
            "1f8ccd885ed343feb16842121acb3168",
            "bf234b411ee347eb84c56dfb9a30ae80",
            "7b39ae66cda04e0d8b06532d652d37c3",
            "70f8ac9b65ad44e492ea3bb451033b40",
            "2f5ec80d63b84ab5abbf4b439cd4b37a",
            "2124de624ecb41ba8cc1eb731271328a",
            "885fc2bb1fdc449994c75e0a9d7ad4f6",
            "88fd28b3894145b5bcde9a18c355cda4",
            "d295322358d742429fd370e5b9261111",
            "230bddf80a994a85ad306fa51623f5d6",
            "e7e70291687043b8803b4591bcb26f3f",
            "bdf0b6154fd145558d96428550276e5f",
            "e5a3afbdb304407da04b91d86072eaa6",
            "f4fbb051e3b34fcbb63db442919db65a",
            "56b220add32b470f8675bed4d2079532",
            "645b5ff687914a8c93e0340a494ccec4",
            "1f9a4185b0d24d24a3debe3915ecefe0",
            "9bad788bb342429a8e918b3068e23880",
            "0c4e3ec93808490595a38fea46627185",
            "1b636cf5b95642039a44a4995ee5ae2d",
            "9d09d4e121204ea284dde800466cac00",
            "c87bbb0ba60c42a7b26ef411165b3e15",
            "209a56e92dc84113a05d48969d506e1c",
            "4c8baf42ea9a4529819a1dcf3f9062e4",
            "222f4d5d4ff64e98b15ca5df5a1acbaa",
            "04517b8843c04c20a7d93042d5dfa1b7",
            "4f42dfbc10df4cca897622c949679a0f",
            "7b7702afc2b14f7ab250990f868c8c85",
            "dc1f172b7e804e2991b3207cdc5b0268",
            "32a45f3155ef461080b101d2a7744d47",
            "e570f6d2af354920ab068efea69cdad7",
            "84121165f43745fe8ac12ef3c45b514f",
            "b99ad78334084c1d9cf50cd7c579a30f",
            "4deb8120f00845b7987eb44971555ad6",
            "ccbe8779734e49118e1bf1aa6514e9ec",
            "e25ca698b9c448d29387c02b5caef1d4",
            "18af20861737490e930ebbd31b23c8be",
            "9fea44c3fda742bf95421245c131ea12",
            "0b154ba3e1c54280a9c60b0fe7d08333",
            "1fd501740dd0400d827d241889bcf46e",
            "cb7ec754b5fa4f0ea6ea6e24167a2d23",
            "2c60de2a7e464662b86d5a1c983da3b5",
            "6442f5a944a04f38840fe5365d1bfe29",
            "1693574a40304f5e9dd5a5bec492560b",
            "560b9fc71071411697895f067b78996d",
            "77f542f41711467e99a084ad50693201",
            "9ac682dd3da042c78fddb83f730ede1e",
            "0a1b6eec18d049f4a8730a846c63b2a0",
            "92b69924dddc44bfafd8be27ec3dada1",
            "f6d12ed1c3144f908123a9ccf55ab33b",
            "6d963ec1536441b68b213e3e804b1f7d"
          ]
        },
        "collapsed": true,
        "id": "sxYh4haZSKNh",
        "outputId": "4d2bcc43-0825-402d-d335-f5bb942e0801"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 131MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 29.7MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 95.2MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.98MB/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95c339d581964b08b5819aa4166223a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50] - Batch loss: 544.0444 - Epoch Loss: 544.0444 - Avg Loss: 544.0444\n",
            "Epoch [1/50] - Batch loss: 539.9706 - Epoch Loss: 1084.0150 - Avg Loss: 542.0075\n",
            "Epoch [1/50] - Batch loss: 535.6476 - Epoch Loss: 1619.6625 - Avg Loss: 539.8875\n",
            "Epoch [1/50] - Batch loss: 530.8463 - Epoch Loss: 2150.5089 - Avg Loss: 537.6272\n",
            "Epoch [1/50] - Batch loss: 525.0850 - Epoch Loss: 2675.5938 - Avg Loss: 535.1188\n",
            "Epoch [1/50] - Batch loss: 518.9064 - Epoch Loss: 3194.5002 - Avg Loss: 532.4167\n",
            "Epoch [1/50] - Batch loss: 511.5636 - Epoch Loss: 3706.0638 - Avg Loss: 529.4377\n",
            "Epoch [1/50] - Batch loss: 503.3069 - Epoch Loss: 4209.3707 - Avg Loss: 526.1713\n",
            "Epoch [1/50] - Batch loss: 493.8606 - Epoch Loss: 4703.2313 - Avg Loss: 522.5813\n",
            "Epoch [1/50] - Batch loss: 481.1222 - Epoch Loss: 5184.3534 - Avg Loss: 518.4353\n",
            "Epoch [1/50] - Batch loss: 469.3226 - Epoch Loss: 5653.6760 - Avg Loss: 513.9705\n",
            "Epoch [1/50] - Batch loss: 455.4171 - Epoch Loss: 6109.0931 - Avg Loss: 509.0911\n",
            "Epoch [1/50] - Batch loss: 441.9178 - Epoch Loss: 6551.0109 - Avg Loss: 503.9239\n",
            "Epoch [1/50] - Batch loss: 424.4488 - Epoch Loss: 6975.4597 - Avg Loss: 498.2471\n",
            "Epoch [1/50] - Batch loss: 406.1717 - Epoch Loss: 7381.6314 - Avg Loss: 492.1088\n",
            "Epoch [1/50] - Batch loss: 387.6401 - Epoch Loss: 7769.2715 - Avg Loss: 485.5795\n",
            "Epoch [1/50] - Batch loss: 364.5213 - Epoch Loss: 8133.7928 - Avg Loss: 478.4584\n",
            "Epoch [1/50] - Batch loss: 342.5422 - Epoch Loss: 8476.3350 - Avg Loss: 470.9075\n",
            "Epoch [1/50] - Batch loss: 324.6567 - Epoch Loss: 8800.9917 - Avg Loss: 463.2101\n",
            "Epoch [1/50] - Batch loss: 301.9503 - Epoch Loss: 9102.9420 - Avg Loss: 455.1471\n",
            "Epoch [1/50] - Batch loss: 283.1410 - Epoch Loss: 9386.0830 - Avg Loss: 446.9563\n",
            "Epoch [1/50] - Batch loss: 269.1442 - Epoch Loss: 9655.2271 - Avg Loss: 438.8740\n",
            "Epoch [1/50] - Batch loss: 252.0614 - Epoch Loss: 9907.2885 - Avg Loss: 430.7517\n",
            "Epoch [1/50] - Batch loss: 249.5159 - Epoch Loss: 10156.8044 - Avg Loss: 423.2002\n",
            "Epoch [1/50] - Batch loss: 241.6680 - Epoch Loss: 10398.4724 - Avg Loss: 415.9389\n",
            "Epoch [1/50] - Batch loss: 241.5894 - Epoch Loss: 10640.0618 - Avg Loss: 409.2331\n",
            "Epoch [1/50] - Batch loss: 234.8732 - Epoch Loss: 10874.9350 - Avg Loss: 402.7754\n",
            "Epoch [1/50] - Batch loss: 224.1122 - Epoch Loss: 11099.0473 - Avg Loss: 396.3945\n",
            "Epoch [1/50] - Batch loss: 236.6640 - Epoch Loss: 11335.7112 - Avg Loss: 390.8866\n",
            "Epoch [1/50] - Batch loss: 228.7915 - Epoch Loss: 11564.5028 - Avg Loss: 385.4834\n",
            "Epoch [1/50] - Batch loss: 225.6888 - Epoch Loss: 11790.1916 - Avg Loss: 380.3288\n",
            "Epoch [1/50] - Batch loss: 234.3812 - Epoch Loss: 12024.5728 - Avg Loss: 375.7679\n",
            "Epoch [1/50] - Batch loss: 220.0951 - Epoch Loss: 12244.6679 - Avg Loss: 371.0505\n",
            "Epoch [1/50] - Batch loss: 217.1949 - Epoch Loss: 12461.8628 - Avg Loss: 366.5254\n",
            "Epoch [1/50] - Batch loss: 213.9657 - Epoch Loss: 12675.8286 - Avg Loss: 362.1665\n",
            "Epoch [1/50] - Batch loss: 220.4190 - Epoch Loss: 12896.2476 - Avg Loss: 358.2291\n",
            "Epoch [1/50] - Batch loss: 218.5047 - Epoch Loss: 13114.7522 - Avg Loss: 354.4528\n",
            "Epoch [1/50] - Batch loss: 215.7581 - Epoch Loss: 13330.5103 - Avg Loss: 350.8029\n",
            "Epoch [1/50] - Batch loss: 221.0284 - Epoch Loss: 13551.5387 - Avg Loss: 347.4754\n",
            "Epoch [1/50] - Batch loss: 216.3851 - Epoch Loss: 13767.9238 - Avg Loss: 344.1981\n",
            "Epoch [1/50] - Batch loss: 208.3868 - Epoch Loss: 13976.3107 - Avg Loss: 340.8856\n",
            "Epoch [1/50] - Batch loss: 210.9417 - Epoch Loss: 14187.2523 - Avg Loss: 337.7917\n",
            "Epoch [1/50] - Batch loss: 208.9997 - Epoch Loss: 14396.2520 - Avg Loss: 334.7966\n",
            "Epoch [1/50] - Batch loss: 209.8886 - Epoch Loss: 14606.1406 - Avg Loss: 331.9577\n",
            "Epoch [1/50] - Batch loss: 214.1101 - Epoch Loss: 14820.2507 - Avg Loss: 329.3389\n",
            "Epoch [1/50] - Batch loss: 209.4967 - Epoch Loss: 15029.7473 - Avg Loss: 326.7336\n",
            "Epoch [1/50] - Batch loss: 213.7314 - Epoch Loss: 15243.4788 - Avg Loss: 324.3293\n",
            "Epoch [1/50] - Batch loss: 206.1500 - Epoch Loss: 15449.6288 - Avg Loss: 321.8673\n",
            "Epoch [1/50] - Batch loss: 209.7654 - Epoch Loss: 15659.3943 - Avg Loss: 319.5795\n",
            "Epoch [1/50] - Batch loss: 209.4849 - Epoch Loss: 15868.8792 - Avg Loss: 317.3776\n",
            "Epoch [1/50] - Batch loss: 204.3106 - Epoch Loss: 16073.1898 - Avg Loss: 315.1606\n",
            "Epoch [1/50] - Batch loss: 205.5414 - Epoch Loss: 16278.7312 - Avg Loss: 313.0525\n",
            "Epoch [1/50] - Batch loss: 212.2189 - Epoch Loss: 16490.9501 - Avg Loss: 311.1500\n",
            "Epoch [1/50] - Batch loss: 215.0315 - Epoch Loss: 16705.9816 - Avg Loss: 309.3700\n",
            "Epoch [1/50] - Batch loss: 210.5843 - Epoch Loss: 16916.5659 - Avg Loss: 307.5739\n",
            "Epoch [1/50] - Batch loss: 215.7000 - Epoch Loss: 17132.2659 - Avg Loss: 305.9333\n",
            "Epoch [1/50] - Batch loss: 209.8951 - Epoch Loss: 17342.1610 - Avg Loss: 304.2484\n",
            "Epoch [1/50] - Batch loss: 204.5554 - Epoch Loss: 17546.7164 - Avg Loss: 302.5296\n",
            "Epoch [1/50] - Batch loss: 210.6298 - Epoch Loss: 17757.3462 - Avg Loss: 300.9720\n",
            "Epoch [1/50] - Batch loss: 204.4638 - Epoch Loss: 17961.8100 - Avg Loss: 299.3635\n",
            "Epoch [1/50] - Batch loss: 213.3489 - Epoch Loss: 18175.1589 - Avg Loss: 297.9534\n",
            "Epoch [1/50] - Batch loss: 210.5798 - Epoch Loss: 18385.7387 - Avg Loss: 296.5442\n",
            "Epoch [1/50] - Batch loss: 214.6787 - Epoch Loss: 18600.4174 - Avg Loss: 295.2447\n",
            "Epoch [1/50] - Batch loss: 204.9256 - Epoch Loss: 18805.3430 - Avg Loss: 293.8335\n",
            "Epoch [1/50] - Batch loss: 214.4863 - Epoch Loss: 19019.8293 - Avg Loss: 292.6128\n",
            "Epoch [1/50] - Batch loss: 204.0418 - Epoch Loss: 19223.8712 - Avg Loss: 291.2708\n",
            "Epoch [1/50] - Batch loss: 209.4906 - Epoch Loss: 19433.3618 - Avg Loss: 290.0502\n",
            "Epoch [1/50] - Batch loss: 210.0229 - Epoch Loss: 19643.3847 - Avg Loss: 288.8733\n",
            "Epoch [1/50] - Batch loss: 197.8096 - Epoch Loss: 19841.1942 - Avg Loss: 287.5535\n",
            "Epoch [1/50] - Batch loss: 207.6470 - Epoch Loss: 20048.8412 - Avg Loss: 286.4120\n",
            "Epoch [1/50] - Batch loss: 208.1565 - Epoch Loss: 20256.9977 - Avg Loss: 285.3098\n",
            "Epoch [1/50] - Batch loss: 206.7842 - Epoch Loss: 20463.7819 - Avg Loss: 284.2192\n",
            "Epoch [1/50] - Batch loss: 205.2353 - Epoch Loss: 20669.0172 - Avg Loss: 283.1372\n",
            "Epoch [1/50] - Batch loss: 208.3498 - Epoch Loss: 20877.3670 - Avg Loss: 282.1266\n",
            "Epoch [1/50] - Batch loss: 206.1980 - Epoch Loss: 21083.5650 - Avg Loss: 281.1142\n",
            "Epoch [1/50] - Batch loss: 208.8994 - Epoch Loss: 21292.4644 - Avg Loss: 280.1640\n",
            "Epoch [1/50] - Batch loss: 210.5141 - Epoch Loss: 21502.9786 - Avg Loss: 279.2595\n",
            "Epoch [1/50] - Batch loss: 210.6568 - Epoch Loss: 21713.6354 - Avg Loss: 278.3799\n",
            "Epoch [1/50] - Batch loss: 203.9075 - Epoch Loss: 21917.5429 - Avg Loss: 277.4373\n",
            "Epoch [1/50] - Batch loss: 205.2232 - Epoch Loss: 22122.7661 - Avg Loss: 276.5346\n",
            "Epoch [1/50] - Batch loss: 210.8223 - Epoch Loss: 22333.5884 - Avg Loss: 275.7233\n",
            "Epoch [1/50] - Batch loss: 211.2557 - Epoch Loss: 22544.8440 - Avg Loss: 274.9371\n",
            "Epoch [1/50] - Batch loss: 207.1913 - Epoch Loss: 22752.0354 - Avg Loss: 274.1209\n",
            "Epoch [1/50] - Batch loss: 203.6274 - Epoch Loss: 22955.6628 - Avg Loss: 273.2817\n",
            "Epoch [1/50] - Batch loss: 208.8059 - Epoch Loss: 23164.4687 - Avg Loss: 272.5232\n",
            "Epoch [1/50] - Batch loss: 205.7543 - Epoch Loss: 23370.2230 - Avg Loss: 271.7468\n",
            "Epoch [1/50] - Batch loss: 207.1369 - Epoch Loss: 23577.3598 - Avg Loss: 271.0041\n",
            "Epoch [1/50] - Batch loss: 202.8074 - Epoch Loss: 23780.1672 - Avg Loss: 270.2292\n",
            "Epoch [1/50] - Batch loss: 207.1935 - Epoch Loss: 23987.3607 - Avg Loss: 269.5209\n",
            "Epoch [1/50] - Batch loss: 206.8228 - Epoch Loss: 24194.1835 - Avg Loss: 268.8243\n",
            "Epoch [1/50] - Batch loss: 206.7061 - Epoch Loss: 24400.8896 - Avg Loss: 268.1416\n",
            "Epoch [1/50] - Batch loss: 214.8969 - Epoch Loss: 24615.7865 - Avg Loss: 267.5629\n",
            "Epoch [1/50] - Batch loss: 208.3929 - Epoch Loss: 24824.1794 - Avg Loss: 266.9267\n",
            "Epoch [1/50] - Batch loss: 206.2694 - Epoch Loss: 25030.4488 - Avg Loss: 266.2814\n",
            "Epoch [1/50] - Batch loss: 208.9041 - Epoch Loss: 25239.3530 - Avg Loss: 265.6774\n",
            "Epoch [1/50] - Batch loss: 203.8290 - Epoch Loss: 25443.1820 - Avg Loss: 265.0331\n",
            "Epoch [1/50] - Batch loss: 201.2695 - Epoch Loss: 25644.4514 - Avg Loss: 264.3758\n",
            "Epoch [1/50] - Batch loss: 207.3878 - Epoch Loss: 25851.8392 - Avg Loss: 263.7943\n",
            "Epoch [1/50] - Batch loss: 205.6465 - Epoch Loss: 26057.4857 - Avg Loss: 263.2069\n",
            "Epoch [1/50] - Batch loss: 201.8839 - Epoch Loss: 26259.3696 - Avg Loss: 262.5937\n",
            "Epoch [1/50] - Batch loss: 211.7493 - Epoch Loss: 26471.1190 - Avg Loss: 262.0903\n",
            "Epoch [1/50] - Batch loss: 204.1497 - Epoch Loss: 26675.2687 - Avg Loss: 261.5222\n",
            "Epoch [1/50] - Batch loss: 204.0593 - Epoch Loss: 26879.3280 - Avg Loss: 260.9643\n",
            "Epoch [1/50] - Batch loss: 203.2735 - Epoch Loss: 27082.6016 - Avg Loss: 260.4096\n",
            "Epoch [1/50] - Batch loss: 207.4659 - Epoch Loss: 27290.0675 - Avg Loss: 259.9054\n",
            "Epoch [1/50] - Batch loss: 207.3798 - Epoch Loss: 27497.4473 - Avg Loss: 259.4099\n",
            "Epoch [1/50] - Batch loss: 207.0020 - Epoch Loss: 27704.4493 - Avg Loss: 258.9201\n",
            "Epoch [1/50] - Batch loss: 208.0681 - Epoch Loss: 27912.5174 - Avg Loss: 258.4492\n",
            "Epoch [1/50] - Batch loss: 206.0806 - Epoch Loss: 28118.5980 - Avg Loss: 257.9688\n",
            "Epoch [1/50] - Batch loss: 207.5927 - Epoch Loss: 28326.1907 - Avg Loss: 257.5108\n",
            "Epoch [1/50] - Batch loss: 199.0304 - Epoch Loss: 28525.2211 - Avg Loss: 256.9840\n",
            "Epoch [1/50] - Batch loss: 205.1374 - Epoch Loss: 28730.3585 - Avg Loss: 256.5211\n",
            "Epoch [1/50] - Batch loss: 198.0214 - Epoch Loss: 28928.3799 - Avg Loss: 256.0034\n",
            "Epoch [1/50] - Batch loss: 205.4227 - Epoch Loss: 29133.8026 - Avg Loss: 255.5597\n",
            "Epoch [1/50] - Batch loss: 208.4041 - Epoch Loss: 29342.2067 - Avg Loss: 255.1496\n",
            "Epoch [1/50] - Batch loss: 204.2167 - Epoch Loss: 29546.4234 - Avg Loss: 254.7105\n",
            "Epoch [1/50] - Batch loss: 202.9557 - Epoch Loss: 29749.3791 - Avg Loss: 254.2682\n",
            "Epoch [1/50] - Batch loss: 204.6504 - Epoch Loss: 29954.0296 - Avg Loss: 253.8477\n",
            "Epoch [1/50] - Batch loss: 209.4173 - Epoch Loss: 30163.4469 - Avg Loss: 253.4743\n",
            "Epoch [1/50] - Batch loss: 209.3456 - Epoch Loss: 30372.7925 - Avg Loss: 253.1066\n",
            "Epoch [1/50] - Batch loss: 205.4449 - Epoch Loss: 30578.2374 - Avg Loss: 252.7127\n",
            "Epoch [1/50] - Batch loss: 201.8636 - Epoch Loss: 30780.1010 - Avg Loss: 252.2959\n",
            "Epoch [1/50] - Batch loss: 210.6339 - Epoch Loss: 30990.7349 - Avg Loss: 251.9572\n",
            "Epoch [1/50] - Batch loss: 209.6229 - Epoch Loss: 31200.3578 - Avg Loss: 251.6158\n",
            "Epoch [1/50] - Batch loss: 200.6025 - Epoch Loss: 31400.9603 - Avg Loss: 251.2077\n",
            "Epoch [1/50] - Batch loss: 199.9258 - Epoch Loss: 31600.8862 - Avg Loss: 250.8007\n",
            "Epoch [1/50] - Batch loss: 207.1510 - Epoch Loss: 31808.0372 - Avg Loss: 250.4570\n",
            "Epoch [1/50] - Batch loss: 208.4056 - Epoch Loss: 32016.4428 - Avg Loss: 250.1285\n",
            "Epoch [1/50] - Batch loss: 200.1690 - Epoch Loss: 32216.6118 - Avg Loss: 249.7412\n",
            "Epoch [1/50] - Batch loss: 201.3439 - Epoch Loss: 32417.9557 - Avg Loss: 249.3689\n",
            "Epoch [1/50] - Batch loss: 203.9422 - Epoch Loss: 32621.8978 - Avg Loss: 249.0221\n",
            "Epoch [1/50] - Batch loss: 211.4697 - Epoch Loss: 32833.3676 - Avg Loss: 248.7376\n",
            "Epoch [1/50] - Batch loss: 204.4595 - Epoch Loss: 33037.8271 - Avg Loss: 248.4047\n",
            "Epoch [1/50] - Batch loss: 202.7708 - Epoch Loss: 33240.5979 - Avg Loss: 248.0642\n",
            "Epoch [1/50] - Batch loss: 206.1930 - Epoch Loss: 33446.7909 - Avg Loss: 247.7540\n",
            "Epoch [1/50] - Batch loss: 201.4425 - Epoch Loss: 33648.2334 - Avg Loss: 247.4135\n",
            "Epoch [1/50] - Batch loss: 199.9416 - Epoch Loss: 33848.1750 - Avg Loss: 247.0670\n",
            "Epoch [1/50] - Batch loss: 207.1134 - Epoch Loss: 34055.2884 - Avg Loss: 246.7775\n",
            "Epoch [1/50] - Batch loss: 202.6465 - Epoch Loss: 34257.9349 - Avg Loss: 246.4600\n",
            "Epoch [1/50] - Batch loss: 208.6336 - Epoch Loss: 34466.5685 - Avg Loss: 246.1898\n",
            "Epoch [1/50] - Batch loss: 204.3600 - Epoch Loss: 34670.9286 - Avg Loss: 245.8931\n",
            "Epoch [1/50] - Batch loss: 212.2822 - Epoch Loss: 34883.2108 - Avg Loss: 245.6564\n",
            "Epoch [1/50] - Batch loss: 206.2594 - Epoch Loss: 35089.4701 - Avg Loss: 245.3809\n",
            "Epoch [1/50] - Batch loss: 199.7658 - Epoch Loss: 35289.2359 - Avg Loss: 245.0641\n",
            "Epoch [1/50] - Batch loss: 210.7878 - Epoch Loss: 35500.0238 - Avg Loss: 244.8278\n",
            "Epoch [1/50] - Batch loss: 208.7287 - Epoch Loss: 35708.7525 - Avg Loss: 244.5805\n",
            "Epoch [1/50] - Batch loss: 205.0323 - Epoch Loss: 35913.7848 - Avg Loss: 244.3115\n",
            "Epoch [1/50] - Batch loss: 212.2743 - Epoch Loss: 36126.0591 - Avg Loss: 244.0950\n",
            "Epoch [1/50] - Batch loss: 196.3208 - Epoch Loss: 36322.3798 - Avg Loss: 243.7744\n",
            "Epoch [1/50] - Batch loss: 206.1627 - Epoch Loss: 36528.5425 - Avg Loss: 243.5236\n",
            "Epoch [1/50] - Batch loss: 202.3434 - Epoch Loss: 36730.8859 - Avg Loss: 243.2509\n",
            "Epoch [1/50] - Batch loss: 208.0217 - Epoch Loss: 36938.9077 - Avg Loss: 243.0191\n",
            "Epoch [1/50] - Batch loss: 201.6197 - Epoch Loss: 37140.5274 - Avg Loss: 242.7485\n",
            "Epoch [1/50] - Batch loss: 195.8256 - Epoch Loss: 37336.3530 - Avg Loss: 242.4439\n",
            "Epoch [1/50] - Batch loss: 202.2509 - Epoch Loss: 37538.6039 - Avg Loss: 242.1845\n",
            "Epoch [1/50] - Batch loss: 195.5440 - Epoch Loss: 37734.1479 - Avg Loss: 241.8856\n",
            "Epoch [1/50] - Batch loss: 204.2981 - Epoch Loss: 37938.4460 - Avg Loss: 241.6462\n",
            "Epoch [1/50] - Batch loss: 205.8009 - Epoch Loss: 38144.2469 - Avg Loss: 241.4193\n",
            "Epoch [1/50] - Batch loss: 208.3421 - Epoch Loss: 38352.5890 - Avg Loss: 241.2113\n",
            "Epoch [1/50] - Batch loss: 201.3600 - Epoch Loss: 38553.9490 - Avg Loss: 240.9622\n",
            "Epoch [1/50] - Batch loss: 200.3615 - Epoch Loss: 38754.3105 - Avg Loss: 240.7100\n",
            "Epoch [1/50] - Batch loss: 209.0434 - Epoch Loss: 38963.3539 - Avg Loss: 240.5145\n",
            "Epoch [1/50] - Batch loss: 196.4107 - Epoch Loss: 39159.7645 - Avg Loss: 240.2440\n",
            "Epoch [1/50] - Batch loss: 203.6568 - Epoch Loss: 39363.4214 - Avg Loss: 240.0209\n",
            "Epoch [1/50] - Batch loss: 206.0945 - Epoch Loss: 39569.5159 - Avg Loss: 239.8152\n",
            "Epoch [1/50] - Batch loss: 200.0003 - Epoch Loss: 39769.5162 - Avg Loss: 239.5754\n",
            "Epoch [1/50] - Batch loss: 195.9967 - Epoch Loss: 39965.5130 - Avg Loss: 239.3144\n",
            "Epoch [1/50] - Batch loss: 202.8985 - Epoch Loss: 40168.4115 - Avg Loss: 239.0977\n",
            "Epoch [1/50] - Batch loss: 208.4720 - Epoch Loss: 40376.8835 - Avg Loss: 238.9165\n",
            "Epoch [1/50] - Batch loss: 195.1991 - Epoch Loss: 40572.0826 - Avg Loss: 238.6593\n",
            "Epoch [1/50] - Batch loss: 202.7552 - Epoch Loss: 40774.8379 - Avg Loss: 238.4493\n",
            "Epoch [1/50] - Batch loss: 198.8000 - Epoch Loss: 40973.6379 - Avg Loss: 238.2188\n",
            "Epoch [1/50] - Batch loss: 198.1096 - Epoch Loss: 41171.7475 - Avg Loss: 237.9870\n",
            "Epoch [1/50] - Batch loss: 193.7002 - Epoch Loss: 41365.4477 - Avg Loss: 237.7325\n",
            "Epoch [1/50] - Batch loss: 205.2919 - Epoch Loss: 41570.7396 - Avg Loss: 237.5471\n",
            "Epoch [1/50] - Batch loss: 202.2891 - Epoch Loss: 41773.0287 - Avg Loss: 237.3468\n",
            "Epoch [1/50] - Batch loss: 201.2863 - Epoch Loss: 41974.3150 - Avg Loss: 237.1430\n",
            "Epoch [1/50] - Batch loss: 199.0584 - Epoch Loss: 42173.3734 - Avg Loss: 236.9291\n",
            "Epoch [1/50] - Batch loss: 206.6137 - Epoch Loss: 42379.9872 - Avg Loss: 236.7597\n",
            "Epoch [1/50] - Batch loss: 205.9200 - Epoch Loss: 42585.9072 - Avg Loss: 236.5884\n",
            "Epoch [1/50] - Batch loss: 206.5891 - Epoch Loss: 42792.4962 - Avg Loss: 236.4226\n",
            "Epoch [1/50] - Batch loss: 206.0343 - Epoch Loss: 42998.5305 - Avg Loss: 236.2557\n",
            "Epoch [1/50] - Batch loss: 203.6289 - Epoch Loss: 43202.1594 - Avg Loss: 236.0774\n",
            "Epoch [1/50] - Batch loss: 200.4230 - Epoch Loss: 43402.5825 - Avg Loss: 235.8836\n",
            "Epoch [1/50] - Batch loss: 201.3810 - Epoch Loss: 43603.9634 - Avg Loss: 235.6971\n",
            "Epoch [1/50] - Batch loss: 198.5475 - Epoch Loss: 43802.5110 - Avg Loss: 235.4974\n",
            "Epoch [1/50] - Batch loss: 199.7198 - Epoch Loss: 44002.2307 - Avg Loss: 235.3060\n",
            "Epoch [1/50] - Batch loss: 197.2827 - Epoch Loss: 44199.5134 - Avg Loss: 235.1038\n",
            "Epoch [1/50] - Batch loss: 203.1813 - Epoch Loss: 44402.6947 - Avg Loss: 234.9349\n",
            "Epoch [1/50] - Batch loss: 199.5273 - Epoch Loss: 44602.2220 - Avg Loss: 234.7485\n",
            "Epoch [1/50] - Batch loss: 197.0046 - Epoch Loss: 44799.2265 - Avg Loss: 234.5509\n",
            "Epoch [1/50] - Batch loss: 202.4378 - Epoch Loss: 45001.6643 - Avg Loss: 234.3837\n",
            "Epoch [1/50] - Batch loss: 203.6087 - Epoch Loss: 45205.2730 - Avg Loss: 234.2242\n",
            "Epoch [1/50] - Batch loss: 201.2446 - Epoch Loss: 45406.5176 - Avg Loss: 234.0542\n",
            "Epoch [1/50] - Batch loss: 203.1640 - Epoch Loss: 45609.6816 - Avg Loss: 233.8958\n",
            "Epoch [1/50] - Batch loss: 197.4909 - Epoch Loss: 45807.1725 - Avg Loss: 233.7101\n",
            "Epoch [1/50] - Batch loss: 199.1863 - Epoch Loss: 46006.3589 - Avg Loss: 233.5348\n",
            "Epoch [1/50] - Batch loss: 203.2208 - Epoch Loss: 46209.5796 - Avg Loss: 233.3817\n",
            "Epoch [1/50] - Batch loss: 204.4267 - Epoch Loss: 46414.0064 - Avg Loss: 233.2362\n",
            "Epoch [1/50] - Batch loss: 192.6107 - Epoch Loss: 46606.6171 - Avg Loss: 233.0331\n",
            "Epoch [1/50] - Batch loss: 200.6348 - Epoch Loss: 46807.2519 - Avg Loss: 232.8719\n",
            "Epoch [1/50] - Batch loss: 207.6028 - Epoch Loss: 47014.8546 - Avg Loss: 232.7468\n",
            "Epoch [1/50] - Batch loss: 199.9021 - Epoch Loss: 47214.7567 - Avg Loss: 232.5850\n",
            "Epoch [1/50] - Batch loss: 201.6979 - Epoch Loss: 47416.4546 - Avg Loss: 232.4336\n",
            "Epoch [1/50] - Batch loss: 199.6915 - Epoch Loss: 47616.1461 - Avg Loss: 232.2739\n",
            "Epoch [1/50] - Batch loss: 205.3784 - Epoch Loss: 47821.5245 - Avg Loss: 232.1433\n",
            "Epoch [1/50] - Batch loss: 204.3361 - Epoch Loss: 48025.8606 - Avg Loss: 232.0090\n",
            "Epoch [1/50] - Batch loss: 200.7814 - Epoch Loss: 48226.6420 - Avg Loss: 231.8589\n",
            "Epoch [1/50] - Batch loss: 196.8856 - Epoch Loss: 48423.5276 - Avg Loss: 231.6915\n",
            "Epoch [1/50] - Batch loss: 197.3109 - Epoch Loss: 48620.8384 - Avg Loss: 231.5278\n",
            "Epoch [1/50] - Batch loss: 192.1622 - Epoch Loss: 48813.0007 - Avg Loss: 231.3412\n",
            "Epoch [1/50] - Batch loss: 188.6247 - Epoch Loss: 49001.6254 - Avg Loss: 231.1397\n",
            "Epoch [1/50] - Batch loss: 206.5079 - Epoch Loss: 49208.1332 - Avg Loss: 231.0241\n",
            "Epoch [1/50] - Batch loss: 199.0186 - Epoch Loss: 49407.1518 - Avg Loss: 230.8745\n",
            "Epoch [1/50] - Batch loss: 192.3530 - Epoch Loss: 49599.5049 - Avg Loss: 230.6954\n",
            "Epoch [1/50] - Batch loss: 195.8695 - Epoch Loss: 49795.3743 - Avg Loss: 230.5341\n",
            "Epoch [1/50] - Batch loss: 196.6504 - Epoch Loss: 49992.0248 - Avg Loss: 230.3780\n",
            "Epoch [1/50] - Batch loss: 197.4313 - Epoch Loss: 50189.4561 - Avg Loss: 230.2269\n",
            "Epoch [1/50] - Batch loss: 193.8564 - Epoch Loss: 50383.3125 - Avg Loss: 230.0608\n",
            "Epoch [1/50] - Batch loss: 191.8261 - Epoch Loss: 50575.1386 - Avg Loss: 229.8870\n",
            "Epoch [1/50] - Batch loss: 200.7280 - Epoch Loss: 50775.8666 - Avg Loss: 229.7551\n",
            "Epoch [1/50] - Batch loss: 200.7955 - Epoch Loss: 50976.6620 - Avg Loss: 229.6246\n",
            "Epoch [1/50] - Batch loss: 193.8109 - Epoch Loss: 51170.4730 - Avg Loss: 229.4640\n",
            "Epoch [1/50] - Batch loss: 194.6347 - Epoch Loss: 51365.1076 - Avg Loss: 229.3085\n",
            "Epoch [1/50] - Batch loss: 199.5517 - Epoch Loss: 51564.6593 - Avg Loss: 229.1763\n",
            "Epoch [1/50] - Batch loss: 202.1645 - Epoch Loss: 51766.8238 - Avg Loss: 229.0567\n",
            "Epoch [1/50] - Batch loss: 192.4015 - Epoch Loss: 51959.2253 - Avg Loss: 228.8953\n",
            "Epoch [1/50] - Batch loss: 199.9416 - Epoch Loss: 52159.1669 - Avg Loss: 228.7683\n",
            "Epoch [1/50] - Batch loss: 196.5889 - Epoch Loss: 52355.7558 - Avg Loss: 228.6278\n",
            "Epoch [1/50] - Batch loss: 197.2083 - Epoch Loss: 52552.9641 - Avg Loss: 228.4911\n",
            "Epoch [1/50] - Batch loss: 184.5933 - Epoch Loss: 52737.5574 - Avg Loss: 228.3011\n",
            "Epoch [1/50] - Batch loss: 194.3187 - Epoch Loss: 52931.8761 - Avg Loss: 228.1546\n",
            "Epoch [1/50] - Batch loss: 201.2036 - Epoch Loss: 53133.0797 - Avg Loss: 228.0390\n",
            "Epoch [1/50] - Batch loss: 195.8378 - Epoch Loss: 53328.9175 - Avg Loss: 227.9014\n",
            "Epoch [1/50] - Batch loss: 194.2661 - Epoch Loss: 53523.1836 - Avg Loss: 227.7582\n",
            "Epoch [1/50] - Batch loss: 193.4695 - Epoch Loss: 53716.6531 - Avg Loss: 227.6129\n",
            "Epoch [1/50] - Batch loss: 196.8362 - Epoch Loss: 53913.4893 - Avg Loss: 227.4831\n",
            "Epoch [1/50] - Batch loss: 192.0373 - Epoch Loss: 54105.5266 - Avg Loss: 227.3341\n",
            "Epoch [1/50] - Batch loss: 197.8707 - Epoch Loss: 54303.3973 - Avg Loss: 227.2109\n",
            "Epoch [1/50] - Batch loss: 197.0745 - Epoch Loss: 54500.4718 - Avg Loss: 227.0853\n",
            "Epoch [1/50] - Batch loss: 203.3039 - Epoch Loss: 54703.7757 - Avg Loss: 226.9866\n",
            "Epoch [1/50] - Batch loss: 195.7626 - Epoch Loss: 54899.5382 - Avg Loss: 226.8576\n",
            "Epoch [1/50] - Batch loss: 195.1029 - Epoch Loss: 55094.6411 - Avg Loss: 226.7269\n",
            "Epoch [1/50] - Batch loss: 195.7287 - Epoch Loss: 55290.3698 - Avg Loss: 226.5999\n",
            "Epoch [1/50] - Batch loss: 203.6857 - Epoch Loss: 55494.0555 - Avg Loss: 226.5063\n",
            "Epoch [1/50] - Batch loss: 200.1054 - Epoch Loss: 55694.1609 - Avg Loss: 226.3990\n",
            "Epoch [1/50] - Batch loss: 201.0807 - Epoch Loss: 55895.2416 - Avg Loss: 226.2965\n",
            "Epoch [1/50] - Batch loss: 191.6211 - Epoch Loss: 56086.8627 - Avg Loss: 226.1567\n",
            "Epoch [1/50] - Batch loss: 204.5659 - Epoch Loss: 56291.4286 - Avg Loss: 226.0700\n",
            "Epoch [1/50] - Batch loss: 195.3228 - Epoch Loss: 56486.7514 - Avg Loss: 225.9470\n",
            "Epoch [1/50] - Batch loss: 197.9900 - Epoch Loss: 56684.7414 - Avg Loss: 225.8356\n",
            "Epoch [1/50] - Batch loss: 196.8002 - Epoch Loss: 56881.5416 - Avg Loss: 225.7204\n",
            "Epoch [1/50] - Batch loss: 190.9097 - Epoch Loss: 57072.4512 - Avg Loss: 225.5828\n",
            "Epoch [1/50] - Batch loss: 198.3824 - Epoch Loss: 57270.8336 - Avg Loss: 225.4757\n",
            "Epoch [1/50] - Batch loss: 192.3703 - Epoch Loss: 57463.2039 - Avg Loss: 225.3459\n",
            "Epoch [1/50] - Batch loss: 194.8611 - Epoch Loss: 57658.0650 - Avg Loss: 225.2268\n",
            "Epoch [1/50] - Batch loss: 195.1157 - Epoch Loss: 57853.1807 - Avg Loss: 225.1097\n",
            "Epoch [1/50] - Batch loss: 195.7941 - Epoch Loss: 58048.9748 - Avg Loss: 224.9960\n",
            "Epoch [1/50] - Batch loss: 193.0052 - Epoch Loss: 58241.9800 - Avg Loss: 224.8725\n",
            "Epoch [1/50] - Batch loss: 194.9128 - Epoch Loss: 58436.8928 - Avg Loss: 224.7573\n",
            "Epoch [1/50] - Batch loss: 184.8658 - Epoch Loss: 58621.7586 - Avg Loss: 224.6044\n",
            "Epoch [1/50] - Batch loss: 192.3326 - Epoch Loss: 58814.0912 - Avg Loss: 224.4813\n",
            "Epoch [1/50] - Batch loss: 191.7483 - Epoch Loss: 59005.8396 - Avg Loss: 224.3568\n",
            "Epoch [1/50] - Batch loss: 185.2146 - Epoch Loss: 59191.0542 - Avg Loss: 224.2085\n",
            "Epoch [1/50] - Batch loss: 192.9673 - Epoch Loss: 59384.0215 - Avg Loss: 224.0906\n",
            "Epoch [1/50] - Batch loss: 198.2790 - Epoch Loss: 59582.3006 - Avg Loss: 223.9936\n",
            "Epoch [1/50] - Batch loss: 197.2482 - Epoch Loss: 59779.5487 - Avg Loss: 223.8934\n",
            "Epoch [1/50] - Batch loss: 189.5669 - Epoch Loss: 59969.1156 - Avg Loss: 223.7654\n",
            "Epoch [1/50] - Batch loss: 184.4630 - Epoch Loss: 60153.5786 - Avg Loss: 223.6193\n",
            "Epoch [1/50] - Batch loss: 191.4723 - Epoch Loss: 60345.0509 - Avg Loss: 223.5002\n",
            "Epoch [1/50] - Batch loss: 200.0566 - Epoch Loss: 60545.1075 - Avg Loss: 223.4137\n",
            "Epoch [1/50] - Batch loss: 191.6663 - Epoch Loss: 60736.7738 - Avg Loss: 223.2970\n",
            "Epoch [1/50] - Batch loss: 195.9456 - Epoch Loss: 60932.7194 - Avg Loss: 223.1968\n",
            "Epoch [1/50] - Batch loss: 195.1095 - Epoch Loss: 61127.8289 - Avg Loss: 223.0943\n",
            "Epoch [1/50] - Batch loss: 194.9443 - Epoch Loss: 61322.7732 - Avg Loss: 222.9919\n",
            "Epoch [1/50] - Batch loss: 194.3643 - Epoch Loss: 61517.1375 - Avg Loss: 222.8882\n",
            "Epoch [1/50] - Batch loss: 200.7942 - Epoch Loss: 61717.9317 - Avg Loss: 222.8084\n",
            "Epoch [1/50] - Batch loss: 186.9877 - Epoch Loss: 61904.9194 - Avg Loss: 222.6796\n",
            "Epoch [1/50] - Batch loss: 193.4962 - Epoch Loss: 62098.4156 - Avg Loss: 222.5750\n",
            "Epoch [1/50] - Batch loss: 194.4062 - Epoch Loss: 62292.8219 - Avg Loss: 222.4744\n",
            "Epoch [1/50] - Batch loss: 196.0497 - Epoch Loss: 62488.8715 - Avg Loss: 222.3803\n",
            "Epoch [1/50] - Batch loss: 186.9890 - Epoch Loss: 62675.8606 - Avg Loss: 222.2548\n",
            "Epoch [1/50] - Batch loss: 189.6838 - Epoch Loss: 62865.5444 - Avg Loss: 222.1397\n",
            "Epoch [1/50] - Batch loss: 197.6436 - Epoch Loss: 63063.1880 - Avg Loss: 222.0535\n",
            "Epoch [1/50] - Batch loss: 192.4223 - Epoch Loss: 63255.6103 - Avg Loss: 221.9495\n",
            "Epoch [1/50] - Batch loss: 195.6574 - Epoch Loss: 63451.2677 - Avg Loss: 221.8576\n",
            "Epoch [1/50] - Batch loss: 199.7205 - Epoch Loss: 63650.9882 - Avg Loss: 221.7804\n",
            "Epoch [1/50] - Batch loss: 193.6220 - Epoch Loss: 63844.6102 - Avg Loss: 221.6827\n",
            "Epoch [1/50] - Batch loss: 195.9921 - Epoch Loss: 64040.6023 - Avg Loss: 221.5938\n",
            "Epoch [1/50] - Batch loss: 190.8710 - Epoch Loss: 64231.4733 - Avg Loss: 221.4878\n",
            "Epoch [1/50] - Batch loss: 193.4167 - Epoch Loss: 64424.8900 - Avg Loss: 221.3914\n",
            "Epoch [1/50] - Batch loss: 188.6920 - Epoch Loss: 64613.5819 - Avg Loss: 221.2794\n",
            "Epoch [1/50] - Batch loss: 194.6783 - Epoch Loss: 64808.2602 - Avg Loss: 221.1886\n",
            "Epoch [1/50] - Batch loss: 187.5443 - Epoch Loss: 64995.8045 - Avg Loss: 221.0742\n",
            "Epoch [1/50] - Batch loss: 199.1729 - Epoch Loss: 65194.9774 - Avg Loss: 220.9999\n",
            "Epoch [1/50] - Batch loss: 189.4725 - Epoch Loss: 65384.4499 - Avg Loss: 220.8934\n",
            "Epoch [1/50] - Batch loss: 194.6664 - Epoch Loss: 65579.1163 - Avg Loss: 220.8051\n",
            "Epoch [1/50] - Batch loss: 198.4644 - Epoch Loss: 65777.5806 - Avg Loss: 220.7301\n",
            "Epoch [1/50] - Batch loss: 186.8634 - Epoch Loss: 65964.4440 - Avg Loss: 220.6169\n",
            "Epoch [1/50] - Batch loss: 191.0455 - Epoch Loss: 66155.4895 - Avg Loss: 220.5183\n",
            "Epoch [1/50] - Batch loss: 189.6208 - Epoch Loss: 66345.1103 - Avg Loss: 220.4156\n",
            "Epoch [1/50] - Batch loss: 194.1962 - Epoch Loss: 66539.3066 - Avg Loss: 220.3288\n",
            "Epoch [1/50] - Batch loss: 194.3406 - Epoch Loss: 66733.6471 - Avg Loss: 220.2431\n",
            "Epoch [1/50] - Batch loss: 186.9491 - Epoch Loss: 66920.5963 - Avg Loss: 220.1335\n",
            "Epoch [1/50] - Batch loss: 190.5393 - Epoch Loss: 67111.1355 - Avg Loss: 220.0365\n",
            "Epoch [1/50] - Batch loss: 196.3888 - Epoch Loss: 67307.5243 - Avg Loss: 219.9592\n",
            "Epoch [1/50] - Batch loss: 186.7941 - Epoch Loss: 67494.3184 - Avg Loss: 219.8512\n",
            "Epoch [1/50] - Batch loss: 197.7650 - Epoch Loss: 67692.0833 - Avg Loss: 219.7795\n",
            "Epoch [1/50] - Batch loss: 194.5132 - Epoch Loss: 67886.5965 - Avg Loss: 219.6977\n",
            "Epoch [1/50] - Batch loss: 194.8845 - Epoch Loss: 68081.4810 - Avg Loss: 219.6177\n",
            "Epoch [1/50] - Batch loss: 182.6774 - Epoch Loss: 68264.1584 - Avg Loss: 219.4989\n",
            "Epoch [1/50] - Batch loss: 202.3981 - Epoch Loss: 68466.5565 - Avg Loss: 219.4441\n",
            "Epoch [1/50] - Batch loss: 193.6028 - Epoch Loss: 68660.1592 - Avg Loss: 219.3615\n",
            "Epoch [1/50] - Batch loss: 197.3939 - Epoch Loss: 68857.5531 - Avg Loss: 219.2916\n",
            "Epoch [1/50] - Batch loss: 192.6551 - Epoch Loss: 69050.2082 - Avg Loss: 219.2070\n",
            "Epoch [1/50] - Batch loss: 190.1049 - Epoch Loss: 69240.3130 - Avg Loss: 219.1149\n",
            "Epoch [1/50] - Batch loss: 183.2133 - Epoch Loss: 69423.5264 - Avg Loss: 219.0017\n",
            "Epoch [1/50] - Batch loss: 191.4293 - Epoch Loss: 69614.9557 - Avg Loss: 218.9150\n",
            "Epoch [1/50] - Batch loss: 191.0552 - Epoch Loss: 69806.0109 - Avg Loss: 218.8276\n",
            "Epoch [1/50] - Batch loss: 197.3115 - Epoch Loss: 70003.3224 - Avg Loss: 218.7604\n",
            "Epoch [1/50] - Batch loss: 193.8999 - Epoch Loss: 70197.2223 - Avg Loss: 218.6829\n",
            "Epoch [1/50] - Batch loss: 191.9790 - Epoch Loss: 70389.2013 - Avg Loss: 218.6000\n",
            "Epoch [1/50] - Batch loss: 183.7842 - Epoch Loss: 70572.9855 - Avg Loss: 218.4922\n",
            "Epoch [1/50] - Batch loss: 193.5724 - Epoch Loss: 70766.5579 - Avg Loss: 218.4153\n",
            "Epoch [1/50] - Batch loss: 189.5585 - Epoch Loss: 70956.1163 - Avg Loss: 218.3265\n",
            "Epoch [1/50] - Batch loss: 190.8170 - Epoch Loss: 71146.9334 - Avg Loss: 218.2421\n",
            "Epoch [1/50] - Batch loss: 194.0075 - Epoch Loss: 71340.9409 - Avg Loss: 218.1680\n",
            "Epoch [1/50] - Batch loss: 194.0819 - Epoch Loss: 71535.0228 - Avg Loss: 218.0946\n",
            "Epoch [1/50] - Batch loss: 196.9037 - Epoch Loss: 71731.9266 - Avg Loss: 218.0302\n",
            "Epoch [1/50] - Batch loss: 190.8486 - Epoch Loss: 71922.7751 - Avg Loss: 217.9478\n",
            "Epoch [1/50] - Batch loss: 191.6800 - Epoch Loss: 72114.4552 - Avg Loss: 217.8684\n",
            "Epoch [1/50] - Batch loss: 186.6005 - Epoch Loss: 72301.0556 - Avg Loss: 217.7743\n",
            "Epoch [1/50] - Batch loss: 194.1877 - Epoch Loss: 72495.2433 - Avg Loss: 217.7034\n",
            "Epoch [1/50] - Batch loss: 192.9213 - Epoch Loss: 72688.1646 - Avg Loss: 217.6292\n",
            "Epoch [1/50] - Batch loss: 195.1612 - Epoch Loss: 72883.3259 - Avg Loss: 217.5622\n",
            "Epoch [1/50] - Batch loss: 191.7965 - Epoch Loss: 73075.1224 - Avg Loss: 217.4855\n",
            "Epoch [1/50] - Batch loss: 191.4942 - Epoch Loss: 73266.6166 - Avg Loss: 217.4084\n",
            "Epoch [1/50] - Batch loss: 195.3986 - Epoch Loss: 73462.0152 - Avg Loss: 217.3432\n",
            "Epoch [1/50] - Batch loss: 188.5488 - Epoch Loss: 73650.5639 - Avg Loss: 217.2583\n",
            "Epoch [1/50] - Batch loss: 186.0096 - Epoch Loss: 73836.5736 - Avg Loss: 217.1664\n",
            "Epoch [1/50] - Batch loss: 192.8904 - Epoch Loss: 74029.4640 - Avg Loss: 217.0952\n",
            "Epoch [1/50] - Batch loss: 184.9917 - Epoch Loss: 74214.4557 - Avg Loss: 217.0013\n",
            "Epoch [1/50] - Batch loss: 186.9409 - Epoch Loss: 74401.3966 - Avg Loss: 216.9137\n",
            "Epoch [1/50] - Batch loss: 195.6203 - Epoch Loss: 74597.0170 - Avg Loss: 216.8518\n",
            "Epoch [1/50] - Batch loss: 201.8685 - Epoch Loss: 74798.8855 - Avg Loss: 216.8084\n",
            "Epoch [1/50] - Batch loss: 192.9874 - Epoch Loss: 74991.8729 - Avg Loss: 216.7395\n",
            "Epoch [1/50] - Batch loss: 191.4331 - Epoch Loss: 75183.3060 - Avg Loss: 216.6666\n",
            "Epoch [1/50] - Batch loss: 192.1651 - Epoch Loss: 75375.4712 - Avg Loss: 216.5962\n",
            "Epoch [1/50] - Batch loss: 197.0808 - Epoch Loss: 75572.5520 - Avg Loss: 216.5403\n",
            "Epoch [1/50] - Batch loss: 192.4101 - Epoch Loss: 75764.9621 - Avg Loss: 216.4713\n",
            "Epoch [1/50] - Batch loss: 190.7461 - Epoch Loss: 75955.7082 - Avg Loss: 216.3980\n",
            "Epoch [1/50] - Batch loss: 189.5818 - Epoch Loss: 76145.2900 - Avg Loss: 216.3218\n",
            "Epoch [1/50] - Batch loss: 199.8479 - Epoch Loss: 76345.1379 - Avg Loss: 216.2752\n",
            "Epoch [1/50] - Batch loss: 200.9387 - Epoch Loss: 76546.0766 - Avg Loss: 216.2319\n",
            "Epoch [1/50] - Batch loss: 196.1202 - Epoch Loss: 76742.1968 - Avg Loss: 216.1752\n",
            "Epoch [1/50] - Batch loss: 190.3510 - Epoch Loss: 76932.5478 - Avg Loss: 216.1027\n",
            "Epoch [1/50] - Batch loss: 194.1627 - Epoch Loss: 77126.7105 - Avg Loss: 216.0412\n",
            "Epoch [1/50] - Batch loss: 193.9865 - Epoch Loss: 77320.6970 - Avg Loss: 215.9796\n",
            "Epoch [1/50] - Batch loss: 197.7206 - Epoch Loss: 77518.4176 - Avg Loss: 215.9287\n",
            "Epoch [1/50] - Batch loss: 197.1379 - Epoch Loss: 77715.5555 - Avg Loss: 215.8765\n",
            "Epoch [1/50] - Batch loss: 191.4441 - Epoch Loss: 77906.9996 - Avg Loss: 215.8089\n",
            "Epoch [1/50] - Batch loss: 197.7307 - Epoch Loss: 78104.7303 - Avg Loss: 215.7589\n",
            "Epoch [1/50] - Batch loss: 183.5935 - Epoch Loss: 78288.3238 - Avg Loss: 215.6703\n",
            "Epoch [1/50] - Batch loss: 197.8720 - Epoch Loss: 78486.1958 - Avg Loss: 215.6214\n",
            "Epoch [1/50] - Batch loss: 192.8475 - Epoch Loss: 78679.0434 - Avg Loss: 215.5590\n",
            "Epoch [1/50] - Batch loss: 193.1934 - Epoch Loss: 78872.2368 - Avg Loss: 215.4979\n",
            "Epoch [1/50] - Batch loss: 192.1772 - Epoch Loss: 79064.4140 - Avg Loss: 215.4344\n",
            "Epoch [1/50] - Batch loss: 189.0549 - Epoch Loss: 79253.4689 - Avg Loss: 215.3627\n",
            "Epoch [1/50] - Batch loss: 197.6520 - Epoch Loss: 79451.1210 - Avg Loss: 215.3147\n",
            "Epoch [1/50] - Batch loss: 193.5601 - Epoch Loss: 79644.6811 - Avg Loss: 215.2559\n",
            "Epoch [1/50] - Batch loss: 189.8466 - Epoch Loss: 79834.5277 - Avg Loss: 215.1874\n",
            "Epoch [1/50] - Batch loss: 192.5534 - Epoch Loss: 80027.0811 - Avg Loss: 215.1266\n",
            "Epoch [1/50] - Batch loss: 186.6376 - Epoch Loss: 80213.7187 - Avg Loss: 215.0502\n",
            "Epoch [1/50] - Batch loss: 200.7719 - Epoch Loss: 80414.4906 - Avg Loss: 215.0120\n",
            "Epoch [1/50] - Batch loss: 187.5413 - Epoch Loss: 80602.0319 - Avg Loss: 214.9388\n",
            "Epoch [1/50] - Batch loss: 187.9656 - Epoch Loss: 80789.9975 - Avg Loss: 214.8670\n",
            "Epoch [1/50] - Batch loss: 190.2931 - Epoch Loss: 80980.2906 - Avg Loss: 214.8018\n",
            "Epoch [1/50] - Batch loss: 183.6400 - Epoch Loss: 81163.9306 - Avg Loss: 214.7194\n",
            "Epoch [1/50] - Batch loss: 189.4412 - Epoch Loss: 81353.3719 - Avg Loss: 214.6527\n",
            "Epoch [1/50] - Batch loss: 196.0471 - Epoch Loss: 81549.4190 - Avg Loss: 214.6037\n",
            "Epoch [1/50] - Batch loss: 186.9747 - Epoch Loss: 81736.3937 - Avg Loss: 214.5312\n",
            "Epoch [1/50] - Batch loss: 188.6279 - Epoch Loss: 81925.0215 - Avg Loss: 214.4634\n",
            "Epoch [1/50] - Batch loss: 193.7184 - Epoch Loss: 82118.7400 - Avg Loss: 214.4092\n",
            "Epoch [1/50] - Batch loss: 194.0606 - Epoch Loss: 82312.8005 - Avg Loss: 214.3563\n",
            "Epoch [1/50] - Batch loss: 189.4909 - Epoch Loss: 82502.2914 - Avg Loss: 214.2917\n",
            "Epoch [1/50] - Batch loss: 189.5533 - Epoch Loss: 82691.8447 - Avg Loss: 214.2276\n",
            "Epoch [1/50] - Batch loss: 193.6897 - Epoch Loss: 82885.5344 - Avg Loss: 214.1745\n",
            "Epoch [1/50] - Batch loss: 193.9081 - Epoch Loss: 83079.4425 - Avg Loss: 214.1223\n",
            "Epoch [1/50] - Batch loss: 192.4292 - Epoch Loss: 83271.8718 - Avg Loss: 214.0665\n",
            "Epoch [1/50] - Batch loss: 194.3489 - Epoch Loss: 83466.2206 - Avg Loss: 214.0160\n",
            "Epoch [1/50] - Batch loss: 182.0220 - Epoch Loss: 83648.2426 - Avg Loss: 213.9341\n",
            "Epoch [1/50] - Batch loss: 193.8404 - Epoch Loss: 83842.0830 - Avg Loss: 213.8829\n",
            "Epoch [1/50] - Batch loss: 181.3343 - Epoch Loss: 84023.4173 - Avg Loss: 213.8000\n",
            "Epoch [1/50] - Batch loss: 201.7121 - Epoch Loss: 84225.1293 - Avg Loss: 213.7694\n",
            "Epoch [1/50] - Batch loss: 198.7371 - Epoch Loss: 84423.8664 - Avg Loss: 213.7313\n",
            "Epoch [1/50] - Batch loss: 183.0169 - Epoch Loss: 84606.8834 - Avg Loss: 213.6537\n",
            "Epoch [1/50] - Batch loss: 188.8258 - Epoch Loss: 84795.7091 - Avg Loss: 213.5912\n",
            "Epoch [1/50] - Batch loss: 194.3655 - Epoch Loss: 84990.0746 - Avg Loss: 213.5429\n",
            "Epoch [1/50] - Batch loss: 202.1021 - Epoch Loss: 85192.1767 - Avg Loss: 213.5142\n",
            "Epoch [1/50] - Batch loss: 183.5488 - Epoch Loss: 85375.7254 - Avg Loss: 213.4393\n",
            "Epoch [1/50] - Batch loss: 187.7671 - Epoch Loss: 85563.4926 - Avg Loss: 213.3753\n",
            "Epoch [1/50] - Batch loss: 191.8685 - Epoch Loss: 85755.3611 - Avg Loss: 213.3218\n",
            "Epoch [1/50] - Batch loss: 196.0311 - Epoch Loss: 85951.3922 - Avg Loss: 213.2789\n",
            "Epoch [1/50] - Batch loss: 188.6653 - Epoch Loss: 86140.0575 - Avg Loss: 213.2180\n",
            "Epoch [1/50] - Batch loss: 187.7466 - Epoch Loss: 86327.8041 - Avg Loss: 213.1551\n",
            "Epoch [1/50] - Batch loss: 199.2788 - Epoch Loss: 86527.0829 - Avg Loss: 213.1209\n",
            "Epoch [1/50] - Batch loss: 202.6677 - Epoch Loss: 86729.7507 - Avg Loss: 213.0952\n",
            "Epoch [1/50] - Batch loss: 187.6626 - Epoch Loss: 86917.4132 - Avg Loss: 213.0329\n",
            "Epoch [1/50] - Batch loss: 194.9203 - Epoch Loss: 87112.3335 - Avg Loss: 212.9886\n",
            "Epoch [1/50] - Batch loss: 188.5880 - Epoch Loss: 87300.9216 - Avg Loss: 212.9291\n",
            "Epoch [1/50] - Batch loss: 198.3040 - Epoch Loss: 87499.2256 - Avg Loss: 212.8935\n",
            "Epoch [1/50] - Batch loss: 187.4183 - Epoch Loss: 87686.6438 - Avg Loss: 212.8317\n",
            "Epoch [1/50] - Batch loss: 189.0922 - Epoch Loss: 87875.7361 - Avg Loss: 212.7742\n",
            "Epoch [1/50] - Batch loss: 192.6365 - Epoch Loss: 88068.3726 - Avg Loss: 212.7255\n",
            "Epoch [1/50] - Batch loss: 193.1913 - Epoch Loss: 88261.5639 - Avg Loss: 212.6785\n",
            "Epoch [1/50] - Batch loss: 196.6013 - Epoch Loss: 88458.1652 - Avg Loss: 212.6398\n",
            "Epoch [1/50] - Batch loss: 188.7540 - Epoch Loss: 88646.9193 - Avg Loss: 212.5825\n",
            "Epoch [1/50] - Batch loss: 190.6753 - Epoch Loss: 88837.5946 - Avg Loss: 212.5301\n",
            "Epoch [1/50] - Batch loss: 190.3778 - Epoch Loss: 89027.9724 - Avg Loss: 212.4773\n",
            "Epoch [1/50] - Batch loss: 190.7236 - Epoch Loss: 89218.6960 - Avg Loss: 212.4255\n",
            "Epoch [1/50] - Batch loss: 184.7191 - Epoch Loss: 89403.4151 - Avg Loss: 212.3597\n",
            "Epoch [1/50] - Batch loss: 193.5896 - Epoch Loss: 89597.0047 - Avg Loss: 212.3152\n",
            "Epoch [1/50] - Batch loss: 193.7654 - Epoch Loss: 89790.7701 - Avg Loss: 212.2713\n",
            "Epoch [1/50] - Batch loss: 196.6553 - Epoch Loss: 89987.4254 - Avg Loss: 212.2345\n",
            "Epoch [1/50] - Batch loss: 187.3648 - Epoch Loss: 90174.7902 - Avg Loss: 212.1760\n",
            "Epoch [1/50] - Batch loss: 186.4597 - Epoch Loss: 90361.2499 - Avg Loss: 212.1156\n",
            "Epoch [1/50] - Batch loss: 195.5119 - Epoch Loss: 90556.7618 - Avg Loss: 212.0767\n",
            "Epoch [1/50] - Batch loss: 199.7724 - Epoch Loss: 90756.5341 - Avg Loss: 212.0480\n",
            "Epoch [1/50] - Batch loss: 191.9144 - Epoch Loss: 90948.4485 - Avg Loss: 212.0010\n",
            "Epoch [1/50] - Batch loss: 191.2639 - Epoch Loss: 91139.7124 - Avg Loss: 211.9528\n",
            "Epoch [1/50] - Batch loss: 198.2518 - Epoch Loss: 91337.9642 - Avg Loss: 211.9210\n",
            "Epoch [1/50] - Batch loss: 188.4623 - Epoch Loss: 91526.4265 - Avg Loss: 211.8667\n",
            "Epoch [1/50] - Batch loss: 193.3263 - Epoch Loss: 91719.7527 - Avg Loss: 211.8239\n",
            "Epoch [1/50] - Batch loss: 187.1285 - Epoch Loss: 91906.8812 - Avg Loss: 211.7670\n",
            "Epoch [1/50] - Batch loss: 189.0541 - Epoch Loss: 92095.9353 - Avg Loss: 211.7148\n",
            "Epoch [1/50] - Batch loss: 190.7735 - Epoch Loss: 92286.7088 - Avg Loss: 211.6668\n",
            "Epoch [1/50] - Batch loss: 191.3319 - Epoch Loss: 92478.0407 - Avg Loss: 211.6202\n",
            "Epoch [1/50] - Batch loss: 194.6911 - Epoch Loss: 92672.7318 - Avg Loss: 211.5816\n",
            "Epoch [1/50] - Batch loss: 193.7445 - Epoch Loss: 92866.4763 - Avg Loss: 211.5409\n",
            "Epoch [1/50] - Batch loss: 191.7732 - Epoch Loss: 93058.2496 - Avg Loss: 211.4960\n",
            "Epoch [1/50] - Batch loss: 192.7103 - Epoch Loss: 93250.9599 - Avg Loss: 211.4534\n",
            "Epoch [1/50] - Batch loss: 192.5798 - Epoch Loss: 93443.5397 - Avg Loss: 211.4107\n",
            "Epoch [1/50] - Batch loss: 192.5672 - Epoch Loss: 93636.1069 - Avg Loss: 211.3682\n",
            "Epoch [1/50] - Batch loss: 194.5809 - Epoch Loss: 93830.6878 - Avg Loss: 211.3304\n",
            "Epoch [1/50] - Batch loss: 189.4728 - Epoch Loss: 94020.1606 - Avg Loss: 211.2813\n",
            "Epoch [1/50] - Batch loss: 196.9150 - Epoch Loss: 94217.0756 - Avg Loss: 211.2490\n",
            "Epoch [1/50] - Batch loss: 191.5159 - Epoch Loss: 94408.5915 - Avg Loss: 211.2049\n",
            "Epoch [1/50] - Batch loss: 195.7702 - Epoch Loss: 94604.3618 - Avg Loss: 211.1705\n",
            "Epoch [1/50] - Batch loss: 197.7570 - Epoch Loss: 94802.1187 - Avg Loss: 211.1406\n",
            "Epoch [1/50] - Batch loss: 190.7495 - Epoch Loss: 94992.8683 - Avg Loss: 211.0953\n",
            "Epoch [1/50] - Batch loss: 190.3113 - Epoch Loss: 95183.1796 - Avg Loss: 211.0492\n",
            "Epoch [1/50] - Batch loss: 192.9023 - Epoch Loss: 95376.0818 - Avg Loss: 211.0090\n",
            "Epoch [1/50] - Batch loss: 187.0562 - Epoch Loss: 95563.1380 - Avg Loss: 210.9562\n",
            "Epoch [1/50] - Batch loss: 189.3878 - Epoch Loss: 95752.5259 - Avg Loss: 210.9086\n",
            "Epoch [1/50] - Batch loss: 185.1898 - Epoch Loss: 95937.7157 - Avg Loss: 210.8521\n",
            "Epoch [1/50] - Batch loss: 191.5462 - Epoch Loss: 96129.2619 - Avg Loss: 210.8098\n",
            "Epoch [1/50] - Batch loss: 197.7894 - Epoch Loss: 96327.0513 - Avg Loss: 210.7813\n",
            "Epoch [1/50] - Batch loss: 193.1962 - Epoch Loss: 96520.2474 - Avg Loss: 210.7429\n",
            "Epoch [1/50] - Batch loss: 190.8195 - Epoch Loss: 96711.0669 - Avg Loss: 210.6995\n",
            "Epoch [1/50] - Batch loss: 190.3020 - Epoch Loss: 96901.3690 - Avg Loss: 210.6551\n",
            "Epoch [1/50] - Batch loss: 184.4766 - Epoch Loss: 97085.8456 - Avg Loss: 210.5984\n",
            "Epoch [1/50] - Batch loss: 186.1909 - Epoch Loss: 97272.0364 - Avg Loss: 210.5455\n",
            "Epoch [1/50] - Batch loss: 189.8667 - Epoch Loss: 97461.9031 - Avg Loss: 210.5009\n",
            "Epoch [1/50] - Batch loss: 192.7282 - Epoch Loss: 97654.6313 - Avg Loss: 210.4626\n",
            "Epoch [1/50] - Batch loss: 184.1124 - Epoch Loss: 97838.7438 - Avg Loss: 210.4059\n",
            "Epoch [1/50] - Batch loss: 194.0021 - Epoch Loss: 98032.7459 - Avg Loss: 210.3707\n",
            "Epoch [1/50] - Batch loss: 192.3089 - Epoch Loss: 98225.0547 - Avg Loss: 210.3320\n",
            "Epoch [1/50] - Batch loss: 185.4076 - Epoch Loss: 98410.4623 - Avg Loss: 210.2788\n",
            "Epoch [1/50] - Batch loss: 187.5022 - Epoch Loss: 98597.9645 - Avg Loss: 210.2302\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 2/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "217633b899b6427fa714a0ebcd9e9736"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/50] - Batch loss: 187.9804 - Epoch Loss: 187.9804 - Avg Loss: 187.9804\n",
            "Epoch [2/50] - Batch loss: 191.1511 - Epoch Loss: 379.1315 - Avg Loss: 189.5658\n",
            "Epoch [2/50] - Batch loss: 196.8809 - Epoch Loss: 576.0124 - Avg Loss: 192.0041\n",
            "Epoch [2/50] - Batch loss: 197.4229 - Epoch Loss: 773.4353 - Avg Loss: 193.3588\n",
            "Epoch [2/50] - Batch loss: 193.0402 - Epoch Loss: 966.4755 - Avg Loss: 193.2951\n",
            "Epoch [2/50] - Batch loss: 188.5405 - Epoch Loss: 1155.0160 - Avg Loss: 192.5027\n",
            "Epoch [2/50] - Batch loss: 193.7181 - Epoch Loss: 1348.7341 - Avg Loss: 192.6763\n",
            "Epoch [2/50] - Batch loss: 196.2276 - Epoch Loss: 1544.9617 - Avg Loss: 193.1202\n",
            "Epoch [2/50] - Batch loss: 194.7505 - Epoch Loss: 1739.7122 - Avg Loss: 193.3014\n",
            "Epoch [2/50] - Batch loss: 192.3071 - Epoch Loss: 1932.0194 - Avg Loss: 193.2019\n",
            "Epoch [2/50] - Batch loss: 190.6797 - Epoch Loss: 2122.6991 - Avg Loss: 192.9726\n",
            "Epoch [2/50] - Batch loss: 178.4820 - Epoch Loss: 2301.1810 - Avg Loss: 191.7651\n",
            "Epoch [2/50] - Batch loss: 190.1723 - Epoch Loss: 2491.3533 - Avg Loss: 191.6426\n",
            "Epoch [2/50] - Batch loss: 193.2825 - Epoch Loss: 2684.6358 - Avg Loss: 191.7597\n",
            "Epoch [2/50] - Batch loss: 194.9134 - Epoch Loss: 2879.5492 - Avg Loss: 191.9699\n",
            "Epoch [2/50] - Batch loss: 195.2619 - Epoch Loss: 3074.8111 - Avg Loss: 192.1757\n",
            "Epoch [2/50] - Batch loss: 190.8275 - Epoch Loss: 3265.6386 - Avg Loss: 192.0964\n",
            "Epoch [2/50] - Batch loss: 186.1303 - Epoch Loss: 3451.7689 - Avg Loss: 191.7649\n",
            "Epoch [2/50] - Batch loss: 189.7568 - Epoch Loss: 3641.5257 - Avg Loss: 191.6592\n",
            "Epoch [2/50] - Batch loss: 195.2101 - Epoch Loss: 3836.7357 - Avg Loss: 191.8368\n",
            "Epoch [2/50] - Batch loss: 187.6463 - Epoch Loss: 4024.3820 - Avg Loss: 191.6372\n",
            "Epoch [2/50] - Batch loss: 180.4503 - Epoch Loss: 4204.8323 - Avg Loss: 191.1287\n",
            "Epoch [2/50] - Batch loss: 195.0504 - Epoch Loss: 4399.8827 - Avg Loss: 191.2992\n",
            "Epoch [2/50] - Batch loss: 190.2579 - Epoch Loss: 4590.1407 - Avg Loss: 191.2559\n",
            "Epoch [2/50] - Batch loss: 203.1530 - Epoch Loss: 4793.2937 - Avg Loss: 191.7317\n",
            "Epoch [2/50] - Batch loss: 188.1054 - Epoch Loss: 4981.3991 - Avg Loss: 191.5923\n",
            "Epoch [2/50] - Batch loss: 186.7690 - Epoch Loss: 5168.1680 - Avg Loss: 191.4136\n",
            "Epoch [2/50] - Batch loss: 189.0166 - Epoch Loss: 5357.1847 - Avg Loss: 191.3280\n",
            "Epoch [2/50] - Batch loss: 193.8821 - Epoch Loss: 5551.0668 - Avg Loss: 191.4161\n",
            "Epoch [2/50] - Batch loss: 185.4710 - Epoch Loss: 5736.5378 - Avg Loss: 191.2179\n",
            "Epoch [2/50] - Batch loss: 189.7706 - Epoch Loss: 5926.3084 - Avg Loss: 191.1712\n",
            "Epoch [2/50] - Batch loss: 186.0544 - Epoch Loss: 6112.3627 - Avg Loss: 191.0113\n",
            "Epoch [2/50] - Batch loss: 178.4579 - Epoch Loss: 6290.8206 - Avg Loss: 190.6309\n",
            "Epoch [2/50] - Batch loss: 188.3792 - Epoch Loss: 6479.1999 - Avg Loss: 190.5647\n",
            "Epoch [2/50] - Batch loss: 190.3224 - Epoch Loss: 6669.5223 - Avg Loss: 190.5578\n",
            "Epoch [2/50] - Batch loss: 196.1009 - Epoch Loss: 6865.6232 - Avg Loss: 190.7118\n",
            "Epoch [2/50] - Batch loss: 194.1951 - Epoch Loss: 7059.8182 - Avg Loss: 190.8059\n",
            "Epoch [2/50] - Batch loss: 192.9447 - Epoch Loss: 7252.7629 - Avg Loss: 190.8622\n",
            "Epoch [2/50] - Batch loss: 195.1585 - Epoch Loss: 7447.9214 - Avg Loss: 190.9723\n",
            "Epoch [2/50] - Batch loss: 192.2710 - Epoch Loss: 7640.1924 - Avg Loss: 191.0048\n",
            "Epoch [2/50] - Batch loss: 193.9023 - Epoch Loss: 7834.0947 - Avg Loss: 191.0755\n",
            "Epoch [2/50] - Batch loss: 188.2902 - Epoch Loss: 8022.3848 - Avg Loss: 191.0092\n",
            "Epoch [2/50] - Batch loss: 182.3315 - Epoch Loss: 8204.7164 - Avg Loss: 190.8074\n",
            "Epoch [2/50] - Batch loss: 196.2869 - Epoch Loss: 8401.0033 - Avg Loss: 190.9319\n",
            "Epoch [2/50] - Batch loss: 187.4552 - Epoch Loss: 8588.4585 - Avg Loss: 190.8546\n",
            "Epoch [2/50] - Batch loss: 184.8926 - Epoch Loss: 8773.3511 - Avg Loss: 190.7250\n",
            "Epoch [2/50] - Batch loss: 192.8154 - Epoch Loss: 8966.1666 - Avg Loss: 190.7695\n",
            "Epoch [2/50] - Batch loss: 191.9946 - Epoch Loss: 9158.1611 - Avg Loss: 190.7950\n",
            "Epoch [2/50] - Batch loss: 197.5544 - Epoch Loss: 9355.7155 - Avg Loss: 190.9330\n",
            "Epoch [2/50] - Batch loss: 187.9055 - Epoch Loss: 9543.6210 - Avg Loss: 190.8724\n",
            "Epoch [2/50] - Batch loss: 198.1100 - Epoch Loss: 9741.7310 - Avg Loss: 191.0143\n",
            "Epoch [2/50] - Batch loss: 191.5911 - Epoch Loss: 9933.3222 - Avg Loss: 191.0254\n",
            "Epoch [2/50] - Batch loss: 195.0045 - Epoch Loss: 10128.3267 - Avg Loss: 191.1005\n",
            "Epoch [2/50] - Batch loss: 184.9869 - Epoch Loss: 10313.3135 - Avg Loss: 190.9873\n",
            "Epoch [2/50] - Batch loss: 194.6577 - Epoch Loss: 10507.9713 - Avg Loss: 191.0540\n",
            "Epoch [2/50] - Batch loss: 190.9121 - Epoch Loss: 10698.8834 - Avg Loss: 191.0515\n",
            "Epoch [2/50] - Batch loss: 193.3046 - Epoch Loss: 10892.1880 - Avg Loss: 191.0910\n",
            "Epoch [2/50] - Batch loss: 192.1763 - Epoch Loss: 11084.3644 - Avg Loss: 191.1097\n",
            "Epoch [2/50] - Batch loss: 189.1979 - Epoch Loss: 11273.5622 - Avg Loss: 191.0773\n",
            "Epoch [2/50] - Batch loss: 194.3468 - Epoch Loss: 11467.9090 - Avg Loss: 191.1318\n",
            "Epoch [2/50] - Batch loss: 191.7052 - Epoch Loss: 11659.6142 - Avg Loss: 191.1412\n",
            "Epoch [2/50] - Batch loss: 180.8898 - Epoch Loss: 11840.5041 - Avg Loss: 190.9759\n",
            "Epoch [2/50] - Batch loss: 185.7037 - Epoch Loss: 12026.2077 - Avg Loss: 190.8922\n",
            "Epoch [2/50] - Batch loss: 189.1185 - Epoch Loss: 12215.3262 - Avg Loss: 190.8645\n",
            "Epoch [2/50] - Batch loss: 189.4828 - Epoch Loss: 12404.8090 - Avg Loss: 190.8432\n",
            "Epoch [2/50] - Batch loss: 193.6887 - Epoch Loss: 12598.4977 - Avg Loss: 190.8863\n",
            "Epoch [2/50] - Batch loss: 189.9289 - Epoch Loss: 12788.4265 - Avg Loss: 190.8720\n",
            "Epoch [2/50] - Batch loss: 185.9799 - Epoch Loss: 12974.4065 - Avg Loss: 190.8001\n",
            "Epoch [2/50] - Batch loss: 187.7858 - Epoch Loss: 13162.1923 - Avg Loss: 190.7564\n",
            "Epoch [2/50] - Batch loss: 197.0076 - Epoch Loss: 13359.1999 - Avg Loss: 190.8457\n",
            "Epoch [2/50] - Batch loss: 190.0712 - Epoch Loss: 13549.2711 - Avg Loss: 190.8348\n",
            "Epoch [2/50] - Batch loss: 194.5804 - Epoch Loss: 13743.8514 - Avg Loss: 190.8868\n",
            "Epoch [2/50] - Batch loss: 190.6911 - Epoch Loss: 13934.5425 - Avg Loss: 190.8841\n",
            "Epoch [2/50] - Batch loss: 192.8577 - Epoch Loss: 14127.4002 - Avg Loss: 190.9108\n",
            "Epoch [2/50] - Batch loss: 181.1386 - Epoch Loss: 14308.5388 - Avg Loss: 190.7805\n",
            "Epoch [2/50] - Batch loss: 186.8950 - Epoch Loss: 14495.4338 - Avg Loss: 190.7294\n",
            "Epoch [2/50] - Batch loss: 194.5568 - Epoch Loss: 14689.9906 - Avg Loss: 190.7791\n",
            "Epoch [2/50] - Batch loss: 188.8962 - Epoch Loss: 14878.8868 - Avg Loss: 190.7550\n",
            "Epoch [2/50] - Batch loss: 191.2509 - Epoch Loss: 15070.1377 - Avg Loss: 190.7612\n",
            "Epoch [2/50] - Batch loss: 197.0825 - Epoch Loss: 15267.2202 - Avg Loss: 190.8403\n",
            "Epoch [2/50] - Batch loss: 194.9394 - Epoch Loss: 15462.1596 - Avg Loss: 190.8909\n",
            "Epoch [2/50] - Batch loss: 191.9813 - Epoch Loss: 15654.1408 - Avg Loss: 190.9042\n",
            "Epoch [2/50] - Batch loss: 190.6427 - Epoch Loss: 15844.7836 - Avg Loss: 190.9010\n",
            "Epoch [2/50] - Batch loss: 195.3049 - Epoch Loss: 16040.0885 - Avg Loss: 190.9534\n",
            "Epoch [2/50] - Batch loss: 195.5165 - Epoch Loss: 16235.6050 - Avg Loss: 191.0071\n",
            "Epoch [2/50] - Batch loss: 191.1033 - Epoch Loss: 16426.7083 - Avg Loss: 191.0082\n",
            "Epoch [2/50] - Batch loss: 196.1478 - Epoch Loss: 16622.8561 - Avg Loss: 191.0673\n",
            "Epoch [2/50] - Batch loss: 187.8617 - Epoch Loss: 16810.7177 - Avg Loss: 191.0309\n",
            "Epoch [2/50] - Batch loss: 184.3975 - Epoch Loss: 16995.1152 - Avg Loss: 190.9564\n",
            "Epoch [2/50] - Batch loss: 191.2600 - Epoch Loss: 17186.3752 - Avg Loss: 190.9597\n",
            "Epoch [2/50] - Batch loss: 191.4393 - Epoch Loss: 17377.8145 - Avg Loss: 190.9650\n",
            "Epoch [2/50] - Batch loss: 188.9019 - Epoch Loss: 17566.7165 - Avg Loss: 190.9426\n",
            "Epoch [2/50] - Batch loss: 191.3943 - Epoch Loss: 17758.1108 - Avg Loss: 190.9474\n",
            "Epoch [2/50] - Batch loss: 189.4433 - Epoch Loss: 17947.5541 - Avg Loss: 190.9314\n",
            "Epoch [2/50] - Batch loss: 187.4963 - Epoch Loss: 18135.0504 - Avg Loss: 190.8953\n",
            "Epoch [2/50] - Batch loss: 183.8082 - Epoch Loss: 18318.8586 - Avg Loss: 190.8214\n",
            "Epoch [2/50] - Batch loss: 196.3014 - Epoch Loss: 18515.1599 - Avg Loss: 190.8779\n",
            "Epoch [2/50] - Batch loss: 194.5748 - Epoch Loss: 18709.7348 - Avg Loss: 190.9157\n",
            "Epoch [2/50] - Batch loss: 188.9649 - Epoch Loss: 18898.6996 - Avg Loss: 190.8960\n",
            "Epoch [2/50] - Batch loss: 184.5551 - Epoch Loss: 19083.2547 - Avg Loss: 190.8325\n",
            "Epoch [2/50] - Batch loss: 184.7839 - Epoch Loss: 19268.0387 - Avg Loss: 190.7727\n",
            "Epoch [2/50] - Batch loss: 187.1388 - Epoch Loss: 19455.1774 - Avg Loss: 190.7370\n",
            "Epoch [2/50] - Batch loss: 197.6055 - Epoch Loss: 19652.7830 - Avg Loss: 190.8037\n",
            "Epoch [2/50] - Batch loss: 188.1720 - Epoch Loss: 19840.9550 - Avg Loss: 190.7784\n",
            "Epoch [2/50] - Batch loss: 186.8002 - Epoch Loss: 20027.7552 - Avg Loss: 190.7405\n",
            "Epoch [2/50] - Batch loss: 190.1644 - Epoch Loss: 20217.9196 - Avg Loss: 190.7351\n",
            "Epoch [2/50] - Batch loss: 185.4004 - Epoch Loss: 20403.3200 - Avg Loss: 190.6852\n",
            "Epoch [2/50] - Batch loss: 192.7223 - Epoch Loss: 20596.0423 - Avg Loss: 190.7041\n",
            "Epoch [2/50] - Batch loss: 184.8401 - Epoch Loss: 20780.8824 - Avg Loss: 190.6503\n",
            "Epoch [2/50] - Batch loss: 186.9095 - Epoch Loss: 20967.7919 - Avg Loss: 190.6163\n",
            "Epoch [2/50] - Batch loss: 192.0479 - Epoch Loss: 21159.8399 - Avg Loss: 190.6292\n",
            "Epoch [2/50] - Batch loss: 192.1055 - Epoch Loss: 21351.9454 - Avg Loss: 190.6424\n",
            "Epoch [2/50] - Batch loss: 184.7939 - Epoch Loss: 21536.7393 - Avg Loss: 190.5906\n",
            "Epoch [2/50] - Batch loss: 186.7003 - Epoch Loss: 21723.4395 - Avg Loss: 190.5565\n",
            "Epoch [2/50] - Batch loss: 192.1530 - Epoch Loss: 21915.5925 - Avg Loss: 190.5704\n",
            "Epoch [2/50] - Batch loss: 192.0310 - Epoch Loss: 22107.6235 - Avg Loss: 190.5830\n",
            "Epoch [2/50] - Batch loss: 183.7608 - Epoch Loss: 22291.3844 - Avg Loss: 190.5247\n",
            "Epoch [2/50] - Batch loss: 181.5100 - Epoch Loss: 22472.8944 - Avg Loss: 190.4483\n",
            "Epoch [2/50] - Batch loss: 189.6877 - Epoch Loss: 22662.5820 - Avg Loss: 190.4419\n",
            "Epoch [2/50] - Batch loss: 188.7417 - Epoch Loss: 22851.3237 - Avg Loss: 190.4277\n",
            "Epoch [2/50] - Batch loss: 186.2858 - Epoch Loss: 23037.6096 - Avg Loss: 190.3935\n",
            "Epoch [2/50] - Batch loss: 188.3423 - Epoch Loss: 23225.9519 - Avg Loss: 190.3767\n",
            "Epoch [2/50] - Batch loss: 186.1730 - Epoch Loss: 23412.1248 - Avg Loss: 190.3425\n",
            "Epoch [2/50] - Batch loss: 187.9220 - Epoch Loss: 23600.0468 - Avg Loss: 190.3230\n",
            "Epoch [2/50] - Batch loss: 192.1899 - Epoch Loss: 23792.2367 - Avg Loss: 190.3379\n",
            "Epoch [2/50] - Batch loss: 182.9616 - Epoch Loss: 23975.1983 - Avg Loss: 190.2794\n",
            "Epoch [2/50] - Batch loss: 193.0640 - Epoch Loss: 24168.2624 - Avg Loss: 190.3013\n",
            "Epoch [2/50] - Batch loss: 193.2413 - Epoch Loss: 24361.5036 - Avg Loss: 190.3242\n",
            "Epoch [2/50] - Batch loss: 183.9003 - Epoch Loss: 24545.4039 - Avg Loss: 190.2744\n",
            "Epoch [2/50] - Batch loss: 181.8873 - Epoch Loss: 24727.2913 - Avg Loss: 190.2099\n",
            "Epoch [2/50] - Batch loss: 187.9919 - Epoch Loss: 24915.2832 - Avg Loss: 190.1930\n",
            "Epoch [2/50] - Batch loss: 186.3031 - Epoch Loss: 25101.5862 - Avg Loss: 190.1635\n",
            "Epoch [2/50] - Batch loss: 193.3460 - Epoch Loss: 25294.9322 - Avg Loss: 190.1875\n",
            "Epoch [2/50] - Batch loss: 184.9616 - Epoch Loss: 25479.8938 - Avg Loss: 190.1485\n",
            "Epoch [2/50] - Batch loss: 183.8365 - Epoch Loss: 25663.7303 - Avg Loss: 190.1017\n",
            "Epoch [2/50] - Batch loss: 193.2558 - Epoch Loss: 25856.9862 - Avg Loss: 190.1249\n",
            "Epoch [2/50] - Batch loss: 192.2417 - Epoch Loss: 26049.2279 - Avg Loss: 190.1403\n",
            "Epoch [2/50] - Batch loss: 194.0585 - Epoch Loss: 26243.2864 - Avg Loss: 190.1687\n",
            "Epoch [2/50] - Batch loss: 183.9126 - Epoch Loss: 26427.1990 - Avg Loss: 190.1237\n",
            "Epoch [2/50] - Batch loss: 189.4196 - Epoch Loss: 26616.6186 - Avg Loss: 190.1187\n",
            "Epoch [2/50] - Batch loss: 189.7466 - Epoch Loss: 26806.3652 - Avg Loss: 190.1161\n",
            "Epoch [2/50] - Batch loss: 185.1104 - Epoch Loss: 26991.4756 - Avg Loss: 190.0808\n",
            "Epoch [2/50] - Batch loss: 186.7593 - Epoch Loss: 27178.2349 - Avg Loss: 190.0576\n",
            "Epoch [2/50] - Batch loss: 193.1657 - Epoch Loss: 27371.4006 - Avg Loss: 190.0792\n",
            "Epoch [2/50] - Batch loss: 185.9087 - Epoch Loss: 27557.3093 - Avg Loss: 190.0504\n",
            "Epoch [2/50] - Batch loss: 185.2104 - Epoch Loss: 27742.5197 - Avg Loss: 190.0173\n",
            "Epoch [2/50] - Batch loss: 183.3315 - Epoch Loss: 27925.8512 - Avg Loss: 189.9718\n",
            "Epoch [2/50] - Batch loss: 196.1799 - Epoch Loss: 28122.0311 - Avg Loss: 190.0137\n",
            "Epoch [2/50] - Batch loss: 192.9145 - Epoch Loss: 28314.9455 - Avg Loss: 190.0332\n",
            "Epoch [2/50] - Batch loss: 180.8248 - Epoch Loss: 28495.7703 - Avg Loss: 189.9718\n",
            "Epoch [2/50] - Batch loss: 194.2802 - Epoch Loss: 28690.0505 - Avg Loss: 190.0003\n",
            "Epoch [2/50] - Batch loss: 192.9105 - Epoch Loss: 28882.9610 - Avg Loss: 190.0195\n",
            "Epoch [2/50] - Batch loss: 190.1873 - Epoch Loss: 29073.1483 - Avg Loss: 190.0206\n",
            "Epoch [2/50] - Batch loss: 182.8145 - Epoch Loss: 29255.9628 - Avg Loss: 189.9738\n",
            "Epoch [2/50] - Batch loss: 185.4971 - Epoch Loss: 29441.4600 - Avg Loss: 189.9449\n",
            "Epoch [2/50] - Batch loss: 188.7134 - Epoch Loss: 29630.1734 - Avg Loss: 189.9370\n",
            "Epoch [2/50] - Batch loss: 187.3990 - Epoch Loss: 29817.5724 - Avg Loss: 189.9208\n",
            "Epoch [2/50] - Batch loss: 187.3330 - Epoch Loss: 30004.9054 - Avg Loss: 189.9045\n",
            "Epoch [2/50] - Batch loss: 185.8336 - Epoch Loss: 30190.7390 - Avg Loss: 189.8789\n",
            "Epoch [2/50] - Batch loss: 193.1782 - Epoch Loss: 30383.9172 - Avg Loss: 189.8995\n",
            "Epoch [2/50] - Batch loss: 193.2659 - Epoch Loss: 30577.1831 - Avg Loss: 189.9204\n",
            "Epoch [2/50] - Batch loss: 185.1109 - Epoch Loss: 30762.2939 - Avg Loss: 189.8907\n",
            "Epoch [2/50] - Batch loss: 197.2725 - Epoch Loss: 30959.5664 - Avg Loss: 189.9360\n",
            "Epoch [2/50] - Batch loss: 194.4844 - Epoch Loss: 31154.0508 - Avg Loss: 189.9637\n",
            "Epoch [2/50] - Batch loss: 186.7254 - Epoch Loss: 31340.7762 - Avg Loss: 189.9441\n",
            "Epoch [2/50] - Batch loss: 184.1195 - Epoch Loss: 31524.8957 - Avg Loss: 189.9090\n",
            "Epoch [2/50] - Batch loss: 186.4473 - Epoch Loss: 31711.3430 - Avg Loss: 189.8883\n",
            "Epoch [2/50] - Batch loss: 186.1794 - Epoch Loss: 31897.5224 - Avg Loss: 189.8662\n",
            "Epoch [2/50] - Batch loss: 193.1884 - Epoch Loss: 32090.7108 - Avg Loss: 189.8859\n",
            "Epoch [2/50] - Batch loss: 189.6614 - Epoch Loss: 32280.3722 - Avg Loss: 189.8845\n",
            "Epoch [2/50] - Batch loss: 185.1009 - Epoch Loss: 32465.4731 - Avg Loss: 189.8566\n",
            "Epoch [2/50] - Batch loss: 193.8980 - Epoch Loss: 32659.3710 - Avg Loss: 189.8801\n",
            "Epoch [2/50] - Batch loss: 194.0787 - Epoch Loss: 32853.4497 - Avg Loss: 189.9043\n",
            "Epoch [2/50] - Batch loss: 194.5550 - Epoch Loss: 33048.0047 - Avg Loss: 189.9311\n",
            "Epoch [2/50] - Batch loss: 179.2289 - Epoch Loss: 33227.2336 - Avg Loss: 189.8699\n",
            "Epoch [2/50] - Batch loss: 185.5333 - Epoch Loss: 33412.7669 - Avg Loss: 189.8453\n",
            "Epoch [2/50] - Batch loss: 187.7334 - Epoch Loss: 33600.5003 - Avg Loss: 189.8333\n",
            "Epoch [2/50] - Batch loss: 195.7358 - Epoch Loss: 33796.2361 - Avg Loss: 189.8665\n",
            "Epoch [2/50] - Batch loss: 195.9247 - Epoch Loss: 33992.1608 - Avg Loss: 189.9003\n",
            "Epoch [2/50] - Batch loss: 183.3554 - Epoch Loss: 34175.5163 - Avg Loss: 189.8640\n",
            "Epoch [2/50] - Batch loss: 187.3132 - Epoch Loss: 34362.8295 - Avg Loss: 189.8499\n",
            "Epoch [2/50] - Batch loss: 192.9820 - Epoch Loss: 34555.8115 - Avg Loss: 189.8671\n",
            "Epoch [2/50] - Batch loss: 190.9621 - Epoch Loss: 34746.7736 - Avg Loss: 189.8731\n",
            "Epoch [2/50] - Batch loss: 197.5626 - Epoch Loss: 34944.3362 - Avg Loss: 189.9149\n",
            "Epoch [2/50] - Batch loss: 188.7876 - Epoch Loss: 35133.1239 - Avg Loss: 189.9088\n",
            "Epoch [2/50] - Batch loss: 191.9881 - Epoch Loss: 35325.1119 - Avg Loss: 189.9200\n",
            "Epoch [2/50] - Batch loss: 186.1088 - Epoch Loss: 35511.2207 - Avg Loss: 189.8996\n",
            "Epoch [2/50] - Batch loss: 191.5617 - Epoch Loss: 35702.7824 - Avg Loss: 189.9084\n",
            "Epoch [2/50] - Batch loss: 194.5045 - Epoch Loss: 35897.2869 - Avg Loss: 189.9327\n",
            "Epoch [2/50] - Batch loss: 178.0246 - Epoch Loss: 36075.3115 - Avg Loss: 189.8701\n",
            "Epoch [2/50] - Batch loss: 192.4654 - Epoch Loss: 36267.7769 - Avg Loss: 189.8836\n",
            "Epoch [2/50] - Batch loss: 189.2378 - Epoch Loss: 36457.0147 - Avg Loss: 189.8803\n",
            "Epoch [2/50] - Batch loss: 187.1789 - Epoch Loss: 36644.1936 - Avg Loss: 189.8663\n",
            "Epoch [2/50] - Batch loss: 189.4689 - Epoch Loss: 36833.6625 - Avg Loss: 189.8642\n",
            "Epoch [2/50] - Batch loss: 191.6661 - Epoch Loss: 37025.3286 - Avg Loss: 189.8735\n",
            "Epoch [2/50] - Batch loss: 196.4301 - Epoch Loss: 37221.7587 - Avg Loss: 189.9069\n",
            "Epoch [2/50] - Batch loss: 188.3220 - Epoch Loss: 37410.0807 - Avg Loss: 189.8989\n",
            "Epoch [2/50] - Batch loss: 192.8305 - Epoch Loss: 37602.9112 - Avg Loss: 189.9137\n",
            "Epoch [2/50] - Batch loss: 189.9950 - Epoch Loss: 37792.9062 - Avg Loss: 189.9141\n",
            "Epoch [2/50] - Batch loss: 197.6132 - Epoch Loss: 37990.5194 - Avg Loss: 189.9526\n",
            "Epoch [2/50] - Batch loss: 187.2455 - Epoch Loss: 38177.7649 - Avg Loss: 189.9391\n",
            "Epoch [2/50] - Batch loss: 192.4255 - Epoch Loss: 38370.1904 - Avg Loss: 189.9514\n",
            "Epoch [2/50] - Batch loss: 192.5380 - Epoch Loss: 38562.7284 - Avg Loss: 189.9642\n",
            "Epoch [2/50] - Batch loss: 184.7834 - Epoch Loss: 38747.5118 - Avg Loss: 189.9388\n",
            "Epoch [2/50] - Batch loss: 182.0928 - Epoch Loss: 38929.6046 - Avg Loss: 189.9005\n",
            "Epoch [2/50] - Batch loss: 188.1499 - Epoch Loss: 39117.7546 - Avg Loss: 189.8920\n",
            "Epoch [2/50] - Batch loss: 185.7713 - Epoch Loss: 39303.5258 - Avg Loss: 189.8721\n",
            "Epoch [2/50] - Batch loss: 188.0661 - Epoch Loss: 39491.5919 - Avg Loss: 189.8634\n",
            "Epoch [2/50] - Batch loss: 191.6164 - Epoch Loss: 39683.2084 - Avg Loss: 189.8718\n",
            "Epoch [2/50] - Batch loss: 183.5629 - Epoch Loss: 39866.7713 - Avg Loss: 189.8418\n",
            "Epoch [2/50] - Batch loss: 181.0483 - Epoch Loss: 40047.8196 - Avg Loss: 189.8001\n",
            "Epoch [2/50] - Batch loss: 182.7476 - Epoch Loss: 40230.5672 - Avg Loss: 189.7668\n",
            "Epoch [2/50] - Batch loss: 179.6569 - Epoch Loss: 40410.2241 - Avg Loss: 189.7194\n",
            "Epoch [2/50] - Batch loss: 181.7584 - Epoch Loss: 40591.9825 - Avg Loss: 189.6822\n",
            "Epoch [2/50] - Batch loss: 189.3775 - Epoch Loss: 40781.3600 - Avg Loss: 189.6807\n",
            "Epoch [2/50] - Batch loss: 187.3563 - Epoch Loss: 40968.7162 - Avg Loss: 189.6700\n",
            "Epoch [2/50] - Batch loss: 188.1585 - Epoch Loss: 41156.8748 - Avg Loss: 189.6630\n",
            "Epoch [2/50] - Batch loss: 188.8051 - Epoch Loss: 41345.6799 - Avg Loss: 189.6591\n",
            "Epoch [2/50] - Batch loss: 186.7945 - Epoch Loss: 41532.4744 - Avg Loss: 189.6460\n",
            "Epoch [2/50] - Batch loss: 183.3344 - Epoch Loss: 41715.8088 - Avg Loss: 189.6173\n",
            "Epoch [2/50] - Batch loss: 195.6476 - Epoch Loss: 41911.4564 - Avg Loss: 189.6446\n",
            "Epoch [2/50] - Batch loss: 188.3008 - Epoch Loss: 42099.7572 - Avg Loss: 189.6385\n",
            "Epoch [2/50] - Batch loss: 184.9217 - Epoch Loss: 42284.6789 - Avg Loss: 189.6174\n",
            "Epoch [2/50] - Batch loss: 188.1511 - Epoch Loss: 42472.8299 - Avg Loss: 189.6108\n",
            "Epoch [2/50] - Batch loss: 188.5071 - Epoch Loss: 42661.3370 - Avg Loss: 189.6059\n",
            "Epoch [2/50] - Batch loss: 191.3935 - Epoch Loss: 42852.7305 - Avg Loss: 189.6139\n",
            "Epoch [2/50] - Batch loss: 184.2670 - Epoch Loss: 43036.9975 - Avg Loss: 189.5903\n",
            "Epoch [2/50] - Batch loss: 192.6109 - Epoch Loss: 43229.6084 - Avg Loss: 189.6035\n",
            "Epoch [2/50] - Batch loss: 185.7854 - Epoch Loss: 43415.3938 - Avg Loss: 189.5869\n",
            "Epoch [2/50] - Batch loss: 183.6482 - Epoch Loss: 43599.0420 - Avg Loss: 189.5611\n",
            "Epoch [2/50] - Batch loss: 184.9618 - Epoch Loss: 43784.0038 - Avg Loss: 189.5411\n",
            "Epoch [2/50] - Batch loss: 182.6624 - Epoch Loss: 43966.6662 - Avg Loss: 189.5115\n",
            "Epoch [2/50] - Batch loss: 185.9592 - Epoch Loss: 44152.6254 - Avg Loss: 189.4962\n",
            "Epoch [2/50] - Batch loss: 184.7772 - Epoch Loss: 44337.4026 - Avg Loss: 189.4761\n",
            "Epoch [2/50] - Batch loss: 190.7611 - Epoch Loss: 44528.1637 - Avg Loss: 189.4815\n",
            "Epoch [2/50] - Batch loss: 186.9335 - Epoch Loss: 44715.0972 - Avg Loss: 189.4708\n",
            "Epoch [2/50] - Batch loss: 187.7936 - Epoch Loss: 44902.8908 - Avg Loss: 189.4637\n",
            "Epoch [2/50] - Batch loss: 194.1241 - Epoch Loss: 45097.0149 - Avg Loss: 189.4833\n",
            "Epoch [2/50] - Batch loss: 194.3864 - Epoch Loss: 45291.4013 - Avg Loss: 189.5038\n",
            "Epoch [2/50] - Batch loss: 197.5692 - Epoch Loss: 45488.9705 - Avg Loss: 189.5374\n",
            "Epoch [2/50] - Batch loss: 181.3972 - Epoch Loss: 45670.3678 - Avg Loss: 189.5036\n",
            "Epoch [2/50] - Batch loss: 189.0827 - Epoch Loss: 45859.4505 - Avg Loss: 189.5019\n",
            "Epoch [2/50] - Batch loss: 181.3315 - Epoch Loss: 46040.7820 - Avg Loss: 189.4682\n",
            "Epoch [2/50] - Batch loss: 183.7131 - Epoch Loss: 46224.4950 - Avg Loss: 189.4447\n",
            "Epoch [2/50] - Batch loss: 181.4140 - Epoch Loss: 46405.9091 - Avg Loss: 189.4119\n",
            "Epoch [2/50] - Batch loss: 184.6141 - Epoch Loss: 46590.5231 - Avg Loss: 189.3924\n",
            "Epoch [2/50] - Batch loss: 183.4735 - Epoch Loss: 46773.9967 - Avg Loss: 189.3684\n",
            "Epoch [2/50] - Batch loss: 180.9803 - Epoch Loss: 46954.9770 - Avg Loss: 189.3346\n",
            "Epoch [2/50] - Batch loss: 187.8831 - Epoch Loss: 47142.8600 - Avg Loss: 189.3288\n",
            "Epoch [2/50] - Batch loss: 183.0250 - Epoch Loss: 47325.8850 - Avg Loss: 189.3035\n",
            "Epoch [2/50] - Batch loss: 193.0778 - Epoch Loss: 47518.9628 - Avg Loss: 189.3186\n",
            "Epoch [2/50] - Batch loss: 188.6341 - Epoch Loss: 47707.5970 - Avg Loss: 189.3159\n",
            "Epoch [2/50] - Batch loss: 192.4060 - Epoch Loss: 47900.0029 - Avg Loss: 189.3281\n",
            "Epoch [2/50] - Batch loss: 191.7133 - Epoch Loss: 48091.7163 - Avg Loss: 189.3375\n",
            "Epoch [2/50] - Batch loss: 179.7762 - Epoch Loss: 48271.4925 - Avg Loss: 189.3000\n",
            "Epoch [2/50] - Batch loss: 186.5473 - Epoch Loss: 48458.0398 - Avg Loss: 189.2892\n",
            "Epoch [2/50] - Batch loss: 183.3569 - Epoch Loss: 48641.3967 - Avg Loss: 189.2661\n",
            "Epoch [2/50] - Batch loss: 192.3020 - Epoch Loss: 48833.6987 - Avg Loss: 189.2779\n",
            "Epoch [2/50] - Batch loss: 185.3192 - Epoch Loss: 49019.0179 - Avg Loss: 189.2626\n",
            "Epoch [2/50] - Batch loss: 178.4849 - Epoch Loss: 49197.5028 - Avg Loss: 189.2212\n",
            "Epoch [2/50] - Batch loss: 196.1418 - Epoch Loss: 49393.6445 - Avg Loss: 189.2477\n",
            "Epoch [2/50] - Batch loss: 183.9005 - Epoch Loss: 49577.5450 - Avg Loss: 189.2273\n",
            "Epoch [2/50] - Batch loss: 185.9929 - Epoch Loss: 49763.5380 - Avg Loss: 189.2150\n",
            "Epoch [2/50] - Batch loss: 180.1387 - Epoch Loss: 49943.6767 - Avg Loss: 189.1806\n",
            "Epoch [2/50] - Batch loss: 187.7167 - Epoch Loss: 50131.3934 - Avg Loss: 189.1751\n",
            "Epoch [2/50] - Batch loss: 186.7973 - Epoch Loss: 50318.1907 - Avg Loss: 189.1661\n",
            "Epoch [2/50] - Batch loss: 188.7513 - Epoch Loss: 50506.9420 - Avg Loss: 189.1646\n",
            "Epoch [2/50] - Batch loss: 192.1031 - Epoch Loss: 50699.0452 - Avg Loss: 189.1755\n",
            "Epoch [2/50] - Batch loss: 191.7837 - Epoch Loss: 50890.8289 - Avg Loss: 189.1852\n",
            "Epoch [2/50] - Batch loss: 192.6995 - Epoch Loss: 51083.5284 - Avg Loss: 189.1983\n",
            "Epoch [2/50] - Batch loss: 183.6679 - Epoch Loss: 51267.1963 - Avg Loss: 189.1778\n",
            "Epoch [2/50] - Batch loss: 191.1313 - Epoch Loss: 51458.3276 - Avg Loss: 189.1850\n",
            "Epoch [2/50] - Batch loss: 193.6437 - Epoch Loss: 51651.9713 - Avg Loss: 189.2014\n",
            "Epoch [2/50] - Batch loss: 188.5409 - Epoch Loss: 51840.5122 - Avg Loss: 189.1989\n",
            "Epoch [2/50] - Batch loss: 185.7268 - Epoch Loss: 52026.2390 - Avg Loss: 189.1863\n",
            "Epoch [2/50] - Batch loss: 186.0401 - Epoch Loss: 52212.2792 - Avg Loss: 189.1749\n",
            "Epoch [2/50] - Batch loss: 192.2122 - Epoch Loss: 52404.4913 - Avg Loss: 189.1859\n",
            "Epoch [2/50] - Batch loss: 186.4024 - Epoch Loss: 52590.8937 - Avg Loss: 189.1759\n",
            "Epoch [2/50] - Batch loss: 188.8014 - Epoch Loss: 52779.6951 - Avg Loss: 189.1745\n",
            "Epoch [2/50] - Batch loss: 181.0455 - Epoch Loss: 52960.7407 - Avg Loss: 189.1455\n",
            "Epoch [2/50] - Batch loss: 185.5899 - Epoch Loss: 53146.3305 - Avg Loss: 189.1328\n",
            "Epoch [2/50] - Batch loss: 192.0796 - Epoch Loss: 53338.4101 - Avg Loss: 189.1433\n",
            "Epoch [2/50] - Batch loss: 184.6848 - Epoch Loss: 53523.0949 - Avg Loss: 189.1275\n",
            "Epoch [2/50] - Batch loss: 184.1841 - Epoch Loss: 53707.2790 - Avg Loss: 189.1101\n",
            "Epoch [2/50] - Batch loss: 195.3101 - Epoch Loss: 53902.5891 - Avg Loss: 189.1319\n",
            "Epoch [2/50] - Batch loss: 185.2581 - Epoch Loss: 54087.8472 - Avg Loss: 189.1183\n",
            "Epoch [2/50] - Batch loss: 184.2285 - Epoch Loss: 54272.0757 - Avg Loss: 189.1013\n",
            "Epoch [2/50] - Batch loss: 188.0149 - Epoch Loss: 54460.0906 - Avg Loss: 189.0975\n",
            "Epoch [2/50] - Batch loss: 179.9004 - Epoch Loss: 54639.9910 - Avg Loss: 189.0657\n",
            "Epoch [2/50] - Batch loss: 184.2225 - Epoch Loss: 54824.2135 - Avg Loss: 189.0490\n",
            "Epoch [2/50] - Batch loss: 191.6197 - Epoch Loss: 55015.8332 - Avg Loss: 189.0578\n",
            "Epoch [2/50] - Batch loss: 184.0580 - Epoch Loss: 55199.8912 - Avg Loss: 189.0407\n",
            "Epoch [2/50] - Batch loss: 195.4585 - Epoch Loss: 55395.3497 - Avg Loss: 189.0626\n",
            "Epoch [2/50] - Batch loss: 195.4749 - Epoch Loss: 55590.8246 - Avg Loss: 189.0844\n",
            "Epoch [2/50] - Batch loss: 185.4360 - Epoch Loss: 55776.2606 - Avg Loss: 189.0721\n",
            "Epoch [2/50] - Batch loss: 184.4930 - Epoch Loss: 55960.7536 - Avg Loss: 189.0566\n",
            "Epoch [2/50] - Batch loss: 192.3131 - Epoch Loss: 56153.0667 - Avg Loss: 189.0676\n",
            "Epoch [2/50] - Batch loss: 185.8393 - Epoch Loss: 56338.9059 - Avg Loss: 189.0567\n",
            "Epoch [2/50] - Batch loss: 194.7520 - Epoch Loss: 56533.6579 - Avg Loss: 189.0758\n",
            "Epoch [2/50] - Batch loss: 184.3619 - Epoch Loss: 56718.0198 - Avg Loss: 189.0601\n",
            "Epoch [2/50] - Batch loss: 192.1010 - Epoch Loss: 56910.1208 - Avg Loss: 189.0702\n",
            "Epoch [2/50] - Batch loss: 189.9542 - Epoch Loss: 57100.0751 - Avg Loss: 189.0731\n",
            "Epoch [2/50] - Batch loss: 199.2183 - Epoch Loss: 57299.2934 - Avg Loss: 189.1066\n",
            "Epoch [2/50] - Batch loss: 182.7719 - Epoch Loss: 57482.0652 - Avg Loss: 189.0857\n",
            "Epoch [2/50] - Batch loss: 184.8953 - Epoch Loss: 57666.9605 - Avg Loss: 189.0720\n",
            "Epoch [2/50] - Batch loss: 193.3103 - Epoch Loss: 57860.2709 - Avg Loss: 189.0859\n",
            "Epoch [2/50] - Batch loss: 186.9066 - Epoch Loss: 58047.1775 - Avg Loss: 189.0788\n",
            "Epoch [2/50] - Batch loss: 180.4377 - Epoch Loss: 58227.6151 - Avg Loss: 189.0507\n",
            "Epoch [2/50] - Batch loss: 187.3716 - Epoch Loss: 58414.9867 - Avg Loss: 189.0453\n",
            "Epoch [2/50] - Batch loss: 190.2970 - Epoch Loss: 58605.2836 - Avg Loss: 189.0493\n",
            "Epoch [2/50] - Batch loss: 187.2475 - Epoch Loss: 58792.5311 - Avg Loss: 189.0435\n",
            "Epoch [2/50] - Batch loss: 188.2836 - Epoch Loss: 58980.8148 - Avg Loss: 189.0411\n",
            "Epoch [2/50] - Batch loss: 185.2866 - Epoch Loss: 59166.1013 - Avg Loss: 189.0291\n",
            "Epoch [2/50] - Batch loss: 186.0490 - Epoch Loss: 59352.1503 - Avg Loss: 189.0196\n",
            "Epoch [2/50] - Batch loss: 191.0511 - Epoch Loss: 59543.2014 - Avg Loss: 189.0260\n",
            "Epoch [2/50] - Batch loss: 189.5145 - Epoch Loss: 59732.7159 - Avg Loss: 189.0276\n",
            "Epoch [2/50] - Batch loss: 191.5332 - Epoch Loss: 59924.2490 - Avg Loss: 189.0355\n",
            "Epoch [2/50] - Batch loss: 183.6224 - Epoch Loss: 60107.8715 - Avg Loss: 189.0185\n",
            "Epoch [2/50] - Batch loss: 190.0153 - Epoch Loss: 60297.8867 - Avg Loss: 189.0216\n",
            "Epoch [2/50] - Batch loss: 196.9797 - Epoch Loss: 60494.8665 - Avg Loss: 189.0465\n",
            "Epoch [2/50] - Batch loss: 189.8818 - Epoch Loss: 60684.7483 - Avg Loss: 189.0491\n",
            "Epoch [2/50] - Batch loss: 186.3770 - Epoch Loss: 60871.1252 - Avg Loss: 189.0408\n",
            "Epoch [2/50] - Batch loss: 181.4122 - Epoch Loss: 61052.5375 - Avg Loss: 189.0171\n",
            "Epoch [2/50] - Batch loss: 187.8810 - Epoch Loss: 61240.4185 - Avg Loss: 189.0136\n",
            "Epoch [2/50] - Batch loss: 185.0106 - Epoch Loss: 61425.4291 - Avg Loss: 189.0013\n",
            "Epoch [2/50] - Batch loss: 186.6309 - Epoch Loss: 61612.0600 - Avg Loss: 188.9940\n",
            "Epoch [2/50] - Batch loss: 188.6960 - Epoch Loss: 61800.7560 - Avg Loss: 188.9931\n",
            "Epoch [2/50] - Batch loss: 189.0202 - Epoch Loss: 61989.7761 - Avg Loss: 188.9932\n",
            "Epoch [2/50] - Batch loss: 191.8782 - Epoch Loss: 62181.6543 - Avg Loss: 189.0020\n",
            "Epoch [2/50] - Batch loss: 181.5154 - Epoch Loss: 62363.1697 - Avg Loss: 188.9793\n",
            "Epoch [2/50] - Batch loss: 189.7128 - Epoch Loss: 62552.8825 - Avg Loss: 188.9815\n",
            "Epoch [2/50] - Batch loss: 192.3685 - Epoch Loss: 62745.2510 - Avg Loss: 188.9917\n",
            "Epoch [2/50] - Batch loss: 193.3133 - Epoch Loss: 62938.5643 - Avg Loss: 189.0047\n",
            "Epoch [2/50] - Batch loss: 187.1508 - Epoch Loss: 63125.7151 - Avg Loss: 188.9991\n",
            "Epoch [2/50] - Batch loss: 177.9072 - Epoch Loss: 63303.6223 - Avg Loss: 188.9660\n",
            "Epoch [2/50] - Batch loss: 192.8229 - Epoch Loss: 63496.4452 - Avg Loss: 188.9775\n",
            "Epoch [2/50] - Batch loss: 185.6037 - Epoch Loss: 63682.0489 - Avg Loss: 188.9675\n",
            "Epoch [2/50] - Batch loss: 190.6965 - Epoch Loss: 63872.7454 - Avg Loss: 188.9726\n",
            "Epoch [2/50] - Batch loss: 191.0571 - Epoch Loss: 64063.8024 - Avg Loss: 188.9788\n",
            "Epoch [2/50] - Batch loss: 184.8301 - Epoch Loss: 64248.6325 - Avg Loss: 188.9666\n",
            "Epoch [2/50] - Batch loss: 185.5178 - Epoch Loss: 64434.1503 - Avg Loss: 188.9565\n",
            "Epoch [2/50] - Batch loss: 183.8945 - Epoch Loss: 64618.0448 - Avg Loss: 188.9417\n",
            "Epoch [2/50] - Batch loss: 182.6028 - Epoch Loss: 64800.6476 - Avg Loss: 188.9232\n",
            "Epoch [2/50] - Batch loss: 184.7838 - Epoch Loss: 64985.4314 - Avg Loss: 188.9111\n",
            "Epoch [2/50] - Batch loss: 194.0212 - Epoch Loss: 65179.4526 - Avg Loss: 188.9259\n",
            "Epoch [2/50] - Batch loss: 191.2484 - Epoch Loss: 65370.7010 - Avg Loss: 188.9327\n",
            "Epoch [2/50] - Batch loss: 186.3033 - Epoch Loss: 65557.0044 - Avg Loss: 188.9251\n",
            "Epoch [2/50] - Batch loss: 186.7449 - Epoch Loss: 65743.7493 - Avg Loss: 188.9188\n",
            "Epoch [2/50] - Batch loss: 187.9861 - Epoch Loss: 65931.7354 - Avg Loss: 188.9161\n",
            "Epoch [2/50] - Batch loss: 183.2520 - Epoch Loss: 66114.9874 - Avg Loss: 188.9000\n",
            "Epoch [2/50] - Batch loss: 187.3448 - Epoch Loss: 66302.3322 - Avg Loss: 188.8955\n",
            "Epoch [2/50] - Batch loss: 191.7508 - Epoch Loss: 66494.0830 - Avg Loss: 188.9036\n",
            "Epoch [2/50] - Batch loss: 188.3455 - Epoch Loss: 66682.4285 - Avg Loss: 188.9021\n",
            "Epoch [2/50] - Batch loss: 194.5764 - Epoch Loss: 66877.0049 - Avg Loss: 188.9181\n",
            "Epoch [2/50] - Batch loss: 184.3112 - Epoch Loss: 67061.3161 - Avg Loss: 188.9051\n",
            "Epoch [2/50] - Batch loss: 191.9065 - Epoch Loss: 67253.2226 - Avg Loss: 188.9135\n",
            "Epoch [2/50] - Batch loss: 190.0938 - Epoch Loss: 67443.3164 - Avg Loss: 188.9169\n",
            "Epoch [2/50] - Batch loss: 181.6165 - Epoch Loss: 67624.9328 - Avg Loss: 188.8965\n",
            "Epoch [2/50] - Batch loss: 185.4812 - Epoch Loss: 67810.4140 - Avg Loss: 188.8869\n",
            "Epoch [2/50] - Batch loss: 189.4945 - Epoch Loss: 67999.9086 - Avg Loss: 188.8886\n",
            "Epoch [2/50] - Batch loss: 190.3231 - Epoch Loss: 68190.2317 - Avg Loss: 188.8926\n",
            "Epoch [2/50] - Batch loss: 183.7332 - Epoch Loss: 68373.9649 - Avg Loss: 188.8784\n",
            "Epoch [2/50] - Batch loss: 190.0077 - Epoch Loss: 68563.9726 - Avg Loss: 188.8815\n",
            "Epoch [2/50] - Batch loss: 190.0802 - Epoch Loss: 68754.0528 - Avg Loss: 188.8848\n",
            "Epoch [2/50] - Batch loss: 191.6507 - Epoch Loss: 68945.7036 - Avg Loss: 188.8923\n",
            "Epoch [2/50] - Batch loss: 184.0965 - Epoch Loss: 69129.8001 - Avg Loss: 188.8792\n",
            "Epoch [2/50] - Batch loss: 187.8997 - Epoch Loss: 69317.6998 - Avg Loss: 188.8766\n",
            "Epoch [2/50] - Batch loss: 189.8252 - Epoch Loss: 69507.5250 - Avg Loss: 188.8791\n",
            "Epoch [2/50] - Batch loss: 191.5939 - Epoch Loss: 69699.1189 - Avg Loss: 188.8865\n",
            "Epoch [2/50] - Batch loss: 187.0837 - Epoch Loss: 69886.2026 - Avg Loss: 188.8816\n",
            "Epoch [2/50] - Batch loss: 188.1120 - Epoch Loss: 70074.3146 - Avg Loss: 188.8796\n",
            "Epoch [2/50] - Batch loss: 198.5139 - Epoch Loss: 70272.8284 - Avg Loss: 188.9055\n",
            "Epoch [2/50] - Batch loss: 188.9272 - Epoch Loss: 70461.7556 - Avg Loss: 188.9055\n",
            "Epoch [2/50] - Batch loss: 193.6965 - Epoch Loss: 70655.4521 - Avg Loss: 188.9183\n",
            "Epoch [2/50] - Batch loss: 191.2081 - Epoch Loss: 70846.6602 - Avg Loss: 188.9244\n",
            "Epoch [2/50] - Batch loss: 184.8290 - Epoch Loss: 71031.4893 - Avg Loss: 188.9135\n",
            "Epoch [2/50] - Batch loss: 189.3828 - Epoch Loss: 71220.8720 - Avg Loss: 188.9148\n",
            "Epoch [2/50] - Batch loss: 188.3411 - Epoch Loss: 71409.2132 - Avg Loss: 188.9133\n",
            "Epoch [2/50] - Batch loss: 187.0998 - Epoch Loss: 71596.3129 - Avg Loss: 188.9085\n",
            "Epoch [2/50] - Batch loss: 180.9553 - Epoch Loss: 71777.2682 - Avg Loss: 188.8875\n",
            "Epoch [2/50] - Batch loss: 186.6479 - Epoch Loss: 71963.9162 - Avg Loss: 188.8817\n",
            "Epoch [2/50] - Batch loss: 192.8398 - Epoch Loss: 72156.7560 - Avg Loss: 188.8920\n",
            "Epoch [2/50] - Batch loss: 197.3125 - Epoch Loss: 72354.0685 - Avg Loss: 188.9140\n",
            "Epoch [2/50] - Batch loss: 198.5558 - Epoch Loss: 72552.6243 - Avg Loss: 188.9391\n",
            "Epoch [2/50] - Batch loss: 188.3677 - Epoch Loss: 72740.9921 - Avg Loss: 188.9376\n",
            "Epoch [2/50] - Batch loss: 185.6738 - Epoch Loss: 72926.6658 - Avg Loss: 188.9292\n",
            "Epoch [2/50] - Batch loss: 187.8035 - Epoch Loss: 73114.4693 - Avg Loss: 188.9263\n",
            "Epoch [2/50] - Batch loss: 189.8401 - Epoch Loss: 73304.3094 - Avg Loss: 188.9286\n",
            "Epoch [2/50] - Batch loss: 179.8615 - Epoch Loss: 73484.1709 - Avg Loss: 188.9053\n",
            "Epoch [2/50] - Batch loss: 191.0151 - Epoch Loss: 73675.1860 - Avg Loss: 188.9107\n",
            "Epoch [2/50] - Batch loss: 188.2072 - Epoch Loss: 73863.3932 - Avg Loss: 188.9089\n",
            "Epoch [2/50] - Batch loss: 181.3709 - Epoch Loss: 74044.7641 - Avg Loss: 188.8897\n",
            "Epoch [2/50] - Batch loss: 190.5187 - Epoch Loss: 74235.2829 - Avg Loss: 188.8938\n",
            "Epoch [2/50] - Batch loss: 185.5382 - Epoch Loss: 74420.8211 - Avg Loss: 188.8853\n",
            "Epoch [2/50] - Batch loss: 182.7668 - Epoch Loss: 74603.5879 - Avg Loss: 188.8698\n",
            "Epoch [2/50] - Batch loss: 179.8996 - Epoch Loss: 74783.4875 - Avg Loss: 188.8472\n",
            "Epoch [2/50] - Batch loss: 181.1664 - Epoch Loss: 74964.6539 - Avg Loss: 188.8278\n",
            "Epoch [2/50] - Batch loss: 187.7879 - Epoch Loss: 75152.4418 - Avg Loss: 188.8252\n",
            "Epoch [2/50] - Batch loss: 183.2250 - Epoch Loss: 75335.6668 - Avg Loss: 188.8112\n",
            "Epoch [2/50] - Batch loss: 189.5460 - Epoch Loss: 75525.2128 - Avg Loss: 188.8130\n",
            "Epoch [2/50] - Batch loss: 189.1025 - Epoch Loss: 75714.3152 - Avg Loss: 188.8138\n",
            "Epoch [2/50] - Batch loss: 184.2651 - Epoch Loss: 75898.5804 - Avg Loss: 188.8024\n",
            "Epoch [2/50] - Batch loss: 181.1564 - Epoch Loss: 76079.7367 - Avg Loss: 188.7835\n",
            "Epoch [2/50] - Batch loss: 184.5726 - Epoch Loss: 76264.3093 - Avg Loss: 188.7730\n",
            "Epoch [2/50] - Batch loss: 185.8140 - Epoch Loss: 76450.1233 - Avg Loss: 188.7657\n",
            "Epoch [2/50] - Batch loss: 186.8819 - Epoch Loss: 76637.0053 - Avg Loss: 188.7611\n",
            "Epoch [2/50] - Batch loss: 188.7931 - Epoch Loss: 76825.7983 - Avg Loss: 188.7612\n",
            "Epoch [2/50] - Batch loss: 188.2782 - Epoch Loss: 77014.0765 - Avg Loss: 188.7600\n",
            "Epoch [2/50] - Batch loss: 177.5884 - Epoch Loss: 77191.6649 - Avg Loss: 188.7327\n",
            "Epoch [2/50] - Batch loss: 188.7259 - Epoch Loss: 77380.3908 - Avg Loss: 188.7327\n",
            "Epoch [2/50] - Batch loss: 189.2581 - Epoch Loss: 77569.6489 - Avg Loss: 188.7339\n",
            "Epoch [2/50] - Batch loss: 183.4544 - Epoch Loss: 77753.1033 - Avg Loss: 188.7211\n",
            "Epoch [2/50] - Batch loss: 187.0443 - Epoch Loss: 77940.1476 - Avg Loss: 188.7171\n",
            "Epoch [2/50] - Batch loss: 187.6566 - Epoch Loss: 78127.8042 - Avg Loss: 188.7145\n",
            "Epoch [2/50] - Batch loss: 185.5420 - Epoch Loss: 78313.3463 - Avg Loss: 188.7069\n",
            "Epoch [2/50] - Batch loss: 187.5824 - Epoch Loss: 78500.9286 - Avg Loss: 188.7042\n",
            "Epoch [2/50] - Batch loss: 182.5669 - Epoch Loss: 78683.4955 - Avg Loss: 188.6894\n",
            "Epoch [2/50] - Batch loss: 187.3933 - Epoch Loss: 78870.8888 - Avg Loss: 188.6863\n",
            "Epoch [2/50] - Batch loss: 182.3823 - Epoch Loss: 79053.2711 - Avg Loss: 188.6713\n",
            "Epoch [2/50] - Batch loss: 178.6787 - Epoch Loss: 79231.9498 - Avg Loss: 188.6475\n",
            "Epoch [2/50] - Batch loss: 179.3990 - Epoch Loss: 79411.3488 - Avg Loss: 188.6255\n",
            "Epoch [2/50] - Batch loss: 181.9643 - Epoch Loss: 79593.3131 - Avg Loss: 188.6097\n",
            "Epoch [2/50] - Batch loss: 188.5348 - Epoch Loss: 79781.8479 - Avg Loss: 188.6096\n",
            "Epoch [2/50] - Batch loss: 182.3556 - Epoch Loss: 79964.2035 - Avg Loss: 188.5948\n",
            "Epoch [2/50] - Batch loss: 192.9174 - Epoch Loss: 80157.1208 - Avg Loss: 188.6050\n",
            "Epoch [2/50] - Batch loss: 194.5686 - Epoch Loss: 80351.6895 - Avg Loss: 188.6190\n",
            "Epoch [2/50] - Batch loss: 193.7600 - Epoch Loss: 80545.4495 - Avg Loss: 188.6310\n",
            "Epoch [2/50] - Batch loss: 187.9152 - Epoch Loss: 80733.3647 - Avg Loss: 188.6294\n",
            "Epoch [2/50] - Batch loss: 185.1551 - Epoch Loss: 80918.5199 - Avg Loss: 188.6213\n",
            "Epoch [2/50] - Batch loss: 187.2446 - Epoch Loss: 81105.7644 - Avg Loss: 188.6181\n",
            "Epoch [2/50] - Batch loss: 181.5718 - Epoch Loss: 81287.3362 - Avg Loss: 188.6017\n",
            "Epoch [2/50] - Batch loss: 187.0653 - Epoch Loss: 81474.4015 - Avg Loss: 188.5982\n",
            "Epoch [2/50] - Batch loss: 179.3844 - Epoch Loss: 81653.7858 - Avg Loss: 188.5769\n",
            "Epoch [2/50] - Batch loss: 183.0077 - Epoch Loss: 81836.7935 - Avg Loss: 188.5640\n",
            "Epoch [2/50] - Batch loss: 181.4774 - Epoch Loss: 82018.2709 - Avg Loss: 188.5477\n",
            "Epoch [2/50] - Batch loss: 179.6193 - Epoch Loss: 82197.8902 - Avg Loss: 188.5273\n",
            "Epoch [2/50] - Batch loss: 183.4657 - Epoch Loss: 82381.3558 - Avg Loss: 188.5157\n",
            "Epoch [2/50] - Batch loss: 180.2233 - Epoch Loss: 82561.5791 - Avg Loss: 188.4968\n",
            "Epoch [2/50] - Batch loss: 185.4706 - Epoch Loss: 82747.0497 - Avg Loss: 188.4899\n",
            "Epoch [2/50] - Batch loss: 194.2904 - Epoch Loss: 82941.3401 - Avg Loss: 188.5030\n",
            "Epoch [2/50] - Batch loss: 184.0998 - Epoch Loss: 83125.4398 - Avg Loss: 188.4931\n",
            "Epoch [2/50] - Batch loss: 180.3991 - Epoch Loss: 83305.8390 - Avg Loss: 188.4747\n",
            "Epoch [2/50] - Batch loss: 179.2726 - Epoch Loss: 83485.1115 - Avg Loss: 188.4540\n",
            "Epoch [2/50] - Batch loss: 192.5119 - Epoch Loss: 83677.6234 - Avg Loss: 188.4631\n",
            "Epoch [2/50] - Batch loss: 181.6685 - Epoch Loss: 83859.2918 - Avg Loss: 188.4478\n",
            "Epoch [2/50] - Batch loss: 188.6129 - Epoch Loss: 84047.9047 - Avg Loss: 188.4482\n",
            "Epoch [2/50] - Batch loss: 185.0149 - Epoch Loss: 84232.9196 - Avg Loss: 188.4405\n",
            "Epoch [2/50] - Batch loss: 184.9124 - Epoch Loss: 84417.8320 - Avg Loss: 188.4327\n",
            "Epoch [2/50] - Batch loss: 188.0432 - Epoch Loss: 84605.8751 - Avg Loss: 188.4318\n",
            "Epoch [2/50] - Batch loss: 187.3196 - Epoch Loss: 84793.1947 - Avg Loss: 188.4293\n",
            "Epoch [2/50] - Batch loss: 186.6782 - Epoch Loss: 84979.8729 - Avg Loss: 188.4254\n",
            "Epoch [2/50] - Batch loss: 188.5880 - Epoch Loss: 85168.4609 - Avg Loss: 188.4258\n",
            "Epoch [2/50] - Batch loss: 183.8946 - Epoch Loss: 85352.3555 - Avg Loss: 188.4158\n",
            "Epoch [2/50] - Batch loss: 186.4783 - Epoch Loss: 85538.8339 - Avg Loss: 188.4115\n",
            "Epoch [2/50] - Batch loss: 179.6951 - Epoch Loss: 85718.5289 - Avg Loss: 188.3924\n",
            "Epoch [2/50] - Batch loss: 188.2720 - Epoch Loss: 85906.8009 - Avg Loss: 188.3921\n",
            "Epoch [2/50] - Batch loss: 180.5596 - Epoch Loss: 86087.3605 - Avg Loss: 188.3750\n",
            "Epoch [2/50] - Batch loss: 177.1885 - Epoch Loss: 86264.5490 - Avg Loss: 188.3505\n",
            "Epoch [2/50] - Batch loss: 180.1711 - Epoch Loss: 86444.7201 - Avg Loss: 188.3327\n",
            "Epoch [2/50] - Batch loss: 181.0485 - Epoch Loss: 86625.7686 - Avg Loss: 188.3169\n",
            "Epoch [2/50] - Batch loss: 177.7281 - Epoch Loss: 86803.4967 - Avg Loss: 188.2939\n",
            "Epoch [2/50] - Batch loss: 180.0582 - Epoch Loss: 86983.5549 - Avg Loss: 188.2761\n",
            "Epoch [2/50] - Batch loss: 189.6844 - Epoch Loss: 87173.2393 - Avg Loss: 188.2791\n",
            "Epoch [2/50] - Batch loss: 183.0159 - Epoch Loss: 87356.2552 - Avg Loss: 188.2678\n",
            "Epoch [2/50] - Batch loss: 190.6768 - Epoch Loss: 87546.9320 - Avg Loss: 188.2730\n",
            "Epoch [2/50] - Batch loss: 188.4484 - Epoch Loss: 87735.3804 - Avg Loss: 188.2733\n",
            "Epoch [2/50] - Batch loss: 186.2387 - Epoch Loss: 87921.6191 - Avg Loss: 188.2690\n",
            "Epoch [2/50] - Batch loss: 186.4475 - Epoch Loss: 88108.0666 - Avg Loss: 188.2651\n",
            "Epoch [2/50] - Batch loss: 186.0794 - Epoch Loss: 88294.1460 - Avg Loss: 188.2604\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 3/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8686c09d3834d15b56615003482ba68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/50] - Batch loss: 185.9478 - Epoch Loss: 185.9478 - Avg Loss: 185.9478\n",
            "Epoch [3/50] - Batch loss: 178.1892 - Epoch Loss: 364.1370 - Avg Loss: 182.0685\n",
            "Epoch [3/50] - Batch loss: 189.3567 - Epoch Loss: 553.4937 - Avg Loss: 184.4979\n",
            "Epoch [3/50] - Batch loss: 187.4281 - Epoch Loss: 740.9218 - Avg Loss: 185.2304\n",
            "Epoch [3/50] - Batch loss: 184.3334 - Epoch Loss: 925.2551 - Avg Loss: 185.0510\n",
            "Epoch [3/50] - Batch loss: 188.3480 - Epoch Loss: 1113.6031 - Avg Loss: 185.6005\n",
            "Epoch [3/50] - Batch loss: 180.1484 - Epoch Loss: 1293.7516 - Avg Loss: 184.8217\n",
            "Epoch [3/50] - Batch loss: 182.4317 - Epoch Loss: 1476.1833 - Avg Loss: 184.5229\n",
            "Epoch [3/50] - Batch loss: 183.5853 - Epoch Loss: 1659.7686 - Avg Loss: 184.4187\n",
            "Epoch [3/50] - Batch loss: 187.8445 - Epoch Loss: 1847.6131 - Avg Loss: 184.7613\n",
            "Epoch [3/50] - Batch loss: 179.2379 - Epoch Loss: 2026.8510 - Avg Loss: 184.2592\n",
            "Epoch [3/50] - Batch loss: 180.8427 - Epoch Loss: 2207.6937 - Avg Loss: 183.9745\n",
            "Epoch [3/50] - Batch loss: 180.9830 - Epoch Loss: 2388.6767 - Avg Loss: 183.7444\n",
            "Epoch [3/50] - Batch loss: 187.4985 - Epoch Loss: 2576.1752 - Avg Loss: 184.0125\n",
            "Epoch [3/50] - Batch loss: 185.8134 - Epoch Loss: 2761.9886 - Avg Loss: 184.1326\n",
            "Epoch [3/50] - Batch loss: 191.4206 - Epoch Loss: 2953.4093 - Avg Loss: 184.5881\n",
            "Epoch [3/50] - Batch loss: 189.4633 - Epoch Loss: 3142.8726 - Avg Loss: 184.8749\n",
            "Epoch [3/50] - Batch loss: 189.6645 - Epoch Loss: 3332.5371 - Avg Loss: 185.1409\n",
            "Epoch [3/50] - Batch loss: 184.0508 - Epoch Loss: 3516.5878 - Avg Loss: 185.0836\n",
            "Epoch [3/50] - Batch loss: 186.4165 - Epoch Loss: 3703.0043 - Avg Loss: 185.1502\n",
            "Epoch [3/50] - Batch loss: 187.5647 - Epoch Loss: 3890.5690 - Avg Loss: 185.2652\n",
            "Epoch [3/50] - Batch loss: 183.2688 - Epoch Loss: 4073.8378 - Avg Loss: 185.1744\n",
            "Epoch [3/50] - Batch loss: 185.7238 - Epoch Loss: 4259.5616 - Avg Loss: 185.1983\n",
            "Epoch [3/50] - Batch loss: 187.1419 - Epoch Loss: 4446.7035 - Avg Loss: 185.2793\n",
            "Epoch [3/50] - Batch loss: 185.9399 - Epoch Loss: 4632.6435 - Avg Loss: 185.3057\n",
            "Epoch [3/50] - Batch loss: 184.4852 - Epoch Loss: 4817.1287 - Avg Loss: 185.2742\n",
            "Epoch [3/50] - Batch loss: 184.7296 - Epoch Loss: 5001.8583 - Avg Loss: 185.2540\n",
            "Epoch [3/50] - Batch loss: 173.1961 - Epoch Loss: 5175.0544 - Avg Loss: 184.8234\n",
            "Epoch [3/50] - Batch loss: 190.0135 - Epoch Loss: 5365.0679 - Avg Loss: 185.0023\n",
            "Epoch [3/50] - Batch loss: 185.7370 - Epoch Loss: 5550.8050 - Avg Loss: 185.0268\n",
            "Epoch [3/50] - Batch loss: 185.1401 - Epoch Loss: 5735.9451 - Avg Loss: 185.0305\n",
            "Epoch [3/50] - Batch loss: 180.7416 - Epoch Loss: 5916.6866 - Avg Loss: 184.8965\n",
            "Epoch [3/50] - Batch loss: 178.0542 - Epoch Loss: 6094.7408 - Avg Loss: 184.6891\n",
            "Epoch [3/50] - Batch loss: 184.2508 - Epoch Loss: 6278.9916 - Avg Loss: 184.6762\n",
            "Epoch [3/50] - Batch loss: 182.4287 - Epoch Loss: 6461.4203 - Avg Loss: 184.6120\n",
            "Epoch [3/50] - Batch loss: 192.3206 - Epoch Loss: 6653.7410 - Avg Loss: 184.8261\n",
            "Epoch [3/50] - Batch loss: 182.7033 - Epoch Loss: 6836.4442 - Avg Loss: 184.7688\n",
            "Epoch [3/50] - Batch loss: 189.3472 - Epoch Loss: 7025.7914 - Avg Loss: 184.8892\n",
            "Epoch [3/50] - Batch loss: 187.2105 - Epoch Loss: 7213.0020 - Avg Loss: 184.9488\n",
            "Epoch [3/50] - Batch loss: 178.5878 - Epoch Loss: 7391.5898 - Avg Loss: 184.7897\n",
            "Epoch [3/50] - Batch loss: 187.7553 - Epoch Loss: 7579.3450 - Avg Loss: 184.8621\n",
            "Epoch [3/50] - Batch loss: 180.7815 - Epoch Loss: 7760.1265 - Avg Loss: 184.7649\n",
            "Epoch [3/50] - Batch loss: 177.5032 - Epoch Loss: 7937.6297 - Avg Loss: 184.5960\n",
            "Epoch [3/50] - Batch loss: 188.8099 - Epoch Loss: 8126.4396 - Avg Loss: 184.6918\n",
            "Epoch [3/50] - Batch loss: 182.3344 - Epoch Loss: 8308.7741 - Avg Loss: 184.6394\n",
            "Epoch [3/50] - Batch loss: 184.8514 - Epoch Loss: 8493.6255 - Avg Loss: 184.6440\n",
            "Epoch [3/50] - Batch loss: 181.4619 - Epoch Loss: 8675.0874 - Avg Loss: 184.5763\n",
            "Epoch [3/50] - Batch loss: 185.0410 - Epoch Loss: 8860.1283 - Avg Loss: 184.5860\n",
            "Epoch [3/50] - Batch loss: 176.4769 - Epoch Loss: 9036.6052 - Avg Loss: 184.4205\n",
            "Epoch [3/50] - Batch loss: 174.5160 - Epoch Loss: 9211.1212 - Avg Loss: 184.2224\n",
            "Epoch [3/50] - Batch loss: 186.2480 - Epoch Loss: 9397.3692 - Avg Loss: 184.2621\n",
            "Epoch [3/50] - Batch loss: 186.3887 - Epoch Loss: 9583.7579 - Avg Loss: 184.3030\n",
            "Epoch [3/50] - Batch loss: 183.6589 - Epoch Loss: 9767.4168 - Avg Loss: 184.2909\n",
            "Epoch [3/50] - Batch loss: 187.4479 - Epoch Loss: 9954.8647 - Avg Loss: 184.3493\n",
            "Epoch [3/50] - Batch loss: 178.3775 - Epoch Loss: 10133.2422 - Avg Loss: 184.2408\n",
            "Epoch [3/50] - Batch loss: 178.3777 - Epoch Loss: 10311.6199 - Avg Loss: 184.1361\n",
            "Epoch [3/50] - Batch loss: 184.1643 - Epoch Loss: 10495.7842 - Avg Loss: 184.1366\n",
            "Epoch [3/50] - Batch loss: 181.0487 - Epoch Loss: 10676.8329 - Avg Loss: 184.0833\n",
            "Epoch [3/50] - Batch loss: 174.6979 - Epoch Loss: 10851.5308 - Avg Loss: 183.9243\n",
            "Epoch [3/50] - Batch loss: 179.0538 - Epoch Loss: 11030.5846 - Avg Loss: 183.8431\n",
            "Epoch [3/50] - Batch loss: 193.0682 - Epoch Loss: 11223.6528 - Avg Loss: 183.9943\n",
            "Epoch [3/50] - Batch loss: 184.2989 - Epoch Loss: 11407.9517 - Avg Loss: 183.9992\n",
            "Epoch [3/50] - Batch loss: 184.9750 - Epoch Loss: 11592.9267 - Avg Loss: 184.0147\n",
            "Epoch [3/50] - Batch loss: 186.3737 - Epoch Loss: 11779.3004 - Avg Loss: 184.0516\n",
            "Epoch [3/50] - Batch loss: 183.1805 - Epoch Loss: 11962.4809 - Avg Loss: 184.0382\n",
            "Epoch [3/50] - Batch loss: 190.3363 - Epoch Loss: 12152.8172 - Avg Loss: 184.1336\n",
            "Epoch [3/50] - Batch loss: 181.5815 - Epoch Loss: 12334.3988 - Avg Loss: 184.0955\n",
            "Epoch [3/50] - Batch loss: 182.6999 - Epoch Loss: 12517.0986 - Avg Loss: 184.0750\n",
            "Epoch [3/50] - Batch loss: 181.5010 - Epoch Loss: 12698.5997 - Avg Loss: 184.0377\n",
            "Epoch [3/50] - Batch loss: 190.9536 - Epoch Loss: 12889.5532 - Avg Loss: 184.1365\n",
            "Epoch [3/50] - Batch loss: 183.1271 - Epoch Loss: 13072.6803 - Avg Loss: 184.1223\n",
            "Epoch [3/50] - Batch loss: 187.0968 - Epoch Loss: 13259.7771 - Avg Loss: 184.1636\n",
            "Epoch [3/50] - Batch loss: 184.7409 - Epoch Loss: 13444.5180 - Avg Loss: 184.1715\n",
            "Epoch [3/50] - Batch loss: 185.3452 - Epoch Loss: 13629.8632 - Avg Loss: 184.1873\n",
            "Epoch [3/50] - Batch loss: 187.7206 - Epoch Loss: 13817.5838 - Avg Loss: 184.2345\n",
            "Epoch [3/50] - Batch loss: 180.2688 - Epoch Loss: 13997.8525 - Avg Loss: 184.1823\n",
            "Epoch [3/50] - Batch loss: 182.9826 - Epoch Loss: 14180.8351 - Avg Loss: 184.1667\n",
            "Epoch [3/50] - Batch loss: 182.0469 - Epoch Loss: 14362.8820 - Avg Loss: 184.1395\n",
            "Epoch [3/50] - Batch loss: 181.8478 - Epoch Loss: 14544.7298 - Avg Loss: 184.1105\n",
            "Epoch [3/50] - Batch loss: 179.1193 - Epoch Loss: 14723.8491 - Avg Loss: 184.0481\n",
            "Epoch [3/50] - Batch loss: 190.1214 - Epoch Loss: 14913.9705 - Avg Loss: 184.1231\n",
            "Epoch [3/50] - Batch loss: 181.6139 - Epoch Loss: 15095.5843 - Avg Loss: 184.0925\n",
            "Epoch [3/50] - Batch loss: 187.2974 - Epoch Loss: 15282.8817 - Avg Loss: 184.1311\n",
            "Epoch [3/50] - Batch loss: 190.3072 - Epoch Loss: 15473.1889 - Avg Loss: 184.2046\n",
            "Epoch [3/50] - Batch loss: 185.0089 - Epoch Loss: 15658.1977 - Avg Loss: 184.2141\n",
            "Epoch [3/50] - Batch loss: 181.6792 - Epoch Loss: 15839.8770 - Avg Loss: 184.1846\n",
            "Epoch [3/50] - Batch loss: 187.1987 - Epoch Loss: 16027.0757 - Avg Loss: 184.2193\n",
            "Epoch [3/50] - Batch loss: 185.3788 - Epoch Loss: 16212.4545 - Avg Loss: 184.2324\n",
            "Epoch [3/50] - Batch loss: 184.4385 - Epoch Loss: 16396.8931 - Avg Loss: 184.2348\n",
            "Epoch [3/50] - Batch loss: 190.2729 - Epoch Loss: 16587.1660 - Avg Loss: 184.3018\n",
            "Epoch [3/50] - Batch loss: 183.2711 - Epoch Loss: 16770.4371 - Avg Loss: 184.2905\n",
            "Epoch [3/50] - Batch loss: 182.3117 - Epoch Loss: 16952.7488 - Avg Loss: 184.2690\n",
            "Epoch [3/50] - Batch loss: 181.6176 - Epoch Loss: 17134.3664 - Avg Loss: 184.2405\n",
            "Epoch [3/50] - Batch loss: 185.8028 - Epoch Loss: 17320.1692 - Avg Loss: 184.2571\n",
            "Epoch [3/50] - Batch loss: 179.3510 - Epoch Loss: 17499.5202 - Avg Loss: 184.2055\n",
            "Epoch [3/50] - Batch loss: 183.8024 - Epoch Loss: 17683.3226 - Avg Loss: 184.2013\n",
            "Epoch [3/50] - Batch loss: 187.3241 - Epoch Loss: 17870.6467 - Avg Loss: 184.2335\n",
            "Epoch [3/50] - Batch loss: 180.7509 - Epoch Loss: 18051.3976 - Avg Loss: 184.1979\n",
            "Epoch [3/50] - Batch loss: 182.2464 - Epoch Loss: 18233.6440 - Avg Loss: 184.1782\n",
            "Epoch [3/50] - Batch loss: 188.8714 - Epoch Loss: 18422.5154 - Avg Loss: 184.2252\n",
            "Epoch [3/50] - Batch loss: 183.7933 - Epoch Loss: 18606.3087 - Avg Loss: 184.2209\n",
            "Epoch [3/50] - Batch loss: 183.6312 - Epoch Loss: 18789.9399 - Avg Loss: 184.2151\n",
            "Epoch [3/50] - Batch loss: 178.3413 - Epoch Loss: 18968.2812 - Avg Loss: 184.1581\n",
            "Epoch [3/50] - Batch loss: 173.9121 - Epoch Loss: 19142.1933 - Avg Loss: 184.0596\n",
            "Epoch [3/50] - Batch loss: 182.5211 - Epoch Loss: 19324.7145 - Avg Loss: 184.0449\n",
            "Epoch [3/50] - Batch loss: 178.4435 - Epoch Loss: 19503.1579 - Avg Loss: 183.9921\n",
            "Epoch [3/50] - Batch loss: 178.1115 - Epoch Loss: 19681.2695 - Avg Loss: 183.9371\n",
            "Epoch [3/50] - Batch loss: 178.6436 - Epoch Loss: 19859.9131 - Avg Loss: 183.8881\n",
            "Epoch [3/50] - Batch loss: 180.8785 - Epoch Loss: 20040.7917 - Avg Loss: 183.8605\n",
            "Epoch [3/50] - Batch loss: 179.4406 - Epoch Loss: 20220.2323 - Avg Loss: 183.8203\n",
            "Epoch [3/50] - Batch loss: 185.3507 - Epoch Loss: 20405.5830 - Avg Loss: 183.8341\n",
            "Epoch [3/50] - Batch loss: 184.1984 - Epoch Loss: 20589.7815 - Avg Loss: 183.8373\n",
            "Epoch [3/50] - Batch loss: 181.8257 - Epoch Loss: 20771.6071 - Avg Loss: 183.8195\n",
            "Epoch [3/50] - Batch loss: 185.7319 - Epoch Loss: 20957.3391 - Avg Loss: 183.8363\n",
            "Epoch [3/50] - Batch loss: 186.1845 - Epoch Loss: 21143.5236 - Avg Loss: 183.8567\n",
            "Epoch [3/50] - Batch loss: 184.5442 - Epoch Loss: 21328.0677 - Avg Loss: 183.8627\n",
            "Epoch [3/50] - Batch loss: 182.7448 - Epoch Loss: 21510.8125 - Avg Loss: 183.8531\n",
            "Epoch [3/50] - Batch loss: 184.3237 - Epoch Loss: 21695.1363 - Avg Loss: 183.8571\n",
            "Epoch [3/50] - Batch loss: 189.7245 - Epoch Loss: 21884.8607 - Avg Loss: 183.9064\n",
            "Epoch [3/50] - Batch loss: 180.7147 - Epoch Loss: 22065.5754 - Avg Loss: 183.8798\n",
            "Epoch [3/50] - Batch loss: 184.6303 - Epoch Loss: 22250.2057 - Avg Loss: 183.8860\n",
            "Epoch [3/50] - Batch loss: 178.3892 - Epoch Loss: 22428.5949 - Avg Loss: 183.8409\n",
            "Epoch [3/50] - Batch loss: 184.7566 - Epoch Loss: 22613.3515 - Avg Loss: 183.8484\n",
            "Epoch [3/50] - Batch loss: 173.1212 - Epoch Loss: 22786.4727 - Avg Loss: 183.7619\n",
            "Epoch [3/50] - Batch loss: 173.4642 - Epoch Loss: 22959.9369 - Avg Loss: 183.6795\n",
            "Epoch [3/50] - Batch loss: 169.5458 - Epoch Loss: 23129.4827 - Avg Loss: 183.5673\n",
            "Epoch [3/50] - Batch loss: 186.2614 - Epoch Loss: 23315.7442 - Avg Loss: 183.5885\n",
            "Epoch [3/50] - Batch loss: 183.7595 - Epoch Loss: 23499.5037 - Avg Loss: 183.5899\n",
            "Epoch [3/50] - Batch loss: 181.2855 - Epoch Loss: 23680.7892 - Avg Loss: 183.5720\n",
            "Epoch [3/50] - Batch loss: 181.6432 - Epoch Loss: 23862.4324 - Avg Loss: 183.5572\n",
            "Epoch [3/50] - Batch loss: 184.0417 - Epoch Loss: 24046.4741 - Avg Loss: 183.5609\n",
            "Epoch [3/50] - Batch loss: 178.4878 - Epoch Loss: 24224.9619 - Avg Loss: 183.5224\n",
            "Epoch [3/50] - Batch loss: 185.1722 - Epoch Loss: 24410.1341 - Avg Loss: 183.5348\n",
            "Epoch [3/50] - Batch loss: 185.2414 - Epoch Loss: 24595.3755 - Avg Loss: 183.5476\n",
            "Epoch [3/50] - Batch loss: 179.6543 - Epoch Loss: 24775.0298 - Avg Loss: 183.5187\n",
            "Epoch [3/50] - Batch loss: 184.5210 - Epoch Loss: 24959.5508 - Avg Loss: 183.5261\n",
            "Epoch [3/50] - Batch loss: 185.1809 - Epoch Loss: 25144.7317 - Avg Loss: 183.5382\n",
            "Epoch [3/50] - Batch loss: 174.3541 - Epoch Loss: 25319.0858 - Avg Loss: 183.4716\n",
            "Epoch [3/50] - Batch loss: 182.2042 - Epoch Loss: 25501.2900 - Avg Loss: 183.4625\n",
            "Epoch [3/50] - Batch loss: 190.6299 - Epoch Loss: 25691.9198 - Avg Loss: 183.5137\n",
            "Epoch [3/50] - Batch loss: 174.2180 - Epoch Loss: 25866.1378 - Avg Loss: 183.4478\n",
            "Epoch [3/50] - Batch loss: 177.9388 - Epoch Loss: 26044.0767 - Avg Loss: 183.4090\n",
            "Epoch [3/50] - Batch loss: 183.0659 - Epoch Loss: 26227.1425 - Avg Loss: 183.4066\n",
            "Epoch [3/50] - Batch loss: 180.3884 - Epoch Loss: 26407.5309 - Avg Loss: 183.3856\n",
            "Epoch [3/50] - Batch loss: 179.9396 - Epoch Loss: 26587.4704 - Avg Loss: 183.3619\n",
            "Epoch [3/50] - Batch loss: 177.8336 - Epoch Loss: 26765.3041 - Avg Loss: 183.3240\n",
            "Epoch [3/50] - Batch loss: 180.9000 - Epoch Loss: 26946.2041 - Avg Loss: 183.3075\n",
            "Epoch [3/50] - Batch loss: 187.6408 - Epoch Loss: 27133.8449 - Avg Loss: 183.3368\n",
            "Epoch [3/50] - Batch loss: 179.3582 - Epoch Loss: 27313.2031 - Avg Loss: 183.3101\n",
            "Epoch [3/50] - Batch loss: 181.5219 - Epoch Loss: 27494.7250 - Avg Loss: 183.2982\n",
            "Epoch [3/50] - Batch loss: 188.5723 - Epoch Loss: 27683.2973 - Avg Loss: 183.3331\n",
            "Epoch [3/50] - Batch loss: 193.3481 - Epoch Loss: 27876.6454 - Avg Loss: 183.3990\n",
            "Epoch [3/50] - Batch loss: 179.7981 - Epoch Loss: 28056.4435 - Avg Loss: 183.3754\n",
            "Epoch [3/50] - Batch loss: 183.8177 - Epoch Loss: 28240.2612 - Avg Loss: 183.3783\n",
            "Epoch [3/50] - Batch loss: 182.3881 - Epoch Loss: 28422.6493 - Avg Loss: 183.3719\n",
            "Epoch [3/50] - Batch loss: 181.9022 - Epoch Loss: 28604.5515 - Avg Loss: 183.3625\n",
            "Epoch [3/50] - Batch loss: 184.7623 - Epoch Loss: 28789.3139 - Avg Loss: 183.3714\n",
            "Epoch [3/50] - Batch loss: 177.5160 - Epoch Loss: 28966.8299 - Avg Loss: 183.3344\n",
            "Epoch [3/50] - Batch loss: 179.4311 - Epoch Loss: 29146.2609 - Avg Loss: 183.3098\n",
            "Epoch [3/50] - Batch loss: 184.3440 - Epoch Loss: 29330.6050 - Avg Loss: 183.3163\n",
            "Epoch [3/50] - Batch loss: 179.2471 - Epoch Loss: 29509.8520 - Avg Loss: 183.2910\n",
            "Epoch [3/50] - Batch loss: 186.5915 - Epoch Loss: 29696.4435 - Avg Loss: 183.3114\n",
            "Epoch [3/50] - Batch loss: 184.0082 - Epoch Loss: 29880.4517 - Avg Loss: 183.3157\n",
            "Epoch [3/50] - Batch loss: 186.7447 - Epoch Loss: 30067.1964 - Avg Loss: 183.3366\n",
            "Epoch [3/50] - Batch loss: 180.6212 - Epoch Loss: 30247.8177 - Avg Loss: 183.3201\n",
            "Epoch [3/50] - Batch loss: 189.7201 - Epoch Loss: 30437.5378 - Avg Loss: 183.3587\n",
            "Epoch [3/50] - Batch loss: 177.9290 - Epoch Loss: 30615.4667 - Avg Loss: 183.3261\n",
            "Epoch [3/50] - Batch loss: 174.4439 - Epoch Loss: 30789.9106 - Avg Loss: 183.2733\n",
            "Epoch [3/50] - Batch loss: 195.1958 - Epoch Loss: 30985.1064 - Avg Loss: 183.3438\n",
            "Epoch [3/50] - Batch loss: 183.3560 - Epoch Loss: 31168.4623 - Avg Loss: 183.3439\n",
            "Epoch [3/50] - Batch loss: 193.0000 - Epoch Loss: 31361.4623 - Avg Loss: 183.4004\n",
            "Epoch [3/50] - Batch loss: 182.8661 - Epoch Loss: 31544.3285 - Avg Loss: 183.3973\n",
            "Epoch [3/50] - Batch loss: 178.5534 - Epoch Loss: 31722.8819 - Avg Loss: 183.3693\n",
            "Epoch [3/50] - Batch loss: 183.9449 - Epoch Loss: 31906.8268 - Avg Loss: 183.3726\n",
            "Epoch [3/50] - Batch loss: 182.2129 - Epoch Loss: 32089.0397 - Avg Loss: 183.3659\n",
            "Epoch [3/50] - Batch loss: 179.4903 - Epoch Loss: 32268.5300 - Avg Loss: 183.3439\n",
            "Epoch [3/50] - Batch loss: 186.3036 - Epoch Loss: 32454.8336 - Avg Loss: 183.3606\n",
            "Epoch [3/50] - Batch loss: 181.8316 - Epoch Loss: 32636.6651 - Avg Loss: 183.3521\n",
            "Epoch [3/50] - Batch loss: 185.0342 - Epoch Loss: 32821.6994 - Avg Loss: 183.3614\n",
            "Epoch [3/50] - Batch loss: 178.4916 - Epoch Loss: 33000.1910 - Avg Loss: 183.3344\n",
            "Epoch [3/50] - Batch loss: 174.5364 - Epoch Loss: 33174.7274 - Avg Loss: 183.2858\n",
            "Epoch [3/50] - Batch loss: 181.0620 - Epoch Loss: 33355.7895 - Avg Loss: 183.2736\n",
            "Epoch [3/50] - Batch loss: 188.0247 - Epoch Loss: 33543.8141 - Avg Loss: 183.2995\n",
            "Epoch [3/50] - Batch loss: 186.4966 - Epoch Loss: 33730.3108 - Avg Loss: 183.3169\n",
            "Epoch [3/50] - Batch loss: 182.2531 - Epoch Loss: 33912.5638 - Avg Loss: 183.3112\n",
            "Epoch [3/50] - Batch loss: 174.9181 - Epoch Loss: 34087.4819 - Avg Loss: 183.2660\n",
            "Epoch [3/50] - Batch loss: 183.6071 - Epoch Loss: 34271.0890 - Avg Loss: 183.2679\n",
            "Epoch [3/50] - Batch loss: 178.2402 - Epoch Loss: 34449.3292 - Avg Loss: 183.2411\n",
            "Epoch [3/50] - Batch loss: 184.2833 - Epoch Loss: 34633.6125 - Avg Loss: 183.2466\n",
            "Epoch [3/50] - Batch loss: 186.5539 - Epoch Loss: 34820.1665 - Avg Loss: 183.2640\n",
            "Epoch [3/50] - Batch loss: 181.4886 - Epoch Loss: 35001.6551 - Avg Loss: 183.2547\n",
            "Epoch [3/50] - Batch loss: 177.2937 - Epoch Loss: 35178.9488 - Avg Loss: 183.2237\n",
            "Epoch [3/50] - Batch loss: 185.1283 - Epoch Loss: 35364.0771 - Avg Loss: 183.2336\n",
            "Epoch [3/50] - Batch loss: 179.7137 - Epoch Loss: 35543.7908 - Avg Loss: 183.2154\n",
            "Epoch [3/50] - Batch loss: 183.7782 - Epoch Loss: 35727.5690 - Avg Loss: 183.2183\n",
            "Epoch [3/50] - Batch loss: 183.5690 - Epoch Loss: 35911.1379 - Avg Loss: 183.2201\n",
            "Epoch [3/50] - Batch loss: 193.1444 - Epoch Loss: 36104.2823 - Avg Loss: 183.2705\n",
            "Epoch [3/50] - Batch loss: 180.9038 - Epoch Loss: 36285.1861 - Avg Loss: 183.2585\n",
            "Epoch [3/50] - Batch loss: 187.9021 - Epoch Loss: 36473.0882 - Avg Loss: 183.2819\n",
            "Epoch [3/50] - Batch loss: 185.7664 - Epoch Loss: 36658.8546 - Avg Loss: 183.2943\n",
            "Epoch [3/50] - Batch loss: 176.8297 - Epoch Loss: 36835.6843 - Avg Loss: 183.2621\n",
            "Epoch [3/50] - Batch loss: 185.1795 - Epoch Loss: 37020.8638 - Avg Loss: 183.2716\n",
            "Epoch [3/50] - Batch loss: 178.0027 - Epoch Loss: 37198.8665 - Avg Loss: 183.2456\n",
            "Epoch [3/50] - Batch loss: 181.5723 - Epoch Loss: 37380.4388 - Avg Loss: 183.2374\n",
            "Epoch [3/50] - Batch loss: 175.0120 - Epoch Loss: 37555.4507 - Avg Loss: 183.1973\n",
            "Epoch [3/50] - Batch loss: 183.6240 - Epoch Loss: 37739.0747 - Avg Loss: 183.1994\n",
            "Epoch [3/50] - Batch loss: 181.7008 - Epoch Loss: 37920.7755 - Avg Loss: 183.1922\n",
            "Epoch [3/50] - Batch loss: 186.0777 - Epoch Loss: 38106.8532 - Avg Loss: 183.2060\n",
            "Epoch [3/50] - Batch loss: 185.7930 - Epoch Loss: 38292.6462 - Avg Loss: 183.2184\n",
            "Epoch [3/50] - Batch loss: 178.8488 - Epoch Loss: 38471.4950 - Avg Loss: 183.1976\n",
            "Epoch [3/50] - Batch loss: 173.9783 - Epoch Loss: 38645.4734 - Avg Loss: 183.1539\n",
            "Epoch [3/50] - Batch loss: 178.5361 - Epoch Loss: 38824.0095 - Avg Loss: 183.1321\n",
            "Epoch [3/50] - Batch loss: 183.8284 - Epoch Loss: 39007.8380 - Avg Loss: 183.1354\n",
            "Epoch [3/50] - Batch loss: 186.7753 - Epoch Loss: 39194.6133 - Avg Loss: 183.1524\n",
            "Epoch [3/50] - Batch loss: 182.9390 - Epoch Loss: 39377.5523 - Avg Loss: 183.1514\n",
            "Epoch [3/50] - Batch loss: 175.6491 - Epoch Loss: 39553.2014 - Avg Loss: 183.1167\n",
            "Epoch [3/50] - Batch loss: 181.6900 - Epoch Loss: 39734.8914 - Avg Loss: 183.1101\n",
            "Epoch [3/50] - Batch loss: 182.6659 - Epoch Loss: 39917.5573 - Avg Loss: 183.1081\n",
            "Epoch [3/50] - Batch loss: 184.5300 - Epoch Loss: 40102.0872 - Avg Loss: 183.1146\n",
            "Epoch [3/50] - Batch loss: 177.0264 - Epoch Loss: 40279.1137 - Avg Loss: 183.0869\n",
            "Epoch [3/50] - Batch loss: 181.6136 - Epoch Loss: 40460.7273 - Avg Loss: 183.0802\n",
            "Epoch [3/50] - Batch loss: 181.8041 - Epoch Loss: 40642.5314 - Avg Loss: 183.0745\n",
            "Epoch [3/50] - Batch loss: 178.0959 - Epoch Loss: 40820.6273 - Avg Loss: 183.0521\n",
            "Epoch [3/50] - Batch loss: 178.4447 - Epoch Loss: 40999.0720 - Avg Loss: 183.0316\n",
            "Epoch [3/50] - Batch loss: 182.4841 - Epoch Loss: 41181.5561 - Avg Loss: 183.0291\n",
            "Epoch [3/50] - Batch loss: 184.1866 - Epoch Loss: 41365.7427 - Avg Loss: 183.0343\n",
            "Epoch [3/50] - Batch loss: 177.2410 - Epoch Loss: 41542.9837 - Avg Loss: 183.0087\n",
            "Epoch [3/50] - Batch loss: 183.4601 - Epoch Loss: 41726.4438 - Avg Loss: 183.0107\n",
            "Epoch [3/50] - Batch loss: 178.9806 - Epoch Loss: 41905.4244 - Avg Loss: 182.9931\n",
            "Epoch [3/50] - Batch loss: 184.4434 - Epoch Loss: 42089.8678 - Avg Loss: 182.9994\n",
            "Epoch [3/50] - Batch loss: 188.1096 - Epoch Loss: 42277.9774 - Avg Loss: 183.0215\n",
            "Epoch [3/50] - Batch loss: 183.7504 - Epoch Loss: 42461.7278 - Avg Loss: 183.0247\n",
            "Epoch [3/50] - Batch loss: 189.1267 - Epoch Loss: 42650.8545 - Avg Loss: 183.0509\n",
            "Epoch [3/50] - Batch loss: 179.0801 - Epoch Loss: 42829.9346 - Avg Loss: 183.0339\n",
            "Epoch [3/50] - Batch loss: 176.7364 - Epoch Loss: 43006.6710 - Avg Loss: 183.0071\n",
            "Epoch [3/50] - Batch loss: 179.5042 - Epoch Loss: 43186.1752 - Avg Loss: 182.9923\n",
            "Epoch [3/50] - Batch loss: 178.7685 - Epoch Loss: 43364.9437 - Avg Loss: 182.9744\n",
            "Epoch [3/50] - Batch loss: 182.6936 - Epoch Loss: 43547.6373 - Avg Loss: 182.9733\n",
            "Epoch [3/50] - Batch loss: 181.8839 - Epoch Loss: 43729.5212 - Avg Loss: 182.9687\n",
            "Epoch [3/50] - Batch loss: 181.8076 - Epoch Loss: 43911.3288 - Avg Loss: 182.9639\n",
            "Epoch [3/50] - Batch loss: 179.7734 - Epoch Loss: 44091.1022 - Avg Loss: 182.9506\n",
            "Epoch [3/50] - Batch loss: 175.1475 - Epoch Loss: 44266.2498 - Avg Loss: 182.9184\n",
            "Epoch [3/50] - Batch loss: 179.4662 - Epoch Loss: 44445.7160 - Avg Loss: 182.9042\n",
            "Epoch [3/50] - Batch loss: 172.6876 - Epoch Loss: 44618.4036 - Avg Loss: 182.8623\n",
            "Epoch [3/50] - Batch loss: 189.6117 - Epoch Loss: 44808.0153 - Avg Loss: 182.8899\n",
            "Epoch [3/50] - Batch loss: 174.8613 - Epoch Loss: 44982.8767 - Avg Loss: 182.8572\n",
            "Epoch [3/50] - Batch loss: 175.8087 - Epoch Loss: 45158.6854 - Avg Loss: 182.8287\n",
            "Epoch [3/50] - Batch loss: 182.0697 - Epoch Loss: 45340.7551 - Avg Loss: 182.8256\n",
            "Epoch [3/50] - Batch loss: 183.5506 - Epoch Loss: 45524.3056 - Avg Loss: 182.8285\n",
            "Epoch [3/50] - Batch loss: 180.4175 - Epoch Loss: 45704.7232 - Avg Loss: 182.8189\n",
            "Epoch [3/50] - Batch loss: 183.0972 - Epoch Loss: 45887.8204 - Avg Loss: 182.8200\n",
            "Epoch [3/50] - Batch loss: 182.0410 - Epoch Loss: 46069.8614 - Avg Loss: 182.8169\n",
            "Epoch [3/50] - Batch loss: 178.0653 - Epoch Loss: 46247.9267 - Avg Loss: 182.7981\n",
            "Epoch [3/50] - Batch loss: 181.8831 - Epoch Loss: 46429.8098 - Avg Loss: 182.7945\n",
            "Epoch [3/50] - Batch loss: 184.9787 - Epoch Loss: 46614.7885 - Avg Loss: 182.8031\n",
            "Epoch [3/50] - Batch loss: 173.3961 - Epoch Loss: 46788.1846 - Avg Loss: 182.7663\n",
            "Epoch [3/50] - Batch loss: 190.2202 - Epoch Loss: 46978.4047 - Avg Loss: 182.7953\n",
            "Epoch [3/50] - Batch loss: 181.9284 - Epoch Loss: 47160.3331 - Avg Loss: 182.7920\n",
            "Epoch [3/50] - Batch loss: 178.1380 - Epoch Loss: 47338.4711 - Avg Loss: 182.7740\n",
            "Epoch [3/50] - Batch loss: 187.7616 - Epoch Loss: 47526.2327 - Avg Loss: 182.7932\n",
            "Epoch [3/50] - Batch loss: 181.0363 - Epoch Loss: 47707.2690 - Avg Loss: 182.7865\n",
            "Epoch [3/50] - Batch loss: 178.6536 - Epoch Loss: 47885.9226 - Avg Loss: 182.7707\n",
            "Epoch [3/50] - Batch loss: 172.1030 - Epoch Loss: 48058.0256 - Avg Loss: 182.7301\n",
            "Epoch [3/50] - Batch loss: 177.3368 - Epoch Loss: 48235.3624 - Avg Loss: 182.7097\n",
            "Epoch [3/50] - Batch loss: 176.5670 - Epoch Loss: 48411.9294 - Avg Loss: 182.6865\n",
            "Epoch [3/50] - Batch loss: 182.8175 - Epoch Loss: 48594.7470 - Avg Loss: 182.6870\n",
            "Epoch [3/50] - Batch loss: 185.5192 - Epoch Loss: 48780.2662 - Avg Loss: 182.6976\n",
            "Epoch [3/50] - Batch loss: 179.4779 - Epoch Loss: 48959.7441 - Avg Loss: 182.6856\n",
            "Epoch [3/50] - Batch loss: 177.3716 - Epoch Loss: 49137.1156 - Avg Loss: 182.6659\n",
            "Epoch [3/50] - Batch loss: 181.0532 - Epoch Loss: 49318.1688 - Avg Loss: 182.6599\n",
            "Epoch [3/50] - Batch loss: 181.9086 - Epoch Loss: 49500.0775 - Avg Loss: 182.6571\n",
            "Epoch [3/50] - Batch loss: 181.8626 - Epoch Loss: 49681.9401 - Avg Loss: 182.6542\n",
            "Epoch [3/50] - Batch loss: 185.2630 - Epoch Loss: 49867.2031 - Avg Loss: 182.6637\n",
            "Epoch [3/50] - Batch loss: 178.9762 - Epoch Loss: 50046.1794 - Avg Loss: 182.6503\n",
            "Epoch [3/50] - Batch loss: 183.5377 - Epoch Loss: 50229.7171 - Avg Loss: 182.6535\n",
            "Epoch [3/50] - Batch loss: 179.1119 - Epoch Loss: 50408.8290 - Avg Loss: 182.6407\n",
            "Epoch [3/50] - Batch loss: 176.2343 - Epoch Loss: 50585.0633 - Avg Loss: 182.6176\n",
            "Epoch [3/50] - Batch loss: 172.5458 - Epoch Loss: 50757.6091 - Avg Loss: 182.5813\n",
            "Epoch [3/50] - Batch loss: 181.7231 - Epoch Loss: 50939.3322 - Avg Loss: 182.5783\n",
            "Epoch [3/50] - Batch loss: 180.9430 - Epoch Loss: 51120.2752 - Avg Loss: 182.5724\n",
            "Epoch [3/50] - Batch loss: 184.5970 - Epoch Loss: 51304.8721 - Avg Loss: 182.5796\n",
            "Epoch [3/50] - Batch loss: 181.5637 - Epoch Loss: 51486.4358 - Avg Loss: 182.5760\n",
            "Epoch [3/50] - Batch loss: 179.5201 - Epoch Loss: 51665.9559 - Avg Loss: 182.5652\n",
            "Epoch [3/50] - Batch loss: 191.4729 - Epoch Loss: 51857.4288 - Avg Loss: 182.5966\n",
            "Epoch [3/50] - Batch loss: 181.3795 - Epoch Loss: 52038.8083 - Avg Loss: 182.5923\n",
            "Epoch [3/50] - Batch loss: 184.6118 - Epoch Loss: 52223.4201 - Avg Loss: 182.5994\n",
            "Epoch [3/50] - Batch loss: 179.4246 - Epoch Loss: 52402.8448 - Avg Loss: 182.5883\n",
            "Epoch [3/50] - Batch loss: 177.8498 - Epoch Loss: 52580.6946 - Avg Loss: 182.5719\n",
            "Epoch [3/50] - Batch loss: 189.3864 - Epoch Loss: 52770.0810 - Avg Loss: 182.5954\n",
            "Epoch [3/50] - Batch loss: 187.5140 - Epoch Loss: 52957.5950 - Avg Loss: 182.6124\n",
            "Epoch [3/50] - Batch loss: 181.0834 - Epoch Loss: 53138.6785 - Avg Loss: 182.6071\n",
            "Epoch [3/50] - Batch loss: 178.3730 - Epoch Loss: 53317.0515 - Avg Loss: 182.5926\n",
            "Epoch [3/50] - Batch loss: 173.4861 - Epoch Loss: 53490.5376 - Avg Loss: 182.5616\n",
            "Epoch [3/50] - Batch loss: 179.9507 - Epoch Loss: 53670.4883 - Avg Loss: 182.5527\n",
            "Epoch [3/50] - Batch loss: 189.2069 - Epoch Loss: 53859.6952 - Avg Loss: 182.5752\n",
            "Epoch [3/50] - Batch loss: 178.6398 - Epoch Loss: 54038.3350 - Avg Loss: 182.5619\n",
            "Epoch [3/50] - Batch loss: 180.0094 - Epoch Loss: 54218.3444 - Avg Loss: 182.5533\n",
            "Epoch [3/50] - Batch loss: 183.3655 - Epoch Loss: 54401.7099 - Avg Loss: 182.5561\n",
            "Epoch [3/50] - Batch loss: 185.9623 - Epoch Loss: 54587.6722 - Avg Loss: 182.5675\n",
            "Epoch [3/50] - Batch loss: 185.6591 - Epoch Loss: 54773.3312 - Avg Loss: 182.5778\n",
            "Epoch [3/50] - Batch loss: 191.2741 - Epoch Loss: 54964.6053 - Avg Loss: 182.6067\n",
            "Epoch [3/50] - Batch loss: 185.3540 - Epoch Loss: 55149.9594 - Avg Loss: 182.6158\n",
            "Epoch [3/50] - Batch loss: 175.1865 - Epoch Loss: 55325.1459 - Avg Loss: 182.5912\n",
            "Epoch [3/50] - Batch loss: 188.4963 - Epoch Loss: 55513.6422 - Avg Loss: 182.6107\n",
            "Epoch [3/50] - Batch loss: 173.0638 - Epoch Loss: 55686.7060 - Avg Loss: 182.5794\n",
            "Epoch [3/50] - Batch loss: 180.0371 - Epoch Loss: 55866.7431 - Avg Loss: 182.5711\n",
            "Epoch [3/50] - Batch loss: 182.9084 - Epoch Loss: 56049.6515 - Avg Loss: 182.5722\n",
            "Epoch [3/50] - Batch loss: 178.6171 - Epoch Loss: 56228.2685 - Avg Loss: 182.5593\n",
            "Epoch [3/50] - Batch loss: 177.1002 - Epoch Loss: 56405.3687 - Avg Loss: 182.5416\n",
            "Epoch [3/50] - Batch loss: 170.2246 - Epoch Loss: 56575.5933 - Avg Loss: 182.5019\n",
            "Epoch [3/50] - Batch loss: 176.0705 - Epoch Loss: 56751.6638 - Avg Loss: 182.4812\n",
            "Epoch [3/50] - Batch loss: 179.5244 - Epoch Loss: 56931.1883 - Avg Loss: 182.4718\n",
            "Epoch [3/50] - Batch loss: 180.8844 - Epoch Loss: 57112.0726 - Avg Loss: 182.4667\n",
            "Epoch [3/50] - Batch loss: 181.7056 - Epoch Loss: 57293.7782 - Avg Loss: 182.4643\n",
            "Epoch [3/50] - Batch loss: 191.2906 - Epoch Loss: 57485.0688 - Avg Loss: 182.4923\n",
            "Epoch [3/50] - Batch loss: 180.3712 - Epoch Loss: 57665.4401 - Avg Loss: 182.4856\n",
            "Epoch [3/50] - Batch loss: 174.2263 - Epoch Loss: 57839.6664 - Avg Loss: 182.4595\n",
            "Epoch [3/50] - Batch loss: 183.6534 - Epoch Loss: 58023.3198 - Avg Loss: 182.4633\n",
            "Epoch [3/50] - Batch loss: 188.1130 - Epoch Loss: 58211.4328 - Avg Loss: 182.4810\n",
            "Epoch [3/50] - Batch loss: 182.5086 - Epoch Loss: 58393.9415 - Avg Loss: 182.4811\n",
            "Epoch [3/50] - Batch loss: 178.7318 - Epoch Loss: 58572.6733 - Avg Loss: 182.4694\n",
            "Epoch [3/50] - Batch loss: 183.9269 - Epoch Loss: 58756.6002 - Avg Loss: 182.4739\n",
            "Epoch [3/50] - Batch loss: 177.7920 - Epoch Loss: 58934.3922 - Avg Loss: 182.4594\n",
            "Epoch [3/50] - Batch loss: 173.4413 - Epoch Loss: 59107.8335 - Avg Loss: 182.4316\n",
            "Epoch [3/50] - Batch loss: 181.0466 - Epoch Loss: 59288.8802 - Avg Loss: 182.4273\n",
            "Epoch [3/50] - Batch loss: 176.9199 - Epoch Loss: 59465.8000 - Avg Loss: 182.4104\n",
            "Epoch [3/50] - Batch loss: 164.6107 - Epoch Loss: 59630.4108 - Avg Loss: 182.3560\n",
            "Epoch [3/50] - Batch loss: 181.4062 - Epoch Loss: 59811.8169 - Avg Loss: 182.3531\n",
            "Epoch [3/50] - Batch loss: 172.3631 - Epoch Loss: 59984.1801 - Avg Loss: 182.3227\n",
            "Epoch [3/50] - Batch loss: 176.8872 - Epoch Loss: 60161.0673 - Avg Loss: 182.3063\n",
            "Epoch [3/50] - Batch loss: 183.6199 - Epoch Loss: 60344.6871 - Avg Loss: 182.3102\n",
            "Epoch [3/50] - Batch loss: 178.6784 - Epoch Loss: 60523.3656 - Avg Loss: 182.2993\n",
            "Epoch [3/50] - Batch loss: 180.5336 - Epoch Loss: 60703.8992 - Avg Loss: 182.2940\n",
            "Epoch [3/50] - Batch loss: 176.8371 - Epoch Loss: 60880.7362 - Avg Loss: 182.2777\n",
            "Epoch [3/50] - Batch loss: 174.5455 - Epoch Loss: 61055.2818 - Avg Loss: 182.2546\n",
            "Epoch [3/50] - Batch loss: 176.5901 - Epoch Loss: 61231.8719 - Avg Loss: 182.2377\n",
            "Epoch [3/50] - Batch loss: 172.8754 - Epoch Loss: 61404.7473 - Avg Loss: 182.2099\n",
            "Epoch [3/50] - Batch loss: 169.2890 - Epoch Loss: 61574.0363 - Avg Loss: 182.1717\n",
            "Epoch [3/50] - Batch loss: 180.8498 - Epoch Loss: 61754.8861 - Avg Loss: 182.1678\n",
            "Epoch [3/50] - Batch loss: 183.7480 - Epoch Loss: 61938.6342 - Avg Loss: 182.1725\n",
            "Epoch [3/50] - Batch loss: 178.0105 - Epoch Loss: 62116.6447 - Avg Loss: 182.1602\n",
            "Epoch [3/50] - Batch loss: 178.7540 - Epoch Loss: 62295.3988 - Avg Loss: 182.1503\n",
            "Epoch [3/50] - Batch loss: 184.9519 - Epoch Loss: 62480.3506 - Avg Loss: 182.1585\n",
            "Epoch [3/50] - Batch loss: 174.1215 - Epoch Loss: 62654.4721 - Avg Loss: 182.1351\n",
            "Epoch [3/50] - Batch loss: 179.1033 - Epoch Loss: 62833.5754 - Avg Loss: 182.1263\n",
            "Epoch [3/50] - Batch loss: 178.6928 - Epoch Loss: 63012.2682 - Avg Loss: 182.1164\n",
            "Epoch [3/50] - Batch loss: 179.9111 - Epoch Loss: 63192.1793 - Avg Loss: 182.1100\n",
            "Epoch [3/50] - Batch loss: 170.2502 - Epoch Loss: 63362.4294 - Avg Loss: 182.0759\n",
            "Epoch [3/50] - Batch loss: 178.1210 - Epoch Loss: 63540.5504 - Avg Loss: 182.0646\n",
            "Epoch [3/50] - Batch loss: 183.9804 - Epoch Loss: 63724.5308 - Avg Loss: 182.0701\n",
            "Epoch [3/50] - Batch loss: 182.1598 - Epoch Loss: 63906.6906 - Avg Loss: 182.0703\n",
            "Epoch [3/50] - Batch loss: 184.3667 - Epoch Loss: 64091.0573 - Avg Loss: 182.0769\n",
            "Epoch [3/50] - Batch loss: 179.2657 - Epoch Loss: 64270.3230 - Avg Loss: 182.0689\n",
            "Epoch [3/50] - Batch loss: 179.7004 - Epoch Loss: 64450.0234 - Avg Loss: 182.0622\n",
            "Epoch [3/50] - Batch loss: 175.0090 - Epoch Loss: 64625.0324 - Avg Loss: 182.0423\n",
            "Epoch [3/50] - Batch loss: 184.0208 - Epoch Loss: 64809.0532 - Avg Loss: 182.0479\n",
            "Epoch [3/50] - Batch loss: 182.0697 - Epoch Loss: 64991.1229 - Avg Loss: 182.0480\n",
            "Epoch [3/50] - Batch loss: 176.7445 - Epoch Loss: 65167.8674 - Avg Loss: 182.0331\n",
            "Epoch [3/50] - Batch loss: 179.1423 - Epoch Loss: 65347.0096 - Avg Loss: 182.0251\n",
            "Epoch [3/50] - Batch loss: 186.6090 - Epoch Loss: 65533.6186 - Avg Loss: 182.0378\n",
            "Epoch [3/50] - Batch loss: 182.5199 - Epoch Loss: 65716.1385 - Avg Loss: 182.0392\n",
            "Epoch [3/50] - Batch loss: 181.3927 - Epoch Loss: 65897.5312 - Avg Loss: 182.0374\n",
            "Epoch [3/50] - Batch loss: 177.9497 - Epoch Loss: 66075.4809 - Avg Loss: 182.0261\n",
            "Epoch [3/50] - Batch loss: 173.5019 - Epoch Loss: 66248.9828 - Avg Loss: 182.0027\n",
            "Epoch [3/50] - Batch loss: 176.6857 - Epoch Loss: 66425.6686 - Avg Loss: 181.9881\n",
            "Epoch [3/50] - Batch loss: 181.5412 - Epoch Loss: 66607.2097 - Avg Loss: 181.9869\n",
            "Epoch [3/50] - Batch loss: 175.2598 - Epoch Loss: 66782.4696 - Avg Loss: 181.9686\n",
            "Epoch [3/50] - Batch loss: 181.4327 - Epoch Loss: 66963.9023 - Avg Loss: 181.9671\n",
            "Epoch [3/50] - Batch loss: 175.9934 - Epoch Loss: 67139.8958 - Avg Loss: 181.9509\n",
            "Epoch [3/50] - Batch loss: 176.1961 - Epoch Loss: 67316.0919 - Avg Loss: 181.9354\n",
            "Epoch [3/50] - Batch loss: 177.5303 - Epoch Loss: 67493.6222 - Avg Loss: 181.9235\n",
            "Epoch [3/50] - Batch loss: 178.1333 - Epoch Loss: 67671.7554 - Avg Loss: 181.9133\n",
            "Epoch [3/50] - Batch loss: 179.0830 - Epoch Loss: 67850.8384 - Avg Loss: 181.9057\n",
            "Epoch [3/50] - Batch loss: 190.3917 - Epoch Loss: 68041.2301 - Avg Loss: 181.9284\n",
            "Epoch [3/50] - Batch loss: 178.8460 - Epoch Loss: 68220.0761 - Avg Loss: 181.9202\n",
            "Epoch [3/50] - Batch loss: 175.9545 - Epoch Loss: 68396.0306 - Avg Loss: 181.9043\n",
            "Epoch [3/50] - Batch loss: 177.3611 - Epoch Loss: 68573.3917 - Avg Loss: 181.8923\n",
            "Epoch [3/50] - Batch loss: 171.6209 - Epoch Loss: 68745.0126 - Avg Loss: 181.8651\n",
            "Epoch [3/50] - Batch loss: 177.6707 - Epoch Loss: 68922.6834 - Avg Loss: 181.8540\n",
            "Epoch [3/50] - Batch loss: 176.2927 - Epoch Loss: 69098.9761 - Avg Loss: 181.8394\n",
            "Epoch [3/50] - Batch loss: 183.2268 - Epoch Loss: 69282.2029 - Avg Loss: 181.8431\n",
            "Epoch [3/50] - Batch loss: 180.6980 - Epoch Loss: 69462.9010 - Avg Loss: 181.8401\n",
            "Epoch [3/50] - Batch loss: 180.4470 - Epoch Loss: 69643.3480 - Avg Loss: 181.8364\n",
            "Epoch [3/50] - Batch loss: 176.6502 - Epoch Loss: 69819.9982 - Avg Loss: 181.8229\n",
            "Epoch [3/50] - Batch loss: 166.9302 - Epoch Loss: 69986.9283 - Avg Loss: 181.7842\n",
            "Epoch [3/50] - Batch loss: 172.9731 - Epoch Loss: 70159.9014 - Avg Loss: 181.7614\n",
            "Epoch [3/50] - Batch loss: 186.5039 - Epoch Loss: 70346.4053 - Avg Loss: 181.7737\n",
            "Epoch [3/50] - Batch loss: 167.2159 - Epoch Loss: 70513.6212 - Avg Loss: 181.7361\n",
            "Epoch [3/50] - Batch loss: 174.3650 - Epoch Loss: 70687.9862 - Avg Loss: 181.7172\n",
            "Epoch [3/50] - Batch loss: 174.2751 - Epoch Loss: 70862.2613 - Avg Loss: 181.6981\n",
            "Epoch [3/50] - Batch loss: 173.6843 - Epoch Loss: 71035.9456 - Avg Loss: 181.6776\n",
            "Epoch [3/50] - Batch loss: 179.8046 - Epoch Loss: 71215.7502 - Avg Loss: 181.6728\n",
            "Epoch [3/50] - Batch loss: 179.6070 - Epoch Loss: 71395.3572 - Avg Loss: 181.6676\n",
            "Epoch [3/50] - Batch loss: 178.1800 - Epoch Loss: 71573.5372 - Avg Loss: 181.6587\n",
            "Epoch [3/50] - Batch loss: 178.8617 - Epoch Loss: 71752.3988 - Avg Loss: 181.6516\n",
            "Epoch [3/50] - Batch loss: 164.2140 - Epoch Loss: 71916.6128 - Avg Loss: 181.6076\n",
            "Epoch [3/50] - Batch loss: 170.5391 - Epoch Loss: 72087.1519 - Avg Loss: 181.5797\n",
            "Epoch [3/50] - Batch loss: 175.8262 - Epoch Loss: 72262.9782 - Avg Loss: 181.5653\n",
            "Epoch [3/50] - Batch loss: 182.5192 - Epoch Loss: 72445.4973 - Avg Loss: 181.5677\n",
            "Epoch [3/50] - Batch loss: 177.0574 - Epoch Loss: 72622.5547 - Avg Loss: 181.5564\n",
            "Epoch [3/50] - Batch loss: 176.2664 - Epoch Loss: 72798.8211 - Avg Loss: 181.5432\n",
            "Epoch [3/50] - Batch loss: 180.7238 - Epoch Loss: 72979.5449 - Avg Loss: 181.5412\n",
            "Epoch [3/50] - Batch loss: 181.8778 - Epoch Loss: 73161.4227 - Avg Loss: 181.5420\n",
            "Epoch [3/50] - Batch loss: 177.1010 - Epoch Loss: 73338.5237 - Avg Loss: 181.5310\n",
            "Epoch [3/50] - Batch loss: 182.0412 - Epoch Loss: 73520.5649 - Avg Loss: 181.5323\n",
            "Epoch [3/50] - Batch loss: 175.2290 - Epoch Loss: 73695.7939 - Avg Loss: 181.5167\n",
            "Epoch [3/50] - Batch loss: 180.7241 - Epoch Loss: 73876.5180 - Avg Loss: 181.5148\n",
            "Epoch [3/50] - Batch loss: 179.8677 - Epoch Loss: 74056.3857 - Avg Loss: 181.5107\n",
            "Epoch [3/50] - Batch loss: 179.5390 - Epoch Loss: 74235.9247 - Avg Loss: 181.5059\n",
            "Epoch [3/50] - Batch loss: 170.7212 - Epoch Loss: 74406.6458 - Avg Loss: 181.4796\n",
            "Epoch [3/50] - Batch loss: 178.6429 - Epoch Loss: 74585.2888 - Avg Loss: 181.4727\n",
            "Epoch [3/50] - Batch loss: 171.9120 - Epoch Loss: 74757.2008 - Avg Loss: 181.4495\n",
            "Epoch [3/50] - Batch loss: 175.9676 - Epoch Loss: 74933.1684 - Avg Loss: 181.4362\n",
            "Epoch [3/50] - Batch loss: 178.5625 - Epoch Loss: 75111.7309 - Avg Loss: 181.4293\n",
            "Epoch [3/50] - Batch loss: 180.1557 - Epoch Loss: 75291.8865 - Avg Loss: 181.4262\n",
            "Epoch [3/50] - Batch loss: 182.7756 - Epoch Loss: 75474.6621 - Avg Loss: 181.4295\n",
            "Epoch [3/50] - Batch loss: 171.7769 - Epoch Loss: 75646.4390 - Avg Loss: 181.4063\n",
            "Epoch [3/50] - Batch loss: 175.8176 - Epoch Loss: 75822.2566 - Avg Loss: 181.3930\n",
            "Epoch [3/50] - Batch loss: 174.9857 - Epoch Loss: 75997.2424 - Avg Loss: 181.3777\n",
            "Epoch [3/50] - Batch loss: 177.0711 - Epoch Loss: 76174.3134 - Avg Loss: 181.3674\n",
            "Epoch [3/50] - Batch loss: 181.4151 - Epoch Loss: 76355.7285 - Avg Loss: 181.3675\n",
            "Epoch [3/50] - Batch loss: 181.2269 - Epoch Loss: 76536.9554 - Avg Loss: 181.3672\n",
            "Epoch [3/50] - Batch loss: 174.7087 - Epoch Loss: 76711.6641 - Avg Loss: 181.3515\n",
            "Epoch [3/50] - Batch loss: 181.6974 - Epoch Loss: 76893.3616 - Avg Loss: 181.3523\n",
            "Epoch [3/50] - Batch loss: 181.4917 - Epoch Loss: 77074.8532 - Avg Loss: 181.3526\n",
            "Epoch [3/50] - Batch loss: 178.3058 - Epoch Loss: 77253.1590 - Avg Loss: 181.3454\n",
            "Epoch [3/50] - Batch loss: 172.9538 - Epoch Loss: 77426.1127 - Avg Loss: 181.3258\n",
            "Epoch [3/50] - Batch loss: 186.4023 - Epoch Loss: 77612.5150 - Avg Loss: 181.3377\n",
            "Epoch [3/50] - Batch loss: 173.5328 - Epoch Loss: 77786.0478 - Avg Loss: 181.3195\n",
            "Epoch [3/50] - Batch loss: 180.8516 - Epoch Loss: 77966.8994 - Avg Loss: 181.3184\n",
            "Epoch [3/50] - Batch loss: 174.1627 - Epoch Loss: 78141.0621 - Avg Loss: 181.3018\n",
            "Epoch [3/50] - Batch loss: 179.2140 - Epoch Loss: 78320.2761 - Avg Loss: 181.2969\n",
            "Epoch [3/50] - Batch loss: 175.0847 - Epoch Loss: 78495.3607 - Avg Loss: 181.2826\n",
            "Epoch [3/50] - Batch loss: 176.3086 - Epoch Loss: 78671.6694 - Avg Loss: 181.2711\n",
            "Epoch [3/50] - Batch loss: 178.7278 - Epoch Loss: 78850.3972 - Avg Loss: 181.2653\n",
            "Epoch [3/50] - Batch loss: 179.2411 - Epoch Loss: 79029.6383 - Avg Loss: 181.2606\n",
            "Epoch [3/50] - Batch loss: 180.0048 - Epoch Loss: 79209.6431 - Avg Loss: 181.2578\n",
            "Epoch [3/50] - Batch loss: 171.5718 - Epoch Loss: 79381.2149 - Avg Loss: 181.2357\n",
            "Epoch [3/50] - Batch loss: 180.4645 - Epoch Loss: 79561.6794 - Avg Loss: 181.2339\n",
            "Epoch [3/50] - Batch loss: 183.6690 - Epoch Loss: 79745.3485 - Avg Loss: 181.2394\n",
            "Epoch [3/50] - Batch loss: 175.5104 - Epoch Loss: 79920.8588 - Avg Loss: 181.2264\n",
            "Epoch [3/50] - Batch loss: 181.4292 - Epoch Loss: 80102.2881 - Avg Loss: 181.2269\n",
            "Epoch [3/50] - Batch loss: 180.0157 - Epoch Loss: 80282.3038 - Avg Loss: 181.2242\n",
            "Epoch [3/50] - Batch loss: 176.3552 - Epoch Loss: 80458.6590 - Avg Loss: 181.2132\n",
            "Epoch [3/50] - Batch loss: 168.8343 - Epoch Loss: 80627.4933 - Avg Loss: 181.1854\n",
            "Epoch [3/50] - Batch loss: 175.4906 - Epoch Loss: 80802.9839 - Avg Loss: 181.1726\n",
            "Epoch [3/50] - Batch loss: 185.3900 - Epoch Loss: 80988.3739 - Avg Loss: 181.1820\n",
            "Epoch [3/50] - Batch loss: 170.7948 - Epoch Loss: 81159.1687 - Avg Loss: 181.1589\n",
            "Epoch [3/50] - Batch loss: 176.9198 - Epoch Loss: 81336.0885 - Avg Loss: 181.1494\n",
            "Epoch [3/50] - Batch loss: 183.5499 - Epoch Loss: 81519.6384 - Avg Loss: 181.1548\n",
            "Epoch [3/50] - Batch loss: 177.1891 - Epoch Loss: 81696.8274 - Avg Loss: 181.1460\n",
            "Epoch [3/50] - Batch loss: 172.5727 - Epoch Loss: 81869.4001 - Avg Loss: 181.1270\n",
            "Epoch [3/50] - Batch loss: 180.3776 - Epoch Loss: 82049.7778 - Avg Loss: 181.1253\n",
            "Epoch [3/50] - Batch loss: 174.3509 - Epoch Loss: 82224.1287 - Avg Loss: 181.1104\n",
            "Epoch [3/50] - Batch loss: 177.7946 - Epoch Loss: 82401.9233 - Avg Loss: 181.1031\n",
            "Epoch [3/50] - Batch loss: 176.2855 - Epoch Loss: 82578.2088 - Avg Loss: 181.0926\n",
            "Epoch [3/50] - Batch loss: 178.8367 - Epoch Loss: 82757.0455 - Avg Loss: 181.0876\n",
            "Epoch [3/50] - Batch loss: 176.9808 - Epoch Loss: 82934.0263 - Avg Loss: 181.0787\n",
            "Epoch [3/50] - Batch loss: 175.1855 - Epoch Loss: 83109.2118 - Avg Loss: 181.0658\n",
            "Epoch [3/50] - Batch loss: 178.3283 - Epoch Loss: 83287.5401 - Avg Loss: 181.0599\n",
            "Epoch [3/50] - Batch loss: 179.1867 - Epoch Loss: 83466.7268 - Avg Loss: 181.0558\n",
            "Epoch [3/50] - Batch loss: 177.7470 - Epoch Loss: 83644.4738 - Avg Loss: 181.0486\n",
            "Epoch [3/50] - Batch loss: 170.2500 - Epoch Loss: 83814.7238 - Avg Loss: 181.0253\n",
            "Epoch [3/50] - Batch loss: 179.9213 - Epoch Loss: 83994.6451 - Avg Loss: 181.0229\n",
            "Epoch [3/50] - Batch loss: 176.7101 - Epoch Loss: 84171.3552 - Avg Loss: 181.0137\n",
            "Epoch [3/50] - Batch loss: 177.5518 - Epoch Loss: 84348.9070 - Avg Loss: 181.0062\n",
            "Epoch [3/50] - Batch loss: 176.6428 - Epoch Loss: 84525.5499 - Avg Loss: 180.9969\n",
            "Epoch [3/50] - Batch loss: 179.4865 - Epoch Loss: 84705.0364 - Avg Loss: 180.9937\n",
            "Epoch [3/50] - Batch loss: 168.0435 - Epoch Loss: 84873.0799 - Avg Loss: 180.9661\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 4/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "870ac42f03db4d45ac3562a676dcda12"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/50] - Batch loss: 176.9105 - Epoch Loss: 176.9105 - Avg Loss: 176.9105\n",
            "Epoch [4/50] - Batch loss: 179.2557 - Epoch Loss: 356.1662 - Avg Loss: 178.0831\n",
            "Epoch [4/50] - Batch loss: 182.0716 - Epoch Loss: 538.2377 - Avg Loss: 179.4126\n",
            "Epoch [4/50] - Batch loss: 176.2413 - Epoch Loss: 714.4790 - Avg Loss: 178.6198\n",
            "Epoch [4/50] - Batch loss: 177.1277 - Epoch Loss: 891.6067 - Avg Loss: 178.3213\n",
            "Epoch [4/50] - Batch loss: 179.7205 - Epoch Loss: 1071.3271 - Avg Loss: 178.5545\n",
            "Epoch [4/50] - Batch loss: 176.3787 - Epoch Loss: 1247.7059 - Avg Loss: 178.2437\n",
            "Epoch [4/50] - Batch loss: 178.0708 - Epoch Loss: 1425.7766 - Avg Loss: 178.2221\n",
            "Epoch [4/50] - Batch loss: 183.1209 - Epoch Loss: 1608.8975 - Avg Loss: 178.7664\n",
            "Epoch [4/50] - Batch loss: 174.5378 - Epoch Loss: 1783.4353 - Avg Loss: 178.3435\n",
            "Epoch [4/50] - Batch loss: 171.4258 - Epoch Loss: 1954.8611 - Avg Loss: 177.7146\n",
            "Epoch [4/50] - Batch loss: 175.6589 - Epoch Loss: 2130.5200 - Avg Loss: 177.5433\n",
            "Epoch [4/50] - Batch loss: 188.5013 - Epoch Loss: 2319.0213 - Avg Loss: 178.3863\n",
            "Epoch [4/50] - Batch loss: 173.7173 - Epoch Loss: 2492.7386 - Avg Loss: 178.0528\n",
            "Epoch [4/50] - Batch loss: 179.5354 - Epoch Loss: 2672.2740 - Avg Loss: 178.1516\n",
            "Epoch [4/50] - Batch loss: 179.2949 - Epoch Loss: 2851.5690 - Avg Loss: 178.2231\n",
            "Epoch [4/50] - Batch loss: 174.0616 - Epoch Loss: 3025.6306 - Avg Loss: 177.9783\n",
            "Epoch [4/50] - Batch loss: 174.7988 - Epoch Loss: 3200.4294 - Avg Loss: 177.8016\n",
            "Epoch [4/50] - Batch loss: 172.3288 - Epoch Loss: 3372.7582 - Avg Loss: 177.5136\n",
            "Epoch [4/50] - Batch loss: 169.7069 - Epoch Loss: 3542.4650 - Avg Loss: 177.1233\n",
            "Epoch [4/50] - Batch loss: 182.4764 - Epoch Loss: 3724.9414 - Avg Loss: 177.3782\n",
            "Epoch [4/50] - Batch loss: 176.6372 - Epoch Loss: 3901.5787 - Avg Loss: 177.3445\n",
            "Epoch [4/50] - Batch loss: 177.4076 - Epoch Loss: 4078.9863 - Avg Loss: 177.3472\n",
            "Epoch [4/50] - Batch loss: 175.6085 - Epoch Loss: 4254.5948 - Avg Loss: 177.2748\n",
            "Epoch [4/50] - Batch loss: 182.6581 - Epoch Loss: 4437.2529 - Avg Loss: 177.4901\n",
            "Epoch [4/50] - Batch loss: 178.1698 - Epoch Loss: 4615.4227 - Avg Loss: 177.5163\n",
            "Epoch [4/50] - Batch loss: 178.0523 - Epoch Loss: 4793.4749 - Avg Loss: 177.5361\n",
            "Epoch [4/50] - Batch loss: 183.9058 - Epoch Loss: 4977.3807 - Avg Loss: 177.7636\n",
            "Epoch [4/50] - Batch loss: 176.2242 - Epoch Loss: 5153.6049 - Avg Loss: 177.7105\n",
            "Epoch [4/50] - Batch loss: 168.3878 - Epoch Loss: 5321.9927 - Avg Loss: 177.3998\n",
            "Epoch [4/50] - Batch loss: 180.6698 - Epoch Loss: 5502.6625 - Avg Loss: 177.5052\n",
            "Epoch [4/50] - Batch loss: 177.6839 - Epoch Loss: 5680.3464 - Avg Loss: 177.5108\n",
            "Epoch [4/50] - Batch loss: 179.3777 - Epoch Loss: 5859.7241 - Avg Loss: 177.5674\n",
            "Epoch [4/50] - Batch loss: 181.6629 - Epoch Loss: 6041.3870 - Avg Loss: 177.6879\n",
            "Epoch [4/50] - Batch loss: 182.1794 - Epoch Loss: 6223.5664 - Avg Loss: 177.8162\n",
            "Epoch [4/50] - Batch loss: 167.4538 - Epoch Loss: 6391.0202 - Avg Loss: 177.5283\n",
            "Epoch [4/50] - Batch loss: 175.1961 - Epoch Loss: 6566.2163 - Avg Loss: 177.4653\n",
            "Epoch [4/50] - Batch loss: 183.5498 - Epoch Loss: 6749.7661 - Avg Loss: 177.6254\n",
            "Epoch [4/50] - Batch loss: 177.1964 - Epoch Loss: 6926.9626 - Avg Loss: 177.6144\n",
            "Epoch [4/50] - Batch loss: 176.3536 - Epoch Loss: 7103.3162 - Avg Loss: 177.5829\n",
            "Epoch [4/50] - Batch loss: 183.1305 - Epoch Loss: 7286.4467 - Avg Loss: 177.7182\n",
            "Epoch [4/50] - Batch loss: 181.9260 - Epoch Loss: 7468.3727 - Avg Loss: 177.8184\n",
            "Epoch [4/50] - Batch loss: 181.3023 - Epoch Loss: 7649.6750 - Avg Loss: 177.8994\n",
            "Epoch [4/50] - Batch loss: 169.8732 - Epoch Loss: 7819.5482 - Avg Loss: 177.7170\n",
            "Epoch [4/50] - Batch loss: 184.7238 - Epoch Loss: 8004.2720 - Avg Loss: 177.8727\n",
            "Epoch [4/50] - Batch loss: 174.6834 - Epoch Loss: 8178.9554 - Avg Loss: 177.8034\n",
            "Epoch [4/50] - Batch loss: 174.7532 - Epoch Loss: 8353.7086 - Avg Loss: 177.7385\n",
            "Epoch [4/50] - Batch loss: 180.8010 - Epoch Loss: 8534.5096 - Avg Loss: 177.8023\n",
            "Epoch [4/50] - Batch loss: 179.9102 - Epoch Loss: 8714.4198 - Avg Loss: 177.8453\n",
            "Epoch [4/50] - Batch loss: 169.8388 - Epoch Loss: 8884.2587 - Avg Loss: 177.6852\n",
            "Epoch [4/50] - Batch loss: 175.7963 - Epoch Loss: 9060.0549 - Avg Loss: 177.6481\n",
            "Epoch [4/50] - Batch loss: 186.3059 - Epoch Loss: 9246.3608 - Avg Loss: 177.8146\n",
            "Epoch [4/50] - Batch loss: 175.7781 - Epoch Loss: 9422.1389 - Avg Loss: 177.7762\n",
            "Epoch [4/50] - Batch loss: 179.5148 - Epoch Loss: 9601.6537 - Avg Loss: 177.8084\n",
            "Epoch [4/50] - Batch loss: 180.1714 - Epoch Loss: 9781.8250 - Avg Loss: 177.8514\n",
            "Epoch [4/50] - Batch loss: 179.1782 - Epoch Loss: 9961.0032 - Avg Loss: 177.8751\n",
            "Epoch [4/50] - Batch loss: 168.3240 - Epoch Loss: 10129.3272 - Avg Loss: 177.7075\n",
            "Epoch [4/50] - Batch loss: 172.3656 - Epoch Loss: 10301.6928 - Avg Loss: 177.6154\n",
            "Epoch [4/50] - Batch loss: 172.6157 - Epoch Loss: 10474.3085 - Avg Loss: 177.5307\n",
            "Epoch [4/50] - Batch loss: 183.1345 - Epoch Loss: 10657.4430 - Avg Loss: 177.6241\n",
            "Epoch [4/50] - Batch loss: 176.6209 - Epoch Loss: 10834.0639 - Avg Loss: 177.6076\n",
            "Epoch [4/50] - Batch loss: 174.1725 - Epoch Loss: 11008.2365 - Avg Loss: 177.5522\n",
            "Epoch [4/50] - Batch loss: 169.0184 - Epoch Loss: 11177.2549 - Avg Loss: 177.4167\n",
            "Epoch [4/50] - Batch loss: 181.4476 - Epoch Loss: 11358.7026 - Avg Loss: 177.4797\n",
            "Epoch [4/50] - Batch loss: 179.8462 - Epoch Loss: 11538.5488 - Avg Loss: 177.5161\n",
            "Epoch [4/50] - Batch loss: 170.9187 - Epoch Loss: 11709.4675 - Avg Loss: 177.4162\n",
            "Epoch [4/50] - Batch loss: 173.4865 - Epoch Loss: 11882.9540 - Avg Loss: 177.3575\n",
            "Epoch [4/50] - Batch loss: 178.6911 - Epoch Loss: 12061.6451 - Avg Loss: 177.3771\n",
            "Epoch [4/50] - Batch loss: 175.9427 - Epoch Loss: 12237.5877 - Avg Loss: 177.3563\n",
            "Epoch [4/50] - Batch loss: 180.9172 - Epoch Loss: 12418.5049 - Avg Loss: 177.4072\n",
            "Epoch [4/50] - Batch loss: 171.3728 - Epoch Loss: 12589.8777 - Avg Loss: 177.3222\n",
            "Epoch [4/50] - Batch loss: 174.0348 - Epoch Loss: 12763.9126 - Avg Loss: 177.2766\n",
            "Epoch [4/50] - Batch loss: 182.9830 - Epoch Loss: 12946.8956 - Avg Loss: 177.3547\n",
            "Epoch [4/50] - Batch loss: 172.9292 - Epoch Loss: 13119.8248 - Avg Loss: 177.2949\n",
            "Epoch [4/50] - Batch loss: 185.9400 - Epoch Loss: 13305.7648 - Avg Loss: 177.4102\n",
            "Epoch [4/50] - Batch loss: 176.3123 - Epoch Loss: 13482.0771 - Avg Loss: 177.3958\n",
            "Epoch [4/50] - Batch loss: 175.1164 - Epoch Loss: 13657.1935 - Avg Loss: 177.3661\n",
            "Epoch [4/50] - Batch loss: 173.3231 - Epoch Loss: 13830.5166 - Avg Loss: 177.3143\n",
            "Epoch [4/50] - Batch loss: 170.9660 - Epoch Loss: 14001.4826 - Avg Loss: 177.2340\n",
            "Epoch [4/50] - Batch loss: 177.1044 - Epoch Loss: 14178.5871 - Avg Loss: 177.2323\n",
            "Epoch [4/50] - Batch loss: 179.8181 - Epoch Loss: 14358.4052 - Avg Loss: 177.2643\n",
            "Epoch [4/50] - Batch loss: 175.6325 - Epoch Loss: 14534.0376 - Avg Loss: 177.2444\n",
            "Epoch [4/50] - Batch loss: 179.6190 - Epoch Loss: 14713.6567 - Avg Loss: 177.2730\n",
            "Epoch [4/50] - Batch loss: 175.5556 - Epoch Loss: 14889.2122 - Avg Loss: 177.2525\n",
            "Epoch [4/50] - Batch loss: 172.7570 - Epoch Loss: 15061.9692 - Avg Loss: 177.1996\n",
            "Epoch [4/50] - Batch loss: 168.9514 - Epoch Loss: 15230.9206 - Avg Loss: 177.1037\n",
            "Epoch [4/50] - Batch loss: 177.6202 - Epoch Loss: 15408.5408 - Avg Loss: 177.1097\n",
            "Epoch [4/50] - Batch loss: 173.7180 - Epoch Loss: 15582.2588 - Avg Loss: 177.0711\n",
            "Epoch [4/50] - Batch loss: 180.0425 - Epoch Loss: 15762.3013 - Avg Loss: 177.1045\n",
            "Epoch [4/50] - Batch loss: 174.7764 - Epoch Loss: 15937.0777 - Avg Loss: 177.0786\n",
            "Epoch [4/50] - Batch loss: 181.1773 - Epoch Loss: 16118.2550 - Avg Loss: 177.1237\n",
            "Epoch [4/50] - Batch loss: 184.8016 - Epoch Loss: 16303.0566 - Avg Loss: 177.2071\n",
            "Epoch [4/50] - Batch loss: 175.2417 - Epoch Loss: 16478.2983 - Avg Loss: 177.1860\n",
            "Epoch [4/50] - Batch loss: 177.6349 - Epoch Loss: 16655.9332 - Avg Loss: 177.1908\n",
            "Epoch [4/50] - Batch loss: 166.6417 - Epoch Loss: 16822.5749 - Avg Loss: 177.0797\n",
            "Epoch [4/50] - Batch loss: 166.1258 - Epoch Loss: 16988.7007 - Avg Loss: 176.9656\n",
            "Epoch [4/50] - Batch loss: 176.2255 - Epoch Loss: 17164.9262 - Avg Loss: 176.9580\n",
            "Epoch [4/50] - Batch loss: 177.5420 - Epoch Loss: 17342.4682 - Avg Loss: 176.9640\n",
            "Epoch [4/50] - Batch loss: 178.9662 - Epoch Loss: 17521.4344 - Avg Loss: 176.9842\n",
            "Epoch [4/50] - Batch loss: 177.7553 - Epoch Loss: 17699.1897 - Avg Loss: 176.9919\n",
            "Epoch [4/50] - Batch loss: 175.4269 - Epoch Loss: 17874.6166 - Avg Loss: 176.9764\n",
            "Epoch [4/50] - Batch loss: 178.9132 - Epoch Loss: 18053.5299 - Avg Loss: 176.9954\n",
            "Epoch [4/50] - Batch loss: 175.2920 - Epoch Loss: 18228.8219 - Avg Loss: 176.9789\n",
            "Epoch [4/50] - Batch loss: 179.9560 - Epoch Loss: 18408.7779 - Avg Loss: 177.0075\n",
            "Epoch [4/50] - Batch loss: 173.9675 - Epoch Loss: 18582.7455 - Avg Loss: 176.9785\n",
            "Epoch [4/50] - Batch loss: 180.6299 - Epoch Loss: 18763.3754 - Avg Loss: 177.0130\n",
            "Epoch [4/50] - Batch loss: 177.8032 - Epoch Loss: 18941.1786 - Avg Loss: 177.0204\n",
            "Epoch [4/50] - Batch loss: 180.7251 - Epoch Loss: 19121.9037 - Avg Loss: 177.0547\n",
            "Epoch [4/50] - Batch loss: 182.0518 - Epoch Loss: 19303.9554 - Avg Loss: 177.1005\n",
            "Epoch [4/50] - Batch loss: 177.3186 - Epoch Loss: 19481.2740 - Avg Loss: 177.1025\n",
            "Epoch [4/50] - Batch loss: 178.9278 - Epoch Loss: 19660.2018 - Avg Loss: 177.1189\n",
            "Epoch [4/50] - Batch loss: 174.2129 - Epoch Loss: 19834.4148 - Avg Loss: 177.0930\n",
            "Epoch [4/50] - Batch loss: 182.3072 - Epoch Loss: 20016.7220 - Avg Loss: 177.1391\n",
            "Epoch [4/50] - Batch loss: 171.0407 - Epoch Loss: 20187.7627 - Avg Loss: 177.0856\n",
            "Epoch [4/50] - Batch loss: 185.2047 - Epoch Loss: 20372.9675 - Avg Loss: 177.1562\n",
            "Epoch [4/50] - Batch loss: 177.7387 - Epoch Loss: 20550.7061 - Avg Loss: 177.1613\n",
            "Epoch [4/50] - Batch loss: 183.8978 - Epoch Loss: 20734.6040 - Avg Loss: 177.2188\n",
            "Epoch [4/50] - Batch loss: 179.1437 - Epoch Loss: 20913.7477 - Avg Loss: 177.2351\n",
            "Epoch [4/50] - Batch loss: 171.5227 - Epoch Loss: 21085.2703 - Avg Loss: 177.1871\n",
            "Epoch [4/50] - Batch loss: 173.1969 - Epoch Loss: 21258.4672 - Avg Loss: 177.1539\n",
            "Epoch [4/50] - Batch loss: 176.5105 - Epoch Loss: 21434.9777 - Avg Loss: 177.1486\n",
            "Epoch [4/50] - Batch loss: 171.6358 - Epoch Loss: 21606.6134 - Avg Loss: 177.1034\n",
            "Epoch [4/50] - Batch loss: 177.3356 - Epoch Loss: 21783.9491 - Avg Loss: 177.1053\n",
            "Epoch [4/50] - Batch loss: 178.5316 - Epoch Loss: 21962.4807 - Avg Loss: 177.1168\n",
            "Epoch [4/50] - Batch loss: 180.7828 - Epoch Loss: 22143.2635 - Avg Loss: 177.1461\n",
            "Epoch [4/50] - Batch loss: 174.9698 - Epoch Loss: 22318.2333 - Avg Loss: 177.1288\n",
            "Epoch [4/50] - Batch loss: 185.7368 - Epoch Loss: 22503.9701 - Avg Loss: 177.1966\n",
            "Epoch [4/50] - Batch loss: 176.0391 - Epoch Loss: 22680.0092 - Avg Loss: 177.1876\n",
            "Epoch [4/50] - Batch loss: 178.4405 - Epoch Loss: 22858.4497 - Avg Loss: 177.1973\n",
            "Epoch [4/50] - Batch loss: 176.2123 - Epoch Loss: 23034.6621 - Avg Loss: 177.1897\n",
            "Epoch [4/50] - Batch loss: 177.4082 - Epoch Loss: 23212.0703 - Avg Loss: 177.1914\n",
            "Epoch [4/50] - Batch loss: 172.3618 - Epoch Loss: 23384.4321 - Avg Loss: 177.1548\n",
            "Epoch [4/50] - Batch loss: 172.8861 - Epoch Loss: 23557.3183 - Avg Loss: 177.1227\n",
            "Epoch [4/50] - Batch loss: 180.2766 - Epoch Loss: 23737.5949 - Avg Loss: 177.1462\n",
            "Epoch [4/50] - Batch loss: 169.2753 - Epoch Loss: 23906.8702 - Avg Loss: 177.0879\n",
            "Epoch [4/50] - Batch loss: 175.8626 - Epoch Loss: 24082.7328 - Avg Loss: 177.0789\n",
            "Epoch [4/50] - Batch loss: 179.0190 - Epoch Loss: 24261.7519 - Avg Loss: 177.0931\n",
            "Epoch [4/50] - Batch loss: 181.6285 - Epoch Loss: 24443.3804 - Avg Loss: 177.1259\n",
            "Epoch [4/50] - Batch loss: 176.9112 - Epoch Loss: 24620.2915 - Avg Loss: 177.1244\n",
            "Epoch [4/50] - Batch loss: 174.3119 - Epoch Loss: 24794.6034 - Avg Loss: 177.1043\n",
            "Epoch [4/50] - Batch loss: 185.4908 - Epoch Loss: 24980.0942 - Avg Loss: 177.1638\n",
            "Epoch [4/50] - Batch loss: 178.6792 - Epoch Loss: 25158.7734 - Avg Loss: 177.1745\n",
            "Epoch [4/50] - Batch loss: 183.0620 - Epoch Loss: 25341.8354 - Avg Loss: 177.2156\n",
            "Epoch [4/50] - Batch loss: 174.2755 - Epoch Loss: 25516.1109 - Avg Loss: 177.1952\n",
            "Epoch [4/50] - Batch loss: 179.6883 - Epoch Loss: 25695.7992 - Avg Loss: 177.2124\n",
            "Epoch [4/50] - Batch loss: 173.2985 - Epoch Loss: 25869.0977 - Avg Loss: 177.1856\n",
            "Epoch [4/50] - Batch loss: 181.7845 - Epoch Loss: 26050.8822 - Avg Loss: 177.2169\n",
            "Epoch [4/50] - Batch loss: 177.0073 - Epoch Loss: 26227.8895 - Avg Loss: 177.2155\n",
            "Epoch [4/50] - Batch loss: 178.9359 - Epoch Loss: 26406.8253 - Avg Loss: 177.2270\n",
            "Epoch [4/50] - Batch loss: 179.3186 - Epoch Loss: 26586.1440 - Avg Loss: 177.2410\n",
            "Epoch [4/50] - Batch loss: 179.3509 - Epoch Loss: 26765.4948 - Avg Loss: 177.2549\n",
            "Epoch [4/50] - Batch loss: 173.9750 - Epoch Loss: 26939.4699 - Avg Loss: 177.2334\n",
            "Epoch [4/50] - Batch loss: 171.2945 - Epoch Loss: 27110.7644 - Avg Loss: 177.1945\n",
            "Epoch [4/50] - Batch loss: 177.5112 - Epoch Loss: 27288.2756 - Avg Loss: 177.1966\n",
            "Epoch [4/50] - Batch loss: 171.4383 - Epoch Loss: 27459.7139 - Avg Loss: 177.1594\n",
            "Epoch [4/50] - Batch loss: 188.6240 - Epoch Loss: 27648.3379 - Avg Loss: 177.2329\n",
            "Epoch [4/50] - Batch loss: 171.2513 - Epoch Loss: 27819.5892 - Avg Loss: 177.1948\n",
            "Epoch [4/50] - Batch loss: 174.8892 - Epoch Loss: 27994.4783 - Avg Loss: 177.1802\n",
            "Epoch [4/50] - Batch loss: 178.4635 - Epoch Loss: 28172.9418 - Avg Loss: 177.1883\n",
            "Epoch [4/50] - Batch loss: 175.6256 - Epoch Loss: 28348.5675 - Avg Loss: 177.1785\n",
            "Epoch [4/50] - Batch loss: 176.6636 - Epoch Loss: 28525.2311 - Avg Loss: 177.1753\n",
            "Epoch [4/50] - Batch loss: 179.3217 - Epoch Loss: 28704.5528 - Avg Loss: 177.1886\n",
            "Epoch [4/50] - Batch loss: 173.4341 - Epoch Loss: 28877.9869 - Avg Loss: 177.1656\n",
            "Epoch [4/50] - Batch loss: 173.2945 - Epoch Loss: 29051.2813 - Avg Loss: 177.1420\n",
            "Epoch [4/50] - Batch loss: 180.0486 - Epoch Loss: 29231.3300 - Avg Loss: 177.1596\n",
            "Epoch [4/50] - Batch loss: 170.8949 - Epoch Loss: 29402.2248 - Avg Loss: 177.1218\n",
            "Epoch [4/50] - Batch loss: 172.9333 - Epoch Loss: 29575.1581 - Avg Loss: 177.0968\n",
            "Epoch [4/50] - Batch loss: 176.2486 - Epoch Loss: 29751.4068 - Avg Loss: 177.0917\n",
            "Epoch [4/50] - Batch loss: 173.0060 - Epoch Loss: 29924.4128 - Avg Loss: 177.0675\n",
            "Epoch [4/50] - Batch loss: 169.0088 - Epoch Loss: 30093.4216 - Avg Loss: 177.0201\n",
            "Epoch [4/50] - Batch loss: 177.9211 - Epoch Loss: 30271.3427 - Avg Loss: 177.0254\n",
            "Epoch [4/50] - Batch loss: 178.3326 - Epoch Loss: 30449.6753 - Avg Loss: 177.0330\n",
            "Epoch [4/50] - Batch loss: 173.9785 - Epoch Loss: 30623.6537 - Avg Loss: 177.0153\n",
            "Epoch [4/50] - Batch loss: 170.4777 - Epoch Loss: 30794.1314 - Avg Loss: 176.9778\n",
            "Epoch [4/50] - Batch loss: 176.9346 - Epoch Loss: 30971.0661 - Avg Loss: 176.9775\n",
            "Epoch [4/50] - Batch loss: 181.3477 - Epoch Loss: 31152.4138 - Avg Loss: 177.0024\n",
            "Epoch [4/50] - Batch loss: 170.9299 - Epoch Loss: 31323.3437 - Avg Loss: 176.9680\n",
            "Epoch [4/50] - Batch loss: 179.6564 - Epoch Loss: 31503.0001 - Avg Loss: 176.9831\n",
            "Epoch [4/50] - Batch loss: 178.8669 - Epoch Loss: 31681.8670 - Avg Loss: 176.9937\n",
            "Epoch [4/50] - Batch loss: 176.3176 - Epoch Loss: 31858.1846 - Avg Loss: 176.9899\n",
            "Epoch [4/50] - Batch loss: 173.8921 - Epoch Loss: 32032.0767 - Avg Loss: 176.9728\n",
            "Epoch [4/50] - Batch loss: 174.0237 - Epoch Loss: 32206.1004 - Avg Loss: 176.9566\n",
            "Epoch [4/50] - Batch loss: 178.3032 - Epoch Loss: 32384.4036 - Avg Loss: 176.9640\n",
            "Epoch [4/50] - Batch loss: 172.7937 - Epoch Loss: 32557.1973 - Avg Loss: 176.9413\n",
            "Epoch [4/50] - Batch loss: 169.1506 - Epoch Loss: 32726.3479 - Avg Loss: 176.8992\n",
            "Epoch [4/50] - Batch loss: 171.4363 - Epoch Loss: 32897.7842 - Avg Loss: 176.8698\n",
            "Epoch [4/50] - Batch loss: 179.7796 - Epoch Loss: 33077.5639 - Avg Loss: 176.8854\n",
            "Epoch [4/50] - Batch loss: 171.7598 - Epoch Loss: 33249.3237 - Avg Loss: 176.8581\n",
            "Epoch [4/50] - Batch loss: 173.4518 - Epoch Loss: 33422.7755 - Avg Loss: 176.8401\n",
            "Epoch [4/50] - Batch loss: 169.8165 - Epoch Loss: 33592.5919 - Avg Loss: 176.8031\n",
            "Epoch [4/50] - Batch loss: 178.3636 - Epoch Loss: 33770.9555 - Avg Loss: 176.8113\n",
            "Epoch [4/50] - Batch loss: 174.7603 - Epoch Loss: 33945.7159 - Avg Loss: 176.8006\n",
            "Epoch [4/50] - Batch loss: 171.3332 - Epoch Loss: 34117.0491 - Avg Loss: 176.7723\n",
            "Epoch [4/50] - Batch loss: 176.4039 - Epoch Loss: 34293.4530 - Avg Loss: 176.7704\n",
            "Epoch [4/50] - Batch loss: 173.1723 - Epoch Loss: 34466.6253 - Avg Loss: 176.7519\n",
            "Epoch [4/50] - Batch loss: 188.9564 - Epoch Loss: 34655.5817 - Avg Loss: 176.8142\n",
            "Epoch [4/50] - Batch loss: 178.7575 - Epoch Loss: 34834.3392 - Avg Loss: 176.8241\n",
            "Epoch [4/50] - Batch loss: 173.2517 - Epoch Loss: 35007.5909 - Avg Loss: 176.8060\n",
            "Epoch [4/50] - Batch loss: 176.5506 - Epoch Loss: 35184.1415 - Avg Loss: 176.8047\n",
            "Epoch [4/50] - Batch loss: 171.6355 - Epoch Loss: 35355.7770 - Avg Loss: 176.7789\n",
            "Epoch [4/50] - Batch loss: 174.1443 - Epoch Loss: 35529.9213 - Avg Loss: 176.7658\n",
            "Epoch [4/50] - Batch loss: 178.8271 - Epoch Loss: 35708.7484 - Avg Loss: 176.7760\n",
            "Epoch [4/50] - Batch loss: 175.0011 - Epoch Loss: 35883.7494 - Avg Loss: 176.7672\n",
            "Epoch [4/50] - Batch loss: 181.6819 - Epoch Loss: 36065.4314 - Avg Loss: 176.7913\n",
            "Epoch [4/50] - Batch loss: 170.2470 - Epoch Loss: 36235.6784 - Avg Loss: 176.7594\n",
            "Epoch [4/50] - Batch loss: 171.3110 - Epoch Loss: 36406.9893 - Avg Loss: 176.7330\n",
            "Epoch [4/50] - Batch loss: 177.6740 - Epoch Loss: 36584.6633 - Avg Loss: 176.7375\n",
            "Epoch [4/50] - Batch loss: 177.0127 - Epoch Loss: 36761.6760 - Avg Loss: 176.7388\n",
            "Epoch [4/50] - Batch loss: 173.7446 - Epoch Loss: 36935.4206 - Avg Loss: 176.7245\n",
            "Epoch [4/50] - Batch loss: 174.8312 - Epoch Loss: 37110.2518 - Avg Loss: 176.7155\n",
            "Epoch [4/50] - Batch loss: 172.0388 - Epoch Loss: 37282.2906 - Avg Loss: 176.6933\n",
            "Epoch [4/50] - Batch loss: 179.1388 - Epoch Loss: 37461.4293 - Avg Loss: 176.7049\n",
            "Epoch [4/50] - Batch loss: 178.0539 - Epoch Loss: 37639.4832 - Avg Loss: 176.7112\n",
            "Epoch [4/50] - Batch loss: 175.7950 - Epoch Loss: 37815.2783 - Avg Loss: 176.7069\n",
            "Epoch [4/50] - Batch loss: 170.5896 - Epoch Loss: 37985.8678 - Avg Loss: 176.6785\n",
            "Epoch [4/50] - Batch loss: 170.5463 - Epoch Loss: 38156.4141 - Avg Loss: 176.6501\n",
            "Epoch [4/50] - Batch loss: 175.9635 - Epoch Loss: 38332.3777 - Avg Loss: 176.6469\n",
            "Epoch [4/50] - Batch loss: 172.3993 - Epoch Loss: 38504.7770 - Avg Loss: 176.6274\n",
            "Epoch [4/50] - Batch loss: 176.3962 - Epoch Loss: 38681.1731 - Avg Loss: 176.6264\n",
            "Epoch [4/50] - Batch loss: 177.7987 - Epoch Loss: 38858.9719 - Avg Loss: 176.6317\n",
            "Epoch [4/50] - Batch loss: 172.1032 - Epoch Loss: 39031.0750 - Avg Loss: 176.6112\n",
            "Epoch [4/50] - Batch loss: 181.0792 - Epoch Loss: 39212.1542 - Avg Loss: 176.6313\n",
            "Epoch [4/50] - Batch loss: 174.3445 - Epoch Loss: 39386.4987 - Avg Loss: 176.6211\n",
            "Epoch [4/50] - Batch loss: 176.8713 - Epoch Loss: 39563.3700 - Avg Loss: 176.6222\n",
            "Epoch [4/50] - Batch loss: 176.9836 - Epoch Loss: 39740.3536 - Avg Loss: 176.6238\n",
            "Epoch [4/50] - Batch loss: 179.7710 - Epoch Loss: 39920.1246 - Avg Loss: 176.6377\n",
            "Epoch [4/50] - Batch loss: 172.5393 - Epoch Loss: 40092.6639 - Avg Loss: 176.6197\n",
            "Epoch [4/50] - Batch loss: 182.4345 - Epoch Loss: 40275.0983 - Avg Loss: 176.6452\n",
            "Epoch [4/50] - Batch loss: 177.3579 - Epoch Loss: 40452.4562 - Avg Loss: 176.6483\n",
            "Epoch [4/50] - Batch loss: 175.5640 - Epoch Loss: 40628.0202 - Avg Loss: 176.6436\n",
            "Epoch [4/50] - Batch loss: 170.8640 - Epoch Loss: 40798.8843 - Avg Loss: 176.6185\n",
            "Epoch [4/50] - Batch loss: 169.4888 - Epoch Loss: 40968.3730 - Avg Loss: 176.5878\n",
            "Epoch [4/50] - Batch loss: 171.5961 - Epoch Loss: 41139.9691 - Avg Loss: 176.5664\n",
            "Epoch [4/50] - Batch loss: 172.1615 - Epoch Loss: 41312.1306 - Avg Loss: 176.5476\n",
            "Epoch [4/50] - Batch loss: 171.4275 - Epoch Loss: 41483.5582 - Avg Loss: 176.5258\n",
            "Epoch [4/50] - Batch loss: 177.4572 - Epoch Loss: 41661.0153 - Avg Loss: 176.5297\n",
            "Epoch [4/50] - Batch loss: 171.9414 - Epoch Loss: 41832.9567 - Avg Loss: 176.5104\n",
            "Epoch [4/50] - Batch loss: 174.4108 - Epoch Loss: 42007.3674 - Avg Loss: 176.5015\n",
            "Epoch [4/50] - Batch loss: 177.3897 - Epoch Loss: 42184.7572 - Avg Loss: 176.5053\n",
            "Epoch [4/50] - Batch loss: 170.1666 - Epoch Loss: 42354.9237 - Avg Loss: 176.4788\n",
            "Epoch [4/50] - Batch loss: 178.4206 - Epoch Loss: 42533.3443 - Avg Loss: 176.4869\n",
            "Epoch [4/50] - Batch loss: 177.4563 - Epoch Loss: 42710.8006 - Avg Loss: 176.4909\n",
            "Epoch [4/50] - Batch loss: 173.2431 - Epoch Loss: 42884.0438 - Avg Loss: 176.4775\n",
            "Epoch [4/50] - Batch loss: 170.5199 - Epoch Loss: 43054.5637 - Avg Loss: 176.4531\n",
            "Epoch [4/50] - Batch loss: 170.9210 - Epoch Loss: 43225.4847 - Avg Loss: 176.4305\n",
            "Epoch [4/50] - Batch loss: 171.9456 - Epoch Loss: 43397.4303 - Avg Loss: 176.4123\n",
            "Epoch [4/50] - Batch loss: 169.9348 - Epoch Loss: 43567.3652 - Avg Loss: 176.3861\n",
            "Epoch [4/50] - Batch loss: 176.2403 - Epoch Loss: 43743.6055 - Avg Loss: 176.3855\n",
            "Epoch [4/50] - Batch loss: 175.0517 - Epoch Loss: 43918.6572 - Avg Loss: 176.3801\n",
            "Epoch [4/50] - Batch loss: 171.5131 - Epoch Loss: 44090.1703 - Avg Loss: 176.3607\n",
            "Epoch [4/50] - Batch loss: 177.2672 - Epoch Loss: 44267.4375 - Avg Loss: 176.3643\n",
            "Epoch [4/50] - Batch loss: 169.2174 - Epoch Loss: 44436.6549 - Avg Loss: 176.3359\n",
            "Epoch [4/50] - Batch loss: 182.6987 - Epoch Loss: 44619.3537 - Avg Loss: 176.3611\n",
            "Epoch [4/50] - Batch loss: 179.8165 - Epoch Loss: 44799.1702 - Avg Loss: 176.3747\n",
            "Epoch [4/50] - Batch loss: 173.4493 - Epoch Loss: 44972.6195 - Avg Loss: 176.3632\n",
            "Epoch [4/50] - Batch loss: 170.2810 - Epoch Loss: 45142.9004 - Avg Loss: 176.3395\n",
            "Epoch [4/50] - Batch loss: 176.0136 - Epoch Loss: 45318.9140 - Avg Loss: 176.3382\n",
            "Epoch [4/50] - Batch loss: 182.3601 - Epoch Loss: 45501.2741 - Avg Loss: 176.3615\n",
            "Epoch [4/50] - Batch loss: 173.0117 - Epoch Loss: 45674.2858 - Avg Loss: 176.3486\n",
            "Epoch [4/50] - Batch loss: 175.9917 - Epoch Loss: 45850.2775 - Avg Loss: 176.3472\n",
            "Epoch [4/50] - Batch loss: 170.2270 - Epoch Loss: 46020.5045 - Avg Loss: 176.3238\n",
            "Epoch [4/50] - Batch loss: 175.9171 - Epoch Loss: 46196.4216 - Avg Loss: 176.3222\n",
            "Epoch [4/50] - Batch loss: 171.6883 - Epoch Loss: 46368.1099 - Avg Loss: 176.3046\n",
            "Epoch [4/50] - Batch loss: 176.3804 - Epoch Loss: 46544.4903 - Avg Loss: 176.3049\n",
            "Epoch [4/50] - Batch loss: 174.9733 - Epoch Loss: 46719.4636 - Avg Loss: 176.2999\n",
            "Epoch [4/50] - Batch loss: 168.6172 - Epoch Loss: 46888.0808 - Avg Loss: 176.2710\n",
            "Epoch [4/50] - Batch loss: 183.6318 - Epoch Loss: 47071.7126 - Avg Loss: 176.2985\n",
            "Epoch [4/50] - Batch loss: 177.6897 - Epoch Loss: 47249.4023 - Avg Loss: 176.3037\n",
            "Epoch [4/50] - Batch loss: 178.8567 - Epoch Loss: 47428.2590 - Avg Loss: 176.3132\n",
            "Epoch [4/50] - Batch loss: 183.5249 - Epoch Loss: 47611.7839 - Avg Loss: 176.3399\n",
            "Epoch [4/50] - Batch loss: 175.3516 - Epoch Loss: 47787.1354 - Avg Loss: 176.3363\n",
            "Epoch [4/50] - Batch loss: 175.3703 - Epoch Loss: 47962.5057 - Avg Loss: 176.3327\n",
            "Epoch [4/50] - Batch loss: 171.5004 - Epoch Loss: 48134.0061 - Avg Loss: 176.3150\n",
            "Epoch [4/50] - Batch loss: 177.0779 - Epoch Loss: 48311.0840 - Avg Loss: 176.3178\n",
            "Epoch [4/50] - Batch loss: 176.2607 - Epoch Loss: 48487.3447 - Avg Loss: 176.3176\n",
            "Epoch [4/50] - Batch loss: 170.0663 - Epoch Loss: 48657.4110 - Avg Loss: 176.2950\n",
            "Epoch [4/50] - Batch loss: 179.1639 - Epoch Loss: 48836.5749 - Avg Loss: 176.3053\n",
            "Epoch [4/50] - Batch loss: 181.3638 - Epoch Loss: 49017.9387 - Avg Loss: 176.3235\n",
            "Epoch [4/50] - Batch loss: 170.9517 - Epoch Loss: 49188.8904 - Avg Loss: 176.3043\n",
            "Epoch [4/50] - Batch loss: 174.9171 - Epoch Loss: 49363.8076 - Avg Loss: 176.2993\n",
            "Epoch [4/50] - Batch loss: 173.8400 - Epoch Loss: 49537.6475 - Avg Loss: 176.2906\n",
            "Epoch [4/50] - Batch loss: 172.1306 - Epoch Loss: 49709.7781 - Avg Loss: 176.2758\n",
            "Epoch [4/50] - Batch loss: 171.0853 - Epoch Loss: 49880.8634 - Avg Loss: 176.2575\n",
            "Epoch [4/50] - Batch loss: 176.7560 - Epoch Loss: 50057.6195 - Avg Loss: 176.2592\n",
            "Epoch [4/50] - Batch loss: 175.3504 - Epoch Loss: 50232.9699 - Avg Loss: 176.2560\n",
            "Epoch [4/50] - Batch loss: 177.6481 - Epoch Loss: 50410.6180 - Avg Loss: 176.2609\n",
            "Epoch [4/50] - Batch loss: 172.6812 - Epoch Loss: 50583.2992 - Avg Loss: 176.2484\n",
            "Epoch [4/50] - Batch loss: 174.0186 - Epoch Loss: 50757.3178 - Avg Loss: 176.2407\n",
            "Epoch [4/50] - Batch loss: 181.2883 - Epoch Loss: 50938.6061 - Avg Loss: 176.2582\n",
            "Epoch [4/50] - Batch loss: 168.5832 - Epoch Loss: 51107.1893 - Avg Loss: 176.2317\n",
            "Epoch [4/50] - Batch loss: 173.6334 - Epoch Loss: 51280.8227 - Avg Loss: 176.2228\n",
            "Epoch [4/50] - Batch loss: 166.1505 - Epoch Loss: 51446.9732 - Avg Loss: 176.1883\n",
            "Epoch [4/50] - Batch loss: 176.1197 - Epoch Loss: 51623.0929 - Avg Loss: 176.1880\n",
            "Epoch [4/50] - Batch loss: 173.9954 - Epoch Loss: 51797.0883 - Avg Loss: 176.1806\n",
            "Epoch [4/50] - Batch loss: 170.5683 - Epoch Loss: 51967.6566 - Avg Loss: 176.1615\n",
            "Epoch [4/50] - Batch loss: 178.4185 - Epoch Loss: 52146.0750 - Avg Loss: 176.1692\n",
            "Epoch [4/50] - Batch loss: 174.5004 - Epoch Loss: 52320.5754 - Avg Loss: 176.1636\n",
            "Epoch [4/50] - Batch loss: 172.9698 - Epoch Loss: 52493.5453 - Avg Loss: 176.1528\n",
            "Epoch [4/50] - Batch loss: 174.7537 - Epoch Loss: 52668.2990 - Avg Loss: 176.1482\n",
            "Epoch [4/50] - Batch loss: 166.9804 - Epoch Loss: 52835.2794 - Avg Loss: 176.1176\n",
            "Epoch [4/50] - Batch loss: 171.0107 - Epoch Loss: 53006.2901 - Avg Loss: 176.1006\n",
            "Epoch [4/50] - Batch loss: 176.0993 - Epoch Loss: 53182.3895 - Avg Loss: 176.1006\n",
            "Epoch [4/50] - Batch loss: 175.1940 - Epoch Loss: 53357.5835 - Avg Loss: 176.0976\n",
            "Epoch [4/50] - Batch loss: 170.5130 - Epoch Loss: 53528.0965 - Avg Loss: 176.0793\n",
            "Epoch [4/50] - Batch loss: 176.8159 - Epoch Loss: 53704.9123 - Avg Loss: 176.0817\n",
            "Epoch [4/50] - Batch loss: 174.0681 - Epoch Loss: 53878.9805 - Avg Loss: 176.0751\n",
            "Epoch [4/50] - Batch loss: 168.9973 - Epoch Loss: 54047.9778 - Avg Loss: 176.0520\n",
            "Epoch [4/50] - Batch loss: 158.0891 - Epoch Loss: 54206.0669 - Avg Loss: 175.9937\n",
            "Epoch [4/50] - Batch loss: 174.2257 - Epoch Loss: 54380.2926 - Avg Loss: 175.9880\n",
            "Epoch [4/50] - Batch loss: 173.8317 - Epoch Loss: 54554.1243 - Avg Loss: 175.9810\n",
            "Epoch [4/50] - Batch loss: 175.1672 - Epoch Loss: 54729.2915 - Avg Loss: 175.9784\n",
            "Epoch [4/50] - Batch loss: 174.8790 - Epoch Loss: 54904.1705 - Avg Loss: 175.9749\n",
            "Epoch [4/50] - Batch loss: 164.8794 - Epoch Loss: 55069.0499 - Avg Loss: 175.9395\n",
            "Epoch [4/50] - Batch loss: 178.6818 - Epoch Loss: 55247.7317 - Avg Loss: 175.9482\n",
            "Epoch [4/50] - Batch loss: 175.1976 - Epoch Loss: 55422.9294 - Avg Loss: 175.9458\n",
            "Epoch [4/50] - Batch loss: 178.7800 - Epoch Loss: 55601.7093 - Avg Loss: 175.9548\n",
            "Epoch [4/50] - Batch loss: 174.0458 - Epoch Loss: 55775.7551 - Avg Loss: 175.9488\n",
            "Epoch [4/50] - Batch loss: 174.2187 - Epoch Loss: 55949.9738 - Avg Loss: 175.9433\n",
            "Epoch [4/50] - Batch loss: 174.3364 - Epoch Loss: 56124.3102 - Avg Loss: 175.9383\n",
            "Epoch [4/50] - Batch loss: 176.8174 - Epoch Loss: 56301.1276 - Avg Loss: 175.9410\n",
            "Epoch [4/50] - Batch loss: 167.2538 - Epoch Loss: 56468.3814 - Avg Loss: 175.9140\n",
            "Epoch [4/50] - Batch loss: 178.3083 - Epoch Loss: 56646.6897 - Avg Loss: 175.9214\n",
            "Epoch [4/50] - Batch loss: 174.9445 - Epoch Loss: 56821.6342 - Avg Loss: 175.9184\n",
            "Epoch [4/50] - Batch loss: 176.9789 - Epoch Loss: 56998.6132 - Avg Loss: 175.9216\n",
            "Epoch [4/50] - Batch loss: 177.3731 - Epoch Loss: 57175.9863 - Avg Loss: 175.9261\n",
            "Epoch [4/50] - Batch loss: 168.2098 - Epoch Loss: 57344.1960 - Avg Loss: 175.9024\n",
            "Epoch [4/50] - Batch loss: 177.7869 - Epoch Loss: 57521.9829 - Avg Loss: 175.9082\n",
            "Epoch [4/50] - Batch loss: 172.4437 - Epoch Loss: 57694.4267 - Avg Loss: 175.8976\n",
            "Epoch [4/50] - Batch loss: 175.2267 - Epoch Loss: 57869.6534 - Avg Loss: 175.8956\n",
            "Epoch [4/50] - Batch loss: 174.2301 - Epoch Loss: 58043.8835 - Avg Loss: 175.8906\n",
            "Epoch [4/50] - Batch loss: 167.8553 - Epoch Loss: 58211.7388 - Avg Loss: 175.8663\n",
            "Epoch [4/50] - Batch loss: 183.3311 - Epoch Loss: 58395.0699 - Avg Loss: 175.8888\n",
            "Epoch [4/50] - Batch loss: 173.6537 - Epoch Loss: 58568.7236 - Avg Loss: 175.8821\n",
            "Epoch [4/50] - Batch loss: 176.2931 - Epoch Loss: 58745.0168 - Avg Loss: 175.8833\n",
            "Epoch [4/50] - Batch loss: 175.8508 - Epoch Loss: 58920.8676 - Avg Loss: 175.8832\n",
            "Epoch [4/50] - Batch loss: 168.9190 - Epoch Loss: 59089.7866 - Avg Loss: 175.8625\n",
            "Epoch [4/50] - Batch loss: 166.3962 - Epoch Loss: 59256.1828 - Avg Loss: 175.8344\n",
            "Epoch [4/50] - Batch loss: 182.9211 - Epoch Loss: 59439.1039 - Avg Loss: 175.8553\n",
            "Epoch [4/50] - Batch loss: 171.1457 - Epoch Loss: 59610.2496 - Avg Loss: 175.8414\n",
            "Epoch [4/50] - Batch loss: 170.2990 - Epoch Loss: 59780.5485 - Avg Loss: 175.8251\n",
            "Epoch [4/50] - Batch loss: 173.5992 - Epoch Loss: 59954.1477 - Avg Loss: 175.8186\n",
            "Epoch [4/50] - Batch loss: 170.8706 - Epoch Loss: 60125.0184 - Avg Loss: 175.8041\n",
            "Epoch [4/50] - Batch loss: 169.1330 - Epoch Loss: 60294.1513 - Avg Loss: 175.7847\n",
            "Epoch [4/50] - Batch loss: 178.3806 - Epoch Loss: 60472.5320 - Avg Loss: 175.7922\n",
            "Epoch [4/50] - Batch loss: 175.1626 - Epoch Loss: 60647.6945 - Avg Loss: 175.7904\n",
            "Epoch [4/50] - Batch loss: 174.3741 - Epoch Loss: 60822.0686 - Avg Loss: 175.7863\n",
            "Epoch [4/50] - Batch loss: 181.8524 - Epoch Loss: 61003.9210 - Avg Loss: 175.8038\n",
            "Epoch [4/50] - Batch loss: 170.2415 - Epoch Loss: 61174.1626 - Avg Loss: 175.7878\n",
            "Epoch [4/50] - Batch loss: 169.5324 - Epoch Loss: 61343.6950 - Avg Loss: 175.7699\n",
            "Epoch [4/50] - Batch loss: 175.6675 - Epoch Loss: 61519.3624 - Avg Loss: 175.7696\n",
            "Epoch [4/50] - Batch loss: 174.6641 - Epoch Loss: 61694.0265 - Avg Loss: 175.7665\n",
            "Epoch [4/50] - Batch loss: 164.5104 - Epoch Loss: 61858.5370 - Avg Loss: 175.7345\n",
            "Epoch [4/50] - Batch loss: 181.1619 - Epoch Loss: 62039.6989 - Avg Loss: 175.7499\n",
            "Epoch [4/50] - Batch loss: 170.7085 - Epoch Loss: 62210.4074 - Avg Loss: 175.7356\n",
            "Epoch [4/50] - Batch loss: 173.8441 - Epoch Loss: 62384.2515 - Avg Loss: 175.7303\n",
            "Epoch [4/50] - Batch loss: 170.6711 - Epoch Loss: 62554.9226 - Avg Loss: 175.7161\n",
            "Epoch [4/50] - Batch loss: 173.8613 - Epoch Loss: 62728.7838 - Avg Loss: 175.7109\n",
            "Epoch [4/50] - Batch loss: 170.9959 - Epoch Loss: 62899.7798 - Avg Loss: 175.6977\n",
            "Epoch [4/50] - Batch loss: 174.7814 - Epoch Loss: 63074.5612 - Avg Loss: 175.6952\n",
            "Epoch [4/50] - Batch loss: 176.0630 - Epoch Loss: 63250.6242 - Avg Loss: 175.6962\n",
            "Epoch [4/50] - Batch loss: 180.6251 - Epoch Loss: 63431.2492 - Avg Loss: 175.7098\n",
            "Epoch [4/50] - Batch loss: 182.1581 - Epoch Loss: 63613.4074 - Avg Loss: 175.7276\n",
            "Epoch [4/50] - Batch loss: 175.9771 - Epoch Loss: 63789.3844 - Avg Loss: 175.7283\n",
            "Epoch [4/50] - Batch loss: 165.4195 - Epoch Loss: 63954.8039 - Avg Loss: 175.7000\n",
            "Epoch [4/50] - Batch loss: 156.5208 - Epoch Loss: 64111.3247 - Avg Loss: 175.6475\n",
            "Epoch [4/50] - Batch loss: 174.1314 - Epoch Loss: 64285.4561 - Avg Loss: 175.6433\n",
            "Epoch [4/50] - Batch loss: 174.7220 - Epoch Loss: 64460.1781 - Avg Loss: 175.6408\n",
            "Epoch [4/50] - Batch loss: 168.5067 - Epoch Loss: 64628.6848 - Avg Loss: 175.6214\n",
            "Epoch [4/50] - Batch loss: 177.4962 - Epoch Loss: 64806.1810 - Avg Loss: 175.6265\n",
            "Epoch [4/50] - Batch loss: 171.1550 - Epoch Loss: 64977.3360 - Avg Loss: 175.6144\n",
            "Epoch [4/50] - Batch loss: 175.0363 - Epoch Loss: 65152.3723 - Avg Loss: 175.6129\n",
            "Epoch [4/50] - Batch loss: 174.6540 - Epoch Loss: 65327.0264 - Avg Loss: 175.6103\n",
            "Epoch [4/50] - Batch loss: 168.8645 - Epoch Loss: 65495.8908 - Avg Loss: 175.5922\n",
            "Epoch [4/50] - Batch loss: 170.6986 - Epoch Loss: 65666.5895 - Avg Loss: 175.5791\n",
            "Epoch [4/50] - Batch loss: 179.6855 - Epoch Loss: 65846.2750 - Avg Loss: 175.5901\n",
            "Epoch [4/50] - Batch loss: 168.2248 - Epoch Loss: 66014.4998 - Avg Loss: 175.5705\n",
            "Epoch [4/50] - Batch loss: 169.9635 - Epoch Loss: 66184.4633 - Avg Loss: 175.5556\n",
            "Epoch [4/50] - Batch loss: 174.3322 - Epoch Loss: 66358.7954 - Avg Loss: 175.5524\n",
            "Epoch [4/50] - Batch loss: 174.9474 - Epoch Loss: 66533.7428 - Avg Loss: 175.5508\n",
            "Epoch [4/50] - Batch loss: 177.2862 - Epoch Loss: 66711.0290 - Avg Loss: 175.5553\n",
            "Epoch [4/50] - Batch loss: 169.6212 - Epoch Loss: 66880.6502 - Avg Loss: 175.5398\n",
            "Epoch [4/50] - Batch loss: 170.8638 - Epoch Loss: 67051.5139 - Avg Loss: 175.5275\n",
            "Epoch [4/50] - Batch loss: 176.1066 - Epoch Loss: 67227.6205 - Avg Loss: 175.5290\n",
            "Epoch [4/50] - Batch loss: 184.9172 - Epoch Loss: 67412.5377 - Avg Loss: 175.5535\n",
            "Epoch [4/50] - Batch loss: 173.7501 - Epoch Loss: 67586.2878 - Avg Loss: 175.5488\n",
            "Epoch [4/50] - Batch loss: 170.0646 - Epoch Loss: 67756.3524 - Avg Loss: 175.5346\n",
            "Epoch [4/50] - Batch loss: 169.7583 - Epoch Loss: 67926.1107 - Avg Loss: 175.5197\n",
            "Epoch [4/50] - Batch loss: 175.3926 - Epoch Loss: 68101.5033 - Avg Loss: 175.5193\n",
            "Epoch [4/50] - Batch loss: 173.3511 - Epoch Loss: 68274.8544 - Avg Loss: 175.5138\n",
            "Epoch [4/50] - Batch loss: 169.5343 - Epoch Loss: 68444.3887 - Avg Loss: 175.4984\n",
            "Epoch [4/50] - Batch loss: 174.5096 - Epoch Loss: 68618.8983 - Avg Loss: 175.4959\n",
            "Epoch [4/50] - Batch loss: 172.3967 - Epoch Loss: 68791.2950 - Avg Loss: 175.4880\n",
            "Epoch [4/50] - Batch loss: 174.2962 - Epoch Loss: 68965.5912 - Avg Loss: 175.4850\n",
            "Epoch [4/50] - Batch loss: 178.5134 - Epoch Loss: 69144.1046 - Avg Loss: 175.4927\n",
            "Epoch [4/50] - Batch loss: 166.1268 - Epoch Loss: 69310.2314 - Avg Loss: 175.4689\n",
            "Epoch [4/50] - Batch loss: 178.0390 - Epoch Loss: 69488.2704 - Avg Loss: 175.4754\n",
            "Epoch [4/50] - Batch loss: 172.4627 - Epoch Loss: 69660.7331 - Avg Loss: 175.4678\n",
            "Epoch [4/50] - Batch loss: 173.5935 - Epoch Loss: 69834.3266 - Avg Loss: 175.4631\n",
            "Epoch [4/50] - Batch loss: 176.4543 - Epoch Loss: 70010.7808 - Avg Loss: 175.4656\n",
            "Epoch [4/50] - Batch loss: 179.9058 - Epoch Loss: 70190.6866 - Avg Loss: 175.4767\n",
            "Epoch [4/50] - Batch loss: 170.1975 - Epoch Loss: 70360.8841 - Avg Loss: 175.4636\n",
            "Epoch [4/50] - Batch loss: 165.4351 - Epoch Loss: 70526.3192 - Avg Loss: 175.4386\n",
            "Epoch [4/50] - Batch loss: 176.2897 - Epoch Loss: 70702.6089 - Avg Loss: 175.4407\n",
            "Epoch [4/50] - Batch loss: 180.2942 - Epoch Loss: 70882.9031 - Avg Loss: 175.4527\n",
            "Epoch [4/50] - Batch loss: 180.9179 - Epoch Loss: 71063.8210 - Avg Loss: 175.4662\n",
            "Epoch [4/50] - Batch loss: 179.6109 - Epoch Loss: 71243.4319 - Avg Loss: 175.4764\n",
            "Epoch [4/50] - Batch loss: 181.4903 - Epoch Loss: 71424.9222 - Avg Loss: 175.4912\n",
            "Epoch [4/50] - Batch loss: 167.4382 - Epoch Loss: 71592.3605 - Avg Loss: 175.4715\n",
            "Epoch [4/50] - Batch loss: 176.7603 - Epoch Loss: 71769.1208 - Avg Loss: 175.4746\n",
            "Epoch [4/50] - Batch loss: 170.4222 - Epoch Loss: 71939.5430 - Avg Loss: 175.4623\n",
            "Epoch [4/50] - Batch loss: 175.0615 - Epoch Loss: 72114.6045 - Avg Loss: 175.4613\n",
            "Epoch [4/50] - Batch loss: 173.1942 - Epoch Loss: 72287.7987 - Avg Loss: 175.4558\n",
            "Epoch [4/50] - Batch loss: 179.0269 - Epoch Loss: 72466.8256 - Avg Loss: 175.4645\n",
            "Epoch [4/50] - Batch loss: 171.4836 - Epoch Loss: 72638.3092 - Avg Loss: 175.4549\n",
            "Epoch [4/50] - Batch loss: 177.5799 - Epoch Loss: 72815.8891 - Avg Loss: 175.4600\n",
            "Epoch [4/50] - Batch loss: 177.5755 - Epoch Loss: 72993.4646 - Avg Loss: 175.4651\n",
            "Epoch [4/50] - Batch loss: 180.1732 - Epoch Loss: 73173.6378 - Avg Loss: 175.4763\n",
            "Epoch [4/50] - Batch loss: 175.3917 - Epoch Loss: 73349.0295 - Avg Loss: 175.4761\n",
            "Epoch [4/50] - Batch loss: 174.4142 - Epoch Loss: 73523.4438 - Avg Loss: 175.4736\n",
            "Epoch [4/50] - Batch loss: 172.2675 - Epoch Loss: 73695.7112 - Avg Loss: 175.4660\n",
            "Epoch [4/50] - Batch loss: 173.4505 - Epoch Loss: 73869.1617 - Avg Loss: 175.4612\n",
            "Epoch [4/50] - Batch loss: 175.1336 - Epoch Loss: 74044.2952 - Avg Loss: 175.4604\n",
            "Epoch [4/50] - Batch loss: 185.9818 - Epoch Loss: 74230.2770 - Avg Loss: 175.4853\n",
            "Epoch [4/50] - Batch loss: 177.8446 - Epoch Loss: 74408.1216 - Avg Loss: 175.4909\n",
            "Epoch [4/50] - Batch loss: 172.8136 - Epoch Loss: 74580.9352 - Avg Loss: 175.4846\n",
            "Epoch [4/50] - Batch loss: 179.2072 - Epoch Loss: 74760.1424 - Avg Loss: 175.4933\n",
            "Epoch [4/50] - Batch loss: 179.0555 - Epoch Loss: 74939.1979 - Avg Loss: 175.5016\n",
            "Epoch [4/50] - Batch loss: 166.5174 - Epoch Loss: 75105.7153 - Avg Loss: 175.4806\n",
            "Epoch [4/50] - Batch loss: 173.8388 - Epoch Loss: 75279.5541 - Avg Loss: 175.4768\n",
            "Epoch [4/50] - Batch loss: 174.5492 - Epoch Loss: 75454.1032 - Avg Loss: 175.4747\n",
            "Epoch [4/50] - Batch loss: 173.8197 - Epoch Loss: 75627.9229 - Avg Loss: 175.4708\n",
            "Epoch [4/50] - Batch loss: 173.7698 - Epoch Loss: 75801.6927 - Avg Loss: 175.4669\n",
            "Epoch [4/50] - Batch loss: 173.3434 - Epoch Loss: 75975.0361 - Avg Loss: 175.4620\n",
            "Epoch [4/50] - Batch loss: 175.7317 - Epoch Loss: 76150.7679 - Avg Loss: 175.4626\n",
            "Epoch [4/50] - Batch loss: 172.0270 - Epoch Loss: 76322.7949 - Avg Loss: 175.4547\n",
            "Epoch [4/50] - Batch loss: 172.7935 - Epoch Loss: 76495.5884 - Avg Loss: 175.4486\n",
            "Epoch [4/50] - Batch loss: 181.0581 - Epoch Loss: 76676.6465 - Avg Loss: 175.4614\n",
            "Epoch [4/50] - Batch loss: 168.4506 - Epoch Loss: 76845.0971 - Avg Loss: 175.4454\n",
            "Epoch [4/50] - Batch loss: 172.9719 - Epoch Loss: 77018.0689 - Avg Loss: 175.4398\n",
            "Epoch [4/50] - Batch loss: 171.8080 - Epoch Loss: 77189.8770 - Avg Loss: 175.4315\n",
            "Epoch [4/50] - Batch loss: 180.5740 - Epoch Loss: 77370.4510 - Avg Loss: 175.4432\n",
            "Epoch [4/50] - Batch loss: 182.6843 - Epoch Loss: 77553.1353 - Avg Loss: 175.4596\n",
            "Epoch [4/50] - Batch loss: 181.6810 - Epoch Loss: 77734.8162 - Avg Loss: 175.4736\n",
            "Epoch [4/50] - Batch loss: 176.1649 - Epoch Loss: 77910.9811 - Avg Loss: 175.4752\n",
            "Epoch [4/50] - Batch loss: 172.6546 - Epoch Loss: 78083.6357 - Avg Loss: 175.4688\n",
            "Epoch [4/50] - Batch loss: 173.3965 - Epoch Loss: 78257.0322 - Avg Loss: 175.4642\n",
            "Epoch [4/50] - Batch loss: 176.7575 - Epoch Loss: 78433.7897 - Avg Loss: 175.4671\n",
            "Epoch [4/50] - Batch loss: 177.0030 - Epoch Loss: 78610.7927 - Avg Loss: 175.4705\n",
            "Epoch [4/50] - Batch loss: 172.2937 - Epoch Loss: 78783.0863 - Avg Loss: 175.4634\n",
            "Epoch [4/50] - Batch loss: 179.3239 - Epoch Loss: 78962.4102 - Avg Loss: 175.4720\n",
            "Epoch [4/50] - Batch loss: 169.8604 - Epoch Loss: 79132.2706 - Avg Loss: 175.4596\n",
            "Epoch [4/50] - Batch loss: 171.2512 - Epoch Loss: 79303.5219 - Avg Loss: 175.4503\n",
            "Epoch [4/50] - Batch loss: 179.1806 - Epoch Loss: 79482.7025 - Avg Loss: 175.4585\n",
            "Epoch [4/50] - Batch loss: 174.9342 - Epoch Loss: 79657.6367 - Avg Loss: 175.4573\n",
            "Epoch [4/50] - Batch loss: 176.7705 - Epoch Loss: 79834.4072 - Avg Loss: 175.4602\n",
            "Epoch [4/50] - Batch loss: 181.8610 - Epoch Loss: 80016.2682 - Avg Loss: 175.4743\n",
            "Epoch [4/50] - Batch loss: 174.8379 - Epoch Loss: 80191.1061 - Avg Loss: 175.4729\n",
            "Epoch [4/50] - Batch loss: 180.2930 - Epoch Loss: 80371.3991 - Avg Loss: 175.4834\n",
            "Epoch [4/50] - Batch loss: 170.2383 - Epoch Loss: 80541.6374 - Avg Loss: 175.4720\n",
            "Epoch [4/50] - Batch loss: 175.6577 - Epoch Loss: 80717.2950 - Avg Loss: 175.4724\n",
            "Epoch [4/50] - Batch loss: 174.2920 - Epoch Loss: 80891.5870 - Avg Loss: 175.4698\n",
            "Epoch [4/50] - Batch loss: 170.2620 - Epoch Loss: 81061.8490 - Avg Loss: 175.4585\n",
            "Epoch [4/50] - Batch loss: 176.2103 - Epoch Loss: 81238.0593 - Avg Loss: 175.4602\n",
            "Epoch [4/50] - Batch loss: 178.0750 - Epoch Loss: 81416.1343 - Avg Loss: 175.4658\n",
            "Epoch [4/50] - Batch loss: 175.7629 - Epoch Loss: 81591.8973 - Avg Loss: 175.4664\n",
            "Epoch [4/50] - Batch loss: 175.5938 - Epoch Loss: 81767.4910 - Avg Loss: 175.4667\n",
            "Epoch [4/50] - Batch loss: 180.3840 - Epoch Loss: 81947.8750 - Avg Loss: 175.4772\n",
            "Epoch [4/50] - Batch loss: 169.4164 - Epoch Loss: 82117.2914 - Avg Loss: 175.4643\n",
            "Epoch [4/50] - Batch loss: 175.2946 - Epoch Loss: 82292.5860 - Avg Loss: 175.4639\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 5/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "baa072f38975442f9203c327076a9fe9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/50] - Batch loss: 171.2092 - Epoch Loss: 171.2092 - Avg Loss: 171.2092\n",
            "Epoch [5/50] - Batch loss: 180.8167 - Epoch Loss: 352.0258 - Avg Loss: 176.0129\n",
            "Epoch [5/50] - Batch loss: 175.2573 - Epoch Loss: 527.2831 - Avg Loss: 175.7610\n",
            "Epoch [5/50] - Batch loss: 171.9964 - Epoch Loss: 699.2795 - Avg Loss: 174.8199\n",
            "Epoch [5/50] - Batch loss: 173.5609 - Epoch Loss: 872.8404 - Avg Loss: 174.5681\n",
            "Epoch [5/50] - Batch loss: 180.6335 - Epoch Loss: 1053.4740 - Avg Loss: 175.5790\n",
            "Epoch [5/50] - Batch loss: 172.3811 - Epoch Loss: 1225.8551 - Avg Loss: 175.1222\n",
            "Epoch [5/50] - Batch loss: 174.2498 - Epoch Loss: 1400.1049 - Avg Loss: 175.0131\n",
            "Epoch [5/50] - Batch loss: 177.6155 - Epoch Loss: 1577.7204 - Avg Loss: 175.3023\n",
            "Epoch [5/50] - Batch loss: 180.4594 - Epoch Loss: 1758.1798 - Avg Loss: 175.8180\n",
            "Epoch [5/50] - Batch loss: 163.8586 - Epoch Loss: 1922.0384 - Avg Loss: 174.7308\n",
            "Epoch [5/50] - Batch loss: 176.1793 - Epoch Loss: 2098.2177 - Avg Loss: 174.8515\n",
            "Epoch [5/50] - Batch loss: 173.8493 - Epoch Loss: 2272.0671 - Avg Loss: 174.7744\n",
            "Epoch [5/50] - Batch loss: 178.6715 - Epoch Loss: 2450.7386 - Avg Loss: 175.0528\n",
            "Epoch [5/50] - Batch loss: 175.1998 - Epoch Loss: 2625.9384 - Avg Loss: 175.0626\n",
            "Epoch [5/50] - Batch loss: 166.8730 - Epoch Loss: 2792.8114 - Avg Loss: 174.5507\n",
            "Epoch [5/50] - Batch loss: 172.5272 - Epoch Loss: 2965.3386 - Avg Loss: 174.4317\n",
            "Epoch [5/50] - Batch loss: 178.2795 - Epoch Loss: 3143.6181 - Avg Loss: 174.6454\n",
            "Epoch [5/50] - Batch loss: 166.7957 - Epoch Loss: 3310.4137 - Avg Loss: 174.2323\n",
            "Epoch [5/50] - Batch loss: 168.9121 - Epoch Loss: 3479.3259 - Avg Loss: 173.9663\n",
            "Epoch [5/50] - Batch loss: 172.0619 - Epoch Loss: 3651.3877 - Avg Loss: 173.8756\n",
            "Epoch [5/50] - Batch loss: 180.2340 - Epoch Loss: 3831.6218 - Avg Loss: 174.1646\n",
            "Epoch [5/50] - Batch loss: 174.0207 - Epoch Loss: 4005.6425 - Avg Loss: 174.1584\n",
            "Epoch [5/50] - Batch loss: 177.4243 - Epoch Loss: 4183.0667 - Avg Loss: 174.2944\n",
            "Epoch [5/50] - Batch loss: 174.4382 - Epoch Loss: 4357.5050 - Avg Loss: 174.3002\n",
            "Epoch [5/50] - Batch loss: 174.1824 - Epoch Loss: 4531.6873 - Avg Loss: 174.2957\n",
            "Epoch [5/50] - Batch loss: 173.0115 - Epoch Loss: 4704.6989 - Avg Loss: 174.2481\n",
            "Epoch [5/50] - Batch loss: 168.8439 - Epoch Loss: 4873.5428 - Avg Loss: 174.0551\n",
            "Epoch [5/50] - Batch loss: 179.5438 - Epoch Loss: 5053.0865 - Avg Loss: 174.2444\n",
            "Epoch [5/50] - Batch loss: 174.3820 - Epoch Loss: 5227.4686 - Avg Loss: 174.2490\n",
            "Epoch [5/50] - Batch loss: 170.6377 - Epoch Loss: 5398.1062 - Avg Loss: 174.1325\n",
            "Epoch [5/50] - Batch loss: 178.4067 - Epoch Loss: 5576.5129 - Avg Loss: 174.2660\n",
            "Epoch [5/50] - Batch loss: 174.9799 - Epoch Loss: 5751.4928 - Avg Loss: 174.2877\n",
            "Epoch [5/50] - Batch loss: 170.5670 - Epoch Loss: 5922.0598 - Avg Loss: 174.1782\n",
            "Epoch [5/50] - Batch loss: 175.6812 - Epoch Loss: 6097.7410 - Avg Loss: 174.2212\n",
            "Epoch [5/50] - Batch loss: 171.4461 - Epoch Loss: 6269.1872 - Avg Loss: 174.1441\n",
            "Epoch [5/50] - Batch loss: 187.7610 - Epoch Loss: 6456.9482 - Avg Loss: 174.5121\n",
            "Epoch [5/50] - Batch loss: 176.5697 - Epoch Loss: 6633.5179 - Avg Loss: 174.5663\n",
            "Epoch [5/50] - Batch loss: 172.1613 - Epoch Loss: 6805.6792 - Avg Loss: 174.5046\n",
            "Epoch [5/50] - Batch loss: 174.2824 - Epoch Loss: 6979.9616 - Avg Loss: 174.4990\n",
            "Epoch [5/50] - Batch loss: 182.7160 - Epoch Loss: 7162.6776 - Avg Loss: 174.6995\n",
            "Epoch [5/50] - Batch loss: 174.1088 - Epoch Loss: 7336.7864 - Avg Loss: 174.6854\n",
            "Epoch [5/50] - Batch loss: 177.2680 - Epoch Loss: 7514.0544 - Avg Loss: 174.7455\n",
            "Epoch [5/50] - Batch loss: 170.8687 - Epoch Loss: 7684.9232 - Avg Loss: 174.6573\n",
            "Epoch [5/50] - Batch loss: 176.0882 - Epoch Loss: 7861.0114 - Avg Loss: 174.6891\n",
            "Epoch [5/50] - Batch loss: 170.7590 - Epoch Loss: 8031.7704 - Avg Loss: 174.6037\n",
            "Epoch [5/50] - Batch loss: 174.0416 - Epoch Loss: 8205.8120 - Avg Loss: 174.5917\n",
            "Epoch [5/50] - Batch loss: 178.8593 - Epoch Loss: 8384.6712 - Avg Loss: 174.6807\n",
            "Epoch [5/50] - Batch loss: 168.7155 - Epoch Loss: 8553.3868 - Avg Loss: 174.5589\n",
            "Epoch [5/50] - Batch loss: 180.2469 - Epoch Loss: 8733.6337 - Avg Loss: 174.6727\n",
            "Epoch [5/50] - Batch loss: 167.3236 - Epoch Loss: 8900.9573 - Avg Loss: 174.5286\n",
            "Epoch [5/50] - Batch loss: 178.3873 - Epoch Loss: 9079.3446 - Avg Loss: 174.6028\n",
            "Epoch [5/50] - Batch loss: 174.1255 - Epoch Loss: 9253.4701 - Avg Loss: 174.5938\n",
            "Epoch [5/50] - Batch loss: 174.4674 - Epoch Loss: 9427.9375 - Avg Loss: 174.5914\n",
            "Epoch [5/50] - Batch loss: 171.9883 - Epoch Loss: 9599.9258 - Avg Loss: 174.5441\n",
            "Epoch [5/50] - Batch loss: 169.1209 - Epoch Loss: 9769.0466 - Avg Loss: 174.4473\n",
            "Epoch [5/50] - Batch loss: 172.0726 - Epoch Loss: 9941.1192 - Avg Loss: 174.4056\n",
            "Epoch [5/50] - Batch loss: 167.7807 - Epoch Loss: 10108.8999 - Avg Loss: 174.2914\n",
            "Epoch [5/50] - Batch loss: 169.3205 - Epoch Loss: 10278.2204 - Avg Loss: 174.2071\n",
            "Epoch [5/50] - Batch loss: 175.7858 - Epoch Loss: 10454.0062 - Avg Loss: 174.2334\n",
            "Epoch [5/50] - Batch loss: 175.6647 - Epoch Loss: 10629.6709 - Avg Loss: 174.2569\n",
            "Epoch [5/50] - Batch loss: 172.7699 - Epoch Loss: 10802.4407 - Avg Loss: 174.2329\n",
            "Epoch [5/50] - Batch loss: 176.0894 - Epoch Loss: 10978.5302 - Avg Loss: 174.2624\n",
            "Epoch [5/50] - Batch loss: 178.6049 - Epoch Loss: 11157.1351 - Avg Loss: 174.3302\n",
            "Epoch [5/50] - Batch loss: 169.6223 - Epoch Loss: 11326.7574 - Avg Loss: 174.2578\n",
            "Epoch [5/50] - Batch loss: 176.4722 - Epoch Loss: 11503.2296 - Avg Loss: 174.2914\n",
            "Epoch [5/50] - Batch loss: 167.6223 - Epoch Loss: 11670.8519 - Avg Loss: 174.1918\n",
            "Epoch [5/50] - Batch loss: 173.2410 - Epoch Loss: 11844.0930 - Avg Loss: 174.1778\n",
            "Epoch [5/50] - Batch loss: 168.0306 - Epoch Loss: 12012.1236 - Avg Loss: 174.0887\n",
            "Epoch [5/50] - Batch loss: 166.1210 - Epoch Loss: 12178.2446 - Avg Loss: 173.9749\n",
            "Epoch [5/50] - Batch loss: 181.1742 - Epoch Loss: 12359.4187 - Avg Loss: 174.0763\n",
            "Epoch [5/50] - Batch loss: 175.9193 - Epoch Loss: 12535.3380 - Avg Loss: 174.1019\n",
            "Epoch [5/50] - Batch loss: 170.6911 - Epoch Loss: 12706.0291 - Avg Loss: 174.0552\n",
            "Epoch [5/50] - Batch loss: 172.9214 - Epoch Loss: 12878.9505 - Avg Loss: 174.0399\n",
            "Epoch [5/50] - Batch loss: 174.7465 - Epoch Loss: 13053.6971 - Avg Loss: 174.0493\n",
            "Epoch [5/50] - Batch loss: 168.9037 - Epoch Loss: 13222.6008 - Avg Loss: 173.9816\n",
            "Epoch [5/50] - Batch loss: 177.8855 - Epoch Loss: 13400.4863 - Avg Loss: 174.0323\n",
            "Epoch [5/50] - Batch loss: 179.7428 - Epoch Loss: 13580.2291 - Avg Loss: 174.1055\n",
            "Epoch [5/50] - Batch loss: 175.8798 - Epoch Loss: 13756.1089 - Avg Loss: 174.1280\n",
            "Epoch [5/50] - Batch loss: 175.2509 - Epoch Loss: 13931.3598 - Avg Loss: 174.1420\n",
            "Epoch [5/50] - Batch loss: 170.6569 - Epoch Loss: 14102.0167 - Avg Loss: 174.0990\n",
            "Epoch [5/50] - Batch loss: 165.0321 - Epoch Loss: 14267.0488 - Avg Loss: 173.9884\n",
            "Epoch [5/50] - Batch loss: 166.6987 - Epoch Loss: 14433.7475 - Avg Loss: 173.9006\n",
            "Epoch [5/50] - Batch loss: 169.9150 - Epoch Loss: 14603.6626 - Avg Loss: 173.8531\n",
            "Epoch [5/50] - Batch loss: 180.0701 - Epoch Loss: 14783.7327 - Avg Loss: 173.9263\n",
            "Epoch [5/50] - Batch loss: 173.7610 - Epoch Loss: 14957.4937 - Avg Loss: 173.9243\n",
            "Epoch [5/50] - Batch loss: 166.8701 - Epoch Loss: 15124.3638 - Avg Loss: 173.8433\n",
            "Epoch [5/50] - Batch loss: 173.4991 - Epoch Loss: 15297.8629 - Avg Loss: 173.8394\n",
            "Epoch [5/50] - Batch loss: 181.6698 - Epoch Loss: 15479.5327 - Avg Loss: 173.9273\n",
            "Epoch [5/50] - Batch loss: 176.0225 - Epoch Loss: 15655.5552 - Avg Loss: 173.9506\n",
            "Epoch [5/50] - Batch loss: 170.1834 - Epoch Loss: 15825.7386 - Avg Loss: 173.9092\n",
            "Epoch [5/50] - Batch loss: 168.6414 - Epoch Loss: 15994.3801 - Avg Loss: 173.8520\n",
            "Epoch [5/50] - Batch loss: 170.1576 - Epoch Loss: 16164.5377 - Avg Loss: 173.8122\n",
            "Epoch [5/50] - Batch loss: 174.6447 - Epoch Loss: 16339.1823 - Avg Loss: 173.8211\n",
            "Epoch [5/50] - Batch loss: 172.2171 - Epoch Loss: 16511.3995 - Avg Loss: 173.8042\n",
            "Epoch [5/50] - Batch loss: 170.0164 - Epoch Loss: 16681.4158 - Avg Loss: 173.7647\n",
            "Epoch [5/50] - Batch loss: 168.5083 - Epoch Loss: 16849.9241 - Avg Loss: 173.7106\n",
            "Epoch [5/50] - Batch loss: 166.2244 - Epoch Loss: 17016.1485 - Avg Loss: 173.6342\n",
            "Epoch [5/50] - Batch loss: 174.1620 - Epoch Loss: 17190.3105 - Avg Loss: 173.6395\n",
            "Epoch [5/50] - Batch loss: 180.6338 - Epoch Loss: 17370.9443 - Avg Loss: 173.7094\n",
            "Epoch [5/50] - Batch loss: 170.7883 - Epoch Loss: 17541.7326 - Avg Loss: 173.6805\n",
            "Epoch [5/50] - Batch loss: 172.7328 - Epoch Loss: 17714.4653 - Avg Loss: 173.6712\n",
            "Epoch [5/50] - Batch loss: 177.0289 - Epoch Loss: 17891.4943 - Avg Loss: 173.7038\n",
            "Epoch [5/50] - Batch loss: 174.8234 - Epoch Loss: 18066.3177 - Avg Loss: 173.7146\n",
            "Epoch [5/50] - Batch loss: 168.8474 - Epoch Loss: 18235.1651 - Avg Loss: 173.6682\n",
            "Epoch [5/50] - Batch loss: 170.8610 - Epoch Loss: 18406.0261 - Avg Loss: 173.6418\n",
            "Epoch [5/50] - Batch loss: 167.5754 - Epoch Loss: 18573.6015 - Avg Loss: 173.5851\n",
            "Epoch [5/50] - Batch loss: 172.9044 - Epoch Loss: 18746.5059 - Avg Loss: 173.5788\n",
            "Epoch [5/50] - Batch loss: 179.2334 - Epoch Loss: 18925.7393 - Avg Loss: 173.6306\n",
            "Epoch [5/50] - Batch loss: 168.0447 - Epoch Loss: 19093.7840 - Avg Loss: 173.5799\n",
            "Epoch [5/50] - Batch loss: 176.1167 - Epoch Loss: 19269.9007 - Avg Loss: 173.6027\n",
            "Epoch [5/50] - Batch loss: 164.9866 - Epoch Loss: 19434.8874 - Avg Loss: 173.5258\n",
            "Epoch [5/50] - Batch loss: 170.8730 - Epoch Loss: 19605.7604 - Avg Loss: 173.5023\n",
            "Epoch [5/50] - Batch loss: 173.1201 - Epoch Loss: 19778.8806 - Avg Loss: 173.4990\n",
            "Epoch [5/50] - Batch loss: 168.0895 - Epoch Loss: 19946.9700 - Avg Loss: 173.4519\n",
            "Epoch [5/50] - Batch loss: 172.0191 - Epoch Loss: 20118.9891 - Avg Loss: 173.4396\n",
            "Epoch [5/50] - Batch loss: 167.7664 - Epoch Loss: 20286.7555 - Avg Loss: 173.3911\n",
            "Epoch [5/50] - Batch loss: 167.1787 - Epoch Loss: 20453.9341 - Avg Loss: 173.3384\n",
            "Epoch [5/50] - Batch loss: 175.7293 - Epoch Loss: 20629.6634 - Avg Loss: 173.3585\n",
            "Epoch [5/50] - Batch loss: 173.9444 - Epoch Loss: 20803.6078 - Avg Loss: 173.3634\n",
            "Epoch [5/50] - Batch loss: 169.0478 - Epoch Loss: 20972.6556 - Avg Loss: 173.3277\n",
            "Epoch [5/50] - Batch loss: 177.6504 - Epoch Loss: 21150.3060 - Avg Loss: 173.3632\n",
            "Epoch [5/50] - Batch loss: 174.6157 - Epoch Loss: 21324.9217 - Avg Loss: 173.3733\n",
            "Epoch [5/50] - Batch loss: 173.7429 - Epoch Loss: 21498.6646 - Avg Loss: 173.3763\n",
            "Epoch [5/50] - Batch loss: 168.4856 - Epoch Loss: 21667.1502 - Avg Loss: 173.3372\n",
            "Epoch [5/50] - Batch loss: 170.9803 - Epoch Loss: 21838.1304 - Avg Loss: 173.3185\n",
            "Epoch [5/50] - Batch loss: 164.8566 - Epoch Loss: 22002.9870 - Avg Loss: 173.2519\n",
            "Epoch [5/50] - Batch loss: 177.4538 - Epoch Loss: 22180.4408 - Avg Loss: 173.2847\n",
            "Epoch [5/50] - Batch loss: 174.9268 - Epoch Loss: 22355.3676 - Avg Loss: 173.2974\n",
            "Epoch [5/50] - Batch loss: 172.1893 - Epoch Loss: 22527.5569 - Avg Loss: 173.2889\n",
            "Epoch [5/50] - Batch loss: 167.8571 - Epoch Loss: 22695.4140 - Avg Loss: 173.2474\n",
            "Epoch [5/50] - Batch loss: 176.4391 - Epoch Loss: 22871.8532 - Avg Loss: 173.2716\n",
            "Epoch [5/50] - Batch loss: 168.6073 - Epoch Loss: 23040.4604 - Avg Loss: 173.2365\n",
            "Epoch [5/50] - Batch loss: 173.8651 - Epoch Loss: 23214.3255 - Avg Loss: 173.2412\n",
            "Epoch [5/50] - Batch loss: 174.5062 - Epoch Loss: 23388.8317 - Avg Loss: 173.2506\n",
            "Epoch [5/50] - Batch loss: 169.2444 - Epoch Loss: 23558.0761 - Avg Loss: 173.2211\n",
            "Epoch [5/50] - Batch loss: 168.3397 - Epoch Loss: 23726.4158 - Avg Loss: 173.1855\n",
            "Epoch [5/50] - Batch loss: 172.1689 - Epoch Loss: 23898.5847 - Avg Loss: 173.1781\n",
            "Epoch [5/50] - Batch loss: 173.7681 - Epoch Loss: 24072.3528 - Avg Loss: 173.1824\n",
            "Epoch [5/50] - Batch loss: 172.1040 - Epoch Loss: 24244.4567 - Avg Loss: 173.1747\n",
            "Epoch [5/50] - Batch loss: 171.3432 - Epoch Loss: 24415.8000 - Avg Loss: 173.1617\n",
            "Epoch [5/50] - Batch loss: 173.1503 - Epoch Loss: 24588.9503 - Avg Loss: 173.1616\n",
            "Epoch [5/50] - Batch loss: 172.0539 - Epoch Loss: 24761.0042 - Avg Loss: 173.1539\n",
            "Epoch [5/50] - Batch loss: 172.4984 - Epoch Loss: 24933.5026 - Avg Loss: 173.1493\n",
            "Epoch [5/50] - Batch loss: 169.6341 - Epoch Loss: 25103.1367 - Avg Loss: 173.1251\n",
            "Epoch [5/50] - Batch loss: 173.5951 - Epoch Loss: 25276.7318 - Avg Loss: 173.1283\n",
            "Epoch [5/50] - Batch loss: 175.3698 - Epoch Loss: 25452.1016 - Avg Loss: 173.1435\n",
            "Epoch [5/50] - Batch loss: 167.6249 - Epoch Loss: 25619.7265 - Avg Loss: 173.1063\n",
            "Epoch [5/50] - Batch loss: 176.5906 - Epoch Loss: 25796.3172 - Avg Loss: 173.1296\n",
            "Epoch [5/50] - Batch loss: 170.3900 - Epoch Loss: 25966.7072 - Avg Loss: 173.1114\n",
            "Epoch [5/50] - Batch loss: 167.4029 - Epoch Loss: 26134.1101 - Avg Loss: 173.0736\n",
            "Epoch [5/50] - Batch loss: 173.6823 - Epoch Loss: 26307.7924 - Avg Loss: 173.0776\n",
            "Epoch [5/50] - Batch loss: 176.9980 - Epoch Loss: 26484.7904 - Avg Loss: 173.1032\n",
            "Epoch [5/50] - Batch loss: 172.5142 - Epoch Loss: 26657.3046 - Avg Loss: 173.0994\n",
            "Epoch [5/50] - Batch loss: 176.0125 - Epoch Loss: 26833.3171 - Avg Loss: 173.1182\n",
            "Epoch [5/50] - Batch loss: 175.5515 - Epoch Loss: 27008.8686 - Avg Loss: 173.1338\n",
            "Epoch [5/50] - Batch loss: 169.4358 - Epoch Loss: 27178.3044 - Avg Loss: 173.1102\n",
            "Epoch [5/50] - Batch loss: 169.4278 - Epoch Loss: 27347.7322 - Avg Loss: 173.0869\n",
            "Epoch [5/50] - Batch loss: 169.0513 - Epoch Loss: 27516.7835 - Avg Loss: 173.0615\n",
            "Epoch [5/50] - Batch loss: 167.7593 - Epoch Loss: 27684.5428 - Avg Loss: 173.0284\n",
            "Epoch [5/50] - Batch loss: 177.5441 - Epoch Loss: 27862.0868 - Avg Loss: 173.0564\n",
            "Epoch [5/50] - Batch loss: 174.8864 - Epoch Loss: 28036.9732 - Avg Loss: 173.0677\n",
            "Epoch [5/50] - Batch loss: 168.2485 - Epoch Loss: 28205.2217 - Avg Loss: 173.0382\n",
            "Epoch [5/50] - Batch loss: 167.3322 - Epoch Loss: 28372.5539 - Avg Loss: 173.0034\n",
            "Epoch [5/50] - Batch loss: 169.7728 - Epoch Loss: 28542.3266 - Avg Loss: 172.9838\n",
            "Epoch [5/50] - Batch loss: 168.7322 - Epoch Loss: 28711.0589 - Avg Loss: 172.9582\n",
            "Epoch [5/50] - Batch loss: 173.4812 - Epoch Loss: 28884.5400 - Avg Loss: 172.9613\n",
            "Epoch [5/50] - Batch loss: 179.1335 - Epoch Loss: 29063.6735 - Avg Loss: 172.9981\n",
            "Epoch [5/50] - Batch loss: 174.2111 - Epoch Loss: 29237.8846 - Avg Loss: 173.0052\n",
            "Epoch [5/50] - Batch loss: 173.9668 - Epoch Loss: 29411.8514 - Avg Loss: 173.0109\n",
            "Epoch [5/50] - Batch loss: 173.4637 - Epoch Loss: 29585.3151 - Avg Loss: 173.0135\n",
            "Epoch [5/50] - Batch loss: 169.0578 - Epoch Loss: 29754.3729 - Avg Loss: 172.9905\n",
            "Epoch [5/50] - Batch loss: 165.4659 - Epoch Loss: 29919.8387 - Avg Loss: 172.9470\n",
            "Epoch [5/50] - Batch loss: 166.7646 - Epoch Loss: 30086.6033 - Avg Loss: 172.9115\n",
            "Epoch [5/50] - Batch loss: 175.1301 - Epoch Loss: 30261.7334 - Avg Loss: 172.9242\n",
            "Epoch [5/50] - Batch loss: 168.8563 - Epoch Loss: 30430.5896 - Avg Loss: 172.9011\n",
            "Epoch [5/50] - Batch loss: 170.5408 - Epoch Loss: 30601.1304 - Avg Loss: 172.8877\n",
            "Epoch [5/50] - Batch loss: 166.0256 - Epoch Loss: 30767.1560 - Avg Loss: 172.8492\n",
            "Epoch [5/50] - Batch loss: 170.0905 - Epoch Loss: 30937.2465 - Avg Loss: 172.8338\n",
            "Epoch [5/50] - Batch loss: 179.3472 - Epoch Loss: 31116.5937 - Avg Loss: 172.8700\n",
            "Epoch [5/50] - Batch loss: 174.7523 - Epoch Loss: 31291.3459 - Avg Loss: 172.8804\n",
            "Epoch [5/50] - Batch loss: 173.9712 - Epoch Loss: 31465.3172 - Avg Loss: 172.8864\n",
            "Epoch [5/50] - Batch loss: 175.2688 - Epoch Loss: 31640.5859 - Avg Loss: 172.8994\n",
            "Epoch [5/50] - Batch loss: 171.5390 - Epoch Loss: 31812.1249 - Avg Loss: 172.8920\n",
            "Epoch [5/50] - Batch loss: 170.9753 - Epoch Loss: 31983.1002 - Avg Loss: 172.8816\n",
            "Epoch [5/50] - Batch loss: 166.5978 - Epoch Loss: 32149.6980 - Avg Loss: 172.8478\n",
            "Epoch [5/50] - Batch loss: 168.8798 - Epoch Loss: 32318.5778 - Avg Loss: 172.8266\n",
            "Epoch [5/50] - Batch loss: 168.1468 - Epoch Loss: 32486.7246 - Avg Loss: 172.8017\n",
            "Epoch [5/50] - Batch loss: 176.0688 - Epoch Loss: 32662.7934 - Avg Loss: 172.8190\n",
            "Epoch [5/50] - Batch loss: 165.9282 - Epoch Loss: 32828.7216 - Avg Loss: 172.7827\n",
            "Epoch [5/50] - Batch loss: 167.9540 - Epoch Loss: 32996.6756 - Avg Loss: 172.7575\n",
            "Epoch [5/50] - Batch loss: 168.3263 - Epoch Loss: 33165.0018 - Avg Loss: 172.7344\n",
            "Epoch [5/50] - Batch loss: 170.1953 - Epoch Loss: 33335.1971 - Avg Loss: 172.7212\n",
            "Epoch [5/50] - Batch loss: 171.2695 - Epoch Loss: 33506.4666 - Avg Loss: 172.7137\n",
            "Epoch [5/50] - Batch loss: 175.9154 - Epoch Loss: 33682.3820 - Avg Loss: 172.7302\n",
            "Epoch [5/50] - Batch loss: 161.4536 - Epoch Loss: 33843.8356 - Avg Loss: 172.6726\n",
            "Epoch [5/50] - Batch loss: 166.7060 - Epoch Loss: 34010.5415 - Avg Loss: 172.6423\n",
            "Epoch [5/50] - Batch loss: 169.4551 - Epoch Loss: 34179.9967 - Avg Loss: 172.6262\n",
            "Epoch [5/50] - Batch loss: 171.7478 - Epoch Loss: 34351.7445 - Avg Loss: 172.6218\n",
            "Epoch [5/50] - Batch loss: 171.5430 - Epoch Loss: 34523.2875 - Avg Loss: 172.6164\n",
            "Epoch [5/50] - Batch loss: 170.1982 - Epoch Loss: 34693.4857 - Avg Loss: 172.6044\n",
            "Epoch [5/50] - Batch loss: 167.1623 - Epoch Loss: 34860.6480 - Avg Loss: 172.5775\n",
            "Epoch [5/50] - Batch loss: 170.0390 - Epoch Loss: 35030.6870 - Avg Loss: 172.5650\n",
            "Epoch [5/50] - Batch loss: 172.6940 - Epoch Loss: 35203.3810 - Avg Loss: 172.5656\n",
            "Epoch [5/50] - Batch loss: 166.4391 - Epoch Loss: 35369.8201 - Avg Loss: 172.5357\n",
            "Epoch [5/50] - Batch loss: 172.3797 - Epoch Loss: 35542.1998 - Avg Loss: 172.5350\n",
            "Epoch [5/50] - Batch loss: 169.3644 - Epoch Loss: 35711.5642 - Avg Loss: 172.5196\n",
            "Epoch [5/50] - Batch loss: 174.2063 - Epoch Loss: 35885.7704 - Avg Loss: 172.5277\n",
            "Epoch [5/50] - Batch loss: 171.4212 - Epoch Loss: 36057.1917 - Avg Loss: 172.5224\n",
            "Epoch [5/50] - Batch loss: 168.9495 - Epoch Loss: 36226.1412 - Avg Loss: 172.5054\n",
            "Epoch [5/50] - Batch loss: 171.6048 - Epoch Loss: 36397.7460 - Avg Loss: 172.5012\n",
            "Epoch [5/50] - Batch loss: 165.2843 - Epoch Loss: 36563.0304 - Avg Loss: 172.4671\n",
            "Epoch [5/50] - Batch loss: 171.6666 - Epoch Loss: 36734.6970 - Avg Loss: 172.4634\n",
            "Epoch [5/50] - Batch loss: 169.6752 - Epoch Loss: 36904.3722 - Avg Loss: 172.4503\n",
            "Epoch [5/50] - Batch loss: 168.7771 - Epoch Loss: 37073.1493 - Avg Loss: 172.4333\n",
            "Epoch [5/50] - Batch loss: 172.9084 - Epoch Loss: 37246.0577 - Avg Loss: 172.4355\n",
            "Epoch [5/50] - Batch loss: 168.0622 - Epoch Loss: 37414.1198 - Avg Loss: 172.4153\n",
            "Epoch [5/50] - Batch loss: 175.6278 - Epoch Loss: 37589.7476 - Avg Loss: 172.4300\n",
            "Epoch [5/50] - Batch loss: 168.3335 - Epoch Loss: 37758.0811 - Avg Loss: 172.4113\n",
            "Epoch [5/50] - Batch loss: 170.5159 - Epoch Loss: 37928.5970 - Avg Loss: 172.4027\n",
            "Epoch [5/50] - Batch loss: 170.4324 - Epoch Loss: 38099.0294 - Avg Loss: 172.3938\n",
            "Epoch [5/50] - Batch loss: 176.3638 - Epoch Loss: 38275.3932 - Avg Loss: 172.4117\n",
            "Epoch [5/50] - Batch loss: 162.7718 - Epoch Loss: 38438.1650 - Avg Loss: 172.3685\n",
            "Epoch [5/50] - Batch loss: 168.4233 - Epoch Loss: 38606.5883 - Avg Loss: 172.3508\n",
            "Epoch [5/50] - Batch loss: 168.3481 - Epoch Loss: 38774.9364 - Avg Loss: 172.3331\n",
            "Epoch [5/50] - Batch loss: 172.2058 - Epoch Loss: 38947.1422 - Avg Loss: 172.3325\n",
            "Epoch [5/50] - Batch loss: 167.1459 - Epoch Loss: 39114.2881 - Avg Loss: 172.3096\n",
            "Epoch [5/50] - Batch loss: 172.4778 - Epoch Loss: 39286.7660 - Avg Loss: 172.3104\n",
            "Epoch [5/50] - Batch loss: 172.5984 - Epoch Loss: 39459.3644 - Avg Loss: 172.3116\n",
            "Epoch [5/50] - Batch loss: 177.4659 - Epoch Loss: 39636.8304 - Avg Loss: 172.3340\n",
            "Epoch [5/50] - Batch loss: 174.5058 - Epoch Loss: 39811.3362 - Avg Loss: 172.3434\n",
            "Epoch [5/50] - Batch loss: 166.3875 - Epoch Loss: 39977.7237 - Avg Loss: 172.3178\n",
            "Epoch [5/50] - Batch loss: 169.0025 - Epoch Loss: 40146.7261 - Avg Loss: 172.3035\n",
            "Epoch [5/50] - Batch loss: 169.5961 - Epoch Loss: 40316.3223 - Avg Loss: 172.2920\n",
            "Epoch [5/50] - Batch loss: 173.9597 - Epoch Loss: 40490.2820 - Avg Loss: 172.2991\n",
            "Epoch [5/50] - Batch loss: 169.6803 - Epoch Loss: 40659.9623 - Avg Loss: 172.2880\n",
            "Epoch [5/50] - Batch loss: 182.5929 - Epoch Loss: 40842.5552 - Avg Loss: 172.3315\n",
            "Epoch [5/50] - Batch loss: 174.9864 - Epoch Loss: 41017.5416 - Avg Loss: 172.3426\n",
            "Epoch [5/50] - Batch loss: 172.3946 - Epoch Loss: 41189.9362 - Avg Loss: 172.3428\n",
            "Epoch [5/50] - Batch loss: 173.7643 - Epoch Loss: 41363.7005 - Avg Loss: 172.3488\n",
            "Epoch [5/50] - Batch loss: 176.0356 - Epoch Loss: 41539.7361 - Avg Loss: 172.3641\n",
            "Epoch [5/50] - Batch loss: 169.8204 - Epoch Loss: 41709.5565 - Avg Loss: 172.3535\n",
            "Epoch [5/50] - Batch loss: 165.6560 - Epoch Loss: 41875.2125 - Avg Loss: 172.3260\n",
            "Epoch [5/50] - Batch loss: 172.0093 - Epoch Loss: 42047.2218 - Avg Loss: 172.3247\n",
            "Epoch [5/50] - Batch loss: 170.6610 - Epoch Loss: 42217.8828 - Avg Loss: 172.3179\n",
            "Epoch [5/50] - Batch loss: 173.0066 - Epoch Loss: 42390.8894 - Avg Loss: 172.3207\n",
            "Epoch [5/50] - Batch loss: 171.5561 - Epoch Loss: 42562.4455 - Avg Loss: 172.3176\n",
            "Epoch [5/50] - Batch loss: 173.0810 - Epoch Loss: 42735.5265 - Avg Loss: 172.3207\n",
            "Epoch [5/50] - Batch loss: 168.4672 - Epoch Loss: 42903.9937 - Avg Loss: 172.3052\n",
            "Epoch [5/50] - Batch loss: 170.4644 - Epoch Loss: 43074.4581 - Avg Loss: 172.2978\n",
            "Epoch [5/50] - Batch loss: 173.0417 - Epoch Loss: 43247.4998 - Avg Loss: 172.3008\n",
            "Epoch [5/50] - Batch loss: 175.3068 - Epoch Loss: 43422.8066 - Avg Loss: 172.3127\n",
            "Epoch [5/50] - Batch loss: 174.2851 - Epoch Loss: 43597.0917 - Avg Loss: 172.3205\n",
            "Epoch [5/50] - Batch loss: 175.7524 - Epoch Loss: 43772.8441 - Avg Loss: 172.3340\n",
            "Epoch [5/50] - Batch loss: 171.8599 - Epoch Loss: 43944.7040 - Avg Loss: 172.3322\n",
            "Epoch [5/50] - Batch loss: 174.0912 - Epoch Loss: 44118.7953 - Avg Loss: 172.3390\n",
            "Epoch [5/50] - Batch loss: 173.1665 - Epoch Loss: 44291.9618 - Avg Loss: 172.3423\n",
            "Epoch [5/50] - Batch loss: 171.6395 - Epoch Loss: 44463.6013 - Avg Loss: 172.3395\n",
            "Epoch [5/50] - Batch loss: 173.3761 - Epoch Loss: 44636.9775 - Avg Loss: 172.3435\n",
            "Epoch [5/50] - Batch loss: 176.0800 - Epoch Loss: 44813.0575 - Avg Loss: 172.3579\n",
            "Epoch [5/50] - Batch loss: 174.9555 - Epoch Loss: 44988.0130 - Avg Loss: 172.3679\n",
            "Epoch [5/50] - Batch loss: 174.5766 - Epoch Loss: 45162.5896 - Avg Loss: 172.3763\n",
            "Epoch [5/50] - Batch loss: 173.1398 - Epoch Loss: 45335.7294 - Avg Loss: 172.3792\n",
            "Epoch [5/50] - Batch loss: 174.5322 - Epoch Loss: 45510.2616 - Avg Loss: 172.3874\n",
            "Epoch [5/50] - Batch loss: 169.9062 - Epoch Loss: 45680.1678 - Avg Loss: 172.3780\n",
            "Epoch [5/50] - Batch loss: 170.1397 - Epoch Loss: 45850.3075 - Avg Loss: 172.3696\n",
            "Epoch [5/50] - Batch loss: 165.3187 - Epoch Loss: 46015.6262 - Avg Loss: 172.3432\n",
            "Epoch [5/50] - Batch loss: 168.7925 - Epoch Loss: 46184.4187 - Avg Loss: 172.3299\n",
            "Epoch [5/50] - Batch loss: 168.3432 - Epoch Loss: 46352.7619 - Avg Loss: 172.3151\n",
            "Epoch [5/50] - Batch loss: 174.0993 - Epoch Loss: 46526.8613 - Avg Loss: 172.3217\n",
            "Epoch [5/50] - Batch loss: 169.5992 - Epoch Loss: 46696.4604 - Avg Loss: 172.3117\n",
            "Epoch [5/50] - Batch loss: 168.0359 - Epoch Loss: 46864.4963 - Avg Loss: 172.2959\n",
            "Epoch [5/50] - Batch loss: 173.5486 - Epoch Loss: 47038.0449 - Avg Loss: 172.3005\n",
            "Epoch [5/50] - Batch loss: 173.3598 - Epoch Loss: 47211.4047 - Avg Loss: 172.3044\n",
            "Epoch [5/50] - Batch loss: 173.4008 - Epoch Loss: 47384.8055 - Avg Loss: 172.3084\n",
            "Epoch [5/50] - Batch loss: 172.2887 - Epoch Loss: 47557.0941 - Avg Loss: 172.3083\n",
            "Epoch [5/50] - Batch loss: 161.9005 - Epoch Loss: 47718.9946 - Avg Loss: 172.2707\n",
            "Epoch [5/50] - Batch loss: 173.7090 - Epoch Loss: 47892.7035 - Avg Loss: 172.2759\n",
            "Epoch [5/50] - Batch loss: 165.9575 - Epoch Loss: 48058.6610 - Avg Loss: 172.2533\n",
            "Epoch [5/50] - Batch loss: 170.8904 - Epoch Loss: 48229.5514 - Avg Loss: 172.2484\n",
            "Epoch [5/50] - Batch loss: 174.9360 - Epoch Loss: 48404.4874 - Avg Loss: 172.2580\n",
            "Epoch [5/50] - Batch loss: 169.0343 - Epoch Loss: 48573.5217 - Avg Loss: 172.2465\n",
            "Epoch [5/50] - Batch loss: 168.5924 - Epoch Loss: 48742.1142 - Avg Loss: 172.2336\n",
            "Epoch [5/50] - Batch loss: 166.2481 - Epoch Loss: 48908.3622 - Avg Loss: 172.2125\n",
            "Epoch [5/50] - Batch loss: 172.6450 - Epoch Loss: 49081.0072 - Avg Loss: 172.2141\n",
            "Epoch [5/50] - Batch loss: 169.3421 - Epoch Loss: 49250.3494 - Avg Loss: 172.2040\n",
            "Epoch [5/50] - Batch loss: 164.0620 - Epoch Loss: 49414.4114 - Avg Loss: 172.1756\n",
            "Epoch [5/50] - Batch loss: 173.4651 - Epoch Loss: 49587.8765 - Avg Loss: 172.1801\n",
            "Epoch [5/50] - Batch loss: 166.3495 - Epoch Loss: 49754.2260 - Avg Loss: 172.1600\n",
            "Epoch [5/50] - Batch loss: 163.4533 - Epoch Loss: 49917.6792 - Avg Loss: 172.1299\n",
            "Epoch [5/50] - Batch loss: 170.6389 - Epoch Loss: 50088.3181 - Avg Loss: 172.1248\n",
            "Epoch [5/50] - Batch loss: 165.7572 - Epoch Loss: 50254.0753 - Avg Loss: 172.1030\n",
            "Epoch [5/50] - Batch loss: 175.5940 - Epoch Loss: 50429.6693 - Avg Loss: 172.1149\n",
            "Epoch [5/50] - Batch loss: 178.3375 - Epoch Loss: 50608.0069 - Avg Loss: 172.1361\n",
            "Epoch [5/50] - Batch loss: 173.4382 - Epoch Loss: 50781.4450 - Avg Loss: 172.1405\n",
            "Epoch [5/50] - Batch loss: 164.5601 - Epoch Loss: 50946.0051 - Avg Loss: 172.1149\n",
            "Epoch [5/50] - Batch loss: 174.4625 - Epoch Loss: 51120.4676 - Avg Loss: 172.1228\n",
            "Epoch [5/50] - Batch loss: 174.0449 - Epoch Loss: 51294.5125 - Avg Loss: 172.1292\n",
            "Epoch [5/50] - Batch loss: 174.7999 - Epoch Loss: 51469.3124 - Avg Loss: 172.1382\n",
            "Epoch [5/50] - Batch loss: 173.0722 - Epoch Loss: 51642.3846 - Avg Loss: 172.1413\n",
            "Epoch [5/50] - Batch loss: 156.4709 - Epoch Loss: 51798.8555 - Avg Loss: 172.0892\n",
            "Epoch [5/50] - Batch loss: 171.0551 - Epoch Loss: 51969.9106 - Avg Loss: 172.0858\n",
            "Epoch [5/50] - Batch loss: 163.8804 - Epoch Loss: 52133.7910 - Avg Loss: 172.0587\n",
            "Epoch [5/50] - Batch loss: 177.3424 - Epoch Loss: 52311.1334 - Avg Loss: 172.0761\n",
            "Epoch [5/50] - Batch loss: 173.9018 - Epoch Loss: 52485.0352 - Avg Loss: 172.0821\n",
            "Epoch [5/50] - Batch loss: 162.7978 - Epoch Loss: 52647.8330 - Avg Loss: 172.0517\n",
            "Epoch [5/50] - Batch loss: 168.5510 - Epoch Loss: 52816.3840 - Avg Loss: 172.0403\n",
            "Epoch [5/50] - Batch loss: 169.7704 - Epoch Loss: 52986.1544 - Avg Loss: 172.0330\n",
            "Epoch [5/50] - Batch loss: 167.5189 - Epoch Loss: 53153.6734 - Avg Loss: 172.0184\n",
            "Epoch [5/50] - Batch loss: 177.7547 - Epoch Loss: 53331.4280 - Avg Loss: 172.0369\n",
            "Epoch [5/50] - Batch loss: 177.1855 - Epoch Loss: 53508.6135 - Avg Loss: 172.0534\n",
            "Epoch [5/50] - Batch loss: 175.0214 - Epoch Loss: 53683.6349 - Avg Loss: 172.0629\n",
            "Epoch [5/50] - Batch loss: 167.4219 - Epoch Loss: 53851.0568 - Avg Loss: 172.0481\n",
            "Epoch [5/50] - Batch loss: 175.1744 - Epoch Loss: 54026.2311 - Avg Loss: 172.0581\n",
            "Epoch [5/50] - Batch loss: 171.1697 - Epoch Loss: 54197.4008 - Avg Loss: 172.0552\n",
            "Epoch [5/50] - Batch loss: 170.3383 - Epoch Loss: 54367.7391 - Avg Loss: 172.0498\n",
            "Epoch [5/50] - Batch loss: 170.1429 - Epoch Loss: 54537.8820 - Avg Loss: 172.0438\n",
            "Epoch [5/50] - Batch loss: 171.2617 - Epoch Loss: 54709.1437 - Avg Loss: 172.0413\n",
            "Epoch [5/50] - Batch loss: 174.0571 - Epoch Loss: 54883.2008 - Avg Loss: 172.0477\n",
            "Epoch [5/50] - Batch loss: 175.2859 - Epoch Loss: 55058.4867 - Avg Loss: 172.0578\n",
            "Epoch [5/50] - Batch loss: 170.5546 - Epoch Loss: 55229.0413 - Avg Loss: 172.0531\n",
            "Epoch [5/50] - Batch loss: 164.4967 - Epoch Loss: 55393.5380 - Avg Loss: 172.0296\n",
            "Epoch [5/50] - Batch loss: 169.2169 - Epoch Loss: 55562.7549 - Avg Loss: 172.0209\n",
            "Epoch [5/50] - Batch loss: 168.8957 - Epoch Loss: 55731.6506 - Avg Loss: 172.0113\n",
            "Epoch [5/50] - Batch loss: 165.3655 - Epoch Loss: 55897.0161 - Avg Loss: 171.9908\n",
            "Epoch [5/50] - Batch loss: 169.6474 - Epoch Loss: 56066.6635 - Avg Loss: 171.9836\n",
            "Epoch [5/50] - Batch loss: 169.1373 - Epoch Loss: 56235.8008 - Avg Loss: 171.9749\n",
            "Epoch [5/50] - Batch loss: 167.3853 - Epoch Loss: 56403.1862 - Avg Loss: 171.9609\n",
            "Epoch [5/50] - Batch loss: 168.6075 - Epoch Loss: 56571.7937 - Avg Loss: 171.9507\n",
            "Epoch [5/50] - Batch loss: 178.7890 - Epoch Loss: 56750.5827 - Avg Loss: 171.9715\n",
            "Epoch [5/50] - Batch loss: 173.3168 - Epoch Loss: 56923.8995 - Avg Loss: 171.9755\n",
            "Epoch [5/50] - Batch loss: 169.1589 - Epoch Loss: 57093.0583 - Avg Loss: 171.9670\n",
            "Epoch [5/50] - Batch loss: 165.5575 - Epoch Loss: 57258.6159 - Avg Loss: 171.9478\n",
            "Epoch [5/50] - Batch loss: 169.5308 - Epoch Loss: 57428.1467 - Avg Loss: 171.9406\n",
            "Epoch [5/50] - Batch loss: 168.5783 - Epoch Loss: 57596.7249 - Avg Loss: 171.9305\n",
            "Epoch [5/50] - Batch loss: 173.5540 - Epoch Loss: 57770.2789 - Avg Loss: 171.9354\n",
            "Epoch [5/50] - Batch loss: 166.9647 - Epoch Loss: 57937.2436 - Avg Loss: 171.9206\n",
            "Epoch [5/50] - Batch loss: 169.7161 - Epoch Loss: 58106.9597 - Avg Loss: 171.9141\n",
            "Epoch [5/50] - Batch loss: 173.6876 - Epoch Loss: 58280.6473 - Avg Loss: 171.9193\n",
            "Epoch [5/50] - Batch loss: 180.3773 - Epoch Loss: 58461.0246 - Avg Loss: 171.9442\n",
            "Epoch [5/50] - Batch loss: 170.7977 - Epoch Loss: 58631.8223 - Avg Loss: 171.9408\n",
            "Epoch [5/50] - Batch loss: 173.0713 - Epoch Loss: 58804.8936 - Avg Loss: 171.9441\n",
            "Epoch [5/50] - Batch loss: 168.1182 - Epoch Loss: 58973.0118 - Avg Loss: 171.9330\n",
            "Epoch [5/50] - Batch loss: 174.9871 - Epoch Loss: 59147.9989 - Avg Loss: 171.9419\n",
            "Epoch [5/50] - Batch loss: 168.9058 - Epoch Loss: 59316.9047 - Avg Loss: 171.9331\n",
            "Epoch [5/50] - Batch loss: 175.5586 - Epoch Loss: 59492.4634 - Avg Loss: 171.9435\n",
            "Epoch [5/50] - Batch loss: 174.3283 - Epoch Loss: 59666.7917 - Avg Loss: 171.9504\n",
            "Epoch [5/50] - Batch loss: 177.5379 - Epoch Loss: 59844.3297 - Avg Loss: 171.9665\n",
            "Epoch [5/50] - Batch loss: 170.5787 - Epoch Loss: 60014.9084 - Avg Loss: 171.9625\n",
            "Epoch [5/50] - Batch loss: 163.4275 - Epoch Loss: 60178.3359 - Avg Loss: 171.9381\n",
            "Epoch [5/50] - Batch loss: 175.2035 - Epoch Loss: 60353.5394 - Avg Loss: 171.9474\n",
            "Epoch [5/50] - Batch loss: 165.7629 - Epoch Loss: 60519.3023 - Avg Loss: 171.9298\n",
            "Epoch [5/50] - Batch loss: 172.0371 - Epoch Loss: 60691.3394 - Avg Loss: 171.9301\n",
            "Epoch [5/50] - Batch loss: 170.5122 - Epoch Loss: 60861.8516 - Avg Loss: 171.9261\n",
            "Epoch [5/50] - Batch loss: 167.5531 - Epoch Loss: 61029.4047 - Avg Loss: 171.9138\n",
            "Epoch [5/50] - Batch loss: 165.5378 - Epoch Loss: 61194.9425 - Avg Loss: 171.8959\n",
            "Epoch [5/50] - Batch loss: 172.8714 - Epoch Loss: 61367.8139 - Avg Loss: 171.8986\n",
            "Epoch [5/50] - Batch loss: 171.8364 - Epoch Loss: 61539.6503 - Avg Loss: 171.8985\n",
            "Epoch [5/50] - Batch loss: 164.7348 - Epoch Loss: 61704.3851 - Avg Loss: 171.8785\n",
            "Epoch [5/50] - Batch loss: 163.8356 - Epoch Loss: 61868.2206 - Avg Loss: 171.8562\n",
            "Epoch [5/50] - Batch loss: 171.6775 - Epoch Loss: 62039.8982 - Avg Loss: 171.8557\n",
            "Epoch [5/50] - Batch loss: 165.6161 - Epoch Loss: 62205.5142 - Avg Loss: 171.8384\n",
            "Epoch [5/50] - Batch loss: 162.4859 - Epoch Loss: 62368.0001 - Avg Loss: 171.8127\n",
            "Epoch [5/50] - Batch loss: 171.7413 - Epoch Loss: 62539.7414 - Avg Loss: 171.8125\n",
            "Epoch [5/50] - Batch loss: 178.8062 - Epoch Loss: 62718.5476 - Avg Loss: 171.8316\n",
            "Epoch [5/50] - Batch loss: 170.5119 - Epoch Loss: 62889.0595 - Avg Loss: 171.8280\n",
            "Epoch [5/50] - Batch loss: 172.2992 - Epoch Loss: 63061.3587 - Avg Loss: 171.8293\n",
            "Epoch [5/50] - Batch loss: 169.0521 - Epoch Loss: 63230.4108 - Avg Loss: 171.8218\n",
            "Epoch [5/50] - Batch loss: 173.3644 - Epoch Loss: 63403.7752 - Avg Loss: 171.8259\n",
            "Epoch [5/50] - Batch loss: 167.6348 - Epoch Loss: 63571.4100 - Avg Loss: 171.8146\n",
            "Epoch [5/50] - Batch loss: 172.1400 - Epoch Loss: 63743.5500 - Avg Loss: 171.8155\n",
            "Epoch [5/50] - Batch loss: 167.2989 - Epoch Loss: 63910.8488 - Avg Loss: 171.8034\n",
            "Epoch [5/50] - Batch loss: 172.6112 - Epoch Loss: 64083.4601 - Avg Loss: 171.8055\n",
            "Epoch [5/50] - Batch loss: 175.4588 - Epoch Loss: 64258.9188 - Avg Loss: 171.8153\n",
            "Epoch [5/50] - Batch loss: 178.2091 - Epoch Loss: 64437.1279 - Avg Loss: 171.8323\n",
            "Epoch [5/50] - Batch loss: 167.3066 - Epoch Loss: 64604.4345 - Avg Loss: 171.8203\n",
            "Epoch [5/50] - Batch loss: 164.3691 - Epoch Loss: 64768.8036 - Avg Loss: 171.8005\n",
            "Epoch [5/50] - Batch loss: 165.8857 - Epoch Loss: 64934.6893 - Avg Loss: 171.7849\n",
            "Epoch [5/50] - Batch loss: 177.1812 - Epoch Loss: 65111.8705 - Avg Loss: 171.7991\n",
            "Epoch [5/50] - Batch loss: 160.2696 - Epoch Loss: 65272.1401 - Avg Loss: 171.7688\n",
            "Epoch [5/50] - Batch loss: 170.0422 - Epoch Loss: 65442.1823 - Avg Loss: 171.7643\n",
            "Epoch [5/50] - Batch loss: 171.6204 - Epoch Loss: 65613.8027 - Avg Loss: 171.7639\n",
            "Epoch [5/50] - Batch loss: 174.8239 - Epoch Loss: 65788.6266 - Avg Loss: 171.7719\n",
            "Epoch [5/50] - Batch loss: 186.1150 - Epoch Loss: 65974.7416 - Avg Loss: 171.8092\n",
            "Epoch [5/50] - Batch loss: 171.1220 - Epoch Loss: 66145.8636 - Avg Loss: 171.8074\n",
            "Epoch [5/50] - Batch loss: 171.9017 - Epoch Loss: 66317.7654 - Avg Loss: 171.8077\n",
            "Epoch [5/50] - Batch loss: 169.2941 - Epoch Loss: 66487.0595 - Avg Loss: 171.8012\n",
            "Epoch [5/50] - Batch loss: 168.3259 - Epoch Loss: 66655.3854 - Avg Loss: 171.7922\n",
            "Epoch [5/50] - Batch loss: 177.4419 - Epoch Loss: 66832.8273 - Avg Loss: 171.8068\n",
            "Epoch [5/50] - Batch loss: 172.9147 - Epoch Loss: 67005.7420 - Avg Loss: 171.8096\n",
            "Epoch [5/50] - Batch loss: 168.9290 - Epoch Loss: 67174.6709 - Avg Loss: 171.8022\n",
            "Epoch [5/50] - Batch loss: 168.2837 - Epoch Loss: 67342.9547 - Avg Loss: 171.7933\n",
            "Epoch [5/50] - Batch loss: 178.7033 - Epoch Loss: 67521.6579 - Avg Loss: 171.8108\n",
            "Epoch [5/50] - Batch loss: 171.4181 - Epoch Loss: 67693.0760 - Avg Loss: 171.8098\n",
            "Epoch [5/50] - Batch loss: 173.8787 - Epoch Loss: 67866.9547 - Avg Loss: 171.8151\n",
            "Epoch [5/50] - Batch loss: 171.7327 - Epoch Loss: 68038.6874 - Avg Loss: 171.8149\n",
            "Epoch [5/50] - Batch loss: 176.2763 - Epoch Loss: 68214.9637 - Avg Loss: 171.8261\n",
            "Epoch [5/50] - Batch loss: 169.9869 - Epoch Loss: 68384.9506 - Avg Loss: 171.8215\n",
            "Epoch [5/50] - Batch loss: 170.4035 - Epoch Loss: 68555.3540 - Avg Loss: 171.8179\n",
            "Epoch [5/50] - Batch loss: 168.5085 - Epoch Loss: 68723.8625 - Avg Loss: 171.8097\n",
            "Epoch [5/50] - Batch loss: 172.6250 - Epoch Loss: 68896.4875 - Avg Loss: 171.8117\n",
            "Epoch [5/50] - Batch loss: 164.7736 - Epoch Loss: 69061.2611 - Avg Loss: 171.7942\n",
            "Epoch [5/50] - Batch loss: 169.6151 - Epoch Loss: 69230.8763 - Avg Loss: 171.7888\n",
            "Epoch [5/50] - Batch loss: 174.4672 - Epoch Loss: 69405.3434 - Avg Loss: 171.7954\n",
            "Epoch [5/50] - Batch loss: 169.9297 - Epoch Loss: 69575.2731 - Avg Loss: 171.7908\n",
            "Epoch [5/50] - Batch loss: 172.0574 - Epoch Loss: 69747.3305 - Avg Loss: 171.7915\n",
            "Epoch [5/50] - Batch loss: 172.7129 - Epoch Loss: 69920.0434 - Avg Loss: 171.7937\n",
            "Epoch [5/50] - Batch loss: 170.6027 - Epoch Loss: 70090.6461 - Avg Loss: 171.7908\n",
            "Epoch [5/50] - Batch loss: 166.4712 - Epoch Loss: 70257.1173 - Avg Loss: 171.7778\n",
            "Epoch [5/50] - Batch loss: 173.1097 - Epoch Loss: 70430.2269 - Avg Loss: 171.7810\n",
            "Epoch [5/50] - Batch loss: 167.1037 - Epoch Loss: 70597.3307 - Avg Loss: 171.7697\n",
            "Epoch [5/50] - Batch loss: 168.7764 - Epoch Loss: 70766.1070 - Avg Loss: 171.7624\n",
            "Epoch [5/50] - Batch loss: 175.1059 - Epoch Loss: 70941.2130 - Avg Loss: 171.7705\n",
            "Epoch [5/50] - Batch loss: 170.9649 - Epoch Loss: 71112.1779 - Avg Loss: 171.7685\n",
            "Epoch [5/50] - Batch loss: 169.8544 - Epoch Loss: 71282.0323 - Avg Loss: 171.7639\n",
            "Epoch [5/50] - Batch loss: 161.4638 - Epoch Loss: 71443.4961 - Avg Loss: 171.7392\n",
            "Epoch [5/50] - Batch loss: 167.3627 - Epoch Loss: 71610.8588 - Avg Loss: 171.7287\n",
            "Epoch [5/50] - Batch loss: 174.2208 - Epoch Loss: 71785.0796 - Avg Loss: 171.7346\n",
            "Epoch [5/50] - Batch loss: 174.9761 - Epoch Loss: 71960.0557 - Avg Loss: 171.7424\n",
            "Epoch [5/50] - Batch loss: 173.1325 - Epoch Loss: 72133.1882 - Avg Loss: 171.7457\n",
            "Epoch [5/50] - Batch loss: 178.0314 - Epoch Loss: 72311.2196 - Avg Loss: 171.7606\n",
            "Epoch [5/50] - Batch loss: 163.2990 - Epoch Loss: 72474.5186 - Avg Loss: 171.7406\n",
            "Epoch [5/50] - Batch loss: 166.9209 - Epoch Loss: 72641.4395 - Avg Loss: 171.7292\n",
            "Epoch [5/50] - Batch loss: 175.7769 - Epoch Loss: 72817.2164 - Avg Loss: 171.7387\n",
            "Epoch [5/50] - Batch loss: 173.2778 - Epoch Loss: 72990.4942 - Avg Loss: 171.7423\n",
            "Epoch [5/50] - Batch loss: 171.4212 - Epoch Loss: 73161.9153 - Avg Loss: 171.7416\n",
            "Epoch [5/50] - Batch loss: 168.1526 - Epoch Loss: 73330.0679 - Avg Loss: 171.7332\n",
            "Epoch [5/50] - Batch loss: 168.4881 - Epoch Loss: 73498.5560 - Avg Loss: 171.7256\n",
            "Epoch [5/50] - Batch loss: 174.9079 - Epoch Loss: 73673.4639 - Avg Loss: 171.7330\n",
            "Epoch [5/50] - Batch loss: 167.7457 - Epoch Loss: 73841.2096 - Avg Loss: 171.7237\n",
            "Epoch [5/50] - Batch loss: 163.5273 - Epoch Loss: 74004.7368 - Avg Loss: 171.7047\n",
            "Epoch [5/50] - Batch loss: 165.0214 - Epoch Loss: 74169.7582 - Avg Loss: 171.6893\n",
            "Epoch [5/50] - Batch loss: 165.9688 - Epoch Loss: 74335.7271 - Avg Loss: 171.6760\n",
            "Epoch [5/50] - Batch loss: 174.0358 - Epoch Loss: 74509.7629 - Avg Loss: 171.6815\n",
            "Epoch [5/50] - Batch loss: 177.7186 - Epoch Loss: 74687.4814 - Avg Loss: 171.6954\n",
            "Epoch [5/50] - Batch loss: 168.5187 - Epoch Loss: 74856.0001 - Avg Loss: 171.6881\n",
            "Epoch [5/50] - Batch loss: 174.1129 - Epoch Loss: 75030.1130 - Avg Loss: 171.6936\n",
            "Epoch [5/50] - Batch loss: 169.9709 - Epoch Loss: 75200.0839 - Avg Loss: 171.6897\n",
            "Epoch [5/50] - Batch loss: 174.4163 - Epoch Loss: 75374.5001 - Avg Loss: 171.6959\n",
            "Epoch [5/50] - Batch loss: 173.2195 - Epoch Loss: 75547.7197 - Avg Loss: 171.6994\n",
            "Epoch [5/50] - Batch loss: 171.4937 - Epoch Loss: 75719.2134 - Avg Loss: 171.6989\n",
            "Epoch [5/50] - Batch loss: 165.9236 - Epoch Loss: 75885.1370 - Avg Loss: 171.6858\n",
            "Epoch [5/50] - Batch loss: 166.0785 - Epoch Loss: 76051.2155 - Avg Loss: 171.6732\n",
            "Epoch [5/50] - Batch loss: 170.6992 - Epoch Loss: 76221.9147 - Avg Loss: 171.6710\n",
            "Epoch [5/50] - Batch loss: 170.1247 - Epoch Loss: 76392.0394 - Avg Loss: 171.6675\n",
            "Epoch [5/50] - Batch loss: 170.7883 - Epoch Loss: 76562.8277 - Avg Loss: 171.6655\n",
            "Epoch [5/50] - Batch loss: 171.6740 - Epoch Loss: 76734.5017 - Avg Loss: 171.6656\n",
            "Epoch [5/50] - Batch loss: 169.7107 - Epoch Loss: 76904.2124 - Avg Loss: 171.6612\n",
            "Epoch [5/50] - Batch loss: 169.7477 - Epoch Loss: 77073.9601 - Avg Loss: 171.6569\n",
            "Epoch [5/50] - Batch loss: 172.0131 - Epoch Loss: 77245.9732 - Avg Loss: 171.6577\n",
            "Epoch [5/50] - Batch loss: 175.5318 - Epoch Loss: 77421.5051 - Avg Loss: 171.6663\n",
            "Epoch [5/50] - Batch loss: 171.7984 - Epoch Loss: 77593.3035 - Avg Loss: 171.6666\n",
            "Epoch [5/50] - Batch loss: 167.1022 - Epoch Loss: 77760.4057 - Avg Loss: 171.6565\n",
            "Epoch [5/50] - Batch loss: 174.9827 - Epoch Loss: 77935.3883 - Avg Loss: 171.6639\n",
            "Epoch [5/50] - Batch loss: 169.5269 - Epoch Loss: 78104.9153 - Avg Loss: 171.6592\n",
            "Epoch [5/50] - Batch loss: 169.1138 - Epoch Loss: 78274.0290 - Avg Loss: 171.6536\n",
            "Epoch [5/50] - Batch loss: 172.3830 - Epoch Loss: 78446.4120 - Avg Loss: 171.6552\n",
            "Epoch [5/50] - Batch loss: 173.9959 - Epoch Loss: 78620.4079 - Avg Loss: 171.6603\n",
            "Epoch [5/50] - Batch loss: 167.3967 - Epoch Loss: 78787.8046 - Avg Loss: 171.6510\n",
            "Epoch [5/50] - Batch loss: 167.1989 - Epoch Loss: 78955.0035 - Avg Loss: 171.6413\n",
            "Epoch [5/50] - Batch loss: 165.5633 - Epoch Loss: 79120.5668 - Avg Loss: 171.6281\n",
            "Epoch [5/50] - Batch loss: 170.1782 - Epoch Loss: 79290.7451 - Avg Loss: 171.6250\n",
            "Epoch [5/50] - Batch loss: 165.0431 - Epoch Loss: 79455.7882 - Avg Loss: 171.6108\n",
            "Epoch [5/50] - Batch loss: 176.7454 - Epoch Loss: 79632.5336 - Avg Loss: 171.6218\n",
            "Epoch [5/50] - Batch loss: 171.3923 - Epoch Loss: 79803.9259 - Avg Loss: 171.6213\n",
            "Epoch [5/50] - Batch loss: 163.0183 - Epoch Loss: 79966.9442 - Avg Loss: 171.6029\n",
            "Epoch [5/50] - Batch loss: 168.5284 - Epoch Loss: 80135.4726 - Avg Loss: 171.5963\n",
            "Epoch [5/50] - Batch loss: 166.2321 - Epoch Loss: 80301.7047 - Avg Loss: 171.5848\n",
            "Epoch [5/50] - Batch loss: 161.1147 - Epoch Loss: 80462.8194 - Avg Loss: 171.5625\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 6/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b936c1256c5a4528a85b23ca549241c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/50] - Batch loss: 165.5672 - Epoch Loss: 165.5672 - Avg Loss: 165.5672\n",
            "Epoch [6/50] - Batch loss: 169.9776 - Epoch Loss: 335.5448 - Avg Loss: 167.7724\n",
            "Epoch [6/50] - Batch loss: 171.4106 - Epoch Loss: 506.9554 - Avg Loss: 168.9851\n",
            "Epoch [6/50] - Batch loss: 172.1597 - Epoch Loss: 679.1152 - Avg Loss: 169.7788\n",
            "Epoch [6/50] - Batch loss: 162.0850 - Epoch Loss: 841.2001 - Avg Loss: 168.2400\n",
            "Epoch [6/50] - Batch loss: 176.0547 - Epoch Loss: 1017.2548 - Avg Loss: 169.5425\n",
            "Epoch [6/50] - Batch loss: 172.7830 - Epoch Loss: 1190.0378 - Avg Loss: 170.0054\n",
            "Epoch [6/50] - Batch loss: 170.0088 - Epoch Loss: 1360.0466 - Avg Loss: 170.0058\n",
            "Epoch [6/50] - Batch loss: 174.8698 - Epoch Loss: 1534.9165 - Avg Loss: 170.5463\n",
            "Epoch [6/50] - Batch loss: 175.4578 - Epoch Loss: 1710.3743 - Avg Loss: 171.0374\n",
            "Epoch [6/50] - Batch loss: 165.4571 - Epoch Loss: 1875.8314 - Avg Loss: 170.5301\n",
            "Epoch [6/50] - Batch loss: 172.4584 - Epoch Loss: 2048.2897 - Avg Loss: 170.6908\n",
            "Epoch [6/50] - Batch loss: 162.0323 - Epoch Loss: 2210.3221 - Avg Loss: 170.0248\n",
            "Epoch [6/50] - Batch loss: 162.6437 - Epoch Loss: 2372.9658 - Avg Loss: 169.4976\n",
            "Epoch [6/50] - Batch loss: 165.5369 - Epoch Loss: 2538.5027 - Avg Loss: 169.2335\n",
            "Epoch [6/50] - Batch loss: 168.1282 - Epoch Loss: 2706.6308 - Avg Loss: 169.1644\n",
            "Epoch [6/50] - Batch loss: 169.8736 - Epoch Loss: 2876.5045 - Avg Loss: 169.2061\n",
            "Epoch [6/50] - Batch loss: 171.7736 - Epoch Loss: 3048.2780 - Avg Loss: 169.3488\n",
            "Epoch [6/50] - Batch loss: 158.0958 - Epoch Loss: 3206.3739 - Avg Loss: 168.7565\n",
            "Epoch [6/50] - Batch loss: 174.0010 - Epoch Loss: 3380.3749 - Avg Loss: 169.0187\n",
            "Epoch [6/50] - Batch loss: 173.2580 - Epoch Loss: 3553.6329 - Avg Loss: 169.2206\n",
            "Epoch [6/50] - Batch loss: 168.4836 - Epoch Loss: 3722.1164 - Avg Loss: 169.1871\n",
            "Epoch [6/50] - Batch loss: 168.3403 - Epoch Loss: 3890.4567 - Avg Loss: 169.1503\n",
            "Epoch [6/50] - Batch loss: 168.1531 - Epoch Loss: 4058.6098 - Avg Loss: 169.1087\n",
            "Epoch [6/50] - Batch loss: 170.0496 - Epoch Loss: 4228.6594 - Avg Loss: 169.1464\n",
            "Epoch [6/50] - Batch loss: 167.0810 - Epoch Loss: 4395.7404 - Avg Loss: 169.0669\n",
            "Epoch [6/50] - Batch loss: 168.5061 - Epoch Loss: 4564.2465 - Avg Loss: 169.0462\n",
            "Epoch [6/50] - Batch loss: 177.8029 - Epoch Loss: 4742.0494 - Avg Loss: 169.3589\n",
            "Epoch [6/50] - Batch loss: 167.6665 - Epoch Loss: 4909.7159 - Avg Loss: 169.3005\n",
            "Epoch [6/50] - Batch loss: 164.9278 - Epoch Loss: 5074.6437 - Avg Loss: 169.1548\n",
            "Epoch [6/50] - Batch loss: 168.0516 - Epoch Loss: 5242.6953 - Avg Loss: 169.1192\n",
            "Epoch [6/50] - Batch loss: 166.8518 - Epoch Loss: 5409.5472 - Avg Loss: 169.0483\n",
            "Epoch [6/50] - Batch loss: 166.9598 - Epoch Loss: 5576.5069 - Avg Loss: 168.9851\n",
            "Epoch [6/50] - Batch loss: 171.7857 - Epoch Loss: 5748.2926 - Avg Loss: 169.0674\n",
            "Epoch [6/50] - Batch loss: 168.5708 - Epoch Loss: 5916.8634 - Avg Loss: 169.0532\n",
            "Epoch [6/50] - Batch loss: 172.9956 - Epoch Loss: 6089.8590 - Avg Loss: 169.1627\n",
            "Epoch [6/50] - Batch loss: 173.6053 - Epoch Loss: 6263.4643 - Avg Loss: 169.2828\n",
            "Epoch [6/50] - Batch loss: 171.9906 - Epoch Loss: 6435.4549 - Avg Loss: 169.3541\n",
            "Epoch [6/50] - Batch loss: 169.9359 - Epoch Loss: 6605.3908 - Avg Loss: 169.3690\n",
            "Epoch [6/50] - Batch loss: 166.2476 - Epoch Loss: 6771.6383 - Avg Loss: 169.2910\n",
            "Epoch [6/50] - Batch loss: 163.1445 - Epoch Loss: 6934.7829 - Avg Loss: 169.1410\n",
            "Epoch [6/50] - Batch loss: 169.9462 - Epoch Loss: 7104.7291 - Avg Loss: 169.1602\n",
            "Epoch [6/50] - Batch loss: 169.4946 - Epoch Loss: 7274.2236 - Avg Loss: 169.1680\n",
            "Epoch [6/50] - Batch loss: 168.7456 - Epoch Loss: 7442.9693 - Avg Loss: 169.1584\n",
            "Epoch [6/50] - Batch loss: 173.7357 - Epoch Loss: 7616.7050 - Avg Loss: 169.2601\n",
            "Epoch [6/50] - Batch loss: 170.1125 - Epoch Loss: 7786.8175 - Avg Loss: 169.2786\n",
            "Epoch [6/50] - Batch loss: 172.2073 - Epoch Loss: 7959.0248 - Avg Loss: 169.3410\n",
            "Epoch [6/50] - Batch loss: 172.2364 - Epoch Loss: 8131.2612 - Avg Loss: 169.4013\n",
            "Epoch [6/50] - Batch loss: 161.2675 - Epoch Loss: 8292.5287 - Avg Loss: 169.2353\n",
            "Epoch [6/50] - Batch loss: 168.0552 - Epoch Loss: 8460.5839 - Avg Loss: 169.2117\n",
            "Epoch [6/50] - Batch loss: 170.2945 - Epoch Loss: 8630.8784 - Avg Loss: 169.2329\n",
            "Epoch [6/50] - Batch loss: 176.7360 - Epoch Loss: 8807.6143 - Avg Loss: 169.3772\n",
            "Epoch [6/50] - Batch loss: 169.4853 - Epoch Loss: 8977.0997 - Avg Loss: 169.3792\n",
            "Epoch [6/50] - Batch loss: 170.4719 - Epoch Loss: 9147.5715 - Avg Loss: 169.3995\n",
            "Epoch [6/50] - Batch loss: 161.9173 - Epoch Loss: 9309.4889 - Avg Loss: 169.2634\n",
            "Epoch [6/50] - Batch loss: 161.5629 - Epoch Loss: 9471.0518 - Avg Loss: 169.1259\n",
            "Epoch [6/50] - Batch loss: 171.7826 - Epoch Loss: 9642.8344 - Avg Loss: 169.1725\n",
            "Epoch [6/50] - Batch loss: 165.9005 - Epoch Loss: 9808.7349 - Avg Loss: 169.1161\n",
            "Epoch [6/50] - Batch loss: 168.7470 - Epoch Loss: 9977.4819 - Avg Loss: 169.1099\n",
            "Epoch [6/50] - Batch loss: 169.4976 - Epoch Loss: 10146.9795 - Avg Loss: 169.1163\n",
            "Epoch [6/50] - Batch loss: 169.8712 - Epoch Loss: 10316.8507 - Avg Loss: 169.1287\n",
            "Epoch [6/50] - Batch loss: 171.5962 - Epoch Loss: 10488.4469 - Avg Loss: 169.1685\n",
            "Epoch [6/50] - Batch loss: 165.4147 - Epoch Loss: 10653.8616 - Avg Loss: 169.1089\n",
            "Epoch [6/50] - Batch loss: 166.9487 - Epoch Loss: 10820.8103 - Avg Loss: 169.0752\n",
            "Epoch [6/50] - Batch loss: 165.9877 - Epoch Loss: 10986.7981 - Avg Loss: 169.0277\n",
            "Epoch [6/50] - Batch loss: 169.4977 - Epoch Loss: 11156.2957 - Avg Loss: 169.0348\n",
            "Epoch [6/50] - Batch loss: 169.4229 - Epoch Loss: 11325.7186 - Avg Loss: 169.0406\n",
            "Epoch [6/50] - Batch loss: 171.0671 - Epoch Loss: 11496.7857 - Avg Loss: 169.0704\n",
            "Epoch [6/50] - Batch loss: 165.3510 - Epoch Loss: 11662.1368 - Avg Loss: 169.0165\n",
            "Epoch [6/50] - Batch loss: 173.1597 - Epoch Loss: 11835.2964 - Avg Loss: 169.0757\n",
            "Epoch [6/50] - Batch loss: 169.4105 - Epoch Loss: 12004.7070 - Avg Loss: 169.0804\n",
            "Epoch [6/50] - Batch loss: 165.8524 - Epoch Loss: 12170.5594 - Avg Loss: 169.0355\n",
            "Epoch [6/50] - Batch loss: 164.5208 - Epoch Loss: 12335.0802 - Avg Loss: 168.9737\n",
            "Epoch [6/50] - Batch loss: 164.5829 - Epoch Loss: 12499.6631 - Avg Loss: 168.9144\n",
            "Epoch [6/50] - Batch loss: 170.4653 - Epoch Loss: 12670.1284 - Avg Loss: 168.9350\n",
            "Epoch [6/50] - Batch loss: 172.8384 - Epoch Loss: 12842.9668 - Avg Loss: 168.9864\n",
            "Epoch [6/50] - Batch loss: 172.0887 - Epoch Loss: 13015.0555 - Avg Loss: 169.0267\n",
            "Epoch [6/50] - Batch loss: 175.1555 - Epoch Loss: 13190.2111 - Avg Loss: 169.1053\n",
            "Epoch [6/50] - Batch loss: 168.2768 - Epoch Loss: 13358.4878 - Avg Loss: 169.0948\n",
            "Epoch [6/50] - Batch loss: 156.1063 - Epoch Loss: 13514.5941 - Avg Loss: 168.9324\n",
            "Epoch [6/50] - Batch loss: 161.9512 - Epoch Loss: 13676.5453 - Avg Loss: 168.8462\n",
            "Epoch [6/50] - Batch loss: 171.4788 - Epoch Loss: 13848.0241 - Avg Loss: 168.8783\n",
            "Epoch [6/50] - Batch loss: 171.9906 - Epoch Loss: 14020.0146 - Avg Loss: 168.9158\n",
            "Epoch [6/50] - Batch loss: 169.5618 - Epoch Loss: 14189.5764 - Avg Loss: 168.9235\n",
            "Epoch [6/50] - Batch loss: 162.3010 - Epoch Loss: 14351.8774 - Avg Loss: 168.8456\n",
            "Epoch [6/50] - Batch loss: 173.2596 - Epoch Loss: 14525.1370 - Avg Loss: 168.8969\n",
            "Epoch [6/50] - Batch loss: 168.6589 - Epoch Loss: 14693.7959 - Avg Loss: 168.8942\n",
            "Epoch [6/50] - Batch loss: 166.3469 - Epoch Loss: 14860.1428 - Avg Loss: 168.8653\n",
            "Epoch [6/50] - Batch loss: 169.1705 - Epoch Loss: 15029.3133 - Avg Loss: 168.8687\n",
            "Epoch [6/50] - Batch loss: 169.9348 - Epoch Loss: 15199.2481 - Avg Loss: 168.8805\n",
            "Epoch [6/50] - Batch loss: 168.4738 - Epoch Loss: 15367.7219 - Avg Loss: 168.8761\n",
            "Epoch [6/50] - Batch loss: 170.4738 - Epoch Loss: 15538.1957 - Avg Loss: 168.8934\n",
            "Epoch [6/50] - Batch loss: 172.0207 - Epoch Loss: 15710.2164 - Avg Loss: 168.9271\n",
            "Epoch [6/50] - Batch loss: 167.0956 - Epoch Loss: 15877.3120 - Avg Loss: 168.9076\n",
            "Epoch [6/50] - Batch loss: 176.2126 - Epoch Loss: 16053.5246 - Avg Loss: 168.9845\n",
            "Epoch [6/50] - Batch loss: 161.1036 - Epoch Loss: 16214.6282 - Avg Loss: 168.9024\n",
            "Epoch [6/50] - Batch loss: 171.8938 - Epoch Loss: 16386.5220 - Avg Loss: 168.9332\n",
            "Epoch [6/50] - Batch loss: 169.4706 - Epoch Loss: 16555.9926 - Avg Loss: 168.9387\n",
            "Epoch [6/50] - Batch loss: 167.2365 - Epoch Loss: 16723.2291 - Avg Loss: 168.9215\n",
            "Epoch [6/50] - Batch loss: 164.1249 - Epoch Loss: 16887.3540 - Avg Loss: 168.8735\n",
            "Epoch [6/50] - Batch loss: 164.5218 - Epoch Loss: 17051.8758 - Avg Loss: 168.8305\n",
            "Epoch [6/50] - Batch loss: 160.2148 - Epoch Loss: 17212.0906 - Avg Loss: 168.7460\n",
            "Epoch [6/50] - Batch loss: 164.4846 - Epoch Loss: 17376.5752 - Avg Loss: 168.7046\n",
            "Epoch [6/50] - Batch loss: 174.0880 - Epoch Loss: 17550.6632 - Avg Loss: 168.7564\n",
            "Epoch [6/50] - Batch loss: 170.3765 - Epoch Loss: 17721.0397 - Avg Loss: 168.7718\n",
            "Epoch [6/50] - Batch loss: 167.2157 - Epoch Loss: 17888.2554 - Avg Loss: 168.7571\n",
            "Epoch [6/50] - Batch loss: 165.8681 - Epoch Loss: 18054.1235 - Avg Loss: 168.7301\n",
            "Epoch [6/50] - Batch loss: 167.2751 - Epoch Loss: 18221.3987 - Avg Loss: 168.7167\n",
            "Epoch [6/50] - Batch loss: 171.8895 - Epoch Loss: 18393.2881 - Avg Loss: 168.7458\n",
            "Epoch [6/50] - Batch loss: 165.0237 - Epoch Loss: 18558.3119 - Avg Loss: 168.7119\n",
            "Epoch [6/50] - Batch loss: 173.7664 - Epoch Loss: 18732.0783 - Avg Loss: 168.7575\n",
            "Epoch [6/50] - Batch loss: 165.6050 - Epoch Loss: 18897.6833 - Avg Loss: 168.7293\n",
            "Epoch [6/50] - Batch loss: 173.8972 - Epoch Loss: 19071.5805 - Avg Loss: 168.7750\n",
            "Epoch [6/50] - Batch loss: 172.6183 - Epoch Loss: 19244.1988 - Avg Loss: 168.8088\n",
            "Epoch [6/50] - Batch loss: 167.5867 - Epoch Loss: 19411.7855 - Avg Loss: 168.7981\n",
            "Epoch [6/50] - Batch loss: 167.6930 - Epoch Loss: 19579.4785 - Avg Loss: 168.7886\n",
            "Epoch [6/50] - Batch loss: 166.5856 - Epoch Loss: 19746.0641 - Avg Loss: 168.7698\n",
            "Epoch [6/50] - Batch loss: 160.7229 - Epoch Loss: 19906.7870 - Avg Loss: 168.7016\n",
            "Epoch [6/50] - Batch loss: 170.7253 - Epoch Loss: 20077.5123 - Avg Loss: 168.7186\n",
            "Epoch [6/50] - Batch loss: 169.3010 - Epoch Loss: 20246.8133 - Avg Loss: 168.7234\n",
            "Epoch [6/50] - Batch loss: 166.0506 - Epoch Loss: 20412.8639 - Avg Loss: 168.7014\n",
            "Epoch [6/50] - Batch loss: 161.9949 - Epoch Loss: 20574.8588 - Avg Loss: 168.6464\n",
            "Epoch [6/50] - Batch loss: 177.5506 - Epoch Loss: 20752.4094 - Avg Loss: 168.7188\n",
            "Epoch [6/50] - Batch loss: 166.9681 - Epoch Loss: 20919.3775 - Avg Loss: 168.7047\n",
            "Epoch [6/50] - Batch loss: 161.6474 - Epoch Loss: 21081.0249 - Avg Loss: 168.6482\n",
            "Epoch [6/50] - Batch loss: 160.4453 - Epoch Loss: 21241.4702 - Avg Loss: 168.5831\n",
            "Epoch [6/50] - Batch loss: 162.1252 - Epoch Loss: 21403.5954 - Avg Loss: 168.5322\n",
            "Epoch [6/50] - Batch loss: 168.1463 - Epoch Loss: 21571.7417 - Avg Loss: 168.5292\n",
            "Epoch [6/50] - Batch loss: 169.0381 - Epoch Loss: 21740.7798 - Avg Loss: 168.5332\n",
            "Epoch [6/50] - Batch loss: 164.4147 - Epoch Loss: 21905.1945 - Avg Loss: 168.5015\n",
            "Epoch [6/50] - Batch loss: 169.5651 - Epoch Loss: 22074.7596 - Avg Loss: 168.5096\n",
            "Epoch [6/50] - Batch loss: 169.0272 - Epoch Loss: 22243.7868 - Avg Loss: 168.5135\n",
            "Epoch [6/50] - Batch loss: 165.9504 - Epoch Loss: 22409.7372 - Avg Loss: 168.4943\n",
            "Epoch [6/50] - Batch loss: 178.1090 - Epoch Loss: 22587.8462 - Avg Loss: 168.5660\n",
            "Epoch [6/50] - Batch loss: 170.8274 - Epoch Loss: 22758.6736 - Avg Loss: 168.5828\n",
            "Epoch [6/50] - Batch loss: 175.4743 - Epoch Loss: 22934.1480 - Avg Loss: 168.6334\n",
            "Epoch [6/50] - Batch loss: 161.9522 - Epoch Loss: 23096.1001 - Avg Loss: 168.5847\n",
            "Epoch [6/50] - Batch loss: 169.4314 - Epoch Loss: 23265.5315 - Avg Loss: 168.5908\n",
            "Epoch [6/50] - Batch loss: 170.1131 - Epoch Loss: 23435.6446 - Avg Loss: 168.6018\n",
            "Epoch [6/50] - Batch loss: 172.7497 - Epoch Loss: 23608.3943 - Avg Loss: 168.6314\n",
            "Epoch [6/50] - Batch loss: 162.7158 - Epoch Loss: 23771.1101 - Avg Loss: 168.5894\n",
            "Epoch [6/50] - Batch loss: 170.8104 - Epoch Loss: 23941.9206 - Avg Loss: 168.6051\n",
            "Epoch [6/50] - Batch loss: 174.2836 - Epoch Loss: 24116.2041 - Avg Loss: 168.6448\n",
            "Epoch [6/50] - Batch loss: 170.9692 - Epoch Loss: 24287.1733 - Avg Loss: 168.6609\n",
            "Epoch [6/50] - Batch loss: 161.7140 - Epoch Loss: 24448.8873 - Avg Loss: 168.6130\n",
            "Epoch [6/50] - Batch loss: 169.5632 - Epoch Loss: 24618.4505 - Avg Loss: 168.6195\n",
            "Epoch [6/50] - Batch loss: 167.4354 - Epoch Loss: 24785.8858 - Avg Loss: 168.6115\n",
            "Epoch [6/50] - Batch loss: 165.3215 - Epoch Loss: 24951.2074 - Avg Loss: 168.5892\n",
            "Epoch [6/50] - Batch loss: 173.8841 - Epoch Loss: 25125.0915 - Avg Loss: 168.6248\n",
            "Epoch [6/50] - Batch loss: 165.7329 - Epoch Loss: 25290.8244 - Avg Loss: 168.6055\n",
            "Epoch [6/50] - Batch loss: 171.9483 - Epoch Loss: 25462.7727 - Avg Loss: 168.6276\n",
            "Epoch [6/50] - Batch loss: 168.9906 - Epoch Loss: 25631.7632 - Avg Loss: 168.6300\n",
            "Epoch [6/50] - Batch loss: 163.6689 - Epoch Loss: 25795.4322 - Avg Loss: 168.5976\n",
            "Epoch [6/50] - Batch loss: 172.9101 - Epoch Loss: 25968.3423 - Avg Loss: 168.6256\n",
            "Epoch [6/50] - Batch loss: 165.3210 - Epoch Loss: 26133.6632 - Avg Loss: 168.6043\n",
            "Epoch [6/50] - Batch loss: 170.0005 - Epoch Loss: 26303.6637 - Avg Loss: 168.6132\n",
            "Epoch [6/50] - Batch loss: 164.4806 - Epoch Loss: 26468.1443 - Avg Loss: 168.5869\n",
            "Epoch [6/50] - Batch loss: 160.3796 - Epoch Loss: 26628.5239 - Avg Loss: 168.5350\n",
            "Epoch [6/50] - Batch loss: 176.5318 - Epoch Loss: 26805.0557 - Avg Loss: 168.5853\n",
            "Epoch [6/50] - Batch loss: 168.8349 - Epoch Loss: 26973.8905 - Avg Loss: 168.5868\n",
            "Epoch [6/50] - Batch loss: 158.0029 - Epoch Loss: 27131.8935 - Avg Loss: 168.5211\n",
            "Epoch [6/50] - Batch loss: 161.4532 - Epoch Loss: 27293.3467 - Avg Loss: 168.4774\n",
            "Epoch [6/50] - Batch loss: 167.5192 - Epoch Loss: 27460.8659 - Avg Loss: 168.4716\n",
            "Epoch [6/50] - Batch loss: 172.2008 - Epoch Loss: 27633.0667 - Avg Loss: 168.4943\n",
            "Epoch [6/50] - Batch loss: 170.9888 - Epoch Loss: 27804.0555 - Avg Loss: 168.5094\n",
            "Epoch [6/50] - Batch loss: 174.6695 - Epoch Loss: 27978.7249 - Avg Loss: 168.5465\n",
            "Epoch [6/50] - Batch loss: 166.5932 - Epoch Loss: 28145.3182 - Avg Loss: 168.5348\n",
            "Epoch [6/50] - Batch loss: 164.8635 - Epoch Loss: 28310.1817 - Avg Loss: 168.5130\n",
            "Epoch [6/50] - Batch loss: 169.1640 - Epoch Loss: 28479.3456 - Avg Loss: 168.5168\n",
            "Epoch [6/50] - Batch loss: 162.3455 - Epoch Loss: 28641.6911 - Avg Loss: 168.4805\n",
            "Epoch [6/50] - Batch loss: 170.8358 - Epoch Loss: 28812.5270 - Avg Loss: 168.4943\n",
            "Epoch [6/50] - Batch loss: 163.5739 - Epoch Loss: 28976.1008 - Avg Loss: 168.4657\n",
            "Epoch [6/50] - Batch loss: 164.0239 - Epoch Loss: 29140.1247 - Avg Loss: 168.4400\n",
            "Epoch [6/50] - Batch loss: 174.8206 - Epoch Loss: 29314.9453 - Avg Loss: 168.4767\n",
            "Epoch [6/50] - Batch loss: 165.7199 - Epoch Loss: 29480.6652 - Avg Loss: 168.4609\n",
            "Epoch [6/50] - Batch loss: 168.5025 - Epoch Loss: 29649.1677 - Avg Loss: 168.4612\n",
            "Epoch [6/50] - Batch loss: 168.5444 - Epoch Loss: 29817.7121 - Avg Loss: 168.4617\n",
            "Epoch [6/50] - Batch loss: 174.2652 - Epoch Loss: 29991.9773 - Avg Loss: 168.4943\n",
            "Epoch [6/50] - Batch loss: 167.7534 - Epoch Loss: 30159.7307 - Avg Loss: 168.4901\n",
            "Epoch [6/50] - Batch loss: 165.6481 - Epoch Loss: 30325.3789 - Avg Loss: 168.4743\n",
            "Epoch [6/50] - Batch loss: 163.2936 - Epoch Loss: 30488.6725 - Avg Loss: 168.4457\n",
            "Epoch [6/50] - Batch loss: 169.3603 - Epoch Loss: 30658.0327 - Avg Loss: 168.4507\n",
            "Epoch [6/50] - Batch loss: 173.3024 - Epoch Loss: 30831.3352 - Avg Loss: 168.4772\n",
            "Epoch [6/50] - Batch loss: 164.8221 - Epoch Loss: 30996.1573 - Avg Loss: 168.4574\n",
            "Epoch [6/50] - Batch loss: 169.5063 - Epoch Loss: 31165.6637 - Avg Loss: 168.4630\n",
            "Epoch [6/50] - Batch loss: 169.2367 - Epoch Loss: 31334.9004 - Avg Loss: 168.4672\n",
            "Epoch [6/50] - Batch loss: 178.9404 - Epoch Loss: 31513.8408 - Avg Loss: 168.5232\n",
            "Epoch [6/50] - Batch loss: 154.9610 - Epoch Loss: 31668.8018 - Avg Loss: 168.4511\n",
            "Epoch [6/50] - Batch loss: 168.2670 - Epoch Loss: 31837.0687 - Avg Loss: 168.4501\n",
            "Epoch [6/50] - Batch loss: 178.2506 - Epoch Loss: 32015.3193 - Avg Loss: 168.5017\n",
            "Epoch [6/50] - Batch loss: 169.6961 - Epoch Loss: 32185.0154 - Avg Loss: 168.5079\n",
            "Epoch [6/50] - Batch loss: 170.6822 - Epoch Loss: 32355.6976 - Avg Loss: 168.5193\n",
            "Epoch [6/50] - Batch loss: 165.2988 - Epoch Loss: 32520.9964 - Avg Loss: 168.5026\n",
            "Epoch [6/50] - Batch loss: 173.8548 - Epoch Loss: 32694.8513 - Avg Loss: 168.5302\n",
            "Epoch [6/50] - Batch loss: 156.4880 - Epoch Loss: 32851.3393 - Avg Loss: 168.4684\n",
            "Epoch [6/50] - Batch loss: 172.0489 - Epoch Loss: 33023.3882 - Avg Loss: 168.4867\n",
            "Epoch [6/50] - Batch loss: 170.3708 - Epoch Loss: 33193.7590 - Avg Loss: 168.4962\n",
            "Epoch [6/50] - Batch loss: 167.4091 - Epoch Loss: 33361.1682 - Avg Loss: 168.4907\n",
            "Epoch [6/50] - Batch loss: 164.6393 - Epoch Loss: 33525.8075 - Avg Loss: 168.4714\n",
            "Epoch [6/50] - Batch loss: 166.4146 - Epoch Loss: 33692.2220 - Avg Loss: 168.4611\n",
            "Epoch [6/50] - Batch loss: 175.0443 - Epoch Loss: 33867.2663 - Avg Loss: 168.4939\n",
            "Epoch [6/50] - Batch loss: 163.1328 - Epoch Loss: 34030.3991 - Avg Loss: 168.4673\n",
            "Epoch [6/50] - Batch loss: 171.2686 - Epoch Loss: 34201.6676 - Avg Loss: 168.4811\n",
            "Epoch [6/50] - Batch loss: 166.1662 - Epoch Loss: 34367.8338 - Avg Loss: 168.4698\n",
            "Epoch [6/50] - Batch loss: 168.5585 - Epoch Loss: 34536.3923 - Avg Loss: 168.4702\n",
            "Epoch [6/50] - Batch loss: 170.7343 - Epoch Loss: 34707.1266 - Avg Loss: 168.4812\n",
            "Epoch [6/50] - Batch loss: 168.5297 - Epoch Loss: 34875.6563 - Avg Loss: 168.4814\n",
            "Epoch [6/50] - Batch loss: 165.2342 - Epoch Loss: 35040.8905 - Avg Loss: 168.4658\n",
            "Epoch [6/50] - Batch loss: 171.8032 - Epoch Loss: 35212.6937 - Avg Loss: 168.4818\n",
            "Epoch [6/50] - Batch loss: 167.8303 - Epoch Loss: 35380.5240 - Avg Loss: 168.4787\n",
            "Epoch [6/50] - Batch loss: 165.5529 - Epoch Loss: 35546.0768 - Avg Loss: 168.4648\n",
            "Epoch [6/50] - Batch loss: 169.8816 - Epoch Loss: 35715.9584 - Avg Loss: 168.4715\n",
            "Epoch [6/50] - Batch loss: 166.0833 - Epoch Loss: 35882.0417 - Avg Loss: 168.4603\n",
            "Epoch [6/50] - Batch loss: 172.4151 - Epoch Loss: 36054.4567 - Avg Loss: 168.4788\n",
            "Epoch [6/50] - Batch loss: 171.7518 - Epoch Loss: 36226.2086 - Avg Loss: 168.4940\n",
            "Epoch [6/50] - Batch loss: 167.7265 - Epoch Loss: 36393.9350 - Avg Loss: 168.4904\n",
            "Epoch [6/50] - Batch loss: 164.8371 - Epoch Loss: 36558.7722 - Avg Loss: 168.4736\n",
            "Epoch [6/50] - Batch loss: 171.9847 - Epoch Loss: 36730.7569 - Avg Loss: 168.4897\n",
            "Epoch [6/50] - Batch loss: 165.7673 - Epoch Loss: 36896.5242 - Avg Loss: 168.4773\n",
            "Epoch [6/50] - Batch loss: 170.0266 - Epoch Loss: 37066.5508 - Avg Loss: 168.4843\n",
            "Epoch [6/50] - Batch loss: 157.4227 - Epoch Loss: 37223.9736 - Avg Loss: 168.4343\n",
            "Epoch [6/50] - Batch loss: 163.5981 - Epoch Loss: 37387.5717 - Avg Loss: 168.4125\n",
            "Epoch [6/50] - Batch loss: 167.4259 - Epoch Loss: 37554.9976 - Avg Loss: 168.4081\n",
            "Epoch [6/50] - Batch loss: 162.3380 - Epoch Loss: 37717.3355 - Avg Loss: 168.3810\n",
            "Epoch [6/50] - Batch loss: 161.8164 - Epoch Loss: 37879.1519 - Avg Loss: 168.3518\n",
            "Epoch [6/50] - Batch loss: 166.5278 - Epoch Loss: 38045.6797 - Avg Loss: 168.3437\n",
            "Epoch [6/50] - Batch loss: 172.4889 - Epoch Loss: 38218.1686 - Avg Loss: 168.3620\n",
            "Epoch [6/50] - Batch loss: 173.6904 - Epoch Loss: 38391.8589 - Avg Loss: 168.3853\n",
            "Epoch [6/50] - Batch loss: 165.4475 - Epoch Loss: 38557.3064 - Avg Loss: 168.3725\n",
            "Epoch [6/50] - Batch loss: 170.9764 - Epoch Loss: 38728.2828 - Avg Loss: 168.3838\n",
            "Epoch [6/50] - Batch loss: 167.0657 - Epoch Loss: 38895.3485 - Avg Loss: 168.3781\n",
            "Epoch [6/50] - Batch loss: 169.9349 - Epoch Loss: 39065.2834 - Avg Loss: 168.3848\n",
            "Epoch [6/50] - Batch loss: 173.2081 - Epoch Loss: 39238.4915 - Avg Loss: 168.4055\n",
            "Epoch [6/50] - Batch loss: 173.6326 - Epoch Loss: 39412.1240 - Avg Loss: 168.4279\n",
            "Epoch [6/50] - Batch loss: 163.1496 - Epoch Loss: 39575.2736 - Avg Loss: 168.4054\n",
            "Epoch [6/50] - Batch loss: 158.5339 - Epoch Loss: 39733.8075 - Avg Loss: 168.3636\n",
            "Epoch [6/50] - Batch loss: 157.5239 - Epoch Loss: 39891.3314 - Avg Loss: 168.3179\n",
            "Epoch [6/50] - Batch loss: 167.8145 - Epoch Loss: 40059.1460 - Avg Loss: 168.3157\n",
            "Epoch [6/50] - Batch loss: 168.6933 - Epoch Loss: 40227.8392 - Avg Loss: 168.3173\n",
            "Epoch [6/50] - Batch loss: 166.2021 - Epoch Loss: 40394.0413 - Avg Loss: 168.3085\n",
            "Epoch [6/50] - Batch loss: 169.5242 - Epoch Loss: 40563.5656 - Avg Loss: 168.3136\n",
            "Epoch [6/50] - Batch loss: 167.8855 - Epoch Loss: 40731.4511 - Avg Loss: 168.3118\n",
            "Epoch [6/50] - Batch loss: 170.2725 - Epoch Loss: 40901.7236 - Avg Loss: 168.3199\n",
            "Epoch [6/50] - Batch loss: 168.5870 - Epoch Loss: 41070.3106 - Avg Loss: 168.3209\n",
            "Epoch [6/50] - Batch loss: 161.7234 - Epoch Loss: 41232.0340 - Avg Loss: 168.2940\n",
            "Epoch [6/50] - Batch loss: 164.4104 - Epoch Loss: 41396.4444 - Avg Loss: 168.2782\n",
            "Epoch [6/50] - Batch loss: 163.9290 - Epoch Loss: 41560.3735 - Avg Loss: 168.2606\n",
            "Epoch [6/50] - Batch loss: 166.1388 - Epoch Loss: 41726.5123 - Avg Loss: 168.2521\n",
            "Epoch [6/50] - Batch loss: 162.8061 - Epoch Loss: 41889.3184 - Avg Loss: 168.2302\n",
            "Epoch [6/50] - Batch loss: 170.9605 - Epoch Loss: 42060.2789 - Avg Loss: 168.2411\n",
            "Epoch [6/50] - Batch loss: 168.6427 - Epoch Loss: 42228.9216 - Avg Loss: 168.2427\n",
            "Epoch [6/50] - Batch loss: 174.3844 - Epoch Loss: 42403.3060 - Avg Loss: 168.2671\n",
            "Epoch [6/50] - Batch loss: 157.7019 - Epoch Loss: 42561.0079 - Avg Loss: 168.2253\n",
            "Epoch [6/50] - Batch loss: 162.8395 - Epoch Loss: 42723.8474 - Avg Loss: 168.2041\n",
            "Epoch [6/50] - Batch loss: 175.5381 - Epoch Loss: 42899.3855 - Avg Loss: 168.2329\n",
            "Epoch [6/50] - Batch loss: 164.0869 - Epoch Loss: 43063.4724 - Avg Loss: 168.2167\n",
            "Epoch [6/50] - Batch loss: 166.7336 - Epoch Loss: 43230.2059 - Avg Loss: 168.2109\n",
            "Epoch [6/50] - Batch loss: 166.1600 - Epoch Loss: 43396.3660 - Avg Loss: 168.2030\n",
            "Epoch [6/50] - Batch loss: 160.1895 - Epoch Loss: 43556.5555 - Avg Loss: 168.1720\n",
            "Epoch [6/50] - Batch loss: 164.6656 - Epoch Loss: 43721.2212 - Avg Loss: 168.1585\n",
            "Epoch [6/50] - Batch loss: 163.1801 - Epoch Loss: 43884.4013 - Avg Loss: 168.1395\n",
            "Epoch [6/50] - Batch loss: 175.2920 - Epoch Loss: 44059.6933 - Avg Loss: 168.1668\n",
            "Epoch [6/50] - Batch loss: 162.8418 - Epoch Loss: 44222.5351 - Avg Loss: 168.1465\n",
            "Epoch [6/50] - Batch loss: 172.5795 - Epoch Loss: 44395.1146 - Avg Loss: 168.1633\n",
            "Epoch [6/50] - Batch loss: 171.8171 - Epoch Loss: 44566.9317 - Avg Loss: 168.1771\n",
            "Epoch [6/50] - Batch loss: 169.2459 - Epoch Loss: 44736.1776 - Avg Loss: 168.1811\n",
            "Epoch [6/50] - Batch loss: 167.7570 - Epoch Loss: 44903.9346 - Avg Loss: 168.1795\n",
            "Epoch [6/50] - Batch loss: 176.6612 - Epoch Loss: 45080.5958 - Avg Loss: 168.2112\n",
            "Epoch [6/50] - Batch loss: 166.3727 - Epoch Loss: 45246.9685 - Avg Loss: 168.2043\n",
            "Epoch [6/50] - Batch loss: 166.6447 - Epoch Loss: 45413.6132 - Avg Loss: 168.1986\n",
            "Epoch [6/50] - Batch loss: 167.4656 - Epoch Loss: 45581.0788 - Avg Loss: 168.1959\n",
            "Epoch [6/50] - Batch loss: 173.0389 - Epoch Loss: 45754.1177 - Avg Loss: 168.2137\n",
            "Epoch [6/50] - Batch loss: 170.9787 - Epoch Loss: 45925.0964 - Avg Loss: 168.2238\n",
            "Epoch [6/50] - Batch loss: 164.0648 - Epoch Loss: 46089.1612 - Avg Loss: 168.2086\n",
            "Epoch [6/50] - Batch loss: 162.1086 - Epoch Loss: 46251.2697 - Avg Loss: 168.1864\n",
            "Epoch [6/50] - Batch loss: 163.4921 - Epoch Loss: 46414.7618 - Avg Loss: 168.1694\n",
            "Epoch [6/50] - Batch loss: 169.6571 - Epoch Loss: 46584.4189 - Avg Loss: 168.1748\n",
            "Epoch [6/50] - Batch loss: 170.4216 - Epoch Loss: 46754.8406 - Avg Loss: 168.1829\n",
            "Epoch [6/50] - Batch loss: 163.8521 - Epoch Loss: 46918.6927 - Avg Loss: 168.1674\n",
            "Epoch [6/50] - Batch loss: 160.8707 - Epoch Loss: 47079.5633 - Avg Loss: 168.1413\n",
            "Epoch [6/50] - Batch loss: 165.8079 - Epoch Loss: 47245.3713 - Avg Loss: 168.1330\n",
            "Epoch [6/50] - Batch loss: 165.3422 - Epoch Loss: 47410.7135 - Avg Loss: 168.1231\n",
            "Epoch [6/50] - Batch loss: 167.5192 - Epoch Loss: 47578.2327 - Avg Loss: 168.1210\n",
            "Epoch [6/50] - Batch loss: 166.5758 - Epoch Loss: 47744.8084 - Avg Loss: 168.1155\n",
            "Epoch [6/50] - Batch loss: 169.2153 - Epoch Loss: 47914.0237 - Avg Loss: 168.1194\n",
            "Epoch [6/50] - Batch loss: 171.2229 - Epoch Loss: 48085.2467 - Avg Loss: 168.1302\n",
            "Epoch [6/50] - Batch loss: 158.1428 - Epoch Loss: 48243.3895 - Avg Loss: 168.0954\n",
            "Epoch [6/50] - Batch loss: 163.4700 - Epoch Loss: 48406.8594 - Avg Loss: 168.0794\n",
            "Epoch [6/50] - Batch loss: 164.9539 - Epoch Loss: 48571.8133 - Avg Loss: 168.0686\n",
            "Epoch [6/50] - Batch loss: 173.1471 - Epoch Loss: 48744.9604 - Avg Loss: 168.0861\n",
            "Epoch [6/50] - Batch loss: 175.4528 - Epoch Loss: 48920.4132 - Avg Loss: 168.1114\n",
            "Epoch [6/50] - Batch loss: 173.2339 - Epoch Loss: 49093.6471 - Avg Loss: 168.1289\n",
            "Epoch [6/50] - Batch loss: 163.6710 - Epoch Loss: 49257.3181 - Avg Loss: 168.1137\n",
            "Epoch [6/50] - Batch loss: 164.2794 - Epoch Loss: 49421.5974 - Avg Loss: 168.1007\n",
            "Epoch [6/50] - Batch loss: 169.7541 - Epoch Loss: 49591.3515 - Avg Loss: 168.1063\n",
            "Epoch [6/50] - Batch loss: 166.6172 - Epoch Loss: 49757.9687 - Avg Loss: 168.1012\n",
            "Epoch [6/50] - Batch loss: 165.2489 - Epoch Loss: 49923.2176 - Avg Loss: 168.0916\n",
            "Epoch [6/50] - Batch loss: 159.7940 - Epoch Loss: 50083.0116 - Avg Loss: 168.0638\n",
            "Epoch [6/50] - Batch loss: 174.1788 - Epoch Loss: 50257.1904 - Avg Loss: 168.0842\n",
            "Epoch [6/50] - Batch loss: 171.4577 - Epoch Loss: 50428.6481 - Avg Loss: 168.0955\n",
            "Epoch [6/50] - Batch loss: 171.0747 - Epoch Loss: 50599.7228 - Avg Loss: 168.1054\n",
            "Epoch [6/50] - Batch loss: 163.2136 - Epoch Loss: 50762.9364 - Avg Loss: 168.0892\n",
            "Epoch [6/50] - Batch loss: 166.7472 - Epoch Loss: 50929.6837 - Avg Loss: 168.0848\n",
            "Epoch [6/50] - Batch loss: 169.1305 - Epoch Loss: 51098.8142 - Avg Loss: 168.0882\n",
            "Epoch [6/50] - Batch loss: 173.0927 - Epoch Loss: 51271.9068 - Avg Loss: 168.1046\n",
            "Epoch [6/50] - Batch loss: 170.2092 - Epoch Loss: 51442.1160 - Avg Loss: 168.1115\n",
            "Epoch [6/50] - Batch loss: 167.1182 - Epoch Loss: 51609.2343 - Avg Loss: 168.1083\n",
            "Epoch [6/50] - Batch loss: 168.3267 - Epoch Loss: 51777.5610 - Avg Loss: 168.1090\n",
            "Epoch [6/50] - Batch loss: 159.4184 - Epoch Loss: 51936.9794 - Avg Loss: 168.0808\n",
            "Epoch [6/50] - Batch loss: 171.2990 - Epoch Loss: 52108.2784 - Avg Loss: 168.0912\n",
            "Epoch [6/50] - Batch loss: 164.9074 - Epoch Loss: 52273.1859 - Avg Loss: 168.0810\n",
            "Epoch [6/50] - Batch loss: 170.4233 - Epoch Loss: 52443.6091 - Avg Loss: 168.0885\n",
            "Epoch [6/50] - Batch loss: 158.8976 - Epoch Loss: 52602.5067 - Avg Loss: 168.0591\n",
            "Epoch [6/50] - Batch loss: 164.6473 - Epoch Loss: 52767.1541 - Avg Loss: 168.0483\n",
            "Epoch [6/50] - Batch loss: 166.6827 - Epoch Loss: 52933.8367 - Avg Loss: 168.0439\n",
            "Epoch [6/50] - Batch loss: 165.3603 - Epoch Loss: 53099.1971 - Avg Loss: 168.0354\n",
            "Epoch [6/50] - Batch loss: 174.8465 - Epoch Loss: 53274.0435 - Avg Loss: 168.0569\n",
            "Epoch [6/50] - Batch loss: 169.9952 - Epoch Loss: 53444.0388 - Avg Loss: 168.0630\n",
            "Epoch [6/50] - Batch loss: 160.2405 - Epoch Loss: 53604.2793 - Avg Loss: 168.0385\n",
            "Epoch [6/50] - Batch loss: 164.3717 - Epoch Loss: 53768.6509 - Avg Loss: 168.0270\n",
            "Epoch [6/50] - Batch loss: 166.8806 - Epoch Loss: 53935.5315 - Avg Loss: 168.0235\n",
            "Epoch [6/50] - Batch loss: 158.8194 - Epoch Loss: 54094.3509 - Avg Loss: 167.9949\n",
            "Epoch [6/50] - Batch loss: 169.6641 - Epoch Loss: 54264.0151 - Avg Loss: 168.0000\n",
            "Epoch [6/50] - Batch loss: 162.0152 - Epoch Loss: 54426.0302 - Avg Loss: 167.9816\n",
            "Epoch [6/50] - Batch loss: 169.2088 - Epoch Loss: 54595.2390 - Avg Loss: 167.9854\n",
            "Epoch [6/50] - Batch loss: 173.6463 - Epoch Loss: 54768.8853 - Avg Loss: 168.0027\n",
            "Epoch [6/50] - Batch loss: 161.5019 - Epoch Loss: 54930.3873 - Avg Loss: 167.9828\n",
            "Epoch [6/50] - Batch loss: 166.9742 - Epoch Loss: 55097.3615 - Avg Loss: 167.9798\n",
            "Epoch [6/50] - Batch loss: 176.7026 - Epoch Loss: 55274.0641 - Avg Loss: 168.0063\n",
            "Epoch [6/50] - Batch loss: 173.5901 - Epoch Loss: 55447.6542 - Avg Loss: 168.0232\n",
            "Epoch [6/50] - Batch loss: 164.9133 - Epoch Loss: 55612.5675 - Avg Loss: 168.0138\n",
            "Epoch [6/50] - Batch loss: 166.6551 - Epoch Loss: 55779.2225 - Avg Loss: 168.0097\n",
            "Epoch [6/50] - Batch loss: 166.3535 - Epoch Loss: 55945.5760 - Avg Loss: 168.0047\n",
            "Epoch [6/50] - Batch loss: 168.0523 - Epoch Loss: 56113.6283 - Avg Loss: 168.0049\n",
            "Epoch [6/50] - Batch loss: 170.6710 - Epoch Loss: 56284.2993 - Avg Loss: 168.0128\n",
            "Epoch [6/50] - Batch loss: 171.3141 - Epoch Loss: 56455.6133 - Avg Loss: 168.0227\n",
            "Epoch [6/50] - Batch loss: 167.1469 - Epoch Loss: 56622.7603 - Avg Loss: 168.0201\n",
            "Epoch [6/50] - Batch loss: 171.0185 - Epoch Loss: 56793.7788 - Avg Loss: 168.0289\n",
            "Epoch [6/50] - Batch loss: 179.5353 - Epoch Loss: 56973.3141 - Avg Loss: 168.0629\n",
            "Epoch [6/50] - Batch loss: 169.2228 - Epoch Loss: 57142.5368 - Avg Loss: 168.0663\n",
            "Epoch [6/50] - Batch loss: 164.6736 - Epoch Loss: 57307.2105 - Avg Loss: 168.0563\n",
            "Epoch [6/50] - Batch loss: 168.4832 - Epoch Loss: 57475.6937 - Avg Loss: 168.0576\n",
            "Epoch [6/50] - Batch loss: 163.9359 - Epoch Loss: 57639.6296 - Avg Loss: 168.0456\n",
            "Epoch [6/50] - Batch loss: 166.6284 - Epoch Loss: 57806.2580 - Avg Loss: 168.0414\n",
            "Epoch [6/50] - Batch loss: 164.0010 - Epoch Loss: 57970.2590 - Avg Loss: 168.0297\n",
            "Epoch [6/50] - Batch loss: 168.8650 - Epoch Loss: 58139.1240 - Avg Loss: 168.0322\n",
            "Epoch [6/50] - Batch loss: 164.0973 - Epoch Loss: 58303.2213 - Avg Loss: 168.0208\n",
            "Epoch [6/50] - Batch loss: 155.7430 - Epoch Loss: 58458.9643 - Avg Loss: 167.9855\n",
            "Epoch [6/50] - Batch loss: 169.1981 - Epoch Loss: 58628.1624 - Avg Loss: 167.9890\n",
            "Epoch [6/50] - Batch loss: 167.9248 - Epoch Loss: 58796.0872 - Avg Loss: 167.9888\n",
            "Epoch [6/50] - Batch loss: 171.1342 - Epoch Loss: 58967.2213 - Avg Loss: 167.9978\n",
            "Epoch [6/50] - Batch loss: 170.7670 - Epoch Loss: 59137.9883 - Avg Loss: 168.0056\n",
            "Epoch [6/50] - Batch loss: 163.6584 - Epoch Loss: 59301.6467 - Avg Loss: 167.9933\n",
            "Epoch [6/50] - Batch loss: 170.2428 - Epoch Loss: 59471.8895 - Avg Loss: 167.9997\n",
            "Epoch [6/50] - Batch loss: 164.4023 - Epoch Loss: 59636.2918 - Avg Loss: 167.9896\n",
            "Epoch [6/50] - Batch loss: 164.1781 - Epoch Loss: 59800.4698 - Avg Loss: 167.9788\n",
            "Epoch [6/50] - Batch loss: 172.9231 - Epoch Loss: 59973.3929 - Avg Loss: 167.9927\n",
            "Epoch [6/50] - Batch loss: 168.9550 - Epoch Loss: 60142.3479 - Avg Loss: 167.9954\n",
            "Epoch [6/50] - Batch loss: 178.1500 - Epoch Loss: 60320.4979 - Avg Loss: 168.0237\n",
            "Epoch [6/50] - Batch loss: 167.8514 - Epoch Loss: 60488.3493 - Avg Loss: 168.0232\n",
            "Epoch [6/50] - Batch loss: 167.7993 - Epoch Loss: 60656.1487 - Avg Loss: 168.0226\n",
            "Epoch [6/50] - Batch loss: 170.7639 - Epoch Loss: 60826.9126 - Avg Loss: 168.0301\n",
            "Epoch [6/50] - Batch loss: 165.0532 - Epoch Loss: 60991.9658 - Avg Loss: 168.0219\n",
            "Epoch [6/50] - Batch loss: 167.1584 - Epoch Loss: 61159.1242 - Avg Loss: 168.0196\n",
            "Epoch [6/50] - Batch loss: 169.4034 - Epoch Loss: 61328.5277 - Avg Loss: 168.0234\n",
            "Epoch [6/50] - Batch loss: 167.0302 - Epoch Loss: 61495.5579 - Avg Loss: 168.0207\n",
            "Epoch [6/50] - Batch loss: 169.4991 - Epoch Loss: 61665.0570 - Avg Loss: 168.0247\n",
            "Epoch [6/50] - Batch loss: 165.9097 - Epoch Loss: 61830.9667 - Avg Loss: 168.0189\n",
            "Epoch [6/50] - Batch loss: 162.1017 - Epoch Loss: 61993.0684 - Avg Loss: 168.0029\n",
            "Epoch [6/50] - Batch loss: 163.2639 - Epoch Loss: 62156.3323 - Avg Loss: 167.9901\n",
            "Epoch [6/50] - Batch loss: 172.8380 - Epoch Loss: 62329.1703 - Avg Loss: 168.0032\n",
            "Epoch [6/50] - Batch loss: 171.3051 - Epoch Loss: 62500.4754 - Avg Loss: 168.0120\n",
            "Epoch [6/50] - Batch loss: 172.7547 - Epoch Loss: 62673.2301 - Avg Loss: 168.0247\n",
            "Epoch [6/50] - Batch loss: 172.9950 - Epoch Loss: 62846.2252 - Avg Loss: 168.0380\n",
            "Epoch [6/50] - Batch loss: 161.6617 - Epoch Loss: 63007.8869 - Avg Loss: 168.0210\n",
            "Epoch [6/50] - Batch loss: 164.3217 - Epoch Loss: 63172.2086 - Avg Loss: 168.0112\n",
            "Epoch [6/50] - Batch loss: 173.4253 - Epoch Loss: 63345.6339 - Avg Loss: 168.0256\n",
            "Epoch [6/50] - Batch loss: 164.3900 - Epoch Loss: 63510.0239 - Avg Loss: 168.0159\n",
            "Epoch [6/50] - Batch loss: 170.7053 - Epoch Loss: 63680.7292 - Avg Loss: 168.0230\n",
            "Epoch [6/50] - Batch loss: 163.6310 - Epoch Loss: 63844.3602 - Avg Loss: 168.0115\n",
            "Epoch [6/50] - Batch loss: 172.2050 - Epoch Loss: 64016.5652 - Avg Loss: 168.0225\n",
            "Epoch [6/50] - Batch loss: 164.2795 - Epoch Loss: 64180.8447 - Avg Loss: 168.0127\n",
            "Epoch [6/50] - Batch loss: 168.1615 - Epoch Loss: 64349.0062 - Avg Loss: 168.0131\n",
            "Epoch [6/50] - Batch loss: 167.5942 - Epoch Loss: 64516.6004 - Avg Loss: 168.0120\n",
            "Epoch [6/50] - Batch loss: 170.2808 - Epoch Loss: 64686.8812 - Avg Loss: 168.0179\n",
            "Epoch [6/50] - Batch loss: 161.8290 - Epoch Loss: 64848.7102 - Avg Loss: 168.0018\n",
            "Epoch [6/50] - Batch loss: 170.3768 - Epoch Loss: 65019.0870 - Avg Loss: 168.0080\n",
            "Epoch [6/50] - Batch loss: 171.9279 - Epoch Loss: 65191.0149 - Avg Loss: 168.0181\n",
            "Epoch [6/50] - Batch loss: 165.4348 - Epoch Loss: 65356.4497 - Avg Loss: 168.0114\n",
            "Epoch [6/50] - Batch loss: 177.1747 - Epoch Loss: 65533.6245 - Avg Loss: 168.0349\n",
            "Epoch [6/50] - Batch loss: 169.0232 - Epoch Loss: 65702.6477 - Avg Loss: 168.0375\n",
            "Epoch [6/50] - Batch loss: 166.1695 - Epoch Loss: 65868.8172 - Avg Loss: 168.0327\n",
            "Epoch [6/50] - Batch loss: 167.1916 - Epoch Loss: 66036.0088 - Avg Loss: 168.0306\n",
            "Epoch [6/50] - Batch loss: 169.6808 - Epoch Loss: 66205.6895 - Avg Loss: 168.0347\n",
            "Epoch [6/50] - Batch loss: 167.2838 - Epoch Loss: 66372.9733 - Avg Loss: 168.0328\n",
            "Epoch [6/50] - Batch loss: 168.2806 - Epoch Loss: 66541.2538 - Avg Loss: 168.0335\n",
            "Epoch [6/50] - Batch loss: 161.8891 - Epoch Loss: 66703.1430 - Avg Loss: 168.0180\n",
            "Epoch [6/50] - Batch loss: 170.3876 - Epoch Loss: 66873.5306 - Avg Loss: 168.0239\n",
            "Epoch [6/50] - Batch loss: 164.9824 - Epoch Loss: 67038.5130 - Avg Loss: 168.0163\n",
            "Epoch [6/50] - Batch loss: 167.1313 - Epoch Loss: 67205.6443 - Avg Loss: 168.0141\n",
            "Epoch [6/50] - Batch loss: 174.6063 - Epoch Loss: 67380.2506 - Avg Loss: 168.0306\n",
            "Epoch [6/50] - Batch loss: 165.6750 - Epoch Loss: 67545.9256 - Avg Loss: 168.0247\n",
            "Epoch [6/50] - Batch loss: 173.3228 - Epoch Loss: 67719.2483 - Avg Loss: 168.0378\n",
            "Epoch [6/50] - Batch loss: 172.3101 - Epoch Loss: 67891.5584 - Avg Loss: 168.0484\n",
            "Epoch [6/50] - Batch loss: 164.4609 - Epoch Loss: 68056.0194 - Avg Loss: 168.0396\n",
            "Epoch [6/50] - Batch loss: 163.2528 - Epoch Loss: 68219.2722 - Avg Loss: 168.0278\n",
            "Epoch [6/50] - Batch loss: 164.7068 - Epoch Loss: 68383.9790 - Avg Loss: 168.0196\n",
            "Epoch [6/50] - Batch loss: 167.0518 - Epoch Loss: 68551.0308 - Avg Loss: 168.0172\n",
            "Epoch [6/50] - Batch loss: 168.4059 - Epoch Loss: 68719.4367 - Avg Loss: 168.0182\n",
            "Epoch [6/50] - Batch loss: 170.9685 - Epoch Loss: 68890.4052 - Avg Loss: 168.0254\n",
            "Epoch [6/50] - Batch loss: 173.3684 - Epoch Loss: 69063.7736 - Avg Loss: 168.0384\n",
            "Epoch [6/50] - Batch loss: 178.1815 - Epoch Loss: 69241.9550 - Avg Loss: 168.0630\n",
            "Epoch [6/50] - Batch loss: 171.6555 - Epoch Loss: 69413.6105 - Avg Loss: 168.0717\n",
            "Epoch [6/50] - Batch loss: 160.6792 - Epoch Loss: 69574.2897 - Avg Loss: 168.0538\n",
            "Epoch [6/50] - Batch loss: 172.5306 - Epoch Loss: 69746.8203 - Avg Loss: 168.0646\n",
            "Epoch [6/50] - Batch loss: 173.9680 - Epoch Loss: 69920.7884 - Avg Loss: 168.0788\n",
            "Epoch [6/50] - Batch loss: 163.3903 - Epoch Loss: 70084.1786 - Avg Loss: 168.0676\n",
            "Epoch [6/50] - Batch loss: 165.2829 - Epoch Loss: 70249.4616 - Avg Loss: 168.0609\n",
            "Epoch [6/50] - Batch loss: 163.3387 - Epoch Loss: 70412.8002 - Avg Loss: 168.0496\n",
            "Epoch [6/50] - Batch loss: 168.4651 - Epoch Loss: 70581.2653 - Avg Loss: 168.0506\n",
            "Epoch [6/50] - Batch loss: 165.4028 - Epoch Loss: 70746.6682 - Avg Loss: 168.0443\n",
            "Epoch [6/50] - Batch loss: 166.6782 - Epoch Loss: 70913.3464 - Avg Loss: 168.0411\n",
            "Epoch [6/50] - Batch loss: 162.6394 - Epoch Loss: 71075.9858 - Avg Loss: 168.0283\n",
            "Epoch [6/50] - Batch loss: 167.6348 - Epoch Loss: 71243.6206 - Avg Loss: 168.0274\n",
            "Epoch [6/50] - Batch loss: 165.2450 - Epoch Loss: 71408.8656 - Avg Loss: 168.0209\n",
            "Epoch [6/50] - Batch loss: 163.1657 - Epoch Loss: 71572.0313 - Avg Loss: 168.0095\n",
            "Epoch [6/50] - Batch loss: 162.1143 - Epoch Loss: 71734.1456 - Avg Loss: 167.9957\n",
            "Epoch [6/50] - Batch loss: 170.6957 - Epoch Loss: 71904.8412 - Avg Loss: 168.0020\n",
            "Epoch [6/50] - Batch loss: 164.6327 - Epoch Loss: 72069.4739 - Avg Loss: 167.9941\n",
            "Epoch [6/50] - Batch loss: 164.8517 - Epoch Loss: 72234.3256 - Avg Loss: 167.9868\n",
            "Epoch [6/50] - Batch loss: 168.5301 - Epoch Loss: 72402.8557 - Avg Loss: 167.9881\n",
            "Epoch [6/50] - Batch loss: 158.8093 - Epoch Loss: 72561.6650 - Avg Loss: 167.9668\n",
            "Epoch [6/50] - Batch loss: 164.8160 - Epoch Loss: 72726.4810 - Avg Loss: 167.9595\n",
            "Epoch [6/50] - Batch loss: 170.7561 - Epoch Loss: 72897.2371 - Avg Loss: 167.9660\n",
            "Epoch [6/50] - Batch loss: 167.0957 - Epoch Loss: 73064.3328 - Avg Loss: 167.9640\n",
            "Epoch [6/50] - Batch loss: 161.0427 - Epoch Loss: 73225.3755 - Avg Loss: 167.9481\n",
            "Epoch [6/50] - Batch loss: 169.1815 - Epoch Loss: 73394.5571 - Avg Loss: 167.9509\n",
            "Epoch [6/50] - Batch loss: 167.6543 - Epoch Loss: 73562.2114 - Avg Loss: 167.9503\n",
            "Epoch [6/50] - Batch loss: 170.6842 - Epoch Loss: 73732.8956 - Avg Loss: 167.9565\n",
            "Epoch [6/50] - Batch loss: 171.6364 - Epoch Loss: 73904.5320 - Avg Loss: 167.9648\n",
            "Epoch [6/50] - Batch loss: 166.1213 - Epoch Loss: 74070.6533 - Avg Loss: 167.9607\n",
            "Epoch [6/50] - Batch loss: 168.3148 - Epoch Loss: 74238.9681 - Avg Loss: 167.9615\n",
            "Epoch [6/50] - Batch loss: 162.5544 - Epoch Loss: 74401.5225 - Avg Loss: 167.9493\n",
            "Epoch [6/50] - Batch loss: 157.6248 - Epoch Loss: 74559.1473 - Avg Loss: 167.9260\n",
            "Epoch [6/50] - Batch loss: 168.2711 - Epoch Loss: 74727.4184 - Avg Loss: 167.9268\n",
            "Epoch [6/50] - Batch loss: 171.2546 - Epoch Loss: 74898.6730 - Avg Loss: 167.9342\n",
            "Epoch [6/50] - Batch loss: 172.5300 - Epoch Loss: 75071.2030 - Avg Loss: 167.9445\n",
            "Epoch [6/50] - Batch loss: 170.1649 - Epoch Loss: 75241.3680 - Avg Loss: 167.9495\n",
            "Epoch [6/50] - Batch loss: 168.8504 - Epoch Loss: 75410.2183 - Avg Loss: 167.9515\n",
            "Epoch [6/50] - Batch loss: 166.0511 - Epoch Loss: 75576.2695 - Avg Loss: 167.9473\n",
            "Epoch [6/50] - Batch loss: 167.3985 - Epoch Loss: 75743.6680 - Avg Loss: 167.9460\n",
            "Epoch [6/50] - Batch loss: 162.6528 - Epoch Loss: 75906.3208 - Avg Loss: 167.9343\n",
            "Epoch [6/50] - Batch loss: 163.1162 - Epoch Loss: 76069.4371 - Avg Loss: 167.9237\n",
            "Epoch [6/50] - Batch loss: 160.1993 - Epoch Loss: 76229.6364 - Avg Loss: 167.9067\n",
            "Epoch [6/50] - Batch loss: 167.8040 - Epoch Loss: 76397.4404 - Avg Loss: 167.9065\n",
            "Epoch [6/50] - Batch loss: 166.5074 - Epoch Loss: 76563.9478 - Avg Loss: 167.9034\n",
            "Epoch [6/50] - Batch loss: 164.1560 - Epoch Loss: 76728.1038 - Avg Loss: 167.8952\n",
            "Epoch [6/50] - Batch loss: 162.9898 - Epoch Loss: 76891.0936 - Avg Loss: 167.8845\n",
            "Epoch [6/50] - Batch loss: 167.5211 - Epoch Loss: 77058.6147 - Avg Loss: 167.8837\n",
            "Epoch [6/50] - Batch loss: 164.2573 - Epoch Loss: 77222.8720 - Avg Loss: 167.8758\n",
            "Epoch [6/50] - Batch loss: 161.4413 - Epoch Loss: 77384.3133 - Avg Loss: 167.8619\n",
            "Epoch [6/50] - Batch loss: 161.8498 - Epoch Loss: 77546.1631 - Avg Loss: 167.8488\n",
            "Epoch [6/50] - Batch loss: 170.8158 - Epoch Loss: 77716.9789 - Avg Loss: 167.8552\n",
            "Epoch [6/50] - Batch loss: 171.5186 - Epoch Loss: 77888.4975 - Avg Loss: 167.8631\n",
            "Epoch [6/50] - Batch loss: 163.0957 - Epoch Loss: 78051.5932 - Avg Loss: 167.8529\n",
            "Epoch [6/50] - Batch loss: 171.5112 - Epoch Loss: 78223.1044 - Avg Loss: 167.8607\n",
            "Epoch [6/50] - Batch loss: 168.2369 - Epoch Loss: 78391.3413 - Avg Loss: 167.8615\n",
            "Epoch [6/50] - Batch loss: 166.0615 - Epoch Loss: 78557.4028 - Avg Loss: 167.8577\n",
            "Epoch [6/50] - Batch loss: 162.7348 - Epoch Loss: 78720.1376 - Avg Loss: 167.8468\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 7/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "116baa5f949a48d3899fd4a1b61cce58"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/50] - Batch loss: 164.8171 - Epoch Loss: 164.8171 - Avg Loss: 164.8171\n",
            "Epoch [7/50] - Batch loss: 162.3757 - Epoch Loss: 327.1928 - Avg Loss: 163.5964\n",
            "Epoch [7/50] - Batch loss: 169.6257 - Epoch Loss: 496.8185 - Avg Loss: 165.6062\n",
            "Epoch [7/50] - Batch loss: 161.8292 - Epoch Loss: 658.6476 - Avg Loss: 164.6619\n",
            "Epoch [7/50] - Batch loss: 164.0978 - Epoch Loss: 822.7454 - Avg Loss: 164.5491\n",
            "Epoch [7/50] - Batch loss: 166.2229 - Epoch Loss: 988.9683 - Avg Loss: 164.8280\n",
            "Epoch [7/50] - Batch loss: 166.6234 - Epoch Loss: 1155.5917 - Avg Loss: 165.0845\n",
            "Epoch [7/50] - Batch loss: 160.4518 - Epoch Loss: 1316.0434 - Avg Loss: 164.5054\n",
            "Epoch [7/50] - Batch loss: 166.8411 - Epoch Loss: 1482.8845 - Avg Loss: 164.7649\n",
            "Epoch [7/50] - Batch loss: 166.4843 - Epoch Loss: 1649.3689 - Avg Loss: 164.9369\n",
            "Epoch [7/50] - Batch loss: 171.8472 - Epoch Loss: 1821.2161 - Avg Loss: 165.5651\n",
            "Epoch [7/50] - Batch loss: 169.4960 - Epoch Loss: 1990.7122 - Avg Loss: 165.8927\n",
            "Epoch [7/50] - Batch loss: 157.8781 - Epoch Loss: 2148.5903 - Avg Loss: 165.2762\n",
            "Epoch [7/50] - Batch loss: 167.7615 - Epoch Loss: 2316.3518 - Avg Loss: 165.4537\n",
            "Epoch [7/50] - Batch loss: 166.7580 - Epoch Loss: 2483.1098 - Avg Loss: 165.5407\n",
            "Epoch [7/50] - Batch loss: 171.7882 - Epoch Loss: 2654.8980 - Avg Loss: 165.9311\n",
            "Epoch [7/50] - Batch loss: 167.6699 - Epoch Loss: 2822.5679 - Avg Loss: 166.0334\n",
            "Epoch [7/50] - Batch loss: 166.7410 - Epoch Loss: 2989.3088 - Avg Loss: 166.0727\n",
            "Epoch [7/50] - Batch loss: 168.8072 - Epoch Loss: 3158.1161 - Avg Loss: 166.2166\n",
            "Epoch [7/50] - Batch loss: 169.3302 - Epoch Loss: 3327.4463 - Avg Loss: 166.3723\n",
            "Epoch [7/50] - Batch loss: 162.1150 - Epoch Loss: 3489.5613 - Avg Loss: 166.1696\n",
            "Epoch [7/50] - Batch loss: 173.9987 - Epoch Loss: 3663.5600 - Avg Loss: 166.5255\n",
            "Epoch [7/50] - Batch loss: 167.3581 - Epoch Loss: 3830.9181 - Avg Loss: 166.5617\n",
            "Epoch [7/50] - Batch loss: 172.3284 - Epoch Loss: 4003.2464 - Avg Loss: 166.8019\n",
            "Epoch [7/50] - Batch loss: 166.3286 - Epoch Loss: 4169.5750 - Avg Loss: 166.7830\n",
            "Epoch [7/50] - Batch loss: 165.1527 - Epoch Loss: 4334.7277 - Avg Loss: 166.7203\n",
            "Epoch [7/50] - Batch loss: 165.3020 - Epoch Loss: 4500.0296 - Avg Loss: 166.6678\n",
            "Epoch [7/50] - Batch loss: 166.0852 - Epoch Loss: 4666.1148 - Avg Loss: 166.6470\n",
            "Epoch [7/50] - Batch loss: 172.7359 - Epoch Loss: 4838.8508 - Avg Loss: 166.8569\n",
            "Epoch [7/50] - Batch loss: 169.5978 - Epoch Loss: 5008.4485 - Avg Loss: 166.9483\n",
            "Epoch [7/50] - Batch loss: 166.8479 - Epoch Loss: 5175.2965 - Avg Loss: 166.9450\n",
            "Epoch [7/50] - Batch loss: 166.1547 - Epoch Loss: 5341.4512 - Avg Loss: 166.9203\n",
            "Epoch [7/50] - Batch loss: 166.5379 - Epoch Loss: 5507.9890 - Avg Loss: 166.9088\n",
            "Epoch [7/50] - Batch loss: 169.9873 - Epoch Loss: 5677.9764 - Avg Loss: 166.9993\n",
            "Epoch [7/50] - Batch loss: 163.5757 - Epoch Loss: 5841.5521 - Avg Loss: 166.9015\n",
            "Epoch [7/50] - Batch loss: 175.9298 - Epoch Loss: 6017.4819 - Avg Loss: 167.1523\n",
            "Epoch [7/50] - Batch loss: 161.5507 - Epoch Loss: 6179.0326 - Avg Loss: 167.0009\n",
            "Epoch [7/50] - Batch loss: 158.6060 - Epoch Loss: 6337.6386 - Avg Loss: 166.7800\n",
            "Epoch [7/50] - Batch loss: 158.0858 - Epoch Loss: 6495.7244 - Avg Loss: 166.5570\n",
            "Epoch [7/50] - Batch loss: 164.0352 - Epoch Loss: 6659.7596 - Avg Loss: 166.4940\n",
            "Epoch [7/50] - Batch loss: 155.4852 - Epoch Loss: 6815.2448 - Avg Loss: 166.2255\n",
            "Epoch [7/50] - Batch loss: 164.3001 - Epoch Loss: 6979.5448 - Avg Loss: 166.1796\n",
            "Epoch [7/50] - Batch loss: 156.7885 - Epoch Loss: 7136.3334 - Avg Loss: 165.9612\n",
            "Epoch [7/50] - Batch loss: 165.6110 - Epoch Loss: 7301.9444 - Avg Loss: 165.9533\n",
            "Epoch [7/50] - Batch loss: 167.7688 - Epoch Loss: 7469.7132 - Avg Loss: 165.9936\n",
            "Epoch [7/50] - Batch loss: 171.9703 - Epoch Loss: 7641.6834 - Avg Loss: 166.1236\n",
            "Epoch [7/50] - Batch loss: 169.4834 - Epoch Loss: 7811.1668 - Avg Loss: 166.1950\n",
            "Epoch [7/50] - Batch loss: 169.1598 - Epoch Loss: 7980.3266 - Avg Loss: 166.2568\n",
            "Epoch [7/50] - Batch loss: 169.4050 - Epoch Loss: 8149.7316 - Avg Loss: 166.3211\n",
            "Epoch [7/50] - Batch loss: 165.8161 - Epoch Loss: 8315.5477 - Avg Loss: 166.3110\n",
            "Epoch [7/50] - Batch loss: 167.2339 - Epoch Loss: 8482.7816 - Avg Loss: 166.3291\n",
            "Epoch [7/50] - Batch loss: 171.3293 - Epoch Loss: 8654.1109 - Avg Loss: 166.4252\n",
            "Epoch [7/50] - Batch loss: 166.2993 - Epoch Loss: 8820.4103 - Avg Loss: 166.4228\n",
            "Epoch [7/50] - Batch loss: 170.7433 - Epoch Loss: 8991.1536 - Avg Loss: 166.5028\n",
            "Epoch [7/50] - Batch loss: 158.4046 - Epoch Loss: 9149.5582 - Avg Loss: 166.3556\n",
            "Epoch [7/50] - Batch loss: 166.9569 - Epoch Loss: 9316.5151 - Avg Loss: 166.3663\n",
            "Epoch [7/50] - Batch loss: 166.1902 - Epoch Loss: 9482.7053 - Avg Loss: 166.3633\n",
            "Epoch [7/50] - Batch loss: 168.4220 - Epoch Loss: 9651.1272 - Avg Loss: 166.3987\n",
            "Epoch [7/50] - Batch loss: 168.8823 - Epoch Loss: 9820.0096 - Avg Loss: 166.4408\n",
            "Epoch [7/50] - Batch loss: 170.4372 - Epoch Loss: 9990.4468 - Avg Loss: 166.5074\n",
            "Epoch [7/50] - Batch loss: 163.2030 - Epoch Loss: 10153.6498 - Avg Loss: 166.4533\n",
            "Epoch [7/50] - Batch loss: 170.1369 - Epoch Loss: 10323.7867 - Avg Loss: 166.5127\n",
            "Epoch [7/50] - Batch loss: 168.3309 - Epoch Loss: 10492.1176 - Avg Loss: 166.5415\n",
            "Epoch [7/50] - Batch loss: 165.5252 - Epoch Loss: 10657.6429 - Avg Loss: 166.5257\n",
            "Epoch [7/50] - Batch loss: 158.4423 - Epoch Loss: 10816.0852 - Avg Loss: 166.4013\n",
            "Epoch [7/50] - Batch loss: 169.8466 - Epoch Loss: 10985.9318 - Avg Loss: 166.4535\n",
            "Epoch [7/50] - Batch loss: 162.9469 - Epoch Loss: 11148.8787 - Avg Loss: 166.4012\n",
            "Epoch [7/50] - Batch loss: 162.4798 - Epoch Loss: 11311.3585 - Avg Loss: 166.3435\n",
            "Epoch [7/50] - Batch loss: 170.8032 - Epoch Loss: 11482.1617 - Avg Loss: 166.4081\n",
            "Epoch [7/50] - Batch loss: 172.5934 - Epoch Loss: 11654.7551 - Avg Loss: 166.4965\n",
            "Epoch [7/50] - Batch loss: 166.4449 - Epoch Loss: 11821.2000 - Avg Loss: 166.4958\n",
            "Epoch [7/50] - Batch loss: 172.9435 - Epoch Loss: 11994.1435 - Avg Loss: 166.5853\n",
            "Epoch [7/50] - Batch loss: 167.6055 - Epoch Loss: 12161.7490 - Avg Loss: 166.5993\n",
            "Epoch [7/50] - Batch loss: 162.4556 - Epoch Loss: 12324.2046 - Avg Loss: 166.5433\n",
            "Epoch [7/50] - Batch loss: 165.2919 - Epoch Loss: 12489.4965 - Avg Loss: 166.5266\n",
            "Epoch [7/50] - Batch loss: 168.6453 - Epoch Loss: 12658.1418 - Avg Loss: 166.5545\n",
            "Epoch [7/50] - Batch loss: 168.9567 - Epoch Loss: 12827.0985 - Avg Loss: 166.5857\n",
            "Epoch [7/50] - Batch loss: 163.5849 - Epoch Loss: 12990.6834 - Avg Loss: 166.5472\n",
            "Epoch [7/50] - Batch loss: 165.7750 - Epoch Loss: 13156.4584 - Avg Loss: 166.5374\n",
            "Epoch [7/50] - Batch loss: 170.6411 - Epoch Loss: 13327.0995 - Avg Loss: 166.5887\n",
            "Epoch [7/50] - Batch loss: 172.1776 - Epoch Loss: 13499.2771 - Avg Loss: 166.6577\n",
            "Epoch [7/50] - Batch loss: 158.6122 - Epoch Loss: 13657.8893 - Avg Loss: 166.5596\n",
            "Epoch [7/50] - Batch loss: 160.6953 - Epoch Loss: 13818.5846 - Avg Loss: 166.4890\n",
            "Epoch [7/50] - Batch loss: 158.4785 - Epoch Loss: 13977.0631 - Avg Loss: 166.3936\n",
            "Epoch [7/50] - Batch loss: 157.4454 - Epoch Loss: 14134.5085 - Avg Loss: 166.2883\n",
            "Epoch [7/50] - Batch loss: 170.5481 - Epoch Loss: 14305.0566 - Avg Loss: 166.3379\n",
            "Epoch [7/50] - Batch loss: 170.8848 - Epoch Loss: 14475.9414 - Avg Loss: 166.3901\n",
            "Epoch [7/50] - Batch loss: 167.2743 - Epoch Loss: 14643.2157 - Avg Loss: 166.4002\n",
            "Epoch [7/50] - Batch loss: 164.3504 - Epoch Loss: 14807.5661 - Avg Loss: 166.3771\n",
            "Epoch [7/50] - Batch loss: 172.7169 - Epoch Loss: 14980.2831 - Avg Loss: 166.4476\n",
            "Epoch [7/50] - Batch loss: 163.4655 - Epoch Loss: 15143.7486 - Avg Loss: 166.4148\n",
            "Epoch [7/50] - Batch loss: 165.6302 - Epoch Loss: 15309.3788 - Avg Loss: 166.4063\n",
            "Epoch [7/50] - Batch loss: 157.6872 - Epoch Loss: 15467.0660 - Avg Loss: 166.3125\n",
            "Epoch [7/50] - Batch loss: 169.4787 - Epoch Loss: 15636.5447 - Avg Loss: 166.3462\n",
            "Epoch [7/50] - Batch loss: 173.0626 - Epoch Loss: 15809.6073 - Avg Loss: 166.4169\n",
            "Epoch [7/50] - Batch loss: 165.3033 - Epoch Loss: 15974.9106 - Avg Loss: 166.4053\n",
            "Epoch [7/50] - Batch loss: 175.8468 - Epoch Loss: 16150.7574 - Avg Loss: 166.5027\n",
            "Epoch [7/50] - Batch loss: 170.8964 - Epoch Loss: 16321.6537 - Avg Loss: 166.5475\n",
            "Epoch [7/50] - Batch loss: 166.9538 - Epoch Loss: 16488.6075 - Avg Loss: 166.5516\n",
            "Epoch [7/50] - Batch loss: 162.0683 - Epoch Loss: 16650.6758 - Avg Loss: 166.5068\n",
            "Epoch [7/50] - Batch loss: 170.6583 - Epoch Loss: 16821.3341 - Avg Loss: 166.5479\n",
            "Epoch [7/50] - Batch loss: 168.2981 - Epoch Loss: 16989.6322 - Avg Loss: 166.5650\n",
            "Epoch [7/50] - Batch loss: 161.0085 - Epoch Loss: 17150.6406 - Avg Loss: 166.5111\n",
            "Epoch [7/50] - Batch loss: 166.4913 - Epoch Loss: 17317.1320 - Avg Loss: 166.5109\n",
            "Epoch [7/50] - Batch loss: 164.6800 - Epoch Loss: 17481.8120 - Avg Loss: 166.4934\n",
            "Epoch [7/50] - Batch loss: 169.0663 - Epoch Loss: 17650.8783 - Avg Loss: 166.5177\n",
            "Epoch [7/50] - Batch loss: 166.9713 - Epoch Loss: 17817.8496 - Avg Loss: 166.5220\n",
            "Epoch [7/50] - Batch loss: 171.3175 - Epoch Loss: 17989.1672 - Avg Loss: 166.5664\n",
            "Epoch [7/50] - Batch loss: 169.5994 - Epoch Loss: 18158.7666 - Avg Loss: 166.5942\n",
            "Epoch [7/50] - Batch loss: 167.7617 - Epoch Loss: 18326.5283 - Avg Loss: 166.6048\n",
            "Epoch [7/50] - Batch loss: 159.9049 - Epoch Loss: 18486.4332 - Avg Loss: 166.5444\n",
            "Epoch [7/50] - Batch loss: 169.9216 - Epoch Loss: 18656.3548 - Avg Loss: 166.5746\n",
            "Epoch [7/50] - Batch loss: 172.2651 - Epoch Loss: 18828.6199 - Avg Loss: 166.6250\n",
            "Epoch [7/50] - Batch loss: 162.9476 - Epoch Loss: 18991.5674 - Avg Loss: 166.5927\n",
            "Epoch [7/50] - Batch loss: 169.8652 - Epoch Loss: 19161.4326 - Avg Loss: 166.6212\n",
            "Epoch [7/50] - Batch loss: 169.6849 - Epoch Loss: 19331.1176 - Avg Loss: 166.6476\n",
            "Epoch [7/50] - Batch loss: 170.8144 - Epoch Loss: 19501.9320 - Avg Loss: 166.6832\n",
            "Epoch [7/50] - Batch loss: 169.6136 - Epoch Loss: 19671.5456 - Avg Loss: 166.7080\n",
            "Epoch [7/50] - Batch loss: 172.7781 - Epoch Loss: 19844.3237 - Avg Loss: 166.7590\n",
            "Epoch [7/50] - Batch loss: 173.4895 - Epoch Loss: 20017.8132 - Avg Loss: 166.8151\n",
            "Epoch [7/50] - Batch loss: 162.5270 - Epoch Loss: 20180.3402 - Avg Loss: 166.7797\n",
            "Epoch [7/50] - Batch loss: 164.7387 - Epoch Loss: 20345.0789 - Avg Loss: 166.7629\n",
            "Epoch [7/50] - Batch loss: 165.8551 - Epoch Loss: 20510.9339 - Avg Loss: 166.7556\n",
            "Epoch [7/50] - Batch loss: 175.3386 - Epoch Loss: 20686.2725 - Avg Loss: 166.8248\n",
            "Epoch [7/50] - Batch loss: 166.0508 - Epoch Loss: 20852.3233 - Avg Loss: 166.8186\n",
            "Epoch [7/50] - Batch loss: 166.4128 - Epoch Loss: 21018.7361 - Avg Loss: 166.8154\n",
            "Epoch [7/50] - Batch loss: 160.9099 - Epoch Loss: 21179.6460 - Avg Loss: 166.7689\n",
            "Epoch [7/50] - Batch loss: 163.4251 - Epoch Loss: 21343.0711 - Avg Loss: 166.7427\n",
            "Epoch [7/50] - Batch loss: 160.9924 - Epoch Loss: 21504.0635 - Avg Loss: 166.6982\n",
            "Epoch [7/50] - Batch loss: 155.3148 - Epoch Loss: 21659.3783 - Avg Loss: 166.6106\n",
            "Epoch [7/50] - Batch loss: 164.2016 - Epoch Loss: 21823.5799 - Avg Loss: 166.5922\n",
            "Epoch [7/50] - Batch loss: 168.3562 - Epoch Loss: 21991.9360 - Avg Loss: 166.6056\n",
            "Epoch [7/50] - Batch loss: 164.3433 - Epoch Loss: 22156.2793 - Avg Loss: 166.5886\n",
            "Epoch [7/50] - Batch loss: 173.4296 - Epoch Loss: 22329.7089 - Avg Loss: 166.6396\n",
            "Epoch [7/50] - Batch loss: 170.3662 - Epoch Loss: 22500.0751 - Avg Loss: 166.6672\n",
            "Epoch [7/50] - Batch loss: 163.2861 - Epoch Loss: 22663.3612 - Avg Loss: 166.6424\n",
            "Epoch [7/50] - Batch loss: 163.4909 - Epoch Loss: 22826.8521 - Avg Loss: 166.6194\n",
            "Epoch [7/50] - Batch loss: 172.2335 - Epoch Loss: 22999.0855 - Avg Loss: 166.6600\n",
            "Epoch [7/50] - Batch loss: 170.8663 - Epoch Loss: 23169.9519 - Avg Loss: 166.6903\n",
            "Epoch [7/50] - Batch loss: 161.5918 - Epoch Loss: 23331.5437 - Avg Loss: 166.6539\n",
            "Epoch [7/50] - Batch loss: 166.1915 - Epoch Loss: 23497.7352 - Avg Loss: 166.6506\n",
            "Epoch [7/50] - Batch loss: 159.8876 - Epoch Loss: 23657.6228 - Avg Loss: 166.6030\n",
            "Epoch [7/50] - Batch loss: 173.8227 - Epoch Loss: 23831.4454 - Avg Loss: 166.6535\n",
            "Epoch [7/50] - Batch loss: 166.9324 - Epoch Loss: 23998.3778 - Avg Loss: 166.6554\n",
            "Epoch [7/50] - Batch loss: 163.7677 - Epoch Loss: 24162.1455 - Avg Loss: 166.6355\n",
            "Epoch [7/50] - Batch loss: 172.6854 - Epoch Loss: 24334.8308 - Avg Loss: 166.6769\n",
            "Epoch [7/50] - Batch loss: 162.8918 - Epoch Loss: 24497.7227 - Avg Loss: 166.6512\n",
            "Epoch [7/50] - Batch loss: 157.5373 - Epoch Loss: 24655.2599 - Avg Loss: 166.5896\n",
            "Epoch [7/50] - Batch loss: 165.5836 - Epoch Loss: 24820.8436 - Avg Loss: 166.5828\n",
            "Epoch [7/50] - Batch loss: 159.4388 - Epoch Loss: 24980.2823 - Avg Loss: 166.5352\n",
            "Epoch [7/50] - Batch loss: 168.9755 - Epoch Loss: 25149.2578 - Avg Loss: 166.5514\n",
            "Epoch [7/50] - Batch loss: 161.9359 - Epoch Loss: 25311.1937 - Avg Loss: 166.5210\n",
            "Epoch [7/50] - Batch loss: 160.0468 - Epoch Loss: 25471.2405 - Avg Loss: 166.4787\n",
            "Epoch [7/50] - Batch loss: 167.1488 - Epoch Loss: 25638.3893 - Avg Loss: 166.4830\n",
            "Epoch [7/50] - Batch loss: 172.9899 - Epoch Loss: 25811.3793 - Avg Loss: 166.5250\n",
            "Epoch [7/50] - Batch loss: 167.0855 - Epoch Loss: 25978.4647 - Avg Loss: 166.5286\n",
            "Epoch [7/50] - Batch loss: 164.4571 - Epoch Loss: 26142.9218 - Avg Loss: 166.5154\n",
            "Epoch [7/50] - Batch loss: 171.5436 - Epoch Loss: 26314.4654 - Avg Loss: 166.5472\n",
            "Epoch [7/50] - Batch loss: 157.3624 - Epoch Loss: 26471.8278 - Avg Loss: 166.4895\n",
            "Epoch [7/50] - Batch loss: 170.8111 - Epoch Loss: 26642.6389 - Avg Loss: 166.5165\n",
            "Epoch [7/50] - Batch loss: 164.2015 - Epoch Loss: 26806.8404 - Avg Loss: 166.5021\n",
            "Epoch [7/50] - Batch loss: 166.1018 - Epoch Loss: 26972.9422 - Avg Loss: 166.4996\n",
            "Epoch [7/50] - Batch loss: 173.0561 - Epoch Loss: 27145.9983 - Avg Loss: 166.5399\n",
            "Epoch [7/50] - Batch loss: 163.5065 - Epoch Loss: 27309.5048 - Avg Loss: 166.5214\n",
            "Epoch [7/50] - Batch loss: 169.5281 - Epoch Loss: 27479.0329 - Avg Loss: 166.5396\n",
            "Epoch [7/50] - Batch loss: 165.8626 - Epoch Loss: 27644.8955 - Avg Loss: 166.5355\n",
            "Epoch [7/50] - Batch loss: 161.1068 - Epoch Loss: 27806.0023 - Avg Loss: 166.5030\n",
            "Epoch [7/50] - Batch loss: 164.0658 - Epoch Loss: 27970.0681 - Avg Loss: 166.4885\n",
            "Epoch [7/50] - Batch loss: 166.3020 - Epoch Loss: 28136.3701 - Avg Loss: 166.4874\n",
            "Epoch [7/50] - Batch loss: 170.0810 - Epoch Loss: 28306.4511 - Avg Loss: 166.5085\n",
            "Epoch [7/50] - Batch loss: 162.8880 - Epoch Loss: 28469.3391 - Avg Loss: 166.4874\n",
            "Epoch [7/50] - Batch loss: 165.8859 - Epoch Loss: 28635.2250 - Avg Loss: 166.4839\n",
            "Epoch [7/50] - Batch loss: 170.0977 - Epoch Loss: 28805.3227 - Avg Loss: 166.5048\n",
            "Epoch [7/50] - Batch loss: 171.7128 - Epoch Loss: 28977.0356 - Avg Loss: 166.5347\n",
            "Epoch [7/50] - Batch loss: 162.6954 - Epoch Loss: 29139.7310 - Avg Loss: 166.5127\n",
            "Epoch [7/50] - Batch loss: 168.3313 - Epoch Loss: 29308.0623 - Avg Loss: 166.5231\n",
            "Epoch [7/50] - Batch loss: 169.6551 - Epoch Loss: 29477.7174 - Avg Loss: 166.5408\n",
            "Epoch [7/50] - Batch loss: 171.8047 - Epoch Loss: 29649.5221 - Avg Loss: 166.5703\n",
            "Epoch [7/50] - Batch loss: 171.0379 - Epoch Loss: 29820.5600 - Avg Loss: 166.5953\n",
            "Epoch [7/50] - Batch loss: 157.5440 - Epoch Loss: 29978.1040 - Avg Loss: 166.5450\n",
            "Epoch [7/50] - Batch loss: 171.2159 - Epoch Loss: 30149.3199 - Avg Loss: 166.5708\n",
            "Epoch [7/50] - Batch loss: 164.5812 - Epoch Loss: 30313.9012 - Avg Loss: 166.5599\n",
            "Epoch [7/50] - Batch loss: 172.2025 - Epoch Loss: 30486.1037 - Avg Loss: 166.5907\n",
            "Epoch [7/50] - Batch loss: 165.2256 - Epoch Loss: 30651.3293 - Avg Loss: 166.5833\n",
            "Epoch [7/50] - Batch loss: 171.0219 - Epoch Loss: 30822.3511 - Avg Loss: 166.6073\n",
            "Epoch [7/50] - Batch loss: 153.2751 - Epoch Loss: 30975.6262 - Avg Loss: 166.5356\n",
            "Epoch [7/50] - Batch loss: 162.7147 - Epoch Loss: 31138.3409 - Avg Loss: 166.5152\n",
            "Epoch [7/50] - Batch loss: 160.0566 - Epoch Loss: 31298.3975 - Avg Loss: 166.4808\n",
            "Epoch [7/50] - Batch loss: 163.7336 - Epoch Loss: 31462.1311 - Avg Loss: 166.4663\n",
            "Epoch [7/50] - Batch loss: 164.8549 - Epoch Loss: 31626.9860 - Avg Loss: 166.4578\n",
            "Epoch [7/50] - Batch loss: 159.7559 - Epoch Loss: 31786.7419 - Avg Loss: 166.4227\n",
            "Epoch [7/50] - Batch loss: 163.2866 - Epoch Loss: 31950.0285 - Avg Loss: 166.4064\n",
            "Epoch [7/50] - Batch loss: 160.8436 - Epoch Loss: 32110.8722 - Avg Loss: 166.3776\n",
            "Epoch [7/50] - Batch loss: 170.3064 - Epoch Loss: 32281.1786 - Avg Loss: 166.3978\n",
            "Epoch [7/50] - Batch loss: 164.3867 - Epoch Loss: 32445.5653 - Avg Loss: 166.3875\n",
            "Epoch [7/50] - Batch loss: 163.9339 - Epoch Loss: 32609.4991 - Avg Loss: 166.3750\n",
            "Epoch [7/50] - Batch loss: 171.7641 - Epoch Loss: 32781.2633 - Avg Loss: 166.4024\n",
            "Epoch [7/50] - Batch loss: 164.5167 - Epoch Loss: 32945.7800 - Avg Loss: 166.3928\n",
            "Epoch [7/50] - Batch loss: 167.4055 - Epoch Loss: 33113.1854 - Avg Loss: 166.3979\n",
            "Epoch [7/50] - Batch loss: 161.9979 - Epoch Loss: 33275.1833 - Avg Loss: 166.3759\n",
            "Epoch [7/50] - Batch loss: 158.4010 - Epoch Loss: 33433.5844 - Avg Loss: 166.3362\n",
            "Epoch [7/50] - Batch loss: 168.7786 - Epoch Loss: 33602.3629 - Avg Loss: 166.3483\n",
            "Epoch [7/50] - Batch loss: 166.4456 - Epoch Loss: 33768.8085 - Avg Loss: 166.3488\n",
            "Epoch [7/50] - Batch loss: 164.6475 - Epoch Loss: 33933.4560 - Avg Loss: 166.3405\n",
            "Epoch [7/50] - Batch loss: 165.0034 - Epoch Loss: 34098.4594 - Avg Loss: 166.3339\n",
            "Epoch [7/50] - Batch loss: 167.2730 - Epoch Loss: 34265.7324 - Avg Loss: 166.3385\n",
            "Epoch [7/50] - Batch loss: 168.1559 - Epoch Loss: 34433.8882 - Avg Loss: 166.3473\n",
            "Epoch [7/50] - Batch loss: 158.7798 - Epoch Loss: 34592.6680 - Avg Loss: 166.3109\n",
            "Epoch [7/50] - Batch loss: 168.0581 - Epoch Loss: 34760.7261 - Avg Loss: 166.3193\n",
            "Epoch [7/50] - Batch loss: 166.7102 - Epoch Loss: 34927.4362 - Avg Loss: 166.3211\n",
            "Epoch [7/50] - Batch loss: 161.3145 - Epoch Loss: 35088.7507 - Avg Loss: 166.2974\n",
            "Epoch [7/50] - Batch loss: 159.6285 - Epoch Loss: 35248.3793 - Avg Loss: 166.2659\n",
            "Epoch [7/50] - Batch loss: 172.4244 - Epoch Loss: 35420.8037 - Avg Loss: 166.2949\n",
            "Epoch [7/50] - Batch loss: 166.2649 - Epoch Loss: 35587.0686 - Avg Loss: 166.2947\n",
            "Epoch [7/50] - Batch loss: 169.8232 - Epoch Loss: 35756.8918 - Avg Loss: 166.3111\n",
            "Epoch [7/50] - Batch loss: 162.8053 - Epoch Loss: 35919.6971 - Avg Loss: 166.2949\n",
            "Epoch [7/50] - Batch loss: 165.0629 - Epoch Loss: 36084.7600 - Avg Loss: 166.2892\n",
            "Epoch [7/50] - Batch loss: 171.6047 - Epoch Loss: 36256.3648 - Avg Loss: 166.3136\n",
            "Epoch [7/50] - Batch loss: 166.9583 - Epoch Loss: 36423.3231 - Avg Loss: 166.3165\n",
            "Epoch [7/50] - Batch loss: 171.2079 - Epoch Loss: 36594.5310 - Avg Loss: 166.3388\n",
            "Epoch [7/50] - Batch loss: 168.4477 - Epoch Loss: 36762.9788 - Avg Loss: 166.3483\n",
            "Epoch [7/50] - Batch loss: 166.7569 - Epoch Loss: 36929.7356 - Avg Loss: 166.3502\n",
            "Epoch [7/50] - Batch loss: 162.3986 - Epoch Loss: 37092.1342 - Avg Loss: 166.3324\n",
            "Epoch [7/50] - Batch loss: 167.6510 - Epoch Loss: 37259.7851 - Avg Loss: 166.3383\n",
            "Epoch [7/50] - Batch loss: 162.5916 - Epoch Loss: 37422.3767 - Avg Loss: 166.3217\n",
            "Epoch [7/50] - Batch loss: 167.7696 - Epoch Loss: 37590.1463 - Avg Loss: 166.3281\n",
            "Epoch [7/50] - Batch loss: 171.4984 - Epoch Loss: 37761.6446 - Avg Loss: 166.3509\n",
            "Epoch [7/50] - Batch loss: 166.7875 - Epoch Loss: 37928.4321 - Avg Loss: 166.3528\n",
            "Epoch [7/50] - Batch loss: 167.1767 - Epoch Loss: 38095.6088 - Avg Loss: 166.3564\n",
            "Epoch [7/50] - Batch loss: 157.8559 - Epoch Loss: 38253.4647 - Avg Loss: 166.3194\n",
            "Epoch [7/50] - Batch loss: 168.0307 - Epoch Loss: 38421.4954 - Avg Loss: 166.3268\n",
            "Epoch [7/50] - Batch loss: 164.7336 - Epoch Loss: 38586.2290 - Avg Loss: 166.3200\n",
            "Epoch [7/50] - Batch loss: 163.8029 - Epoch Loss: 38750.0318 - Avg Loss: 166.3091\n",
            "Epoch [7/50] - Batch loss: 161.7409 - Epoch Loss: 38911.7727 - Avg Loss: 166.2896\n",
            "Epoch [7/50] - Batch loss: 167.5949 - Epoch Loss: 39079.3676 - Avg Loss: 166.2952\n",
            "Epoch [7/50] - Batch loss: 152.3536 - Epoch Loss: 39231.7213 - Avg Loss: 166.2361\n",
            "Epoch [7/50] - Batch loss: 174.3315 - Epoch Loss: 39406.0528 - Avg Loss: 166.2703\n",
            "Epoch [7/50] - Batch loss: 165.4449 - Epoch Loss: 39571.4977 - Avg Loss: 166.2668\n",
            "Epoch [7/50] - Batch loss: 162.7870 - Epoch Loss: 39734.2847 - Avg Loss: 166.2522\n",
            "Epoch [7/50] - Batch loss: 158.9125 - Epoch Loss: 39893.1972 - Avg Loss: 166.2217\n",
            "Epoch [7/50] - Batch loss: 164.6319 - Epoch Loss: 40057.8291 - Avg Loss: 166.2151\n",
            "Epoch [7/50] - Batch loss: 167.2054 - Epoch Loss: 40225.0345 - Avg Loss: 166.2192\n",
            "Epoch [7/50] - Batch loss: 169.6215 - Epoch Loss: 40394.6560 - Avg Loss: 166.2332\n",
            "Epoch [7/50] - Batch loss: 157.0524 - Epoch Loss: 40551.7085 - Avg Loss: 166.1955\n",
            "Epoch [7/50] - Batch loss: 165.0840 - Epoch Loss: 40716.7925 - Avg Loss: 166.1910\n",
            "Epoch [7/50] - Batch loss: 162.9698 - Epoch Loss: 40879.7623 - Avg Loss: 166.1779\n",
            "Epoch [7/50] - Batch loss: 163.0234 - Epoch Loss: 41042.7857 - Avg Loss: 166.1651\n",
            "Epoch [7/50] - Batch loss: 165.0865 - Epoch Loss: 41207.8722 - Avg Loss: 166.1608\n",
            "Epoch [7/50] - Batch loss: 169.9408 - Epoch Loss: 41377.8130 - Avg Loss: 166.1760\n",
            "Epoch [7/50] - Batch loss: 168.2834 - Epoch Loss: 41546.0965 - Avg Loss: 166.1844\n",
            "Epoch [7/50] - Batch loss: 165.5358 - Epoch Loss: 41711.6322 - Avg Loss: 166.1818\n",
            "Epoch [7/50] - Batch loss: 163.5659 - Epoch Loss: 41875.1981 - Avg Loss: 166.1714\n",
            "Epoch [7/50] - Batch loss: 160.8573 - Epoch Loss: 42036.0555 - Avg Loss: 166.1504\n",
            "Epoch [7/50] - Batch loss: 167.9590 - Epoch Loss: 42204.0144 - Avg Loss: 166.1575\n",
            "Epoch [7/50] - Batch loss: 161.9914 - Epoch Loss: 42366.0058 - Avg Loss: 166.1412\n",
            "Epoch [7/50] - Batch loss: 169.6732 - Epoch Loss: 42535.6791 - Avg Loss: 166.1550\n",
            "Epoch [7/50] - Batch loss: 165.1629 - Epoch Loss: 42700.8420 - Avg Loss: 166.1511\n",
            "Epoch [7/50] - Batch loss: 166.3449 - Epoch Loss: 42867.1869 - Avg Loss: 166.1519\n",
            "Epoch [7/50] - Batch loss: 172.2083 - Epoch Loss: 43039.3952 - Avg Loss: 166.1753\n",
            "Epoch [7/50] - Batch loss: 165.0206 - Epoch Loss: 43204.4159 - Avg Loss: 166.1708\n",
            "Epoch [7/50] - Batch loss: 161.8307 - Epoch Loss: 43366.2466 - Avg Loss: 166.1542\n",
            "Epoch [7/50] - Batch loss: 166.3931 - Epoch Loss: 43532.6397 - Avg Loss: 166.1551\n",
            "Epoch [7/50] - Batch loss: 155.6085 - Epoch Loss: 43688.2482 - Avg Loss: 166.1150\n",
            "Epoch [7/50] - Batch loss: 165.8974 - Epoch Loss: 43854.1456 - Avg Loss: 166.1142\n",
            "Epoch [7/50] - Batch loss: 162.7454 - Epoch Loss: 44016.8910 - Avg Loss: 166.1015\n",
            "Epoch [7/50] - Batch loss: 158.6910 - Epoch Loss: 44175.5820 - Avg Loss: 166.0736\n",
            "Epoch [7/50] - Batch loss: 168.0177 - Epoch Loss: 44343.5997 - Avg Loss: 166.0809\n",
            "Epoch [7/50] - Batch loss: 157.7874 - Epoch Loss: 44501.3871 - Avg Loss: 166.0500\n",
            "Epoch [7/50] - Batch loss: 164.5314 - Epoch Loss: 44665.9185 - Avg Loss: 166.0443\n",
            "Epoch [7/50] - Batch loss: 155.9457 - Epoch Loss: 44821.8642 - Avg Loss: 166.0069\n",
            "Epoch [7/50] - Batch loss: 164.6826 - Epoch Loss: 44986.5468 - Avg Loss: 166.0020\n",
            "Epoch [7/50] - Batch loss: 166.9066 - Epoch Loss: 45153.4534 - Avg Loss: 166.0053\n",
            "Epoch [7/50] - Batch loss: 172.7665 - Epoch Loss: 45326.2200 - Avg Loss: 166.0301\n",
            "Epoch [7/50] - Batch loss: 167.7036 - Epoch Loss: 45493.9236 - Avg Loss: 166.0362\n",
            "Epoch [7/50] - Batch loss: 161.6141 - Epoch Loss: 45655.5377 - Avg Loss: 166.0201\n",
            "Epoch [7/50] - Batch loss: 163.3080 - Epoch Loss: 45818.8457 - Avg Loss: 166.0103\n",
            "Epoch [7/50] - Batch loss: 161.5175 - Epoch Loss: 45980.3632 - Avg Loss: 165.9941\n",
            "Epoch [7/50] - Batch loss: 167.6814 - Epoch Loss: 46148.0446 - Avg Loss: 166.0002\n",
            "Epoch [7/50] - Batch loss: 163.4385 - Epoch Loss: 46311.4831 - Avg Loss: 165.9910\n",
            "Epoch [7/50] - Batch loss: 166.3482 - Epoch Loss: 46477.8313 - Avg Loss: 165.9923\n",
            "Epoch [7/50] - Batch loss: 174.4781 - Epoch Loss: 46652.3094 - Avg Loss: 166.0225\n",
            "Epoch [7/50] - Batch loss: 173.9565 - Epoch Loss: 46826.2658 - Avg Loss: 166.0506\n",
            "Epoch [7/50] - Batch loss: 160.8293 - Epoch Loss: 46987.0951 - Avg Loss: 166.0321\n",
            "Epoch [7/50] - Batch loss: 163.5420 - Epoch Loss: 47150.6371 - Avg Loss: 166.0234\n",
            "Epoch [7/50] - Batch loss: 172.0206 - Epoch Loss: 47322.6577 - Avg Loss: 166.0444\n",
            "Epoch [7/50] - Batch loss: 160.4157 - Epoch Loss: 47483.0734 - Avg Loss: 166.0247\n",
            "Epoch [7/50] - Batch loss: 160.1672 - Epoch Loss: 47643.2407 - Avg Loss: 166.0043\n",
            "Epoch [7/50] - Batch loss: 157.8152 - Epoch Loss: 47801.0559 - Avg Loss: 165.9759\n",
            "Epoch [7/50] - Batch loss: 161.6627 - Epoch Loss: 47962.7186 - Avg Loss: 165.9610\n",
            "Epoch [7/50] - Batch loss: 160.1329 - Epoch Loss: 48122.8515 - Avg Loss: 165.9409\n",
            "Epoch [7/50] - Batch loss: 166.7046 - Epoch Loss: 48289.5561 - Avg Loss: 165.9435\n",
            "Epoch [7/50] - Batch loss: 170.0887 - Epoch Loss: 48459.6448 - Avg Loss: 165.9577\n",
            "Epoch [7/50] - Batch loss: 168.1238 - Epoch Loss: 48627.7686 - Avg Loss: 165.9651\n",
            "Epoch [7/50] - Batch loss: 175.2226 - Epoch Loss: 48802.9913 - Avg Loss: 165.9966\n",
            "Epoch [7/50] - Batch loss: 166.6410 - Epoch Loss: 48969.6323 - Avg Loss: 165.9988\n",
            "Epoch [7/50] - Batch loss: 163.5676 - Epoch Loss: 49133.1999 - Avg Loss: 165.9905\n",
            "Epoch [7/50] - Batch loss: 161.9068 - Epoch Loss: 49295.1067 - Avg Loss: 165.9768\n",
            "Epoch [7/50] - Batch loss: 162.1732 - Epoch Loss: 49457.2799 - Avg Loss: 165.9640\n",
            "Epoch [7/50] - Batch loss: 165.3729 - Epoch Loss: 49622.6528 - Avg Loss: 165.9620\n",
            "Epoch [7/50] - Batch loss: 167.4816 - Epoch Loss: 49790.1344 - Avg Loss: 165.9671\n",
            "Epoch [7/50] - Batch loss: 162.4140 - Epoch Loss: 49952.5484 - Avg Loss: 165.9553\n",
            "Epoch [7/50] - Batch loss: 164.7391 - Epoch Loss: 50117.2876 - Avg Loss: 165.9513\n",
            "Epoch [7/50] - Batch loss: 168.0559 - Epoch Loss: 50285.3435 - Avg Loss: 165.9582\n",
            "Epoch [7/50] - Batch loss: 166.4702 - Epoch Loss: 50451.8137 - Avg Loss: 165.9599\n",
            "Epoch [7/50] - Batch loss: 166.4283 - Epoch Loss: 50618.2420 - Avg Loss: 165.9614\n",
            "Epoch [7/50] - Batch loss: 161.4781 - Epoch Loss: 50779.7202 - Avg Loss: 165.9468\n",
            "Epoch [7/50] - Batch loss: 164.3996 - Epoch Loss: 50944.1198 - Avg Loss: 165.9418\n",
            "Epoch [7/50] - Batch loss: 162.0551 - Epoch Loss: 51106.1749 - Avg Loss: 165.9291\n",
            "Epoch [7/50] - Batch loss: 162.9169 - Epoch Loss: 51269.0918 - Avg Loss: 165.9194\n",
            "Epoch [7/50] - Batch loss: 165.6376 - Epoch Loss: 51434.7295 - Avg Loss: 165.9185\n",
            "Epoch [7/50] - Batch loss: 159.0569 - Epoch Loss: 51593.7863 - Avg Loss: 165.8964\n",
            "Epoch [7/50] - Batch loss: 162.5505 - Epoch Loss: 51756.3369 - Avg Loss: 165.8857\n",
            "Epoch [7/50] - Batch loss: 167.8393 - Epoch Loss: 51924.1762 - Avg Loss: 165.8919\n",
            "Epoch [7/50] - Batch loss: 163.5263 - Epoch Loss: 52087.7024 - Avg Loss: 165.8844\n",
            "Epoch [7/50] - Batch loss: 165.1056 - Epoch Loss: 52252.8081 - Avg Loss: 165.8819\n",
            "Epoch [7/50] - Batch loss: 164.9374 - Epoch Loss: 52417.7455 - Avg Loss: 165.8789\n",
            "Epoch [7/50] - Batch loss: 161.4811 - Epoch Loss: 52579.2265 - Avg Loss: 165.8651\n",
            "Epoch [7/50] - Batch loss: 159.0971 - Epoch Loss: 52738.3237 - Avg Loss: 165.8438\n",
            "Epoch [7/50] - Batch loss: 168.2270 - Epoch Loss: 52906.5506 - Avg Loss: 165.8513\n",
            "Epoch [7/50] - Batch loss: 160.8300 - Epoch Loss: 53067.3806 - Avg Loss: 165.8356\n",
            "Epoch [7/50] - Batch loss: 165.7672 - Epoch Loss: 53233.1479 - Avg Loss: 165.8354\n",
            "Epoch [7/50] - Batch loss: 160.1604 - Epoch Loss: 53393.3083 - Avg Loss: 165.8177\n",
            "Epoch [7/50] - Batch loss: 159.1328 - Epoch Loss: 53552.4411 - Avg Loss: 165.7970\n",
            "Epoch [7/50] - Batch loss: 166.8459 - Epoch Loss: 53719.2869 - Avg Loss: 165.8003\n",
            "Epoch [7/50] - Batch loss: 174.3629 - Epoch Loss: 53893.6498 - Avg Loss: 165.8266\n",
            "Epoch [7/50] - Batch loss: 166.1263 - Epoch Loss: 54059.7761 - Avg Loss: 165.8275\n",
            "Epoch [7/50] - Batch loss: 160.3892 - Epoch Loss: 54220.1653 - Avg Loss: 165.8109\n",
            "Epoch [7/50] - Batch loss: 166.0442 - Epoch Loss: 54386.2095 - Avg Loss: 165.8116\n",
            "Epoch [7/50] - Batch loss: 162.3596 - Epoch Loss: 54548.5691 - Avg Loss: 165.8011\n",
            "Epoch [7/50] - Batch loss: 159.6288 - Epoch Loss: 54708.1979 - Avg Loss: 165.7824\n",
            "Epoch [7/50] - Batch loss: 173.7803 - Epoch Loss: 54881.9782 - Avg Loss: 165.8066\n",
            "Epoch [7/50] - Batch loss: 163.2052 - Epoch Loss: 55045.1834 - Avg Loss: 165.7987\n",
            "Epoch [7/50] - Batch loss: 164.4297 - Epoch Loss: 55209.6130 - Avg Loss: 165.7946\n",
            "Epoch [7/50] - Batch loss: 157.1395 - Epoch Loss: 55366.7526 - Avg Loss: 165.7687\n",
            "Epoch [7/50] - Batch loss: 160.7712 - Epoch Loss: 55527.5237 - Avg Loss: 165.7538\n",
            "Epoch [7/50] - Batch loss: 158.6899 - Epoch Loss: 55686.2137 - Avg Loss: 165.7328\n",
            "Epoch [7/50] - Batch loss: 158.5948 - Epoch Loss: 55844.8084 - Avg Loss: 165.7116\n",
            "Epoch [7/50] - Batch loss: 163.3179 - Epoch Loss: 56008.1264 - Avg Loss: 165.7045\n",
            "Epoch [7/50] - Batch loss: 172.2118 - Epoch Loss: 56180.3382 - Avg Loss: 165.7237\n",
            "Epoch [7/50] - Batch loss: 164.8661 - Epoch Loss: 56345.2043 - Avg Loss: 165.7212\n",
            "Epoch [7/50] - Batch loss: 162.7896 - Epoch Loss: 56507.9939 - Avg Loss: 165.7126\n",
            "Epoch [7/50] - Batch loss: 168.8004 - Epoch Loss: 56676.7943 - Avg Loss: 165.7216\n",
            "Epoch [7/50] - Batch loss: 160.3344 - Epoch Loss: 56837.1287 - Avg Loss: 165.7059\n",
            "Epoch [7/50] - Batch loss: 166.2137 - Epoch Loss: 57003.3424 - Avg Loss: 165.7074\n",
            "Epoch [7/50] - Batch loss: 175.0188 - Epoch Loss: 57178.3612 - Avg Loss: 165.7344\n",
            "Epoch [7/50] - Batch loss: 168.7650 - Epoch Loss: 57347.1262 - Avg Loss: 165.7431\n",
            "Epoch [7/50] - Batch loss: 177.8227 - Epoch Loss: 57524.9489 - Avg Loss: 165.7780\n",
            "Epoch [7/50] - Batch loss: 164.8674 - Epoch Loss: 57689.8163 - Avg Loss: 165.7753\n",
            "Epoch [7/50] - Batch loss: 164.7301 - Epoch Loss: 57854.5464 - Avg Loss: 165.7723\n",
            "Epoch [7/50] - Batch loss: 161.9109 - Epoch Loss: 58016.4572 - Avg Loss: 165.7613\n",
            "Epoch [7/50] - Batch loss: 162.6767 - Epoch Loss: 58179.1340 - Avg Loss: 165.7525\n",
            "Epoch [7/50] - Batch loss: 161.0950 - Epoch Loss: 58340.2289 - Avg Loss: 165.7393\n",
            "Epoch [7/50] - Batch loss: 165.5717 - Epoch Loss: 58505.8007 - Avg Loss: 165.7388\n",
            "Epoch [7/50] - Batch loss: 167.9986 - Epoch Loss: 58673.7993 - Avg Loss: 165.7452\n",
            "Epoch [7/50] - Batch loss: 162.9615 - Epoch Loss: 58836.7608 - Avg Loss: 165.7374\n",
            "Epoch [7/50] - Batch loss: 163.0728 - Epoch Loss: 58999.8336 - Avg Loss: 165.7299\n",
            "Epoch [7/50] - Batch loss: 160.3646 - Epoch Loss: 59160.1982 - Avg Loss: 165.7148\n",
            "Epoch [7/50] - Batch loss: 165.8640 - Epoch Loss: 59326.0622 - Avg Loss: 165.7153\n",
            "Epoch [7/50] - Batch loss: 169.2189 - Epoch Loss: 59495.2811 - Avg Loss: 165.7250\n",
            "Epoch [7/50] - Batch loss: 167.1148 - Epoch Loss: 59662.3959 - Avg Loss: 165.7289\n",
            "Epoch [7/50] - Batch loss: 165.9184 - Epoch Loss: 59828.3143 - Avg Loss: 165.7294\n",
            "Epoch [7/50] - Batch loss: 159.9465 - Epoch Loss: 59988.2608 - Avg Loss: 165.7134\n",
            "Epoch [7/50] - Batch loss: 158.7040 - Epoch Loss: 60146.9648 - Avg Loss: 165.6941\n",
            "Epoch [7/50] - Batch loss: 153.6882 - Epoch Loss: 60300.6530 - Avg Loss: 165.6611\n",
            "Epoch [7/50] - Batch loss: 165.1830 - Epoch Loss: 60465.8360 - Avg Loss: 165.6598\n",
            "Epoch [7/50] - Batch loss: 163.2185 - Epoch Loss: 60629.0545 - Avg Loss: 165.6532\n",
            "Epoch [7/50] - Batch loss: 167.0459 - Epoch Loss: 60796.1004 - Avg Loss: 165.6569\n",
            "Epoch [7/50] - Batch loss: 167.8710 - Epoch Loss: 60963.9715 - Avg Loss: 165.6630\n",
            "Epoch [7/50] - Batch loss: 163.7417 - Epoch Loss: 61127.7132 - Avg Loss: 165.6578\n",
            "Epoch [7/50] - Batch loss: 154.1011 - Epoch Loss: 61281.8142 - Avg Loss: 165.6265\n",
            "Epoch [7/50] - Batch loss: 163.4326 - Epoch Loss: 61445.2469 - Avg Loss: 165.6206\n",
            "Epoch [7/50] - Batch loss: 167.5508 - Epoch Loss: 61612.7977 - Avg Loss: 165.6258\n",
            "Epoch [7/50] - Batch loss: 164.7969 - Epoch Loss: 61777.5946 - Avg Loss: 165.6236\n",
            "Epoch [7/50] - Batch loss: 163.0089 - Epoch Loss: 61940.6035 - Avg Loss: 165.6166\n",
            "Epoch [7/50] - Batch loss: 162.8105 - Epoch Loss: 62103.4140 - Avg Loss: 165.6091\n",
            "Epoch [7/50] - Batch loss: 168.4265 - Epoch Loss: 62271.8405 - Avg Loss: 165.6166\n",
            "Epoch [7/50] - Batch loss: 161.4323 - Epoch Loss: 62433.2728 - Avg Loss: 165.6055\n",
            "Epoch [7/50] - Batch loss: 168.0447 - Epoch Loss: 62601.3175 - Avg Loss: 165.6120\n",
            "Epoch [7/50] - Batch loss: 168.0231 - Epoch Loss: 62769.3405 - Avg Loss: 165.6183\n",
            "Epoch [7/50] - Batch loss: 171.9950 - Epoch Loss: 62941.3356 - Avg Loss: 165.6351\n",
            "Epoch [7/50] - Batch loss: 166.3253 - Epoch Loss: 63107.6608 - Avg Loss: 165.6369\n",
            "Epoch [7/50] - Batch loss: 161.5038 - Epoch Loss: 63269.1647 - Avg Loss: 165.6261\n",
            "Epoch [7/50] - Batch loss: 168.1444 - Epoch Loss: 63437.3091 - Avg Loss: 165.6327\n",
            "Epoch [7/50] - Batch loss: 169.0825 - Epoch Loss: 63606.3915 - Avg Loss: 165.6416\n",
            "Epoch [7/50] - Batch loss: 169.9970 - Epoch Loss: 63776.3885 - Avg Loss: 165.6530\n",
            "Epoch [7/50] - Batch loss: 160.8479 - Epoch Loss: 63937.2364 - Avg Loss: 165.6405\n",
            "Epoch [7/50] - Batch loss: 171.1549 - Epoch Loss: 64108.3914 - Avg Loss: 165.6548\n",
            "Epoch [7/50] - Batch loss: 170.2238 - Epoch Loss: 64278.6151 - Avg Loss: 165.6665\n",
            "Epoch [7/50] - Batch loss: 158.0015 - Epoch Loss: 64436.6166 - Avg Loss: 165.6468\n",
            "Epoch [7/50] - Batch loss: 163.0336 - Epoch Loss: 64599.6502 - Avg Loss: 165.6401\n",
            "Epoch [7/50] - Batch loss: 166.3596 - Epoch Loss: 64766.0099 - Avg Loss: 165.6420\n",
            "Epoch [7/50] - Batch loss: 154.9921 - Epoch Loss: 64921.0019 - Avg Loss: 165.6148\n",
            "Epoch [7/50] - Batch loss: 161.4666 - Epoch Loss: 65082.4685 - Avg Loss: 165.6042\n",
            "Epoch [7/50] - Batch loss: 165.8215 - Epoch Loss: 65248.2900 - Avg Loss: 165.6048\n",
            "Epoch [7/50] - Batch loss: 166.9737 - Epoch Loss: 65415.2637 - Avg Loss: 165.6083\n",
            "Epoch [7/50] - Batch loss: 177.5491 - Epoch Loss: 65592.8129 - Avg Loss: 165.6384\n",
            "Epoch [7/50] - Batch loss: 174.7954 - Epoch Loss: 65767.6082 - Avg Loss: 165.6615\n",
            "Epoch [7/50] - Batch loss: 171.6960 - Epoch Loss: 65939.3043 - Avg Loss: 165.6766\n",
            "Epoch [7/50] - Batch loss: 172.1544 - Epoch Loss: 66111.4586 - Avg Loss: 165.6929\n",
            "Epoch [7/50] - Batch loss: 163.6595 - Epoch Loss: 66275.1182 - Avg Loss: 165.6878\n",
            "Epoch [7/50] - Batch loss: 164.2426 - Epoch Loss: 66439.3608 - Avg Loss: 165.6842\n",
            "Epoch [7/50] - Batch loss: 164.1549 - Epoch Loss: 66603.5157 - Avg Loss: 165.6804\n",
            "Epoch [7/50] - Batch loss: 162.4820 - Epoch Loss: 66765.9976 - Avg Loss: 165.6725\n",
            "Epoch [7/50] - Batch loss: 165.5203 - Epoch Loss: 66931.5179 - Avg Loss: 165.6721\n",
            "Epoch [7/50] - Batch loss: 165.2528 - Epoch Loss: 67096.7708 - Avg Loss: 165.6710\n",
            "Epoch [7/50] - Batch loss: 159.8134 - Epoch Loss: 67256.5842 - Avg Loss: 165.6566\n",
            "Epoch [7/50] - Batch loss: 161.2656 - Epoch Loss: 67417.8498 - Avg Loss: 165.6458\n",
            "Epoch [7/50] - Batch loss: 163.8647 - Epoch Loss: 67581.7145 - Avg Loss: 165.6415\n",
            "Epoch [7/50] - Batch loss: 156.9462 - Epoch Loss: 67738.6607 - Avg Loss: 165.6202\n",
            "Epoch [7/50] - Batch loss: 167.1411 - Epoch Loss: 67905.8018 - Avg Loss: 165.6239\n",
            "Epoch [7/50] - Batch loss: 168.1009 - Epoch Loss: 68073.9027 - Avg Loss: 165.6299\n",
            "Epoch [7/50] - Batch loss: 161.8024 - Epoch Loss: 68235.7051 - Avg Loss: 165.6206\n",
            "Epoch [7/50] - Batch loss: 164.6852 - Epoch Loss: 68400.3903 - Avg Loss: 165.6184\n",
            "Epoch [7/50] - Batch loss: 166.2340 - Epoch Loss: 68566.6243 - Avg Loss: 165.6199\n",
            "Epoch [7/50] - Batch loss: 164.9675 - Epoch Loss: 68731.5917 - Avg Loss: 165.6183\n",
            "Epoch [7/50] - Batch loss: 161.2958 - Epoch Loss: 68892.8875 - Avg Loss: 165.6079\n",
            "Epoch [7/50] - Batch loss: 171.2885 - Epoch Loss: 69064.1761 - Avg Loss: 165.6215\n",
            "Epoch [7/50] - Batch loss: 160.8552 - Epoch Loss: 69225.0312 - Avg Loss: 165.6101\n",
            "Epoch [7/50] - Batch loss: 170.2941 - Epoch Loss: 69395.3254 - Avg Loss: 165.6213\n",
            "Epoch [7/50] - Batch loss: 167.8421 - Epoch Loss: 69563.1675 - Avg Loss: 165.6266\n",
            "Epoch [7/50] - Batch loss: 166.9593 - Epoch Loss: 69730.1267 - Avg Loss: 165.6298\n",
            "Epoch [7/50] - Batch loss: 168.1246 - Epoch Loss: 69898.2513 - Avg Loss: 165.6357\n",
            "Epoch [7/50] - Batch loss: 160.2043 - Epoch Loss: 70058.4556 - Avg Loss: 165.6228\n",
            "Epoch [7/50] - Batch loss: 155.1493 - Epoch Loss: 70213.6049 - Avg Loss: 165.5981\n",
            "Epoch [7/50] - Batch loss: 161.1242 - Epoch Loss: 70374.7291 - Avg Loss: 165.5876\n",
            "Epoch [7/50] - Batch loss: 162.0788 - Epoch Loss: 70536.8079 - Avg Loss: 165.5794\n",
            "Epoch [7/50] - Batch loss: 165.3947 - Epoch Loss: 70702.2026 - Avg Loss: 165.5789\n",
            "Epoch [7/50] - Batch loss: 166.2061 - Epoch Loss: 70868.4088 - Avg Loss: 165.5804\n",
            "Epoch [7/50] - Batch loss: 165.6882 - Epoch Loss: 71034.0969 - Avg Loss: 165.5806\n",
            "Epoch [7/50] - Batch loss: 168.1103 - Epoch Loss: 71202.2072 - Avg Loss: 165.5865\n",
            "Epoch [7/50] - Batch loss: 165.8543 - Epoch Loss: 71368.0616 - Avg Loss: 165.5871\n",
            "Epoch [7/50] - Batch loss: 163.8495 - Epoch Loss: 71531.9110 - Avg Loss: 165.5831\n",
            "Epoch [7/50] - Batch loss: 159.0479 - Epoch Loss: 71690.9589 - Avg Loss: 165.5680\n",
            "Epoch [7/50] - Batch loss: 167.1175 - Epoch Loss: 71858.0765 - Avg Loss: 165.5716\n",
            "Epoch [7/50] - Batch loss: 162.5047 - Epoch Loss: 72020.5812 - Avg Loss: 165.5646\n",
            "Epoch [7/50] - Batch loss: 168.7955 - Epoch Loss: 72189.3766 - Avg Loss: 165.5720\n",
            "Epoch [7/50] - Batch loss: 163.1215 - Epoch Loss: 72352.4982 - Avg Loss: 165.5664\n",
            "Epoch [7/50] - Batch loss: 171.8733 - Epoch Loss: 72524.3715 - Avg Loss: 165.5808\n",
            "Epoch [7/50] - Batch loss: 174.3047 - Epoch Loss: 72698.6762 - Avg Loss: 165.6006\n",
            "Epoch [7/50] - Batch loss: 169.3047 - Epoch Loss: 72867.9809 - Avg Loss: 165.6090\n",
            "Epoch [7/50] - Batch loss: 170.9505 - Epoch Loss: 73038.9313 - Avg Loss: 165.6212\n",
            "Epoch [7/50] - Batch loss: 164.1816 - Epoch Loss: 73203.1129 - Avg Loss: 165.6179\n",
            "Epoch [7/50] - Batch loss: 165.0439 - Epoch Loss: 73368.1568 - Avg Loss: 165.6166\n",
            "Epoch [7/50] - Batch loss: 166.6224 - Epoch Loss: 73534.7792 - Avg Loss: 165.6189\n",
            "Epoch [7/50] - Batch loss: 165.4842 - Epoch Loss: 73700.2634 - Avg Loss: 165.6186\n",
            "Epoch [7/50] - Batch loss: 163.8026 - Epoch Loss: 73864.0660 - Avg Loss: 165.6145\n",
            "Epoch [7/50] - Batch loss: 158.2628 - Epoch Loss: 74022.3288 - Avg Loss: 165.5981\n",
            "Epoch [7/50] - Batch loss: 163.8142 - Epoch Loss: 74186.1430 - Avg Loss: 165.5941\n",
            "Epoch [7/50] - Batch loss: 163.2381 - Epoch Loss: 74349.3811 - Avg Loss: 165.5888\n",
            "Epoch [7/50] - Batch loss: 172.7970 - Epoch Loss: 74522.1781 - Avg Loss: 165.6048\n",
            "Epoch [7/50] - Batch loss: 167.3116 - Epoch Loss: 74689.4897 - Avg Loss: 165.6086\n",
            "Epoch [7/50] - Batch loss: 167.3368 - Epoch Loss: 74856.8264 - Avg Loss: 165.6124\n",
            "Epoch [7/50] - Batch loss: 169.5155 - Epoch Loss: 75026.3420 - Avg Loss: 165.6211\n",
            "Epoch [7/50] - Batch loss: 169.8019 - Epoch Loss: 75196.1439 - Avg Loss: 165.6303\n",
            "Epoch [7/50] - Batch loss: 160.5759 - Epoch Loss: 75356.7198 - Avg Loss: 165.6192\n",
            "Epoch [7/50] - Batch loss: 157.6776 - Epoch Loss: 75514.3974 - Avg Loss: 165.6017\n",
            "Epoch [7/50] - Batch loss: 168.7737 - Epoch Loss: 75683.1711 - Avg Loss: 165.6087\n",
            "Epoch [7/50] - Batch loss: 171.9337 - Epoch Loss: 75855.1048 - Avg Loss: 165.6225\n",
            "Epoch [7/50] - Batch loss: 170.3177 - Epoch Loss: 76025.4224 - Avg Loss: 165.6327\n",
            "Epoch [7/50] - Batch loss: 163.1239 - Epoch Loss: 76188.5464 - Avg Loss: 165.6273\n",
            "Epoch [7/50] - Batch loss: 167.1840 - Epoch Loss: 76355.7303 - Avg Loss: 165.6307\n",
            "Epoch [7/50] - Batch loss: 158.3915 - Epoch Loss: 76514.1218 - Avg Loss: 165.6150\n",
            "Epoch [7/50] - Batch loss: 167.6067 - Epoch Loss: 76681.7284 - Avg Loss: 165.6193\n",
            "Epoch [7/50] - Batch loss: 162.8044 - Epoch Loss: 76844.5329 - Avg Loss: 165.6132\n",
            "Epoch [7/50] - Batch loss: 167.4788 - Epoch Loss: 77012.0117 - Avg Loss: 165.6172\n",
            "Epoch [7/50] - Batch loss: 161.3407 - Epoch Loss: 77173.3524 - Avg Loss: 165.6081\n",
            "Epoch [7/50] - Batch loss: 164.3647 - Epoch Loss: 77337.7172 - Avg Loss: 165.6054\n",
            "Epoch [7/50] - Batch loss: 165.9399 - Epoch Loss: 77503.6571 - Avg Loss: 165.6061\n",
            "Epoch [7/50] - Batch loss: 168.7494 - Epoch Loss: 77672.4065 - Avg Loss: 165.6128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 8/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e23603b159da4e34b1daf5c8a64899aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/50] - Batch loss: 171.3440 - Epoch Loss: 171.3440 - Avg Loss: 171.3440\n",
            "Epoch [8/50] - Batch loss: 158.1878 - Epoch Loss: 329.5319 - Avg Loss: 164.7659\n",
            "Epoch [8/50] - Batch loss: 162.1384 - Epoch Loss: 491.6703 - Avg Loss: 163.8901\n",
            "Epoch [8/50] - Batch loss: 164.3650 - Epoch Loss: 656.0353 - Avg Loss: 164.0088\n",
            "Epoch [8/50] - Batch loss: 166.5363 - Epoch Loss: 822.5716 - Avg Loss: 164.5143\n",
            "Epoch [8/50] - Batch loss: 163.6245 - Epoch Loss: 986.1961 - Avg Loss: 164.3660\n",
            "Epoch [8/50] - Batch loss: 163.9199 - Epoch Loss: 1150.1160 - Avg Loss: 164.3023\n",
            "Epoch [8/50] - Batch loss: 167.3550 - Epoch Loss: 1317.4711 - Avg Loss: 164.6839\n",
            "Epoch [8/50] - Batch loss: 163.2536 - Epoch Loss: 1480.7247 - Avg Loss: 164.5250\n",
            "Epoch [8/50] - Batch loss: 164.4374 - Epoch Loss: 1645.1621 - Avg Loss: 164.5162\n",
            "Epoch [8/50] - Batch loss: 166.1262 - Epoch Loss: 1811.2883 - Avg Loss: 164.6626\n",
            "Epoch [8/50] - Batch loss: 160.1324 - Epoch Loss: 1971.4207 - Avg Loss: 164.2851\n",
            "Epoch [8/50] - Batch loss: 163.2978 - Epoch Loss: 2134.7184 - Avg Loss: 164.2091\n",
            "Epoch [8/50] - Batch loss: 166.1479 - Epoch Loss: 2300.8663 - Avg Loss: 164.3476\n",
            "Epoch [8/50] - Batch loss: 169.0749 - Epoch Loss: 2469.9413 - Avg Loss: 164.6628\n",
            "Epoch [8/50] - Batch loss: 158.8952 - Epoch Loss: 2628.8364 - Avg Loss: 164.3023\n",
            "Epoch [8/50] - Batch loss: 172.0522 - Epoch Loss: 2800.8886 - Avg Loss: 164.7582\n",
            "Epoch [8/50] - Batch loss: 168.7197 - Epoch Loss: 2969.6083 - Avg Loss: 164.9782\n",
            "Epoch [8/50] - Batch loss: 171.1775 - Epoch Loss: 3140.7858 - Avg Loss: 165.3045\n",
            "Epoch [8/50] - Batch loss: 164.5821 - Epoch Loss: 3305.3679 - Avg Loss: 165.2684\n",
            "Epoch [8/50] - Batch loss: 162.4679 - Epoch Loss: 3467.8358 - Avg Loss: 165.1350\n",
            "Epoch [8/50] - Batch loss: 172.5307 - Epoch Loss: 3640.3665 - Avg Loss: 165.4712\n",
            "Epoch [8/50] - Batch loss: 167.9830 - Epoch Loss: 3808.3496 - Avg Loss: 165.5804\n",
            "Epoch [8/50] - Batch loss: 163.3581 - Epoch Loss: 3971.7077 - Avg Loss: 165.4878\n",
            "Epoch [8/50] - Batch loss: 168.4729 - Epoch Loss: 4140.1806 - Avg Loss: 165.6072\n",
            "Epoch [8/50] - Batch loss: 162.7332 - Epoch Loss: 4302.9137 - Avg Loss: 165.4967\n",
            "Epoch [8/50] - Batch loss: 169.5022 - Epoch Loss: 4472.4159 - Avg Loss: 165.6450\n",
            "Epoch [8/50] - Batch loss: 167.6435 - Epoch Loss: 4640.0594 - Avg Loss: 165.7164\n",
            "Epoch [8/50] - Batch loss: 166.0345 - Epoch Loss: 4806.0939 - Avg Loss: 165.7274\n",
            "Epoch [8/50] - Batch loss: 166.4563 - Epoch Loss: 4972.5503 - Avg Loss: 165.7517\n",
            "Epoch [8/50] - Batch loss: 163.4070 - Epoch Loss: 5135.9572 - Avg Loss: 165.6760\n",
            "Epoch [8/50] - Batch loss: 161.7697 - Epoch Loss: 5297.7269 - Avg Loss: 165.5540\n",
            "Epoch [8/50] - Batch loss: 165.0705 - Epoch Loss: 5462.7974 - Avg Loss: 165.5393\n",
            "Epoch [8/50] - Batch loss: 165.5332 - Epoch Loss: 5628.3306 - Avg Loss: 165.5391\n",
            "Epoch [8/50] - Batch loss: 172.0270 - Epoch Loss: 5800.3576 - Avg Loss: 165.7245\n",
            "Epoch [8/50] - Batch loss: 165.8676 - Epoch Loss: 5966.2252 - Avg Loss: 165.7285\n",
            "Epoch [8/50] - Batch loss: 168.5596 - Epoch Loss: 6134.7848 - Avg Loss: 165.8050\n",
            "Epoch [8/50] - Batch loss: 164.5290 - Epoch Loss: 6299.3138 - Avg Loss: 165.7714\n",
            "Epoch [8/50] - Batch loss: 168.4692 - Epoch Loss: 6467.7830 - Avg Loss: 165.8406\n",
            "Epoch [8/50] - Batch loss: 162.3442 - Epoch Loss: 6630.1272 - Avg Loss: 165.7532\n",
            "Epoch [8/50] - Batch loss: 160.7554 - Epoch Loss: 6790.8826 - Avg Loss: 165.6313\n",
            "Epoch [8/50] - Batch loss: 166.0875 - Epoch Loss: 6956.9701 - Avg Loss: 165.6421\n",
            "Epoch [8/50] - Batch loss: 172.0841 - Epoch Loss: 7129.0542 - Avg Loss: 165.7920\n",
            "Epoch [8/50] - Batch loss: 167.5452 - Epoch Loss: 7296.5994 - Avg Loss: 165.8318\n",
            "Epoch [8/50] - Batch loss: 161.3691 - Epoch Loss: 7457.9684 - Avg Loss: 165.7326\n",
            "Epoch [8/50] - Batch loss: 175.4853 - Epoch Loss: 7633.4537 - Avg Loss: 165.9446\n",
            "Epoch [8/50] - Batch loss: 157.6763 - Epoch Loss: 7791.1301 - Avg Loss: 165.7687\n",
            "Epoch [8/50] - Batch loss: 158.5053 - Epoch Loss: 7949.6354 - Avg Loss: 165.6174\n",
            "Epoch [8/50] - Batch loss: 162.5776 - Epoch Loss: 8112.2129 - Avg Loss: 165.5554\n",
            "Epoch [8/50] - Batch loss: 157.8680 - Epoch Loss: 8270.0809 - Avg Loss: 165.4016\n",
            "Epoch [8/50] - Batch loss: 158.5409 - Epoch Loss: 8428.6219 - Avg Loss: 165.2671\n",
            "Epoch [8/50] - Batch loss: 160.3485 - Epoch Loss: 8588.9704 - Avg Loss: 165.1725\n",
            "Epoch [8/50] - Batch loss: 163.1522 - Epoch Loss: 8752.1227 - Avg Loss: 165.1344\n",
            "Epoch [8/50] - Batch loss: 168.8421 - Epoch Loss: 8920.9648 - Avg Loss: 165.2031\n",
            "Epoch [8/50] - Batch loss: 164.9220 - Epoch Loss: 9085.8868 - Avg Loss: 165.1979\n",
            "Epoch [8/50] - Batch loss: 172.7949 - Epoch Loss: 9258.6816 - Avg Loss: 165.3336\n",
            "Epoch [8/50] - Batch loss: 162.9564 - Epoch Loss: 9421.6381 - Avg Loss: 165.2919\n",
            "Epoch [8/50] - Batch loss: 157.5714 - Epoch Loss: 9579.2095 - Avg Loss: 165.1588\n",
            "Epoch [8/50] - Batch loss: 164.4758 - Epoch Loss: 9743.6853 - Avg Loss: 165.1472\n",
            "Epoch [8/50] - Batch loss: 162.9921 - Epoch Loss: 9906.6774 - Avg Loss: 165.1113\n",
            "Epoch [8/50] - Batch loss: 167.1337 - Epoch Loss: 10073.8111 - Avg Loss: 165.1444\n",
            "Epoch [8/50] - Batch loss: 160.3979 - Epoch Loss: 10234.2090 - Avg Loss: 165.0679\n",
            "Epoch [8/50] - Batch loss: 156.5980 - Epoch Loss: 10390.8071 - Avg Loss: 164.9334\n",
            "Epoch [8/50] - Batch loss: 162.7152 - Epoch Loss: 10553.5223 - Avg Loss: 164.8988\n",
            "Epoch [8/50] - Batch loss: 166.2386 - Epoch Loss: 10719.7609 - Avg Loss: 164.9194\n",
            "Epoch [8/50] - Batch loss: 168.6799 - Epoch Loss: 10888.4408 - Avg Loss: 164.9764\n",
            "Epoch [8/50] - Batch loss: 167.5302 - Epoch Loss: 11055.9710 - Avg Loss: 165.0145\n",
            "Epoch [8/50] - Batch loss: 173.5355 - Epoch Loss: 11229.5065 - Avg Loss: 165.1398\n",
            "Epoch [8/50] - Batch loss: 162.3367 - Epoch Loss: 11391.8432 - Avg Loss: 165.0992\n",
            "Epoch [8/50] - Batch loss: 163.7751 - Epoch Loss: 11555.6183 - Avg Loss: 165.0803\n",
            "Epoch [8/50] - Batch loss: 157.6627 - Epoch Loss: 11713.2810 - Avg Loss: 164.9758\n",
            "Epoch [8/50] - Batch loss: 160.2935 - Epoch Loss: 11873.5744 - Avg Loss: 164.9108\n",
            "Epoch [8/50] - Batch loss: 165.3848 - Epoch Loss: 12038.9592 - Avg Loss: 164.9172\n",
            "Epoch [8/50] - Batch loss: 170.6821 - Epoch Loss: 12209.6413 - Avg Loss: 164.9952\n",
            "Epoch [8/50] - Batch loss: 161.2975 - Epoch Loss: 12370.9388 - Avg Loss: 164.9459\n",
            "Epoch [8/50] - Batch loss: 169.0541 - Epoch Loss: 12539.9929 - Avg Loss: 164.9999\n",
            "Epoch [8/50] - Batch loss: 167.0545 - Epoch Loss: 12707.0474 - Avg Loss: 165.0266\n",
            "Epoch [8/50] - Batch loss: 165.9469 - Epoch Loss: 12872.9943 - Avg Loss: 165.0384\n",
            "Epoch [8/50] - Batch loss: 163.0808 - Epoch Loss: 13036.0751 - Avg Loss: 165.0136\n",
            "Epoch [8/50] - Batch loss: 164.5134 - Epoch Loss: 13200.5885 - Avg Loss: 165.0074\n",
            "Epoch [8/50] - Batch loss: 166.9107 - Epoch Loss: 13367.4991 - Avg Loss: 165.0309\n",
            "Epoch [8/50] - Batch loss: 161.8817 - Epoch Loss: 13529.3808 - Avg Loss: 164.9924\n",
            "Epoch [8/50] - Batch loss: 170.6810 - Epoch Loss: 13700.0618 - Avg Loss: 165.0610\n",
            "Epoch [8/50] - Batch loss: 156.8607 - Epoch Loss: 13856.9226 - Avg Loss: 164.9634\n",
            "Epoch [8/50] - Batch loss: 164.5986 - Epoch Loss: 14021.5212 - Avg Loss: 164.9591\n",
            "Epoch [8/50] - Batch loss: 161.6030 - Epoch Loss: 14183.1243 - Avg Loss: 164.9200\n",
            "Epoch [8/50] - Batch loss: 167.7707 - Epoch Loss: 14350.8949 - Avg Loss: 164.9528\n",
            "Epoch [8/50] - Batch loss: 173.1162 - Epoch Loss: 14524.0112 - Avg Loss: 165.0456\n",
            "Epoch [8/50] - Batch loss: 163.4137 - Epoch Loss: 14687.4249 - Avg Loss: 165.0272\n",
            "Epoch [8/50] - Batch loss: 171.6404 - Epoch Loss: 14859.0653 - Avg Loss: 165.1007\n",
            "Epoch [8/50] - Batch loss: 153.4503 - Epoch Loss: 15012.5156 - Avg Loss: 164.9727\n",
            "Epoch [8/50] - Batch loss: 168.8979 - Epoch Loss: 15181.4135 - Avg Loss: 165.0154\n",
            "Epoch [8/50] - Batch loss: 164.7105 - Epoch Loss: 15346.1240 - Avg Loss: 165.0121\n",
            "Epoch [8/50] - Batch loss: 169.8192 - Epoch Loss: 15515.9432 - Avg Loss: 165.0632\n",
            "Epoch [8/50] - Batch loss: 170.4336 - Epoch Loss: 15686.3768 - Avg Loss: 165.1198\n",
            "Epoch [8/50] - Batch loss: 162.6592 - Epoch Loss: 15849.0360 - Avg Loss: 165.0941\n",
            "Epoch [8/50] - Batch loss: 170.1938 - Epoch Loss: 16019.2298 - Avg Loss: 165.1467\n",
            "Epoch [8/50] - Batch loss: 168.8546 - Epoch Loss: 16188.0844 - Avg Loss: 165.1845\n",
            "Epoch [8/50] - Batch loss: 175.8565 - Epoch Loss: 16363.9408 - Avg Loss: 165.2923\n",
            "Epoch [8/50] - Batch loss: 170.5872 - Epoch Loss: 16534.5280 - Avg Loss: 165.3453\n",
            "Epoch [8/50] - Batch loss: 166.4185 - Epoch Loss: 16700.9465 - Avg Loss: 165.3559\n",
            "Epoch [8/50] - Batch loss: 163.8731 - Epoch Loss: 16864.8196 - Avg Loss: 165.3414\n",
            "Epoch [8/50] - Batch loss: 159.5218 - Epoch Loss: 17024.3414 - Avg Loss: 165.2849\n",
            "Epoch [8/50] - Batch loss: 167.5264 - Epoch Loss: 17191.8678 - Avg Loss: 165.3064\n",
            "Epoch [8/50] - Batch loss: 160.2312 - Epoch Loss: 17352.0989 - Avg Loss: 165.2581\n",
            "Epoch [8/50] - Batch loss: 167.5508 - Epoch Loss: 17519.6497 - Avg Loss: 165.2797\n",
            "Epoch [8/50] - Batch loss: 166.6187 - Epoch Loss: 17686.2684 - Avg Loss: 165.2922\n",
            "Epoch [8/50] - Batch loss: 158.9468 - Epoch Loss: 17845.2152 - Avg Loss: 165.2335\n",
            "Epoch [8/50] - Batch loss: 169.8154 - Epoch Loss: 18015.0306 - Avg Loss: 165.2755\n",
            "Epoch [8/50] - Batch loss: 162.0580 - Epoch Loss: 18177.0887 - Avg Loss: 165.2463\n",
            "Epoch [8/50] - Batch loss: 169.4018 - Epoch Loss: 18346.4905 - Avg Loss: 165.2837\n",
            "Epoch [8/50] - Batch loss: 164.8516 - Epoch Loss: 18511.3421 - Avg Loss: 165.2798\n",
            "Epoch [8/50] - Batch loss: 161.0212 - Epoch Loss: 18672.3633 - Avg Loss: 165.2422\n",
            "Epoch [8/50] - Batch loss: 160.4985 - Epoch Loss: 18832.8618 - Avg Loss: 165.2005\n",
            "Epoch [8/50] - Batch loss: 173.0037 - Epoch Loss: 19005.8655 - Avg Loss: 165.2684\n",
            "Epoch [8/50] - Batch loss: 167.4733 - Epoch Loss: 19173.3388 - Avg Loss: 165.2874\n",
            "Epoch [8/50] - Batch loss: 164.6737 - Epoch Loss: 19338.0125 - Avg Loss: 165.2822\n",
            "Epoch [8/50] - Batch loss: 166.5709 - Epoch Loss: 19504.5833 - Avg Loss: 165.2931\n",
            "Epoch [8/50] - Batch loss: 169.0986 - Epoch Loss: 19673.6819 - Avg Loss: 165.3251\n",
            "Epoch [8/50] - Batch loss: 166.1627 - Epoch Loss: 19839.8446 - Avg Loss: 165.3320\n",
            "Epoch [8/50] - Batch loss: 157.8960 - Epoch Loss: 19997.7406 - Avg Loss: 165.2706\n",
            "Epoch [8/50] - Batch loss: 170.1891 - Epoch Loss: 20167.9297 - Avg Loss: 165.3109\n",
            "Epoch [8/50] - Batch loss: 167.8525 - Epoch Loss: 20335.7822 - Avg Loss: 165.3316\n",
            "Epoch [8/50] - Batch loss: 163.7710 - Epoch Loss: 20499.5532 - Avg Loss: 165.3190\n",
            "Epoch [8/50] - Batch loss: 170.5119 - Epoch Loss: 20670.0652 - Avg Loss: 165.3605\n",
            "Epoch [8/50] - Batch loss: 169.0897 - Epoch Loss: 20839.1548 - Avg Loss: 165.3901\n",
            "Epoch [8/50] - Batch loss: 165.6257 - Epoch Loss: 21004.7805 - Avg Loss: 165.3920\n",
            "Epoch [8/50] - Batch loss: 159.5165 - Epoch Loss: 21164.2970 - Avg Loss: 165.3461\n",
            "Epoch [8/50] - Batch loss: 170.1881 - Epoch Loss: 21334.4850 - Avg Loss: 165.3836\n",
            "Epoch [8/50] - Batch loss: 171.6689 - Epoch Loss: 21506.1539 - Avg Loss: 165.4320\n",
            "Epoch [8/50] - Batch loss: 161.2889 - Epoch Loss: 21667.4428 - Avg Loss: 165.4003\n",
            "Epoch [8/50] - Batch loss: 161.1395 - Epoch Loss: 21828.5822 - Avg Loss: 165.3680\n",
            "Epoch [8/50] - Batch loss: 162.3393 - Epoch Loss: 21990.9216 - Avg Loss: 165.3453\n",
            "Epoch [8/50] - Batch loss: 156.9617 - Epoch Loss: 22147.8832 - Avg Loss: 165.2827\n",
            "Epoch [8/50] - Batch loss: 163.5259 - Epoch Loss: 22311.4092 - Avg Loss: 165.2697\n",
            "Epoch [8/50] - Batch loss: 166.4763 - Epoch Loss: 22477.8855 - Avg Loss: 165.2786\n",
            "Epoch [8/50] - Batch loss: 169.3187 - Epoch Loss: 22647.2042 - Avg Loss: 165.3081\n",
            "Epoch [8/50] - Batch loss: 164.3803 - Epoch Loss: 22811.5845 - Avg Loss: 165.3013\n",
            "Epoch [8/50] - Batch loss: 169.3201 - Epoch Loss: 22980.9046 - Avg Loss: 165.3302\n",
            "Epoch [8/50] - Batch loss: 171.1618 - Epoch Loss: 23152.0663 - Avg Loss: 165.3719\n",
            "Epoch [8/50] - Batch loss: 177.1977 - Epoch Loss: 23329.2640 - Avg Loss: 165.4558\n",
            "Epoch [8/50] - Batch loss: 163.0513 - Epoch Loss: 23492.3154 - Avg Loss: 165.4388\n",
            "Epoch [8/50] - Batch loss: 164.4086 - Epoch Loss: 23656.7239 - Avg Loss: 165.4316\n",
            "Epoch [8/50] - Batch loss: 169.8953 - Epoch Loss: 23826.6192 - Avg Loss: 165.4626\n",
            "Epoch [8/50] - Batch loss: 171.6808 - Epoch Loss: 23998.3000 - Avg Loss: 165.5055\n",
            "Epoch [8/50] - Batch loss: 166.0186 - Epoch Loss: 24164.3186 - Avg Loss: 165.5090\n",
            "Epoch [8/50] - Batch loss: 164.7649 - Epoch Loss: 24329.0835 - Avg Loss: 165.5040\n",
            "Epoch [8/50] - Batch loss: 175.7011 - Epoch Loss: 24504.7846 - Avg Loss: 165.5729\n",
            "Epoch [8/50] - Batch loss: 170.8568 - Epoch Loss: 24675.6414 - Avg Loss: 165.6083\n",
            "Epoch [8/50] - Batch loss: 170.8852 - Epoch Loss: 24846.5266 - Avg Loss: 165.6435\n",
            "Epoch [8/50] - Batch loss: 155.1313 - Epoch Loss: 25001.6578 - Avg Loss: 165.5739\n",
            "Epoch [8/50] - Batch loss: 168.6170 - Epoch Loss: 25170.2748 - Avg Loss: 165.5939\n",
            "Epoch [8/50] - Batch loss: 159.6952 - Epoch Loss: 25329.9700 - Avg Loss: 165.5554\n",
            "Epoch [8/50] - Batch loss: 162.8081 - Epoch Loss: 25492.7781 - Avg Loss: 165.5375\n",
            "Epoch [8/50] - Batch loss: 167.5699 - Epoch Loss: 25660.3480 - Avg Loss: 165.5506\n",
            "Epoch [8/50] - Batch loss: 171.7977 - Epoch Loss: 25832.1457 - Avg Loss: 165.5907\n",
            "Epoch [8/50] - Batch loss: 162.5239 - Epoch Loss: 25994.6696 - Avg Loss: 165.5711\n",
            "Epoch [8/50] - Batch loss: 167.2104 - Epoch Loss: 26161.8800 - Avg Loss: 165.5815\n",
            "Epoch [8/50] - Batch loss: 166.4936 - Epoch Loss: 26328.3736 - Avg Loss: 165.5873\n",
            "Epoch [8/50] - Batch loss: 169.3210 - Epoch Loss: 26497.6946 - Avg Loss: 165.6106\n",
            "Epoch [8/50] - Batch loss: 171.1917 - Epoch Loss: 26668.8863 - Avg Loss: 165.6453\n",
            "Epoch [8/50] - Batch loss: 158.8207 - Epoch Loss: 26827.7070 - Avg Loss: 165.6031\n",
            "Epoch [8/50] - Batch loss: 160.6896 - Epoch Loss: 26988.3967 - Avg Loss: 165.5730\n",
            "Epoch [8/50] - Batch loss: 165.3594 - Epoch Loss: 27153.7560 - Avg Loss: 165.5717\n",
            "Epoch [8/50] - Batch loss: 165.1001 - Epoch Loss: 27318.8562 - Avg Loss: 165.5688\n",
            "Epoch [8/50] - Batch loss: 169.7835 - Epoch Loss: 27488.6397 - Avg Loss: 165.5942\n",
            "Epoch [8/50] - Batch loss: 164.0866 - Epoch Loss: 27652.7263 - Avg Loss: 165.5852\n",
            "Epoch [8/50] - Batch loss: 168.8756 - Epoch Loss: 27821.6019 - Avg Loss: 165.6048\n",
            "Epoch [8/50] - Batch loss: 171.8721 - Epoch Loss: 27993.4740 - Avg Loss: 165.6419\n",
            "Epoch [8/50] - Batch loss: 162.0454 - Epoch Loss: 28155.5194 - Avg Loss: 165.6207\n",
            "Epoch [8/50] - Batch loss: 163.5533 - Epoch Loss: 28319.0727 - Avg Loss: 165.6086\n",
            "Epoch [8/50] - Batch loss: 164.6987 - Epoch Loss: 28483.7713 - Avg Loss: 165.6033\n",
            "Epoch [8/50] - Batch loss: 163.0069 - Epoch Loss: 28646.7782 - Avg Loss: 165.5883\n",
            "Epoch [8/50] - Batch loss: 162.1242 - Epoch Loss: 28808.9024 - Avg Loss: 165.5684\n",
            "Epoch [8/50] - Batch loss: 164.8711 - Epoch Loss: 28973.7736 - Avg Loss: 165.5644\n",
            "Epoch [8/50] - Batch loss: 165.9808 - Epoch Loss: 29139.7543 - Avg Loss: 165.5668\n",
            "Epoch [8/50] - Batch loss: 162.1966 - Epoch Loss: 29301.9510 - Avg Loss: 165.5477\n",
            "Epoch [8/50] - Batch loss: 159.1756 - Epoch Loss: 29461.1265 - Avg Loss: 165.5119\n",
            "Epoch [8/50] - Batch loss: 164.1638 - Epoch Loss: 29625.2903 - Avg Loss: 165.5044\n",
            "Epoch [8/50] - Batch loss: 161.1453 - Epoch Loss: 29786.4356 - Avg Loss: 165.4802\n",
            "Epoch [8/50] - Batch loss: 162.8367 - Epoch Loss: 29949.2723 - Avg Loss: 165.4656\n",
            "Epoch [8/50] - Batch loss: 159.1008 - Epoch Loss: 30108.3731 - Avg Loss: 165.4306\n",
            "Epoch [8/50] - Batch loss: 166.2441 - Epoch Loss: 30274.6172 - Avg Loss: 165.4351\n",
            "Epoch [8/50] - Batch loss: 167.0919 - Epoch Loss: 30441.7091 - Avg Loss: 165.4441\n",
            "Epoch [8/50] - Batch loss: 171.0062 - Epoch Loss: 30612.7154 - Avg Loss: 165.4741\n",
            "Epoch [8/50] - Batch loss: 173.6907 - Epoch Loss: 30786.4061 - Avg Loss: 165.5183\n",
            "Epoch [8/50] - Batch loss: 165.8268 - Epoch Loss: 30952.2329 - Avg Loss: 165.5200\n",
            "Epoch [8/50] - Batch loss: 159.5551 - Epoch Loss: 31111.7879 - Avg Loss: 165.4882\n",
            "Epoch [8/50] - Batch loss: 163.4234 - Epoch Loss: 31275.2113 - Avg Loss: 165.4773\n",
            "Epoch [8/50] - Batch loss: 158.1342 - Epoch Loss: 31433.3455 - Avg Loss: 165.4387\n",
            "Epoch [8/50] - Batch loss: 167.2161 - Epoch Loss: 31600.5616 - Avg Loss: 165.4480\n",
            "Epoch [8/50] - Batch loss: 161.6150 - Epoch Loss: 31762.1766 - Avg Loss: 165.4280\n",
            "Epoch [8/50] - Batch loss: 164.4696 - Epoch Loss: 31926.6462 - Avg Loss: 165.4230\n",
            "Epoch [8/50] - Batch loss: 165.4854 - Epoch Loss: 32092.1316 - Avg Loss: 165.4234\n",
            "Epoch [8/50] - Batch loss: 165.3451 - Epoch Loss: 32257.4766 - Avg Loss: 165.4230\n",
            "Epoch [8/50] - Batch loss: 158.4582 - Epoch Loss: 32415.9348 - Avg Loss: 165.3874\n",
            "Epoch [8/50] - Batch loss: 163.2708 - Epoch Loss: 32579.2057 - Avg Loss: 165.3767\n",
            "Epoch [8/50] - Batch loss: 170.1551 - Epoch Loss: 32749.3608 - Avg Loss: 165.4008\n",
            "Epoch [8/50] - Batch loss: 160.3407 - Epoch Loss: 32909.7014 - Avg Loss: 165.3754\n",
            "Epoch [8/50] - Batch loss: 173.1164 - Epoch Loss: 33082.8179 - Avg Loss: 165.4141\n",
            "Epoch [8/50] - Batch loss: 166.1534 - Epoch Loss: 33248.9713 - Avg Loss: 165.4178\n",
            "Epoch [8/50] - Batch loss: 161.4445 - Epoch Loss: 33410.4157 - Avg Loss: 165.3981\n",
            "Epoch [8/50] - Batch loss: 162.6969 - Epoch Loss: 33573.1127 - Avg Loss: 165.3848\n",
            "Epoch [8/50] - Batch loss: 164.8229 - Epoch Loss: 33737.9356 - Avg Loss: 165.3820\n",
            "Epoch [8/50] - Batch loss: 168.3052 - Epoch Loss: 33906.2408 - Avg Loss: 165.3963\n",
            "Epoch [8/50] - Batch loss: 163.7565 - Epoch Loss: 34069.9973 - Avg Loss: 165.3883\n",
            "Epoch [8/50] - Batch loss: 167.6337 - Epoch Loss: 34237.6310 - Avg Loss: 165.3992\n",
            "Epoch [8/50] - Batch loss: 168.2828 - Epoch Loss: 34405.9138 - Avg Loss: 165.4130\n",
            "Epoch [8/50] - Batch loss: 166.8590 - Epoch Loss: 34572.7728 - Avg Loss: 165.4200\n",
            "Epoch [8/50] - Batch loss: 156.7888 - Epoch Loss: 34729.5616 - Avg Loss: 165.3789\n",
            "Epoch [8/50] - Batch loss: 159.0494 - Epoch Loss: 34888.6110 - Avg Loss: 165.3489\n",
            "Epoch [8/50] - Batch loss: 162.3264 - Epoch Loss: 35050.9374 - Avg Loss: 165.3346\n",
            "Epoch [8/50] - Batch loss: 161.1286 - Epoch Loss: 35212.0660 - Avg Loss: 165.3149\n",
            "Epoch [8/50] - Batch loss: 169.2845 - Epoch Loss: 35381.3505 - Avg Loss: 165.3334\n",
            "Epoch [8/50] - Batch loss: 157.2846 - Epoch Loss: 35538.6351 - Avg Loss: 165.2960\n",
            "Epoch [8/50] - Batch loss: 163.5019 - Epoch Loss: 35702.1370 - Avg Loss: 165.2877\n",
            "Epoch [8/50] - Batch loss: 160.9731 - Epoch Loss: 35863.1101 - Avg Loss: 165.2678\n",
            "Epoch [8/50] - Batch loss: 157.0979 - Epoch Loss: 36020.2080 - Avg Loss: 165.2303\n",
            "Epoch [8/50] - Batch loss: 164.2818 - Epoch Loss: 36184.4898 - Avg Loss: 165.2260\n",
            "Epoch [8/50] - Batch loss: 163.2309 - Epoch Loss: 36347.7207 - Avg Loss: 165.2169\n",
            "Epoch [8/50] - Batch loss: 171.4673 - Epoch Loss: 36519.1880 - Avg Loss: 165.2452\n",
            "Epoch [8/50] - Batch loss: 162.5246 - Epoch Loss: 36681.7126 - Avg Loss: 165.2329\n",
            "Epoch [8/50] - Batch loss: 174.4106 - Epoch Loss: 36856.1232 - Avg Loss: 165.2741\n",
            "Epoch [8/50] - Batch loss: 172.5659 - Epoch Loss: 37028.6891 - Avg Loss: 165.3066\n",
            "Epoch [8/50] - Batch loss: 169.9074 - Epoch Loss: 37198.5965 - Avg Loss: 165.3271\n",
            "Epoch [8/50] - Batch loss: 165.8397 - Epoch Loss: 37364.4362 - Avg Loss: 165.3294\n",
            "Epoch [8/50] - Batch loss: 159.1987 - Epoch Loss: 37523.6349 - Avg Loss: 165.3024\n",
            "Epoch [8/50] - Batch loss: 162.2093 - Epoch Loss: 37685.8442 - Avg Loss: 165.2888\n",
            "Epoch [8/50] - Batch loss: 167.2262 - Epoch Loss: 37853.0704 - Avg Loss: 165.2973\n",
            "Epoch [8/50] - Batch loss: 164.6565 - Epoch Loss: 38017.7269 - Avg Loss: 165.2945\n",
            "Epoch [8/50] - Batch loss: 171.6643 - Epoch Loss: 38189.3912 - Avg Loss: 165.3220\n",
            "Epoch [8/50] - Batch loss: 172.4315 - Epoch Loss: 38361.8227 - Avg Loss: 165.3527\n",
            "Epoch [8/50] - Batch loss: 166.5200 - Epoch Loss: 38528.3427 - Avg Loss: 165.3577\n",
            "Epoch [8/50] - Batch loss: 163.6520 - Epoch Loss: 38691.9947 - Avg Loss: 165.3504\n",
            "Epoch [8/50] - Batch loss: 168.5578 - Epoch Loss: 38860.5526 - Avg Loss: 165.3641\n",
            "Epoch [8/50] - Batch loss: 163.2463 - Epoch Loss: 39023.7989 - Avg Loss: 165.3551\n",
            "Epoch [8/50] - Batch loss: 162.2533 - Epoch Loss: 39186.0522 - Avg Loss: 165.3420\n",
            "Epoch [8/50] - Batch loss: 167.6024 - Epoch Loss: 39353.6547 - Avg Loss: 165.3515\n",
            "Epoch [8/50] - Batch loss: 157.6810 - Epoch Loss: 39511.3357 - Avg Loss: 165.3194\n",
            "Epoch [8/50] - Batch loss: 168.1101 - Epoch Loss: 39679.4458 - Avg Loss: 165.3310\n",
            "Epoch [8/50] - Batch loss: 170.8077 - Epoch Loss: 39850.2535 - Avg Loss: 165.3537\n",
            "Epoch [8/50] - Batch loss: 167.3596 - Epoch Loss: 40017.6131 - Avg Loss: 165.3620\n",
            "Epoch [8/50] - Batch loss: 163.6538 - Epoch Loss: 40181.2669 - Avg Loss: 165.3550\n",
            "Epoch [8/50] - Batch loss: 171.4571 - Epoch Loss: 40352.7240 - Avg Loss: 165.3800\n",
            "Epoch [8/50] - Batch loss: 168.1814 - Epoch Loss: 40520.9054 - Avg Loss: 165.3915\n",
            "Epoch [8/50] - Batch loss: 165.0933 - Epoch Loss: 40685.9987 - Avg Loss: 165.3902\n",
            "Epoch [8/50] - Batch loss: 165.1416 - Epoch Loss: 40851.1403 - Avg Loss: 165.3892\n",
            "Epoch [8/50] - Batch loss: 168.8240 - Epoch Loss: 41019.9643 - Avg Loss: 165.4031\n",
            "Epoch [8/50] - Batch loss: 165.1540 - Epoch Loss: 41185.1183 - Avg Loss: 165.4021\n",
            "Epoch [8/50] - Batch loss: 161.0050 - Epoch Loss: 41346.1233 - Avg Loss: 165.3845\n",
            "Epoch [8/50] - Batch loss: 167.0847 - Epoch Loss: 41513.2080 - Avg Loss: 165.3913\n",
            "Epoch [8/50] - Batch loss: 164.8136 - Epoch Loss: 41678.0216 - Avg Loss: 165.3890\n",
            "Epoch [8/50] - Batch loss: 170.8925 - Epoch Loss: 41848.9141 - Avg Loss: 165.4107\n",
            "Epoch [8/50] - Batch loss: 161.6397 - Epoch Loss: 42010.5538 - Avg Loss: 165.3959\n",
            "Epoch [8/50] - Batch loss: 161.4352 - Epoch Loss: 42171.9890 - Avg Loss: 165.3803\n",
            "Epoch [8/50] - Batch loss: 162.4765 - Epoch Loss: 42334.4655 - Avg Loss: 165.3690\n",
            "Epoch [8/50] - Batch loss: 166.9330 - Epoch Loss: 42501.3985 - Avg Loss: 165.3751\n",
            "Epoch [8/50] - Batch loss: 169.9153 - Epoch Loss: 42671.3137 - Avg Loss: 165.3927\n",
            "Epoch [8/50] - Batch loss: 168.9078 - Epoch Loss: 42840.2215 - Avg Loss: 165.4063\n",
            "Epoch [8/50] - Batch loss: 168.4115 - Epoch Loss: 43008.6330 - Avg Loss: 165.4178\n",
            "Epoch [8/50] - Batch loss: 167.0024 - Epoch Loss: 43175.6355 - Avg Loss: 165.4239\n",
            "Epoch [8/50] - Batch loss: 172.3400 - Epoch Loss: 43347.9755 - Avg Loss: 165.4503\n",
            "Epoch [8/50] - Batch loss: 177.7550 - Epoch Loss: 43525.7305 - Avg Loss: 165.4971\n",
            "Epoch [8/50] - Batch loss: 159.9721 - Epoch Loss: 43685.7026 - Avg Loss: 165.4761\n",
            "Epoch [8/50] - Batch loss: 161.0219 - Epoch Loss: 43846.7245 - Avg Loss: 165.4593\n",
            "Epoch [8/50] - Batch loss: 163.6609 - Epoch Loss: 44010.3854 - Avg Loss: 165.4526\n",
            "Epoch [8/50] - Batch loss: 165.1742 - Epoch Loss: 44175.5596 - Avg Loss: 165.4515\n",
            "Epoch [8/50] - Batch loss: 164.4091 - Epoch Loss: 44339.9687 - Avg Loss: 165.4476\n",
            "Epoch [8/50] - Batch loss: 167.7347 - Epoch Loss: 44507.7034 - Avg Loss: 165.4561\n",
            "Epoch [8/50] - Batch loss: 164.7775 - Epoch Loss: 44672.4809 - Avg Loss: 165.4536\n",
            "Epoch [8/50] - Batch loss: 170.1723 - Epoch Loss: 44842.6531 - Avg Loss: 165.4710\n",
            "Epoch [8/50] - Batch loss: 164.4442 - Epoch Loss: 45007.0973 - Avg Loss: 165.4673\n",
            "Epoch [8/50] - Batch loss: 159.7529 - Epoch Loss: 45166.8501 - Avg Loss: 165.4463\n",
            "Epoch [8/50] - Batch loss: 166.9436 - Epoch Loss: 45333.7937 - Avg Loss: 165.4518\n",
            "Epoch [8/50] - Batch loss: 158.4534 - Epoch Loss: 45492.2471 - Avg Loss: 165.4264\n",
            "Epoch [8/50] - Batch loss: 162.1071 - Epoch Loss: 45654.3542 - Avg Loss: 165.4143\n",
            "Epoch [8/50] - Batch loss: 160.9270 - Epoch Loss: 45815.2812 - Avg Loss: 165.3981\n",
            "Epoch [8/50] - Batch loss: 155.3368 - Epoch Loss: 45970.6180 - Avg Loss: 165.3619\n",
            "Epoch [8/50] - Batch loss: 155.7661 - Epoch Loss: 46126.3841 - Avg Loss: 165.3275\n",
            "Epoch [8/50] - Batch loss: 167.8212 - Epoch Loss: 46294.2053 - Avg Loss: 165.3364\n",
            "Epoch [8/50] - Batch loss: 158.3271 - Epoch Loss: 46452.5324 - Avg Loss: 165.3115\n",
            "Epoch [8/50] - Batch loss: 164.4623 - Epoch Loss: 46616.9946 - Avg Loss: 165.3085\n",
            "Epoch [8/50] - Batch loss: 163.8866 - Epoch Loss: 46780.8813 - Avg Loss: 165.3035\n",
            "Epoch [8/50] - Batch loss: 172.0297 - Epoch Loss: 46952.9110 - Avg Loss: 165.3272\n",
            "Epoch [8/50] - Batch loss: 161.8228 - Epoch Loss: 47114.7337 - Avg Loss: 165.3149\n",
            "Epoch [8/50] - Batch loss: 168.0330 - Epoch Loss: 47282.7668 - Avg Loss: 165.3244\n",
            "Epoch [8/50] - Batch loss: 164.9763 - Epoch Loss: 47447.7430 - Avg Loss: 165.3231\n",
            "Epoch [8/50] - Batch loss: 161.0922 - Epoch Loss: 47608.8352 - Avg Loss: 165.3085\n",
            "Epoch [8/50] - Batch loss: 172.1437 - Epoch Loss: 47780.9789 - Avg Loss: 165.3321\n",
            "Epoch [8/50] - Batch loss: 169.6130 - Epoch Loss: 47950.5919 - Avg Loss: 165.3469\n",
            "Epoch [8/50] - Batch loss: 158.0756 - Epoch Loss: 48108.6675 - Avg Loss: 165.3219\n",
            "Epoch [8/50] - Batch loss: 166.4621 - Epoch Loss: 48275.1295 - Avg Loss: 165.3258\n",
            "Epoch [8/50] - Batch loss: 167.0317 - Epoch Loss: 48442.1613 - Avg Loss: 165.3316\n",
            "Epoch [8/50] - Batch loss: 167.2249 - Epoch Loss: 48609.3862 - Avg Loss: 165.3380\n",
            "Epoch [8/50] - Batch loss: 154.5184 - Epoch Loss: 48763.9045 - Avg Loss: 165.3014\n",
            "Epoch [8/50] - Batch loss: 162.1962 - Epoch Loss: 48926.1007 - Avg Loss: 165.2909\n",
            "Epoch [8/50] - Batch loss: 175.3924 - Epoch Loss: 49101.4931 - Avg Loss: 165.3249\n",
            "Epoch [8/50] - Batch loss: 165.4396 - Epoch Loss: 49266.9327 - Avg Loss: 165.3253\n",
            "Epoch [8/50] - Batch loss: 166.4229 - Epoch Loss: 49433.3556 - Avg Loss: 165.3289\n",
            "Epoch [8/50] - Batch loss: 165.0523 - Epoch Loss: 49598.4080 - Avg Loss: 165.3280\n",
            "Epoch [8/50] - Batch loss: 171.2565 - Epoch Loss: 49769.6644 - Avg Loss: 165.3477\n",
            "Epoch [8/50] - Batch loss: 165.5547 - Epoch Loss: 49935.2191 - Avg Loss: 165.3484\n",
            "Epoch [8/50] - Batch loss: 164.2738 - Epoch Loss: 50099.4929 - Avg Loss: 165.3449\n",
            "Epoch [8/50] - Batch loss: 162.6729 - Epoch Loss: 50262.1658 - Avg Loss: 165.3361\n",
            "Epoch [8/50] - Batch loss: 165.5940 - Epoch Loss: 50427.7598 - Avg Loss: 165.3369\n",
            "Epoch [8/50] - Batch loss: 167.8407 - Epoch Loss: 50595.6005 - Avg Loss: 165.3451\n",
            "Epoch [8/50] - Batch loss: 161.1275 - Epoch Loss: 50756.7280 - Avg Loss: 165.3314\n",
            "Epoch [8/50] - Batch loss: 166.8263 - Epoch Loss: 50923.5543 - Avg Loss: 165.3362\n",
            "Epoch [8/50] - Batch loss: 167.8031 - Epoch Loss: 51091.3574 - Avg Loss: 165.3442\n",
            "Epoch [8/50] - Batch loss: 165.3315 - Epoch Loss: 51256.6888 - Avg Loss: 165.3442\n",
            "Epoch [8/50] - Batch loss: 176.6353 - Epoch Loss: 51433.3241 - Avg Loss: 165.3805\n",
            "Epoch [8/50] - Batch loss: 169.3677 - Epoch Loss: 51602.6918 - Avg Loss: 165.3932\n",
            "Epoch [8/50] - Batch loss: 168.9910 - Epoch Loss: 51771.6828 - Avg Loss: 165.4047\n",
            "Epoch [8/50] - Batch loss: 163.5766 - Epoch Loss: 51935.2594 - Avg Loss: 165.3989\n",
            "Epoch [8/50] - Batch loss: 167.8143 - Epoch Loss: 52103.0737 - Avg Loss: 165.4066\n",
            "Epoch [8/50] - Batch loss: 166.5466 - Epoch Loss: 52269.6203 - Avg Loss: 165.4102\n",
            "Epoch [8/50] - Batch loss: 167.3684 - Epoch Loss: 52436.9887 - Avg Loss: 165.4164\n",
            "Epoch [8/50] - Batch loss: 165.5767 - Epoch Loss: 52602.5654 - Avg Loss: 165.4169\n",
            "Epoch [8/50] - Batch loss: 172.1721 - Epoch Loss: 52774.7375 - Avg Loss: 165.4380\n",
            "Epoch [8/50] - Batch loss: 161.4257 - Epoch Loss: 52936.1632 - Avg Loss: 165.4255\n",
            "Epoch [8/50] - Batch loss: 173.7478 - Epoch Loss: 53109.9110 - Avg Loss: 165.4514\n",
            "Epoch [8/50] - Batch loss: 171.0702 - Epoch Loss: 53280.9812 - Avg Loss: 165.4689\n",
            "Epoch [8/50] - Batch loss: 162.0183 - Epoch Loss: 53442.9995 - Avg Loss: 165.4582\n",
            "Epoch [8/50] - Batch loss: 161.2678 - Epoch Loss: 53604.2673 - Avg Loss: 165.4453\n",
            "Epoch [8/50] - Batch loss: 165.4527 - Epoch Loss: 53769.7200 - Avg Loss: 165.4453\n",
            "Epoch [8/50] - Batch loss: 173.8283 - Epoch Loss: 53943.5483 - Avg Loss: 165.4710\n",
            "Epoch [8/50] - Batch loss: 172.5043 - Epoch Loss: 54116.0526 - Avg Loss: 165.4925\n",
            "Epoch [8/50] - Batch loss: 167.5512 - Epoch Loss: 54283.6038 - Avg Loss: 165.4988\n",
            "Epoch [8/50] - Batch loss: 169.9505 - Epoch Loss: 54453.5543 - Avg Loss: 165.5123\n",
            "Epoch [8/50] - Batch loss: 161.9952 - Epoch Loss: 54615.5495 - Avg Loss: 165.5017\n",
            "Epoch [8/50] - Batch loss: 169.1302 - Epoch Loss: 54784.6796 - Avg Loss: 165.5126\n",
            "Epoch [8/50] - Batch loss: 164.1371 - Epoch Loss: 54948.8167 - Avg Loss: 165.5085\n",
            "Epoch [8/50] - Batch loss: 172.7474 - Epoch Loss: 55121.5641 - Avg Loss: 165.5302\n",
            "Epoch [8/50] - Batch loss: 170.6731 - Epoch Loss: 55292.2372 - Avg Loss: 165.5456\n",
            "Epoch [8/50] - Batch loss: 165.3866 - Epoch Loss: 55457.6239 - Avg Loss: 165.5451\n",
            "Epoch [8/50] - Batch loss: 170.0373 - Epoch Loss: 55627.6612 - Avg Loss: 165.5585\n",
            "Epoch [8/50] - Batch loss: 161.7134 - Epoch Loss: 55789.3746 - Avg Loss: 165.5471\n",
            "Epoch [8/50] - Batch loss: 170.5084 - Epoch Loss: 55959.8830 - Avg Loss: 165.5618\n",
            "Epoch [8/50] - Batch loss: 163.5536 - Epoch Loss: 56123.4367 - Avg Loss: 165.5559\n",
            "Epoch [8/50] - Batch loss: 164.6062 - Epoch Loss: 56288.0429 - Avg Loss: 165.5531\n",
            "Epoch [8/50] - Batch loss: 173.0842 - Epoch Loss: 56461.1271 - Avg Loss: 165.5752\n",
            "Epoch [8/50] - Batch loss: 173.7558 - Epoch Loss: 56634.8829 - Avg Loss: 165.5991\n",
            "Epoch [8/50] - Batch loss: 170.3804 - Epoch Loss: 56805.2633 - Avg Loss: 165.6130\n",
            "Epoch [8/50] - Batch loss: 171.1802 - Epoch Loss: 56976.4435 - Avg Loss: 165.6292\n",
            "Epoch [8/50] - Batch loss: 161.9824 - Epoch Loss: 57138.4259 - Avg Loss: 165.6186\n",
            "Epoch [8/50] - Batch loss: 170.9672 - Epoch Loss: 57309.3931 - Avg Loss: 165.6341\n",
            "Epoch [8/50] - Batch loss: 168.2928 - Epoch Loss: 57477.6859 - Avg Loss: 165.6417\n",
            "Epoch [8/50] - Batch loss: 165.0061 - Epoch Loss: 57642.6920 - Avg Loss: 165.6399\n",
            "Epoch [8/50] - Batch loss: 170.5947 - Epoch Loss: 57813.2867 - Avg Loss: 165.6541\n",
            "Epoch [8/50] - Batch loss: 172.3754 - Epoch Loss: 57985.6621 - Avg Loss: 165.6733\n",
            "Epoch [8/50] - Batch loss: 165.2386 - Epoch Loss: 58150.9007 - Avg Loss: 165.6721\n",
            "Epoch [8/50] - Batch loss: 167.7187 - Epoch Loss: 58318.6194 - Avg Loss: 165.6779\n",
            "Epoch [8/50] - Batch loss: 165.1094 - Epoch Loss: 58483.7288 - Avg Loss: 165.6763\n",
            "Epoch [8/50] - Batch loss: 168.3887 - Epoch Loss: 58652.1175 - Avg Loss: 165.6839\n",
            "Epoch [8/50] - Batch loss: 175.2682 - Epoch Loss: 58827.3857 - Avg Loss: 165.7109\n",
            "Epoch [8/50] - Batch loss: 168.9791 - Epoch Loss: 58996.3648 - Avg Loss: 165.7201\n",
            "Epoch [8/50] - Batch loss: 165.4086 - Epoch Loss: 59161.7735 - Avg Loss: 165.7193\n",
            "Epoch [8/50] - Batch loss: 165.2570 - Epoch Loss: 59327.0305 - Avg Loss: 165.7180\n",
            "Epoch [8/50] - Batch loss: 163.9022 - Epoch Loss: 59490.9327 - Avg Loss: 165.7129\n",
            "Epoch [8/50] - Batch loss: 175.4687 - Epoch Loss: 59666.4014 - Avg Loss: 165.7400\n",
            "Epoch [8/50] - Batch loss: 175.0173 - Epoch Loss: 59841.4187 - Avg Loss: 165.7657\n",
            "Epoch [8/50] - Batch loss: 161.6400 - Epoch Loss: 60003.0587 - Avg Loss: 165.7543\n",
            "Epoch [8/50] - Batch loss: 167.8642 - Epoch Loss: 60170.9229 - Avg Loss: 165.7601\n",
            "Epoch [8/50] - Batch loss: 157.7722 - Epoch Loss: 60328.6952 - Avg Loss: 165.7382\n",
            "Epoch [8/50] - Batch loss: 157.2495 - Epoch Loss: 60485.9446 - Avg Loss: 165.7149\n",
            "Epoch [8/50] - Batch loss: 162.4302 - Epoch Loss: 60648.3748 - Avg Loss: 165.7059\n",
            "Epoch [8/50] - Batch loss: 165.8092 - Epoch Loss: 60814.1840 - Avg Loss: 165.7062\n",
            "Epoch [8/50] - Batch loss: 162.3979 - Epoch Loss: 60976.5819 - Avg Loss: 165.6972\n",
            "Epoch [8/50] - Batch loss: 167.3456 - Epoch Loss: 61143.9275 - Avg Loss: 165.7017\n",
            "Epoch [8/50] - Batch loss: 167.8880 - Epoch Loss: 61311.8155 - Avg Loss: 165.7076\n",
            "Epoch [8/50] - Batch loss: 169.1927 - Epoch Loss: 61481.0082 - Avg Loss: 165.7170\n",
            "Epoch [8/50] - Batch loss: 160.3533 - Epoch Loss: 61641.3615 - Avg Loss: 165.7026\n",
            "Epoch [8/50] - Batch loss: 161.7813 - Epoch Loss: 61803.1428 - Avg Loss: 165.6921\n",
            "Epoch [8/50] - Batch loss: 165.6111 - Epoch Loss: 61968.7539 - Avg Loss: 165.6919\n",
            "Epoch [8/50] - Batch loss: 165.0121 - Epoch Loss: 62133.7660 - Avg Loss: 165.6900\n",
            "Epoch [8/50] - Batch loss: 168.8838 - Epoch Loss: 62302.6498 - Avg Loss: 165.6985\n",
            "Epoch [8/50] - Batch loss: 160.3243 - Epoch Loss: 62462.9741 - Avg Loss: 165.6843\n",
            "Epoch [8/50] - Batch loss: 171.9175 - Epoch Loss: 62634.8916 - Avg Loss: 165.7008\n",
            "Epoch [8/50] - Batch loss: 158.9003 - Epoch Loss: 62793.7920 - Avg Loss: 165.6828\n",
            "Epoch [8/50] - Batch loss: 164.3682 - Epoch Loss: 62958.1602 - Avg Loss: 165.6794\n",
            "Epoch [8/50] - Batch loss: 161.6833 - Epoch Loss: 63119.8435 - Avg Loss: 165.6689\n",
            "Epoch [8/50] - Batch loss: 160.1424 - Epoch Loss: 63279.9859 - Avg Loss: 165.6544\n",
            "Epoch [8/50] - Batch loss: 169.3654 - Epoch Loss: 63449.3514 - Avg Loss: 165.6641\n",
            "Epoch [8/50] - Batch loss: 171.6066 - Epoch Loss: 63620.9579 - Avg Loss: 165.6796\n",
            "Epoch [8/50] - Batch loss: 168.4742 - Epoch Loss: 63789.4322 - Avg Loss: 165.6868\n",
            "Epoch [8/50] - Batch loss: 160.2967 - Epoch Loss: 63949.7289 - Avg Loss: 165.6729\n",
            "Epoch [8/50] - Batch loss: 162.8546 - Epoch Loss: 64112.5834 - Avg Loss: 165.6656\n",
            "Epoch [8/50] - Batch loss: 171.7413 - Epoch Loss: 64284.3248 - Avg Loss: 165.6812\n",
            "Epoch [8/50] - Batch loss: 161.0571 - Epoch Loss: 64445.3818 - Avg Loss: 165.6694\n",
            "Epoch [8/50] - Batch loss: 169.4435 - Epoch Loss: 64614.8253 - Avg Loss: 165.6790\n",
            "Epoch [8/50] - Batch loss: 169.8841 - Epoch Loss: 64784.7095 - Avg Loss: 165.6898\n",
            "Epoch [8/50] - Batch loss: 170.8009 - Epoch Loss: 64955.5103 - Avg Loss: 165.7028\n",
            "Epoch [8/50] - Batch loss: 173.9359 - Epoch Loss: 65129.4463 - Avg Loss: 165.7238\n",
            "Epoch [8/50] - Batch loss: 168.3659 - Epoch Loss: 65297.8122 - Avg Loss: 165.7305\n",
            "Epoch [8/50] - Batch loss: 167.3438 - Epoch Loss: 65465.1560 - Avg Loss: 165.7346\n",
            "Epoch [8/50] - Batch loss: 171.1948 - Epoch Loss: 65636.3509 - Avg Loss: 165.7484\n",
            "Epoch [8/50] - Batch loss: 166.2021 - Epoch Loss: 65802.5530 - Avg Loss: 165.7495\n",
            "Epoch [8/50] - Batch loss: 172.4723 - Epoch Loss: 65975.0253 - Avg Loss: 165.7664\n",
            "Epoch [8/50] - Batch loss: 168.1977 - Epoch Loss: 66143.2230 - Avg Loss: 165.7725\n",
            "Epoch [8/50] - Batch loss: 176.4811 - Epoch Loss: 66319.7041 - Avg Loss: 165.7993\n",
            "Epoch [8/50] - Batch loss: 170.8821 - Epoch Loss: 66490.5862 - Avg Loss: 165.8119\n",
            "Epoch [8/50] - Batch loss: 162.5135 - Epoch Loss: 66653.0997 - Avg Loss: 165.8037\n",
            "Epoch [8/50] - Batch loss: 161.3558 - Epoch Loss: 66814.4555 - Avg Loss: 165.7927\n",
            "Epoch [8/50] - Batch loss: 167.2481 - Epoch Loss: 66981.7036 - Avg Loss: 165.7963\n",
            "Epoch [8/50] - Batch loss: 166.8877 - Epoch Loss: 67148.5912 - Avg Loss: 165.7990\n",
            "Epoch [8/50] - Batch loss: 162.1867 - Epoch Loss: 67310.7780 - Avg Loss: 165.7901\n",
            "Epoch [8/50] - Batch loss: 169.2692 - Epoch Loss: 67480.0471 - Avg Loss: 165.7986\n",
            "Epoch [8/50] - Batch loss: 167.5592 - Epoch Loss: 67647.6064 - Avg Loss: 165.8030\n",
            "Epoch [8/50] - Batch loss: 168.9097 - Epoch Loss: 67816.5161 - Avg Loss: 165.8106\n",
            "Epoch [8/50] - Batch loss: 169.5176 - Epoch Loss: 67986.0337 - Avg Loss: 165.8196\n",
            "Epoch [8/50] - Batch loss: 176.1137 - Epoch Loss: 68162.1474 - Avg Loss: 165.8446\n",
            "Epoch [8/50] - Batch loss: 168.3593 - Epoch Loss: 68330.5067 - Avg Loss: 165.8507\n",
            "Epoch [8/50] - Batch loss: 166.9976 - Epoch Loss: 68497.5043 - Avg Loss: 165.8535\n",
            "Epoch [8/50] - Batch loss: 167.6005 - Epoch Loss: 68665.1048 - Avg Loss: 165.8577\n",
            "Epoch [8/50] - Batch loss: 165.7285 - Epoch Loss: 68830.8333 - Avg Loss: 165.8574\n",
            "Epoch [8/50] - Batch loss: 165.0972 - Epoch Loss: 68995.9305 - Avg Loss: 165.8556\n",
            "Epoch [8/50] - Batch loss: 164.4917 - Epoch Loss: 69160.4222 - Avg Loss: 165.8523\n",
            "Epoch [8/50] - Batch loss: 165.0280 - Epoch Loss: 69325.4502 - Avg Loss: 165.8504\n",
            "Epoch [8/50] - Batch loss: 172.6006 - Epoch Loss: 69498.0507 - Avg Loss: 165.8665\n",
            "Epoch [8/50] - Batch loss: 173.9249 - Epoch Loss: 69671.9756 - Avg Loss: 165.8857\n",
            "Epoch [8/50] - Batch loss: 161.6760 - Epoch Loss: 69833.6517 - Avg Loss: 165.8757\n",
            "Epoch [8/50] - Batch loss: 165.8099 - Epoch Loss: 69999.4616 - Avg Loss: 165.8755\n",
            "Epoch [8/50] - Batch loss: 163.8278 - Epoch Loss: 70163.2894 - Avg Loss: 165.8707\n",
            "Epoch [8/50] - Batch loss: 167.5589 - Epoch Loss: 70330.8482 - Avg Loss: 165.8746\n",
            "Epoch [8/50] - Batch loss: 171.8513 - Epoch Loss: 70502.6995 - Avg Loss: 165.8887\n",
            "Epoch [8/50] - Batch loss: 167.0990 - Epoch Loss: 70669.7984 - Avg Loss: 165.8915\n",
            "Epoch [8/50] - Batch loss: 169.2185 - Epoch Loss: 70839.0170 - Avg Loss: 165.8993\n",
            "Epoch [8/50] - Batch loss: 170.3313 - Epoch Loss: 71009.3482 - Avg Loss: 165.9097\n",
            "Epoch [8/50] - Batch loss: 175.5083 - Epoch Loss: 71184.8566 - Avg Loss: 165.9321\n",
            "Epoch [8/50] - Batch loss: 170.3376 - Epoch Loss: 71355.1942 - Avg Loss: 165.9423\n",
            "Epoch [8/50] - Batch loss: 165.7341 - Epoch Loss: 71520.9283 - Avg Loss: 165.9418\n",
            "Epoch [8/50] - Batch loss: 169.5359 - Epoch Loss: 71690.4642 - Avg Loss: 165.9501\n",
            "Epoch [8/50] - Batch loss: 162.6361 - Epoch Loss: 71853.1003 - Avg Loss: 165.9425\n",
            "Epoch [8/50] - Batch loss: 170.2794 - Epoch Loss: 72023.3797 - Avg Loss: 165.9525\n",
            "Epoch [8/50] - Batch loss: 172.8552 - Epoch Loss: 72196.2349 - Avg Loss: 165.9684\n",
            "Epoch [8/50] - Batch loss: 178.9794 - Epoch Loss: 72375.2144 - Avg Loss: 165.9982\n",
            "Epoch [8/50] - Batch loss: 173.1698 - Epoch Loss: 72548.3842 - Avg Loss: 166.0146\n",
            "Epoch [8/50] - Batch loss: 175.1912 - Epoch Loss: 72723.5753 - Avg Loss: 166.0356\n",
            "Epoch [8/50] - Batch loss: 159.0210 - Epoch Loss: 72882.5963 - Avg Loss: 166.0196\n",
            "Epoch [8/50] - Batch loss: 174.3405 - Epoch Loss: 73056.9368 - Avg Loss: 166.0385\n",
            "Epoch [8/50] - Batch loss: 169.7872 - Epoch Loss: 73226.7240 - Avg Loss: 166.0470\n",
            "Epoch [8/50] - Batch loss: 169.7223 - Epoch Loss: 73396.4463 - Avg Loss: 166.0553\n",
            "Epoch [8/50] - Batch loss: 169.9380 - Epoch Loss: 73566.3843 - Avg Loss: 166.0641\n",
            "Epoch [8/50] - Batch loss: 174.2601 - Epoch Loss: 73740.6444 - Avg Loss: 166.0825\n",
            "Epoch [8/50] - Batch loss: 179.8524 - Epoch Loss: 73920.4968 - Avg Loss: 166.1135\n",
            "Epoch [8/50] - Batch loss: 166.2774 - Epoch Loss: 74086.7742 - Avg Loss: 166.1138\n",
            "Epoch [8/50] - Batch loss: 177.4031 - Epoch Loss: 74264.1773 - Avg Loss: 166.1391\n",
            "Epoch [8/50] - Batch loss: 176.1075 - Epoch Loss: 74440.2848 - Avg Loss: 166.1613\n",
            "Epoch [8/50] - Batch loss: 179.0656 - Epoch Loss: 74619.3504 - Avg Loss: 166.1901\n",
            "Epoch [8/50] - Batch loss: 175.0624 - Epoch Loss: 74794.4128 - Avg Loss: 166.2098\n",
            "Epoch [8/50] - Batch loss: 176.6003 - Epoch Loss: 74971.0131 - Avg Loss: 166.2328\n",
            "Epoch [8/50] - Batch loss: 179.1749 - Epoch Loss: 75150.1880 - Avg Loss: 166.2615\n",
            "Epoch [8/50] - Batch loss: 165.9929 - Epoch Loss: 75316.1809 - Avg Loss: 166.2609\n",
            "Epoch [8/50] - Batch loss: 160.6864 - Epoch Loss: 75476.8674 - Avg Loss: 166.2486\n",
            "Epoch [8/50] - Batch loss: 172.3443 - Epoch Loss: 75649.2117 - Avg Loss: 166.2620\n",
            "Epoch [8/50] - Batch loss: 172.1227 - Epoch Loss: 75821.3344 - Avg Loss: 166.2749\n",
            "Epoch [8/50] - Batch loss: 173.0211 - Epoch Loss: 75994.3555 - Avg Loss: 166.2896\n",
            "Epoch [8/50] - Batch loss: 156.4422 - Epoch Loss: 76150.7976 - Avg Loss: 166.2681\n",
            "Epoch [8/50] - Batch loss: 173.8515 - Epoch Loss: 76324.6492 - Avg Loss: 166.2846\n",
            "Epoch [8/50] - Batch loss: 168.5457 - Epoch Loss: 76493.1949 - Avg Loss: 166.2896\n",
            "Epoch [8/50] - Batch loss: 171.2943 - Epoch Loss: 76664.4892 - Avg Loss: 166.3004\n",
            "Epoch [8/50] - Batch loss: 171.7295 - Epoch Loss: 76836.2187 - Avg Loss: 166.3122\n",
            "Epoch [8/50] - Batch loss: 172.2807 - Epoch Loss: 77008.4994 - Avg Loss: 166.3251\n",
            "Epoch [8/50] - Batch loss: 168.6072 - Epoch Loss: 77177.1066 - Avg Loss: 166.3300\n",
            "Epoch [8/50] - Batch loss: 174.5421 - Epoch Loss: 77351.6487 - Avg Loss: 166.3476\n",
            "Epoch [8/50] - Batch loss: 173.3519 - Epoch Loss: 77525.0006 - Avg Loss: 166.3627\n",
            "Epoch [8/50] - Batch loss: 165.5440 - Epoch Loss: 77690.5446 - Avg Loss: 166.3609\n",
            "Epoch [8/50] - Batch loss: 169.4387 - Epoch Loss: 77859.9833 - Avg Loss: 166.3675\n",
            "Epoch [8/50] - Batch loss: 161.6564 - Epoch Loss: 78021.6397 - Avg Loss: 166.3574\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 9/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d09dc537ff7458c9aa0196ef43f0556"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/50] - Batch loss: 179.1650 - Epoch Loss: 179.1650 - Avg Loss: 179.1650\n",
            "Epoch [9/50] - Batch loss: 180.8561 - Epoch Loss: 360.0211 - Avg Loss: 180.0106\n",
            "Epoch [9/50] - Batch loss: 169.0801 - Epoch Loss: 529.1013 - Avg Loss: 176.3671\n",
            "Epoch [9/50] - Batch loss: 173.3237 - Epoch Loss: 702.4249 - Avg Loss: 175.6062\n",
            "Epoch [9/50] - Batch loss: 177.7749 - Epoch Loss: 880.1999 - Avg Loss: 176.0400\n",
            "Epoch [9/50] - Batch loss: 170.9957 - Epoch Loss: 1051.1955 - Avg Loss: 175.1993\n",
            "Epoch [9/50] - Batch loss: 171.6058 - Epoch Loss: 1222.8013 - Avg Loss: 174.6859\n",
            "Epoch [9/50] - Batch loss: 179.8857 - Epoch Loss: 1402.6870 - Avg Loss: 175.3359\n",
            "Epoch [9/50] - Batch loss: 170.5937 - Epoch Loss: 1573.2807 - Avg Loss: 174.8090\n",
            "Epoch [9/50] - Batch loss: 174.8812 - Epoch Loss: 1748.1618 - Avg Loss: 174.8162\n",
            "Epoch [9/50] - Batch loss: 160.9299 - Epoch Loss: 1909.0918 - Avg Loss: 173.5538\n",
            "Epoch [9/50] - Batch loss: 165.1495 - Epoch Loss: 2074.2413 - Avg Loss: 172.8534\n",
            "Epoch [9/50] - Batch loss: 171.0083 - Epoch Loss: 2245.2496 - Avg Loss: 172.7115\n",
            "Epoch [9/50] - Batch loss: 175.8178 - Epoch Loss: 2421.0674 - Avg Loss: 172.9334\n",
            "Epoch [9/50] - Batch loss: 166.8320 - Epoch Loss: 2587.8995 - Avg Loss: 172.5266\n",
            "Epoch [9/50] - Batch loss: 175.6658 - Epoch Loss: 2763.5653 - Avg Loss: 172.7228\n",
            "Epoch [9/50] - Batch loss: 176.1758 - Epoch Loss: 2939.7411 - Avg Loss: 172.9259\n",
            "Epoch [9/50] - Batch loss: 164.3834 - Epoch Loss: 3104.1245 - Avg Loss: 172.4514\n",
            "Epoch [9/50] - Batch loss: 165.3979 - Epoch Loss: 3269.5223 - Avg Loss: 172.0801\n",
            "Epoch [9/50] - Batch loss: 164.4922 - Epoch Loss: 3434.0146 - Avg Loss: 171.7007\n",
            "Epoch [9/50] - Batch loss: 168.3232 - Epoch Loss: 3602.3378 - Avg Loss: 171.5399\n",
            "Epoch [9/50] - Batch loss: 171.1746 - Epoch Loss: 3773.5124 - Avg Loss: 171.5233\n",
            "Epoch [9/50] - Batch loss: 169.6325 - Epoch Loss: 3943.1449 - Avg Loss: 171.4411\n",
            "Epoch [9/50] - Batch loss: 173.6490 - Epoch Loss: 4116.7938 - Avg Loss: 171.5331\n",
            "Epoch [9/50] - Batch loss: 159.7028 - Epoch Loss: 4276.4966 - Avg Loss: 171.0599\n",
            "Epoch [9/50] - Batch loss: 173.5265 - Epoch Loss: 4450.0231 - Avg Loss: 171.1547\n",
            "Epoch [9/50] - Batch loss: 170.2629 - Epoch Loss: 4620.2860 - Avg Loss: 171.1217\n",
            "Epoch [9/50] - Batch loss: 170.5841 - Epoch Loss: 4790.8701 - Avg Loss: 171.1025\n",
            "Epoch [9/50] - Batch loss: 174.9257 - Epoch Loss: 4965.7958 - Avg Loss: 171.2343\n",
            "Epoch [9/50] - Batch loss: 168.9264 - Epoch Loss: 5134.7222 - Avg Loss: 171.1574\n",
            "Epoch [9/50] - Batch loss: 174.8949 - Epoch Loss: 5309.6171 - Avg Loss: 171.2780\n",
            "Epoch [9/50] - Batch loss: 169.8795 - Epoch Loss: 5479.4966 - Avg Loss: 171.2343\n",
            "Epoch [9/50] - Batch loss: 172.0225 - Epoch Loss: 5651.5191 - Avg Loss: 171.2582\n",
            "Epoch [9/50] - Batch loss: 173.0119 - Epoch Loss: 5824.5310 - Avg Loss: 171.3097\n",
            "Epoch [9/50] - Batch loss: 174.0578 - Epoch Loss: 5998.5889 - Avg Loss: 171.3883\n",
            "Epoch [9/50] - Batch loss: 174.0570 - Epoch Loss: 6172.6459 - Avg Loss: 171.4624\n",
            "Epoch [9/50] - Batch loss: 176.6863 - Epoch Loss: 6349.3322 - Avg Loss: 171.6036\n",
            "Epoch [9/50] - Batch loss: 171.9272 - Epoch Loss: 6521.2593 - Avg Loss: 171.6121\n",
            "Epoch [9/50] - Batch loss: 175.0353 - Epoch Loss: 6696.2946 - Avg Loss: 171.6999\n",
            "Epoch [9/50] - Batch loss: 166.3255 - Epoch Loss: 6862.6201 - Avg Loss: 171.5655\n",
            "Epoch [9/50] - Batch loss: 165.3198 - Epoch Loss: 7027.9399 - Avg Loss: 171.4132\n",
            "Epoch [9/50] - Batch loss: 169.4356 - Epoch Loss: 7197.3755 - Avg Loss: 171.3661\n",
            "Epoch [9/50] - Batch loss: 174.3207 - Epoch Loss: 7371.6962 - Avg Loss: 171.4348\n",
            "Epoch [9/50] - Batch loss: 169.3999 - Epoch Loss: 7541.0961 - Avg Loss: 171.3885\n",
            "Epoch [9/50] - Batch loss: 170.2816 - Epoch Loss: 7711.3777 - Avg Loss: 171.3639\n",
            "Epoch [9/50] - Batch loss: 174.2279 - Epoch Loss: 7885.6056 - Avg Loss: 171.4262\n",
            "Epoch [9/50] - Batch loss: 171.6350 - Epoch Loss: 8057.2405 - Avg Loss: 171.4306\n",
            "Epoch [9/50] - Batch loss: 171.9804 - Epoch Loss: 8229.2209 - Avg Loss: 171.4421\n",
            "Epoch [9/50] - Batch loss: 174.5829 - Epoch Loss: 8403.8038 - Avg Loss: 171.5062\n",
            "Epoch [9/50] - Batch loss: 178.1724 - Epoch Loss: 8581.9762 - Avg Loss: 171.6395\n",
            "Epoch [9/50] - Batch loss: 175.8339 - Epoch Loss: 8757.8101 - Avg Loss: 171.7218\n",
            "Epoch [9/50] - Batch loss: 168.5060 - Epoch Loss: 8926.3161 - Avg Loss: 171.6599\n",
            "Epoch [9/50] - Batch loss: 155.2790 - Epoch Loss: 9081.5950 - Avg Loss: 171.3508\n",
            "Epoch [9/50] - Batch loss: 171.2970 - Epoch Loss: 9252.8920 - Avg Loss: 171.3499\n",
            "Epoch [9/50] - Batch loss: 167.7447 - Epoch Loss: 9420.6367 - Avg Loss: 171.2843\n",
            "Epoch [9/50] - Batch loss: 172.2283 - Epoch Loss: 9592.8650 - Avg Loss: 171.3012\n",
            "Epoch [9/50] - Batch loss: 169.6301 - Epoch Loss: 9762.4951 - Avg Loss: 171.2718\n",
            "Epoch [9/50] - Batch loss: 166.6520 - Epoch Loss: 9929.1471 - Avg Loss: 171.1922\n",
            "Epoch [9/50] - Batch loss: 164.3347 - Epoch Loss: 10093.4818 - Avg Loss: 171.0760\n",
            "Epoch [9/50] - Batch loss: 169.8621 - Epoch Loss: 10263.3439 - Avg Loss: 171.0557\n",
            "Epoch [9/50] - Batch loss: 163.7037 - Epoch Loss: 10427.0476 - Avg Loss: 170.9352\n",
            "Epoch [9/50] - Batch loss: 162.4413 - Epoch Loss: 10589.4889 - Avg Loss: 170.7982\n",
            "Epoch [9/50] - Batch loss: 174.8029 - Epoch Loss: 10764.2919 - Avg Loss: 170.8618\n",
            "Epoch [9/50] - Batch loss: 168.9913 - Epoch Loss: 10933.2831 - Avg Loss: 170.8325\n",
            "Epoch [9/50] - Batch loss: 164.2293 - Epoch Loss: 11097.5125 - Avg Loss: 170.7310\n",
            "Epoch [9/50] - Batch loss: 165.3698 - Epoch Loss: 11262.8822 - Avg Loss: 170.6497\n",
            "Epoch [9/50] - Batch loss: 169.7758 - Epoch Loss: 11432.6581 - Avg Loss: 170.6367\n",
            "Epoch [9/50] - Batch loss: 172.9716 - Epoch Loss: 11605.6296 - Avg Loss: 170.6710\n",
            "Epoch [9/50] - Batch loss: 166.7977 - Epoch Loss: 11772.4274 - Avg Loss: 170.6149\n",
            "Epoch [9/50] - Batch loss: 169.2987 - Epoch Loss: 11941.7260 - Avg Loss: 170.5961\n",
            "Epoch [9/50] - Batch loss: 174.4455 - Epoch Loss: 12116.1715 - Avg Loss: 170.6503\n",
            "Epoch [9/50] - Batch loss: 169.9192 - Epoch Loss: 12286.0907 - Avg Loss: 170.6401\n",
            "Epoch [9/50] - Batch loss: 178.4763 - Epoch Loss: 12464.5670 - Avg Loss: 170.7475\n",
            "Epoch [9/50] - Batch loss: 162.1910 - Epoch Loss: 12626.7580 - Avg Loss: 170.6319\n",
            "Epoch [9/50] - Batch loss: 176.6283 - Epoch Loss: 12803.3863 - Avg Loss: 170.7118\n",
            "Epoch [9/50] - Batch loss: 172.6790 - Epoch Loss: 12976.0654 - Avg Loss: 170.7377\n",
            "Epoch [9/50] - Batch loss: 182.2106 - Epoch Loss: 13158.2759 - Avg Loss: 170.8867\n",
            "Epoch [9/50] - Batch loss: 166.1808 - Epoch Loss: 13324.4567 - Avg Loss: 170.8264\n",
            "Epoch [9/50] - Batch loss: 172.1798 - Epoch Loss: 13496.6366 - Avg Loss: 170.8435\n",
            "Epoch [9/50] - Batch loss: 169.3592 - Epoch Loss: 13665.9958 - Avg Loss: 170.8249\n",
            "Epoch [9/50] - Batch loss: 169.9281 - Epoch Loss: 13835.9239 - Avg Loss: 170.8139\n",
            "Epoch [9/50] - Batch loss: 172.2420 - Epoch Loss: 14008.1659 - Avg Loss: 170.8313\n",
            "Epoch [9/50] - Batch loss: 169.2755 - Epoch Loss: 14177.4414 - Avg Loss: 170.8125\n",
            "Epoch [9/50] - Batch loss: 166.0162 - Epoch Loss: 14343.4576 - Avg Loss: 170.7554\n",
            "Epoch [9/50] - Batch loss: 172.6141 - Epoch Loss: 14516.0716 - Avg Loss: 170.7773\n",
            "Epoch [9/50] - Batch loss: 174.7459 - Epoch Loss: 14690.8176 - Avg Loss: 170.8235\n",
            "Epoch [9/50] - Batch loss: 168.7028 - Epoch Loss: 14859.5203 - Avg Loss: 170.7991\n",
            "Epoch [9/50] - Batch loss: 168.0969 - Epoch Loss: 15027.6172 - Avg Loss: 170.7684\n",
            "Epoch [9/50] - Batch loss: 176.5368 - Epoch Loss: 15204.1540 - Avg Loss: 170.8332\n",
            "Epoch [9/50] - Batch loss: 164.8015 - Epoch Loss: 15368.9555 - Avg Loss: 170.7662\n",
            "Epoch [9/50] - Batch loss: 164.9231 - Epoch Loss: 15533.8786 - Avg Loss: 170.7020\n",
            "Epoch [9/50] - Batch loss: 164.5313 - Epoch Loss: 15698.4099 - Avg Loss: 170.6349\n",
            "Epoch [9/50] - Batch loss: 171.2103 - Epoch Loss: 15869.6202 - Avg Loss: 170.6411\n",
            "Epoch [9/50] - Batch loss: 168.7669 - Epoch Loss: 16038.3871 - Avg Loss: 170.6211\n",
            "Epoch [9/50] - Batch loss: 166.7348 - Epoch Loss: 16205.1219 - Avg Loss: 170.5802\n",
            "Epoch [9/50] - Batch loss: 169.8130 - Epoch Loss: 16374.9349 - Avg Loss: 170.5722\n",
            "Epoch [9/50] - Batch loss: 154.9633 - Epoch Loss: 16529.8982 - Avg Loss: 170.4113\n",
            "Epoch [9/50] - Batch loss: 176.7613 - Epoch Loss: 16706.6595 - Avg Loss: 170.4761\n",
            "Epoch [9/50] - Batch loss: 166.5806 - Epoch Loss: 16873.2401 - Avg Loss: 170.4368\n",
            "Epoch [9/50] - Batch loss: 166.3731 - Epoch Loss: 17039.6132 - Avg Loss: 170.3961\n",
            "Epoch [9/50] - Batch loss: 163.8574 - Epoch Loss: 17203.4705 - Avg Loss: 170.3314\n",
            "Epoch [9/50] - Batch loss: 171.4796 - Epoch Loss: 17374.9502 - Avg Loss: 170.3426\n",
            "Epoch [9/50] - Batch loss: 177.5380 - Epoch Loss: 17552.4882 - Avg Loss: 170.4125\n",
            "Epoch [9/50] - Batch loss: 167.5464 - Epoch Loss: 17720.0345 - Avg Loss: 170.3849\n",
            "Epoch [9/50] - Batch loss: 171.7020 - Epoch Loss: 17891.7366 - Avg Loss: 170.3975\n",
            "Epoch [9/50] - Batch loss: 168.4078 - Epoch Loss: 18060.1444 - Avg Loss: 170.3787\n",
            "Epoch [9/50] - Batch loss: 173.7465 - Epoch Loss: 18233.8909 - Avg Loss: 170.4102\n",
            "Epoch [9/50] - Batch loss: 161.5879 - Epoch Loss: 18395.4788 - Avg Loss: 170.3285\n",
            "Epoch [9/50] - Batch loss: 169.5384 - Epoch Loss: 18565.0172 - Avg Loss: 170.3213\n",
            "Epoch [9/50] - Batch loss: 169.5424 - Epoch Loss: 18734.5596 - Avg Loss: 170.3142\n",
            "Epoch [9/50] - Batch loss: 169.4790 - Epoch Loss: 18904.0386 - Avg Loss: 170.3067\n",
            "Epoch [9/50] - Batch loss: 178.3819 - Epoch Loss: 19082.4205 - Avg Loss: 170.3788\n",
            "Epoch [9/50] - Batch loss: 158.5211 - Epoch Loss: 19240.9415 - Avg Loss: 170.2738\n",
            "Epoch [9/50] - Batch loss: 169.3534 - Epoch Loss: 19410.2950 - Avg Loss: 170.2657\n",
            "Epoch [9/50] - Batch loss: 171.1632 - Epoch Loss: 19581.4582 - Avg Loss: 170.2735\n",
            "Epoch [9/50] - Batch loss: 175.7343 - Epoch Loss: 19757.1924 - Avg Loss: 170.3206\n",
            "Epoch [9/50] - Batch loss: 179.5929 - Epoch Loss: 19936.7853 - Avg Loss: 170.3999\n",
            "Epoch [9/50] - Batch loss: 170.8879 - Epoch Loss: 20107.6732 - Avg Loss: 170.4040\n",
            "Epoch [9/50] - Batch loss: 175.6640 - Epoch Loss: 20283.3373 - Avg Loss: 170.4482\n",
            "Epoch [9/50] - Batch loss: 166.6147 - Epoch Loss: 20449.9520 - Avg Loss: 170.4163\n",
            "Epoch [9/50] - Batch loss: 176.8132 - Epoch Loss: 20626.7652 - Avg Loss: 170.4691\n",
            "Epoch [9/50] - Batch loss: 171.1147 - Epoch Loss: 20797.8800 - Avg Loss: 170.4744\n",
            "Epoch [9/50] - Batch loss: 173.1783 - Epoch Loss: 20971.0583 - Avg Loss: 170.4964\n",
            "Epoch [9/50] - Batch loss: 168.2708 - Epoch Loss: 21139.3291 - Avg Loss: 170.4785\n",
            "Epoch [9/50] - Batch loss: 172.8308 - Epoch Loss: 21312.1599 - Avg Loss: 170.4973\n",
            "Epoch [9/50] - Batch loss: 174.7272 - Epoch Loss: 21486.8871 - Avg Loss: 170.5309\n",
            "Epoch [9/50] - Batch loss: 170.6600 - Epoch Loss: 21657.5471 - Avg Loss: 170.5319\n",
            "Epoch [9/50] - Batch loss: 173.9649 - Epoch Loss: 21831.5120 - Avg Loss: 170.5587\n",
            "Epoch [9/50] - Batch loss: 169.3237 - Epoch Loss: 22000.8357 - Avg Loss: 170.5491\n",
            "Epoch [9/50] - Batch loss: 172.2140 - Epoch Loss: 22173.0497 - Avg Loss: 170.5619\n",
            "Epoch [9/50] - Batch loss: 167.3956 - Epoch Loss: 22340.4453 - Avg Loss: 170.5378\n",
            "Epoch [9/50] - Batch loss: 169.2221 - Epoch Loss: 22509.6674 - Avg Loss: 170.5278\n",
            "Epoch [9/50] - Batch loss: 175.3583 - Epoch Loss: 22685.0257 - Avg Loss: 170.5641\n",
            "Epoch [9/50] - Batch loss: 166.7865 - Epoch Loss: 22851.8122 - Avg Loss: 170.5359\n",
            "Epoch [9/50] - Batch loss: 177.1862 - Epoch Loss: 23028.9984 - Avg Loss: 170.5852\n",
            "Epoch [9/50] - Batch loss: 166.6855 - Epoch Loss: 23195.6838 - Avg Loss: 170.5565\n",
            "Epoch [9/50] - Batch loss: 169.0452 - Epoch Loss: 23364.7290 - Avg Loss: 170.5455\n",
            "Epoch [9/50] - Batch loss: 165.8209 - Epoch Loss: 23530.5499 - Avg Loss: 170.5112\n",
            "Epoch [9/50] - Batch loss: 167.3387 - Epoch Loss: 23697.8885 - Avg Loss: 170.4884\n",
            "Epoch [9/50] - Batch loss: 166.4017 - Epoch Loss: 23864.2903 - Avg Loss: 170.4592\n",
            "Epoch [9/50] - Batch loss: 177.9529 - Epoch Loss: 24042.2432 - Avg Loss: 170.5124\n",
            "Epoch [9/50] - Batch loss: 167.6324 - Epoch Loss: 24209.8756 - Avg Loss: 170.4921\n",
            "Epoch [9/50] - Batch loss: 177.2271 - Epoch Loss: 24387.1027 - Avg Loss: 170.5392\n",
            "Epoch [9/50] - Batch loss: 169.9042 - Epoch Loss: 24557.0069 - Avg Loss: 170.5348\n",
            "Epoch [9/50] - Batch loss: 167.1557 - Epoch Loss: 24724.1626 - Avg Loss: 170.5115\n",
            "Epoch [9/50] - Batch loss: 177.6757 - Epoch Loss: 24901.8383 - Avg Loss: 170.5605\n",
            "Epoch [9/50] - Batch loss: 167.2121 - Epoch Loss: 25069.0504 - Avg Loss: 170.5378\n",
            "Epoch [9/50] - Batch loss: 169.3112 - Epoch Loss: 25238.3616 - Avg Loss: 170.5295\n",
            "Epoch [9/50] - Batch loss: 156.7336 - Epoch Loss: 25395.0953 - Avg Loss: 170.4369\n",
            "Epoch [9/50] - Batch loss: 172.0955 - Epoch Loss: 25567.1907 - Avg Loss: 170.4479\n",
            "Epoch [9/50] - Batch loss: 166.0139 - Epoch Loss: 25733.2046 - Avg Loss: 170.4186\n",
            "Epoch [9/50] - Batch loss: 169.7033 - Epoch Loss: 25902.9079 - Avg Loss: 170.4139\n",
            "Epoch [9/50] - Batch loss: 174.6753 - Epoch Loss: 26077.5832 - Avg Loss: 170.4417\n",
            "Epoch [9/50] - Batch loss: 164.2378 - Epoch Loss: 26241.8210 - Avg Loss: 170.4014\n",
            "Epoch [9/50] - Batch loss: 166.4850 - Epoch Loss: 26408.3060 - Avg Loss: 170.3762\n",
            "Epoch [9/50] - Batch loss: 167.2799 - Epoch Loss: 26575.5859 - Avg Loss: 170.3563\n",
            "Epoch [9/50] - Batch loss: 170.2475 - Epoch Loss: 26745.8334 - Avg Loss: 170.3556\n",
            "Epoch [9/50] - Batch loss: 178.4159 - Epoch Loss: 26924.2493 - Avg Loss: 170.4066\n",
            "Epoch [9/50] - Batch loss: 171.0899 - Epoch Loss: 27095.3392 - Avg Loss: 170.4109\n",
            "Epoch [9/50] - Batch loss: 170.3880 - Epoch Loss: 27265.7272 - Avg Loss: 170.4108\n",
            "Epoch [9/50] - Batch loss: 163.9627 - Epoch Loss: 27429.6899 - Avg Loss: 170.3707\n",
            "Epoch [9/50] - Batch loss: 169.9567 - Epoch Loss: 27599.6466 - Avg Loss: 170.3682\n",
            "Epoch [9/50] - Batch loss: 167.6478 - Epoch Loss: 27767.2944 - Avg Loss: 170.3515\n",
            "Epoch [9/50] - Batch loss: 173.0042 - Epoch Loss: 27940.2986 - Avg Loss: 170.3677\n",
            "Epoch [9/50] - Batch loss: 177.5026 - Epoch Loss: 28117.8012 - Avg Loss: 170.4109\n",
            "Epoch [9/50] - Batch loss: 171.4511 - Epoch Loss: 28289.2523 - Avg Loss: 170.4172\n",
            "Epoch [9/50] - Batch loss: 177.0285 - Epoch Loss: 28466.2808 - Avg Loss: 170.4568\n",
            "Epoch [9/50] - Batch loss: 168.9675 - Epoch Loss: 28635.2483 - Avg Loss: 170.4479\n",
            "Epoch [9/50] - Batch loss: 168.9562 - Epoch Loss: 28804.2045 - Avg Loss: 170.4391\n",
            "Epoch [9/50] - Batch loss: 166.9774 - Epoch Loss: 28971.1819 - Avg Loss: 170.4187\n",
            "Epoch [9/50] - Batch loss: 172.3317 - Epoch Loss: 29143.5137 - Avg Loss: 170.4299\n",
            "Epoch [9/50] - Batch loss: 163.2231 - Epoch Loss: 29306.7367 - Avg Loss: 170.3880\n",
            "Epoch [9/50] - Batch loss: 166.7471 - Epoch Loss: 29473.4838 - Avg Loss: 170.3670\n",
            "Epoch [9/50] - Batch loss: 164.8090 - Epoch Loss: 29638.2928 - Avg Loss: 170.3350\n",
            "Epoch [9/50] - Batch loss: 164.9409 - Epoch Loss: 29803.2336 - Avg Loss: 170.3042\n",
            "Epoch [9/50] - Batch loss: 168.4631 - Epoch Loss: 29971.6968 - Avg Loss: 170.2937\n",
            "Epoch [9/50] - Batch loss: 172.2262 - Epoch Loss: 30143.9230 - Avg Loss: 170.3046\n",
            "Epoch [9/50] - Batch loss: 170.5523 - Epoch Loss: 30314.4753 - Avg Loss: 170.3060\n",
            "Epoch [9/50] - Batch loss: 167.8782 - Epoch Loss: 30482.3534 - Avg Loss: 170.2925\n",
            "Epoch [9/50] - Batch loss: 170.1880 - Epoch Loss: 30652.5414 - Avg Loss: 170.2919\n",
            "Epoch [9/50] - Batch loss: 165.9468 - Epoch Loss: 30818.4882 - Avg Loss: 170.2679\n",
            "Epoch [9/50] - Batch loss: 172.1492 - Epoch Loss: 30990.6375 - Avg Loss: 170.2782\n",
            "Epoch [9/50] - Batch loss: 176.3141 - Epoch Loss: 31166.9516 - Avg Loss: 170.3112\n",
            "Epoch [9/50] - Batch loss: 174.4417 - Epoch Loss: 31341.3932 - Avg Loss: 170.3337\n",
            "Epoch [9/50] - Batch loss: 172.1359 - Epoch Loss: 31513.5292 - Avg Loss: 170.3434\n",
            "Epoch [9/50] - Batch loss: 166.9173 - Epoch Loss: 31680.4465 - Avg Loss: 170.3250\n",
            "Epoch [9/50] - Batch loss: 162.3298 - Epoch Loss: 31842.7763 - Avg Loss: 170.2822\n",
            "Epoch [9/50] - Batch loss: 163.0108 - Epoch Loss: 32005.7872 - Avg Loss: 170.2435\n",
            "Epoch [9/50] - Batch loss: 176.6974 - Epoch Loss: 32182.4846 - Avg Loss: 170.2777\n",
            "Epoch [9/50] - Batch loss: 172.4044 - Epoch Loss: 32354.8890 - Avg Loss: 170.2889\n",
            "Epoch [9/50] - Batch loss: 165.4358 - Epoch Loss: 32520.3248 - Avg Loss: 170.2635\n",
            "Epoch [9/50] - Batch loss: 176.8065 - Epoch Loss: 32697.1313 - Avg Loss: 170.2976\n",
            "Epoch [9/50] - Batch loss: 179.4342 - Epoch Loss: 32876.5655 - Avg Loss: 170.3449\n",
            "Epoch [9/50] - Batch loss: 169.0817 - Epoch Loss: 33045.6472 - Avg Loss: 170.3384\n",
            "Epoch [9/50] - Batch loss: 167.7850 - Epoch Loss: 33213.4322 - Avg Loss: 170.3253\n",
            "Epoch [9/50] - Batch loss: 165.6907 - Epoch Loss: 33379.1230 - Avg Loss: 170.3016\n",
            "Epoch [9/50] - Batch loss: 162.2980 - Epoch Loss: 33541.4210 - Avg Loss: 170.2610\n",
            "Epoch [9/50] - Batch loss: 169.8236 - Epoch Loss: 33711.2446 - Avg Loss: 170.2588\n",
            "Epoch [9/50] - Batch loss: 171.9815 - Epoch Loss: 33883.2261 - Avg Loss: 170.2675\n",
            "Epoch [9/50] - Batch loss: 172.4366 - Epoch Loss: 34055.6627 - Avg Loss: 170.2783\n",
            "Epoch [9/50] - Batch loss: 166.7340 - Epoch Loss: 34222.3967 - Avg Loss: 170.2607\n",
            "Epoch [9/50] - Batch loss: 170.7634 - Epoch Loss: 34393.1601 - Avg Loss: 170.2632\n",
            "Epoch [9/50] - Batch loss: 177.7965 - Epoch Loss: 34570.9566 - Avg Loss: 170.3003\n",
            "Epoch [9/50] - Batch loss: 166.0665 - Epoch Loss: 34737.0231 - Avg Loss: 170.2795\n",
            "Epoch [9/50] - Batch loss: 168.3474 - Epoch Loss: 34905.3705 - Avg Loss: 170.2701\n",
            "Epoch [9/50] - Batch loss: 166.1910 - Epoch Loss: 35071.5614 - Avg Loss: 170.2503\n",
            "Epoch [9/50] - Batch loss: 166.8558 - Epoch Loss: 35238.4173 - Avg Loss: 170.2339\n",
            "Epoch [9/50] - Batch loss: 157.9639 - Epoch Loss: 35396.3812 - Avg Loss: 170.1749\n",
            "Epoch [9/50] - Batch loss: 163.1726 - Epoch Loss: 35559.5538 - Avg Loss: 170.1414\n",
            "Epoch [9/50] - Batch loss: 161.6093 - Epoch Loss: 35721.1631 - Avg Loss: 170.1008\n",
            "Epoch [9/50] - Batch loss: 163.9988 - Epoch Loss: 35885.1619 - Avg Loss: 170.0719\n",
            "Epoch [9/50] - Batch loss: 182.2018 - Epoch Loss: 36067.3637 - Avg Loss: 170.1291\n",
            "Epoch [9/50] - Batch loss: 169.7640 - Epoch Loss: 36237.1277 - Avg Loss: 170.1274\n",
            "Epoch [9/50] - Batch loss: 164.3996 - Epoch Loss: 36401.5272 - Avg Loss: 170.1006\n",
            "Epoch [9/50] - Batch loss: 168.8077 - Epoch Loss: 36570.3349 - Avg Loss: 170.0946\n",
            "Epoch [9/50] - Batch loss: 170.5788 - Epoch Loss: 36740.9138 - Avg Loss: 170.0968\n",
            "Epoch [9/50] - Batch loss: 167.1758 - Epoch Loss: 36908.0895 - Avg Loss: 170.0834\n",
            "Epoch [9/50] - Batch loss: 168.7947 - Epoch Loss: 37076.8842 - Avg Loss: 170.0775\n",
            "Epoch [9/50] - Batch loss: 168.8437 - Epoch Loss: 37245.7279 - Avg Loss: 170.0718\n",
            "Epoch [9/50] - Batch loss: 170.5898 - Epoch Loss: 37416.3177 - Avg Loss: 170.0742\n",
            "Epoch [9/50] - Batch loss: 175.2325 - Epoch Loss: 37591.5502 - Avg Loss: 170.0975\n",
            "Epoch [9/50] - Batch loss: 172.4265 - Epoch Loss: 37763.9767 - Avg Loss: 170.1080\n",
            "Epoch [9/50] - Batch loss: 164.5154 - Epoch Loss: 37928.4920 - Avg Loss: 170.0829\n",
            "Epoch [9/50] - Batch loss: 174.0239 - Epoch Loss: 38102.5160 - Avg Loss: 170.1005\n",
            "Epoch [9/50] - Batch loss: 171.3764 - Epoch Loss: 38273.8924 - Avg Loss: 170.1062\n",
            "Epoch [9/50] - Batch loss: 170.1189 - Epoch Loss: 38444.0113 - Avg Loss: 170.1062\n",
            "Epoch [9/50] - Batch loss: 163.6728 - Epoch Loss: 38607.6841 - Avg Loss: 170.0779\n",
            "Epoch [9/50] - Batch loss: 174.1057 - Epoch Loss: 38781.7898 - Avg Loss: 170.0956\n",
            "Epoch [9/50] - Batch loss: 170.0325 - Epoch Loss: 38951.8223 - Avg Loss: 170.0953\n",
            "Epoch [9/50] - Batch loss: 160.4709 - Epoch Loss: 39112.2933 - Avg Loss: 170.0534\n",
            "Epoch [9/50] - Batch loss: 168.7602 - Epoch Loss: 39281.0535 - Avg Loss: 170.0479\n",
            "Epoch [9/50] - Batch loss: 161.2442 - Epoch Loss: 39442.2977 - Avg Loss: 170.0099\n",
            "Epoch [9/50] - Batch loss: 166.0879 - Epoch Loss: 39608.3856 - Avg Loss: 169.9931\n",
            "Epoch [9/50] - Batch loss: 164.0119 - Epoch Loss: 39772.3975 - Avg Loss: 169.9675\n",
            "Epoch [9/50] - Batch loss: 167.6290 - Epoch Loss: 39940.0265 - Avg Loss: 169.9576\n",
            "Epoch [9/50] - Batch loss: 168.1561 - Epoch Loss: 40108.1826 - Avg Loss: 169.9499\n",
            "Epoch [9/50] - Batch loss: 169.7745 - Epoch Loss: 40277.9571 - Avg Loss: 169.9492\n",
            "Epoch [9/50] - Batch loss: 173.9198 - Epoch Loss: 40451.8769 - Avg Loss: 169.9659\n",
            "Epoch [9/50] - Batch loss: 158.0275 - Epoch Loss: 40609.9044 - Avg Loss: 169.9159\n",
            "Epoch [9/50] - Batch loss: 167.6581 - Epoch Loss: 40777.5625 - Avg Loss: 169.9065\n",
            "Epoch [9/50] - Batch loss: 172.0535 - Epoch Loss: 40949.6159 - Avg Loss: 169.9154\n",
            "Epoch [9/50] - Batch loss: 170.3751 - Epoch Loss: 41119.9910 - Avg Loss: 169.9173\n",
            "Epoch [9/50] - Batch loss: 168.8954 - Epoch Loss: 41288.8864 - Avg Loss: 169.9131\n",
            "Epoch [9/50] - Batch loss: 175.3851 - Epoch Loss: 41464.2715 - Avg Loss: 169.9355\n",
            "Epoch [9/50] - Batch loss: 164.0601 - Epoch Loss: 41628.3316 - Avg Loss: 169.9116\n",
            "Epoch [9/50] - Batch loss: 161.5867 - Epoch Loss: 41789.9183 - Avg Loss: 169.8777\n",
            "Epoch [9/50] - Batch loss: 172.4144 - Epoch Loss: 41962.3327 - Avg Loss: 169.8880\n",
            "Epoch [9/50] - Batch loss: 168.2166 - Epoch Loss: 42130.5493 - Avg Loss: 169.8812\n",
            "Epoch [9/50] - Batch loss: 171.6368 - Epoch Loss: 42302.1860 - Avg Loss: 169.8883\n",
            "Epoch [9/50] - Batch loss: 174.1443 - Epoch Loss: 42476.3303 - Avg Loss: 169.9053\n",
            "Epoch [9/50] - Batch loss: 167.1783 - Epoch Loss: 42643.5086 - Avg Loss: 169.8945\n",
            "Epoch [9/50] - Batch loss: 166.9210 - Epoch Loss: 42810.4296 - Avg Loss: 169.8827\n",
            "Epoch [9/50] - Batch loss: 172.7557 - Epoch Loss: 42983.1853 - Avg Loss: 169.8940\n",
            "Epoch [9/50] - Batch loss: 162.6711 - Epoch Loss: 43145.8563 - Avg Loss: 169.8656\n",
            "Epoch [9/50] - Batch loss: 172.6259 - Epoch Loss: 43318.4822 - Avg Loss: 169.8764\n",
            "Epoch [9/50] - Batch loss: 169.7537 - Epoch Loss: 43488.2359 - Avg Loss: 169.8759\n",
            "Epoch [9/50] - Batch loss: 166.1418 - Epoch Loss: 43654.3777 - Avg Loss: 169.8614\n",
            "Epoch [9/50] - Batch loss: 164.7245 - Epoch Loss: 43819.1022 - Avg Loss: 169.8415\n",
            "Epoch [9/50] - Batch loss: 169.0585 - Epoch Loss: 43988.1607 - Avg Loss: 169.8385\n",
            "Epoch [9/50] - Batch loss: 173.5340 - Epoch Loss: 44161.6947 - Avg Loss: 169.8527\n",
            "Epoch [9/50] - Batch loss: 167.2542 - Epoch Loss: 44328.9488 - Avg Loss: 169.8427\n",
            "Epoch [9/50] - Batch loss: 175.9031 - Epoch Loss: 44504.8519 - Avg Loss: 169.8658\n",
            "Epoch [9/50] - Batch loss: 164.5774 - Epoch Loss: 44669.4293 - Avg Loss: 169.8457\n",
            "Epoch [9/50] - Batch loss: 165.9110 - Epoch Loss: 44835.3403 - Avg Loss: 169.8308\n",
            "Epoch [9/50] - Batch loss: 161.6013 - Epoch Loss: 44996.9416 - Avg Loss: 169.7998\n",
            "Epoch [9/50] - Batch loss: 168.2719 - Epoch Loss: 45165.2135 - Avg Loss: 169.7940\n",
            "Epoch [9/50] - Batch loss: 171.8140 - Epoch Loss: 45337.0275 - Avg Loss: 169.8016\n",
            "Epoch [9/50] - Batch loss: 166.9579 - Epoch Loss: 45503.9854 - Avg Loss: 169.7910\n",
            "Epoch [9/50] - Batch loss: 163.1758 - Epoch Loss: 45667.1612 - Avg Loss: 169.7664\n",
            "Epoch [9/50] - Batch loss: 160.8658 - Epoch Loss: 45828.0270 - Avg Loss: 169.7334\n",
            "Epoch [9/50] - Batch loss: 165.0233 - Epoch Loss: 45993.0502 - Avg Loss: 169.7161\n",
            "Epoch [9/50] - Batch loss: 163.2777 - Epoch Loss: 46156.3280 - Avg Loss: 169.6924\n",
            "Epoch [9/50] - Batch loss: 162.0997 - Epoch Loss: 46318.4276 - Avg Loss: 169.6646\n",
            "Epoch [9/50] - Batch loss: 161.1143 - Epoch Loss: 46479.5420 - Avg Loss: 169.6334\n",
            "Epoch [9/50] - Batch loss: 169.4086 - Epoch Loss: 46648.9505 - Avg Loss: 169.6325\n",
            "Epoch [9/50] - Batch loss: 159.3816 - Epoch Loss: 46808.3322 - Avg Loss: 169.5954\n",
            "Epoch [9/50] - Batch loss: 167.7403 - Epoch Loss: 46976.0725 - Avg Loss: 169.5887\n",
            "Epoch [9/50] - Batch loss: 159.3457 - Epoch Loss: 47135.4182 - Avg Loss: 169.5519\n",
            "Epoch [9/50] - Batch loss: 167.1594 - Epoch Loss: 47302.5776 - Avg Loss: 169.5433\n",
            "Epoch [9/50] - Batch loss: 164.4431 - Epoch Loss: 47467.0206 - Avg Loss: 169.5251\n",
            "Epoch [9/50] - Batch loss: 160.7851 - Epoch Loss: 47627.8058 - Avg Loss: 169.4940\n",
            "Epoch [9/50] - Batch loss: 165.1921 - Epoch Loss: 47792.9978 - Avg Loss: 169.4787\n",
            "Epoch [9/50] - Batch loss: 170.9511 - Epoch Loss: 47963.9490 - Avg Loss: 169.4839\n",
            "Epoch [9/50] - Batch loss: 164.9090 - Epoch Loss: 48128.8580 - Avg Loss: 169.4678\n",
            "Epoch [9/50] - Batch loss: 164.4074 - Epoch Loss: 48293.2654 - Avg Loss: 169.4501\n",
            "Epoch [9/50] - Batch loss: 168.7695 - Epoch Loss: 48462.0349 - Avg Loss: 169.4477\n",
            "Epoch [9/50] - Batch loss: 165.8982 - Epoch Loss: 48627.9331 - Avg Loss: 169.4353\n",
            "Epoch [9/50] - Batch loss: 166.5672 - Epoch Loss: 48794.5003 - Avg Loss: 169.4253\n",
            "Epoch [9/50] - Batch loss: 162.7125 - Epoch Loss: 48957.2128 - Avg Loss: 169.4021\n",
            "Epoch [9/50] - Batch loss: 153.8965 - Epoch Loss: 49111.1092 - Avg Loss: 169.3487\n",
            "Epoch [9/50] - Batch loss: 179.8624 - Epoch Loss: 49290.9717 - Avg Loss: 169.3848\n",
            "Epoch [9/50] - Batch loss: 166.3317 - Epoch Loss: 49457.3034 - Avg Loss: 169.3743\n",
            "Epoch [9/50] - Batch loss: 164.5612 - Epoch Loss: 49621.8646 - Avg Loss: 169.3579\n",
            "Epoch [9/50] - Batch loss: 170.0279 - Epoch Loss: 49791.8925 - Avg Loss: 169.3602\n",
            "Epoch [9/50] - Batch loss: 169.2498 - Epoch Loss: 49961.1422 - Avg Loss: 169.3598\n",
            "Epoch [9/50] - Batch loss: 171.6462 - Epoch Loss: 50132.7884 - Avg Loss: 169.3675\n",
            "Epoch [9/50] - Batch loss: 166.2733 - Epoch Loss: 50299.0617 - Avg Loss: 169.3571\n",
            "Epoch [9/50] - Batch loss: 163.4055 - Epoch Loss: 50462.4672 - Avg Loss: 169.3371\n",
            "Epoch [9/50] - Batch loss: 161.4168 - Epoch Loss: 50623.8840 - Avg Loss: 169.3106\n",
            "Epoch [9/50] - Batch loss: 161.2680 - Epoch Loss: 50785.1520 - Avg Loss: 169.2838\n",
            "Epoch [9/50] - Batch loss: 163.2165 - Epoch Loss: 50948.3685 - Avg Loss: 169.2637\n",
            "Epoch [9/50] - Batch loss: 170.3471 - Epoch Loss: 51118.7155 - Avg Loss: 169.2673\n",
            "Epoch [9/50] - Batch loss: 173.9715 - Epoch Loss: 51292.6871 - Avg Loss: 169.2828\n",
            "Epoch [9/50] - Batch loss: 167.2635 - Epoch Loss: 51459.9505 - Avg Loss: 169.2762\n",
            "Epoch [9/50] - Batch loss: 160.3917 - Epoch Loss: 51620.3422 - Avg Loss: 169.2470\n",
            "Epoch [9/50] - Batch loss: 160.1810 - Epoch Loss: 51780.5233 - Avg Loss: 169.2174\n",
            "Epoch [9/50] - Batch loss: 165.6418 - Epoch Loss: 51946.1650 - Avg Loss: 169.2057\n",
            "Epoch [9/50] - Batch loss: 165.9701 - Epoch Loss: 52112.1351 - Avg Loss: 169.1952\n",
            "Epoch [9/50] - Batch loss: 165.0883 - Epoch Loss: 52277.2234 - Avg Loss: 169.1820\n",
            "Epoch [9/50] - Batch loss: 171.7886 - Epoch Loss: 52449.0120 - Avg Loss: 169.1904\n",
            "Epoch [9/50] - Batch loss: 160.5263 - Epoch Loss: 52609.5383 - Avg Loss: 169.1625\n",
            "Epoch [9/50] - Batch loss: 160.6524 - Epoch Loss: 52770.1907 - Avg Loss: 169.1352\n",
            "Epoch [9/50] - Batch loss: 167.9690 - Epoch Loss: 52938.1597 - Avg Loss: 169.1315\n",
            "Epoch [9/50] - Batch loss: 164.3465 - Epoch Loss: 53102.5062 - Avg Loss: 169.1163\n",
            "Epoch [9/50] - Batch loss: 162.1402 - Epoch Loss: 53264.6464 - Avg Loss: 169.0941\n",
            "Epoch [9/50] - Batch loss: 169.7840 - Epoch Loss: 53434.4303 - Avg Loss: 169.0963\n",
            "Epoch [9/50] - Batch loss: 170.0857 - Epoch Loss: 53604.5160 - Avg Loss: 169.0994\n",
            "Epoch [9/50] - Batch loss: 163.6525 - Epoch Loss: 53768.1685 - Avg Loss: 169.0823\n",
            "Epoch [9/50] - Batch loss: 163.8203 - Epoch Loss: 53931.9889 - Avg Loss: 169.0658\n",
            "Epoch [9/50] - Batch loss: 165.6046 - Epoch Loss: 54097.5935 - Avg Loss: 169.0550\n",
            "Epoch [9/50] - Batch loss: 172.9288 - Epoch Loss: 54270.5222 - Avg Loss: 169.0670\n",
            "Epoch [9/50] - Batch loss: 162.1585 - Epoch Loss: 54432.6807 - Avg Loss: 169.0456\n",
            "Epoch [9/50] - Batch loss: 167.7619 - Epoch Loss: 54600.4426 - Avg Loss: 169.0416\n",
            "Epoch [9/50] - Batch loss: 169.5228 - Epoch Loss: 54769.9654 - Avg Loss: 169.0431\n",
            "Epoch [9/50] - Batch loss: 160.2424 - Epoch Loss: 54930.2078 - Avg Loss: 169.0160\n",
            "Epoch [9/50] - Batch loss: 169.8112 - Epoch Loss: 55100.0190 - Avg Loss: 169.0185\n",
            "Epoch [9/50] - Batch loss: 165.8271 - Epoch Loss: 55265.8461 - Avg Loss: 169.0087\n",
            "Epoch [9/50] - Batch loss: 161.8696 - Epoch Loss: 55427.7157 - Avg Loss: 168.9869\n",
            "Epoch [9/50] - Batch loss: 159.7505 - Epoch Loss: 55587.4662 - Avg Loss: 168.9589\n",
            "Epoch [9/50] - Batch loss: 167.9292 - Epoch Loss: 55755.3954 - Avg Loss: 168.9557\n",
            "Epoch [9/50] - Batch loss: 165.0461 - Epoch Loss: 55920.4416 - Avg Loss: 168.9439\n",
            "Epoch [9/50] - Batch loss: 167.8333 - Epoch Loss: 56088.2748 - Avg Loss: 168.9406\n",
            "Epoch [9/50] - Batch loss: 159.8525 - Epoch Loss: 56248.1273 - Avg Loss: 168.9133\n",
            "Epoch [9/50] - Batch loss: 169.2346 - Epoch Loss: 56417.3619 - Avg Loss: 168.9143\n",
            "Epoch [9/50] - Batch loss: 166.8555 - Epoch Loss: 56584.2174 - Avg Loss: 168.9081\n",
            "Epoch [9/50] - Batch loss: 161.6640 - Epoch Loss: 56745.8814 - Avg Loss: 168.8866\n",
            "Epoch [9/50] - Batch loss: 163.7992 - Epoch Loss: 56909.6806 - Avg Loss: 168.8715\n",
            "Epoch [9/50] - Batch loss: 165.8550 - Epoch Loss: 57075.5356 - Avg Loss: 168.8625\n",
            "Epoch [9/50] - Batch loss: 170.0225 - Epoch Loss: 57245.5581 - Avg Loss: 168.8660\n",
            "Epoch [9/50] - Batch loss: 163.5587 - Epoch Loss: 57409.1169 - Avg Loss: 168.8503\n",
            "Epoch [9/50] - Batch loss: 158.6717 - Epoch Loss: 57567.7886 - Avg Loss: 168.8205\n",
            "Epoch [9/50] - Batch loss: 160.2472 - Epoch Loss: 57728.0358 - Avg Loss: 168.7954\n",
            "Epoch [9/50] - Batch loss: 167.1769 - Epoch Loss: 57895.2127 - Avg Loss: 168.7907\n",
            "Epoch [9/50] - Batch loss: 166.1767 - Epoch Loss: 58061.3894 - Avg Loss: 168.7831\n",
            "Epoch [9/50] - Batch loss: 165.7379 - Epoch Loss: 58227.1273 - Avg Loss: 168.7743\n",
            "Epoch [9/50] - Batch loss: 167.1489 - Epoch Loss: 58394.2762 - Avg Loss: 168.7696\n",
            "Epoch [9/50] - Batch loss: 167.4179 - Epoch Loss: 58561.6941 - Avg Loss: 168.7657\n",
            "Epoch [9/50] - Batch loss: 167.4324 - Epoch Loss: 58729.1265 - Avg Loss: 168.7619\n",
            "Epoch [9/50] - Batch loss: 165.3710 - Epoch Loss: 58894.4975 - Avg Loss: 168.7521\n",
            "Epoch [9/50] - Batch loss: 169.6937 - Epoch Loss: 59064.1911 - Avg Loss: 168.7548\n",
            "Epoch [9/50] - Batch loss: 167.4845 - Epoch Loss: 59231.6757 - Avg Loss: 168.7512\n",
            "Epoch [9/50] - Batch loss: 161.3452 - Epoch Loss: 59393.0208 - Avg Loss: 168.7302\n",
            "Epoch [9/50] - Batch loss: 168.6588 - Epoch Loss: 59561.6796 - Avg Loss: 168.7300\n",
            "Epoch [9/50] - Batch loss: 167.8027 - Epoch Loss: 59729.4823 - Avg Loss: 168.7274\n",
            "Epoch [9/50] - Batch loss: 164.0445 - Epoch Loss: 59893.5268 - Avg Loss: 168.7142\n",
            "Epoch [9/50] - Batch loss: 155.3393 - Epoch Loss: 60048.8661 - Avg Loss: 168.6766\n",
            "Epoch [9/50] - Batch loss: 168.7890 - Epoch Loss: 60217.6551 - Avg Loss: 168.6769\n",
            "Epoch [9/50] - Batch loss: 163.1306 - Epoch Loss: 60380.7857 - Avg Loss: 168.6614\n",
            "Epoch [9/50] - Batch loss: 163.2265 - Epoch Loss: 60544.0122 - Avg Loss: 168.6463\n",
            "Epoch [9/50] - Batch loss: 165.4823 - Epoch Loss: 60709.4945 - Avg Loss: 168.6375\n",
            "Epoch [9/50] - Batch loss: 161.7940 - Epoch Loss: 60871.2885 - Avg Loss: 168.6185\n",
            "Epoch [9/50] - Batch loss: 171.4078 - Epoch Loss: 61042.6963 - Avg Loss: 168.6262\n",
            "Epoch [9/50] - Batch loss: 167.0259 - Epoch Loss: 61209.7222 - Avg Loss: 168.6218\n",
            "Epoch [9/50] - Batch loss: 166.9941 - Epoch Loss: 61376.7163 - Avg Loss: 168.6174\n",
            "Epoch [9/50] - Batch loss: 161.1598 - Epoch Loss: 61537.8762 - Avg Loss: 168.5969\n",
            "Epoch [9/50] - Batch loss: 164.7229 - Epoch Loss: 61702.5991 - Avg Loss: 168.5863\n",
            "Epoch [9/50] - Batch loss: 173.0859 - Epoch Loss: 61875.6850 - Avg Loss: 168.5986\n",
            "Epoch [9/50] - Batch loss: 164.0931 - Epoch Loss: 62039.7780 - Avg Loss: 168.5864\n",
            "Epoch [9/50] - Batch loss: 161.7300 - Epoch Loss: 62201.5080 - Avg Loss: 168.5678\n",
            "Epoch [9/50] - Batch loss: 155.8572 - Epoch Loss: 62357.3653 - Avg Loss: 168.5334\n",
            "Epoch [9/50] - Batch loss: 173.5370 - Epoch Loss: 62530.9022 - Avg Loss: 168.5469\n",
            "Epoch [9/50] - Batch loss: 168.2282 - Epoch Loss: 62699.1304 - Avg Loss: 168.5460\n",
            "Epoch [9/50] - Batch loss: 168.9949 - Epoch Loss: 62868.1253 - Avg Loss: 168.5473\n",
            "Epoch [9/50] - Batch loss: 166.5647 - Epoch Loss: 63034.6900 - Avg Loss: 168.5420\n",
            "Epoch [9/50] - Batch loss: 161.7675 - Epoch Loss: 63196.4576 - Avg Loss: 168.5239\n",
            "Epoch [9/50] - Batch loss: 166.9917 - Epoch Loss: 63363.4492 - Avg Loss: 168.5198\n",
            "Epoch [9/50] - Batch loss: 174.4201 - Epoch Loss: 63537.8693 - Avg Loss: 168.5355\n",
            "Epoch [9/50] - Batch loss: 167.1389 - Epoch Loss: 63705.0083 - Avg Loss: 168.5318\n",
            "Epoch [9/50] - Batch loss: 166.6084 - Epoch Loss: 63871.6167 - Avg Loss: 168.5267\n",
            "Epoch [9/50] - Batch loss: 172.7956 - Epoch Loss: 64044.4123 - Avg Loss: 168.5379\n",
            "Epoch [9/50] - Batch loss: 173.6512 - Epoch Loss: 64218.0635 - Avg Loss: 168.5513\n",
            "Epoch [9/50] - Batch loss: 171.5052 - Epoch Loss: 64389.5687 - Avg Loss: 168.5591\n",
            "Epoch [9/50] - Batch loss: 174.4204 - Epoch Loss: 64563.9891 - Avg Loss: 168.5744\n",
            "Epoch [9/50] - Batch loss: 159.0260 - Epoch Loss: 64723.0151 - Avg Loss: 168.5495\n",
            "Epoch [9/50] - Batch loss: 169.5124 - Epoch Loss: 64892.5275 - Avg Loss: 168.5520\n",
            "Epoch [9/50] - Batch loss: 164.3257 - Epoch Loss: 65056.8531 - Avg Loss: 168.5411\n",
            "Epoch [9/50] - Batch loss: 171.0544 - Epoch Loss: 65227.9075 - Avg Loss: 168.5476\n",
            "Epoch [9/50] - Batch loss: 165.2737 - Epoch Loss: 65393.1812 - Avg Loss: 168.5391\n",
            "Epoch [9/50] - Batch loss: 165.9680 - Epoch Loss: 65559.1493 - Avg Loss: 168.5325\n",
            "Epoch [9/50] - Batch loss: 175.5415 - Epoch Loss: 65734.6907 - Avg Loss: 168.5505\n",
            "Epoch [9/50] - Batch loss: 161.2584 - Epoch Loss: 65895.9491 - Avg Loss: 168.5318\n",
            "Epoch [9/50] - Batch loss: 165.1662 - Epoch Loss: 66061.1153 - Avg Loss: 168.5233\n",
            "Epoch [9/50] - Batch loss: 163.4453 - Epoch Loss: 66224.5606 - Avg Loss: 168.5103\n",
            "Epoch [9/50] - Batch loss: 158.6308 - Epoch Loss: 66383.1914 - Avg Loss: 168.4853\n",
            "Epoch [9/50] - Batch loss: 171.5235 - Epoch Loss: 66554.7149 - Avg Loss: 168.4929\n",
            "Epoch [9/50] - Batch loss: 167.0394 - Epoch Loss: 66721.7542 - Avg Loss: 168.4893\n",
            "Epoch [9/50] - Batch loss: 164.7323 - Epoch Loss: 66886.4866 - Avg Loss: 168.4798\n",
            "Epoch [9/50] - Batch loss: 169.7936 - Epoch Loss: 67056.2802 - Avg Loss: 168.4831\n",
            "Epoch [9/50] - Batch loss: 176.0200 - Epoch Loss: 67232.3002 - Avg Loss: 168.5020\n",
            "Epoch [9/50] - Batch loss: 166.0432 - Epoch Loss: 67398.3434 - Avg Loss: 168.4959\n",
            "Epoch [9/50] - Batch loss: 167.6314 - Epoch Loss: 67565.9748 - Avg Loss: 168.4937\n",
            "Epoch [9/50] - Batch loss: 167.1872 - Epoch Loss: 67733.1620 - Avg Loss: 168.4905\n",
            "Epoch [9/50] - Batch loss: 172.1146 - Epoch Loss: 67905.2766 - Avg Loss: 168.4994\n",
            "Epoch [9/50] - Batch loss: 170.6566 - Epoch Loss: 68075.9332 - Avg Loss: 168.5048\n",
            "Epoch [9/50] - Batch loss: 163.9268 - Epoch Loss: 68239.8600 - Avg Loss: 168.4935\n",
            "Epoch [9/50] - Batch loss: 173.5585 - Epoch Loss: 68413.4185 - Avg Loss: 168.5060\n",
            "Epoch [9/50] - Batch loss: 168.5742 - Epoch Loss: 68581.9926 - Avg Loss: 168.5061\n",
            "Epoch [9/50] - Batch loss: 166.5772 - Epoch Loss: 68748.5698 - Avg Loss: 168.5014\n",
            "Epoch [9/50] - Batch loss: 167.6740 - Epoch Loss: 68916.2438 - Avg Loss: 168.4994\n",
            "Epoch [9/50] - Batch loss: 165.8183 - Epoch Loss: 69082.0621 - Avg Loss: 168.4928\n",
            "Epoch [9/50] - Batch loss: 169.7580 - Epoch Loss: 69251.8201 - Avg Loss: 168.4959\n",
            "Epoch [9/50] - Batch loss: 171.4374 - Epoch Loss: 69423.2575 - Avg Loss: 168.5031\n",
            "Epoch [9/50] - Batch loss: 168.4502 - Epoch Loss: 69591.7077 - Avg Loss: 168.5029\n",
            "Epoch [9/50] - Batch loss: 162.0268 - Epoch Loss: 69753.7346 - Avg Loss: 168.4873\n",
            "Epoch [9/50] - Batch loss: 164.1794 - Epoch Loss: 69917.9140 - Avg Loss: 168.4769\n",
            "Epoch [9/50] - Batch loss: 155.8457 - Epoch Loss: 70073.7597 - Avg Loss: 168.4465\n",
            "Epoch [9/50] - Batch loss: 160.4271 - Epoch Loss: 70234.1868 - Avg Loss: 168.4273\n",
            "Epoch [9/50] - Batch loss: 176.0176 - Epoch Loss: 70410.2044 - Avg Loss: 168.4455\n",
            "Epoch [9/50] - Batch loss: 170.3442 - Epoch Loss: 70580.5486 - Avg Loss: 168.4500\n",
            "Epoch [9/50] - Batch loss: 161.9924 - Epoch Loss: 70742.5409 - Avg Loss: 168.4346\n",
            "Epoch [9/50] - Batch loss: 164.6383 - Epoch Loss: 70907.1792 - Avg Loss: 168.4256\n",
            "Epoch [9/50] - Batch loss: 163.0221 - Epoch Loss: 71070.2013 - Avg Loss: 168.4128\n",
            "Epoch [9/50] - Batch loss: 164.2729 - Epoch Loss: 71234.4742 - Avg Loss: 168.4030\n",
            "Epoch [9/50] - Batch loss: 167.8543 - Epoch Loss: 71402.3285 - Avg Loss: 168.4017\n",
            "Epoch [9/50] - Batch loss: 172.1033 - Epoch Loss: 71574.4317 - Avg Loss: 168.4104\n",
            "Epoch [9/50] - Batch loss: 161.4892 - Epoch Loss: 71735.9210 - Avg Loss: 168.3942\n",
            "Epoch [9/50] - Batch loss: 163.3297 - Epoch Loss: 71899.2507 - Avg Loss: 168.3823\n",
            "Epoch [9/50] - Batch loss: 166.4000 - Epoch Loss: 72065.6507 - Avg Loss: 168.3777\n",
            "Epoch [9/50] - Batch loss: 161.3476 - Epoch Loss: 72226.9983 - Avg Loss: 168.3613\n",
            "Epoch [9/50] - Batch loss: 168.3423 - Epoch Loss: 72395.3405 - Avg Loss: 168.3613\n",
            "Epoch [9/50] - Batch loss: 161.0301 - Epoch Loss: 72556.3706 - Avg Loss: 168.3442\n",
            "Epoch [9/50] - Batch loss: 165.1792 - Epoch Loss: 72721.5499 - Avg Loss: 168.3369\n",
            "Epoch [9/50] - Batch loss: 160.8154 - Epoch Loss: 72882.3652 - Avg Loss: 168.3196\n",
            "Epoch [9/50] - Batch loss: 171.3064 - Epoch Loss: 73053.6717 - Avg Loss: 168.3264\n",
            "Epoch [9/50] - Batch loss: 167.5384 - Epoch Loss: 73221.2101 - Avg Loss: 168.3246\n",
            "Epoch [9/50] - Batch loss: 172.7142 - Epoch Loss: 73393.9243 - Avg Loss: 168.3347\n",
            "Epoch [9/50] - Batch loss: 160.3988 - Epoch Loss: 73554.3231 - Avg Loss: 168.3165\n",
            "Epoch [9/50] - Batch loss: 162.1734 - Epoch Loss: 73716.4964 - Avg Loss: 168.3025\n",
            "Epoch [9/50] - Batch loss: 168.2783 - Epoch Loss: 73884.7748 - Avg Loss: 168.3024\n",
            "Epoch [9/50] - Batch loss: 169.0656 - Epoch Loss: 74053.8404 - Avg Loss: 168.3042\n",
            "Epoch [9/50] - Batch loss: 156.3020 - Epoch Loss: 74210.1423 - Avg Loss: 168.2770\n",
            "Epoch [9/50] - Batch loss: 166.0917 - Epoch Loss: 74376.2340 - Avg Loss: 168.2720\n",
            "Epoch [9/50] - Batch loss: 163.8031 - Epoch Loss: 74540.0371 - Avg Loss: 168.2619\n",
            "Epoch [9/50] - Batch loss: 169.6125 - Epoch Loss: 74709.6496 - Avg Loss: 168.2650\n",
            "Epoch [9/50] - Batch loss: 163.4172 - Epoch Loss: 74873.0668 - Avg Loss: 168.2541\n",
            "Epoch [9/50] - Batch loss: 166.4622 - Epoch Loss: 75039.5291 - Avg Loss: 168.2501\n",
            "Epoch [9/50] - Batch loss: 168.2489 - Epoch Loss: 75207.7780 - Avg Loss: 168.2501\n",
            "Epoch [9/50] - Batch loss: 171.1929 - Epoch Loss: 75378.9708 - Avg Loss: 168.2566\n",
            "Epoch [9/50] - Batch loss: 162.6382 - Epoch Loss: 75541.6090 - Avg Loss: 168.2441\n",
            "Epoch [9/50] - Batch loss: 159.4198 - Epoch Loss: 75701.0288 - Avg Loss: 168.2245\n",
            "Epoch [9/50] - Batch loss: 174.0384 - Epoch Loss: 75875.0672 - Avg Loss: 168.2374\n",
            "Epoch [9/50] - Batch loss: 165.5587 - Epoch Loss: 76040.6259 - Avg Loss: 168.2315\n",
            "Epoch [9/50] - Batch loss: 161.0519 - Epoch Loss: 76201.6778 - Avg Loss: 168.2156\n",
            "Epoch [9/50] - Batch loss: 153.1594 - Epoch Loss: 76354.8372 - Avg Loss: 168.1825\n",
            "Epoch [9/50] - Batch loss: 162.8130 - Epoch Loss: 76517.6502 - Avg Loss: 168.1707\n",
            "Epoch [9/50] - Batch loss: 156.5847 - Epoch Loss: 76674.2348 - Avg Loss: 168.1453\n",
            "Epoch [9/50] - Batch loss: 158.8079 - Epoch Loss: 76833.0427 - Avg Loss: 168.1248\n",
            "Epoch [9/50] - Batch loss: 165.1664 - Epoch Loss: 76998.2091 - Avg Loss: 168.1184\n",
            "Epoch [9/50] - Batch loss: 169.2666 - Epoch Loss: 77167.4757 - Avg Loss: 168.1209\n",
            "Epoch [9/50] - Batch loss: 169.1333 - Epoch Loss: 77336.6090 - Avg Loss: 168.1231\n",
            "Epoch [9/50] - Batch loss: 159.5901 - Epoch Loss: 77496.1991 - Avg Loss: 168.1046\n",
            "Epoch [9/50] - Batch loss: 156.2895 - Epoch Loss: 77652.4885 - Avg Loss: 168.0790\n",
            "Epoch [9/50] - Batch loss: 161.8329 - Epoch Loss: 77814.3215 - Avg Loss: 168.0655\n",
            "Epoch [9/50] - Batch loss: 163.7712 - Epoch Loss: 77978.0927 - Avg Loss: 168.0562\n",
            "Epoch [9/50] - Batch loss: 167.2101 - Epoch Loss: 78145.3029 - Avg Loss: 168.0544\n",
            "Epoch [9/50] - Batch loss: 166.3510 - Epoch Loss: 78311.6539 - Avg Loss: 168.0508\n",
            "Epoch [9/50] - Batch loss: 175.3390 - Epoch Loss: 78486.9929 - Avg Loss: 168.0664\n",
            "Epoch [9/50] - Batch loss: 164.3409 - Epoch Loss: 78651.3338 - Avg Loss: 168.0584\n",
            "Epoch [9/50] - Batch loss: 173.0961 - Epoch Loss: 78824.4299 - Avg Loss: 168.0691\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 10/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6aca790fb1ec41379be855f74ad4734b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/50] - Batch loss: 158.7532 - Epoch Loss: 158.7532 - Avg Loss: 158.7532\n",
            "Epoch [10/50] - Batch loss: 164.5512 - Epoch Loss: 323.3044 - Avg Loss: 161.6522\n",
            "Epoch [10/50] - Batch loss: 168.1072 - Epoch Loss: 491.4115 - Avg Loss: 163.8038\n",
            "Epoch [10/50] - Batch loss: 168.5910 - Epoch Loss: 660.0026 - Avg Loss: 165.0006\n",
            "Epoch [10/50] - Batch loss: 163.9491 - Epoch Loss: 823.9516 - Avg Loss: 164.7903\n",
            "Epoch [10/50] - Batch loss: 171.3044 - Epoch Loss: 995.2561 - Avg Loss: 165.8760\n",
            "Epoch [10/50] - Batch loss: 165.5219 - Epoch Loss: 1160.7779 - Avg Loss: 165.8254\n",
            "Epoch [10/50] - Batch loss: 165.7616 - Epoch Loss: 1326.5396 - Avg Loss: 165.8174\n",
            "Epoch [10/50] - Batch loss: 155.8230 - Epoch Loss: 1482.3625 - Avg Loss: 164.7069\n",
            "Epoch [10/50] - Batch loss: 169.4212 - Epoch Loss: 1651.7837 - Avg Loss: 165.1784\n",
            "Epoch [10/50] - Batch loss: 169.1118 - Epoch Loss: 1820.8955 - Avg Loss: 165.5360\n",
            "Epoch [10/50] - Batch loss: 168.6162 - Epoch Loss: 1989.5117 - Avg Loss: 165.7926\n",
            "Epoch [10/50] - Batch loss: 168.2619 - Epoch Loss: 2157.7736 - Avg Loss: 165.9826\n",
            "Epoch [10/50] - Batch loss: 163.4410 - Epoch Loss: 2321.2146 - Avg Loss: 165.8010\n",
            "Epoch [10/50] - Batch loss: 176.6996 - Epoch Loss: 2497.9142 - Avg Loss: 166.5276\n",
            "Epoch [10/50] - Batch loss: 166.9395 - Epoch Loss: 2664.8537 - Avg Loss: 166.5534\n",
            "Epoch [10/50] - Batch loss: 159.1706 - Epoch Loss: 2824.0243 - Avg Loss: 166.1191\n",
            "Epoch [10/50] - Batch loss: 169.1691 - Epoch Loss: 2993.1934 - Avg Loss: 166.2885\n",
            "Epoch [10/50] - Batch loss: 162.2473 - Epoch Loss: 3155.4407 - Avg Loss: 166.0758\n",
            "Epoch [10/50] - Batch loss: 171.8703 - Epoch Loss: 3327.3111 - Avg Loss: 166.3656\n",
            "Epoch [10/50] - Batch loss: 164.4891 - Epoch Loss: 3491.8002 - Avg Loss: 166.2762\n",
            "Epoch [10/50] - Batch loss: 169.2239 - Epoch Loss: 3661.0241 - Avg Loss: 166.4102\n",
            "Epoch [10/50] - Batch loss: 172.9952 - Epoch Loss: 3834.0193 - Avg Loss: 166.6965\n",
            "Epoch [10/50] - Batch loss: 162.1691 - Epoch Loss: 3996.1884 - Avg Loss: 166.5078\n",
            "Epoch [10/50] - Batch loss: 161.0934 - Epoch Loss: 4157.2818 - Avg Loss: 166.2913\n",
            "Epoch [10/50] - Batch loss: 169.3584 - Epoch Loss: 4326.6402 - Avg Loss: 166.4092\n",
            "Epoch [10/50] - Batch loss: 163.6774 - Epoch Loss: 4490.3175 - Avg Loss: 166.3081\n",
            "Epoch [10/50] - Batch loss: 166.8761 - Epoch Loss: 4657.1937 - Avg Loss: 166.3283\n",
            "Epoch [10/50] - Batch loss: 168.0094 - Epoch Loss: 4825.2030 - Avg Loss: 166.3863\n",
            "Epoch [10/50] - Batch loss: 162.4523 - Epoch Loss: 4987.6553 - Avg Loss: 166.2552\n",
            "Epoch [10/50] - Batch loss: 166.1361 - Epoch Loss: 5153.7914 - Avg Loss: 166.2513\n",
            "Epoch [10/50] - Batch loss: 158.5832 - Epoch Loss: 5312.3746 - Avg Loss: 166.0117\n",
            "Epoch [10/50] - Batch loss: 170.0487 - Epoch Loss: 5482.4232 - Avg Loss: 166.1340\n",
            "Epoch [10/50] - Batch loss: 165.4990 - Epoch Loss: 5647.9223 - Avg Loss: 166.1154\n",
            "Epoch [10/50] - Batch loss: 168.2459 - Epoch Loss: 5816.1681 - Avg Loss: 166.1762\n",
            "Epoch [10/50] - Batch loss: 169.5941 - Epoch Loss: 5985.7623 - Avg Loss: 166.2712\n",
            "Epoch [10/50] - Batch loss: 162.5210 - Epoch Loss: 6148.2833 - Avg Loss: 166.1698\n",
            "Epoch [10/50] - Batch loss: 160.7991 - Epoch Loss: 6309.0824 - Avg Loss: 166.0285\n",
            "Epoch [10/50] - Batch loss: 170.1281 - Epoch Loss: 6479.2104 - Avg Loss: 166.1336\n",
            "Epoch [10/50] - Batch loss: 171.1165 - Epoch Loss: 6650.3269 - Avg Loss: 166.2582\n",
            "Epoch [10/50] - Batch loss: 159.6268 - Epoch Loss: 6809.9537 - Avg Loss: 166.0964\n",
            "Epoch [10/50] - Batch loss: 165.1957 - Epoch Loss: 6975.1495 - Avg Loss: 166.0750\n",
            "Epoch [10/50] - Batch loss: 155.6429 - Epoch Loss: 7130.7924 - Avg Loss: 165.8324\n",
            "Epoch [10/50] - Batch loss: 164.8855 - Epoch Loss: 7295.6779 - Avg Loss: 165.8109\n",
            "Epoch [10/50] - Batch loss: 165.4548 - Epoch Loss: 7461.1327 - Avg Loss: 165.8029\n",
            "Epoch [10/50] - Batch loss: 162.3133 - Epoch Loss: 7623.4460 - Avg Loss: 165.7271\n",
            "Epoch [10/50] - Batch loss: 162.1222 - Epoch Loss: 7785.5682 - Avg Loss: 165.6504\n",
            "Epoch [10/50] - Batch loss: 175.2041 - Epoch Loss: 7960.7723 - Avg Loss: 165.8494\n",
            "Epoch [10/50] - Batch loss: 158.1626 - Epoch Loss: 8118.9349 - Avg Loss: 165.6925\n",
            "Epoch [10/50] - Batch loss: 152.9526 - Epoch Loss: 8271.8875 - Avg Loss: 165.4377\n",
            "Epoch [10/50] - Batch loss: 163.7989 - Epoch Loss: 8435.6864 - Avg Loss: 165.4056\n",
            "Epoch [10/50] - Batch loss: 168.7154 - Epoch Loss: 8604.4017 - Avg Loss: 165.4693\n",
            "Epoch [10/50] - Batch loss: 160.8689 - Epoch Loss: 8765.2706 - Avg Loss: 165.3825\n",
            "Epoch [10/50] - Batch loss: 165.6489 - Epoch Loss: 8930.9196 - Avg Loss: 165.3874\n",
            "Epoch [10/50] - Batch loss: 165.0738 - Epoch Loss: 9095.9934 - Avg Loss: 165.3817\n",
            "Epoch [10/50] - Batch loss: 165.1694 - Epoch Loss: 9261.1628 - Avg Loss: 165.3779\n",
            "Epoch [10/50] - Batch loss: 164.1465 - Epoch Loss: 9425.3092 - Avg Loss: 165.3563\n",
            "Epoch [10/50] - Batch loss: 161.9784 - Epoch Loss: 9587.2877 - Avg Loss: 165.2981\n",
            "Epoch [10/50] - Batch loss: 165.3106 - Epoch Loss: 9752.5983 - Avg Loss: 165.2983\n",
            "Epoch [10/50] - Batch loss: 174.9728 - Epoch Loss: 9927.5711 - Avg Loss: 165.4595\n",
            "Epoch [10/50] - Batch loss: 164.4572 - Epoch Loss: 10092.0282 - Avg Loss: 165.4431\n",
            "Epoch [10/50] - Batch loss: 158.5921 - Epoch Loss: 10250.6203 - Avg Loss: 165.3326\n",
            "Epoch [10/50] - Batch loss: 167.5975 - Epoch Loss: 10418.2178 - Avg Loss: 165.3685\n",
            "Epoch [10/50] - Batch loss: 167.6107 - Epoch Loss: 10585.8285 - Avg Loss: 165.4036\n",
            "Epoch [10/50] - Batch loss: 165.6037 - Epoch Loss: 10751.4323 - Avg Loss: 165.4067\n",
            "Epoch [10/50] - Batch loss: 154.7019 - Epoch Loss: 10906.1342 - Avg Loss: 165.2445\n",
            "Epoch [10/50] - Batch loss: 162.5793 - Epoch Loss: 11068.7135 - Avg Loss: 165.2047\n",
            "Epoch [10/50] - Batch loss: 162.3443 - Epoch Loss: 11231.0578 - Avg Loss: 165.1626\n",
            "Epoch [10/50] - Batch loss: 156.1380 - Epoch Loss: 11387.1958 - Avg Loss: 165.0318\n",
            "Epoch [10/50] - Batch loss: 159.6467 - Epoch Loss: 11546.8424 - Avg Loss: 164.9549\n",
            "Epoch [10/50] - Batch loss: 165.6321 - Epoch Loss: 11712.4745 - Avg Loss: 164.9644\n",
            "Epoch [10/50] - Batch loss: 172.9058 - Epoch Loss: 11885.3803 - Avg Loss: 165.0747\n",
            "Epoch [10/50] - Batch loss: 162.6296 - Epoch Loss: 12048.0099 - Avg Loss: 165.0412\n",
            "Epoch [10/50] - Batch loss: 161.3901 - Epoch Loss: 12209.4001 - Avg Loss: 164.9919\n",
            "Epoch [10/50] - Batch loss: 168.3495 - Epoch Loss: 12377.7495 - Avg Loss: 165.0367\n",
            "Epoch [10/50] - Batch loss: 165.0521 - Epoch Loss: 12542.8017 - Avg Loss: 165.0369\n",
            "Epoch [10/50] - Batch loss: 162.1137 - Epoch Loss: 12704.9153 - Avg Loss: 164.9989\n",
            "Epoch [10/50] - Batch loss: 167.5127 - Epoch Loss: 12872.4281 - Avg Loss: 165.0311\n",
            "Epoch [10/50] - Batch loss: 168.1800 - Epoch Loss: 13040.6081 - Avg Loss: 165.0710\n",
            "Epoch [10/50] - Batch loss: 157.3366 - Epoch Loss: 13197.9447 - Avg Loss: 164.9743\n",
            "Epoch [10/50] - Batch loss: 161.0682 - Epoch Loss: 13359.0129 - Avg Loss: 164.9261\n",
            "Epoch [10/50] - Batch loss: 166.1249 - Epoch Loss: 13525.1379 - Avg Loss: 164.9407\n",
            "Epoch [10/50] - Batch loss: 170.9171 - Epoch Loss: 13696.0550 - Avg Loss: 165.0127\n",
            "Epoch [10/50] - Batch loss: 157.0250 - Epoch Loss: 13853.0800 - Avg Loss: 164.9176\n",
            "Epoch [10/50] - Batch loss: 166.4609 - Epoch Loss: 14019.5409 - Avg Loss: 164.9358\n",
            "Epoch [10/50] - Batch loss: 172.2246 - Epoch Loss: 14191.7655 - Avg Loss: 165.0205\n",
            "Epoch [10/50] - Batch loss: 161.0353 - Epoch Loss: 14352.8009 - Avg Loss: 164.9747\n",
            "Epoch [10/50] - Batch loss: 166.1010 - Epoch Loss: 14518.9019 - Avg Loss: 164.9875\n",
            "Epoch [10/50] - Batch loss: 157.7099 - Epoch Loss: 14676.6118 - Avg Loss: 164.9058\n",
            "Epoch [10/50] - Batch loss: 161.3603 - Epoch Loss: 14837.9721 - Avg Loss: 164.8664\n",
            "Epoch [10/50] - Batch loss: 166.2963 - Epoch Loss: 15004.2684 - Avg Loss: 164.8821\n",
            "Epoch [10/50] - Batch loss: 165.8607 - Epoch Loss: 15170.1290 - Avg Loss: 164.8927\n",
            "Epoch [10/50] - Batch loss: 169.3314 - Epoch Loss: 15339.4604 - Avg Loss: 164.9404\n",
            "Epoch [10/50] - Batch loss: 167.4544 - Epoch Loss: 15506.9149 - Avg Loss: 164.9672\n",
            "Epoch [10/50] - Batch loss: 157.6078 - Epoch Loss: 15664.5227 - Avg Loss: 164.8897\n",
            "Epoch [10/50] - Batch loss: 162.7117 - Epoch Loss: 15827.2344 - Avg Loss: 164.8670\n",
            "Epoch [10/50] - Batch loss: 174.8400 - Epoch Loss: 16002.0744 - Avg Loss: 164.9698\n",
            "Epoch [10/50] - Batch loss: 162.9061 - Epoch Loss: 16164.9804 - Avg Loss: 164.9488\n",
            "Epoch [10/50] - Batch loss: 162.0489 - Epoch Loss: 16327.0294 - Avg Loss: 164.9195\n",
            "Epoch [10/50] - Batch loss: 168.1073 - Epoch Loss: 16495.1367 - Avg Loss: 164.9514\n",
            "Epoch [10/50] - Batch loss: 177.1346 - Epoch Loss: 16672.2713 - Avg Loss: 165.0720\n",
            "Epoch [10/50] - Batch loss: 157.2149 - Epoch Loss: 16829.4862 - Avg Loss: 164.9950\n",
            "Epoch [10/50] - Batch loss: 167.8034 - Epoch Loss: 16997.2897 - Avg Loss: 165.0222\n",
            "Epoch [10/50] - Batch loss: 173.8375 - Epoch Loss: 17171.1271 - Avg Loss: 165.1070\n",
            "Epoch [10/50] - Batch loss: 163.1339 - Epoch Loss: 17334.2610 - Avg Loss: 165.0882\n",
            "Epoch [10/50] - Batch loss: 164.1649 - Epoch Loss: 17498.4259 - Avg Loss: 165.0795\n",
            "Epoch [10/50] - Batch loss: 168.8448 - Epoch Loss: 17667.2707 - Avg Loss: 165.1147\n",
            "Epoch [10/50] - Batch loss: 161.6680 - Epoch Loss: 17828.9387 - Avg Loss: 165.0828\n",
            "Epoch [10/50] - Batch loss: 161.3749 - Epoch Loss: 17990.3136 - Avg Loss: 165.0487\n",
            "Epoch [10/50] - Batch loss: 165.6938 - Epoch Loss: 18156.0075 - Avg Loss: 165.0546\n",
            "Epoch [10/50] - Batch loss: 171.7252 - Epoch Loss: 18327.7327 - Avg Loss: 165.1147\n",
            "Epoch [10/50] - Batch loss: 159.8383 - Epoch Loss: 18487.5710 - Avg Loss: 165.0676\n",
            "Epoch [10/50] - Batch loss: 160.1675 - Epoch Loss: 18647.7385 - Avg Loss: 165.0242\n",
            "Epoch [10/50] - Batch loss: 162.9806 - Epoch Loss: 18810.7191 - Avg Loss: 165.0063\n",
            "Epoch [10/50] - Batch loss: 164.2572 - Epoch Loss: 18974.9763 - Avg Loss: 164.9998\n",
            "Epoch [10/50] - Batch loss: 158.7722 - Epoch Loss: 19133.7486 - Avg Loss: 164.9461\n",
            "Epoch [10/50] - Batch loss: 161.8352 - Epoch Loss: 19295.5838 - Avg Loss: 164.9195\n",
            "Epoch [10/50] - Batch loss: 167.5588 - Epoch Loss: 19463.1426 - Avg Loss: 164.9419\n",
            "Epoch [10/50] - Batch loss: 166.4827 - Epoch Loss: 19629.6253 - Avg Loss: 164.9548\n",
            "Epoch [10/50] - Batch loss: 169.2340 - Epoch Loss: 19798.8592 - Avg Loss: 164.9905\n",
            "Epoch [10/50] - Batch loss: 157.5325 - Epoch Loss: 19956.3917 - Avg Loss: 164.9289\n",
            "Epoch [10/50] - Batch loss: 160.0842 - Epoch Loss: 20116.4759 - Avg Loss: 164.8891\n",
            "Epoch [10/50] - Batch loss: 165.3359 - Epoch Loss: 20281.8118 - Avg Loss: 164.8928\n",
            "Epoch [10/50] - Batch loss: 160.9844 - Epoch Loss: 20442.7962 - Avg Loss: 164.8613\n",
            "Epoch [10/50] - Batch loss: 171.5221 - Epoch Loss: 20614.3183 - Avg Loss: 164.9145\n",
            "Epoch [10/50] - Batch loss: 158.6413 - Epoch Loss: 20772.9596 - Avg Loss: 164.8648\n",
            "Epoch [10/50] - Batch loss: 165.3761 - Epoch Loss: 20938.3357 - Avg Loss: 164.8688\n",
            "Epoch [10/50] - Batch loss: 157.2467 - Epoch Loss: 21095.5823 - Avg Loss: 164.8092\n",
            "Epoch [10/50] - Batch loss: 160.5706 - Epoch Loss: 21256.1529 - Avg Loss: 164.7764\n",
            "Epoch [10/50] - Batch loss: 167.2053 - Epoch Loss: 21423.3582 - Avg Loss: 164.7951\n",
            "Epoch [10/50] - Batch loss: 165.0902 - Epoch Loss: 21588.4483 - Avg Loss: 164.7973\n",
            "Epoch [10/50] - Batch loss: 158.7796 - Epoch Loss: 21747.2280 - Avg Loss: 164.7517\n",
            "Epoch [10/50] - Batch loss: 164.9365 - Epoch Loss: 21912.1645 - Avg Loss: 164.7531\n",
            "Epoch [10/50] - Batch loss: 168.1771 - Epoch Loss: 22080.3416 - Avg Loss: 164.7787\n",
            "Epoch [10/50] - Batch loss: 167.8681 - Epoch Loss: 22248.2097 - Avg Loss: 164.8016\n",
            "Epoch [10/50] - Batch loss: 162.6991 - Epoch Loss: 22410.9088 - Avg Loss: 164.7861\n",
            "Epoch [10/50] - Batch loss: 163.4549 - Epoch Loss: 22574.3637 - Avg Loss: 164.7764\n",
            "Epoch [10/50] - Batch loss: 165.5911 - Epoch Loss: 22739.9548 - Avg Loss: 164.7823\n",
            "Epoch [10/50] - Batch loss: 170.0233 - Epoch Loss: 22909.9781 - Avg Loss: 164.8200\n",
            "Epoch [10/50] - Batch loss: 161.1451 - Epoch Loss: 23071.1232 - Avg Loss: 164.7937\n",
            "Epoch [10/50] - Batch loss: 167.1746 - Epoch Loss: 23238.2978 - Avg Loss: 164.8106\n",
            "Epoch [10/50] - Batch loss: 168.9332 - Epoch Loss: 23407.2310 - Avg Loss: 164.8397\n",
            "Epoch [10/50] - Batch loss: 161.7320 - Epoch Loss: 23568.9630 - Avg Loss: 164.8179\n",
            "Epoch [10/50] - Batch loss: 162.8964 - Epoch Loss: 23731.8593 - Avg Loss: 164.8046\n",
            "Epoch [10/50] - Batch loss: 154.8860 - Epoch Loss: 23886.7454 - Avg Loss: 164.7362\n",
            "Epoch [10/50] - Batch loss: 166.0853 - Epoch Loss: 24052.8307 - Avg Loss: 164.7454\n",
            "Epoch [10/50] - Batch loss: 161.9914 - Epoch Loss: 24214.8221 - Avg Loss: 164.7267\n",
            "Epoch [10/50] - Batch loss: 161.8389 - Epoch Loss: 24376.6610 - Avg Loss: 164.7072\n",
            "Epoch [10/50] - Batch loss: 164.9796 - Epoch Loss: 24541.6406 - Avg Loss: 164.7090\n",
            "Epoch [10/50] - Batch loss: 164.9277 - Epoch Loss: 24706.5683 - Avg Loss: 164.7105\n",
            "Epoch [10/50] - Batch loss: 161.2580 - Epoch Loss: 24867.8263 - Avg Loss: 164.6876\n",
            "Epoch [10/50] - Batch loss: 173.9719 - Epoch Loss: 25041.7982 - Avg Loss: 164.7487\n",
            "Epoch [10/50] - Batch loss: 164.5505 - Epoch Loss: 25206.3487 - Avg Loss: 164.7474\n",
            "Epoch [10/50] - Batch loss: 168.2354 - Epoch Loss: 25374.5841 - Avg Loss: 164.7700\n",
            "Epoch [10/50] - Batch loss: 175.5165 - Epoch Loss: 25550.1005 - Avg Loss: 164.8394\n",
            "Epoch [10/50] - Batch loss: 155.7244 - Epoch Loss: 25705.8250 - Avg Loss: 164.7809\n",
            "Epoch [10/50] - Batch loss: 167.2764 - Epoch Loss: 25873.1014 - Avg Loss: 164.7968\n",
            "Epoch [10/50] - Batch loss: 166.0742 - Epoch Loss: 26039.1756 - Avg Loss: 164.8049\n",
            "Epoch [10/50] - Batch loss: 163.5229 - Epoch Loss: 26202.6985 - Avg Loss: 164.7968\n",
            "Epoch [10/50] - Batch loss: 164.5446 - Epoch Loss: 26367.2431 - Avg Loss: 164.7953\n",
            "Epoch [10/50] - Batch loss: 164.2561 - Epoch Loss: 26531.4993 - Avg Loss: 164.7919\n",
            "Epoch [10/50] - Batch loss: 171.5478 - Epoch Loss: 26703.0471 - Avg Loss: 164.8336\n",
            "Epoch [10/50] - Batch loss: 163.4864 - Epoch Loss: 26866.5335 - Avg Loss: 164.8254\n",
            "Epoch [10/50] - Batch loss: 159.8442 - Epoch Loss: 27026.3777 - Avg Loss: 164.7950\n",
            "Epoch [10/50] - Batch loss: 163.4124 - Epoch Loss: 27189.7901 - Avg Loss: 164.7866\n",
            "Epoch [10/50] - Batch loss: 169.2509 - Epoch Loss: 27359.0410 - Avg Loss: 164.8135\n",
            "Epoch [10/50] - Batch loss: 165.6467 - Epoch Loss: 27524.6877 - Avg Loss: 164.8185\n",
            "Epoch [10/50] - Batch loss: 163.8917 - Epoch Loss: 27688.5794 - Avg Loss: 164.8130\n",
            "Epoch [10/50] - Batch loss: 162.0591 - Epoch Loss: 27850.6386 - Avg Loss: 164.7967\n",
            "Epoch [10/50] - Batch loss: 171.6776 - Epoch Loss: 28022.3162 - Avg Loss: 164.8372\n",
            "Epoch [10/50] - Batch loss: 162.5048 - Epoch Loss: 28184.8210 - Avg Loss: 164.8235\n",
            "Epoch [10/50] - Batch loss: 163.5942 - Epoch Loss: 28348.4152 - Avg Loss: 164.8164\n",
            "Epoch [10/50] - Batch loss: 164.7798 - Epoch Loss: 28513.1950 - Avg Loss: 164.8162\n",
            "Epoch [10/50] - Batch loss: 170.9099 - Epoch Loss: 28684.1049 - Avg Loss: 164.8512\n",
            "Epoch [10/50] - Batch loss: 173.7071 - Epoch Loss: 28857.8120 - Avg Loss: 164.9018\n",
            "Epoch [10/50] - Batch loss: 161.6689 - Epoch Loss: 29019.4809 - Avg Loss: 164.8834\n",
            "Epoch [10/50] - Batch loss: 172.9158 - Epoch Loss: 29192.3966 - Avg Loss: 164.9288\n",
            "Epoch [10/50] - Batch loss: 162.9107 - Epoch Loss: 29355.3073 - Avg Loss: 164.9175\n",
            "Epoch [10/50] - Batch loss: 168.2217 - Epoch Loss: 29523.5290 - Avg Loss: 164.9359\n",
            "Epoch [10/50] - Batch loss: 166.4974 - Epoch Loss: 29690.0264 - Avg Loss: 164.9446\n",
            "Epoch [10/50] - Batch loss: 165.0079 - Epoch Loss: 29855.0344 - Avg Loss: 164.9449\n",
            "Epoch [10/50] - Batch loss: 160.4487 - Epoch Loss: 30015.4830 - Avg Loss: 164.9202\n",
            "Epoch [10/50] - Batch loss: 173.0504 - Epoch Loss: 30188.5334 - Avg Loss: 164.9647\n",
            "Epoch [10/50] - Batch loss: 159.6265 - Epoch Loss: 30348.1599 - Avg Loss: 164.9357\n",
            "Epoch [10/50] - Batch loss: 157.3659 - Epoch Loss: 30505.5258 - Avg Loss: 164.8947\n",
            "Epoch [10/50] - Batch loss: 160.7687 - Epoch Loss: 30666.2945 - Avg Loss: 164.8726\n",
            "Epoch [10/50] - Batch loss: 162.5402 - Epoch Loss: 30828.8347 - Avg Loss: 164.8601\n",
            "Epoch [10/50] - Batch loss: 163.6166 - Epoch Loss: 30992.4513 - Avg Loss: 164.8535\n",
            "Epoch [10/50] - Batch loss: 165.5208 - Epoch Loss: 31157.9721 - Avg Loss: 164.8570\n",
            "Epoch [10/50] - Batch loss: 166.0559 - Epoch Loss: 31324.0280 - Avg Loss: 164.8633\n",
            "Epoch [10/50] - Batch loss: 158.9533 - Epoch Loss: 31482.9813 - Avg Loss: 164.8324\n",
            "Epoch [10/50] - Batch loss: 165.0587 - Epoch Loss: 31648.0399 - Avg Loss: 164.8335\n",
            "Epoch [10/50] - Batch loss: 160.2250 - Epoch Loss: 31808.2650 - Avg Loss: 164.8097\n",
            "Epoch [10/50] - Batch loss: 170.2609 - Epoch Loss: 31978.5258 - Avg Loss: 164.8378\n",
            "Epoch [10/50] - Batch loss: 161.8282 - Epoch Loss: 32140.3540 - Avg Loss: 164.8223\n",
            "Epoch [10/50] - Batch loss: 166.3817 - Epoch Loss: 32306.7357 - Avg Loss: 164.8303\n",
            "Epoch [10/50] - Batch loss: 163.2993 - Epoch Loss: 32470.0350 - Avg Loss: 164.8225\n",
            "Epoch [10/50] - Batch loss: 168.9641 - Epoch Loss: 32638.9991 - Avg Loss: 164.8434\n",
            "Epoch [10/50] - Batch loss: 168.6164 - Epoch Loss: 32807.6155 - Avg Loss: 164.8624\n",
            "Epoch [10/50] - Batch loss: 165.5507 - Epoch Loss: 32973.1662 - Avg Loss: 164.8658\n",
            "Epoch [10/50] - Batch loss: 160.7624 - Epoch Loss: 33133.9286 - Avg Loss: 164.8454\n",
            "Epoch [10/50] - Batch loss: 164.7271 - Epoch Loss: 33298.6557 - Avg Loss: 164.8448\n",
            "Epoch [10/50] - Batch loss: 173.4122 - Epoch Loss: 33472.0680 - Avg Loss: 164.8870\n",
            "Epoch [10/50] - Batch loss: 169.8185 - Epoch Loss: 33641.8865 - Avg Loss: 164.9112\n",
            "Epoch [10/50] - Batch loss: 167.6279 - Epoch Loss: 33809.5144 - Avg Loss: 164.9245\n",
            "Epoch [10/50] - Batch loss: 168.6003 - Epoch Loss: 33978.1147 - Avg Loss: 164.9423\n",
            "Epoch [10/50] - Batch loss: 161.1662 - Epoch Loss: 34139.2809 - Avg Loss: 164.9241\n",
            "Epoch [10/50] - Batch loss: 165.5165 - Epoch Loss: 34304.7975 - Avg Loss: 164.9269\n",
            "Epoch [10/50] - Batch loss: 161.9354 - Epoch Loss: 34466.7329 - Avg Loss: 164.9126\n",
            "Epoch [10/50] - Batch loss: 160.3022 - Epoch Loss: 34627.0351 - Avg Loss: 164.8906\n",
            "Epoch [10/50] - Batch loss: 158.4567 - Epoch Loss: 34785.4917 - Avg Loss: 164.8602\n",
            "Epoch [10/50] - Batch loss: 165.8369 - Epoch Loss: 34951.3286 - Avg Loss: 164.8648\n",
            "Epoch [10/50] - Batch loss: 172.2386 - Epoch Loss: 35123.5673 - Avg Loss: 164.8994\n",
            "Epoch [10/50] - Batch loss: 162.3399 - Epoch Loss: 35285.9071 - Avg Loss: 164.8874\n",
            "Epoch [10/50] - Batch loss: 158.2693 - Epoch Loss: 35444.1764 - Avg Loss: 164.8566\n",
            "Epoch [10/50] - Batch loss: 165.7071 - Epoch Loss: 35609.8835 - Avg Loss: 164.8606\n",
            "Epoch [10/50] - Batch loss: 160.8001 - Epoch Loss: 35770.6836 - Avg Loss: 164.8419\n",
            "Epoch [10/50] - Batch loss: 162.2954 - Epoch Loss: 35932.9790 - Avg Loss: 164.8302\n",
            "Epoch [10/50] - Batch loss: 167.1318 - Epoch Loss: 36100.1108 - Avg Loss: 164.8407\n",
            "Epoch [10/50] - Batch loss: 164.5508 - Epoch Loss: 36264.6616 - Avg Loss: 164.8394\n",
            "Epoch [10/50] - Batch loss: 159.2201 - Epoch Loss: 36423.8817 - Avg Loss: 164.8139\n",
            "Epoch [10/50] - Batch loss: 169.1574 - Epoch Loss: 36593.0391 - Avg Loss: 164.8335\n",
            "Epoch [10/50] - Batch loss: 169.6110 - Epoch Loss: 36762.6501 - Avg Loss: 164.8549\n",
            "Epoch [10/50] - Batch loss: 158.1194 - Epoch Loss: 36920.7695 - Avg Loss: 164.8249\n",
            "Epoch [10/50] - Batch loss: 161.1481 - Epoch Loss: 37081.9177 - Avg Loss: 164.8085\n",
            "Epoch [10/50] - Batch loss: 159.1516 - Epoch Loss: 37241.0693 - Avg Loss: 164.7835\n",
            "Epoch [10/50] - Batch loss: 162.5124 - Epoch Loss: 37403.5817 - Avg Loss: 164.7735\n",
            "Epoch [10/50] - Batch loss: 160.6274 - Epoch Loss: 37564.2091 - Avg Loss: 164.7553\n",
            "Epoch [10/50] - Batch loss: 158.7207 - Epoch Loss: 37722.9298 - Avg Loss: 164.7290\n",
            "Epoch [10/50] - Batch loss: 169.8786 - Epoch Loss: 37892.8085 - Avg Loss: 164.7513\n",
            "Epoch [10/50] - Batch loss: 168.3534 - Epoch Loss: 38061.1619 - Avg Loss: 164.7669\n",
            "Epoch [10/50] - Batch loss: 166.5936 - Epoch Loss: 38227.7555 - Avg Loss: 164.7748\n",
            "Epoch [10/50] - Batch loss: 174.6084 - Epoch Loss: 38402.3638 - Avg Loss: 164.8170\n",
            "Epoch [10/50] - Batch loss: 163.6614 - Epoch Loss: 38566.0252 - Avg Loss: 164.8121\n",
            "Epoch [10/50] - Batch loss: 172.9797 - Epoch Loss: 38739.0049 - Avg Loss: 164.8468\n",
            "Epoch [10/50] - Batch loss: 164.6833 - Epoch Loss: 38903.6882 - Avg Loss: 164.8461\n",
            "Epoch [10/50] - Batch loss: 171.1103 - Epoch Loss: 39074.7985 - Avg Loss: 164.8726\n",
            "Epoch [10/50] - Batch loss: 162.9337 - Epoch Loss: 39237.7321 - Avg Loss: 164.8644\n",
            "Epoch [10/50] - Batch loss: 171.0723 - Epoch Loss: 39408.8045 - Avg Loss: 164.8904\n",
            "Epoch [10/50] - Batch loss: 165.5236 - Epoch Loss: 39574.3281 - Avg Loss: 164.8930\n",
            "Epoch [10/50] - Batch loss: 173.8131 - Epoch Loss: 39748.1412 - Avg Loss: 164.9300\n",
            "Epoch [10/50] - Batch loss: 168.8540 - Epoch Loss: 39916.9952 - Avg Loss: 164.9463\n",
            "Epoch [10/50] - Batch loss: 173.1061 - Epoch Loss: 40090.1013 - Avg Loss: 164.9798\n",
            "Epoch [10/50] - Batch loss: 165.8992 - Epoch Loss: 40256.0005 - Avg Loss: 164.9836\n",
            "Epoch [10/50] - Batch loss: 169.6087 - Epoch Loss: 40425.6092 - Avg Loss: 165.0025\n",
            "Epoch [10/50] - Batch loss: 165.6959 - Epoch Loss: 40591.3051 - Avg Loss: 165.0053\n",
            "Epoch [10/50] - Batch loss: 162.2024 - Epoch Loss: 40753.5076 - Avg Loss: 164.9940\n",
            "Epoch [10/50] - Batch loss: 172.3214 - Epoch Loss: 40925.8290 - Avg Loss: 165.0235\n",
            "Epoch [10/50] - Batch loss: 173.6405 - Epoch Loss: 41099.4695 - Avg Loss: 165.0581\n",
            "Epoch [10/50] - Batch loss: 166.2326 - Epoch Loss: 41265.7021 - Avg Loss: 165.0628\n",
            "Epoch [10/50] - Batch loss: 156.4989 - Epoch Loss: 41422.2009 - Avg Loss: 165.0287\n",
            "Epoch [10/50] - Batch loss: 160.7560 - Epoch Loss: 41582.9569 - Avg Loss: 165.0117\n",
            "Epoch [10/50] - Batch loss: 171.4207 - Epoch Loss: 41754.3776 - Avg Loss: 165.0371\n",
            "Epoch [10/50] - Batch loss: 168.6846 - Epoch Loss: 41923.0623 - Avg Loss: 165.0514\n",
            "Epoch [10/50] - Batch loss: 172.1685 - Epoch Loss: 42095.2307 - Avg Loss: 165.0793\n",
            "Epoch [10/50] - Batch loss: 163.7941 - Epoch Loss: 42259.0248 - Avg Loss: 165.0743\n",
            "Epoch [10/50] - Batch loss: 160.4212 - Epoch Loss: 42419.4460 - Avg Loss: 165.0562\n",
            "Epoch [10/50] - Batch loss: 171.4712 - Epoch Loss: 42590.9172 - Avg Loss: 165.0811\n",
            "Epoch [10/50] - Batch loss: 167.4384 - Epoch Loss: 42758.3556 - Avg Loss: 165.0902\n",
            "Epoch [10/50] - Batch loss: 171.5479 - Epoch Loss: 42929.9035 - Avg Loss: 165.1150\n",
            "Epoch [10/50] - Batch loss: 175.9906 - Epoch Loss: 43105.8941 - Avg Loss: 165.1567\n",
            "Epoch [10/50] - Batch loss: 170.4862 - Epoch Loss: 43276.3803 - Avg Loss: 165.1770\n",
            "Epoch [10/50] - Batch loss: 175.8045 - Epoch Loss: 43452.1847 - Avg Loss: 165.2174\n",
            "Epoch [10/50] - Batch loss: 159.8140 - Epoch Loss: 43611.9987 - Avg Loss: 165.1970\n",
            "Epoch [10/50] - Batch loss: 164.2868 - Epoch Loss: 43776.2856 - Avg Loss: 165.1935\n",
            "Epoch [10/50] - Batch loss: 168.1274 - Epoch Loss: 43944.4129 - Avg Loss: 165.2046\n",
            "Epoch [10/50] - Batch loss: 171.3561 - Epoch Loss: 44115.7691 - Avg Loss: 165.2276\n",
            "Epoch [10/50] - Batch loss: 164.2895 - Epoch Loss: 44280.0586 - Avg Loss: 165.2241\n",
            "Epoch [10/50] - Batch loss: 166.9665 - Epoch Loss: 44447.0251 - Avg Loss: 165.2306\n",
            "Epoch [10/50] - Batch loss: 168.5458 - Epoch Loss: 44615.5709 - Avg Loss: 165.2429\n",
            "Epoch [10/50] - Batch loss: 168.6083 - Epoch Loss: 44784.1792 - Avg Loss: 165.2553\n",
            "Epoch [10/50] - Batch loss: 167.5333 - Epoch Loss: 44951.7126 - Avg Loss: 165.2636\n",
            "Epoch [10/50] - Batch loss: 168.2469 - Epoch Loss: 45119.9595 - Avg Loss: 165.2746\n",
            "Epoch [10/50] - Batch loss: 165.4730 - Epoch Loss: 45285.4326 - Avg Loss: 165.2753\n",
            "Epoch [10/50] - Batch loss: 170.7196 - Epoch Loss: 45456.1521 - Avg Loss: 165.2951\n",
            "Epoch [10/50] - Batch loss: 170.9832 - Epoch Loss: 45627.1353 - Avg Loss: 165.3157\n",
            "Epoch [10/50] - Batch loss: 163.7897 - Epoch Loss: 45790.9250 - Avg Loss: 165.3102\n",
            "Epoch [10/50] - Batch loss: 157.8412 - Epoch Loss: 45948.7662 - Avg Loss: 165.2833\n",
            "Epoch [10/50] - Batch loss: 166.8524 - Epoch Loss: 46115.6187 - Avg Loss: 165.2890\n",
            "Epoch [10/50] - Batch loss: 168.2597 - Epoch Loss: 46283.8783 - Avg Loss: 165.2996\n",
            "Epoch [10/50] - Batch loss: 160.0994 - Epoch Loss: 46443.9778 - Avg Loss: 165.2811\n",
            "Epoch [10/50] - Batch loss: 164.4999 - Epoch Loss: 46608.4777 - Avg Loss: 165.2783\n",
            "Epoch [10/50] - Batch loss: 161.9139 - Epoch Loss: 46770.3916 - Avg Loss: 165.2664\n",
            "Epoch [10/50] - Batch loss: 165.5490 - Epoch Loss: 46935.9405 - Avg Loss: 165.2674\n",
            "Epoch [10/50] - Batch loss: 164.3610 - Epoch Loss: 47100.3015 - Avg Loss: 165.2642\n",
            "Epoch [10/50] - Batch loss: 160.5866 - Epoch Loss: 47260.8882 - Avg Loss: 165.2479\n",
            "Epoch [10/50] - Batch loss: 169.7031 - Epoch Loss: 47430.5913 - Avg Loss: 165.2634\n",
            "Epoch [10/50] - Batch loss: 169.2483 - Epoch Loss: 47599.8396 - Avg Loss: 165.2772\n",
            "Epoch [10/50] - Batch loss: 169.5543 - Epoch Loss: 47769.3939 - Avg Loss: 165.2920\n",
            "Epoch [10/50] - Batch loss: 167.8152 - Epoch Loss: 47937.2090 - Avg Loss: 165.3007\n",
            "Epoch [10/50] - Batch loss: 164.0274 - Epoch Loss: 48101.2364 - Avg Loss: 165.2963\n",
            "Epoch [10/50] - Batch loss: 170.8745 - Epoch Loss: 48272.1109 - Avg Loss: 165.3154\n",
            "Epoch [10/50] - Batch loss: 163.1499 - Epoch Loss: 48435.2609 - Avg Loss: 165.3081\n",
            "Epoch [10/50] - Batch loss: 168.1425 - Epoch Loss: 48603.4034 - Avg Loss: 165.3177\n",
            "Epoch [10/50] - Batch loss: 164.4315 - Epoch Loss: 48767.8349 - Avg Loss: 165.3147\n",
            "Epoch [10/50] - Batch loss: 169.4508 - Epoch Loss: 48937.2857 - Avg Loss: 165.3287\n",
            "Epoch [10/50] - Batch loss: 167.3116 - Epoch Loss: 49104.5973 - Avg Loss: 165.3353\n",
            "Epoch [10/50] - Batch loss: 168.6817 - Epoch Loss: 49273.2791 - Avg Loss: 165.3466\n",
            "Epoch [10/50] - Batch loss: 163.2228 - Epoch Loss: 49436.5019 - Avg Loss: 165.3395\n",
            "Epoch [10/50] - Batch loss: 162.1250 - Epoch Loss: 49598.6269 - Avg Loss: 165.3288\n",
            "Epoch [10/50] - Batch loss: 161.6747 - Epoch Loss: 49760.3015 - Avg Loss: 165.3166\n",
            "Epoch [10/50] - Batch loss: 164.5190 - Epoch Loss: 49924.8206 - Avg Loss: 165.3140\n",
            "Epoch [10/50] - Batch loss: 166.0004 - Epoch Loss: 50090.8210 - Avg Loss: 165.3162\n",
            "Epoch [10/50] - Batch loss: 169.6682 - Epoch Loss: 50260.4892 - Avg Loss: 165.3306\n",
            "Epoch [10/50] - Batch loss: 173.8480 - Epoch Loss: 50434.3372 - Avg Loss: 165.3585\n",
            "Epoch [10/50] - Batch loss: 162.8065 - Epoch Loss: 50597.1436 - Avg Loss: 165.3501\n",
            "Epoch [10/50] - Batch loss: 161.7948 - Epoch Loss: 50758.9385 - Avg Loss: 165.3386\n",
            "Epoch [10/50] - Batch loss: 161.2625 - Epoch Loss: 50920.2010 - Avg Loss: 165.3253\n",
            "Epoch [10/50] - Batch loss: 172.0375 - Epoch Loss: 51092.2385 - Avg Loss: 165.3471\n",
            "Epoch [10/50] - Batch loss: 162.4321 - Epoch Loss: 51254.6705 - Avg Loss: 165.3376\n",
            "Epoch [10/50] - Batch loss: 165.2990 - Epoch Loss: 51419.9695 - Avg Loss: 165.3375\n",
            "Epoch [10/50] - Batch loss: 158.3601 - Epoch Loss: 51578.3296 - Avg Loss: 165.3152\n",
            "Epoch [10/50] - Batch loss: 160.0166 - Epoch Loss: 51738.3462 - Avg Loss: 165.2982\n",
            "Epoch [10/50] - Batch loss: 166.5770 - Epoch Loss: 51904.9231 - Avg Loss: 165.3023\n",
            "Epoch [10/50] - Batch loss: 175.1376 - Epoch Loss: 52080.0607 - Avg Loss: 165.3335\n",
            "Epoch [10/50] - Batch loss: 172.4109 - Epoch Loss: 52252.4717 - Avg Loss: 165.3559\n",
            "Epoch [10/50] - Batch loss: 171.8710 - Epoch Loss: 52424.3427 - Avg Loss: 165.3765\n",
            "Epoch [10/50] - Batch loss: 164.5770 - Epoch Loss: 52588.9197 - Avg Loss: 165.3740\n",
            "Epoch [10/50] - Batch loss: 167.7790 - Epoch Loss: 52756.6987 - Avg Loss: 165.3815\n",
            "Epoch [10/50] - Batch loss: 170.9655 - Epoch Loss: 52927.6641 - Avg Loss: 165.3990\n",
            "Epoch [10/50] - Batch loss: 163.2167 - Epoch Loss: 53090.8808 - Avg Loss: 165.3922\n",
            "Epoch [10/50] - Batch loss: 166.0715 - Epoch Loss: 53256.9524 - Avg Loss: 165.3943\n",
            "Epoch [10/50] - Batch loss: 166.2424 - Epoch Loss: 53423.1947 - Avg Loss: 165.3969\n",
            "Epoch [10/50] - Batch loss: 159.1717 - Epoch Loss: 53582.3665 - Avg Loss: 165.3777\n",
            "Epoch [10/50] - Batch loss: 164.8244 - Epoch Loss: 53747.1909 - Avg Loss: 165.3760\n",
            "Epoch [10/50] - Batch loss: 157.4629 - Epoch Loss: 53904.6538 - Avg Loss: 165.3517\n",
            "Epoch [10/50] - Batch loss: 162.8803 - Epoch Loss: 54067.5341 - Avg Loss: 165.3441\n",
            "Epoch [10/50] - Batch loss: 157.7610 - Epoch Loss: 54225.2951 - Avg Loss: 165.3210\n",
            "Epoch [10/50] - Batch loss: 170.7568 - Epoch Loss: 54396.0519 - Avg Loss: 165.3375\n",
            "Epoch [10/50] - Batch loss: 164.1335 - Epoch Loss: 54560.1854 - Avg Loss: 165.3339\n",
            "Epoch [10/50] - Batch loss: 159.7555 - Epoch Loss: 54719.9409 - Avg Loss: 165.3170\n",
            "Epoch [10/50] - Batch loss: 174.1008 - Epoch Loss: 54894.0416 - Avg Loss: 165.3435\n",
            "Epoch [10/50] - Batch loss: 160.3528 - Epoch Loss: 55054.3944 - Avg Loss: 165.3285\n",
            "Epoch [10/50] - Batch loss: 166.2805 - Epoch Loss: 55220.6749 - Avg Loss: 165.3314\n",
            "Epoch [10/50] - Batch loss: 166.5263 - Epoch Loss: 55387.2012 - Avg Loss: 165.3349\n",
            "Epoch [10/50] - Batch loss: 165.9292 - Epoch Loss: 55553.1304 - Avg Loss: 165.3367\n",
            "Epoch [10/50] - Batch loss: 155.6667 - Epoch Loss: 55708.7971 - Avg Loss: 165.3080\n",
            "Epoch [10/50] - Batch loss: 162.9795 - Epoch Loss: 55871.7765 - Avg Loss: 165.3011\n",
            "Epoch [10/50] - Batch loss: 162.3363 - Epoch Loss: 56034.1128 - Avg Loss: 165.2924\n",
            "Epoch [10/50] - Batch loss: 172.4250 - Epoch Loss: 56206.5378 - Avg Loss: 165.3133\n",
            "Epoch [10/50] - Batch loss: 166.3780 - Epoch Loss: 56372.9158 - Avg Loss: 165.3165\n",
            "Epoch [10/50] - Batch loss: 165.2403 - Epoch Loss: 56538.1561 - Avg Loss: 165.3162\n",
            "Epoch [10/50] - Batch loss: 164.8138 - Epoch Loss: 56702.9699 - Avg Loss: 165.3148\n",
            "Epoch [10/50] - Batch loss: 165.1126 - Epoch Loss: 56868.0825 - Avg Loss: 165.3142\n",
            "Epoch [10/50] - Batch loss: 164.7381 - Epoch Loss: 57032.8206 - Avg Loss: 165.3125\n",
            "Epoch [10/50] - Batch loss: 157.0338 - Epoch Loss: 57189.8543 - Avg Loss: 165.2886\n",
            "Epoch [10/50] - Batch loss: 168.4168 - Epoch Loss: 57358.2711 - Avg Loss: 165.2976\n",
            "Epoch [10/50] - Batch loss: 165.6097 - Epoch Loss: 57523.8808 - Avg Loss: 165.2985\n",
            "Epoch [10/50] - Batch loss: 168.9888 - Epoch Loss: 57692.8696 - Avg Loss: 165.3091\n",
            "Epoch [10/50] - Batch loss: 164.3912 - Epoch Loss: 57857.2608 - Avg Loss: 165.3065\n",
            "Epoch [10/50] - Batch loss: 163.9152 - Epoch Loss: 58021.1760 - Avg Loss: 165.3025\n",
            "Epoch [10/50] - Batch loss: 158.2217 - Epoch Loss: 58179.3977 - Avg Loss: 165.2824\n",
            "Epoch [10/50] - Batch loss: 168.6607 - Epoch Loss: 58348.0585 - Avg Loss: 165.2920\n",
            "Epoch [10/50] - Batch loss: 165.7975 - Epoch Loss: 58513.8560 - Avg Loss: 165.2934\n",
            "Epoch [10/50] - Batch loss: 168.9316 - Epoch Loss: 58682.7876 - Avg Loss: 165.3036\n",
            "Epoch [10/50] - Batch loss: 169.9539 - Epoch Loss: 58852.7415 - Avg Loss: 165.3167\n",
            "Epoch [10/50] - Batch loss: 163.4805 - Epoch Loss: 59016.2220 - Avg Loss: 165.3115\n",
            "Epoch [10/50] - Batch loss: 169.9106 - Epoch Loss: 59186.1326 - Avg Loss: 165.3244\n",
            "Epoch [10/50] - Batch loss: 165.0401 - Epoch Loss: 59351.1727 - Avg Loss: 165.3236\n",
            "Epoch [10/50] - Batch loss: 167.7315 - Epoch Loss: 59518.9042 - Avg Loss: 165.3303\n",
            "Epoch [10/50] - Batch loss: 157.9537 - Epoch Loss: 59676.8579 - Avg Loss: 165.3099\n",
            "Epoch [10/50] - Batch loss: 165.8224 - Epoch Loss: 59842.6802 - Avg Loss: 165.3113\n",
            "Epoch [10/50] - Batch loss: 165.7320 - Epoch Loss: 60008.4123 - Avg Loss: 165.3124\n",
            "Epoch [10/50] - Batch loss: 165.9357 - Epoch Loss: 60174.3480 - Avg Loss: 165.3141\n",
            "Epoch [10/50] - Batch loss: 163.6368 - Epoch Loss: 60337.9848 - Avg Loss: 165.3095\n",
            "Epoch [10/50] - Batch loss: 171.4370 - Epoch Loss: 60509.4217 - Avg Loss: 165.3263\n",
            "Epoch [10/50] - Batch loss: 164.5055 - Epoch Loss: 60673.9272 - Avg Loss: 165.3241\n",
            "Epoch [10/50] - Batch loss: 159.8594 - Epoch Loss: 60833.7866 - Avg Loss: 165.3092\n",
            "Epoch [10/50] - Batch loss: 169.6312 - Epoch Loss: 61003.4178 - Avg Loss: 165.3209\n",
            "Epoch [10/50] - Batch loss: 156.7562 - Epoch Loss: 61160.1740 - Avg Loss: 165.2978\n",
            "Epoch [10/50] - Batch loss: 152.3629 - Epoch Loss: 61312.5369 - Avg Loss: 165.2629\n",
            "Epoch [10/50] - Batch loss: 165.7119 - Epoch Loss: 61478.2488 - Avg Loss: 165.2641\n",
            "Epoch [10/50] - Batch loss: 165.7925 - Epoch Loss: 61644.0413 - Avg Loss: 165.2655\n",
            "Epoch [10/50] - Batch loss: 160.9392 - Epoch Loss: 61804.9805 - Avg Loss: 165.2540\n",
            "Epoch [10/50] - Batch loss: 166.8017 - Epoch Loss: 61971.7822 - Avg Loss: 165.2581\n",
            "Epoch [10/50] - Batch loss: 171.1534 - Epoch Loss: 62142.9355 - Avg Loss: 165.2738\n",
            "Epoch [10/50] - Batch loss: 161.7948 - Epoch Loss: 62304.7303 - Avg Loss: 165.2645\n",
            "Epoch [10/50] - Batch loss: 158.5297 - Epoch Loss: 62463.2600 - Avg Loss: 165.2467\n",
            "Epoch [10/50] - Batch loss: 167.1134 - Epoch Loss: 62630.3734 - Avg Loss: 165.2516\n",
            "Epoch [10/50] - Batch loss: 155.6152 - Epoch Loss: 62785.9886 - Avg Loss: 165.2263\n",
            "Epoch [10/50] - Batch loss: 166.5745 - Epoch Loss: 62952.5632 - Avg Loss: 165.2298\n",
            "Epoch [10/50] - Batch loss: 162.5688 - Epoch Loss: 63115.1319 - Avg Loss: 165.2229\n",
            "Epoch [10/50] - Batch loss: 159.8155 - Epoch Loss: 63274.9474 - Avg Loss: 165.2087\n",
            "Epoch [10/50] - Batch loss: 168.2179 - Epoch Loss: 63443.1654 - Avg Loss: 165.2166\n",
            "Epoch [10/50] - Batch loss: 167.7611 - Epoch Loss: 63610.9264 - Avg Loss: 165.2232\n",
            "Epoch [10/50] - Batch loss: 165.0910 - Epoch Loss: 63776.0175 - Avg Loss: 165.2228\n",
            "Epoch [10/50] - Batch loss: 158.3862 - Epoch Loss: 63934.4037 - Avg Loss: 165.2052\n",
            "Epoch [10/50] - Batch loss: 158.1021 - Epoch Loss: 64092.5058 - Avg Loss: 165.1869\n",
            "Epoch [10/50] - Batch loss: 166.9032 - Epoch Loss: 64259.4089 - Avg Loss: 165.1913\n",
            "Epoch [10/50] - Batch loss: 167.9236 - Epoch Loss: 64427.3325 - Avg Loss: 165.1983\n",
            "Epoch [10/50] - Batch loss: 167.4740 - Epoch Loss: 64594.8066 - Avg Loss: 165.2041\n",
            "Epoch [10/50] - Batch loss: 162.9920 - Epoch Loss: 64757.7986 - Avg Loss: 165.1985\n",
            "Epoch [10/50] - Batch loss: 165.5507 - Epoch Loss: 64923.3493 - Avg Loss: 165.1994\n",
            "Epoch [10/50] - Batch loss: 157.3280 - Epoch Loss: 65080.6773 - Avg Loss: 165.1794\n",
            "Epoch [10/50] - Batch loss: 160.3674 - Epoch Loss: 65241.0447 - Avg Loss: 165.1672\n",
            "Epoch [10/50] - Batch loss: 165.4473 - Epoch Loss: 65406.4920 - Avg Loss: 165.1679\n",
            "Epoch [10/50] - Batch loss: 160.8895 - Epoch Loss: 65567.3815 - Avg Loss: 165.1571\n",
            "Epoch [10/50] - Batch loss: 162.4355 - Epoch Loss: 65729.8170 - Avg Loss: 165.1503\n",
            "Epoch [10/50] - Batch loss: 162.6329 - Epoch Loss: 65892.4498 - Avg Loss: 165.1440\n",
            "Epoch [10/50] - Batch loss: 165.3975 - Epoch Loss: 66057.8474 - Avg Loss: 165.1446\n",
            "Epoch [10/50] - Batch loss: 158.5714 - Epoch Loss: 66216.4187 - Avg Loss: 165.1282\n",
            "Epoch [10/50] - Batch loss: 167.3346 - Epoch Loss: 66383.7533 - Avg Loss: 165.1337\n",
            "Epoch [10/50] - Batch loss: 165.6308 - Epoch Loss: 66549.3841 - Avg Loss: 165.1349\n",
            "Epoch [10/50] - Batch loss: 161.8688 - Epoch Loss: 66711.2529 - Avg Loss: 165.1269\n",
            "Epoch [10/50] - Batch loss: 167.0026 - Epoch Loss: 66878.2555 - Avg Loss: 165.1315\n",
            "Epoch [10/50] - Batch loss: 160.6600 - Epoch Loss: 67038.9155 - Avg Loss: 165.1205\n",
            "Epoch [10/50] - Batch loss: 163.3925 - Epoch Loss: 67202.3079 - Avg Loss: 165.1162\n",
            "Epoch [10/50] - Batch loss: 162.5558 - Epoch Loss: 67364.8638 - Avg Loss: 165.1100\n",
            "Epoch [10/50] - Batch loss: 165.7915 - Epoch Loss: 67530.6553 - Avg Loss: 165.1116\n",
            "Epoch [10/50] - Batch loss: 163.9146 - Epoch Loss: 67694.5699 - Avg Loss: 165.1087\n",
            "Epoch [10/50] - Batch loss: 159.0364 - Epoch Loss: 67853.6063 - Avg Loss: 165.0939\n",
            "Epoch [10/50] - Batch loss: 153.0934 - Epoch Loss: 68006.6996 - Avg Loss: 165.0648\n",
            "Epoch [10/50] - Batch loss: 163.0719 - Epoch Loss: 68169.7715 - Avg Loss: 165.0600\n",
            "Epoch [10/50] - Batch loss: 162.4032 - Epoch Loss: 68332.1747 - Avg Loss: 165.0536\n",
            "Epoch [10/50] - Batch loss: 158.1520 - Epoch Loss: 68490.3267 - Avg Loss: 165.0369\n",
            "Epoch [10/50] - Batch loss: 166.2495 - Epoch Loss: 68656.5761 - Avg Loss: 165.0398\n",
            "Epoch [10/50] - Batch loss: 164.1014 - Epoch Loss: 68820.6775 - Avg Loss: 165.0376\n",
            "Epoch [10/50] - Batch loss: 163.9226 - Epoch Loss: 68984.6001 - Avg Loss: 165.0349\n",
            "Epoch [10/50] - Batch loss: 166.0022 - Epoch Loss: 69150.6023 - Avg Loss: 165.0372\n",
            "Epoch [10/50] - Batch loss: 165.3075 - Epoch Loss: 69315.9097 - Avg Loss: 165.0379\n",
            "Epoch [10/50] - Batch loss: 170.9270 - Epoch Loss: 69486.8367 - Avg Loss: 165.0519\n",
            "Epoch [10/50] - Batch loss: 153.4284 - Epoch Loss: 69640.2651 - Avg Loss: 165.0243\n",
            "Epoch [10/50] - Batch loss: 163.3239 - Epoch Loss: 69803.5890 - Avg Loss: 165.0203\n",
            "Epoch [10/50] - Batch loss: 158.0006 - Epoch Loss: 69961.5896 - Avg Loss: 165.0037\n",
            "Epoch [10/50] - Batch loss: 173.9660 - Epoch Loss: 70135.5556 - Avg Loss: 165.0248\n",
            "Epoch [10/50] - Batch loss: 169.2028 - Epoch Loss: 70304.7584 - Avg Loss: 165.0346\n",
            "Epoch [10/50] - Batch loss: 162.5732 - Epoch Loss: 70467.3315 - Avg Loss: 165.0289\n",
            "Epoch [10/50] - Batch loss: 166.1150 - Epoch Loss: 70633.4465 - Avg Loss: 165.0314\n",
            "Epoch [10/50] - Batch loss: 155.0354 - Epoch Loss: 70788.4819 - Avg Loss: 165.0081\n",
            "Epoch [10/50] - Batch loss: 170.3997 - Epoch Loss: 70958.8816 - Avg Loss: 165.0207\n",
            "Epoch [10/50] - Batch loss: 172.4119 - Epoch Loss: 71131.2935 - Avg Loss: 165.0378\n",
            "Epoch [10/50] - Batch loss: 159.2419 - Epoch Loss: 71290.5354 - Avg Loss: 165.0244\n",
            "Epoch [10/50] - Batch loss: 161.9968 - Epoch Loss: 71452.5322 - Avg Loss: 165.0174\n",
            "Epoch [10/50] - Batch loss: 157.2413 - Epoch Loss: 71609.7735 - Avg Loss: 164.9995\n",
            "Epoch [10/50] - Batch loss: 165.8392 - Epoch Loss: 71775.6127 - Avg Loss: 165.0014\n",
            "Epoch [10/50] - Batch loss: 163.9129 - Epoch Loss: 71939.5256 - Avg Loss: 164.9989\n",
            "Epoch [10/50] - Batch loss: 164.0538 - Epoch Loss: 72103.5794 - Avg Loss: 164.9967\n",
            "Epoch [10/50] - Batch loss: 168.9642 - Epoch Loss: 72272.5436 - Avg Loss: 165.0058\n",
            "Epoch [10/50] - Batch loss: 164.0351 - Epoch Loss: 72436.5787 - Avg Loss: 165.0036\n",
            "Epoch [10/50] - Batch loss: 167.0160 - Epoch Loss: 72603.5947 - Avg Loss: 165.0082\n",
            "Epoch [10/50] - Batch loss: 159.3842 - Epoch Loss: 72762.9789 - Avg Loss: 164.9954\n",
            "Epoch [10/50] - Batch loss: 167.4865 - Epoch Loss: 72930.4654 - Avg Loss: 165.0011\n",
            "Epoch [10/50] - Batch loss: 164.9282 - Epoch Loss: 73095.3936 - Avg Loss: 165.0009\n",
            "Epoch [10/50] - Batch loss: 152.3414 - Epoch Loss: 73247.7350 - Avg Loss: 164.9724\n",
            "Epoch [10/50] - Batch loss: 161.3873 - Epoch Loss: 73409.1223 - Avg Loss: 164.9643\n",
            "Epoch [10/50] - Batch loss: 162.2815 - Epoch Loss: 73571.4038 - Avg Loss: 164.9583\n",
            "Epoch [10/50] - Batch loss: 158.4796 - Epoch Loss: 73729.8835 - Avg Loss: 164.9438\n",
            "Epoch [10/50] - Batch loss: 166.9803 - Epoch Loss: 73896.8638 - Avg Loss: 164.9484\n",
            "Epoch [10/50] - Batch loss: 166.5195 - Epoch Loss: 74063.3833 - Avg Loss: 164.9519\n",
            "Epoch [10/50] - Batch loss: 161.3252 - Epoch Loss: 74224.7085 - Avg Loss: 164.9438\n",
            "Epoch [10/50] - Batch loss: 161.9294 - Epoch Loss: 74386.6379 - Avg Loss: 164.9371\n",
            "Epoch [10/50] - Batch loss: 159.5937 - Epoch Loss: 74546.2316 - Avg Loss: 164.9253\n",
            "Epoch [10/50] - Batch loss: 167.9072 - Epoch Loss: 74714.1388 - Avg Loss: 164.9319\n",
            "Epoch [10/50] - Batch loss: 168.3207 - Epoch Loss: 74882.4595 - Avg Loss: 164.9393\n",
            "Epoch [10/50] - Batch loss: 165.8489 - Epoch Loss: 75048.3084 - Avg Loss: 164.9413\n",
            "Epoch [10/50] - Batch loss: 156.9480 - Epoch Loss: 75205.2564 - Avg Loss: 164.9238\n",
            "Epoch [10/50] - Batch loss: 160.2035 - Epoch Loss: 75365.4599 - Avg Loss: 164.9135\n",
            "Epoch [10/50] - Batch loss: 166.6950 - Epoch Loss: 75532.1549 - Avg Loss: 164.9174\n",
            "Epoch [10/50] - Batch loss: 163.5458 - Epoch Loss: 75695.7006 - Avg Loss: 164.9144\n",
            "Epoch [10/50] - Batch loss: 162.6976 - Epoch Loss: 75858.3982 - Avg Loss: 164.9096\n",
            "Epoch [10/50] - Batch loss: 167.0987 - Epoch Loss: 76025.4969 - Avg Loss: 164.9143\n",
            "Epoch [10/50] - Batch loss: 168.5038 - Epoch Loss: 76194.0007 - Avg Loss: 164.9221\n",
            "Epoch [10/50] - Batch loss: 166.1539 - Epoch Loss: 76360.1546 - Avg Loss: 164.9247\n",
            "Epoch [10/50] - Batch loss: 169.5711 - Epoch Loss: 76529.7257 - Avg Loss: 164.9348\n",
            "Epoch [10/50] - Batch loss: 164.1002 - Epoch Loss: 76693.8259 - Avg Loss: 164.9330\n",
            "Epoch [10/50] - Batch loss: 166.8973 - Epoch Loss: 76860.7232 - Avg Loss: 164.9372\n",
            "Epoch [10/50] - Batch loss: 160.4980 - Epoch Loss: 77021.2212 - Avg Loss: 164.9277\n",
            "Epoch [10/50] - Batch loss: 162.3473 - Epoch Loss: 77183.5685 - Avg Loss: 164.9222\n",
            "Epoch [10/50] - Batch loss: 165.2122 - Epoch Loss: 77348.7807 - Avg Loss: 164.9228\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 11/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c4a4cc2645a42008f0c7cb2a70e83d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/50] - Batch loss: 168.6880 - Epoch Loss: 168.6880 - Avg Loss: 168.6880\n",
            "Epoch [11/50] - Batch loss: 175.6990 - Epoch Loss: 344.3870 - Avg Loss: 172.1935\n",
            "Epoch [11/50] - Batch loss: 167.7534 - Epoch Loss: 512.1404 - Avg Loss: 170.7135\n",
            "Epoch [11/50] - Batch loss: 168.5034 - Epoch Loss: 680.6438 - Avg Loss: 170.1609\n",
            "Epoch [11/50] - Batch loss: 162.2774 - Epoch Loss: 842.9212 - Avg Loss: 168.5842\n",
            "Epoch [11/50] - Batch loss: 164.2499 - Epoch Loss: 1007.1711 - Avg Loss: 167.8618\n",
            "Epoch [11/50] - Batch loss: 167.5264 - Epoch Loss: 1174.6975 - Avg Loss: 167.8139\n",
            "Epoch [11/50] - Batch loss: 159.4476 - Epoch Loss: 1334.1451 - Avg Loss: 166.7681\n",
            "Epoch [11/50] - Batch loss: 164.1190 - Epoch Loss: 1498.2641 - Avg Loss: 166.4738\n",
            "Epoch [11/50] - Batch loss: 165.7340 - Epoch Loss: 1663.9981 - Avg Loss: 166.3998\n",
            "Epoch [11/50] - Batch loss: 153.4304 - Epoch Loss: 1817.4285 - Avg Loss: 165.2208\n",
            "Epoch [11/50] - Batch loss: 165.9400 - Epoch Loss: 1983.3685 - Avg Loss: 165.2807\n",
            "Epoch [11/50] - Batch loss: 165.4771 - Epoch Loss: 2148.8456 - Avg Loss: 165.2958\n",
            "Epoch [11/50] - Batch loss: 161.1618 - Epoch Loss: 2310.0074 - Avg Loss: 165.0005\n",
            "Epoch [11/50] - Batch loss: 163.8415 - Epoch Loss: 2473.8489 - Avg Loss: 164.9233\n",
            "Epoch [11/50] - Batch loss: 166.7126 - Epoch Loss: 2640.5615 - Avg Loss: 165.0351\n",
            "Epoch [11/50] - Batch loss: 165.3697 - Epoch Loss: 2805.9312 - Avg Loss: 165.0548\n",
            "Epoch [11/50] - Batch loss: 160.1535 - Epoch Loss: 2966.0846 - Avg Loss: 164.7825\n",
            "Epoch [11/50] - Batch loss: 161.3177 - Epoch Loss: 3127.4024 - Avg Loss: 164.6001\n",
            "Epoch [11/50] - Batch loss: 164.1497 - Epoch Loss: 3291.5520 - Avg Loss: 164.5776\n",
            "Epoch [11/50] - Batch loss: 162.4918 - Epoch Loss: 3454.0438 - Avg Loss: 164.4783\n",
            "Epoch [11/50] - Batch loss: 171.5596 - Epoch Loss: 3625.6034 - Avg Loss: 164.8002\n",
            "Epoch [11/50] - Batch loss: 158.4368 - Epoch Loss: 3784.0403 - Avg Loss: 164.5235\n",
            "Epoch [11/50] - Batch loss: 162.4544 - Epoch Loss: 3946.4947 - Avg Loss: 164.4373\n",
            "Epoch [11/50] - Batch loss: 164.2185 - Epoch Loss: 4110.7131 - Avg Loss: 164.4285\n",
            "Epoch [11/50] - Batch loss: 153.4402 - Epoch Loss: 4264.1534 - Avg Loss: 164.0059\n",
            "Epoch [11/50] - Batch loss: 164.4419 - Epoch Loss: 4428.5953 - Avg Loss: 164.0220\n",
            "Epoch [11/50] - Batch loss: 163.2079 - Epoch Loss: 4591.8032 - Avg Loss: 163.9930\n",
            "Epoch [11/50] - Batch loss: 165.5995 - Epoch Loss: 4757.4027 - Avg Loss: 164.0484\n",
            "Epoch [11/50] - Batch loss: 165.9482 - Epoch Loss: 4923.3510 - Avg Loss: 164.1117\n",
            "Epoch [11/50] - Batch loss: 163.7587 - Epoch Loss: 5087.1097 - Avg Loss: 164.1003\n",
            "Epoch [11/50] - Batch loss: 165.0958 - Epoch Loss: 5252.2055 - Avg Loss: 164.1314\n",
            "Epoch [11/50] - Batch loss: 162.1139 - Epoch Loss: 5414.3193 - Avg Loss: 164.0703\n",
            "Epoch [11/50] - Batch loss: 169.0245 - Epoch Loss: 5583.3439 - Avg Loss: 164.2160\n",
            "Epoch [11/50] - Batch loss: 168.4680 - Epoch Loss: 5751.8118 - Avg Loss: 164.3375\n",
            "Epoch [11/50] - Batch loss: 161.9458 - Epoch Loss: 5913.7576 - Avg Loss: 164.2710\n",
            "Epoch [11/50] - Batch loss: 168.1009 - Epoch Loss: 6081.8585 - Avg Loss: 164.3746\n",
            "Epoch [11/50] - Batch loss: 161.7468 - Epoch Loss: 6243.6053 - Avg Loss: 164.3054\n",
            "Epoch [11/50] - Batch loss: 156.1670 - Epoch Loss: 6399.7723 - Avg Loss: 164.0967\n",
            "Epoch [11/50] - Batch loss: 163.7612 - Epoch Loss: 6563.5335 - Avg Loss: 164.0883\n",
            "Epoch [11/50] - Batch loss: 158.7383 - Epoch Loss: 6722.2717 - Avg Loss: 163.9578\n",
            "Epoch [11/50] - Batch loss: 158.4935 - Epoch Loss: 6880.7653 - Avg Loss: 163.8277\n",
            "Epoch [11/50] - Batch loss: 157.3453 - Epoch Loss: 7038.1106 - Avg Loss: 163.6770\n",
            "Epoch [11/50] - Batch loss: 166.5637 - Epoch Loss: 7204.6743 - Avg Loss: 163.7426\n",
            "Epoch [11/50] - Batch loss: 162.8242 - Epoch Loss: 7367.4984 - Avg Loss: 163.7222\n",
            "Epoch [11/50] - Batch loss: 162.5770 - Epoch Loss: 7530.0754 - Avg Loss: 163.6973\n",
            "Epoch [11/50] - Batch loss: 173.1747 - Epoch Loss: 7703.2502 - Avg Loss: 163.8989\n",
            "Epoch [11/50] - Batch loss: 163.2729 - Epoch Loss: 7866.5231 - Avg Loss: 163.8859\n",
            "Epoch [11/50] - Batch loss: 159.9036 - Epoch Loss: 8026.4267 - Avg Loss: 163.8046\n",
            "Epoch [11/50] - Batch loss: 165.4067 - Epoch Loss: 8191.8334 - Avg Loss: 163.8367\n",
            "Epoch [11/50] - Batch loss: 155.4514 - Epoch Loss: 8347.2848 - Avg Loss: 163.6723\n",
            "Epoch [11/50] - Batch loss: 160.1582 - Epoch Loss: 8507.4430 - Avg Loss: 163.6047\n",
            "Epoch [11/50] - Batch loss: 163.7628 - Epoch Loss: 8671.2058 - Avg Loss: 163.6077\n",
            "Epoch [11/50] - Batch loss: 161.0006 - Epoch Loss: 8832.2064 - Avg Loss: 163.5594\n",
            "Epoch [11/50] - Batch loss: 161.6048 - Epoch Loss: 8993.8112 - Avg Loss: 163.5238\n",
            "Epoch [11/50] - Batch loss: 161.8258 - Epoch Loss: 9155.6370 - Avg Loss: 163.4935\n",
            "Epoch [11/50] - Batch loss: 165.8637 - Epoch Loss: 9321.5007 - Avg Loss: 163.5351\n",
            "Epoch [11/50] - Batch loss: 164.6060 - Epoch Loss: 9486.1067 - Avg Loss: 163.5536\n",
            "Epoch [11/50] - Batch loss: 154.3046 - Epoch Loss: 9640.4112 - Avg Loss: 163.3968\n",
            "Epoch [11/50] - Batch loss: 163.7670 - Epoch Loss: 9804.1782 - Avg Loss: 163.4030\n",
            "Epoch [11/50] - Batch loss: 161.8710 - Epoch Loss: 9966.0493 - Avg Loss: 163.3779\n",
            "Epoch [11/50] - Batch loss: 162.5977 - Epoch Loss: 10128.6469 - Avg Loss: 163.3653\n",
            "Epoch [11/50] - Batch loss: 164.8473 - Epoch Loss: 10293.4943 - Avg Loss: 163.3888\n",
            "Epoch [11/50] - Batch loss: 160.6538 - Epoch Loss: 10454.1481 - Avg Loss: 163.3461\n",
            "Epoch [11/50] - Batch loss: 154.7411 - Epoch Loss: 10608.8892 - Avg Loss: 163.2137\n",
            "Epoch [11/50] - Batch loss: 166.6953 - Epoch Loss: 10775.5845 - Avg Loss: 163.2664\n",
            "Epoch [11/50] - Batch loss: 165.6313 - Epoch Loss: 10941.2159 - Avg Loss: 163.3017\n",
            "Epoch [11/50] - Batch loss: 165.0893 - Epoch Loss: 11106.3052 - Avg Loss: 163.3280\n",
            "Epoch [11/50] - Batch loss: 160.4278 - Epoch Loss: 11266.7330 - Avg Loss: 163.2860\n",
            "Epoch [11/50] - Batch loss: 165.7552 - Epoch Loss: 11432.4881 - Avg Loss: 163.3213\n",
            "Epoch [11/50] - Batch loss: 160.4493 - Epoch Loss: 11592.9374 - Avg Loss: 163.2808\n",
            "Epoch [11/50] - Batch loss: 171.6411 - Epoch Loss: 11764.5786 - Avg Loss: 163.3969\n",
            "Epoch [11/50] - Batch loss: 168.4377 - Epoch Loss: 11933.0163 - Avg Loss: 163.4660\n",
            "Epoch [11/50] - Batch loss: 160.9800 - Epoch Loss: 12093.9963 - Avg Loss: 163.4324\n",
            "Epoch [11/50] - Batch loss: 160.5819 - Epoch Loss: 12254.5782 - Avg Loss: 163.3944\n",
            "Epoch [11/50] - Batch loss: 164.2283 - Epoch Loss: 12418.8065 - Avg Loss: 163.4053\n",
            "Epoch [11/50] - Batch loss: 156.2346 - Epoch Loss: 12575.0411 - Avg Loss: 163.3122\n",
            "Epoch [11/50] - Batch loss: 165.1122 - Epoch Loss: 12740.1533 - Avg Loss: 163.3353\n",
            "Epoch [11/50] - Batch loss: 167.7985 - Epoch Loss: 12907.9518 - Avg Loss: 163.3918\n",
            "Epoch [11/50] - Batch loss: 167.1078 - Epoch Loss: 13075.0597 - Avg Loss: 163.4382\n",
            "Epoch [11/50] - Batch loss: 170.5492 - Epoch Loss: 13245.6089 - Avg Loss: 163.5260\n",
            "Epoch [11/50] - Batch loss: 167.7742 - Epoch Loss: 13413.3831 - Avg Loss: 163.5778\n",
            "Epoch [11/50] - Batch loss: 172.9039 - Epoch Loss: 13586.2870 - Avg Loss: 163.6902\n",
            "Epoch [11/50] - Batch loss: 170.6402 - Epoch Loss: 13756.9271 - Avg Loss: 163.7729\n",
            "Epoch [11/50] - Batch loss: 168.5334 - Epoch Loss: 13925.4606 - Avg Loss: 163.8289\n",
            "Epoch [11/50] - Batch loss: 169.3056 - Epoch Loss: 14094.7662 - Avg Loss: 163.8926\n",
            "Epoch [11/50] - Batch loss: 166.5585 - Epoch Loss: 14261.3247 - Avg Loss: 163.9233\n",
            "Epoch [11/50] - Batch loss: 160.4321 - Epoch Loss: 14421.7568 - Avg Loss: 163.8836\n",
            "Epoch [11/50] - Batch loss: 156.2786 - Epoch Loss: 14578.0354 - Avg Loss: 163.7982\n",
            "Epoch [11/50] - Batch loss: 151.2862 - Epoch Loss: 14729.3216 - Avg Loss: 163.6591\n",
            "Epoch [11/50] - Batch loss: 158.7938 - Epoch Loss: 14888.1154 - Avg Loss: 163.6057\n",
            "Epoch [11/50] - Batch loss: 155.9042 - Epoch Loss: 15044.0196 - Avg Loss: 163.5220\n",
            "Epoch [11/50] - Batch loss: 161.7942 - Epoch Loss: 15205.8138 - Avg Loss: 163.5034\n",
            "Epoch [11/50] - Batch loss: 147.7657 - Epoch Loss: 15353.5795 - Avg Loss: 163.3360\n",
            "Epoch [11/50] - Batch loss: 161.4361 - Epoch Loss: 15515.0155 - Avg Loss: 163.3160\n",
            "Epoch [11/50] - Batch loss: 171.8165 - Epoch Loss: 15686.8320 - Avg Loss: 163.4045\n",
            "Epoch [11/50] - Batch loss: 160.2654 - Epoch Loss: 15847.0974 - Avg Loss: 163.3721\n",
            "Epoch [11/50] - Batch loss: 160.9652 - Epoch Loss: 16008.0626 - Avg Loss: 163.3476\n",
            "Epoch [11/50] - Batch loss: 170.4923 - Epoch Loss: 16178.5549 - Avg Loss: 163.4197\n",
            "Epoch [11/50] - Batch loss: 169.5147 - Epoch Loss: 16348.0696 - Avg Loss: 163.4807\n",
            "Epoch [11/50] - Batch loss: 164.8153 - Epoch Loss: 16512.8849 - Avg Loss: 163.4939\n",
            "Epoch [11/50] - Batch loss: 166.2473 - Epoch Loss: 16679.1322 - Avg Loss: 163.5209\n",
            "Epoch [11/50] - Batch loss: 166.0040 - Epoch Loss: 16845.1361 - Avg Loss: 163.5450\n",
            "Epoch [11/50] - Batch loss: 164.1873 - Epoch Loss: 17009.3234 - Avg Loss: 163.5512\n",
            "Epoch [11/50] - Batch loss: 170.7029 - Epoch Loss: 17180.0263 - Avg Loss: 163.6193\n",
            "Epoch [11/50] - Batch loss: 170.3650 - Epoch Loss: 17350.3913 - Avg Loss: 163.6829\n",
            "Epoch [11/50] - Batch loss: 165.3157 - Epoch Loss: 17515.7070 - Avg Loss: 163.6982\n",
            "Epoch [11/50] - Batch loss: 166.8023 - Epoch Loss: 17682.5093 - Avg Loss: 163.7269\n",
            "Epoch [11/50] - Batch loss: 172.6176 - Epoch Loss: 17855.1269 - Avg Loss: 163.8085\n",
            "Epoch [11/50] - Batch loss: 164.8458 - Epoch Loss: 18019.9727 - Avg Loss: 163.8179\n",
            "Epoch [11/50] - Batch loss: 156.2087 - Epoch Loss: 18176.1813 - Avg Loss: 163.7494\n",
            "Epoch [11/50] - Batch loss: 165.9319 - Epoch Loss: 18342.1133 - Avg Loss: 163.7689\n",
            "Epoch [11/50] - Batch loss: 174.5494 - Epoch Loss: 18516.6627 - Avg Loss: 163.8643\n",
            "Epoch [11/50] - Batch loss: 163.2053 - Epoch Loss: 18679.8680 - Avg Loss: 163.8585\n",
            "Epoch [11/50] - Batch loss: 165.6297 - Epoch Loss: 18845.4977 - Avg Loss: 163.8739\n",
            "Epoch [11/50] - Batch loss: 164.0416 - Epoch Loss: 19009.5394 - Avg Loss: 163.8753\n",
            "Epoch [11/50] - Batch loss: 163.8277 - Epoch Loss: 19173.3671 - Avg Loss: 163.8749\n",
            "Epoch [11/50] - Batch loss: 163.2215 - Epoch Loss: 19336.5885 - Avg Loss: 163.8694\n",
            "Epoch [11/50] - Batch loss: 163.4382 - Epoch Loss: 19500.0267 - Avg Loss: 163.8658\n",
            "Epoch [11/50] - Batch loss: 164.6565 - Epoch Loss: 19664.6832 - Avg Loss: 163.8724\n",
            "Epoch [11/50] - Batch loss: 161.2666 - Epoch Loss: 19825.9498 - Avg Loss: 163.8508\n",
            "Epoch [11/50] - Batch loss: 161.9820 - Epoch Loss: 19987.9317 - Avg Loss: 163.8355\n",
            "Epoch [11/50] - Batch loss: 160.1220 - Epoch Loss: 20148.0538 - Avg Loss: 163.8053\n",
            "Epoch [11/50] - Batch loss: 157.1886 - Epoch Loss: 20305.2424 - Avg Loss: 163.7520\n",
            "Epoch [11/50] - Batch loss: 163.6319 - Epoch Loss: 20468.8743 - Avg Loss: 163.7510\n",
            "Epoch [11/50] - Batch loss: 161.5263 - Epoch Loss: 20630.4005 - Avg Loss: 163.7333\n",
            "Epoch [11/50] - Batch loss: 162.8400 - Epoch Loss: 20793.2406 - Avg Loss: 163.7263\n",
            "Epoch [11/50] - Batch loss: 166.3558 - Epoch Loss: 20959.5963 - Avg Loss: 163.7468\n",
            "Epoch [11/50] - Batch loss: 160.3802 - Epoch Loss: 21119.9766 - Avg Loss: 163.7207\n",
            "Epoch [11/50] - Batch loss: 156.8078 - Epoch Loss: 21276.7844 - Avg Loss: 163.6676\n",
            "Epoch [11/50] - Batch loss: 157.0582 - Epoch Loss: 21433.8427 - Avg Loss: 163.6171\n",
            "Epoch [11/50] - Batch loss: 163.8078 - Epoch Loss: 21597.6505 - Avg Loss: 163.6186\n",
            "Epoch [11/50] - Batch loss: 164.0572 - Epoch Loss: 21761.7077 - Avg Loss: 163.6219\n",
            "Epoch [11/50] - Batch loss: 160.1534 - Epoch Loss: 21921.8611 - Avg Loss: 163.5960\n",
            "Epoch [11/50] - Batch loss: 162.1064 - Epoch Loss: 22083.9675 - Avg Loss: 163.5849\n",
            "Epoch [11/50] - Batch loss: 166.4691 - Epoch Loss: 22250.4366 - Avg Loss: 163.6062\n",
            "Epoch [11/50] - Batch loss: 161.6666 - Epoch Loss: 22412.1032 - Avg Loss: 163.5920\n",
            "Epoch [11/50] - Batch loss: 169.0997 - Epoch Loss: 22581.2028 - Avg Loss: 163.6319\n",
            "Epoch [11/50] - Batch loss: 164.4512 - Epoch Loss: 22745.6540 - Avg Loss: 163.6378\n",
            "Epoch [11/50] - Batch loss: 168.2047 - Epoch Loss: 22913.8587 - Avg Loss: 163.6704\n",
            "Epoch [11/50] - Batch loss: 169.2626 - Epoch Loss: 23083.1212 - Avg Loss: 163.7101\n",
            "Epoch [11/50] - Batch loss: 169.1845 - Epoch Loss: 23252.3058 - Avg Loss: 163.7486\n",
            "Epoch [11/50] - Batch loss: 167.3027 - Epoch Loss: 23419.6085 - Avg Loss: 163.7735\n",
            "Epoch [11/50] - Batch loss: 165.6465 - Epoch Loss: 23585.2549 - Avg Loss: 163.7865\n",
            "Epoch [11/50] - Batch loss: 168.5576 - Epoch Loss: 23753.8125 - Avg Loss: 163.8194\n",
            "Epoch [11/50] - Batch loss: 169.5486 - Epoch Loss: 23923.3611 - Avg Loss: 163.8586\n",
            "Epoch [11/50] - Batch loss: 172.0557 - Epoch Loss: 24095.4168 - Avg Loss: 163.9144\n",
            "Epoch [11/50] - Batch loss: 164.5618 - Epoch Loss: 24259.9786 - Avg Loss: 163.9188\n",
            "Epoch [11/50] - Batch loss: 168.3092 - Epoch Loss: 24428.2878 - Avg Loss: 163.9482\n",
            "Epoch [11/50] - Batch loss: 170.3075 - Epoch Loss: 24598.5953 - Avg Loss: 163.9906\n",
            "Epoch [11/50] - Batch loss: 160.8736 - Epoch Loss: 24759.4689 - Avg Loss: 163.9700\n",
            "Epoch [11/50] - Batch loss: 167.4779 - Epoch Loss: 24926.9468 - Avg Loss: 163.9931\n",
            "Epoch [11/50] - Batch loss: 171.0807 - Epoch Loss: 25098.0275 - Avg Loss: 164.0394\n",
            "Epoch [11/50] - Batch loss: 170.0260 - Epoch Loss: 25268.0535 - Avg Loss: 164.0783\n",
            "Epoch [11/50] - Batch loss: 162.9046 - Epoch Loss: 25430.9581 - Avg Loss: 164.0707\n",
            "Epoch [11/50] - Batch loss: 170.1250 - Epoch Loss: 25601.0831 - Avg Loss: 164.1095\n",
            "Epoch [11/50] - Batch loss: 166.6685 - Epoch Loss: 25767.7516 - Avg Loss: 164.1258\n",
            "Epoch [11/50] - Batch loss: 173.0692 - Epoch Loss: 25940.8208 - Avg Loss: 164.1824\n",
            "Epoch [11/50] - Batch loss: 166.6476 - Epoch Loss: 26107.4684 - Avg Loss: 164.1979\n",
            "Epoch [11/50] - Batch loss: 160.6376 - Epoch Loss: 26268.1060 - Avg Loss: 164.1757\n",
            "Epoch [11/50] - Batch loss: 164.5358 - Epoch Loss: 26432.6418 - Avg Loss: 164.1779\n",
            "Epoch [11/50] - Batch loss: 156.6833 - Epoch Loss: 26589.3252 - Avg Loss: 164.1316\n",
            "Epoch [11/50] - Batch loss: 166.9989 - Epoch Loss: 26756.3241 - Avg Loss: 164.1492\n",
            "Epoch [11/50] - Batch loss: 170.0289 - Epoch Loss: 26926.3530 - Avg Loss: 164.1851\n",
            "Epoch [11/50] - Batch loss: 164.1450 - Epoch Loss: 27090.4979 - Avg Loss: 164.1848\n",
            "Epoch [11/50] - Batch loss: 167.8163 - Epoch Loss: 27258.3143 - Avg Loss: 164.2067\n",
            "Epoch [11/50] - Batch loss: 155.5034 - Epoch Loss: 27413.8177 - Avg Loss: 164.1546\n",
            "Epoch [11/50] - Batch loss: 170.3622 - Epoch Loss: 27584.1799 - Avg Loss: 164.1915\n",
            "Epoch [11/50] - Batch loss: 160.4502 - Epoch Loss: 27744.6301 - Avg Loss: 164.1694\n",
            "Epoch [11/50] - Batch loss: 165.5143 - Epoch Loss: 27910.1444 - Avg Loss: 164.1773\n",
            "Epoch [11/50] - Batch loss: 159.3877 - Epoch Loss: 28069.5321 - Avg Loss: 164.1493\n",
            "Epoch [11/50] - Batch loss: 165.3687 - Epoch Loss: 28234.9008 - Avg Loss: 164.1564\n",
            "Epoch [11/50] - Batch loss: 172.6517 - Epoch Loss: 28407.5525 - Avg Loss: 164.2055\n",
            "Epoch [11/50] - Batch loss: 168.6031 - Epoch Loss: 28576.1556 - Avg Loss: 164.2308\n",
            "Epoch [11/50] - Batch loss: 167.9365 - Epoch Loss: 28744.0921 - Avg Loss: 164.2520\n",
            "Epoch [11/50] - Batch loss: 170.4789 - Epoch Loss: 28914.5710 - Avg Loss: 164.2873\n",
            "Epoch [11/50] - Batch loss: 161.2554 - Epoch Loss: 29075.8264 - Avg Loss: 164.2702\n",
            "Epoch [11/50] - Batch loss: 174.3941 - Epoch Loss: 29250.2205 - Avg Loss: 164.3271\n",
            "Epoch [11/50] - Batch loss: 175.3096 - Epoch Loss: 29425.5301 - Avg Loss: 164.3884\n",
            "Epoch [11/50] - Batch loss: 165.2698 - Epoch Loss: 29590.7999 - Avg Loss: 164.3933\n",
            "Epoch [11/50] - Batch loss: 156.2243 - Epoch Loss: 29747.0242 - Avg Loss: 164.3482\n",
            "Epoch [11/50] - Batch loss: 168.5889 - Epoch Loss: 29915.6131 - Avg Loss: 164.3715\n",
            "Epoch [11/50] - Batch loss: 178.6003 - Epoch Loss: 30094.2134 - Avg Loss: 164.4493\n",
            "Epoch [11/50] - Batch loss: 157.9209 - Epoch Loss: 30252.1343 - Avg Loss: 164.4138\n",
            "Epoch [11/50] - Batch loss: 167.8223 - Epoch Loss: 30419.9567 - Avg Loss: 164.4322\n",
            "Epoch [11/50] - Batch loss: 159.9575 - Epoch Loss: 30579.9141 - Avg Loss: 164.4081\n",
            "Epoch [11/50] - Batch loss: 166.1867 - Epoch Loss: 30746.1008 - Avg Loss: 164.4177\n",
            "Epoch [11/50] - Batch loss: 167.9116 - Epoch Loss: 30914.0124 - Avg Loss: 164.4362\n",
            "Epoch [11/50] - Batch loss: 170.1806 - Epoch Loss: 31084.1930 - Avg Loss: 164.4666\n",
            "Epoch [11/50] - Batch loss: 172.7564 - Epoch Loss: 31256.9494 - Avg Loss: 164.5103\n",
            "Epoch [11/50] - Batch loss: 161.9619 - Epoch Loss: 31418.9113 - Avg Loss: 164.4969\n",
            "Epoch [11/50] - Batch loss: 168.6068 - Epoch Loss: 31587.5181 - Avg Loss: 164.5183\n",
            "Epoch [11/50] - Batch loss: 162.2228 - Epoch Loss: 31749.7410 - Avg Loss: 164.5064\n",
            "Epoch [11/50] - Batch loss: 164.1989 - Epoch Loss: 31913.9399 - Avg Loss: 164.5048\n",
            "Epoch [11/50] - Batch loss: 162.6516 - Epoch Loss: 32076.5915 - Avg Loss: 164.4953\n",
            "Epoch [11/50] - Batch loss: 161.7401 - Epoch Loss: 32238.3316 - Avg Loss: 164.4813\n",
            "Epoch [11/50] - Batch loss: 163.0019 - Epoch Loss: 32401.3335 - Avg Loss: 164.4738\n",
            "Epoch [11/50] - Batch loss: 166.9828 - Epoch Loss: 32568.3163 - Avg Loss: 164.4864\n",
            "Epoch [11/50] - Batch loss: 166.2401 - Epoch Loss: 32734.5564 - Avg Loss: 164.4953\n",
            "Epoch [11/50] - Batch loss: 166.3374 - Epoch Loss: 32900.8938 - Avg Loss: 164.5045\n",
            "Epoch [11/50] - Batch loss: 161.9861 - Epoch Loss: 33062.8799 - Avg Loss: 164.4919\n",
            "Epoch [11/50] - Batch loss: 168.2645 - Epoch Loss: 33231.1445 - Avg Loss: 164.5106\n",
            "Epoch [11/50] - Batch loss: 169.0381 - Epoch Loss: 33400.1826 - Avg Loss: 164.5329\n",
            "Epoch [11/50] - Batch loss: 164.8270 - Epoch Loss: 33565.0095 - Avg Loss: 164.5344\n",
            "Epoch [11/50] - Batch loss: 169.8512 - Epoch Loss: 33734.8607 - Avg Loss: 164.5603\n",
            "Epoch [11/50] - Batch loss: 161.0726 - Epoch Loss: 33895.9333 - Avg Loss: 164.5434\n",
            "Epoch [11/50] - Batch loss: 157.6513 - Epoch Loss: 34053.5846 - Avg Loss: 164.5101\n",
            "Epoch [11/50] - Batch loss: 172.3219 - Epoch Loss: 34225.9065 - Avg Loss: 164.5476\n",
            "Epoch [11/50] - Batch loss: 169.6629 - Epoch Loss: 34395.5694 - Avg Loss: 164.5721\n",
            "Epoch [11/50] - Batch loss: 157.7048 - Epoch Loss: 34553.2742 - Avg Loss: 164.5394\n",
            "Epoch [11/50] - Batch loss: 166.0530 - Epoch Loss: 34719.3272 - Avg Loss: 164.5466\n",
            "Epoch [11/50] - Batch loss: 162.4066 - Epoch Loss: 34881.7338 - Avg Loss: 164.5365\n",
            "Epoch [11/50] - Batch loss: 165.1382 - Epoch Loss: 35046.8721 - Avg Loss: 164.5393\n",
            "Epoch [11/50] - Batch loss: 160.2983 - Epoch Loss: 35207.1704 - Avg Loss: 164.5195\n",
            "Epoch [11/50] - Batch loss: 166.5781 - Epoch Loss: 35373.7485 - Avg Loss: 164.5291\n",
            "Epoch [11/50] - Batch loss: 161.2175 - Epoch Loss: 35534.9660 - Avg Loss: 164.5137\n",
            "Epoch [11/50] - Batch loss: 164.3431 - Epoch Loss: 35699.3091 - Avg Loss: 164.5129\n",
            "Epoch [11/50] - Batch loss: 170.8189 - Epoch Loss: 35870.1280 - Avg Loss: 164.5419\n",
            "Epoch [11/50] - Batch loss: 166.7365 - Epoch Loss: 36036.8645 - Avg Loss: 164.5519\n",
            "Epoch [11/50] - Batch loss: 161.4051 - Epoch Loss: 36198.2696 - Avg Loss: 164.5376\n",
            "Epoch [11/50] - Batch loss: 174.2192 - Epoch Loss: 36372.4887 - Avg Loss: 164.5814\n",
            "Epoch [11/50] - Batch loss: 171.3821 - Epoch Loss: 36543.8708 - Avg Loss: 164.6120\n",
            "Epoch [11/50] - Batch loss: 166.6369 - Epoch Loss: 36710.5078 - Avg Loss: 164.6211\n",
            "Epoch [11/50] - Batch loss: 163.6019 - Epoch Loss: 36874.1097 - Avg Loss: 164.6166\n",
            "Epoch [11/50] - Batch loss: 170.3833 - Epoch Loss: 37044.4930 - Avg Loss: 164.6422\n",
            "Epoch [11/50] - Batch loss: 159.0366 - Epoch Loss: 37203.5295 - Avg Loss: 164.6174\n",
            "Epoch [11/50] - Batch loss: 164.7596 - Epoch Loss: 37368.2892 - Avg Loss: 164.6180\n",
            "Epoch [11/50] - Batch loss: 156.8488 - Epoch Loss: 37525.1379 - Avg Loss: 164.5839\n",
            "Epoch [11/50] - Batch loss: 173.7433 - Epoch Loss: 37698.8812 - Avg Loss: 164.6239\n",
            "Epoch [11/50] - Batch loss: 159.8913 - Epoch Loss: 37858.7725 - Avg Loss: 164.6034\n",
            "Epoch [11/50] - Batch loss: 163.3186 - Epoch Loss: 38022.0911 - Avg Loss: 164.5978\n",
            "Epoch [11/50] - Batch loss: 164.2202 - Epoch Loss: 38186.3113 - Avg Loss: 164.5962\n",
            "Epoch [11/50] - Batch loss: 162.6391 - Epoch Loss: 38348.9504 - Avg Loss: 164.5878\n",
            "Epoch [11/50] - Batch loss: 161.4775 - Epoch Loss: 38510.4279 - Avg Loss: 164.5745\n",
            "Epoch [11/50] - Batch loss: 169.6137 - Epoch Loss: 38680.0416 - Avg Loss: 164.5959\n",
            "Epoch [11/50] - Batch loss: 170.6911 - Epoch Loss: 38850.7327 - Avg Loss: 164.6217\n",
            "Epoch [11/50] - Batch loss: 159.1124 - Epoch Loss: 39009.8451 - Avg Loss: 164.5985\n",
            "Epoch [11/50] - Batch loss: 167.4685 - Epoch Loss: 39177.3136 - Avg Loss: 164.6106\n",
            "Epoch [11/50] - Batch loss: 165.5360 - Epoch Loss: 39342.8496 - Avg Loss: 164.6144\n",
            "Epoch [11/50] - Batch loss: 162.8451 - Epoch Loss: 39505.6947 - Avg Loss: 164.6071\n",
            "Epoch [11/50] - Batch loss: 159.0170 - Epoch Loss: 39664.7117 - Avg Loss: 164.5839\n",
            "Epoch [11/50] - Batch loss: 168.9771 - Epoch Loss: 39833.6888 - Avg Loss: 164.6020\n",
            "Epoch [11/50] - Batch loss: 168.5415 - Epoch Loss: 40002.2303 - Avg Loss: 164.6182\n",
            "Epoch [11/50] - Batch loss: 160.7416 - Epoch Loss: 40162.9719 - Avg Loss: 164.6023\n",
            "Epoch [11/50] - Batch loss: 160.0561 - Epoch Loss: 40323.0280 - Avg Loss: 164.5838\n",
            "Epoch [11/50] - Batch loss: 157.9268 - Epoch Loss: 40480.9548 - Avg Loss: 164.5567\n",
            "Epoch [11/50] - Batch loss: 161.8678 - Epoch Loss: 40642.8226 - Avg Loss: 164.5458\n",
            "Epoch [11/50] - Batch loss: 166.8884 - Epoch Loss: 40809.7110 - Avg Loss: 164.5553\n",
            "Epoch [11/50] - Batch loss: 163.9463 - Epoch Loss: 40973.6573 - Avg Loss: 164.5528\n",
            "Epoch [11/50] - Batch loss: 162.1469 - Epoch Loss: 41135.8042 - Avg Loss: 164.5432\n",
            "Epoch [11/50] - Batch loss: 165.2164 - Epoch Loss: 41301.0206 - Avg Loss: 164.5459\n",
            "Epoch [11/50] - Batch loss: 165.7729 - Epoch Loss: 41466.7935 - Avg Loss: 164.5508\n",
            "Epoch [11/50] - Batch loss: 164.9494 - Epoch Loss: 41631.7429 - Avg Loss: 164.5523\n",
            "Epoch [11/50] - Batch loss: 168.7870 - Epoch Loss: 41800.5299 - Avg Loss: 164.5690\n",
            "Epoch [11/50] - Batch loss: 156.3366 - Epoch Loss: 41956.8665 - Avg Loss: 164.5367\n",
            "Epoch [11/50] - Batch loss: 157.8013 - Epoch Loss: 42114.6678 - Avg Loss: 164.5104\n",
            "Epoch [11/50] - Batch loss: 160.5955 - Epoch Loss: 42275.2633 - Avg Loss: 164.4952\n",
            "Epoch [11/50] - Batch loss: 163.3153 - Epoch Loss: 42438.5787 - Avg Loss: 164.4906\n",
            "Epoch [11/50] - Batch loss: 163.2593 - Epoch Loss: 42601.8380 - Avg Loss: 164.4859\n",
            "Epoch [11/50] - Batch loss: 159.2663 - Epoch Loss: 42761.1043 - Avg Loss: 164.4658\n",
            "Epoch [11/50] - Batch loss: 168.2965 - Epoch Loss: 42929.4008 - Avg Loss: 164.4805\n",
            "Epoch [11/50] - Batch loss: 162.8446 - Epoch Loss: 43092.2454 - Avg Loss: 164.4742\n",
            "Epoch [11/50] - Batch loss: 160.9662 - Epoch Loss: 43253.2116 - Avg Loss: 164.4609\n",
            "Epoch [11/50] - Batch loss: 154.7269 - Epoch Loss: 43407.9385 - Avg Loss: 164.4240\n",
            "Epoch [11/50] - Batch loss: 168.7373 - Epoch Loss: 43576.6758 - Avg Loss: 164.4403\n",
            "Epoch [11/50] - Batch loss: 147.5272 - Epoch Loss: 43724.2029 - Avg Loss: 164.3767\n",
            "Epoch [11/50] - Batch loss: 165.3700 - Epoch Loss: 43889.5729 - Avg Loss: 164.3804\n",
            "Epoch [11/50] - Batch loss: 161.9947 - Epoch Loss: 44051.5676 - Avg Loss: 164.3715\n",
            "Epoch [11/50] - Batch loss: 156.2631 - Epoch Loss: 44207.8307 - Avg Loss: 164.3414\n",
            "Epoch [11/50] - Batch loss: 165.4855 - Epoch Loss: 44373.3163 - Avg Loss: 164.3456\n",
            "Epoch [11/50] - Batch loss: 165.0413 - Epoch Loss: 44538.3576 - Avg Loss: 164.3482\n",
            "Epoch [11/50] - Batch loss: 166.9086 - Epoch Loss: 44705.2662 - Avg Loss: 164.3576\n",
            "Epoch [11/50] - Batch loss: 162.7382 - Epoch Loss: 44868.0043 - Avg Loss: 164.3517\n",
            "Epoch [11/50] - Batch loss: 165.3209 - Epoch Loss: 45033.3253 - Avg Loss: 164.3552\n",
            "Epoch [11/50] - Batch loss: 161.5899 - Epoch Loss: 45194.9151 - Avg Loss: 164.3451\n",
            "Epoch [11/50] - Batch loss: 162.0627 - Epoch Loss: 45356.9778 - Avg Loss: 164.3369\n",
            "Epoch [11/50] - Batch loss: 162.5959 - Epoch Loss: 45519.5737 - Avg Loss: 164.3306\n",
            "Epoch [11/50] - Batch loss: 160.5845 - Epoch Loss: 45680.1582 - Avg Loss: 164.3171\n",
            "Epoch [11/50] - Batch loss: 174.0021 - Epoch Loss: 45854.1602 - Avg Loss: 164.3518\n",
            "Epoch [11/50] - Batch loss: 166.7333 - Epoch Loss: 46020.8935 - Avg Loss: 164.3603\n",
            "Epoch [11/50] - Batch loss: 157.9802 - Epoch Loss: 46178.8737 - Avg Loss: 164.3376\n",
            "Epoch [11/50] - Batch loss: 161.5810 - Epoch Loss: 46340.4547 - Avg Loss: 164.3279\n",
            "Epoch [11/50] - Batch loss: 161.2107 - Epoch Loss: 46501.6654 - Avg Loss: 164.3168\n",
            "Epoch [11/50] - Batch loss: 164.0141 - Epoch Loss: 46665.6796 - Avg Loss: 164.3158\n",
            "Epoch [11/50] - Batch loss: 153.1011 - Epoch Loss: 46818.7806 - Avg Loss: 164.2764\n",
            "Epoch [11/50] - Batch loss: 165.9605 - Epoch Loss: 46984.7411 - Avg Loss: 164.2823\n",
            "Epoch [11/50] - Batch loss: 171.3253 - Epoch Loss: 47156.0665 - Avg Loss: 164.3069\n",
            "Epoch [11/50] - Batch loss: 164.1014 - Epoch Loss: 47320.1679 - Avg Loss: 164.3061\n",
            "Epoch [11/50] - Batch loss: 164.1766 - Epoch Loss: 47484.3445 - Avg Loss: 164.3057\n",
            "Epoch [11/50] - Batch loss: 163.1348 - Epoch Loss: 47647.4793 - Avg Loss: 164.3017\n",
            "Epoch [11/50] - Batch loss: 159.6075 - Epoch Loss: 47807.0868 - Avg Loss: 164.2855\n",
            "Epoch [11/50] - Batch loss: 163.0217 - Epoch Loss: 47970.1085 - Avg Loss: 164.2812\n",
            "Epoch [11/50] - Batch loss: 165.8241 - Epoch Loss: 48135.9326 - Avg Loss: 164.2865\n",
            "Epoch [11/50] - Batch loss: 163.2205 - Epoch Loss: 48299.1531 - Avg Loss: 164.2828\n",
            "Epoch [11/50] - Batch loss: 166.6102 - Epoch Loss: 48465.7633 - Avg Loss: 164.2907\n",
            "Epoch [11/50] - Batch loss: 154.9802 - Epoch Loss: 48620.7436 - Avg Loss: 164.2593\n",
            "Epoch [11/50] - Batch loss: 160.4817 - Epoch Loss: 48781.2253 - Avg Loss: 164.2465\n",
            "Epoch [11/50] - Batch loss: 158.1266 - Epoch Loss: 48939.3519 - Avg Loss: 164.2260\n",
            "Epoch [11/50] - Batch loss: 163.2363 - Epoch Loss: 49102.5882 - Avg Loss: 164.2227\n",
            "Epoch [11/50] - Batch loss: 167.6358 - Epoch Loss: 49270.2240 - Avg Loss: 164.2341\n",
            "Epoch [11/50] - Batch loss: 166.7746 - Epoch Loss: 49436.9986 - Avg Loss: 164.2425\n",
            "Epoch [11/50] - Batch loss: 158.6478 - Epoch Loss: 49595.6464 - Avg Loss: 164.2240\n",
            "Epoch [11/50] - Batch loss: 163.1961 - Epoch Loss: 49758.8425 - Avg Loss: 164.2206\n",
            "Epoch [11/50] - Batch loss: 162.2370 - Epoch Loss: 49921.0795 - Avg Loss: 164.2141\n",
            "Epoch [11/50] - Batch loss: 171.4966 - Epoch Loss: 50092.5761 - Avg Loss: 164.2380\n",
            "Epoch [11/50] - Batch loss: 158.2622 - Epoch Loss: 50250.8383 - Avg Loss: 164.2184\n",
            "Epoch [11/50] - Batch loss: 160.0912 - Epoch Loss: 50410.9295 - Avg Loss: 164.2050\n",
            "Epoch [11/50] - Batch loss: 166.7167 - Epoch Loss: 50577.6462 - Avg Loss: 164.2131\n",
            "Epoch [11/50] - Batch loss: 168.3872 - Epoch Loss: 50746.0333 - Avg Loss: 164.2266\n",
            "Epoch [11/50] - Batch loss: 164.7288 - Epoch Loss: 50910.7621 - Avg Loss: 164.2283\n",
            "Epoch [11/50] - Batch loss: 163.8435 - Epoch Loss: 51074.6056 - Avg Loss: 164.2270\n",
            "Epoch [11/50] - Batch loss: 157.0171 - Epoch Loss: 51231.6228 - Avg Loss: 164.2039\n",
            "Epoch [11/50] - Batch loss: 164.1523 - Epoch Loss: 51395.7751 - Avg Loss: 164.2038\n",
            "Epoch [11/50] - Batch loss: 153.3751 - Epoch Loss: 51549.1502 - Avg Loss: 164.1693\n",
            "Epoch [11/50] - Batch loss: 159.4553 - Epoch Loss: 51708.6055 - Avg Loss: 164.1543\n",
            "Epoch [11/50] - Batch loss: 163.8138 - Epoch Loss: 51872.4194 - Avg Loss: 164.1532\n",
            "Epoch [11/50] - Batch loss: 163.8431 - Epoch Loss: 52036.2625 - Avg Loss: 164.1522\n",
            "Epoch [11/50] - Batch loss: 164.6708 - Epoch Loss: 52200.9333 - Avg Loss: 164.1539\n",
            "Epoch [11/50] - Batch loss: 159.3041 - Epoch Loss: 52360.2374 - Avg Loss: 164.1387\n",
            "Epoch [11/50] - Batch loss: 153.6420 - Epoch Loss: 52513.8793 - Avg Loss: 164.1059\n",
            "Epoch [11/50] - Batch loss: 162.5305 - Epoch Loss: 52676.4099 - Avg Loss: 164.1010\n",
            "Epoch [11/50] - Batch loss: 161.1258 - Epoch Loss: 52837.5356 - Avg Loss: 164.0917\n",
            "Epoch [11/50] - Batch loss: 169.0676 - Epoch Loss: 53006.6032 - Avg Loss: 164.1071\n",
            "Epoch [11/50] - Batch loss: 165.5338 - Epoch Loss: 53172.1371 - Avg Loss: 164.1115\n",
            "Epoch [11/50] - Batch loss: 158.4486 - Epoch Loss: 53330.5856 - Avg Loss: 164.0941\n",
            "Epoch [11/50] - Batch loss: 171.7705 - Epoch Loss: 53502.3562 - Avg Loss: 164.1177\n",
            "Epoch [11/50] - Batch loss: 161.8535 - Epoch Loss: 53664.2097 - Avg Loss: 164.1107\n",
            "Epoch [11/50] - Batch loss: 168.7000 - Epoch Loss: 53832.9097 - Avg Loss: 164.1247\n",
            "Epoch [11/50] - Batch loss: 158.3717 - Epoch Loss: 53991.2814 - Avg Loss: 164.1072\n",
            "Epoch [11/50] - Batch loss: 160.3786 - Epoch Loss: 54151.6600 - Avg Loss: 164.0959\n",
            "Epoch [11/50] - Batch loss: 162.0611 - Epoch Loss: 54313.7211 - Avg Loss: 164.0898\n",
            "Epoch [11/50] - Batch loss: 166.2346 - Epoch Loss: 54479.9557 - Avg Loss: 164.0963\n",
            "Epoch [11/50] - Batch loss: 163.7166 - Epoch Loss: 54643.6723 - Avg Loss: 164.0951\n",
            "Epoch [11/50] - Batch loss: 156.9585 - Epoch Loss: 54800.6308 - Avg Loss: 164.0737\n",
            "Epoch [11/50] - Batch loss: 156.3997 - Epoch Loss: 54957.0305 - Avg Loss: 164.0508\n",
            "Epoch [11/50] - Batch loss: 164.9473 - Epoch Loss: 55121.9778 - Avg Loss: 164.0535\n",
            "Epoch [11/50] - Batch loss: 159.9436 - Epoch Loss: 55281.9214 - Avg Loss: 164.0413\n",
            "Epoch [11/50] - Batch loss: 162.1308 - Epoch Loss: 55444.0522 - Avg Loss: 164.0357\n",
            "Epoch [11/50] - Batch loss: 166.8864 - Epoch Loss: 55610.9386 - Avg Loss: 164.0441\n",
            "Epoch [11/50] - Batch loss: 168.0345 - Epoch Loss: 55778.9731 - Avg Loss: 164.0558\n",
            "Epoch [11/50] - Batch loss: 161.8531 - Epoch Loss: 55940.8262 - Avg Loss: 164.0493\n",
            "Epoch [11/50] - Batch loss: 163.9222 - Epoch Loss: 56104.7483 - Avg Loss: 164.0490\n",
            "Epoch [11/50] - Batch loss: 158.0134 - Epoch Loss: 56262.7617 - Avg Loss: 164.0314\n",
            "Epoch [11/50] - Batch loss: 165.9592 - Epoch Loss: 56428.7209 - Avg Loss: 164.0370\n",
            "Epoch [11/50] - Batch loss: 165.6602 - Epoch Loss: 56594.3811 - Avg Loss: 164.0417\n",
            "Epoch [11/50] - Batch loss: 162.8683 - Epoch Loss: 56757.2494 - Avg Loss: 164.0383\n",
            "Epoch [11/50] - Batch loss: 154.5290 - Epoch Loss: 56911.7784 - Avg Loss: 164.0109\n",
            "Epoch [11/50] - Batch loss: 156.7033 - Epoch Loss: 57068.4817 - Avg Loss: 163.9899\n",
            "Epoch [11/50] - Batch loss: 168.0728 - Epoch Loss: 57236.5545 - Avg Loss: 164.0016\n",
            "Epoch [11/50] - Batch loss: 167.7278 - Epoch Loss: 57404.2823 - Avg Loss: 164.0122\n",
            "Epoch [11/50] - Batch loss: 171.7183 - Epoch Loss: 57576.0005 - Avg Loss: 164.0342\n",
            "Epoch [11/50] - Batch loss: 167.3625 - Epoch Loss: 57743.3630 - Avg Loss: 164.0436\n",
            "Epoch [11/50] - Batch loss: 167.9978 - Epoch Loss: 57911.3608 - Avg Loss: 164.0548\n",
            "Epoch [11/50] - Batch loss: 164.5172 - Epoch Loss: 58075.8781 - Avg Loss: 164.0562\n",
            "Epoch [11/50] - Batch loss: 157.5544 - Epoch Loss: 58233.4325 - Avg Loss: 164.0378\n",
            "Epoch [11/50] - Batch loss: 162.9048 - Epoch Loss: 58396.3373 - Avg Loss: 164.0347\n",
            "Epoch [11/50] - Batch loss: 167.1805 - Epoch Loss: 58563.5179 - Avg Loss: 164.0435\n",
            "Epoch [11/50] - Batch loss: 155.8427 - Epoch Loss: 58719.3606 - Avg Loss: 164.0206\n",
            "Epoch [11/50] - Batch loss: 168.8846 - Epoch Loss: 58888.2451 - Avg Loss: 164.0341\n",
            "Epoch [11/50] - Batch loss: 158.8214 - Epoch Loss: 59047.0665 - Avg Loss: 164.0196\n",
            "Epoch [11/50] - Batch loss: 160.2711 - Epoch Loss: 59207.3376 - Avg Loss: 164.0092\n",
            "Epoch [11/50] - Batch loss: 156.2019 - Epoch Loss: 59363.5395 - Avg Loss: 163.9877\n",
            "Epoch [11/50] - Batch loss: 157.7311 - Epoch Loss: 59521.2706 - Avg Loss: 163.9704\n",
            "Epoch [11/50] - Batch loss: 165.7566 - Epoch Loss: 59687.0272 - Avg Loss: 163.9753\n",
            "Epoch [11/50] - Batch loss: 155.0517 - Epoch Loss: 59842.0789 - Avg Loss: 163.9509\n",
            "Epoch [11/50] - Batch loss: 166.5505 - Epoch Loss: 60008.6294 - Avg Loss: 163.9580\n",
            "Epoch [11/50] - Batch loss: 155.6684 - Epoch Loss: 60164.2978 - Avg Loss: 163.9354\n",
            "Epoch [11/50] - Batch loss: 168.1821 - Epoch Loss: 60332.4799 - Avg Loss: 163.9470\n",
            "Epoch [11/50] - Batch loss: 165.0681 - Epoch Loss: 60497.5480 - Avg Loss: 163.9500\n",
            "Epoch [11/50] - Batch loss: 156.2307 - Epoch Loss: 60653.7786 - Avg Loss: 163.9291\n",
            "Epoch [11/50] - Batch loss: 165.2116 - Epoch Loss: 60818.9902 - Avg Loss: 163.9326\n",
            "Epoch [11/50] - Batch loss: 164.6924 - Epoch Loss: 60983.6827 - Avg Loss: 163.9346\n",
            "Epoch [11/50] - Batch loss: 161.0869 - Epoch Loss: 61144.7696 - Avg Loss: 163.9270\n",
            "Epoch [11/50] - Batch loss: 161.8854 - Epoch Loss: 61306.6550 - Avg Loss: 163.9215\n",
            "Epoch [11/50] - Batch loss: 169.3270 - Epoch Loss: 61475.9820 - Avg Loss: 163.9360\n",
            "Epoch [11/50] - Batch loss: 166.5951 - Epoch Loss: 61642.5772 - Avg Loss: 163.9430\n",
            "Epoch [11/50] - Batch loss: 170.0216 - Epoch Loss: 61812.5987 - Avg Loss: 163.9591\n",
            "Epoch [11/50] - Batch loss: 162.3088 - Epoch Loss: 61974.9075 - Avg Loss: 163.9548\n",
            "Epoch [11/50] - Batch loss: 166.0400 - Epoch Loss: 62140.9475 - Avg Loss: 163.9603\n",
            "Epoch [11/50] - Batch loss: 161.8336 - Epoch Loss: 62302.7812 - Avg Loss: 163.9547\n",
            "Epoch [11/50] - Batch loss: 161.2268 - Epoch Loss: 62464.0080 - Avg Loss: 163.9475\n",
            "Epoch [11/50] - Batch loss: 156.2518 - Epoch Loss: 62620.2598 - Avg Loss: 163.9274\n",
            "Epoch [11/50] - Batch loss: 160.8522 - Epoch Loss: 62781.1120 - Avg Loss: 163.9194\n",
            "Epoch [11/50] - Batch loss: 165.4542 - Epoch Loss: 62946.5663 - Avg Loss: 163.9233\n",
            "Epoch [11/50] - Batch loss: 165.9661 - Epoch Loss: 63112.5323 - Avg Loss: 163.9287\n",
            "Epoch [11/50] - Batch loss: 156.8964 - Epoch Loss: 63269.4288 - Avg Loss: 163.9104\n",
            "Epoch [11/50] - Batch loss: 164.7714 - Epoch Loss: 63434.2002 - Avg Loss: 163.9127\n",
            "Epoch [11/50] - Batch loss: 166.2343 - Epoch Loss: 63600.4344 - Avg Loss: 163.9186\n",
            "Epoch [11/50] - Batch loss: 166.7965 - Epoch Loss: 63767.2309 - Avg Loss: 163.9260\n",
            "Epoch [11/50] - Batch loss: 166.8573 - Epoch Loss: 63934.0883 - Avg Loss: 163.9336\n",
            "Epoch [11/50] - Batch loss: 164.2571 - Epoch Loss: 64098.3453 - Avg Loss: 163.9344\n",
            "Epoch [11/50] - Batch loss: 163.9616 - Epoch Loss: 64262.3069 - Avg Loss: 163.9345\n",
            "Epoch [11/50] - Batch loss: 166.2995 - Epoch Loss: 64428.6064 - Avg Loss: 163.9405\n",
            "Epoch [11/50] - Batch loss: 157.0634 - Epoch Loss: 64585.6698 - Avg Loss: 163.9230\n",
            "Epoch [11/50] - Batch loss: 157.4915 - Epoch Loss: 64743.1613 - Avg Loss: 163.9067\n",
            "Epoch [11/50] - Batch loss: 157.4247 - Epoch Loss: 64900.5860 - Avg Loss: 163.8904\n",
            "Epoch [11/50] - Batch loss: 154.5764 - Epoch Loss: 65055.1624 - Avg Loss: 163.8669\n",
            "Epoch [11/50] - Batch loss: 158.8958 - Epoch Loss: 65214.0582 - Avg Loss: 163.8544\n",
            "Epoch [11/50] - Batch loss: 161.4046 - Epoch Loss: 65375.4628 - Avg Loss: 163.8483\n",
            "Epoch [11/50] - Batch loss: 171.5720 - Epoch Loss: 65547.0349 - Avg Loss: 163.8676\n",
            "Epoch [11/50] - Batch loss: 169.0622 - Epoch Loss: 65716.0971 - Avg Loss: 163.8805\n",
            "Epoch [11/50] - Batch loss: 164.1549 - Epoch Loss: 65880.2520 - Avg Loss: 163.8812\n",
            "Epoch [11/50] - Batch loss: 165.4797 - Epoch Loss: 66045.7317 - Avg Loss: 163.8852\n",
            "Epoch [11/50] - Batch loss: 164.7419 - Epoch Loss: 66210.4736 - Avg Loss: 163.8873\n",
            "Epoch [11/50] - Batch loss: 160.6564 - Epoch Loss: 66371.1300 - Avg Loss: 163.8793\n",
            "Epoch [11/50] - Batch loss: 169.9489 - Epoch Loss: 66541.0788 - Avg Loss: 163.8943\n",
            "Epoch [11/50] - Batch loss: 156.5994 - Epoch Loss: 66697.6783 - Avg Loss: 163.8764\n",
            "Epoch [11/50] - Batch loss: 163.1363 - Epoch Loss: 66860.8146 - Avg Loss: 163.8745\n",
            "Epoch [11/50] - Batch loss: 166.1300 - Epoch Loss: 67026.9445 - Avg Loss: 163.8801\n",
            "Epoch [11/50] - Batch loss: 166.8355 - Epoch Loss: 67193.7800 - Avg Loss: 163.8873\n",
            "Epoch [11/50] - Batch loss: 158.5067 - Epoch Loss: 67352.2867 - Avg Loss: 163.8742\n",
            "Epoch [11/50] - Batch loss: 164.0927 - Epoch Loss: 67516.3795 - Avg Loss: 163.8747\n",
            "Epoch [11/50] - Batch loss: 164.4771 - Epoch Loss: 67680.8566 - Avg Loss: 163.8762\n",
            "Epoch [11/50] - Batch loss: 168.6990 - Epoch Loss: 67849.5556 - Avg Loss: 163.8878\n",
            "Epoch [11/50] - Batch loss: 159.4929 - Epoch Loss: 68009.0485 - Avg Loss: 163.8772\n",
            "Epoch [11/50] - Batch loss: 155.8587 - Epoch Loss: 68164.9073 - Avg Loss: 163.8580\n",
            "Epoch [11/50] - Batch loss: 164.5367 - Epoch Loss: 68329.4439 - Avg Loss: 163.8596\n",
            "Epoch [11/50] - Batch loss: 153.6334 - Epoch Loss: 68483.0773 - Avg Loss: 163.8351\n",
            "Epoch [11/50] - Batch loss: 166.2490 - Epoch Loss: 68649.3263 - Avg Loss: 163.8409\n",
            "Epoch [11/50] - Batch loss: 157.5664 - Epoch Loss: 68806.8927 - Avg Loss: 163.8259\n",
            "Epoch [11/50] - Batch loss: 164.7345 - Epoch Loss: 68971.6272 - Avg Loss: 163.8281\n",
            "Epoch [11/50] - Batch loss: 161.5199 - Epoch Loss: 69133.1470 - Avg Loss: 163.8226\n",
            "Epoch [11/50] - Batch loss: 162.4679 - Epoch Loss: 69295.6149 - Avg Loss: 163.8194\n",
            "Epoch [11/50] - Batch loss: 165.9489 - Epoch Loss: 69461.5639 - Avg Loss: 163.8244\n",
            "Epoch [11/50] - Batch loss: 161.8818 - Epoch Loss: 69623.4456 - Avg Loss: 163.8199\n",
            "Epoch [11/50] - Batch loss: 163.3164 - Epoch Loss: 69786.7620 - Avg Loss: 163.8187\n",
            "Epoch [11/50] - Batch loss: 158.3975 - Epoch Loss: 69945.1596 - Avg Loss: 163.8060\n",
            "Epoch [11/50] - Batch loss: 167.7737 - Epoch Loss: 70112.9332 - Avg Loss: 163.8153\n",
            "Epoch [11/50] - Batch loss: 161.7635 - Epoch Loss: 70274.6967 - Avg Loss: 163.8105\n",
            "Epoch [11/50] - Batch loss: 160.2909 - Epoch Loss: 70434.9876 - Avg Loss: 163.8023\n",
            "Epoch [11/50] - Batch loss: 165.7434 - Epoch Loss: 70600.7310 - Avg Loss: 163.8068\n",
            "Epoch [11/50] - Batch loss: 165.0922 - Epoch Loss: 70765.8232 - Avg Loss: 163.8098\n",
            "Epoch [11/50] - Batch loss: 164.1466 - Epoch Loss: 70929.9698 - Avg Loss: 163.8106\n",
            "Epoch [11/50] - Batch loss: 162.1700 - Epoch Loss: 71092.1398 - Avg Loss: 163.8068\n",
            "Epoch [11/50] - Batch loss: 162.1254 - Epoch Loss: 71254.2652 - Avg Loss: 163.8029\n",
            "Epoch [11/50] - Batch loss: 160.9460 - Epoch Loss: 71415.2111 - Avg Loss: 163.7964\n",
            "Epoch [11/50] - Batch loss: 166.1550 - Epoch Loss: 71581.3661 - Avg Loss: 163.8018\n",
            "Epoch [11/50] - Batch loss: 163.3380 - Epoch Loss: 71744.7041 - Avg Loss: 163.8007\n",
            "Epoch [11/50] - Batch loss: 153.5672 - Epoch Loss: 71898.2713 - Avg Loss: 163.7774\n",
            "Epoch [11/50] - Batch loss: 169.2612 - Epoch Loss: 72067.5325 - Avg Loss: 163.7898\n",
            "Epoch [11/50] - Batch loss: 169.7947 - Epoch Loss: 72237.3272 - Avg Loss: 163.8035\n",
            "Epoch [11/50] - Batch loss: 156.1540 - Epoch Loss: 72393.4811 - Avg Loss: 163.7862\n",
            "Epoch [11/50] - Batch loss: 164.8590 - Epoch Loss: 72558.3402 - Avg Loss: 163.7886\n",
            "Epoch [11/50] - Batch loss: 158.6817 - Epoch Loss: 72717.0219 - Avg Loss: 163.7771\n",
            "Epoch [11/50] - Batch loss: 154.2310 - Epoch Loss: 72871.2529 - Avg Loss: 163.7556\n",
            "Epoch [11/50] - Batch loss: 159.5643 - Epoch Loss: 73030.8173 - Avg Loss: 163.7462\n",
            "Epoch [11/50] - Batch loss: 161.7655 - Epoch Loss: 73192.5828 - Avg Loss: 163.7418\n",
            "Epoch [11/50] - Batch loss: 160.8527 - Epoch Loss: 73353.4355 - Avg Loss: 163.7353\n",
            "Epoch [11/50] - Batch loss: 159.1306 - Epoch Loss: 73512.5661 - Avg Loss: 163.7251\n",
            "Epoch [11/50] - Batch loss: 161.3866 - Epoch Loss: 73673.9526 - Avg Loss: 163.7199\n",
            "Epoch [11/50] - Batch loss: 167.8511 - Epoch Loss: 73841.8038 - Avg Loss: 163.7291\n",
            "Epoch [11/50] - Batch loss: 162.7683 - Epoch Loss: 74004.5721 - Avg Loss: 163.7269\n",
            "Epoch [11/50] - Batch loss: 168.6929 - Epoch Loss: 74173.2650 - Avg Loss: 163.7379\n",
            "Epoch [11/50] - Batch loss: 163.3631 - Epoch Loss: 74336.6281 - Avg Loss: 163.7371\n",
            "Epoch [11/50] - Batch loss: 163.8434 - Epoch Loss: 74500.4716 - Avg Loss: 163.7373\n",
            "Epoch [11/50] - Batch loss: 159.7521 - Epoch Loss: 74660.2237 - Avg Loss: 163.7286\n",
            "Epoch [11/50] - Batch loss: 170.8276 - Epoch Loss: 74831.0512 - Avg Loss: 163.7441\n",
            "Epoch [11/50] - Batch loss: 163.1502 - Epoch Loss: 74994.2014 - Avg Loss: 163.7428\n",
            "Epoch [11/50] - Batch loss: 165.7442 - Epoch Loss: 75159.9456 - Avg Loss: 163.7472\n",
            "Epoch [11/50] - Batch loss: 164.4969 - Epoch Loss: 75324.4425 - Avg Loss: 163.7488\n",
            "Epoch [11/50] - Batch loss: 165.1405 - Epoch Loss: 75489.5831 - Avg Loss: 163.7518\n",
            "Epoch [11/50] - Batch loss: 161.8499 - Epoch Loss: 75651.4330 - Avg Loss: 163.7477\n",
            "Epoch [11/50] - Batch loss: 166.3962 - Epoch Loss: 75817.8291 - Avg Loss: 163.7534\n",
            "Epoch [11/50] - Batch loss: 161.7341 - Epoch Loss: 75979.5632 - Avg Loss: 163.7491\n",
            "Epoch [11/50] - Batch loss: 164.0126 - Epoch Loss: 76143.5758 - Avg Loss: 163.7496\n",
            "Epoch [11/50] - Batch loss: 158.7205 - Epoch Loss: 76302.2963 - Avg Loss: 163.7388\n",
            "Epoch [11/50] - Batch loss: 169.2856 - Epoch Loss: 76471.5819 - Avg Loss: 163.7507\n",
            "Epoch [11/50] - Batch loss: 156.4370 - Epoch Loss: 76628.0190 - Avg Loss: 163.7351\n",
            "Epoch [11/50] - Batch loss: 167.7144 - Epoch Loss: 76795.7334 - Avg Loss: 163.7436\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 12/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca66d113aaad412b81607a209d293720"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/50] - Batch loss: 158.5282 - Epoch Loss: 158.5282 - Avg Loss: 158.5282\n",
            "Epoch [12/50] - Batch loss: 165.2050 - Epoch Loss: 323.7332 - Avg Loss: 161.8666\n",
            "Epoch [12/50] - Batch loss: 155.8705 - Epoch Loss: 479.6037 - Avg Loss: 159.8679\n",
            "Epoch [12/50] - Batch loss: 168.2883 - Epoch Loss: 647.8920 - Avg Loss: 161.9730\n",
            "Epoch [12/50] - Batch loss: 167.2014 - Epoch Loss: 815.0934 - Avg Loss: 163.0187\n",
            "Epoch [12/50] - Batch loss: 170.3855 - Epoch Loss: 985.4789 - Avg Loss: 164.2465\n",
            "Epoch [12/50] - Batch loss: 161.5473 - Epoch Loss: 1147.0262 - Avg Loss: 163.8609\n",
            "Epoch [12/50] - Batch loss: 162.4389 - Epoch Loss: 1309.4652 - Avg Loss: 163.6831\n",
            "Epoch [12/50] - Batch loss: 168.1318 - Epoch Loss: 1477.5970 - Avg Loss: 164.1774\n",
            "Epoch [12/50] - Batch loss: 161.1454 - Epoch Loss: 1638.7424 - Avg Loss: 163.8742\n",
            "Epoch [12/50] - Batch loss: 163.2694 - Epoch Loss: 1802.0118 - Avg Loss: 163.8193\n",
            "Epoch [12/50] - Batch loss: 172.1340 - Epoch Loss: 1974.1458 - Avg Loss: 164.5122\n",
            "Epoch [12/50] - Batch loss: 159.2796 - Epoch Loss: 2133.4255 - Avg Loss: 164.1097\n",
            "Epoch [12/50] - Batch loss: 157.5995 - Epoch Loss: 2291.0250 - Avg Loss: 163.6446\n",
            "Epoch [12/50] - Batch loss: 157.8338 - Epoch Loss: 2448.8588 - Avg Loss: 163.2573\n",
            "Epoch [12/50] - Batch loss: 171.4699 - Epoch Loss: 2620.3287 - Avg Loss: 163.7705\n",
            "Epoch [12/50] - Batch loss: 159.2624 - Epoch Loss: 2779.5911 - Avg Loss: 163.5054\n",
            "Epoch [12/50] - Batch loss: 166.6951 - Epoch Loss: 2946.2862 - Avg Loss: 163.6826\n",
            "Epoch [12/50] - Batch loss: 167.4375 - Epoch Loss: 3113.7237 - Avg Loss: 163.8802\n",
            "Epoch [12/50] - Batch loss: 161.8148 - Epoch Loss: 3275.5385 - Avg Loss: 163.7769\n",
            "Epoch [12/50] - Batch loss: 164.1618 - Epoch Loss: 3439.7003 - Avg Loss: 163.7953\n",
            "Epoch [12/50] - Batch loss: 167.4710 - Epoch Loss: 3607.1713 - Avg Loss: 163.9623\n",
            "Epoch [12/50] - Batch loss: 163.0824 - Epoch Loss: 3770.2537 - Avg Loss: 163.9241\n",
            "Epoch [12/50] - Batch loss: 161.4816 - Epoch Loss: 3931.7354 - Avg Loss: 163.8223\n",
            "Epoch [12/50] - Batch loss: 157.2390 - Epoch Loss: 4088.9743 - Avg Loss: 163.5590\n",
            "Epoch [12/50] - Batch loss: 169.8607 - Epoch Loss: 4258.8351 - Avg Loss: 163.8013\n",
            "Epoch [12/50] - Batch loss: 163.1763 - Epoch Loss: 4422.0113 - Avg Loss: 163.7782\n",
            "Epoch [12/50] - Batch loss: 169.7707 - Epoch Loss: 4591.7820 - Avg Loss: 163.9922\n",
            "Epoch [12/50] - Batch loss: 170.3669 - Epoch Loss: 4762.1489 - Avg Loss: 164.2120\n",
            "Epoch [12/50] - Batch loss: 168.1893 - Epoch Loss: 4930.3382 - Avg Loss: 164.3446\n",
            "Epoch [12/50] - Batch loss: 166.1497 - Epoch Loss: 5096.4879 - Avg Loss: 164.4028\n",
            "Epoch [12/50] - Batch loss: 164.8100 - Epoch Loss: 5261.2979 - Avg Loss: 164.4156\n",
            "Epoch [12/50] - Batch loss: 164.6823 - Epoch Loss: 5425.9803 - Avg Loss: 164.4236\n",
            "Epoch [12/50] - Batch loss: 149.7670 - Epoch Loss: 5575.7472 - Avg Loss: 163.9926\n",
            "Epoch [12/50] - Batch loss: 163.9875 - Epoch Loss: 5739.7348 - Avg Loss: 163.9924\n",
            "Epoch [12/50] - Batch loss: 169.7679 - Epoch Loss: 5909.5026 - Avg Loss: 164.1529\n",
            "Epoch [12/50] - Batch loss: 165.4932 - Epoch Loss: 6074.9958 - Avg Loss: 164.1891\n",
            "Epoch [12/50] - Batch loss: 162.5353 - Epoch Loss: 6237.5311 - Avg Loss: 164.1456\n",
            "Epoch [12/50] - Batch loss: 165.4834 - Epoch Loss: 6403.0145 - Avg Loss: 164.1799\n",
            "Epoch [12/50] - Batch loss: 164.6992 - Epoch Loss: 6567.7137 - Avg Loss: 164.1928\n",
            "Epoch [12/50] - Batch loss: 160.2912 - Epoch Loss: 6728.0050 - Avg Loss: 164.0977\n",
            "Epoch [12/50] - Batch loss: 152.2183 - Epoch Loss: 6880.2233 - Avg Loss: 163.8148\n",
            "Epoch [12/50] - Batch loss: 161.5875 - Epoch Loss: 7041.8108 - Avg Loss: 163.7630\n",
            "Epoch [12/50] - Batch loss: 156.8161 - Epoch Loss: 7198.6269 - Avg Loss: 163.6052\n",
            "Epoch [12/50] - Batch loss: 158.7465 - Epoch Loss: 7357.3734 - Avg Loss: 163.4972\n",
            "Epoch [12/50] - Batch loss: 168.7581 - Epoch Loss: 7526.1315 - Avg Loss: 163.6116\n",
            "Epoch [12/50] - Batch loss: 162.5856 - Epoch Loss: 7688.7171 - Avg Loss: 163.5897\n",
            "Epoch [12/50] - Batch loss: 168.0627 - Epoch Loss: 7856.7798 - Avg Loss: 163.6829\n",
            "Epoch [12/50] - Batch loss: 169.5911 - Epoch Loss: 8026.3709 - Avg Loss: 163.8035\n",
            "Epoch [12/50] - Batch loss: 161.3697 - Epoch Loss: 8187.7406 - Avg Loss: 163.7548\n",
            "Epoch [12/50] - Batch loss: 169.1196 - Epoch Loss: 8356.8601 - Avg Loss: 163.8600\n",
            "Epoch [12/50] - Batch loss: 167.9131 - Epoch Loss: 8524.7733 - Avg Loss: 163.9379\n",
            "Epoch [12/50] - Batch loss: 163.1595 - Epoch Loss: 8687.9328 - Avg Loss: 163.9233\n",
            "Epoch [12/50] - Batch loss: 159.5604 - Epoch Loss: 8847.4932 - Avg Loss: 163.8425\n",
            "Epoch [12/50] - Batch loss: 159.9600 - Epoch Loss: 9007.4532 - Avg Loss: 163.7719\n",
            "Epoch [12/50] - Batch loss: 163.0203 - Epoch Loss: 9170.4735 - Avg Loss: 163.7585\n",
            "Epoch [12/50] - Batch loss: 169.8632 - Epoch Loss: 9340.3367 - Avg Loss: 163.8656\n",
            "Epoch [12/50] - Batch loss: 167.5956 - Epoch Loss: 9507.9323 - Avg Loss: 163.9299\n",
            "Epoch [12/50] - Batch loss: 169.6583 - Epoch Loss: 9677.5906 - Avg Loss: 164.0270\n",
            "Epoch [12/50] - Batch loss: 158.5519 - Epoch Loss: 9836.1425 - Avg Loss: 163.9357\n",
            "Epoch [12/50] - Batch loss: 156.5677 - Epoch Loss: 9992.7101 - Avg Loss: 163.8149\n",
            "Epoch [12/50] - Batch loss: 168.1808 - Epoch Loss: 10160.8910 - Avg Loss: 163.8853\n",
            "Epoch [12/50] - Batch loss: 160.5957 - Epoch Loss: 10321.4866 - Avg Loss: 163.8331\n",
            "Epoch [12/50] - Batch loss: 156.1658 - Epoch Loss: 10477.6524 - Avg Loss: 163.7133\n",
            "Epoch [12/50] - Batch loss: 165.0644 - Epoch Loss: 10642.7168 - Avg Loss: 163.7341\n",
            "Epoch [12/50] - Batch loss: 155.6364 - Epoch Loss: 10798.3532 - Avg Loss: 163.6114\n",
            "Epoch [12/50] - Batch loss: 175.5210 - Epoch Loss: 10973.8742 - Avg Loss: 163.7892\n",
            "Epoch [12/50] - Batch loss: 165.4197 - Epoch Loss: 11139.2939 - Avg Loss: 163.8131\n",
            "Epoch [12/50] - Batch loss: 163.0247 - Epoch Loss: 11302.3186 - Avg Loss: 163.8017\n",
            "Epoch [12/50] - Batch loss: 168.3926 - Epoch Loss: 11470.7112 - Avg Loss: 163.8673\n",
            "Epoch [12/50] - Batch loss: 161.2160 - Epoch Loss: 11631.9272 - Avg Loss: 163.8300\n",
            "Epoch [12/50] - Batch loss: 152.3558 - Epoch Loss: 11784.2830 - Avg Loss: 163.6706\n",
            "Epoch [12/50] - Batch loss: 161.3829 - Epoch Loss: 11945.6658 - Avg Loss: 163.6393\n",
            "Epoch [12/50] - Batch loss: 165.0419 - Epoch Loss: 12110.7078 - Avg Loss: 163.6582\n",
            "Epoch [12/50] - Batch loss: 163.5597 - Epoch Loss: 12274.2675 - Avg Loss: 163.6569\n",
            "Epoch [12/50] - Batch loss: 155.1706 - Epoch Loss: 12429.4380 - Avg Loss: 163.5452\n",
            "Epoch [12/50] - Batch loss: 171.8739 - Epoch Loss: 12601.3119 - Avg Loss: 163.6534\n",
            "Epoch [12/50] - Batch loss: 168.2366 - Epoch Loss: 12769.5485 - Avg Loss: 163.7122\n",
            "Epoch [12/50] - Batch loss: 165.3534 - Epoch Loss: 12934.9019 - Avg Loss: 163.7329\n",
            "Epoch [12/50] - Batch loss: 160.5013 - Epoch Loss: 13095.4032 - Avg Loss: 163.6925\n",
            "Epoch [12/50] - Batch loss: 160.0772 - Epoch Loss: 13255.4804 - Avg Loss: 163.6479\n",
            "Epoch [12/50] - Batch loss: 166.1736 - Epoch Loss: 13421.6540 - Avg Loss: 163.6787\n",
            "Epoch [12/50] - Batch loss: 161.0676 - Epoch Loss: 13582.7216 - Avg Loss: 163.6472\n",
            "Epoch [12/50] - Batch loss: 163.1487 - Epoch Loss: 13745.8702 - Avg Loss: 163.6413\n",
            "Epoch [12/50] - Batch loss: 166.9287 - Epoch Loss: 13912.7989 - Avg Loss: 163.6800\n",
            "Epoch [12/50] - Batch loss: 165.2108 - Epoch Loss: 14078.0097 - Avg Loss: 163.6978\n",
            "Epoch [12/50] - Batch loss: 164.6277 - Epoch Loss: 14242.6374 - Avg Loss: 163.7085\n",
            "Epoch [12/50] - Batch loss: 166.9790 - Epoch Loss: 14409.6164 - Avg Loss: 163.7456\n",
            "Epoch [12/50] - Batch loss: 166.3406 - Epoch Loss: 14575.9570 - Avg Loss: 163.7748\n",
            "Epoch [12/50] - Batch loss: 163.0341 - Epoch Loss: 14738.9911 - Avg Loss: 163.7666\n",
            "Epoch [12/50] - Batch loss: 167.6322 - Epoch Loss: 14906.6233 - Avg Loss: 163.8090\n",
            "Epoch [12/50] - Batch loss: 159.9087 - Epoch Loss: 15066.5320 - Avg Loss: 163.7667\n",
            "Epoch [12/50] - Batch loss: 165.0444 - Epoch Loss: 15231.5764 - Avg Loss: 163.7804\n",
            "Epoch [12/50] - Batch loss: 171.2246 - Epoch Loss: 15402.8010 - Avg Loss: 163.8596\n",
            "Epoch [12/50] - Batch loss: 160.2646 - Epoch Loss: 15563.0656 - Avg Loss: 163.8217\n",
            "Epoch [12/50] - Batch loss: 163.2098 - Epoch Loss: 15726.2754 - Avg Loss: 163.8154\n",
            "Epoch [12/50] - Batch loss: 160.5336 - Epoch Loss: 15886.8090 - Avg Loss: 163.7815\n",
            "Epoch [12/50] - Batch loss: 157.0836 - Epoch Loss: 16043.8927 - Avg Loss: 163.7132\n",
            "Epoch [12/50] - Batch loss: 168.7887 - Epoch Loss: 16212.6813 - Avg Loss: 163.7645\n",
            "Epoch [12/50] - Batch loss: 165.8197 - Epoch Loss: 16378.5011 - Avg Loss: 163.7850\n",
            "Epoch [12/50] - Batch loss: 163.7680 - Epoch Loss: 16542.2690 - Avg Loss: 163.7848\n",
            "Epoch [12/50] - Batch loss: 163.0704 - Epoch Loss: 16705.3394 - Avg Loss: 163.7778\n",
            "Epoch [12/50] - Batch loss: 159.8365 - Epoch Loss: 16865.1759 - Avg Loss: 163.7396\n",
            "Epoch [12/50] - Batch loss: 162.0389 - Epoch Loss: 17027.2147 - Avg Loss: 163.7232\n",
            "Epoch [12/50] - Batch loss: 158.1174 - Epoch Loss: 17185.3321 - Avg Loss: 163.6698\n",
            "Epoch [12/50] - Batch loss: 167.2594 - Epoch Loss: 17352.5915 - Avg Loss: 163.7037\n",
            "Epoch [12/50] - Batch loss: 167.8147 - Epoch Loss: 17520.4062 - Avg Loss: 163.7421\n",
            "Epoch [12/50] - Batch loss: 172.4296 - Epoch Loss: 17692.8358 - Avg Loss: 163.8226\n",
            "Epoch [12/50] - Batch loss: 164.3107 - Epoch Loss: 17857.1465 - Avg Loss: 163.8270\n",
            "Epoch [12/50] - Batch loss: 160.5182 - Epoch Loss: 18017.6647 - Avg Loss: 163.7970\n",
            "Epoch [12/50] - Batch loss: 159.9401 - Epoch Loss: 18177.6048 - Avg Loss: 163.7622\n",
            "Epoch [12/50] - Batch loss: 165.7553 - Epoch Loss: 18343.3601 - Avg Loss: 163.7800\n",
            "Epoch [12/50] - Batch loss: 166.6417 - Epoch Loss: 18510.0018 - Avg Loss: 163.8053\n",
            "Epoch [12/50] - Batch loss: 168.1663 - Epoch Loss: 18678.1681 - Avg Loss: 163.8436\n",
            "Epoch [12/50] - Batch loss: 162.7572 - Epoch Loss: 18840.9253 - Avg Loss: 163.8341\n",
            "Epoch [12/50] - Batch loss: 151.8038 - Epoch Loss: 18992.7290 - Avg Loss: 163.7304\n",
            "Epoch [12/50] - Batch loss: 169.1638 - Epoch Loss: 19161.8929 - Avg Loss: 163.7769\n",
            "Epoch [12/50] - Batch loss: 168.4110 - Epoch Loss: 19330.3039 - Avg Loss: 163.8161\n",
            "Epoch [12/50] - Batch loss: 165.0351 - Epoch Loss: 19495.3390 - Avg Loss: 163.8264\n",
            "Epoch [12/50] - Batch loss: 156.2848 - Epoch Loss: 19651.6238 - Avg Loss: 163.7635\n",
            "Epoch [12/50] - Batch loss: 170.6100 - Epoch Loss: 19822.2338 - Avg Loss: 163.8201\n",
            "Epoch [12/50] - Batch loss: 161.2940 - Epoch Loss: 19983.5278 - Avg Loss: 163.7994\n",
            "Epoch [12/50] - Batch loss: 155.6745 - Epoch Loss: 20139.2023 - Avg Loss: 163.7334\n",
            "Epoch [12/50] - Batch loss: 171.2501 - Epoch Loss: 20310.4524 - Avg Loss: 163.7940\n",
            "Epoch [12/50] - Batch loss: 162.3933 - Epoch Loss: 20472.8458 - Avg Loss: 163.7828\n",
            "Epoch [12/50] - Batch loss: 164.7440 - Epoch Loss: 20637.5898 - Avg Loss: 163.7904\n",
            "Epoch [12/50] - Batch loss: 166.1444 - Epoch Loss: 20803.7342 - Avg Loss: 163.8089\n",
            "Epoch [12/50] - Batch loss: 161.7827 - Epoch Loss: 20965.5169 - Avg Loss: 163.7931\n",
            "Epoch [12/50] - Batch loss: 162.7099 - Epoch Loss: 21128.2268 - Avg Loss: 163.7847\n",
            "Epoch [12/50] - Batch loss: 163.7221 - Epoch Loss: 21291.9489 - Avg Loss: 163.7842\n",
            "Epoch [12/50] - Batch loss: 166.0166 - Epoch Loss: 21457.9655 - Avg Loss: 163.8013\n",
            "Epoch [12/50] - Batch loss: 160.2849 - Epoch Loss: 21618.2504 - Avg Loss: 163.7746\n",
            "Epoch [12/50] - Batch loss: 157.3128 - Epoch Loss: 21775.5632 - Avg Loss: 163.7260\n",
            "Epoch [12/50] - Batch loss: 158.4675 - Epoch Loss: 21934.0307 - Avg Loss: 163.6868\n",
            "Epoch [12/50] - Batch loss: 164.8455 - Epoch Loss: 22098.8762 - Avg Loss: 163.6954\n",
            "Epoch [12/50] - Batch loss: 165.4843 - Epoch Loss: 22264.3605 - Avg Loss: 163.7085\n",
            "Epoch [12/50] - Batch loss: 163.2738 - Epoch Loss: 22427.6343 - Avg Loss: 163.7054\n",
            "Epoch [12/50] - Batch loss: 159.3954 - Epoch Loss: 22587.0297 - Avg Loss: 163.6741\n",
            "Epoch [12/50] - Batch loss: 164.6375 - Epoch Loss: 22751.6672 - Avg Loss: 163.6811\n",
            "Epoch [12/50] - Batch loss: 165.5371 - Epoch Loss: 22917.2043 - Avg Loss: 163.6943\n",
            "Epoch [12/50] - Batch loss: 169.9622 - Epoch Loss: 23087.1665 - Avg Loss: 163.7388\n",
            "Epoch [12/50] - Batch loss: 160.1970 - Epoch Loss: 23247.3635 - Avg Loss: 163.7138\n",
            "Epoch [12/50] - Batch loss: 165.6712 - Epoch Loss: 23413.0347 - Avg Loss: 163.7275\n",
            "Epoch [12/50] - Batch loss: 163.7251 - Epoch Loss: 23576.7599 - Avg Loss: 163.7275\n",
            "Epoch [12/50] - Batch loss: 163.0564 - Epoch Loss: 23739.8163 - Avg Loss: 163.7229\n",
            "Epoch [12/50] - Batch loss: 170.3120 - Epoch Loss: 23910.1283 - Avg Loss: 163.7680\n",
            "Epoch [12/50] - Batch loss: 161.5139 - Epoch Loss: 24071.6422 - Avg Loss: 163.7527\n",
            "Epoch [12/50] - Batch loss: 165.0311 - Epoch Loss: 24236.6733 - Avg Loss: 163.7613\n",
            "Epoch [12/50] - Batch loss: 158.9472 - Epoch Loss: 24395.6205 - Avg Loss: 163.7290\n",
            "Epoch [12/50] - Batch loss: 164.7282 - Epoch Loss: 24560.3487 - Avg Loss: 163.7357\n",
            "Epoch [12/50] - Batch loss: 171.0719 - Epoch Loss: 24731.4206 - Avg Loss: 163.7842\n",
            "Epoch [12/50] - Batch loss: 155.0437 - Epoch Loss: 24886.4643 - Avg Loss: 163.7267\n",
            "Epoch [12/50] - Batch loss: 166.3287 - Epoch Loss: 25052.7929 - Avg Loss: 163.7437\n",
            "Epoch [12/50] - Batch loss: 157.2022 - Epoch Loss: 25209.9951 - Avg Loss: 163.7013\n",
            "Epoch [12/50] - Batch loss: 158.1151 - Epoch Loss: 25368.1102 - Avg Loss: 163.6652\n",
            "Epoch [12/50] - Batch loss: 169.0351 - Epoch Loss: 25537.1453 - Avg Loss: 163.6996\n",
            "Epoch [12/50] - Batch loss: 160.4994 - Epoch Loss: 25697.6447 - Avg Loss: 163.6793\n",
            "Epoch [12/50] - Batch loss: 168.4211 - Epoch Loss: 25866.0658 - Avg Loss: 163.7093\n",
            "Epoch [12/50] - Batch loss: 160.2655 - Epoch Loss: 26026.3313 - Avg Loss: 163.6876\n",
            "Epoch [12/50] - Batch loss: 163.6006 - Epoch Loss: 26189.9319 - Avg Loss: 163.6871\n",
            "Epoch [12/50] - Batch loss: 157.2518 - Epoch Loss: 26347.1837 - Avg Loss: 163.6471\n",
            "Epoch [12/50] - Batch loss: 162.6815 - Epoch Loss: 26509.8652 - Avg Loss: 163.6411\n",
            "Epoch [12/50] - Batch loss: 153.4866 - Epoch Loss: 26663.3518 - Avg Loss: 163.5788\n",
            "Epoch [12/50] - Batch loss: 165.5562 - Epoch Loss: 26828.9080 - Avg Loss: 163.5909\n",
            "Epoch [12/50] - Batch loss: 172.8365 - Epoch Loss: 27001.7445 - Avg Loss: 163.6469\n",
            "Epoch [12/50] - Batch loss: 163.7843 - Epoch Loss: 27165.5288 - Avg Loss: 163.6478\n",
            "Epoch [12/50] - Batch loss: 167.4836 - Epoch Loss: 27333.0123 - Avg Loss: 163.6707\n",
            "Epoch [12/50] - Batch loss: 161.1579 - Epoch Loss: 27494.1702 - Avg Loss: 163.6558\n",
            "Epoch [12/50] - Batch loss: 168.5620 - Epoch Loss: 27662.7323 - Avg Loss: 163.6848\n",
            "Epoch [12/50] - Batch loss: 161.2691 - Epoch Loss: 27824.0013 - Avg Loss: 163.6706\n",
            "Epoch [12/50] - Batch loss: 161.2346 - Epoch Loss: 27985.2360 - Avg Loss: 163.6564\n",
            "Epoch [12/50] - Batch loss: 159.2899 - Epoch Loss: 28144.5259 - Avg Loss: 163.6310\n",
            "Epoch [12/50] - Batch loss: 166.2403 - Epoch Loss: 28310.7662 - Avg Loss: 163.6460\n",
            "Epoch [12/50] - Batch loss: 164.3459 - Epoch Loss: 28475.1121 - Avg Loss: 163.6501\n",
            "Epoch [12/50] - Batch loss: 155.6093 - Epoch Loss: 28630.7214 - Avg Loss: 163.6041\n",
            "Epoch [12/50] - Batch loss: 160.7618 - Epoch Loss: 28791.4832 - Avg Loss: 163.5880\n",
            "Epoch [12/50] - Batch loss: 162.9673 - Epoch Loss: 28954.4505 - Avg Loss: 163.5845\n",
            "Epoch [12/50] - Batch loss: 160.4578 - Epoch Loss: 29114.9083 - Avg Loss: 163.5669\n",
            "Epoch [12/50] - Batch loss: 167.8312 - Epoch Loss: 29282.7395 - Avg Loss: 163.5907\n",
            "Epoch [12/50] - Batch loss: 153.6058 - Epoch Loss: 29436.3453 - Avg Loss: 163.5353\n",
            "Epoch [12/50] - Batch loss: 164.4036 - Epoch Loss: 29600.7489 - Avg Loss: 163.5400\n",
            "Epoch [12/50] - Batch loss: 160.4239 - Epoch Loss: 29761.1727 - Avg Loss: 163.5229\n",
            "Epoch [12/50] - Batch loss: 161.8932 - Epoch Loss: 29923.0659 - Avg Loss: 163.5140\n",
            "Epoch [12/50] - Batch loss: 167.7193 - Epoch Loss: 30090.7853 - Avg Loss: 163.5369\n",
            "Epoch [12/50] - Batch loss: 164.2877 - Epoch Loss: 30255.0730 - Avg Loss: 163.5409\n",
            "Epoch [12/50] - Batch loss: 169.2128 - Epoch Loss: 30424.2858 - Avg Loss: 163.5714\n",
            "Epoch [12/50] - Batch loss: 162.1210 - Epoch Loss: 30586.4068 - Avg Loss: 163.5637\n",
            "Epoch [12/50] - Batch loss: 161.4987 - Epoch Loss: 30747.9054 - Avg Loss: 163.5527\n",
            "Epoch [12/50] - Batch loss: 165.6300 - Epoch Loss: 30913.5354 - Avg Loss: 163.5637\n",
            "Epoch [12/50] - Batch loss: 162.7634 - Epoch Loss: 31076.2988 - Avg Loss: 163.5595\n",
            "Epoch [12/50] - Batch loss: 156.9719 - Epoch Loss: 31233.2707 - Avg Loss: 163.5250\n",
            "Epoch [12/50] - Batch loss: 160.6411 - Epoch Loss: 31393.9118 - Avg Loss: 163.5100\n",
            "Epoch [12/50] - Batch loss: 158.2009 - Epoch Loss: 31552.1127 - Avg Loss: 163.4824\n",
            "Epoch [12/50] - Batch loss: 156.2643 - Epoch Loss: 31708.3770 - Avg Loss: 163.4452\n",
            "Epoch [12/50] - Batch loss: 164.9981 - Epoch Loss: 31873.3751 - Avg Loss: 163.4532\n",
            "Epoch [12/50] - Batch loss: 161.5779 - Epoch Loss: 32034.9530 - Avg Loss: 163.4436\n",
            "Epoch [12/50] - Batch loss: 154.5752 - Epoch Loss: 32189.5282 - Avg Loss: 163.3986\n",
            "Epoch [12/50] - Batch loss: 172.4212 - Epoch Loss: 32361.9494 - Avg Loss: 163.4442\n",
            "Epoch [12/50] - Batch loss: 157.6794 - Epoch Loss: 32519.6288 - Avg Loss: 163.4152\n",
            "Epoch [12/50] - Batch loss: 158.8103 - Epoch Loss: 32678.4391 - Avg Loss: 163.3922\n",
            "Epoch [12/50] - Batch loss: 145.3197 - Epoch Loss: 32823.7588 - Avg Loss: 163.3023\n",
            "Epoch [12/50] - Batch loss: 158.8025 - Epoch Loss: 32982.5612 - Avg Loss: 163.2800\n",
            "Epoch [12/50] - Batch loss: 158.7339 - Epoch Loss: 33141.2951 - Avg Loss: 163.2576\n",
            "Epoch [12/50] - Batch loss: 169.5466 - Epoch Loss: 33310.8417 - Avg Loss: 163.2884\n",
            "Epoch [12/50] - Batch loss: 162.3842 - Epoch Loss: 33473.2259 - Avg Loss: 163.2840\n",
            "Epoch [12/50] - Batch loss: 163.1335 - Epoch Loss: 33636.3594 - Avg Loss: 163.2833\n",
            "Epoch [12/50] - Batch loss: 162.5539 - Epoch Loss: 33798.9133 - Avg Loss: 163.2798\n",
            "Epoch [12/50] - Batch loss: 163.0089 - Epoch Loss: 33961.9222 - Avg Loss: 163.2785\n",
            "Epoch [12/50] - Batch loss: 159.8366 - Epoch Loss: 34121.7589 - Avg Loss: 163.2620\n",
            "Epoch [12/50] - Batch loss: 163.9644 - Epoch Loss: 34285.7233 - Avg Loss: 163.2653\n",
            "Epoch [12/50] - Batch loss: 160.8616 - Epoch Loss: 34446.5848 - Avg Loss: 163.2540\n",
            "Epoch [12/50] - Batch loss: 167.7752 - Epoch Loss: 34614.3601 - Avg Loss: 163.2753\n",
            "Epoch [12/50] - Batch loss: 169.1469 - Epoch Loss: 34783.5070 - Avg Loss: 163.3028\n",
            "Epoch [12/50] - Batch loss: 153.1443 - Epoch Loss: 34936.6513 - Avg Loss: 163.2554\n",
            "Epoch [12/50] - Batch loss: 161.2262 - Epoch Loss: 35097.8775 - Avg Loss: 163.2459\n",
            "Epoch [12/50] - Batch loss: 155.7816 - Epoch Loss: 35253.6591 - Avg Loss: 163.2114\n",
            "Epoch [12/50] - Batch loss: 163.0090 - Epoch Loss: 35416.6681 - Avg Loss: 163.2105\n",
            "Epoch [12/50] - Batch loss: 168.4886 - Epoch Loss: 35585.1567 - Avg Loss: 163.2347\n",
            "Epoch [12/50] - Batch loss: 165.5969 - Epoch Loss: 35750.7536 - Avg Loss: 163.2455\n",
            "Epoch [12/50] - Batch loss: 156.4744 - Epoch Loss: 35907.2281 - Avg Loss: 163.2147\n",
            "Epoch [12/50] - Batch loss: 163.9458 - Epoch Loss: 36071.1739 - Avg Loss: 163.2180\n",
            "Epoch [12/50] - Batch loss: 156.4543 - Epoch Loss: 36227.6282 - Avg Loss: 163.1875\n",
            "Epoch [12/50] - Batch loss: 155.0494 - Epoch Loss: 36382.6776 - Avg Loss: 163.1510\n",
            "Epoch [12/50] - Batch loss: 157.5461 - Epoch Loss: 36540.2237 - Avg Loss: 163.1260\n",
            "Epoch [12/50] - Batch loss: 168.6267 - Epoch Loss: 36708.8504 - Avg Loss: 163.1504\n",
            "Epoch [12/50] - Batch loss: 170.5841 - Epoch Loss: 36879.4345 - Avg Loss: 163.1833\n",
            "Epoch [12/50] - Batch loss: 154.4710 - Epoch Loss: 37033.9055 - Avg Loss: 163.1450\n",
            "Epoch [12/50] - Batch loss: 160.0827 - Epoch Loss: 37193.9882 - Avg Loss: 163.1315\n",
            "Epoch [12/50] - Batch loss: 169.9142 - Epoch Loss: 37363.9024 - Avg Loss: 163.1611\n",
            "Epoch [12/50] - Batch loss: 155.9291 - Epoch Loss: 37519.8315 - Avg Loss: 163.1297\n",
            "Epoch [12/50] - Batch loss: 162.6532 - Epoch Loss: 37682.4847 - Avg Loss: 163.1276\n",
            "Epoch [12/50] - Batch loss: 160.6534 - Epoch Loss: 37843.1382 - Avg Loss: 163.1170\n",
            "Epoch [12/50] - Batch loss: 158.7068 - Epoch Loss: 38001.8450 - Avg Loss: 163.0980\n",
            "Epoch [12/50] - Batch loss: 168.3602 - Epoch Loss: 38170.2052 - Avg Loss: 163.1205\n",
            "Epoch [12/50] - Batch loss: 167.1227 - Epoch Loss: 38337.3279 - Avg Loss: 163.1376\n",
            "Epoch [12/50] - Batch loss: 159.4313 - Epoch Loss: 38496.7591 - Avg Loss: 163.1219\n",
            "Epoch [12/50] - Batch loss: 167.9127 - Epoch Loss: 38664.6718 - Avg Loss: 163.1421\n",
            "Epoch [12/50] - Batch loss: 164.3293 - Epoch Loss: 38829.0011 - Avg Loss: 163.1471\n",
            "Epoch [12/50] - Batch loss: 166.6437 - Epoch Loss: 38995.6448 - Avg Loss: 163.1617\n",
            "Epoch [12/50] - Batch loss: 159.4938 - Epoch Loss: 39155.1386 - Avg Loss: 163.1464\n",
            "Epoch [12/50] - Batch loss: 170.1566 - Epoch Loss: 39325.2952 - Avg Loss: 163.1755\n",
            "Epoch [12/50] - Batch loss: 158.5795 - Epoch Loss: 39483.8746 - Avg Loss: 163.1565\n",
            "Epoch [12/50] - Batch loss: 159.5902 - Epoch Loss: 39643.4649 - Avg Loss: 163.1418\n",
            "Epoch [12/50] - Batch loss: 165.4962 - Epoch Loss: 39808.9610 - Avg Loss: 163.1515\n",
            "Epoch [12/50] - Batch loss: 152.1448 - Epoch Loss: 39961.1059 - Avg Loss: 163.1066\n",
            "Epoch [12/50] - Batch loss: 160.4130 - Epoch Loss: 40121.5189 - Avg Loss: 163.0956\n",
            "Epoch [12/50] - Batch loss: 157.1082 - Epoch Loss: 40278.6271 - Avg Loss: 163.0714\n",
            "Epoch [12/50] - Batch loss: 155.1863 - Epoch Loss: 40433.8134 - Avg Loss: 163.0396\n",
            "Epoch [12/50] - Batch loss: 165.9715 - Epoch Loss: 40599.7849 - Avg Loss: 163.0513\n",
            "Epoch [12/50] - Batch loss: 169.5152 - Epoch Loss: 40769.3001 - Avg Loss: 163.0772\n",
            "Epoch [12/50] - Batch loss: 160.3632 - Epoch Loss: 40929.6633 - Avg Loss: 163.0664\n",
            "Epoch [12/50] - Batch loss: 161.4705 - Epoch Loss: 41091.1338 - Avg Loss: 163.0601\n",
            "Epoch [12/50] - Batch loss: 168.5652 - Epoch Loss: 41259.6990 - Avg Loss: 163.0818\n",
            "Epoch [12/50] - Batch loss: 168.8911 - Epoch Loss: 41428.5900 - Avg Loss: 163.1047\n",
            "Epoch [12/50] - Batch loss: 171.9554 - Epoch Loss: 41600.5454 - Avg Loss: 163.1394\n",
            "Epoch [12/50] - Batch loss: 162.6400 - Epoch Loss: 41763.1854 - Avg Loss: 163.1374\n",
            "Epoch [12/50] - Batch loss: 164.5411 - Epoch Loss: 41927.7265 - Avg Loss: 163.1429\n",
            "Epoch [12/50] - Batch loss: 150.5179 - Epoch Loss: 42078.2444 - Avg Loss: 163.0940\n",
            "Epoch [12/50] - Batch loss: 161.0837 - Epoch Loss: 42239.3281 - Avg Loss: 163.0862\n",
            "Epoch [12/50] - Batch loss: 158.7793 - Epoch Loss: 42398.1074 - Avg Loss: 163.0696\n",
            "Epoch [12/50] - Batch loss: 166.9894 - Epoch Loss: 42565.0968 - Avg Loss: 163.0847\n",
            "Epoch [12/50] - Batch loss: 161.0083 - Epoch Loss: 42726.1051 - Avg Loss: 163.0767\n",
            "Epoch [12/50] - Batch loss: 159.6081 - Epoch Loss: 42885.7133 - Avg Loss: 163.0635\n",
            "Epoch [12/50] - Batch loss: 157.4242 - Epoch Loss: 43043.1375 - Avg Loss: 163.0422\n",
            "Epoch [12/50] - Batch loss: 160.1309 - Epoch Loss: 43203.2684 - Avg Loss: 163.0312\n",
            "Epoch [12/50] - Batch loss: 163.6867 - Epoch Loss: 43366.9550 - Avg Loss: 163.0337\n",
            "Epoch [12/50] - Batch loss: 162.1818 - Epoch Loss: 43529.1368 - Avg Loss: 163.0305\n",
            "Epoch [12/50] - Batch loss: 160.6273 - Epoch Loss: 43689.7641 - Avg Loss: 163.0215\n",
            "Epoch [12/50] - Batch loss: 161.7081 - Epoch Loss: 43851.4721 - Avg Loss: 163.0166\n",
            "Epoch [12/50] - Batch loss: 161.3930 - Epoch Loss: 44012.8651 - Avg Loss: 163.0106\n",
            "Epoch [12/50] - Batch loss: 155.3035 - Epoch Loss: 44168.1686 - Avg Loss: 162.9822\n",
            "Epoch [12/50] - Batch loss: 157.7591 - Epoch Loss: 44325.9276 - Avg Loss: 162.9630\n",
            "Epoch [12/50] - Batch loss: 163.3849 - Epoch Loss: 44489.3126 - Avg Loss: 162.9645\n",
            "Epoch [12/50] - Batch loss: 159.7731 - Epoch Loss: 44649.0857 - Avg Loss: 162.9529\n",
            "Epoch [12/50] - Batch loss: 165.2785 - Epoch Loss: 44814.3642 - Avg Loss: 162.9613\n",
            "Epoch [12/50] - Batch loss: 160.3826 - Epoch Loss: 44974.7468 - Avg Loss: 162.9520\n",
            "Epoch [12/50] - Batch loss: 163.6845 - Epoch Loss: 45138.4313 - Avg Loss: 162.9546\n",
            "Epoch [12/50] - Batch loss: 165.1548 - Epoch Loss: 45303.5861 - Avg Loss: 162.9625\n",
            "Epoch [12/50] - Batch loss: 160.7428 - Epoch Loss: 45464.3289 - Avg Loss: 162.9546\n",
            "Epoch [12/50] - Batch loss: 163.8314 - Epoch Loss: 45628.1604 - Avg Loss: 162.9577\n",
            "Epoch [12/50] - Batch loss: 159.5957 - Epoch Loss: 45787.7560 - Avg Loss: 162.9458\n",
            "Epoch [12/50] - Batch loss: 161.0385 - Epoch Loss: 45948.7946 - Avg Loss: 162.9390\n",
            "Epoch [12/50] - Batch loss: 158.1273 - Epoch Loss: 46106.9218 - Avg Loss: 162.9220\n",
            "Epoch [12/50] - Batch loss: 159.2251 - Epoch Loss: 46266.1470 - Avg Loss: 162.9090\n",
            "Epoch [12/50] - Batch loss: 157.2930 - Epoch Loss: 46423.4400 - Avg Loss: 162.8893\n",
            "Epoch [12/50] - Batch loss: 170.6804 - Epoch Loss: 46594.1204 - Avg Loss: 162.9165\n",
            "Epoch [12/50] - Batch loss: 167.8025 - Epoch Loss: 46761.9229 - Avg Loss: 162.9335\n",
            "Epoch [12/50] - Batch loss: 164.4035 - Epoch Loss: 46926.3264 - Avg Loss: 162.9386\n",
            "Epoch [12/50] - Batch loss: 158.4533 - Epoch Loss: 47084.7798 - Avg Loss: 162.9231\n",
            "Epoch [12/50] - Batch loss: 159.4191 - Epoch Loss: 47244.1989 - Avg Loss: 162.9110\n",
            "Epoch [12/50] - Batch loss: 167.8176 - Epoch Loss: 47412.0165 - Avg Loss: 162.9279\n",
            "Epoch [12/50] - Batch loss: 157.1228 - Epoch Loss: 47569.1393 - Avg Loss: 162.9080\n",
            "Epoch [12/50] - Batch loss: 156.6315 - Epoch Loss: 47725.7708 - Avg Loss: 162.8866\n",
            "Epoch [12/50] - Batch loss: 171.3522 - Epoch Loss: 47897.1231 - Avg Loss: 162.9154\n",
            "Epoch [12/50] - Batch loss: 161.9120 - Epoch Loss: 48059.0350 - Avg Loss: 162.9120\n",
            "Epoch [12/50] - Batch loss: 166.2695 - Epoch Loss: 48225.3046 - Avg Loss: 162.9233\n",
            "Epoch [12/50] - Batch loss: 161.4076 - Epoch Loss: 48386.7122 - Avg Loss: 162.9182\n",
            "Epoch [12/50] - Batch loss: 161.8490 - Epoch Loss: 48548.5611 - Avg Loss: 162.9146\n",
            "Epoch [12/50] - Batch loss: 165.8548 - Epoch Loss: 48714.4159 - Avg Loss: 162.9245\n",
            "Epoch [12/50] - Batch loss: 159.9050 - Epoch Loss: 48874.3209 - Avg Loss: 162.9144\n",
            "Epoch [12/50] - Batch loss: 158.3376 - Epoch Loss: 49032.6584 - Avg Loss: 162.8992\n",
            "Epoch [12/50] - Batch loss: 176.7652 - Epoch Loss: 49209.4236 - Avg Loss: 162.9451\n",
            "Epoch [12/50] - Batch loss: 165.5758 - Epoch Loss: 49374.9994 - Avg Loss: 162.9538\n",
            "Epoch [12/50] - Batch loss: 166.3808 - Epoch Loss: 49541.3802 - Avg Loss: 162.9651\n",
            "Epoch [12/50] - Batch loss: 165.6037 - Epoch Loss: 49706.9838 - Avg Loss: 162.9737\n",
            "Epoch [12/50] - Batch loss: 157.1588 - Epoch Loss: 49864.1426 - Avg Loss: 162.9547\n",
            "Epoch [12/50] - Batch loss: 163.2859 - Epoch Loss: 50027.4285 - Avg Loss: 162.9558\n",
            "Epoch [12/50] - Batch loss: 158.7509 - Epoch Loss: 50186.1794 - Avg Loss: 162.9421\n",
            "Epoch [12/50] - Batch loss: 155.8377 - Epoch Loss: 50342.0171 - Avg Loss: 162.9191\n",
            "Epoch [12/50] - Batch loss: 170.8617 - Epoch Loss: 50512.8788 - Avg Loss: 162.9448\n",
            "Epoch [12/50] - Batch loss: 159.2194 - Epoch Loss: 50672.0983 - Avg Loss: 162.9328\n",
            "Epoch [12/50] - Batch loss: 165.5859 - Epoch Loss: 50837.6842 - Avg Loss: 162.9413\n",
            "Epoch [12/50] - Batch loss: 161.6133 - Epoch Loss: 50999.2975 - Avg Loss: 162.9371\n",
            "Epoch [12/50] - Batch loss: 163.4578 - Epoch Loss: 51162.7553 - Avg Loss: 162.9387\n",
            "Epoch [12/50] - Batch loss: 168.3315 - Epoch Loss: 51331.0868 - Avg Loss: 162.9558\n",
            "Epoch [12/50] - Batch loss: 159.3169 - Epoch Loss: 51490.4037 - Avg Loss: 162.9443\n",
            "Epoch [12/50] - Batch loss: 161.1510 - Epoch Loss: 51651.5547 - Avg Loss: 162.9387\n",
            "Epoch [12/50] - Batch loss: 159.5465 - Epoch Loss: 51811.1012 - Avg Loss: 162.9280\n",
            "Epoch [12/50] - Batch loss: 158.7145 - Epoch Loss: 51969.8156 - Avg Loss: 162.9148\n",
            "Epoch [12/50] - Batch loss: 162.3230 - Epoch Loss: 52132.1386 - Avg Loss: 162.9129\n",
            "Epoch [12/50] - Batch loss: 165.5493 - Epoch Loss: 52297.6879 - Avg Loss: 162.9211\n",
            "Epoch [12/50] - Batch loss: 165.0571 - Epoch Loss: 52462.7451 - Avg Loss: 162.9278\n",
            "Epoch [12/50] - Batch loss: 156.9601 - Epoch Loss: 52619.7052 - Avg Loss: 162.9093\n",
            "Epoch [12/50] - Batch loss: 165.4147 - Epoch Loss: 52785.1199 - Avg Loss: 162.9170\n",
            "Epoch [12/50] - Batch loss: 163.6441 - Epoch Loss: 52948.7640 - Avg Loss: 162.9193\n",
            "Epoch [12/50] - Batch loss: 149.4679 - Epoch Loss: 53098.2319 - Avg Loss: 162.8780\n",
            "Epoch [12/50] - Batch loss: 164.3879 - Epoch Loss: 53262.6199 - Avg Loss: 162.8826\n",
            "Epoch [12/50] - Batch loss: 166.8057 - Epoch Loss: 53429.4256 - Avg Loss: 162.8946\n",
            "Epoch [12/50] - Batch loss: 162.4667 - Epoch Loss: 53591.8923 - Avg Loss: 162.8933\n",
            "Epoch [12/50] - Batch loss: 157.5208 - Epoch Loss: 53749.4131 - Avg Loss: 162.8770\n",
            "Epoch [12/50] - Batch loss: 157.3495 - Epoch Loss: 53906.7626 - Avg Loss: 162.8603\n",
            "Epoch [12/50] - Batch loss: 162.6304 - Epoch Loss: 54069.3930 - Avg Loss: 162.8596\n",
            "Epoch [12/50] - Batch loss: 173.8206 - Epoch Loss: 54243.2136 - Avg Loss: 162.8925\n",
            "Epoch [12/50] - Batch loss: 159.2820 - Epoch Loss: 54402.4956 - Avg Loss: 162.8817\n",
            "Epoch [12/50] - Batch loss: 164.9086 - Epoch Loss: 54567.4042 - Avg Loss: 162.8878\n",
            "Epoch [12/50] - Batch loss: 161.4887 - Epoch Loss: 54728.8929 - Avg Loss: 162.8836\n",
            "Epoch [12/50] - Batch loss: 156.9246 - Epoch Loss: 54885.8175 - Avg Loss: 162.8659\n",
            "Epoch [12/50] - Batch loss: 167.0559 - Epoch Loss: 55052.8734 - Avg Loss: 162.8783\n",
            "Epoch [12/50] - Batch loss: 161.6835 - Epoch Loss: 55214.5569 - Avg Loss: 162.8748\n",
            "Epoch [12/50] - Batch loss: 162.1837 - Epoch Loss: 55376.7406 - Avg Loss: 162.8728\n",
            "Epoch [12/50] - Batch loss: 159.8586 - Epoch Loss: 55536.5992 - Avg Loss: 162.8639\n",
            "Epoch [12/50] - Batch loss: 154.3806 - Epoch Loss: 55690.9798 - Avg Loss: 162.8391\n",
            "Epoch [12/50] - Batch loss: 158.9398 - Epoch Loss: 55849.9195 - Avg Loss: 162.8278\n",
            "Epoch [12/50] - Batch loss: 161.8119 - Epoch Loss: 56011.7314 - Avg Loss: 162.8248\n",
            "Epoch [12/50] - Batch loss: 167.0114 - Epoch Loss: 56178.7428 - Avg Loss: 162.8369\n",
            "Epoch [12/50] - Batch loss: 158.4921 - Epoch Loss: 56337.2349 - Avg Loss: 162.8244\n",
            "Epoch [12/50] - Batch loss: 159.2133 - Epoch Loss: 56496.4482 - Avg Loss: 162.8140\n",
            "Epoch [12/50] - Batch loss: 165.1646 - Epoch Loss: 56661.6128 - Avg Loss: 162.8207\n",
            "Epoch [12/50] - Batch loss: 161.9476 - Epoch Loss: 56823.5605 - Avg Loss: 162.8182\n",
            "Epoch [12/50] - Batch loss: 163.5589 - Epoch Loss: 56987.1194 - Avg Loss: 162.8203\n",
            "Epoch [12/50] - Batch loss: 167.8993 - Epoch Loss: 57155.0187 - Avg Loss: 162.8348\n",
            "Epoch [12/50] - Batch loss: 168.1630 - Epoch Loss: 57323.1817 - Avg Loss: 162.8499\n",
            "Epoch [12/50] - Batch loss: 159.0863 - Epoch Loss: 57482.2680 - Avg Loss: 162.8393\n",
            "Epoch [12/50] - Batch loss: 163.7111 - Epoch Loss: 57645.9790 - Avg Loss: 162.8417\n",
            "Epoch [12/50] - Batch loss: 161.7238 - Epoch Loss: 57807.7029 - Avg Loss: 162.8386\n",
            "Epoch [12/50] - Batch loss: 160.3479 - Epoch Loss: 57968.0507 - Avg Loss: 162.8316\n",
            "Epoch [12/50] - Batch loss: 163.5884 - Epoch Loss: 58131.6391 - Avg Loss: 162.8337\n",
            "Epoch [12/50] - Batch loss: 157.1539 - Epoch Loss: 58288.7930 - Avg Loss: 162.8179\n",
            "Epoch [12/50] - Batch loss: 161.2474 - Epoch Loss: 58450.0404 - Avg Loss: 162.8135\n",
            "Epoch [12/50] - Batch loss: 168.6866 - Epoch Loss: 58618.7271 - Avg Loss: 162.8298\n",
            "Epoch [12/50] - Batch loss: 154.5919 - Epoch Loss: 58773.3190 - Avg Loss: 162.8070\n",
            "Epoch [12/50] - Batch loss: 166.0827 - Epoch Loss: 58939.4017 - Avg Loss: 162.8160\n",
            "Epoch [12/50] - Batch loss: 155.4583 - Epoch Loss: 59094.8600 - Avg Loss: 162.7958\n",
            "Epoch [12/50] - Batch loss: 166.2285 - Epoch Loss: 59261.0885 - Avg Loss: 162.8052\n",
            "Epoch [12/50] - Batch loss: 161.2160 - Epoch Loss: 59422.3045 - Avg Loss: 162.8008\n",
            "Epoch [12/50] - Batch loss: 157.4278 - Epoch Loss: 59579.7323 - Avg Loss: 162.7862\n",
            "Epoch [12/50] - Batch loss: 161.7052 - Epoch Loss: 59741.4375 - Avg Loss: 162.7832\n",
            "Epoch [12/50] - Batch loss: 162.1089 - Epoch Loss: 59903.5464 - Avg Loss: 162.7814\n",
            "Epoch [12/50] - Batch loss: 161.3826 - Epoch Loss: 60064.9290 - Avg Loss: 162.7776\n",
            "Epoch [12/50] - Batch loss: 166.6046 - Epoch Loss: 60231.5337 - Avg Loss: 162.7879\n",
            "Epoch [12/50] - Batch loss: 163.3275 - Epoch Loss: 60394.8612 - Avg Loss: 162.7894\n",
            "Epoch [12/50] - Batch loss: 155.3344 - Epoch Loss: 60550.1956 - Avg Loss: 162.7693\n",
            "Epoch [12/50] - Batch loss: 166.3726 - Epoch Loss: 60716.5682 - Avg Loss: 162.7790\n",
            "Epoch [12/50] - Batch loss: 161.2455 - Epoch Loss: 60877.8136 - Avg Loss: 162.7749\n",
            "Epoch [12/50] - Batch loss: 156.1662 - Epoch Loss: 61033.9799 - Avg Loss: 162.7573\n",
            "Epoch [12/50] - Batch loss: 157.8204 - Epoch Loss: 61191.8003 - Avg Loss: 162.7441\n",
            "Epoch [12/50] - Batch loss: 161.0746 - Epoch Loss: 61352.8749 - Avg Loss: 162.7397\n",
            "Epoch [12/50] - Batch loss: 159.0066 - Epoch Loss: 61511.8815 - Avg Loss: 162.7298\n",
            "Epoch [12/50] - Batch loss: 158.4116 - Epoch Loss: 61670.2931 - Avg Loss: 162.7185\n",
            "Epoch [12/50] - Batch loss: 158.3682 - Epoch Loss: 61828.6613 - Avg Loss: 162.7070\n",
            "Epoch [12/50] - Batch loss: 158.5698 - Epoch Loss: 61987.2311 - Avg Loss: 162.6961\n",
            "Epoch [12/50] - Batch loss: 160.3216 - Epoch Loss: 62147.5528 - Avg Loss: 162.6899\n",
            "Epoch [12/50] - Batch loss: 168.4019 - Epoch Loss: 62315.9547 - Avg Loss: 162.7048\n",
            "Epoch [12/50] - Batch loss: 156.1400 - Epoch Loss: 62472.0947 - Avg Loss: 162.6877\n",
            "Epoch [12/50] - Batch loss: 159.8726 - Epoch Loss: 62631.9673 - Avg Loss: 162.6804\n",
            "Epoch [12/50] - Batch loss: 169.3182 - Epoch Loss: 62801.2854 - Avg Loss: 162.6976\n",
            "Epoch [12/50] - Batch loss: 164.7076 - Epoch Loss: 62965.9931 - Avg Loss: 162.7028\n",
            "Epoch [12/50] - Batch loss: 158.3476 - Epoch Loss: 63124.3407 - Avg Loss: 162.6916\n",
            "Epoch [12/50] - Batch loss: 159.7019 - Epoch Loss: 63284.0426 - Avg Loss: 162.6839\n",
            "Epoch [12/50] - Batch loss: 169.8552 - Epoch Loss: 63453.8978 - Avg Loss: 162.7023\n",
            "Epoch [12/50] - Batch loss: 159.6523 - Epoch Loss: 63613.5500 - Avg Loss: 162.6945\n",
            "Epoch [12/50] - Batch loss: 168.6425 - Epoch Loss: 63782.1925 - Avg Loss: 162.7097\n",
            "Epoch [12/50] - Batch loss: 164.9218 - Epoch Loss: 63947.1144 - Avg Loss: 162.7153\n",
            "Epoch [12/50] - Batch loss: 163.5790 - Epoch Loss: 64110.6934 - Avg Loss: 162.7175\n",
            "Epoch [12/50] - Batch loss: 171.9966 - Epoch Loss: 64282.6900 - Avg Loss: 162.7410\n",
            "Epoch [12/50] - Batch loss: 162.8033 - Epoch Loss: 64445.4932 - Avg Loss: 162.7411\n",
            "Epoch [12/50] - Batch loss: 159.2498 - Epoch Loss: 64604.7430 - Avg Loss: 162.7324\n",
            "Epoch [12/50] - Batch loss: 163.6956 - Epoch Loss: 64768.4386 - Avg Loss: 162.7348\n",
            "Epoch [12/50] - Batch loss: 161.7086 - Epoch Loss: 64930.1472 - Avg Loss: 162.7322\n",
            "Epoch [12/50] - Batch loss: 161.6046 - Epoch Loss: 65091.7519 - Avg Loss: 162.7294\n",
            "Epoch [12/50] - Batch loss: 161.3578 - Epoch Loss: 65253.1096 - Avg Loss: 162.7260\n",
            "Epoch [12/50] - Batch loss: 161.5571 - Epoch Loss: 65414.6668 - Avg Loss: 162.7231\n",
            "Epoch [12/50] - Batch loss: 161.4355 - Epoch Loss: 65576.1023 - Avg Loss: 162.7199\n",
            "Epoch [12/50] - Batch loss: 163.6062 - Epoch Loss: 65739.7085 - Avg Loss: 162.7221\n",
            "Epoch [12/50] - Batch loss: 166.5463 - Epoch Loss: 65906.2548 - Avg Loss: 162.7315\n",
            "Epoch [12/50] - Batch loss: 164.0195 - Epoch Loss: 66070.2743 - Avg Loss: 162.7347\n",
            "Epoch [12/50] - Batch loss: 157.5670 - Epoch Loss: 66227.8413 - Avg Loss: 162.7220\n",
            "Epoch [12/50] - Batch loss: 158.3689 - Epoch Loss: 66386.2102 - Avg Loss: 162.7113\n",
            "Epoch [12/50] - Batch loss: 156.3437 - Epoch Loss: 66542.5539 - Avg Loss: 162.6957\n",
            "Epoch [12/50] - Batch loss: 154.5786 - Epoch Loss: 66697.1325 - Avg Loss: 162.6759\n",
            "Epoch [12/50] - Batch loss: 162.7870 - Epoch Loss: 66859.9195 - Avg Loss: 162.6762\n",
            "Epoch [12/50] - Batch loss: 165.9016 - Epoch Loss: 67025.8211 - Avg Loss: 162.6840\n",
            "Epoch [12/50] - Batch loss: 161.6976 - Epoch Loss: 67187.5187 - Avg Loss: 162.6816\n",
            "Epoch [12/50] - Batch loss: 159.5822 - Epoch Loss: 67347.1008 - Avg Loss: 162.6742\n",
            "Epoch [12/50] - Batch loss: 170.9473 - Epoch Loss: 67518.0481 - Avg Loss: 162.6941\n",
            "Epoch [12/50] - Batch loss: 159.5215 - Epoch Loss: 67677.5696 - Avg Loss: 162.6865\n",
            "Epoch [12/50] - Batch loss: 172.4895 - Epoch Loss: 67850.0591 - Avg Loss: 162.7100\n",
            "Epoch [12/50] - Batch loss: 156.8135 - Epoch Loss: 68006.8727 - Avg Loss: 162.6959\n",
            "Epoch [12/50] - Batch loss: 166.7990 - Epoch Loss: 68173.6716 - Avg Loss: 162.7057\n",
            "Epoch [12/50] - Batch loss: 167.1318 - Epoch Loss: 68340.8035 - Avg Loss: 162.7162\n",
            "Epoch [12/50] - Batch loss: 153.8492 - Epoch Loss: 68494.6527 - Avg Loss: 162.6951\n",
            "Epoch [12/50] - Batch loss: 163.7290 - Epoch Loss: 68658.3817 - Avg Loss: 162.6976\n",
            "Epoch [12/50] - Batch loss: 172.3924 - Epoch Loss: 68830.7741 - Avg Loss: 162.7205\n",
            "Epoch [12/50] - Batch loss: 157.9302 - Epoch Loss: 68988.7043 - Avg Loss: 162.7092\n",
            "Epoch [12/50] - Batch loss: 160.7215 - Epoch Loss: 69149.4258 - Avg Loss: 162.7045\n",
            "Epoch [12/50] - Batch loss: 154.7898 - Epoch Loss: 69304.2156 - Avg Loss: 162.6860\n",
            "Epoch [12/50] - Batch loss: 165.9753 - Epoch Loss: 69470.1909 - Avg Loss: 162.6937\n",
            "Epoch [12/50] - Batch loss: 155.9449 - Epoch Loss: 69626.1358 - Avg Loss: 162.6779\n",
            "Epoch [12/50] - Batch loss: 165.2056 - Epoch Loss: 69791.3415 - Avg Loss: 162.6838\n",
            "Epoch [12/50] - Batch loss: 164.4666 - Epoch Loss: 69955.8080 - Avg Loss: 162.6879\n",
            "Epoch [12/50] - Batch loss: 165.9068 - Epoch Loss: 70121.7148 - Avg Loss: 162.6954\n",
            "Epoch [12/50] - Batch loss: 153.8794 - Epoch Loss: 70275.5943 - Avg Loss: 162.6750\n",
            "Epoch [12/50] - Batch loss: 162.2556 - Epoch Loss: 70437.8499 - Avg Loss: 162.6740\n",
            "Epoch [12/50] - Batch loss: 155.7386 - Epoch Loss: 70593.5885 - Avg Loss: 162.6580\n",
            "Epoch [12/50] - Batch loss: 172.4560 - Epoch Loss: 70766.0445 - Avg Loss: 162.6806\n",
            "Epoch [12/50] - Batch loss: 163.7968 - Epoch Loss: 70929.8413 - Avg Loss: 162.6831\n",
            "Epoch [12/50] - Batch loss: 154.2191 - Epoch Loss: 71084.0604 - Avg Loss: 162.6638\n",
            "Epoch [12/50] - Batch loss: 155.1005 - Epoch Loss: 71239.1609 - Avg Loss: 162.6465\n",
            "Epoch [12/50] - Batch loss: 161.2317 - Epoch Loss: 71400.3926 - Avg Loss: 162.6433\n",
            "Epoch [12/50] - Batch loss: 159.9136 - Epoch Loss: 71560.3062 - Avg Loss: 162.6371\n",
            "Epoch [12/50] - Batch loss: 162.4438 - Epoch Loss: 71722.7500 - Avg Loss: 162.6366\n",
            "Epoch [12/50] - Batch loss: 160.4819 - Epoch Loss: 71883.2319 - Avg Loss: 162.6317\n",
            "Epoch [12/50] - Batch loss: 161.2519 - Epoch Loss: 72044.4839 - Avg Loss: 162.6286\n",
            "Epoch [12/50] - Batch loss: 168.2786 - Epoch Loss: 72212.7625 - Avg Loss: 162.6414\n",
            "Epoch [12/50] - Batch loss: 162.4005 - Epoch Loss: 72375.1629 - Avg Loss: 162.6408\n",
            "Epoch [12/50] - Batch loss: 154.4255 - Epoch Loss: 72529.5885 - Avg Loss: 162.6224\n",
            "Epoch [12/50] - Batch loss: 160.9511 - Epoch Loss: 72690.5396 - Avg Loss: 162.6187\n",
            "Epoch [12/50] - Batch loss: 169.5764 - Epoch Loss: 72860.1160 - Avg Loss: 162.6342\n",
            "Epoch [12/50] - Batch loss: 164.8572 - Epoch Loss: 73024.9732 - Avg Loss: 162.6391\n",
            "Epoch [12/50] - Batch loss: 160.9565 - Epoch Loss: 73185.9297 - Avg Loss: 162.6354\n",
            "Epoch [12/50] - Batch loss: 164.6635 - Epoch Loss: 73350.5932 - Avg Loss: 162.6399\n",
            "Epoch [12/50] - Batch loss: 159.6490 - Epoch Loss: 73510.2422 - Avg Loss: 162.6333\n",
            "Epoch [12/50] - Batch loss: 163.7284 - Epoch Loss: 73673.9706 - Avg Loss: 162.6357\n",
            "Epoch [12/50] - Batch loss: 161.6575 - Epoch Loss: 73835.6282 - Avg Loss: 162.6335\n",
            "Epoch [12/50] - Batch loss: 169.3357 - Epoch Loss: 74004.9639 - Avg Loss: 162.6483\n",
            "Epoch [12/50] - Batch loss: 162.6016 - Epoch Loss: 74167.5654 - Avg Loss: 162.6482\n",
            "Epoch [12/50] - Batch loss: 161.6982 - Epoch Loss: 74329.2636 - Avg Loss: 162.6461\n",
            "Epoch [12/50] - Batch loss: 158.6424 - Epoch Loss: 74487.9061 - Avg Loss: 162.6373\n",
            "Epoch [12/50] - Batch loss: 157.4923 - Epoch Loss: 74645.3984 - Avg Loss: 162.6261\n",
            "Epoch [12/50] - Batch loss: 163.2278 - Epoch Loss: 74808.6261 - Avg Loss: 162.6274\n",
            "Epoch [12/50] - Batch loss: 165.6579 - Epoch Loss: 74974.2841 - Avg Loss: 162.6340\n",
            "Epoch [12/50] - Batch loss: 166.3866 - Epoch Loss: 75140.6707 - Avg Loss: 162.6421\n",
            "Epoch [12/50] - Batch loss: 160.8987 - Epoch Loss: 75301.5693 - Avg Loss: 162.6384\n",
            "Epoch [12/50] - Batch loss: 158.4051 - Epoch Loss: 75459.9744 - Avg Loss: 162.6293\n",
            "Epoch [12/50] - Batch loss: 155.7280 - Epoch Loss: 75615.7025 - Avg Loss: 162.6144\n",
            "Epoch [12/50] - Batch loss: 165.5860 - Epoch Loss: 75781.2885 - Avg Loss: 162.6208\n",
            "Epoch [12/50] - Batch loss: 160.2757 - Epoch Loss: 75941.5641 - Avg Loss: 162.6158\n",
            "Epoch [12/50] - Batch loss: 160.8018 - Epoch Loss: 76102.3659 - Avg Loss: 162.6119\n",
            "Epoch [12/50] - Batch loss: 160.0224 - Epoch Loss: 76262.3883 - Avg Loss: 162.6064\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 13/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19e918dd4b2149818701cfaba7e9089e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/50] - Batch loss: 157.2189 - Epoch Loss: 157.2189 - Avg Loss: 157.2189\n",
            "Epoch [13/50] - Batch loss: 157.5158 - Epoch Loss: 314.7346 - Avg Loss: 157.3673\n",
            "Epoch [13/50] - Batch loss: 150.7612 - Epoch Loss: 465.4959 - Avg Loss: 155.1653\n",
            "Epoch [13/50] - Batch loss: 157.9403 - Epoch Loss: 623.4361 - Avg Loss: 155.8590\n",
            "Epoch [13/50] - Batch loss: 159.5193 - Epoch Loss: 782.9555 - Avg Loss: 156.5911\n",
            "Epoch [13/50] - Batch loss: 156.9740 - Epoch Loss: 939.9295 - Avg Loss: 156.6549\n",
            "Epoch [13/50] - Batch loss: 152.0229 - Epoch Loss: 1091.9524 - Avg Loss: 155.9932\n",
            "Epoch [13/50] - Batch loss: 165.0443 - Epoch Loss: 1256.9966 - Avg Loss: 157.1246\n",
            "Epoch [13/50] - Batch loss: 157.7363 - Epoch Loss: 1414.7330 - Avg Loss: 157.1926\n",
            "Epoch [13/50] - Batch loss: 161.6823 - Epoch Loss: 1576.4152 - Avg Loss: 157.6415\n",
            "Epoch [13/50] - Batch loss: 163.5691 - Epoch Loss: 1739.9843 - Avg Loss: 158.1804\n",
            "Epoch [13/50] - Batch loss: 155.3678 - Epoch Loss: 1895.3522 - Avg Loss: 157.9460\n",
            "Epoch [13/50] - Batch loss: 160.1325 - Epoch Loss: 2055.4847 - Avg Loss: 158.1142\n",
            "Epoch [13/50] - Batch loss: 155.4279 - Epoch Loss: 2210.9126 - Avg Loss: 157.9223\n",
            "Epoch [13/50] - Batch loss: 157.0350 - Epoch Loss: 2367.9476 - Avg Loss: 157.8632\n",
            "Epoch [13/50] - Batch loss: 159.7663 - Epoch Loss: 2527.7140 - Avg Loss: 157.9821\n",
            "Epoch [13/50] - Batch loss: 163.3368 - Epoch Loss: 2691.0507 - Avg Loss: 158.2971\n",
            "Epoch [13/50] - Batch loss: 161.0654 - Epoch Loss: 2852.1161 - Avg Loss: 158.4509\n",
            "Epoch [13/50] - Batch loss: 161.5622 - Epoch Loss: 3013.6783 - Avg Loss: 158.6146\n",
            "Epoch [13/50] - Batch loss: 162.6541 - Epoch Loss: 3176.3324 - Avg Loss: 158.8166\n",
            "Epoch [13/50] - Batch loss: 165.8861 - Epoch Loss: 3342.2185 - Avg Loss: 159.1533\n",
            "Epoch [13/50] - Batch loss: 154.4760 - Epoch Loss: 3496.6945 - Avg Loss: 158.9407\n",
            "Epoch [13/50] - Batch loss: 160.6824 - Epoch Loss: 3657.3769 - Avg Loss: 159.0164\n",
            "Epoch [13/50] - Batch loss: 162.8828 - Epoch Loss: 3820.2597 - Avg Loss: 159.1775\n",
            "Epoch [13/50] - Batch loss: 162.5588 - Epoch Loss: 3982.8186 - Avg Loss: 159.3127\n",
            "Epoch [13/50] - Batch loss: 168.0679 - Epoch Loss: 4150.8865 - Avg Loss: 159.6495\n",
            "Epoch [13/50] - Batch loss: 166.8982 - Epoch Loss: 4317.7847 - Avg Loss: 159.9180\n",
            "Epoch [13/50] - Batch loss: 168.5309 - Epoch Loss: 4486.3156 - Avg Loss: 160.2256\n",
            "Epoch [13/50] - Batch loss: 153.5297 - Epoch Loss: 4639.8453 - Avg Loss: 159.9947\n",
            "Epoch [13/50] - Batch loss: 160.5896 - Epoch Loss: 4800.4349 - Avg Loss: 160.0145\n",
            "Epoch [13/50] - Batch loss: 159.1213 - Epoch Loss: 4959.5562 - Avg Loss: 159.9857\n",
            "Epoch [13/50] - Batch loss: 162.1179 - Epoch Loss: 5121.6741 - Avg Loss: 160.0523\n",
            "Epoch [13/50] - Batch loss: 157.7707 - Epoch Loss: 5279.4448 - Avg Loss: 159.9832\n",
            "Epoch [13/50] - Batch loss: 167.1389 - Epoch Loss: 5446.5837 - Avg Loss: 160.1936\n",
            "Epoch [13/50] - Batch loss: 158.8389 - Epoch Loss: 5605.4226 - Avg Loss: 160.1549\n",
            "Epoch [13/50] - Batch loss: 160.8403 - Epoch Loss: 5766.2629 - Avg Loss: 160.1740\n",
            "Epoch [13/50] - Batch loss: 166.5350 - Epoch Loss: 5932.7979 - Avg Loss: 160.3459\n",
            "Epoch [13/50] - Batch loss: 165.1145 - Epoch Loss: 6097.9123 - Avg Loss: 160.4714\n",
            "Epoch [13/50] - Batch loss: 169.9793 - Epoch Loss: 6267.8916 - Avg Loss: 160.7152\n",
            "Epoch [13/50] - Batch loss: 157.1887 - Epoch Loss: 6425.0803 - Avg Loss: 160.6270\n",
            "Epoch [13/50] - Batch loss: 162.7489 - Epoch Loss: 6587.8292 - Avg Loss: 160.6788\n",
            "Epoch [13/50] - Batch loss: 157.8749 - Epoch Loss: 6745.7041 - Avg Loss: 160.6120\n",
            "Epoch [13/50] - Batch loss: 167.6749 - Epoch Loss: 6913.3790 - Avg Loss: 160.7763\n",
            "Epoch [13/50] - Batch loss: 167.3556 - Epoch Loss: 7080.7346 - Avg Loss: 160.9258\n",
            "Epoch [13/50] - Batch loss: 168.6744 - Epoch Loss: 7249.4089 - Avg Loss: 161.0980\n",
            "Epoch [13/50] - Batch loss: 157.1508 - Epoch Loss: 7406.5597 - Avg Loss: 161.0122\n",
            "Epoch [13/50] - Batch loss: 158.1457 - Epoch Loss: 7564.7054 - Avg Loss: 160.9512\n",
            "Epoch [13/50] - Batch loss: 167.1417 - Epoch Loss: 7731.8471 - Avg Loss: 161.0801\n",
            "Epoch [13/50] - Batch loss: 167.3418 - Epoch Loss: 7899.1889 - Avg Loss: 161.2079\n",
            "Epoch [13/50] - Batch loss: 164.4271 - Epoch Loss: 8063.6159 - Avg Loss: 161.2723\n",
            "Epoch [13/50] - Batch loss: 156.0500 - Epoch Loss: 8219.6659 - Avg Loss: 161.1699\n",
            "Epoch [13/50] - Batch loss: 162.2333 - Epoch Loss: 8381.8992 - Avg Loss: 161.1904\n",
            "Epoch [13/50] - Batch loss: 163.9528 - Epoch Loss: 8545.8520 - Avg Loss: 161.2425\n",
            "Epoch [13/50] - Batch loss: 157.4882 - Epoch Loss: 8703.3402 - Avg Loss: 161.1730\n",
            "Epoch [13/50] - Batch loss: 164.3102 - Epoch Loss: 8867.6504 - Avg Loss: 161.2300\n",
            "Epoch [13/50] - Batch loss: 163.5869 - Epoch Loss: 9031.2373 - Avg Loss: 161.2721\n",
            "Epoch [13/50] - Batch loss: 164.6163 - Epoch Loss: 9195.8536 - Avg Loss: 161.3308\n",
            "Epoch [13/50] - Batch loss: 165.6828 - Epoch Loss: 9361.5364 - Avg Loss: 161.4058\n",
            "Epoch [13/50] - Batch loss: 154.8412 - Epoch Loss: 9516.3776 - Avg Loss: 161.2945\n",
            "Epoch [13/50] - Batch loss: 160.1180 - Epoch Loss: 9676.4956 - Avg Loss: 161.2749\n",
            "Epoch [13/50] - Batch loss: 162.8005 - Epoch Loss: 9839.2961 - Avg Loss: 161.2999\n",
            "Epoch [13/50] - Batch loss: 164.1160 - Epoch Loss: 10003.4120 - Avg Loss: 161.3454\n",
            "Epoch [13/50] - Batch loss: 162.3511 - Epoch Loss: 10165.7631 - Avg Loss: 161.3613\n",
            "Epoch [13/50] - Batch loss: 155.7688 - Epoch Loss: 10321.5319 - Avg Loss: 161.2739\n",
            "Epoch [13/50] - Batch loss: 158.2634 - Epoch Loss: 10479.7953 - Avg Loss: 161.2276\n",
            "Epoch [13/50] - Batch loss: 163.0860 - Epoch Loss: 10642.8812 - Avg Loss: 161.2558\n",
            "Epoch [13/50] - Batch loss: 160.0977 - Epoch Loss: 10802.9789 - Avg Loss: 161.2385\n",
            "Epoch [13/50] - Batch loss: 160.0114 - Epoch Loss: 10962.9903 - Avg Loss: 161.2204\n",
            "Epoch [13/50] - Batch loss: 161.9772 - Epoch Loss: 11124.9675 - Avg Loss: 161.2314\n",
            "Epoch [13/50] - Batch loss: 164.8208 - Epoch Loss: 11289.7883 - Avg Loss: 161.2827\n",
            "Epoch [13/50] - Batch loss: 172.1309 - Epoch Loss: 11461.9192 - Avg Loss: 161.4355\n",
            "Epoch [13/50] - Batch loss: 162.0537 - Epoch Loss: 11623.9729 - Avg Loss: 161.4441\n",
            "Epoch [13/50] - Batch loss: 161.5474 - Epoch Loss: 11785.5203 - Avg Loss: 161.4455\n",
            "Epoch [13/50] - Batch loss: 165.4217 - Epoch Loss: 11950.9420 - Avg Loss: 161.4992\n",
            "Epoch [13/50] - Batch loss: 162.9485 - Epoch Loss: 12113.8905 - Avg Loss: 161.5185\n",
            "Epoch [13/50] - Batch loss: 167.1779 - Epoch Loss: 12281.0683 - Avg Loss: 161.5930\n",
            "Epoch [13/50] - Batch loss: 159.3818 - Epoch Loss: 12440.4502 - Avg Loss: 161.5643\n",
            "Epoch [13/50] - Batch loss: 155.8452 - Epoch Loss: 12596.2954 - Avg Loss: 161.4910\n",
            "Epoch [13/50] - Batch loss: 165.6353 - Epoch Loss: 12761.9306 - Avg Loss: 161.5434\n",
            "Epoch [13/50] - Batch loss: 147.5916 - Epoch Loss: 12909.5223 - Avg Loss: 161.3690\n",
            "Epoch [13/50] - Batch loss: 155.1205 - Epoch Loss: 13064.6427 - Avg Loss: 161.2919\n",
            "Epoch [13/50] - Batch loss: 161.4944 - Epoch Loss: 13226.1372 - Avg Loss: 161.2944\n",
            "Epoch [13/50] - Batch loss: 171.7118 - Epoch Loss: 13397.8490 - Avg Loss: 161.4199\n",
            "Epoch [13/50] - Batch loss: 162.7105 - Epoch Loss: 13560.5595 - Avg Loss: 161.4352\n",
            "Epoch [13/50] - Batch loss: 166.5540 - Epoch Loss: 13727.1135 - Avg Loss: 161.4955\n",
            "Epoch [13/50] - Batch loss: 160.0542 - Epoch Loss: 13887.1677 - Avg Loss: 161.4787\n",
            "Epoch [13/50] - Batch loss: 162.5210 - Epoch Loss: 14049.6888 - Avg Loss: 161.4907\n",
            "Epoch [13/50] - Batch loss: 161.2640 - Epoch Loss: 14210.9528 - Avg Loss: 161.4881\n",
            "Epoch [13/50] - Batch loss: 157.3519 - Epoch Loss: 14368.3047 - Avg Loss: 161.4416\n",
            "Epoch [13/50] - Batch loss: 158.9775 - Epoch Loss: 14527.2822 - Avg Loss: 161.4142\n",
            "Epoch [13/50] - Batch loss: 154.3226 - Epoch Loss: 14681.6048 - Avg Loss: 161.3363\n",
            "Epoch [13/50] - Batch loss: 157.3609 - Epoch Loss: 14838.9656 - Avg Loss: 161.2931\n",
            "Epoch [13/50] - Batch loss: 158.7893 - Epoch Loss: 14997.7549 - Avg Loss: 161.2662\n",
            "Epoch [13/50] - Batch loss: 166.7425 - Epoch Loss: 15164.4974 - Avg Loss: 161.3244\n",
            "Epoch [13/50] - Batch loss: 166.9046 - Epoch Loss: 15331.4020 - Avg Loss: 161.3832\n",
            "Epoch [13/50] - Batch loss: 166.1396 - Epoch Loss: 15497.5416 - Avg Loss: 161.4327\n",
            "Epoch [13/50] - Batch loss: 162.4169 - Epoch Loss: 15659.9585 - Avg Loss: 161.4429\n",
            "Epoch [13/50] - Batch loss: 166.3307 - Epoch Loss: 15826.2892 - Avg Loss: 161.4927\n",
            "Epoch [13/50] - Batch loss: 161.1672 - Epoch Loss: 15987.4564 - Avg Loss: 161.4895\n",
            "Epoch [13/50] - Batch loss: 154.9553 - Epoch Loss: 16142.4117 - Avg Loss: 161.4241\n",
            "Epoch [13/50] - Batch loss: 166.5864 - Epoch Loss: 16308.9980 - Avg Loss: 161.4752\n",
            "Epoch [13/50] - Batch loss: 165.2953 - Epoch Loss: 16474.2934 - Avg Loss: 161.5127\n",
            "Epoch [13/50] - Batch loss: 169.1561 - Epoch Loss: 16643.4495 - Avg Loss: 161.5869\n",
            "Epoch [13/50] - Batch loss: 165.3495 - Epoch Loss: 16808.7990 - Avg Loss: 161.6231\n",
            "Epoch [13/50] - Batch loss: 168.3694 - Epoch Loss: 16977.1685 - Avg Loss: 161.6873\n",
            "Epoch [13/50] - Batch loss: 163.5875 - Epoch Loss: 17140.7560 - Avg Loss: 161.7052\n",
            "Epoch [13/50] - Batch loss: 158.7249 - Epoch Loss: 17299.4809 - Avg Loss: 161.6774\n",
            "Epoch [13/50] - Batch loss: 164.1850 - Epoch Loss: 17463.6658 - Avg Loss: 161.7006\n",
            "Epoch [13/50] - Batch loss: 164.9088 - Epoch Loss: 17628.5746 - Avg Loss: 161.7300\n",
            "Epoch [13/50] - Batch loss: 155.3578 - Epoch Loss: 17783.9324 - Avg Loss: 161.6721\n",
            "Epoch [13/50] - Batch loss: 158.5137 - Epoch Loss: 17942.4461 - Avg Loss: 161.6437\n",
            "Epoch [13/50] - Batch loss: 162.7773 - Epoch Loss: 18105.2234 - Avg Loss: 161.6538\n",
            "Epoch [13/50] - Batch loss: 163.0428 - Epoch Loss: 18268.2662 - Avg Loss: 161.6661\n",
            "Epoch [13/50] - Batch loss: 162.4722 - Epoch Loss: 18430.7384 - Avg Loss: 161.6731\n",
            "Epoch [13/50] - Batch loss: 155.1397 - Epoch Loss: 18585.8781 - Avg Loss: 161.6163\n",
            "Epoch [13/50] - Batch loss: 163.7255 - Epoch Loss: 18749.6036 - Avg Loss: 161.6345\n",
            "Epoch [13/50] - Batch loss: 164.5090 - Epoch Loss: 18914.1126 - Avg Loss: 161.6591\n",
            "Epoch [13/50] - Batch loss: 163.0556 - Epoch Loss: 19077.1682 - Avg Loss: 161.6709\n",
            "Epoch [13/50] - Batch loss: 165.6120 - Epoch Loss: 19242.7803 - Avg Loss: 161.7040\n",
            "Epoch [13/50] - Batch loss: 158.7009 - Epoch Loss: 19401.4812 - Avg Loss: 161.6790\n",
            "Epoch [13/50] - Batch loss: 167.6115 - Epoch Loss: 19569.0927 - Avg Loss: 161.7280\n",
            "Epoch [13/50] - Batch loss: 171.6772 - Epoch Loss: 19740.7700 - Avg Loss: 161.8096\n",
            "Epoch [13/50] - Batch loss: 164.2001 - Epoch Loss: 19904.9700 - Avg Loss: 161.8290\n",
            "Epoch [13/50] - Batch loss: 159.4025 - Epoch Loss: 20064.3726 - Avg Loss: 161.8095\n",
            "Epoch [13/50] - Batch loss: 161.0211 - Epoch Loss: 20225.3936 - Avg Loss: 161.8031\n",
            "Epoch [13/50] - Batch loss: 162.4958 - Epoch Loss: 20387.8894 - Avg Loss: 161.8086\n",
            "Epoch [13/50] - Batch loss: 163.8246 - Epoch Loss: 20551.7140 - Avg Loss: 161.8245\n",
            "Epoch [13/50] - Batch loss: 164.3582 - Epoch Loss: 20716.0722 - Avg Loss: 161.8443\n",
            "Epoch [13/50] - Batch loss: 153.4398 - Epoch Loss: 20869.5120 - Avg Loss: 161.7792\n",
            "Epoch [13/50] - Batch loss: 165.2592 - Epoch Loss: 21034.7712 - Avg Loss: 161.8059\n",
            "Epoch [13/50] - Batch loss: 162.5080 - Epoch Loss: 21197.2792 - Avg Loss: 161.8113\n",
            "Epoch [13/50] - Batch loss: 157.6166 - Epoch Loss: 21354.8958 - Avg Loss: 161.7795\n",
            "Epoch [13/50] - Batch loss: 151.8809 - Epoch Loss: 21506.7767 - Avg Loss: 161.7051\n",
            "Epoch [13/50] - Batch loss: 166.6940 - Epoch Loss: 21673.4707 - Avg Loss: 161.7423\n",
            "Epoch [13/50] - Batch loss: 161.7162 - Epoch Loss: 21835.1870 - Avg Loss: 161.7421\n",
            "Epoch [13/50] - Batch loss: 168.6391 - Epoch Loss: 22003.8261 - Avg Loss: 161.7928\n",
            "Epoch [13/50] - Batch loss: 167.4985 - Epoch Loss: 22171.3245 - Avg Loss: 161.8345\n",
            "Epoch [13/50] - Batch loss: 164.5919 - Epoch Loss: 22335.9164 - Avg Loss: 161.8545\n",
            "Epoch [13/50] - Batch loss: 154.3907 - Epoch Loss: 22490.3072 - Avg Loss: 161.8008\n",
            "Epoch [13/50] - Batch loss: 164.0405 - Epoch Loss: 22654.3476 - Avg Loss: 161.8168\n",
            "Epoch [13/50] - Batch loss: 159.3757 - Epoch Loss: 22813.7234 - Avg Loss: 161.7995\n",
            "Epoch [13/50] - Batch loss: 170.7328 - Epoch Loss: 22984.4562 - Avg Loss: 161.8624\n",
            "Epoch [13/50] - Batch loss: 152.7493 - Epoch Loss: 23137.2055 - Avg Loss: 161.7986\n",
            "Epoch [13/50] - Batch loss: 154.9035 - Epoch Loss: 23292.1089 - Avg Loss: 161.7508\n",
            "Epoch [13/50] - Batch loss: 166.9352 - Epoch Loss: 23459.0441 - Avg Loss: 161.7865\n",
            "Epoch [13/50] - Batch loss: 165.3392 - Epoch Loss: 23624.3833 - Avg Loss: 161.8108\n",
            "Epoch [13/50] - Batch loss: 159.0891 - Epoch Loss: 23783.4725 - Avg Loss: 161.7923\n",
            "Epoch [13/50] - Batch loss: 167.0096 - Epoch Loss: 23950.4820 - Avg Loss: 161.8276\n",
            "Epoch [13/50] - Batch loss: 166.0275 - Epoch Loss: 24116.5096 - Avg Loss: 161.8558\n",
            "Epoch [13/50] - Batch loss: 161.6110 - Epoch Loss: 24278.1206 - Avg Loss: 161.8541\n",
            "Epoch [13/50] - Batch loss: 165.0243 - Epoch Loss: 24443.1449 - Avg Loss: 161.8751\n",
            "Epoch [13/50] - Batch loss: 162.8169 - Epoch Loss: 24605.9618 - Avg Loss: 161.8813\n",
            "Epoch [13/50] - Batch loss: 164.7599 - Epoch Loss: 24770.7217 - Avg Loss: 161.9001\n",
            "Epoch [13/50] - Batch loss: 163.0843 - Epoch Loss: 24933.8060 - Avg Loss: 161.9078\n",
            "Epoch [13/50] - Batch loss: 156.1901 - Epoch Loss: 25089.9960 - Avg Loss: 161.8709\n",
            "Epoch [13/50] - Batch loss: 159.9792 - Epoch Loss: 25249.9753 - Avg Loss: 161.8588\n",
            "Epoch [13/50] - Batch loss: 156.2377 - Epoch Loss: 25406.2130 - Avg Loss: 161.8230\n",
            "Epoch [13/50] - Batch loss: 163.5108 - Epoch Loss: 25569.7237 - Avg Loss: 161.8337\n",
            "Epoch [13/50] - Batch loss: 163.0798 - Epoch Loss: 25732.8035 - Avg Loss: 161.8415\n",
            "Epoch [13/50] - Batch loss: 165.7344 - Epoch Loss: 25898.5379 - Avg Loss: 161.8659\n",
            "Epoch [13/50] - Batch loss: 162.8751 - Epoch Loss: 26061.4130 - Avg Loss: 161.8721\n",
            "Epoch [13/50] - Batch loss: 158.7588 - Epoch Loss: 26220.1719 - Avg Loss: 161.8529\n",
            "Epoch [13/50] - Batch loss: 154.6267 - Epoch Loss: 26374.7986 - Avg Loss: 161.8086\n",
            "Epoch [13/50] - Batch loss: 160.4968 - Epoch Loss: 26535.2954 - Avg Loss: 161.8006\n",
            "Epoch [13/50] - Batch loss: 162.2327 - Epoch Loss: 26697.5281 - Avg Loss: 161.8032\n",
            "Epoch [13/50] - Batch loss: 167.2304 - Epoch Loss: 26864.7585 - Avg Loss: 161.8359\n",
            "Epoch [13/50] - Batch loss: 167.5426 - Epoch Loss: 27032.3011 - Avg Loss: 161.8701\n",
            "Epoch [13/50] - Batch loss: 169.3387 - Epoch Loss: 27201.6398 - Avg Loss: 161.9145\n",
            "Epoch [13/50] - Batch loss: 163.1690 - Epoch Loss: 27364.8088 - Avg Loss: 161.9219\n",
            "Epoch [13/50] - Batch loss: 164.3920 - Epoch Loss: 27529.2008 - Avg Loss: 161.9365\n",
            "Epoch [13/50] - Batch loss: 164.4155 - Epoch Loss: 27693.6163 - Avg Loss: 161.9510\n",
            "Epoch [13/50] - Batch loss: 164.1044 - Epoch Loss: 27857.7207 - Avg Loss: 161.9635\n",
            "Epoch [13/50] - Batch loss: 156.8750 - Epoch Loss: 28014.5958 - Avg Loss: 161.9341\n",
            "Epoch [13/50] - Batch loss: 157.4766 - Epoch Loss: 28172.0724 - Avg Loss: 161.9085\n",
            "Epoch [13/50] - Batch loss: 164.0981 - Epoch Loss: 28336.1705 - Avg Loss: 161.9210\n",
            "Epoch [13/50] - Batch loss: 172.0069 - Epoch Loss: 28508.1774 - Avg Loss: 161.9783\n",
            "Epoch [13/50] - Batch loss: 159.0852 - Epoch Loss: 28667.2626 - Avg Loss: 161.9619\n",
            "Epoch [13/50] - Batch loss: 155.5890 - Epoch Loss: 28822.8516 - Avg Loss: 161.9261\n",
            "Epoch [13/50] - Batch loss: 163.1168 - Epoch Loss: 28985.9684 - Avg Loss: 161.9328\n",
            "Epoch [13/50] - Batch loss: 162.9348 - Epoch Loss: 29148.9031 - Avg Loss: 161.9384\n",
            "Epoch [13/50] - Batch loss: 163.9276 - Epoch Loss: 29312.8307 - Avg Loss: 161.9493\n",
            "Epoch [13/50] - Batch loss: 157.6863 - Epoch Loss: 29470.5170 - Avg Loss: 161.9259\n",
            "Epoch [13/50] - Batch loss: 151.8797 - Epoch Loss: 29622.3967 - Avg Loss: 161.8710\n",
            "Epoch [13/50] - Batch loss: 156.2584 - Epoch Loss: 29778.6551 - Avg Loss: 161.8405\n",
            "Epoch [13/50] - Batch loss: 160.6191 - Epoch Loss: 29939.2742 - Avg Loss: 161.8339\n",
            "Epoch [13/50] - Batch loss: 162.1614 - Epoch Loss: 30101.4356 - Avg Loss: 161.8357\n",
            "Epoch [13/50] - Batch loss: 163.9755 - Epoch Loss: 30265.4111 - Avg Loss: 161.8471\n",
            "Epoch [13/50] - Batch loss: 167.6368 - Epoch Loss: 30433.0479 - Avg Loss: 161.8779\n",
            "Epoch [13/50] - Batch loss: 153.0739 - Epoch Loss: 30586.1218 - Avg Loss: 161.8313\n",
            "Epoch [13/50] - Batch loss: 162.8937 - Epoch Loss: 30749.0155 - Avg Loss: 161.8369\n",
            "Epoch [13/50] - Batch loss: 168.3784 - Epoch Loss: 30917.3939 - Avg Loss: 161.8712\n",
            "Epoch [13/50] - Batch loss: 158.7932 - Epoch Loss: 31076.1871 - Avg Loss: 161.8551\n",
            "Epoch [13/50] - Batch loss: 167.8217 - Epoch Loss: 31244.0088 - Avg Loss: 161.8861\n",
            "Epoch [13/50] - Batch loss: 159.5037 - Epoch Loss: 31403.5125 - Avg Loss: 161.8738\n",
            "Epoch [13/50] - Batch loss: 167.7762 - Epoch Loss: 31571.2887 - Avg Loss: 161.9040\n",
            "Epoch [13/50] - Batch loss: 162.8532 - Epoch Loss: 31734.1419 - Avg Loss: 161.9089\n",
            "Epoch [13/50] - Batch loss: 166.6264 - Epoch Loss: 31900.7683 - Avg Loss: 161.9328\n",
            "Epoch [13/50] - Batch loss: 164.1084 - Epoch Loss: 32064.8767 - Avg Loss: 161.9438\n",
            "Epoch [13/50] - Batch loss: 166.9914 - Epoch Loss: 32231.8681 - Avg Loss: 161.9692\n",
            "Epoch [13/50] - Batch loss: 160.9306 - Epoch Loss: 32392.7987 - Avg Loss: 161.9640\n",
            "Epoch [13/50] - Batch loss: 157.2292 - Epoch Loss: 32550.0279 - Avg Loss: 161.9404\n",
            "Epoch [13/50] - Batch loss: 159.8117 - Epoch Loss: 32709.8397 - Avg Loss: 161.9299\n",
            "Epoch [13/50] - Batch loss: 152.4054 - Epoch Loss: 32862.2451 - Avg Loss: 161.8830\n",
            "Epoch [13/50] - Batch loss: 163.6386 - Epoch Loss: 33025.8837 - Avg Loss: 161.8916\n",
            "Epoch [13/50] - Batch loss: 169.4373 - Epoch Loss: 33195.3210 - Avg Loss: 161.9284\n",
            "Epoch [13/50] - Batch loss: 165.1670 - Epoch Loss: 33360.4881 - Avg Loss: 161.9441\n",
            "Epoch [13/50] - Batch loss: 163.0635 - Epoch Loss: 33523.5515 - Avg Loss: 161.9495\n",
            "Epoch [13/50] - Batch loss: 160.0686 - Epoch Loss: 33683.6201 - Avg Loss: 161.9405\n",
            "Epoch [13/50] - Batch loss: 155.3503 - Epoch Loss: 33838.9704 - Avg Loss: 161.9089\n",
            "Epoch [13/50] - Batch loss: 157.2172 - Epoch Loss: 33996.1876 - Avg Loss: 161.8866\n",
            "Epoch [13/50] - Batch loss: 167.5941 - Epoch Loss: 34163.7817 - Avg Loss: 161.9137\n",
            "Epoch [13/50] - Batch loss: 153.5056 - Epoch Loss: 34317.2873 - Avg Loss: 161.8740\n",
            "Epoch [13/50] - Batch loss: 155.6773 - Epoch Loss: 34472.9646 - Avg Loss: 161.8449\n",
            "Epoch [13/50] - Batch loss: 161.9088 - Epoch Loss: 34634.8734 - Avg Loss: 161.8452\n",
            "Epoch [13/50] - Batch loss: 168.8083 - Epoch Loss: 34803.6817 - Avg Loss: 161.8776\n",
            "Epoch [13/50] - Batch loss: 157.5869 - Epoch Loss: 34961.2686 - Avg Loss: 161.8577\n",
            "Epoch [13/50] - Batch loss: 165.2870 - Epoch Loss: 35126.5557 - Avg Loss: 161.8735\n",
            "Epoch [13/50] - Batch loss: 160.3309 - Epoch Loss: 35286.8866 - Avg Loss: 161.8665\n",
            "Epoch [13/50] - Batch loss: 164.9084 - Epoch Loss: 35451.7950 - Avg Loss: 161.8803\n",
            "Epoch [13/50] - Batch loss: 162.6411 - Epoch Loss: 35614.4360 - Avg Loss: 161.8838\n",
            "Epoch [13/50] - Batch loss: 163.4535 - Epoch Loss: 35777.8896 - Avg Loss: 161.8909\n",
            "Epoch [13/50] - Batch loss: 164.1093 - Epoch Loss: 35941.9988 - Avg Loss: 161.9009\n",
            "Epoch [13/50] - Batch loss: 165.3262 - Epoch Loss: 36107.3251 - Avg Loss: 161.9163\n",
            "Epoch [13/50] - Batch loss: 158.1490 - Epoch Loss: 36265.4741 - Avg Loss: 161.8994\n",
            "Epoch [13/50] - Batch loss: 165.5128 - Epoch Loss: 36430.9868 - Avg Loss: 161.9155\n",
            "Epoch [13/50] - Batch loss: 157.3751 - Epoch Loss: 36588.3619 - Avg Loss: 161.8954\n",
            "Epoch [13/50] - Batch loss: 160.0886 - Epoch Loss: 36748.4505 - Avg Loss: 161.8874\n",
            "Epoch [13/50] - Batch loss: 174.6389 - Epoch Loss: 36923.0894 - Avg Loss: 161.9434\n",
            "Epoch [13/50] - Batch loss: 151.6720 - Epoch Loss: 37074.7614 - Avg Loss: 161.8985\n",
            "Epoch [13/50] - Batch loss: 163.6035 - Epoch Loss: 37238.3649 - Avg Loss: 161.9059\n",
            "Epoch [13/50] - Batch loss: 158.0286 - Epoch Loss: 37396.3934 - Avg Loss: 161.8891\n",
            "Epoch [13/50] - Batch loss: 157.4373 - Epoch Loss: 37553.8308 - Avg Loss: 161.8700\n",
            "Epoch [13/50] - Batch loss: 157.9269 - Epoch Loss: 37711.7577 - Avg Loss: 161.8530\n",
            "Epoch [13/50] - Batch loss: 164.5096 - Epoch Loss: 37876.2673 - Avg Loss: 161.8644\n",
            "Epoch [13/50] - Batch loss: 161.7520 - Epoch Loss: 38038.0193 - Avg Loss: 161.8639\n",
            "Epoch [13/50] - Batch loss: 157.2442 - Epoch Loss: 38195.2635 - Avg Loss: 161.8443\n",
            "Epoch [13/50] - Batch loss: 167.1468 - Epoch Loss: 38362.4103 - Avg Loss: 161.8667\n",
            "Epoch [13/50] - Batch loss: 163.1528 - Epoch Loss: 38525.5631 - Avg Loss: 161.8721\n",
            "Epoch [13/50] - Batch loss: 159.9480 - Epoch Loss: 38685.5111 - Avg Loss: 161.8641\n",
            "Epoch [13/50] - Batch loss: 161.2305 - Epoch Loss: 38846.7415 - Avg Loss: 161.8614\n",
            "Epoch [13/50] - Batch loss: 166.6743 - Epoch Loss: 39013.4158 - Avg Loss: 161.8814\n",
            "Epoch [13/50] - Batch loss: 159.8922 - Epoch Loss: 39173.3081 - Avg Loss: 161.8732\n",
            "Epoch [13/50] - Batch loss: 158.2042 - Epoch Loss: 39331.5123 - Avg Loss: 161.8581\n",
            "Epoch [13/50] - Batch loss: 166.7122 - Epoch Loss: 39498.2244 - Avg Loss: 161.8780\n",
            "Epoch [13/50] - Batch loss: 157.1093 - Epoch Loss: 39655.3337 - Avg Loss: 161.8585\n",
            "Epoch [13/50] - Batch loss: 154.5123 - Epoch Loss: 39809.8460 - Avg Loss: 161.8286\n",
            "Epoch [13/50] - Batch loss: 165.8752 - Epoch Loss: 39975.7212 - Avg Loss: 161.8450\n",
            "Epoch [13/50] - Batch loss: 164.3553 - Epoch Loss: 40140.0765 - Avg Loss: 161.8551\n",
            "Epoch [13/50] - Batch loss: 151.4648 - Epoch Loss: 40291.5413 - Avg Loss: 161.8134\n",
            "Epoch [13/50] - Batch loss: 156.7561 - Epoch Loss: 40448.2974 - Avg Loss: 161.7932\n",
            "Epoch [13/50] - Batch loss: 163.6223 - Epoch Loss: 40611.9197 - Avg Loss: 161.8005\n",
            "Epoch [13/50] - Batch loss: 157.2308 - Epoch Loss: 40769.1505 - Avg Loss: 161.7823\n",
            "Epoch [13/50] - Batch loss: 157.8923 - Epoch Loss: 40927.0428 - Avg Loss: 161.7670\n",
            "Epoch [13/50] - Batch loss: 165.4601 - Epoch Loss: 41092.5030 - Avg Loss: 161.7815\n",
            "Epoch [13/50] - Batch loss: 153.3557 - Epoch Loss: 41245.8587 - Avg Loss: 161.7485\n",
            "Epoch [13/50] - Batch loss: 153.5722 - Epoch Loss: 41399.4309 - Avg Loss: 161.7165\n",
            "Epoch [13/50] - Batch loss: 165.8969 - Epoch Loss: 41565.3278 - Avg Loss: 161.7328\n",
            "Epoch [13/50] - Batch loss: 161.6050 - Epoch Loss: 41726.9329 - Avg Loss: 161.7323\n",
            "Epoch [13/50] - Batch loss: 153.4143 - Epoch Loss: 41880.3471 - Avg Loss: 161.7002\n",
            "Epoch [13/50] - Batch loss: 160.5704 - Epoch Loss: 42040.9175 - Avg Loss: 161.6958\n",
            "Epoch [13/50] - Batch loss: 169.1866 - Epoch Loss: 42210.1041 - Avg Loss: 161.7245\n",
            "Epoch [13/50] - Batch loss: 161.8173 - Epoch Loss: 42371.9214 - Avg Loss: 161.7249\n",
            "Epoch [13/50] - Batch loss: 164.2560 - Epoch Loss: 42536.1774 - Avg Loss: 161.7345\n",
            "Epoch [13/50] - Batch loss: 162.3963 - Epoch Loss: 42698.5737 - Avg Loss: 161.7370\n",
            "Epoch [13/50] - Batch loss: 156.0368 - Epoch Loss: 42854.6105 - Avg Loss: 161.7155\n",
            "Epoch [13/50] - Batch loss: 162.7128 - Epoch Loss: 43017.3233 - Avg Loss: 161.7193\n",
            "Epoch [13/50] - Batch loss: 163.7497 - Epoch Loss: 43181.0731 - Avg Loss: 161.7269\n",
            "Epoch [13/50] - Batch loss: 160.3323 - Epoch Loss: 43341.4053 - Avg Loss: 161.7217\n",
            "Epoch [13/50] - Batch loss: 159.7027 - Epoch Loss: 43501.1080 - Avg Loss: 161.7142\n",
            "Epoch [13/50] - Batch loss: 163.1772 - Epoch Loss: 43664.2852 - Avg Loss: 161.7196\n",
            "Epoch [13/50] - Batch loss: 162.3522 - Epoch Loss: 43826.6374 - Avg Loss: 161.7219\n",
            "Epoch [13/50] - Batch loss: 170.1958 - Epoch Loss: 43996.8333 - Avg Loss: 161.7531\n",
            "Epoch [13/50] - Batch loss: 172.9407 - Epoch Loss: 44169.7739 - Avg Loss: 161.7940\n",
            "Epoch [13/50] - Batch loss: 164.8955 - Epoch Loss: 44334.6694 - Avg Loss: 161.8054\n",
            "Epoch [13/50] - Batch loss: 160.5632 - Epoch Loss: 44495.2326 - Avg Loss: 161.8008\n",
            "Epoch [13/50] - Batch loss: 155.7590 - Epoch Loss: 44650.9917 - Avg Loss: 161.7790\n",
            "Epoch [13/50] - Batch loss: 156.9119 - Epoch Loss: 44807.9036 - Avg Loss: 161.7614\n",
            "Epoch [13/50] - Batch loss: 159.3726 - Epoch Loss: 44967.2762 - Avg Loss: 161.7528\n",
            "Epoch [13/50] - Batch loss: 161.1160 - Epoch Loss: 45128.3922 - Avg Loss: 161.7505\n",
            "Epoch [13/50] - Batch loss: 157.3011 - Epoch Loss: 45285.6933 - Avg Loss: 161.7346\n",
            "Epoch [13/50] - Batch loss: 157.6871 - Epoch Loss: 45443.3803 - Avg Loss: 161.7202\n",
            "Epoch [13/50] - Batch loss: 155.7782 - Epoch Loss: 45599.1586 - Avg Loss: 161.6991\n",
            "Epoch [13/50] - Batch loss: 158.4283 - Epoch Loss: 45757.5869 - Avg Loss: 161.6876\n",
            "Epoch [13/50] - Batch loss: 161.9851 - Epoch Loss: 45919.5720 - Avg Loss: 161.6886\n",
            "Epoch [13/50] - Batch loss: 160.5228 - Epoch Loss: 46080.0948 - Avg Loss: 161.6845\n",
            "Epoch [13/50] - Batch loss: 165.3998 - Epoch Loss: 46245.4946 - Avg Loss: 161.6975\n",
            "Epoch [13/50] - Batch loss: 162.6200 - Epoch Loss: 46408.1145 - Avg Loss: 161.7007\n",
            "Epoch [13/50] - Batch loss: 160.9566 - Epoch Loss: 46569.0711 - Avg Loss: 161.6982\n",
            "Epoch [13/50] - Batch loss: 154.0096 - Epoch Loss: 46723.0807 - Avg Loss: 161.6716\n",
            "Epoch [13/50] - Batch loss: 165.5179 - Epoch Loss: 46888.5985 - Avg Loss: 161.6848\n",
            "Epoch [13/50] - Batch loss: 168.1505 - Epoch Loss: 47056.7490 - Avg Loss: 161.7070\n",
            "Epoch [13/50] - Batch loss: 163.5584 - Epoch Loss: 47220.3073 - Avg Loss: 161.7134\n",
            "Epoch [13/50] - Batch loss: 157.5577 - Epoch Loss: 47377.8651 - Avg Loss: 161.6992\n",
            "Epoch [13/50] - Batch loss: 166.2400 - Epoch Loss: 47544.1051 - Avg Loss: 161.7146\n",
            "Epoch [13/50] - Batch loss: 163.7610 - Epoch Loss: 47707.8660 - Avg Loss: 161.7216\n",
            "Epoch [13/50] - Batch loss: 163.2705 - Epoch Loss: 47871.1365 - Avg Loss: 161.7268\n",
            "Epoch [13/50] - Batch loss: 160.8484 - Epoch Loss: 48031.9849 - Avg Loss: 161.7239\n",
            "Epoch [13/50] - Batch loss: 162.1268 - Epoch Loss: 48194.1118 - Avg Loss: 161.7252\n",
            "Epoch [13/50] - Batch loss: 157.0848 - Epoch Loss: 48351.1966 - Avg Loss: 161.7097\n",
            "Epoch [13/50] - Batch loss: 160.4086 - Epoch Loss: 48511.6052 - Avg Loss: 161.7054\n",
            "Epoch [13/50] - Batch loss: 172.7099 - Epoch Loss: 48684.3151 - Avg Loss: 161.7419\n",
            "Epoch [13/50] - Batch loss: 155.2919 - Epoch Loss: 48839.6070 - Avg Loss: 161.7206\n",
            "Epoch [13/50] - Batch loss: 162.6543 - Epoch Loss: 49002.2613 - Avg Loss: 161.7236\n",
            "Epoch [13/50] - Batch loss: 159.3049 - Epoch Loss: 49161.5661 - Avg Loss: 161.7157\n",
            "Epoch [13/50] - Batch loss: 158.8784 - Epoch Loss: 49320.4445 - Avg Loss: 161.7064\n",
            "Epoch [13/50] - Batch loss: 160.6284 - Epoch Loss: 49481.0729 - Avg Loss: 161.7029\n",
            "Epoch [13/50] - Batch loss: 164.7399 - Epoch Loss: 49645.8128 - Avg Loss: 161.7127\n",
            "Epoch [13/50] - Batch loss: 169.9393 - Epoch Loss: 49815.7521 - Avg Loss: 161.7395\n",
            "Epoch [13/50] - Batch loss: 161.9539 - Epoch Loss: 49977.7061 - Avg Loss: 161.7401\n",
            "Epoch [13/50] - Batch loss: 158.4855 - Epoch Loss: 50136.1916 - Avg Loss: 161.7297\n",
            "Epoch [13/50] - Batch loss: 155.4092 - Epoch Loss: 50291.6008 - Avg Loss: 161.7093\n",
            "Epoch [13/50] - Batch loss: 159.8846 - Epoch Loss: 50451.4854 - Avg Loss: 161.7035\n",
            "Epoch [13/50] - Batch loss: 158.5317 - Epoch Loss: 50610.0171 - Avg Loss: 161.6933\n",
            "Epoch [13/50] - Batch loss: 164.4550 - Epoch Loss: 50774.4721 - Avg Loss: 161.7021\n",
            "Epoch [13/50] - Batch loss: 154.4555 - Epoch Loss: 50928.9276 - Avg Loss: 161.6791\n",
            "Epoch [13/50] - Batch loss: 162.0755 - Epoch Loss: 51091.0031 - Avg Loss: 161.6804\n",
            "Epoch [13/50] - Batch loss: 158.7966 - Epoch Loss: 51249.7996 - Avg Loss: 161.6713\n",
            "Epoch [13/50] - Batch loss: 156.7501 - Epoch Loss: 51406.5497 - Avg Loss: 161.6558\n",
            "Epoch [13/50] - Batch loss: 159.7059 - Epoch Loss: 51566.2557 - Avg Loss: 161.6497\n",
            "Epoch [13/50] - Batch loss: 157.9800 - Epoch Loss: 51724.2357 - Avg Loss: 161.6382\n",
            "Epoch [13/50] - Batch loss: 155.5723 - Epoch Loss: 51879.8080 - Avg Loss: 161.6193\n",
            "Epoch [13/50] - Batch loss: 167.5146 - Epoch Loss: 52047.3226 - Avg Loss: 161.6376\n",
            "Epoch [13/50] - Batch loss: 162.4891 - Epoch Loss: 52209.8117 - Avg Loss: 161.6403\n",
            "Epoch [13/50] - Batch loss: 163.9243 - Epoch Loss: 52373.7360 - Avg Loss: 161.6473\n",
            "Epoch [13/50] - Batch loss: 167.4843 - Epoch Loss: 52541.2203 - Avg Loss: 161.6653\n",
            "Epoch [13/50] - Batch loss: 169.6608 - Epoch Loss: 52710.8810 - Avg Loss: 161.6898\n",
            "Epoch [13/50] - Batch loss: 157.0488 - Epoch Loss: 52867.9298 - Avg Loss: 161.6756\n",
            "Epoch [13/50] - Batch loss: 156.8229 - Epoch Loss: 53024.7527 - Avg Loss: 161.6608\n",
            "Epoch [13/50] - Batch loss: 159.4914 - Epoch Loss: 53184.2442 - Avg Loss: 161.6542\n",
            "Epoch [13/50] - Batch loss: 156.1400 - Epoch Loss: 53340.3842 - Avg Loss: 161.6375\n",
            "Epoch [13/50] - Batch loss: 163.5429 - Epoch Loss: 53503.9271 - Avg Loss: 161.6433\n",
            "Epoch [13/50] - Batch loss: 155.1592 - Epoch Loss: 53659.0863 - Avg Loss: 161.6238\n",
            "Epoch [13/50] - Batch loss: 162.6655 - Epoch Loss: 53821.7519 - Avg Loss: 161.6269\n",
            "Epoch [13/50] - Batch loss: 155.1960 - Epoch Loss: 53976.9479 - Avg Loss: 161.6076\n",
            "Epoch [13/50] - Batch loss: 162.4225 - Epoch Loss: 54139.3704 - Avg Loss: 161.6101\n",
            "Epoch [13/50] - Batch loss: 166.5953 - Epoch Loss: 54305.9657 - Avg Loss: 161.6249\n",
            "Epoch [13/50] - Batch loss: 161.0591 - Epoch Loss: 54467.0248 - Avg Loss: 161.6232\n",
            "Epoch [13/50] - Batch loss: 163.7835 - Epoch Loss: 54630.8083 - Avg Loss: 161.6296\n",
            "Epoch [13/50] - Batch loss: 161.0212 - Epoch Loss: 54791.8296 - Avg Loss: 161.6278\n",
            "Epoch [13/50] - Batch loss: 159.1886 - Epoch Loss: 54951.0181 - Avg Loss: 161.6206\n",
            "Epoch [13/50] - Batch loss: 164.8869 - Epoch Loss: 55115.9050 - Avg Loss: 161.6302\n",
            "Epoch [13/50] - Batch loss: 160.6388 - Epoch Loss: 55276.5439 - Avg Loss: 161.6273\n",
            "Epoch [13/50] - Batch loss: 160.4746 - Epoch Loss: 55437.0184 - Avg Loss: 161.6240\n",
            "Epoch [13/50] - Batch loss: 154.3563 - Epoch Loss: 55591.3748 - Avg Loss: 161.6028\n",
            "Epoch [13/50] - Batch loss: 163.7358 - Epoch Loss: 55755.1105 - Avg Loss: 161.6090\n",
            "Epoch [13/50] - Batch loss: 152.3780 - Epoch Loss: 55907.4885 - Avg Loss: 161.5823\n",
            "Epoch [13/50] - Batch loss: 158.4827 - Epoch Loss: 56065.9713 - Avg Loss: 161.5734\n",
            "Epoch [13/50] - Batch loss: 161.2021 - Epoch Loss: 56227.1734 - Avg Loss: 161.5723\n",
            "Epoch [13/50] - Batch loss: 159.5173 - Epoch Loss: 56386.6907 - Avg Loss: 161.5664\n",
            "Epoch [13/50] - Batch loss: 160.4340 - Epoch Loss: 56547.1246 - Avg Loss: 161.5632\n",
            "Epoch [13/50] - Batch loss: 167.8618 - Epoch Loss: 56714.9865 - Avg Loss: 161.5812\n",
            "Epoch [13/50] - Batch loss: 163.6943 - Epoch Loss: 56878.6807 - Avg Loss: 161.5872\n",
            "Epoch [13/50] - Batch loss: 157.2082 - Epoch Loss: 57035.8889 - Avg Loss: 161.5748\n",
            "Epoch [13/50] - Batch loss: 154.8744 - Epoch Loss: 57190.7633 - Avg Loss: 161.5558\n",
            "Epoch [13/50] - Batch loss: 156.2480 - Epoch Loss: 57347.0113 - Avg Loss: 161.5409\n",
            "Epoch [13/50] - Batch loss: 166.7213 - Epoch Loss: 57513.7325 - Avg Loss: 161.5554\n",
            "Epoch [13/50] - Batch loss: 161.8925 - Epoch Loss: 57675.6250 - Avg Loss: 161.5564\n",
            "Epoch [13/50] - Batch loss: 152.9717 - Epoch Loss: 57828.5967 - Avg Loss: 161.5324\n",
            "Epoch [13/50] - Batch loss: 157.4214 - Epoch Loss: 57986.0182 - Avg Loss: 161.5209\n",
            "Epoch [13/50] - Batch loss: 160.9786 - Epoch Loss: 58146.9968 - Avg Loss: 161.5194\n",
            "Epoch [13/50] - Batch loss: 168.7085 - Epoch Loss: 58315.7053 - Avg Loss: 161.5393\n",
            "Epoch [13/50] - Batch loss: 168.5144 - Epoch Loss: 58484.2198 - Avg Loss: 161.5586\n",
            "Epoch [13/50] - Batch loss: 162.1587 - Epoch Loss: 58646.3785 - Avg Loss: 161.5603\n",
            "Epoch [13/50] - Batch loss: 161.4898 - Epoch Loss: 58807.8683 - Avg Loss: 161.5601\n",
            "Epoch [13/50] - Batch loss: 157.6761 - Epoch Loss: 58965.5443 - Avg Loss: 161.5494\n",
            "Epoch [13/50] - Batch loss: 158.2497 - Epoch Loss: 59123.7940 - Avg Loss: 161.5404\n",
            "Epoch [13/50] - Batch loss: 161.6445 - Epoch Loss: 59285.4386 - Avg Loss: 161.5407\n",
            "Epoch [13/50] - Batch loss: 162.9966 - Epoch Loss: 59448.4351 - Avg Loss: 161.5447\n",
            "Epoch [13/50] - Batch loss: 162.6674 - Epoch Loss: 59611.1025 - Avg Loss: 161.5477\n",
            "Epoch [13/50] - Batch loss: 164.2800 - Epoch Loss: 59775.3826 - Avg Loss: 161.5551\n",
            "Epoch [13/50] - Batch loss: 162.9992 - Epoch Loss: 59938.3817 - Avg Loss: 161.5590\n",
            "Epoch [13/50] - Batch loss: 159.8030 - Epoch Loss: 60098.1848 - Avg Loss: 161.5543\n",
            "Epoch [13/50] - Batch loss: 165.8811 - Epoch Loss: 60264.0658 - Avg Loss: 161.5659\n",
            "Epoch [13/50] - Batch loss: 159.4420 - Epoch Loss: 60423.5078 - Avg Loss: 161.5602\n",
            "Epoch [13/50] - Batch loss: 156.9192 - Epoch Loss: 60580.4270 - Avg Loss: 161.5478\n",
            "Epoch [13/50] - Batch loss: 158.1426 - Epoch Loss: 60738.5696 - Avg Loss: 161.5387\n",
            "Epoch [13/50] - Batch loss: 162.0150 - Epoch Loss: 60900.5846 - Avg Loss: 161.5400\n",
            "Epoch [13/50] - Batch loss: 156.9636 - Epoch Loss: 61057.5481 - Avg Loss: 161.5279\n",
            "Epoch [13/50] - Batch loss: 158.2769 - Epoch Loss: 61215.8251 - Avg Loss: 161.5193\n",
            "Epoch [13/50] - Batch loss: 166.1184 - Epoch Loss: 61381.9435 - Avg Loss: 161.5314\n",
            "Epoch [13/50] - Batch loss: 170.3261 - Epoch Loss: 61552.2695 - Avg Loss: 161.5545\n",
            "Epoch [13/50] - Batch loss: 148.3302 - Epoch Loss: 61700.5997 - Avg Loss: 161.5199\n",
            "Epoch [13/50] - Batch loss: 159.8268 - Epoch Loss: 61860.4265 - Avg Loss: 161.5155\n",
            "Epoch [13/50] - Batch loss: 164.2743 - Epoch Loss: 62024.7007 - Avg Loss: 161.5227\n",
            "Epoch [13/50] - Batch loss: 154.8944 - Epoch Loss: 62179.5951 - Avg Loss: 161.5054\n",
            "Epoch [13/50] - Batch loss: 158.2581 - Epoch Loss: 62337.8532 - Avg Loss: 161.4970\n",
            "Epoch [13/50] - Batch loss: 157.4183 - Epoch Loss: 62495.2715 - Avg Loss: 161.4865\n",
            "Epoch [13/50] - Batch loss: 160.8983 - Epoch Loss: 62656.1697 - Avg Loss: 161.4850\n",
            "Epoch [13/50] - Batch loss: 167.2169 - Epoch Loss: 62823.3866 - Avg Loss: 161.4997\n",
            "Epoch [13/50] - Batch loss: 163.6293 - Epoch Loss: 62987.0159 - Avg Loss: 161.5052\n",
            "Epoch [13/50] - Batch loss: 153.4108 - Epoch Loss: 63140.4266 - Avg Loss: 161.4845\n",
            "Epoch [13/50] - Batch loss: 159.9085 - Epoch Loss: 63300.3352 - Avg Loss: 161.4804\n",
            "Epoch [13/50] - Batch loss: 160.2960 - Epoch Loss: 63460.6311 - Avg Loss: 161.4774\n",
            "Epoch [13/50] - Batch loss: 169.1499 - Epoch Loss: 63629.7810 - Avg Loss: 161.4969\n",
            "Epoch [13/50] - Batch loss: 162.8364 - Epoch Loss: 63792.6174 - Avg Loss: 161.5003\n",
            "Epoch [13/50] - Batch loss: 164.1168 - Epoch Loss: 63956.7342 - Avg Loss: 161.5069\n",
            "Epoch [13/50] - Batch loss: 165.6761 - Epoch Loss: 64122.4103 - Avg Loss: 161.5174\n",
            "Epoch [13/50] - Batch loss: 157.9485 - Epoch Loss: 64280.3588 - Avg Loss: 161.5084\n",
            "Epoch [13/50] - Batch loss: 161.9618 - Epoch Loss: 64442.3206 - Avg Loss: 161.5096\n",
            "Epoch [13/50] - Batch loss: 161.5998 - Epoch Loss: 64603.9204 - Avg Loss: 161.5098\n",
            "Epoch [13/50] - Batch loss: 160.9354 - Epoch Loss: 64764.8558 - Avg Loss: 161.5084\n",
            "Epoch [13/50] - Batch loss: 159.3618 - Epoch Loss: 64924.2176 - Avg Loss: 161.5030\n",
            "Epoch [13/50] - Batch loss: 164.7665 - Epoch Loss: 65088.9841 - Avg Loss: 161.5111\n",
            "Epoch [13/50] - Batch loss: 170.9174 - Epoch Loss: 65259.9015 - Avg Loss: 161.5344\n",
            "Epoch [13/50] - Batch loss: 163.3118 - Epoch Loss: 65423.2133 - Avg Loss: 161.5388\n",
            "Epoch [13/50] - Batch loss: 155.3415 - Epoch Loss: 65578.5548 - Avg Loss: 161.5235\n",
            "Epoch [13/50] - Batch loss: 161.5799 - Epoch Loss: 65740.1348 - Avg Loss: 161.5237\n",
            "Epoch [13/50] - Batch loss: 156.7754 - Epoch Loss: 65896.9101 - Avg Loss: 161.5120\n",
            "Epoch [13/50] - Batch loss: 160.9172 - Epoch Loss: 66057.8273 - Avg Loss: 161.5106\n",
            "Epoch [13/50] - Batch loss: 162.4877 - Epoch Loss: 66220.3150 - Avg Loss: 161.5130\n",
            "Epoch [13/50] - Batch loss: 154.6872 - Epoch Loss: 66375.0022 - Avg Loss: 161.4964\n",
            "Epoch [13/50] - Batch loss: 165.2029 - Epoch Loss: 66540.2050 - Avg Loss: 161.5054\n",
            "Epoch [13/50] - Batch loss: 156.1831 - Epoch Loss: 66696.3881 - Avg Loss: 161.4925\n",
            "Epoch [13/50] - Batch loss: 152.0404 - Epoch Loss: 66848.4285 - Avg Loss: 161.4696\n",
            "Epoch [13/50] - Batch loss: 167.8403 - Epoch Loss: 67016.2688 - Avg Loss: 161.4850\n",
            "Epoch [13/50] - Batch loss: 157.6587 - Epoch Loss: 67173.9275 - Avg Loss: 161.4758\n",
            "Epoch [13/50] - Batch loss: 174.6164 - Epoch Loss: 67348.5438 - Avg Loss: 161.5073\n",
            "Epoch [13/50] - Batch loss: 156.9113 - Epoch Loss: 67505.4551 - Avg Loss: 161.4963\n",
            "Epoch [13/50] - Batch loss: 165.9712 - Epoch Loss: 67671.4263 - Avg Loss: 161.5070\n",
            "Epoch [13/50] - Batch loss: 167.0199 - Epoch Loss: 67838.4462 - Avg Loss: 161.5201\n",
            "Epoch [13/50] - Batch loss: 157.0787 - Epoch Loss: 67995.5250 - Avg Loss: 161.5096\n",
            "Epoch [13/50] - Batch loss: 159.0668 - Epoch Loss: 68154.5918 - Avg Loss: 161.5038\n",
            "Epoch [13/50] - Batch loss: 156.5570 - Epoch Loss: 68311.1488 - Avg Loss: 161.4921\n",
            "Epoch [13/50] - Batch loss: 157.0387 - Epoch Loss: 68468.1874 - Avg Loss: 161.4816\n",
            "Epoch [13/50] - Batch loss: 159.9112 - Epoch Loss: 68628.0987 - Avg Loss: 161.4779\n",
            "Epoch [13/50] - Batch loss: 162.2465 - Epoch Loss: 68790.3452 - Avg Loss: 161.4797\n",
            "Epoch [13/50] - Batch loss: 156.4129 - Epoch Loss: 68946.7582 - Avg Loss: 161.4678\n",
            "Epoch [13/50] - Batch loss: 161.9082 - Epoch Loss: 69108.6664 - Avg Loss: 161.4688\n",
            "Epoch [13/50] - Batch loss: 158.5767 - Epoch Loss: 69267.2431 - Avg Loss: 161.4621\n",
            "Epoch [13/50] - Batch loss: 165.8494 - Epoch Loss: 69433.0925 - Avg Loss: 161.4723\n",
            "Epoch [13/50] - Batch loss: 153.6987 - Epoch Loss: 69586.7912 - Avg Loss: 161.4543\n",
            "Epoch [13/50] - Batch loss: 162.8096 - Epoch Loss: 69749.6009 - Avg Loss: 161.4574\n",
            "Epoch [13/50] - Batch loss: 170.5846 - Epoch Loss: 69920.1854 - Avg Loss: 161.4785\n",
            "Epoch [13/50] - Batch loss: 167.7152 - Epoch Loss: 70087.9007 - Avg Loss: 161.4929\n",
            "Epoch [13/50] - Batch loss: 160.0179 - Epoch Loss: 70247.9185 - Avg Loss: 161.4895\n",
            "Epoch [13/50] - Batch loss: 169.9418 - Epoch Loss: 70417.8603 - Avg Loss: 161.5089\n",
            "Epoch [13/50] - Batch loss: 160.0580 - Epoch Loss: 70577.9183 - Avg Loss: 161.5055\n",
            "Epoch [13/50] - Batch loss: 162.1548 - Epoch Loss: 70740.0731 - Avg Loss: 161.5070\n",
            "Epoch [13/50] - Batch loss: 160.5179 - Epoch Loss: 70900.5910 - Avg Loss: 161.5048\n",
            "Epoch [13/50] - Batch loss: 158.6791 - Epoch Loss: 71059.2700 - Avg Loss: 161.4983\n",
            "Epoch [13/50] - Batch loss: 159.8956 - Epoch Loss: 71219.1656 - Avg Loss: 161.4947\n",
            "Epoch [13/50] - Batch loss: 157.4179 - Epoch Loss: 71376.5835 - Avg Loss: 161.4855\n",
            "Epoch [13/50] - Batch loss: 162.1893 - Epoch Loss: 71538.7729 - Avg Loss: 161.4871\n",
            "Epoch [13/50] - Batch loss: 159.0959 - Epoch Loss: 71697.8688 - Avg Loss: 161.4817\n",
            "Epoch [13/50] - Batch loss: 162.9971 - Epoch Loss: 71860.8659 - Avg Loss: 161.4851\n",
            "Epoch [13/50] - Batch loss: 151.7246 - Epoch Loss: 72012.5905 - Avg Loss: 161.4632\n",
            "Epoch [13/50] - Batch loss: 165.3465 - Epoch Loss: 72177.9370 - Avg Loss: 161.4719\n",
            "Epoch [13/50] - Batch loss: 160.6045 - Epoch Loss: 72338.5415 - Avg Loss: 161.4700\n",
            "Epoch [13/50] - Batch loss: 156.3971 - Epoch Loss: 72494.9386 - Avg Loss: 161.4587\n",
            "Epoch [13/50] - Batch loss: 161.3080 - Epoch Loss: 72656.2466 - Avg Loss: 161.4583\n",
            "Epoch [13/50] - Batch loss: 164.1984 - Epoch Loss: 72820.4450 - Avg Loss: 161.4644\n",
            "Epoch [13/50] - Batch loss: 161.6298 - Epoch Loss: 72982.0748 - Avg Loss: 161.4648\n",
            "Epoch [13/50] - Batch loss: 157.0159 - Epoch Loss: 73139.0907 - Avg Loss: 161.4549\n",
            "Epoch [13/50] - Batch loss: 152.1070 - Epoch Loss: 73291.1977 - Avg Loss: 161.4344\n",
            "Epoch [13/50] - Batch loss: 160.3890 - Epoch Loss: 73451.5867 - Avg Loss: 161.4321\n",
            "Epoch [13/50] - Batch loss: 161.8504 - Epoch Loss: 73613.4371 - Avg Loss: 161.4330\n",
            "Epoch [13/50] - Batch loss: 164.8637 - Epoch Loss: 73778.3008 - Avg Loss: 161.4405\n",
            "Epoch [13/50] - Batch loss: 157.2448 - Epoch Loss: 73935.5456 - Avg Loss: 161.4313\n",
            "Epoch [13/50] - Batch loss: 161.0954 - Epoch Loss: 74096.6410 - Avg Loss: 161.4306\n",
            "Epoch [13/50] - Batch loss: 156.0679 - Epoch Loss: 74252.7089 - Avg Loss: 161.4189\n",
            "Epoch [13/50] - Batch loss: 161.3978 - Epoch Loss: 74414.1067 - Avg Loss: 161.4189\n",
            "Epoch [13/50] - Batch loss: 165.4320 - Epoch Loss: 74579.5387 - Avg Loss: 161.4276\n",
            "Epoch [13/50] - Batch loss: 162.1815 - Epoch Loss: 74741.7202 - Avg Loss: 161.4292\n",
            "Epoch [13/50] - Batch loss: 171.7787 - Epoch Loss: 74913.4989 - Avg Loss: 161.4515\n",
            "Epoch [13/50] - Batch loss: 160.7828 - Epoch Loss: 75074.2817 - Avg Loss: 161.4501\n",
            "Epoch [13/50] - Batch loss: 161.4737 - Epoch Loss: 75235.7554 - Avg Loss: 161.4501\n",
            "Epoch [13/50] - Batch loss: 158.5959 - Epoch Loss: 75394.3513 - Avg Loss: 161.4440\n",
            "Epoch [13/50] - Batch loss: 161.7942 - Epoch Loss: 75556.1455 - Avg Loss: 161.4448\n",
            "Epoch [13/50] - Batch loss: 160.4553 - Epoch Loss: 75716.6008 - Avg Loss: 161.4426\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 14/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b22809982fe4d7b96bf517c3d937144"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/50] - Batch loss: 153.2502 - Epoch Loss: 153.2502 - Avg Loss: 153.2502\n",
            "Epoch [14/50] - Batch loss: 168.5108 - Epoch Loss: 321.7611 - Avg Loss: 160.8805\n",
            "Epoch [14/50] - Batch loss: 160.4091 - Epoch Loss: 482.1702 - Avg Loss: 160.7234\n",
            "Epoch [14/50] - Batch loss: 157.5696 - Epoch Loss: 639.7399 - Avg Loss: 159.9350\n",
            "Epoch [14/50] - Batch loss: 157.0967 - Epoch Loss: 796.8366 - Avg Loss: 159.3673\n",
            "Epoch [14/50] - Batch loss: 161.8924 - Epoch Loss: 958.7290 - Avg Loss: 159.7882\n",
            "Epoch [14/50] - Batch loss: 151.0007 - Epoch Loss: 1109.7298 - Avg Loss: 158.5328\n",
            "Epoch [14/50] - Batch loss: 158.3020 - Epoch Loss: 1268.0318 - Avg Loss: 158.5040\n",
            "Epoch [14/50] - Batch loss: 161.4713 - Epoch Loss: 1429.5031 - Avg Loss: 158.8337\n",
            "Epoch [14/50] - Batch loss: 164.8415 - Epoch Loss: 1594.3446 - Avg Loss: 159.4345\n",
            "Epoch [14/50] - Batch loss: 159.7168 - Epoch Loss: 1754.0614 - Avg Loss: 159.4601\n",
            "Epoch [14/50] - Batch loss: 159.6616 - Epoch Loss: 1913.7230 - Avg Loss: 159.4769\n",
            "Epoch [14/50] - Batch loss: 157.5321 - Epoch Loss: 2071.2551 - Avg Loss: 159.3273\n",
            "Epoch [14/50] - Batch loss: 160.4147 - Epoch Loss: 2231.6698 - Avg Loss: 159.4050\n",
            "Epoch [14/50] - Batch loss: 157.8512 - Epoch Loss: 2389.5210 - Avg Loss: 159.3014\n",
            "Epoch [14/50] - Batch loss: 153.2355 - Epoch Loss: 2542.7565 - Avg Loss: 158.9223\n",
            "Epoch [14/50] - Batch loss: 160.3852 - Epoch Loss: 2703.1417 - Avg Loss: 159.0083\n",
            "Epoch [14/50] - Batch loss: 161.8811 - Epoch Loss: 2865.0228 - Avg Loss: 159.1679\n",
            "Epoch [14/50] - Batch loss: 170.3581 - Epoch Loss: 3035.3809 - Avg Loss: 159.7569\n",
            "Epoch [14/50] - Batch loss: 162.4922 - Epoch Loss: 3197.8731 - Avg Loss: 159.8937\n",
            "Epoch [14/50] - Batch loss: 163.0898 - Epoch Loss: 3360.9629 - Avg Loss: 160.0459\n",
            "Epoch [14/50] - Batch loss: 171.8331 - Epoch Loss: 3532.7960 - Avg Loss: 160.5816\n",
            "Epoch [14/50] - Batch loss: 163.9952 - Epoch Loss: 3696.7912 - Avg Loss: 160.7301\n",
            "Epoch [14/50] - Batch loss: 163.7815 - Epoch Loss: 3860.5727 - Avg Loss: 160.8572\n",
            "Epoch [14/50] - Batch loss: 158.0453 - Epoch Loss: 4018.6180 - Avg Loss: 160.7447\n",
            "Epoch [14/50] - Batch loss: 148.2027 - Epoch Loss: 4166.8207 - Avg Loss: 160.2623\n",
            "Epoch [14/50] - Batch loss: 160.8241 - Epoch Loss: 4327.6448 - Avg Loss: 160.2831\n",
            "Epoch [14/50] - Batch loss: 165.6135 - Epoch Loss: 4493.2583 - Avg Loss: 160.4735\n",
            "Epoch [14/50] - Batch loss: 152.0721 - Epoch Loss: 4645.3304 - Avg Loss: 160.1838\n",
            "Epoch [14/50] - Batch loss: 161.3302 - Epoch Loss: 4806.6606 - Avg Loss: 160.2220\n",
            "Epoch [14/50] - Batch loss: 163.9440 - Epoch Loss: 4970.6046 - Avg Loss: 160.3421\n",
            "Epoch [14/50] - Batch loss: 156.0293 - Epoch Loss: 5126.6339 - Avg Loss: 160.2073\n",
            "Epoch [14/50] - Batch loss: 163.7005 - Epoch Loss: 5290.3344 - Avg Loss: 160.3132\n",
            "Epoch [14/50] - Batch loss: 168.8366 - Epoch Loss: 5459.1709 - Avg Loss: 160.5639\n",
            "Epoch [14/50] - Batch loss: 154.1694 - Epoch Loss: 5613.3404 - Avg Loss: 160.3812\n",
            "Epoch [14/50] - Batch loss: 151.1025 - Epoch Loss: 5764.4429 - Avg Loss: 160.1234\n",
            "Epoch [14/50] - Batch loss: 163.0729 - Epoch Loss: 5927.5158 - Avg Loss: 160.2031\n",
            "Epoch [14/50] - Batch loss: 158.1102 - Epoch Loss: 6085.6260 - Avg Loss: 160.1481\n",
            "Epoch [14/50] - Batch loss: 161.4631 - Epoch Loss: 6247.0891 - Avg Loss: 160.1818\n",
            "Epoch [14/50] - Batch loss: 163.2836 - Epoch Loss: 6410.3727 - Avg Loss: 160.2593\n",
            "Epoch [14/50] - Batch loss: 157.5378 - Epoch Loss: 6567.9106 - Avg Loss: 160.1929\n",
            "Epoch [14/50] - Batch loss: 162.8403 - Epoch Loss: 6730.7509 - Avg Loss: 160.2560\n",
            "Epoch [14/50] - Batch loss: 163.0231 - Epoch Loss: 6893.7739 - Avg Loss: 160.3203\n",
            "Epoch [14/50] - Batch loss: 159.2353 - Epoch Loss: 7053.0092 - Avg Loss: 160.2957\n",
            "Epoch [14/50] - Batch loss: 155.5398 - Epoch Loss: 7208.5490 - Avg Loss: 160.1900\n",
            "Epoch [14/50] - Batch loss: 151.4347 - Epoch Loss: 7359.9837 - Avg Loss: 159.9996\n",
            "Epoch [14/50] - Batch loss: 162.5999 - Epoch Loss: 7522.5836 - Avg Loss: 160.0550\n",
            "Epoch [14/50] - Batch loss: 164.9587 - Epoch Loss: 7687.5423 - Avg Loss: 160.1571\n",
            "Epoch [14/50] - Batch loss: 159.9844 - Epoch Loss: 7847.5267 - Avg Loss: 160.1536\n",
            "Epoch [14/50] - Batch loss: 161.8037 - Epoch Loss: 8009.3304 - Avg Loss: 160.1866\n",
            "Epoch [14/50] - Batch loss: 165.8652 - Epoch Loss: 8175.1957 - Avg Loss: 160.2980\n",
            "Epoch [14/50] - Batch loss: 162.7233 - Epoch Loss: 8337.9189 - Avg Loss: 160.3446\n",
            "Epoch [14/50] - Batch loss: 159.2007 - Epoch Loss: 8497.1197 - Avg Loss: 160.3230\n",
            "Epoch [14/50] - Batch loss: 159.1080 - Epoch Loss: 8656.2276 - Avg Loss: 160.3005\n",
            "Epoch [14/50] - Batch loss: 157.9818 - Epoch Loss: 8814.2094 - Avg Loss: 160.2584\n",
            "Epoch [14/50] - Batch loss: 163.6060 - Epoch Loss: 8977.8154 - Avg Loss: 160.3181\n",
            "Epoch [14/50] - Batch loss: 164.2957 - Epoch Loss: 9142.1111 - Avg Loss: 160.3879\n",
            "Epoch [14/50] - Batch loss: 163.3541 - Epoch Loss: 9305.4653 - Avg Loss: 160.4391\n",
            "Epoch [14/50] - Batch loss: 157.7086 - Epoch Loss: 9463.1739 - Avg Loss: 160.3928\n",
            "Epoch [14/50] - Batch loss: 164.2803 - Epoch Loss: 9627.4542 - Avg Loss: 160.4576\n",
            "Epoch [14/50] - Batch loss: 160.1435 - Epoch Loss: 9787.5977 - Avg Loss: 160.4524\n",
            "Epoch [14/50] - Batch loss: 161.4761 - Epoch Loss: 9949.0738 - Avg Loss: 160.4689\n",
            "Epoch [14/50] - Batch loss: 163.3271 - Epoch Loss: 10112.4009 - Avg Loss: 160.5143\n",
            "Epoch [14/50] - Batch loss: 160.0322 - Epoch Loss: 10272.4331 - Avg Loss: 160.5068\n",
            "Epoch [14/50] - Batch loss: 160.3450 - Epoch Loss: 10432.7781 - Avg Loss: 160.5043\n",
            "Epoch [14/50] - Batch loss: 160.5683 - Epoch Loss: 10593.3465 - Avg Loss: 160.5052\n",
            "Epoch [14/50] - Batch loss: 152.0008 - Epoch Loss: 10745.3472 - Avg Loss: 160.3783\n",
            "Epoch [14/50] - Batch loss: 159.2721 - Epoch Loss: 10904.6194 - Avg Loss: 160.3620\n",
            "Epoch [14/50] - Batch loss: 153.2727 - Epoch Loss: 11057.8920 - Avg Loss: 160.2593\n",
            "Epoch [14/50] - Batch loss: 165.7588 - Epoch Loss: 11223.6508 - Avg Loss: 160.3379\n",
            "Epoch [14/50] - Batch loss: 158.1455 - Epoch Loss: 11381.7963 - Avg Loss: 160.3070\n",
            "Epoch [14/50] - Batch loss: 155.7124 - Epoch Loss: 11537.5087 - Avg Loss: 160.2432\n",
            "Epoch [14/50] - Batch loss: 167.6368 - Epoch Loss: 11705.1455 - Avg Loss: 160.3445\n",
            "Epoch [14/50] - Batch loss: 162.3529 - Epoch Loss: 11867.4984 - Avg Loss: 160.3716\n",
            "Epoch [14/50] - Batch loss: 161.6999 - Epoch Loss: 12029.1982 - Avg Loss: 160.3893\n",
            "Epoch [14/50] - Batch loss: 158.1527 - Epoch Loss: 12187.3509 - Avg Loss: 160.3599\n",
            "Epoch [14/50] - Batch loss: 163.7102 - Epoch Loss: 12351.0612 - Avg Loss: 160.4034\n",
            "Epoch [14/50] - Batch loss: 164.2828 - Epoch Loss: 12515.3440 - Avg Loss: 160.4531\n",
            "Epoch [14/50] - Batch loss: 169.2885 - Epoch Loss: 12684.6326 - Avg Loss: 160.5650\n",
            "Epoch [14/50] - Batch loss: 158.4299 - Epoch Loss: 12843.0624 - Avg Loss: 160.5383\n",
            "Epoch [14/50] - Batch loss: 155.9388 - Epoch Loss: 12999.0012 - Avg Loss: 160.4815\n",
            "Epoch [14/50] - Batch loss: 152.3048 - Epoch Loss: 13151.3060 - Avg Loss: 160.3818\n",
            "Epoch [14/50] - Batch loss: 157.2127 - Epoch Loss: 13308.5186 - Avg Loss: 160.3436\n",
            "Epoch [14/50] - Batch loss: 161.4916 - Epoch Loss: 13470.0103 - Avg Loss: 160.3573\n",
            "Epoch [14/50] - Batch loss: 152.1804 - Epoch Loss: 13622.1906 - Avg Loss: 160.2611\n",
            "Epoch [14/50] - Batch loss: 163.8496 - Epoch Loss: 13786.0402 - Avg Loss: 160.3028\n",
            "Epoch [14/50] - Batch loss: 163.2948 - Epoch Loss: 13949.3350 - Avg Loss: 160.3372\n",
            "Epoch [14/50] - Batch loss: 163.0134 - Epoch Loss: 14112.3484 - Avg Loss: 160.3676\n",
            "Epoch [14/50] - Batch loss: 160.4060 - Epoch Loss: 14272.7544 - Avg Loss: 160.3680\n",
            "Epoch [14/50] - Batch loss: 161.5618 - Epoch Loss: 14434.3161 - Avg Loss: 160.3813\n",
            "Epoch [14/50] - Batch loss: 164.6409 - Epoch Loss: 14598.9571 - Avg Loss: 160.4281\n",
            "Epoch [14/50] - Batch loss: 162.6600 - Epoch Loss: 14761.6171 - Avg Loss: 160.4524\n",
            "Epoch [14/50] - Batch loss: 157.1747 - Epoch Loss: 14918.7918 - Avg Loss: 160.4171\n",
            "Epoch [14/50] - Batch loss: 152.3407 - Epoch Loss: 15071.1325 - Avg Loss: 160.3312\n",
            "Epoch [14/50] - Batch loss: 163.7237 - Epoch Loss: 15234.8562 - Avg Loss: 160.3669\n",
            "Epoch [14/50] - Batch loss: 157.1616 - Epoch Loss: 15392.0177 - Avg Loss: 160.3335\n",
            "Epoch [14/50] - Batch loss: 167.9163 - Epoch Loss: 15559.9341 - Avg Loss: 160.4117\n",
            "Epoch [14/50] - Batch loss: 165.5876 - Epoch Loss: 15725.5217 - Avg Loss: 160.4645\n",
            "Epoch [14/50] - Batch loss: 166.0488 - Epoch Loss: 15891.5705 - Avg Loss: 160.5209\n",
            "Epoch [14/50] - Batch loss: 155.3351 - Epoch Loss: 16046.9056 - Avg Loss: 160.4691\n",
            "Epoch [14/50] - Batch loss: 155.0931 - Epoch Loss: 16201.9987 - Avg Loss: 160.4158\n",
            "Epoch [14/50] - Batch loss: 161.8120 - Epoch Loss: 16363.8108 - Avg Loss: 160.4295\n",
            "Epoch [14/50] - Batch loss: 161.5356 - Epoch Loss: 16525.3463 - Avg Loss: 160.4403\n",
            "Epoch [14/50] - Batch loss: 162.1675 - Epoch Loss: 16687.5138 - Avg Loss: 160.4569\n",
            "Epoch [14/50] - Batch loss: 164.4034 - Epoch Loss: 16851.9173 - Avg Loss: 160.4945\n",
            "Epoch [14/50] - Batch loss: 163.1368 - Epoch Loss: 17015.0540 - Avg Loss: 160.5194\n",
            "Epoch [14/50] - Batch loss: 156.2433 - Epoch Loss: 17171.2973 - Avg Loss: 160.4794\n",
            "Epoch [14/50] - Batch loss: 162.7422 - Epoch Loss: 17334.0396 - Avg Loss: 160.5004\n",
            "Epoch [14/50] - Batch loss: 160.3865 - Epoch Loss: 17494.4261 - Avg Loss: 160.4993\n",
            "Epoch [14/50] - Batch loss: 165.1584 - Epoch Loss: 17659.5845 - Avg Loss: 160.5417\n",
            "Epoch [14/50] - Batch loss: 155.4633 - Epoch Loss: 17815.0478 - Avg Loss: 160.4959\n",
            "Epoch [14/50] - Batch loss: 162.7288 - Epoch Loss: 17977.7766 - Avg Loss: 160.5159\n",
            "Epoch [14/50] - Batch loss: 166.3880 - Epoch Loss: 18144.1646 - Avg Loss: 160.5678\n",
            "Epoch [14/50] - Batch loss: 159.1750 - Epoch Loss: 18303.3397 - Avg Loss: 160.5556\n",
            "Epoch [14/50] - Batch loss: 163.5145 - Epoch Loss: 18466.8542 - Avg Loss: 160.5813\n",
            "Epoch [14/50] - Batch loss: 172.2115 - Epoch Loss: 18639.0657 - Avg Loss: 160.6816\n",
            "Epoch [14/50] - Batch loss: 160.2416 - Epoch Loss: 18799.3073 - Avg Loss: 160.6778\n",
            "Epoch [14/50] - Batch loss: 157.7821 - Epoch Loss: 18957.0893 - Avg Loss: 160.6533\n",
            "Epoch [14/50] - Batch loss: 164.1134 - Epoch Loss: 19121.2027 - Avg Loss: 160.6824\n",
            "Epoch [14/50] - Batch loss: 160.5283 - Epoch Loss: 19281.7310 - Avg Loss: 160.6811\n",
            "Epoch [14/50] - Batch loss: 158.0937 - Epoch Loss: 19439.8247 - Avg Loss: 160.6597\n",
            "Epoch [14/50] - Batch loss: 160.9936 - Epoch Loss: 19600.8183 - Avg Loss: 160.6624\n",
            "Epoch [14/50] - Batch loss: 158.7196 - Epoch Loss: 19759.5379 - Avg Loss: 160.6466\n",
            "Epoch [14/50] - Batch loss: 167.2009 - Epoch Loss: 19926.7388 - Avg Loss: 160.6995\n",
            "Epoch [14/50] - Batch loss: 158.1248 - Epoch Loss: 20084.8636 - Avg Loss: 160.6789\n",
            "Epoch [14/50] - Batch loss: 162.4479 - Epoch Loss: 20247.3115 - Avg Loss: 160.6929\n",
            "Epoch [14/50] - Batch loss: 165.3322 - Epoch Loss: 20412.6437 - Avg Loss: 160.7295\n",
            "Epoch [14/50] - Batch loss: 160.6528 - Epoch Loss: 20573.2965 - Avg Loss: 160.7289\n",
            "Epoch [14/50] - Batch loss: 154.1885 - Epoch Loss: 20727.4850 - Avg Loss: 160.6782\n",
            "Epoch [14/50] - Batch loss: 163.5268 - Epoch Loss: 20891.0118 - Avg Loss: 160.7001\n",
            "Epoch [14/50] - Batch loss: 158.0944 - Epoch Loss: 21049.1062 - Avg Loss: 160.6802\n",
            "Epoch [14/50] - Batch loss: 165.0204 - Epoch Loss: 21214.1266 - Avg Loss: 160.7131\n",
            "Epoch [14/50] - Batch loss: 157.9882 - Epoch Loss: 21372.1147 - Avg Loss: 160.6926\n",
            "Epoch [14/50] - Batch loss: 168.6672 - Epoch Loss: 21540.7819 - Avg Loss: 160.7521\n",
            "Epoch [14/50] - Batch loss: 154.9096 - Epoch Loss: 21695.6915 - Avg Loss: 160.7088\n",
            "Epoch [14/50] - Batch loss: 157.9560 - Epoch Loss: 21853.6475 - Avg Loss: 160.6886\n",
            "Epoch [14/50] - Batch loss: 154.4541 - Epoch Loss: 22008.1016 - Avg Loss: 160.6431\n",
            "Epoch [14/50] - Batch loss: 162.9249 - Epoch Loss: 22171.0265 - Avg Loss: 160.6596\n",
            "Epoch [14/50] - Batch loss: 164.1733 - Epoch Loss: 22335.1998 - Avg Loss: 160.6849\n",
            "Epoch [14/50] - Batch loss: 159.7767 - Epoch Loss: 22494.9765 - Avg Loss: 160.6784\n",
            "Epoch [14/50] - Batch loss: 163.4723 - Epoch Loss: 22658.4488 - Avg Loss: 160.6982\n",
            "Epoch [14/50] - Batch loss: 159.3403 - Epoch Loss: 22817.7891 - Avg Loss: 160.6887\n",
            "Epoch [14/50] - Batch loss: 161.8916 - Epoch Loss: 22979.6806 - Avg Loss: 160.6971\n",
            "Epoch [14/50] - Batch loss: 164.4200 - Epoch Loss: 23144.1006 - Avg Loss: 160.7229\n",
            "Epoch [14/50] - Batch loss: 155.0439 - Epoch Loss: 23299.1445 - Avg Loss: 160.6838\n",
            "Epoch [14/50] - Batch loss: 165.4808 - Epoch Loss: 23464.6254 - Avg Loss: 160.7166\n",
            "Epoch [14/50] - Batch loss: 156.7549 - Epoch Loss: 23621.3802 - Avg Loss: 160.6897\n",
            "Epoch [14/50] - Batch loss: 149.6286 - Epoch Loss: 23771.0088 - Avg Loss: 160.6149\n",
            "Epoch [14/50] - Batch loss: 163.9667 - Epoch Loss: 23934.9755 - Avg Loss: 160.6374\n",
            "Epoch [14/50] - Batch loss: 161.4925 - Epoch Loss: 24096.4680 - Avg Loss: 160.6431\n",
            "Epoch [14/50] - Batch loss: 163.5509 - Epoch Loss: 24260.0189 - Avg Loss: 160.6624\n",
            "Epoch [14/50] - Batch loss: 164.3459 - Epoch Loss: 24424.3648 - Avg Loss: 160.6866\n",
            "Epoch [14/50] - Batch loss: 156.4243 - Epoch Loss: 24580.7892 - Avg Loss: 160.6588\n",
            "Epoch [14/50] - Batch loss: 158.2807 - Epoch Loss: 24739.0698 - Avg Loss: 160.6433\n",
            "Epoch [14/50] - Batch loss: 152.6237 - Epoch Loss: 24891.6936 - Avg Loss: 160.5916\n",
            "Epoch [14/50] - Batch loss: 167.5446 - Epoch Loss: 25059.2381 - Avg Loss: 160.6361\n",
            "Epoch [14/50] - Batch loss: 166.6967 - Epoch Loss: 25225.9349 - Avg Loss: 160.6747\n",
            "Epoch [14/50] - Batch loss: 155.8233 - Epoch Loss: 25381.7582 - Avg Loss: 160.6440\n",
            "Epoch [14/50] - Batch loss: 167.6914 - Epoch Loss: 25549.4496 - Avg Loss: 160.6884\n",
            "Epoch [14/50] - Batch loss: 160.3822 - Epoch Loss: 25709.8318 - Avg Loss: 160.6864\n",
            "Epoch [14/50] - Batch loss: 160.4737 - Epoch Loss: 25870.3055 - Avg Loss: 160.6851\n",
            "Epoch [14/50] - Batch loss: 164.2411 - Epoch Loss: 26034.5466 - Avg Loss: 160.7071\n",
            "Epoch [14/50] - Batch loss: 166.7567 - Epoch Loss: 26201.3033 - Avg Loss: 160.7442\n",
            "Epoch [14/50] - Batch loss: 167.0931 - Epoch Loss: 26368.3965 - Avg Loss: 160.7829\n",
            "Epoch [14/50] - Batch loss: 160.2054 - Epoch Loss: 26528.6018 - Avg Loss: 160.7794\n",
            "Epoch [14/50] - Batch loss: 160.2108 - Epoch Loss: 26688.8126 - Avg Loss: 160.7760\n",
            "Epoch [14/50] - Batch loss: 168.6423 - Epoch Loss: 26857.4549 - Avg Loss: 160.8231\n",
            "Epoch [14/50] - Batch loss: 165.2412 - Epoch Loss: 27022.6962 - Avg Loss: 160.8494\n",
            "Epoch [14/50] - Batch loss: 165.5721 - Epoch Loss: 27188.2682 - Avg Loss: 160.8773\n",
            "Epoch [14/50] - Batch loss: 162.9748 - Epoch Loss: 27351.2430 - Avg Loss: 160.8897\n",
            "Epoch [14/50] - Batch loss: 155.8516 - Epoch Loss: 27507.0946 - Avg Loss: 160.8602\n",
            "Epoch [14/50] - Batch loss: 160.2281 - Epoch Loss: 27667.3228 - Avg Loss: 160.8565\n",
            "Epoch [14/50] - Batch loss: 162.0859 - Epoch Loss: 27829.4086 - Avg Loss: 160.8636\n",
            "Epoch [14/50] - Batch loss: 169.4148 - Epoch Loss: 27998.8234 - Avg Loss: 160.9128\n",
            "Epoch [14/50] - Batch loss: 162.5519 - Epoch Loss: 28161.3753 - Avg Loss: 160.9221\n",
            "Epoch [14/50] - Batch loss: 173.4532 - Epoch Loss: 28334.8285 - Avg Loss: 160.9933\n",
            "Epoch [14/50] - Batch loss: 166.6794 - Epoch Loss: 28501.5079 - Avg Loss: 161.0255\n",
            "Epoch [14/50] - Batch loss: 156.2990 - Epoch Loss: 28657.8069 - Avg Loss: 160.9989\n",
            "Epoch [14/50] - Batch loss: 171.0346 - Epoch Loss: 28828.8415 - Avg Loss: 161.0550\n",
            "Epoch [14/50] - Batch loss: 159.3690 - Epoch Loss: 28988.2105 - Avg Loss: 161.0456\n",
            "Epoch [14/50] - Batch loss: 173.6454 - Epoch Loss: 29161.8559 - Avg Loss: 161.1152\n",
            "Epoch [14/50] - Batch loss: 158.9471 - Epoch Loss: 29320.8030 - Avg Loss: 161.1033\n",
            "Epoch [14/50] - Batch loss: 162.8697 - Epoch Loss: 29483.6727 - Avg Loss: 161.1130\n",
            "Epoch [14/50] - Batch loss: 156.9806 - Epoch Loss: 29640.6532 - Avg Loss: 161.0905\n",
            "Epoch [14/50] - Batch loss: 157.7631 - Epoch Loss: 29798.4163 - Avg Loss: 161.0725\n",
            "Epoch [14/50] - Batch loss: 163.4214 - Epoch Loss: 29961.8377 - Avg Loss: 161.0851\n",
            "Epoch [14/50] - Batch loss: 163.9808 - Epoch Loss: 30125.8185 - Avg Loss: 161.1006\n",
            "Epoch [14/50] - Batch loss: 167.4236 - Epoch Loss: 30293.2421 - Avg Loss: 161.1343\n",
            "Epoch [14/50] - Batch loss: 162.0027 - Epoch Loss: 30455.2447 - Avg Loss: 161.1389\n",
            "Epoch [14/50] - Batch loss: 160.7012 - Epoch Loss: 30615.9459 - Avg Loss: 161.1366\n",
            "Epoch [14/50] - Batch loss: 160.7327 - Epoch Loss: 30776.6787 - Avg Loss: 161.1344\n",
            "Epoch [14/50] - Batch loss: 160.6774 - Epoch Loss: 30937.3561 - Avg Loss: 161.1321\n",
            "Epoch [14/50] - Batch loss: 170.4909 - Epoch Loss: 31107.8470 - Avg Loss: 161.1806\n",
            "Epoch [14/50] - Batch loss: 164.9008 - Epoch Loss: 31272.7478 - Avg Loss: 161.1997\n",
            "Epoch [14/50] - Batch loss: 163.7890 - Epoch Loss: 31436.5368 - Avg Loss: 161.2130\n",
            "Epoch [14/50] - Batch loss: 157.3897 - Epoch Loss: 31593.9265 - Avg Loss: 161.1935\n",
            "Epoch [14/50] - Batch loss: 162.5399 - Epoch Loss: 31756.4664 - Avg Loss: 161.2003\n",
            "Epoch [14/50] - Batch loss: 163.4654 - Epoch Loss: 31919.9318 - Avg Loss: 161.2118\n",
            "Epoch [14/50] - Batch loss: 155.2786 - Epoch Loss: 32075.2104 - Avg Loss: 161.1820\n",
            "Epoch [14/50] - Batch loss: 163.6877 - Epoch Loss: 32238.8980 - Avg Loss: 161.1945\n",
            "Epoch [14/50] - Batch loss: 161.0760 - Epoch Loss: 32399.9741 - Avg Loss: 161.1939\n",
            "Epoch [14/50] - Batch loss: 156.4188 - Epoch Loss: 32556.3929 - Avg Loss: 161.1703\n",
            "Epoch [14/50] - Batch loss: 163.7433 - Epoch Loss: 32720.1361 - Avg Loss: 161.1829\n",
            "Epoch [14/50] - Batch loss: 155.6929 - Epoch Loss: 32875.8290 - Avg Loss: 161.1560\n",
            "Epoch [14/50] - Batch loss: 163.9444 - Epoch Loss: 33039.7734 - Avg Loss: 161.1696\n",
            "Epoch [14/50] - Batch loss: 164.5172 - Epoch Loss: 33204.2906 - Avg Loss: 161.1859\n",
            "Epoch [14/50] - Batch loss: 169.8261 - Epoch Loss: 33374.1167 - Avg Loss: 161.2276\n",
            "Epoch [14/50] - Batch loss: 159.2426 - Epoch Loss: 33533.3593 - Avg Loss: 161.2181\n",
            "Epoch [14/50] - Batch loss: 156.9053 - Epoch Loss: 33690.2647 - Avg Loss: 161.1974\n",
            "Epoch [14/50] - Batch loss: 156.8190 - Epoch Loss: 33847.0836 - Avg Loss: 161.1766\n",
            "Epoch [14/50] - Batch loss: 158.6354 - Epoch Loss: 34005.7191 - Avg Loss: 161.1645\n",
            "Epoch [14/50] - Batch loss: 163.6314 - Epoch Loss: 34169.3505 - Avg Loss: 161.1762\n",
            "Epoch [14/50] - Batch loss: 161.2442 - Epoch Loss: 34330.5947 - Avg Loss: 161.1765\n",
            "Epoch [14/50] - Batch loss: 167.0556 - Epoch Loss: 34497.6503 - Avg Loss: 161.2040\n",
            "Epoch [14/50] - Batch loss: 162.6896 - Epoch Loss: 34660.3399 - Avg Loss: 161.2109\n",
            "Epoch [14/50] - Batch loss: 162.8655 - Epoch Loss: 34823.2054 - Avg Loss: 161.2185\n",
            "Epoch [14/50] - Batch loss: 162.2365 - Epoch Loss: 34985.4419 - Avg Loss: 161.2232\n",
            "Epoch [14/50] - Batch loss: 161.4617 - Epoch Loss: 35146.9036 - Avg Loss: 161.2243\n",
            "Epoch [14/50] - Batch loss: 168.4308 - Epoch Loss: 35315.3345 - Avg Loss: 161.2572\n",
            "Epoch [14/50] - Batch loss: 155.6895 - Epoch Loss: 35471.0239 - Avg Loss: 161.2319\n",
            "Epoch [14/50] - Batch loss: 164.2449 - Epoch Loss: 35635.2688 - Avg Loss: 161.2456\n",
            "Epoch [14/50] - Batch loss: 167.6140 - Epoch Loss: 35802.8828 - Avg Loss: 161.2742\n",
            "Epoch [14/50] - Batch loss: 161.1639 - Epoch Loss: 35964.0467 - Avg Loss: 161.2738\n",
            "Epoch [14/50] - Batch loss: 167.6253 - Epoch Loss: 36131.6721 - Avg Loss: 161.3021\n",
            "Epoch [14/50] - Batch loss: 154.1877 - Epoch Loss: 36285.8597 - Avg Loss: 161.2705\n",
            "Epoch [14/50] - Batch loss: 154.6724 - Epoch Loss: 36440.5322 - Avg Loss: 161.2413\n",
            "Epoch [14/50] - Batch loss: 160.7638 - Epoch Loss: 36601.2960 - Avg Loss: 161.2392\n",
            "Epoch [14/50] - Batch loss: 164.1062 - Epoch Loss: 36765.4023 - Avg Loss: 161.2518\n",
            "Epoch [14/50] - Batch loss: 159.1155 - Epoch Loss: 36924.5178 - Avg Loss: 161.2424\n",
            "Epoch [14/50] - Batch loss: 165.8124 - Epoch Loss: 37090.3302 - Avg Loss: 161.2623\n",
            "Epoch [14/50] - Batch loss: 163.6880 - Epoch Loss: 37254.0182 - Avg Loss: 161.2728\n",
            "Epoch [14/50] - Batch loss: 162.0895 - Epoch Loss: 37416.1077 - Avg Loss: 161.2763\n",
            "Epoch [14/50] - Batch loss: 158.4530 - Epoch Loss: 37574.5607 - Avg Loss: 161.2642\n",
            "Epoch [14/50] - Batch loss: 166.6152 - Epoch Loss: 37741.1759 - Avg Loss: 161.2871\n",
            "Epoch [14/50] - Batch loss: 155.5597 - Epoch Loss: 37896.7356 - Avg Loss: 161.2627\n",
            "Epoch [14/50] - Batch loss: 172.4794 - Epoch Loss: 38069.2150 - Avg Loss: 161.3102\n",
            "Epoch [14/50] - Batch loss: 163.0799 - Epoch Loss: 38232.2949 - Avg Loss: 161.3177\n",
            "Epoch [14/50] - Batch loss: 155.4863 - Epoch Loss: 38387.7812 - Avg Loss: 161.2932\n",
            "Epoch [14/50] - Batch loss: 160.1296 - Epoch Loss: 38547.9108 - Avg Loss: 161.2883\n",
            "Epoch [14/50] - Batch loss: 161.1378 - Epoch Loss: 38709.0486 - Avg Loss: 161.2877\n",
            "Epoch [14/50] - Batch loss: 169.9254 - Epoch Loss: 38878.9740 - Avg Loss: 161.3235\n",
            "Epoch [14/50] - Batch loss: 151.6379 - Epoch Loss: 39030.6118 - Avg Loss: 161.2835\n",
            "Epoch [14/50] - Batch loss: 168.9045 - Epoch Loss: 39199.5163 - Avg Loss: 161.3149\n",
            "Epoch [14/50] - Batch loss: 164.4910 - Epoch Loss: 39364.0074 - Avg Loss: 161.3279\n",
            "Epoch [14/50] - Batch loss: 165.3110 - Epoch Loss: 39529.3184 - Avg Loss: 161.3442\n",
            "Epoch [14/50] - Batch loss: 158.8257 - Epoch Loss: 39688.1441 - Avg Loss: 161.3339\n",
            "Epoch [14/50] - Batch loss: 164.4630 - Epoch Loss: 39852.6071 - Avg Loss: 161.3466\n",
            "Epoch [14/50] - Batch loss: 158.1064 - Epoch Loss: 40010.7135 - Avg Loss: 161.3335\n",
            "Epoch [14/50] - Batch loss: 154.5744 - Epoch Loss: 40165.2878 - Avg Loss: 161.3064\n",
            "Epoch [14/50] - Batch loss: 162.4726 - Epoch Loss: 40327.7604 - Avg Loss: 161.3110\n",
            "Epoch [14/50] - Batch loss: 155.6756 - Epoch Loss: 40483.4360 - Avg Loss: 161.2886\n",
            "Epoch [14/50] - Batch loss: 161.1049 - Epoch Loss: 40644.5409 - Avg Loss: 161.2879\n",
            "Epoch [14/50] - Batch loss: 159.7613 - Epoch Loss: 40804.3022 - Avg Loss: 161.2818\n",
            "Epoch [14/50] - Batch loss: 164.1034 - Epoch Loss: 40968.4056 - Avg Loss: 161.2929\n",
            "Epoch [14/50] - Batch loss: 154.0495 - Epoch Loss: 41122.4551 - Avg Loss: 161.2645\n",
            "Epoch [14/50] - Batch loss: 158.7274 - Epoch Loss: 41281.1825 - Avg Loss: 161.2546\n",
            "Epoch [14/50] - Batch loss: 160.5634 - Epoch Loss: 41441.7460 - Avg Loss: 161.2519\n",
            "Epoch [14/50] - Batch loss: 159.0580 - Epoch Loss: 41600.8039 - Avg Loss: 161.2434\n",
            "Epoch [14/50] - Batch loss: 161.4358 - Epoch Loss: 41762.2398 - Avg Loss: 161.2442\n",
            "Epoch [14/50] - Batch loss: 160.0672 - Epoch Loss: 41922.3070 - Avg Loss: 161.2396\n",
            "Epoch [14/50] - Batch loss: 165.2414 - Epoch Loss: 42087.5484 - Avg Loss: 161.2550\n",
            "Epoch [14/50] - Batch loss: 161.9297 - Epoch Loss: 42249.4781 - Avg Loss: 161.2576\n",
            "Epoch [14/50] - Batch loss: 158.1988 - Epoch Loss: 42407.6769 - Avg Loss: 161.2459\n",
            "Epoch [14/50] - Batch loss: 156.5586 - Epoch Loss: 42564.2355 - Avg Loss: 161.2282\n",
            "Epoch [14/50] - Batch loss: 162.7605 - Epoch Loss: 42726.9960 - Avg Loss: 161.2339\n",
            "Epoch [14/50] - Batch loss: 157.3767 - Epoch Loss: 42884.3727 - Avg Loss: 161.2194\n",
            "Epoch [14/50] - Batch loss: 159.1421 - Epoch Loss: 43043.5148 - Avg Loss: 161.2117\n",
            "Epoch [14/50] - Batch loss: 160.8159 - Epoch Loss: 43204.3307 - Avg Loss: 161.2102\n",
            "Epoch [14/50] - Batch loss: 161.5130 - Epoch Loss: 43365.8437 - Avg Loss: 161.2113\n",
            "Epoch [14/50] - Batch loss: 161.9466 - Epoch Loss: 43527.7903 - Avg Loss: 161.2140\n",
            "Epoch [14/50] - Batch loss: 165.6990 - Epoch Loss: 43693.4893 - Avg Loss: 161.2306\n",
            "Epoch [14/50] - Batch loss: 174.1962 - Epoch Loss: 43867.6855 - Avg Loss: 161.2783\n",
            "Epoch [14/50] - Batch loss: 162.4414 - Epoch Loss: 44030.1269 - Avg Loss: 161.2825\n",
            "Epoch [14/50] - Batch loss: 153.4847 - Epoch Loss: 44183.6116 - Avg Loss: 161.2541\n",
            "Epoch [14/50] - Batch loss: 158.4679 - Epoch Loss: 44342.0794 - Avg Loss: 161.2439\n",
            "Epoch [14/50] - Batch loss: 162.5831 - Epoch Loss: 44504.6626 - Avg Loss: 161.2488\n",
            "Epoch [14/50] - Batch loss: 156.0653 - Epoch Loss: 44660.7279 - Avg Loss: 161.2301\n",
            "Epoch [14/50] - Batch loss: 158.8725 - Epoch Loss: 44819.6004 - Avg Loss: 161.2216\n",
            "Epoch [14/50] - Batch loss: 157.3868 - Epoch Loss: 44976.9872 - Avg Loss: 161.2078\n",
            "Epoch [14/50] - Batch loss: 154.3755 - Epoch Loss: 45131.3627 - Avg Loss: 161.1834\n",
            "Epoch [14/50] - Batch loss: 162.8162 - Epoch Loss: 45294.1789 - Avg Loss: 161.1892\n",
            "Epoch [14/50] - Batch loss: 161.4739 - Epoch Loss: 45455.6528 - Avg Loss: 161.1903\n",
            "Epoch [14/50] - Batch loss: 167.1572 - Epoch Loss: 45622.8100 - Avg Loss: 161.2113\n",
            "Epoch [14/50] - Batch loss: 161.9208 - Epoch Loss: 45784.7309 - Avg Loss: 161.2138\n",
            "Epoch [14/50] - Batch loss: 164.9702 - Epoch Loss: 45949.7011 - Avg Loss: 161.2270\n",
            "Epoch [14/50] - Batch loss: 162.9202 - Epoch Loss: 46112.6213 - Avg Loss: 161.2329\n",
            "Epoch [14/50] - Batch loss: 163.8327 - Epoch Loss: 46276.4540 - Avg Loss: 161.2420\n",
            "Epoch [14/50] - Batch loss: 162.9837 - Epoch Loss: 46439.4376 - Avg Loss: 161.2480\n",
            "Epoch [14/50] - Batch loss: 168.5102 - Epoch Loss: 46607.9478 - Avg Loss: 161.2732\n",
            "Epoch [14/50] - Batch loss: 161.6825 - Epoch Loss: 46769.6303 - Avg Loss: 161.2746\n",
            "Epoch [14/50] - Batch loss: 157.9859 - Epoch Loss: 46927.6161 - Avg Loss: 161.2633\n",
            "Epoch [14/50] - Batch loss: 166.5887 - Epoch Loss: 47094.2049 - Avg Loss: 161.2815\n",
            "Epoch [14/50] - Batch loss: 166.3211 - Epoch Loss: 47260.5260 - Avg Loss: 161.2987\n",
            "Epoch [14/50] - Batch loss: 161.5492 - Epoch Loss: 47422.0752 - Avg Loss: 161.2996\n",
            "Epoch [14/50] - Batch loss: 160.0407 - Epoch Loss: 47582.1159 - Avg Loss: 161.2953\n",
            "Epoch [14/50] - Batch loss: 161.3748 - Epoch Loss: 47743.4906 - Avg Loss: 161.2956\n",
            "Epoch [14/50] - Batch loss: 167.4541 - Epoch Loss: 47910.9447 - Avg Loss: 161.3163\n",
            "Epoch [14/50] - Batch loss: 162.7336 - Epoch Loss: 48073.6783 - Avg Loss: 161.3211\n",
            "Epoch [14/50] - Batch loss: 158.4372 - Epoch Loss: 48232.1155 - Avg Loss: 161.3114\n",
            "Epoch [14/50] - Batch loss: 155.9103 - Epoch Loss: 48388.0258 - Avg Loss: 161.2934\n",
            "Epoch [14/50] - Batch loss: 160.0663 - Epoch Loss: 48548.0921 - Avg Loss: 161.2893\n",
            "Epoch [14/50] - Batch loss: 164.0470 - Epoch Loss: 48712.1391 - Avg Loss: 161.2985\n",
            "Epoch [14/50] - Batch loss: 161.5573 - Epoch Loss: 48873.6964 - Avg Loss: 161.2993\n",
            "Epoch [14/50] - Batch loss: 159.6576 - Epoch Loss: 49033.3539 - Avg Loss: 161.2939\n",
            "Epoch [14/50] - Batch loss: 158.6019 - Epoch Loss: 49191.9558 - Avg Loss: 161.2851\n",
            "Epoch [14/50] - Batch loss: 165.9740 - Epoch Loss: 49357.9299 - Avg Loss: 161.3004\n",
            "Epoch [14/50] - Batch loss: 157.4193 - Epoch Loss: 49515.3492 - Avg Loss: 161.2878\n",
            "Epoch [14/50] - Batch loss: 154.3493 - Epoch Loss: 49669.6985 - Avg Loss: 161.2653\n",
            "Epoch [14/50] - Batch loss: 155.5025 - Epoch Loss: 49825.2010 - Avg Loss: 161.2466\n",
            "Epoch [14/50] - Batch loss: 163.0664 - Epoch Loss: 49988.2675 - Avg Loss: 161.2525\n",
            "Epoch [14/50] - Batch loss: 160.9402 - Epoch Loss: 50149.2077 - Avg Loss: 161.2515\n",
            "Epoch [14/50] - Batch loss: 170.9788 - Epoch Loss: 50320.1865 - Avg Loss: 161.2826\n",
            "Epoch [14/50] - Batch loss: 160.1833 - Epoch Loss: 50480.3698 - Avg Loss: 161.2791\n",
            "Epoch [14/50] - Batch loss: 160.2535 - Epoch Loss: 50640.6233 - Avg Loss: 161.2759\n",
            "Epoch [14/50] - Batch loss: 166.5366 - Epoch Loss: 50807.1599 - Avg Loss: 161.2926\n",
            "Epoch [14/50] - Batch loss: 160.3810 - Epoch Loss: 50967.5410 - Avg Loss: 161.2897\n",
            "Epoch [14/50] - Batch loss: 160.4138 - Epoch Loss: 51127.9548 - Avg Loss: 161.2869\n",
            "Epoch [14/50] - Batch loss: 168.4916 - Epoch Loss: 51296.4464 - Avg Loss: 161.3096\n",
            "Epoch [14/50] - Batch loss: 167.3088 - Epoch Loss: 51463.7551 - Avg Loss: 161.3284\n",
            "Epoch [14/50] - Batch loss: 160.1971 - Epoch Loss: 51623.9522 - Avg Loss: 161.3249\n",
            "Epoch [14/50] - Batch loss: 159.6764 - Epoch Loss: 51783.6286 - Avg Loss: 161.3197\n",
            "Epoch [14/50] - Batch loss: 162.0123 - Epoch Loss: 51945.6409 - Avg Loss: 161.3219\n",
            "Epoch [14/50] - Batch loss: 159.9232 - Epoch Loss: 52105.5641 - Avg Loss: 161.3175\n",
            "Epoch [14/50] - Batch loss: 155.4197 - Epoch Loss: 52260.9838 - Avg Loss: 161.2993\n",
            "Epoch [14/50] - Batch loss: 159.0562 - Epoch Loss: 52420.0399 - Avg Loss: 161.2924\n",
            "Epoch [14/50] - Batch loss: 157.9120 - Epoch Loss: 52577.9519 - Avg Loss: 161.2821\n",
            "Epoch [14/50] - Batch loss: 167.7498 - Epoch Loss: 52745.7018 - Avg Loss: 161.3018\n",
            "Epoch [14/50] - Batch loss: 160.3239 - Epoch Loss: 52906.0256 - Avg Loss: 161.2989\n",
            "Epoch [14/50] - Batch loss: 163.6559 - Epoch Loss: 53069.6815 - Avg Loss: 161.3060\n",
            "Epoch [14/50] - Batch loss: 160.7314 - Epoch Loss: 53230.4129 - Avg Loss: 161.3043\n",
            "Epoch [14/50] - Batch loss: 154.4541 - Epoch Loss: 53384.8671 - Avg Loss: 161.2836\n",
            "Epoch [14/50] - Batch loss: 171.0095 - Epoch Loss: 53555.8766 - Avg Loss: 161.3129\n",
            "Epoch [14/50] - Batch loss: 159.6196 - Epoch Loss: 53715.4962 - Avg Loss: 161.3078\n",
            "Epoch [14/50] - Batch loss: 156.6528 - Epoch Loss: 53872.1490 - Avg Loss: 161.2939\n",
            "Epoch [14/50] - Batch loss: 154.8601 - Epoch Loss: 54027.0091 - Avg Loss: 161.2747\n",
            "Epoch [14/50] - Batch loss: 163.5812 - Epoch Loss: 54190.5903 - Avg Loss: 161.2815\n",
            "Epoch [14/50] - Batch loss: 163.9224 - Epoch Loss: 54354.5127 - Avg Loss: 161.2894\n",
            "Epoch [14/50] - Batch loss: 171.1055 - Epoch Loss: 54525.6182 - Avg Loss: 161.3184\n",
            "Epoch [14/50] - Batch loss: 174.8338 - Epoch Loss: 54700.4520 - Avg Loss: 161.3583\n",
            "Epoch [14/50] - Batch loss: 164.9873 - Epoch Loss: 54865.4393 - Avg Loss: 161.3689\n",
            "Epoch [14/50] - Batch loss: 164.1753 - Epoch Loss: 55029.6146 - Avg Loss: 161.3772\n",
            "Epoch [14/50] - Batch loss: 163.3638 - Epoch Loss: 55192.9784 - Avg Loss: 161.3830\n",
            "Epoch [14/50] - Batch loss: 161.4030 - Epoch Loss: 55354.3813 - Avg Loss: 161.3830\n",
            "Epoch [14/50] - Batch loss: 155.6258 - Epoch Loss: 55510.0071 - Avg Loss: 161.3663\n",
            "Epoch [14/50] - Batch loss: 164.3261 - Epoch Loss: 55674.3332 - Avg Loss: 161.3749\n",
            "Epoch [14/50] - Batch loss: 156.7167 - Epoch Loss: 55831.0499 - Avg Loss: 161.3614\n",
            "Epoch [14/50] - Batch loss: 161.6712 - Epoch Loss: 55992.7211 - Avg Loss: 161.3623\n",
            "Epoch [14/50] - Batch loss: 165.6042 - Epoch Loss: 56158.3252 - Avg Loss: 161.3745\n",
            "Epoch [14/50] - Batch loss: 160.2226 - Epoch Loss: 56318.5478 - Avg Loss: 161.3712\n",
            "Epoch [14/50] - Batch loss: 165.4465 - Epoch Loss: 56483.9943 - Avg Loss: 161.3828\n",
            "Epoch [14/50] - Batch loss: 170.2122 - Epoch Loss: 56654.2065 - Avg Loss: 161.4080\n",
            "Epoch [14/50] - Batch loss: 163.2209 - Epoch Loss: 56817.4274 - Avg Loss: 161.4131\n",
            "Epoch [14/50] - Batch loss: 165.5282 - Epoch Loss: 56982.9556 - Avg Loss: 161.4248\n",
            "Epoch [14/50] - Batch loss: 166.0905 - Epoch Loss: 57149.0461 - Avg Loss: 161.4380\n",
            "Epoch [14/50] - Batch loss: 162.1078 - Epoch Loss: 57311.1539 - Avg Loss: 161.4399\n",
            "Epoch [14/50] - Batch loss: 162.0371 - Epoch Loss: 57473.1910 - Avg Loss: 161.4415\n",
            "Epoch [14/50] - Batch loss: 159.4819 - Epoch Loss: 57632.6729 - Avg Loss: 161.4361\n",
            "Epoch [14/50] - Batch loss: 158.8689 - Epoch Loss: 57791.5418 - Avg Loss: 161.4289\n",
            "Epoch [14/50] - Batch loss: 159.4885 - Epoch Loss: 57951.0303 - Avg Loss: 161.4235\n",
            "Epoch [14/50] - Batch loss: 159.4595 - Epoch Loss: 58110.4898 - Avg Loss: 161.4180\n",
            "Epoch [14/50] - Batch loss: 161.2938 - Epoch Loss: 58271.7836 - Avg Loss: 161.4177\n",
            "Epoch [14/50] - Batch loss: 159.3234 - Epoch Loss: 58431.1070 - Avg Loss: 161.4119\n",
            "Epoch [14/50] - Batch loss: 158.3560 - Epoch Loss: 58589.4630 - Avg Loss: 161.4035\n",
            "Epoch [14/50] - Batch loss: 163.1871 - Epoch Loss: 58752.6501 - Avg Loss: 161.4084\n",
            "Epoch [14/50] - Batch loss: 156.2650 - Epoch Loss: 58908.9151 - Avg Loss: 161.3943\n",
            "Epoch [14/50] - Batch loss: 162.1620 - Epoch Loss: 59071.0771 - Avg Loss: 161.3964\n",
            "Epoch [14/50] - Batch loss: 158.7120 - Epoch Loss: 59229.7891 - Avg Loss: 161.3891\n",
            "Epoch [14/50] - Batch loss: 158.3253 - Epoch Loss: 59388.1144 - Avg Loss: 161.3807\n",
            "Epoch [14/50] - Batch loss: 161.3817 - Epoch Loss: 59549.4962 - Avg Loss: 161.3807\n",
            "Epoch [14/50] - Batch loss: 164.5030 - Epoch Loss: 59713.9991 - Avg Loss: 161.3892\n",
            "Epoch [14/50] - Batch loss: 167.8024 - Epoch Loss: 59881.8015 - Avg Loss: 161.4065\n",
            "Epoch [14/50] - Batch loss: 159.0934 - Epoch Loss: 60040.8949 - Avg Loss: 161.4003\n",
            "Epoch [14/50] - Batch loss: 163.6518 - Epoch Loss: 60204.5467 - Avg Loss: 161.4063\n",
            "Epoch [14/50] - Batch loss: 158.3108 - Epoch Loss: 60362.8575 - Avg Loss: 161.3980\n",
            "Epoch [14/50] - Batch loss: 152.7368 - Epoch Loss: 60515.5943 - Avg Loss: 161.3749\n",
            "Epoch [14/50] - Batch loss: 160.1824 - Epoch Loss: 60675.7767 - Avg Loss: 161.3717\n",
            "Epoch [14/50] - Batch loss: 164.4169 - Epoch Loss: 60840.1935 - Avg Loss: 161.3798\n",
            "Epoch [14/50] - Batch loss: 170.0159 - Epoch Loss: 61010.2094 - Avg Loss: 161.4027\n",
            "Epoch [14/50] - Batch loss: 169.6151 - Epoch Loss: 61179.8245 - Avg Loss: 161.4243\n",
            "Epoch [14/50] - Batch loss: 157.1035 - Epoch Loss: 61336.9280 - Avg Loss: 161.4130\n",
            "Epoch [14/50] - Batch loss: 163.7555 - Epoch Loss: 61500.6835 - Avg Loss: 161.4191\n",
            "Epoch [14/50] - Batch loss: 170.9968 - Epoch Loss: 61671.6803 - Avg Loss: 161.4442\n",
            "Epoch [14/50] - Batch loss: 158.0622 - Epoch Loss: 61829.7425 - Avg Loss: 161.4354\n",
            "Epoch [14/50] - Batch loss: 157.4940 - Epoch Loss: 61987.2365 - Avg Loss: 161.4251\n",
            "Epoch [14/50] - Batch loss: 157.5585 - Epoch Loss: 62144.7950 - Avg Loss: 161.4151\n",
            "Epoch [14/50] - Batch loss: 163.0378 - Epoch Loss: 62307.8328 - Avg Loss: 161.4193\n",
            "Epoch [14/50] - Batch loss: 162.2181 - Epoch Loss: 62470.0509 - Avg Loss: 161.4213\n",
            "Epoch [14/50] - Batch loss: 156.1435 - Epoch Loss: 62626.1944 - Avg Loss: 161.4077\n",
            "Epoch [14/50] - Batch loss: 162.1373 - Epoch Loss: 62788.3317 - Avg Loss: 161.4096\n",
            "Epoch [14/50] - Batch loss: 169.0640 - Epoch Loss: 62957.3958 - Avg Loss: 161.4292\n",
            "Epoch [14/50] - Batch loss: 159.1104 - Epoch Loss: 63116.5061 - Avg Loss: 161.4233\n",
            "Epoch [14/50] - Batch loss: 169.1155 - Epoch Loss: 63285.6216 - Avg Loss: 161.4429\n",
            "Epoch [14/50] - Batch loss: 165.3103 - Epoch Loss: 63450.9320 - Avg Loss: 161.4528\n",
            "Epoch [14/50] - Batch loss: 168.0207 - Epoch Loss: 63618.9527 - Avg Loss: 161.4694\n",
            "Epoch [14/50] - Batch loss: 156.4093 - Epoch Loss: 63775.3620 - Avg Loss: 161.4566\n",
            "Epoch [14/50] - Batch loss: 160.4348 - Epoch Loss: 63935.7968 - Avg Loss: 161.4540\n",
            "Epoch [14/50] - Batch loss: 161.8738 - Epoch Loss: 64097.6706 - Avg Loss: 161.4551\n",
            "Epoch [14/50] - Batch loss: 166.7034 - Epoch Loss: 64264.3740 - Avg Loss: 161.4683\n",
            "Epoch [14/50] - Batch loss: 161.6863 - Epoch Loss: 64426.0603 - Avg Loss: 161.4688\n",
            "Epoch [14/50] - Batch loss: 156.8861 - Epoch Loss: 64582.9464 - Avg Loss: 161.4574\n",
            "Epoch [14/50] - Batch loss: 158.2730 - Epoch Loss: 64741.2193 - Avg Loss: 161.4494\n",
            "Epoch [14/50] - Batch loss: 151.7342 - Epoch Loss: 64892.9536 - Avg Loss: 161.4253\n",
            "Epoch [14/50] - Batch loss: 166.8064 - Epoch Loss: 65059.7600 - Avg Loss: 161.4386\n",
            "Epoch [14/50] - Batch loss: 161.1361 - Epoch Loss: 65220.8961 - Avg Loss: 161.4379\n",
            "Epoch [14/50] - Batch loss: 157.5340 - Epoch Loss: 65378.4301 - Avg Loss: 161.4282\n",
            "Epoch [14/50] - Batch loss: 160.8809 - Epoch Loss: 65539.3110 - Avg Loss: 161.4269\n",
            "Epoch [14/50] - Batch loss: 156.4417 - Epoch Loss: 65695.7527 - Avg Loss: 161.4146\n",
            "Epoch [14/50] - Batch loss: 156.5868 - Epoch Loss: 65852.3395 - Avg Loss: 161.4028\n",
            "Epoch [14/50] - Batch loss: 159.5971 - Epoch Loss: 66011.9365 - Avg Loss: 161.3984\n",
            "Epoch [14/50] - Batch loss: 165.3135 - Epoch Loss: 66177.2500 - Avg Loss: 161.4079\n",
            "Epoch [14/50] - Batch loss: 161.1824 - Epoch Loss: 66338.4324 - Avg Loss: 161.4074\n",
            "Epoch [14/50] - Batch loss: 159.3433 - Epoch Loss: 66497.7758 - Avg Loss: 161.4024\n",
            "Epoch [14/50] - Batch loss: 159.0532 - Epoch Loss: 66656.8290 - Avg Loss: 161.3967\n",
            "Epoch [14/50] - Batch loss: 163.1999 - Epoch Loss: 66820.0289 - Avg Loss: 161.4010\n",
            "Epoch [14/50] - Batch loss: 162.4037 - Epoch Loss: 66982.4325 - Avg Loss: 161.4035\n",
            "Epoch [14/50] - Batch loss: 154.6535 - Epoch Loss: 67137.0860 - Avg Loss: 161.3872\n",
            "Epoch [14/50] - Batch loss: 164.7647 - Epoch Loss: 67301.8507 - Avg Loss: 161.3953\n",
            "Epoch [14/50] - Batch loss: 159.5633 - Epoch Loss: 67461.4140 - Avg Loss: 161.3909\n",
            "Epoch [14/50] - Batch loss: 154.1067 - Epoch Loss: 67615.5208 - Avg Loss: 161.3736\n",
            "Epoch [14/50] - Batch loss: 163.9475 - Epoch Loss: 67779.4682 - Avg Loss: 161.3797\n",
            "Epoch [14/50] - Batch loss: 163.1160 - Epoch Loss: 67942.5843 - Avg Loss: 161.3838\n",
            "Epoch [14/50] - Batch loss: 155.8510 - Epoch Loss: 68098.4353 - Avg Loss: 161.3707\n",
            "Epoch [14/50] - Batch loss: 149.5774 - Epoch Loss: 68248.0127 - Avg Loss: 161.3428\n",
            "Epoch [14/50] - Batch loss: 162.8754 - Epoch Loss: 68410.8880 - Avg Loss: 161.3464\n",
            "Epoch [14/50] - Batch loss: 155.0319 - Epoch Loss: 68565.9199 - Avg Loss: 161.3316\n",
            "Epoch [14/50] - Batch loss: 167.1354 - Epoch Loss: 68733.0553 - Avg Loss: 161.3452\n",
            "Epoch [14/50] - Batch loss: 162.1421 - Epoch Loss: 68895.1974 - Avg Loss: 161.3471\n",
            "Epoch [14/50] - Batch loss: 162.1123 - Epoch Loss: 69057.3097 - Avg Loss: 161.3489\n",
            "Epoch [14/50] - Batch loss: 160.2850 - Epoch Loss: 69217.5947 - Avg Loss: 161.3464\n",
            "Epoch [14/50] - Batch loss: 156.1788 - Epoch Loss: 69373.7734 - Avg Loss: 161.3344\n",
            "Epoch [14/50] - Batch loss: 150.8000 - Epoch Loss: 69524.5734 - Avg Loss: 161.3099\n",
            "Epoch [14/50] - Batch loss: 159.3529 - Epoch Loss: 69683.9263 - Avg Loss: 161.3054\n",
            "Epoch [14/50] - Batch loss: 157.6634 - Epoch Loss: 69841.5897 - Avg Loss: 161.2970\n",
            "Epoch [14/50] - Batch loss: 154.2561 - Epoch Loss: 69995.8457 - Avg Loss: 161.2808\n",
            "Epoch [14/50] - Batch loss: 166.7341 - Epoch Loss: 70162.5798 - Avg Loss: 161.2933\n",
            "Epoch [14/50] - Batch loss: 158.4324 - Epoch Loss: 70321.0123 - Avg Loss: 161.2867\n",
            "Epoch [14/50] - Batch loss: 172.3607 - Epoch Loss: 70493.3729 - Avg Loss: 161.3121\n",
            "Epoch [14/50] - Batch loss: 162.4469 - Epoch Loss: 70655.8199 - Avg Loss: 161.3147\n",
            "Epoch [14/50] - Batch loss: 166.8274 - Epoch Loss: 70822.6473 - Avg Loss: 161.3272\n",
            "Epoch [14/50] - Batch loss: 158.4691 - Epoch Loss: 70981.1164 - Avg Loss: 161.3207\n",
            "Epoch [14/50] - Batch loss: 160.7480 - Epoch Loss: 71141.8644 - Avg Loss: 161.3194\n",
            "Epoch [14/50] - Batch loss: 153.7919 - Epoch Loss: 71295.6562 - Avg Loss: 161.3024\n",
            "Epoch [14/50] - Batch loss: 161.7951 - Epoch Loss: 71457.4513 - Avg Loss: 161.3035\n",
            "Epoch [14/50] - Batch loss: 159.9761 - Epoch Loss: 71617.4274 - Avg Loss: 161.3005\n",
            "Epoch [14/50] - Batch loss: 167.0771 - Epoch Loss: 71784.5046 - Avg Loss: 161.3135\n",
            "Epoch [14/50] - Batch loss: 163.8981 - Epoch Loss: 71948.4027 - Avg Loss: 161.3193\n",
            "Epoch [14/50] - Batch loss: 160.5634 - Epoch Loss: 72108.9661 - Avg Loss: 161.3176\n",
            "Epoch [14/50] - Batch loss: 169.8921 - Epoch Loss: 72278.8583 - Avg Loss: 161.3367\n",
            "Epoch [14/50] - Batch loss: 160.6882 - Epoch Loss: 72439.5464 - Avg Loss: 161.3353\n",
            "Epoch [14/50] - Batch loss: 162.9163 - Epoch Loss: 72602.4628 - Avg Loss: 161.3388\n",
            "Epoch [14/50] - Batch loss: 157.6040 - Epoch Loss: 72760.0668 - Avg Loss: 161.3305\n",
            "Epoch [14/50] - Batch loss: 160.1678 - Epoch Loss: 72920.2346 - Avg Loss: 161.3280\n",
            "Epoch [14/50] - Batch loss: 157.5885 - Epoch Loss: 73077.8231 - Avg Loss: 161.3197\n",
            "Epoch [14/50] - Batch loss: 158.6665 - Epoch Loss: 73236.4896 - Avg Loss: 161.3139\n",
            "Epoch [14/50] - Batch loss: 158.2539 - Epoch Loss: 73394.7434 - Avg Loss: 161.3071\n",
            "Epoch [14/50] - Batch loss: 163.5927 - Epoch Loss: 73558.3361 - Avg Loss: 161.3121\n",
            "Epoch [14/50] - Batch loss: 157.3018 - Epoch Loss: 73715.6380 - Avg Loss: 161.3034\n",
            "Epoch [14/50] - Batch loss: 156.1631 - Epoch Loss: 73871.8011 - Avg Loss: 161.2921\n",
            "Epoch [14/50] - Batch loss: 162.0184 - Epoch Loss: 74033.8195 - Avg Loss: 161.2937\n",
            "Epoch [14/50] - Batch loss: 158.1852 - Epoch Loss: 74192.0046 - Avg Loss: 161.2870\n",
            "Epoch [14/50] - Batch loss: 162.9647 - Epoch Loss: 74354.9693 - Avg Loss: 161.2906\n",
            "Epoch [14/50] - Batch loss: 159.4004 - Epoch Loss: 74514.3697 - Avg Loss: 161.2865\n",
            "Epoch [14/50] - Batch loss: 165.3193 - Epoch Loss: 74679.6890 - Avg Loss: 161.2952\n",
            "Epoch [14/50] - Batch loss: 164.9291 - Epoch Loss: 74844.6182 - Avg Loss: 161.3031\n",
            "Epoch [14/50] - Batch loss: 157.2139 - Epoch Loss: 75001.8320 - Avg Loss: 161.2943\n",
            "Epoch [14/50] - Batch loss: 155.3961 - Epoch Loss: 75157.2281 - Avg Loss: 161.2816\n",
            "Epoch [14/50] - Batch loss: 159.1041 - Epoch Loss: 75316.3322 - Avg Loss: 161.2769\n",
            "Epoch [14/50] - Batch loss: 155.2034 - Epoch Loss: 75471.5355 - Avg Loss: 161.2640\n",
            "Epoch [14/50] - Batch loss: 158.1846 - Epoch Loss: 75629.7201 - Avg Loss: 161.2574\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 15/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7615ac8b74c748d28e5104216b6dc95a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/50] - Batch loss: 160.9924 - Epoch Loss: 160.9924 - Avg Loss: 160.9924\n",
            "Epoch [15/50] - Batch loss: 155.7508 - Epoch Loss: 316.7433 - Avg Loss: 158.3716\n",
            "Epoch [15/50] - Batch loss: 152.7357 - Epoch Loss: 469.4789 - Avg Loss: 156.4930\n",
            "Epoch [15/50] - Batch loss: 159.9494 - Epoch Loss: 629.4283 - Avg Loss: 157.3571\n",
            "Epoch [15/50] - Batch loss: 164.2070 - Epoch Loss: 793.6353 - Avg Loss: 158.7271\n",
            "Epoch [15/50] - Batch loss: 161.6309 - Epoch Loss: 955.2662 - Avg Loss: 159.2110\n",
            "Epoch [15/50] - Batch loss: 163.5546 - Epoch Loss: 1118.8208 - Avg Loss: 159.8315\n",
            "Epoch [15/50] - Batch loss: 162.2160 - Epoch Loss: 1281.0368 - Avg Loss: 160.1296\n",
            "Epoch [15/50] - Batch loss: 162.4361 - Epoch Loss: 1443.4729 - Avg Loss: 160.3859\n",
            "Epoch [15/50] - Batch loss: 165.8012 - Epoch Loss: 1609.2741 - Avg Loss: 160.9274\n",
            "Epoch [15/50] - Batch loss: 164.2463 - Epoch Loss: 1773.5204 - Avg Loss: 161.2291\n",
            "Epoch [15/50] - Batch loss: 162.7196 - Epoch Loss: 1936.2400 - Avg Loss: 161.3533\n",
            "Epoch [15/50] - Batch loss: 161.8886 - Epoch Loss: 2098.1286 - Avg Loss: 161.3945\n",
            "Epoch [15/50] - Batch loss: 164.7549 - Epoch Loss: 2262.8836 - Avg Loss: 161.6345\n",
            "Epoch [15/50] - Batch loss: 162.8180 - Epoch Loss: 2425.7016 - Avg Loss: 161.7134\n",
            "Epoch [15/50] - Batch loss: 160.1488 - Epoch Loss: 2585.8504 - Avg Loss: 161.6157\n",
            "Epoch [15/50] - Batch loss: 163.0789 - Epoch Loss: 2748.9293 - Avg Loss: 161.7017\n",
            "Epoch [15/50] - Batch loss: 164.7988 - Epoch Loss: 2913.7281 - Avg Loss: 161.8738\n",
            "Epoch [15/50] - Batch loss: 165.0228 - Epoch Loss: 3078.7508 - Avg Loss: 162.0395\n",
            "Epoch [15/50] - Batch loss: 162.2669 - Epoch Loss: 3241.0177 - Avg Loss: 162.0509\n",
            "Epoch [15/50] - Batch loss: 164.7071 - Epoch Loss: 3405.7248 - Avg Loss: 162.1774\n",
            "Epoch [15/50] - Batch loss: 168.8703 - Epoch Loss: 3574.5951 - Avg Loss: 162.4816\n",
            "Epoch [15/50] - Batch loss: 159.2896 - Epoch Loss: 3733.8847 - Avg Loss: 162.3428\n",
            "Epoch [15/50] - Batch loss: 157.8481 - Epoch Loss: 3891.7328 - Avg Loss: 162.1555\n",
            "Epoch [15/50] - Batch loss: 167.8643 - Epoch Loss: 4059.5971 - Avg Loss: 162.3839\n",
            "Epoch [15/50] - Batch loss: 155.7149 - Epoch Loss: 4215.3120 - Avg Loss: 162.1274\n",
            "Epoch [15/50] - Batch loss: 155.6602 - Epoch Loss: 4370.9722 - Avg Loss: 161.8879\n",
            "Epoch [15/50] - Batch loss: 167.4052 - Epoch Loss: 4538.3774 - Avg Loss: 162.0849\n",
            "Epoch [15/50] - Batch loss: 167.2954 - Epoch Loss: 4705.6728 - Avg Loss: 162.2646\n",
            "Epoch [15/50] - Batch loss: 165.1701 - Epoch Loss: 4870.8430 - Avg Loss: 162.3614\n",
            "Epoch [15/50] - Batch loss: 150.8007 - Epoch Loss: 5021.6436 - Avg Loss: 161.9885\n",
            "Epoch [15/50] - Batch loss: 165.4821 - Epoch Loss: 5187.1257 - Avg Loss: 162.0977\n",
            "Epoch [15/50] - Batch loss: 164.4128 - Epoch Loss: 5351.5385 - Avg Loss: 162.1678\n",
            "Epoch [15/50] - Batch loss: 160.1934 - Epoch Loss: 5511.7320 - Avg Loss: 162.1098\n",
            "Epoch [15/50] - Batch loss: 168.2281 - Epoch Loss: 5679.9601 - Avg Loss: 162.2846\n",
            "Epoch [15/50] - Batch loss: 158.3875 - Epoch Loss: 5838.3476 - Avg Loss: 162.1763\n",
            "Epoch [15/50] - Batch loss: 167.2357 - Epoch Loss: 6005.5833 - Avg Loss: 162.3131\n",
            "Epoch [15/50] - Batch loss: 161.9901 - Epoch Loss: 6167.5733 - Avg Loss: 162.3046\n",
            "Epoch [15/50] - Batch loss: 163.3238 - Epoch Loss: 6330.8972 - Avg Loss: 162.3307\n",
            "Epoch [15/50] - Batch loss: 165.5852 - Epoch Loss: 6496.4824 - Avg Loss: 162.4121\n",
            "Epoch [15/50] - Batch loss: 158.9460 - Epoch Loss: 6655.4284 - Avg Loss: 162.3275\n",
            "Epoch [15/50] - Batch loss: 153.9555 - Epoch Loss: 6809.3839 - Avg Loss: 162.1282\n",
            "Epoch [15/50] - Batch loss: 161.5829 - Epoch Loss: 6970.9669 - Avg Loss: 162.1155\n",
            "Epoch [15/50] - Batch loss: 156.0304 - Epoch Loss: 7126.9972 - Avg Loss: 161.9772\n",
            "Epoch [15/50] - Batch loss: 162.7386 - Epoch Loss: 7289.7358 - Avg Loss: 161.9941\n",
            "Epoch [15/50] - Batch loss: 163.0696 - Epoch Loss: 7452.8055 - Avg Loss: 162.0175\n",
            "Epoch [15/50] - Batch loss: 163.5461 - Epoch Loss: 7616.3516 - Avg Loss: 162.0500\n",
            "Epoch [15/50] - Batch loss: 154.3637 - Epoch Loss: 7770.7153 - Avg Loss: 161.8899\n",
            "Epoch [15/50] - Batch loss: 159.2634 - Epoch Loss: 7929.9787 - Avg Loss: 161.8363\n",
            "Epoch [15/50] - Batch loss: 158.3548 - Epoch Loss: 8088.3335 - Avg Loss: 161.7667\n",
            "Epoch [15/50] - Batch loss: 159.4272 - Epoch Loss: 8247.7607 - Avg Loss: 161.7208\n",
            "Epoch [15/50] - Batch loss: 160.5428 - Epoch Loss: 8408.3035 - Avg Loss: 161.6981\n",
            "Epoch [15/50] - Batch loss: 160.9700 - Epoch Loss: 8569.2736 - Avg Loss: 161.6844\n",
            "Epoch [15/50] - Batch loss: 154.9761 - Epoch Loss: 8724.2497 - Avg Loss: 161.5602\n",
            "Epoch [15/50] - Batch loss: 156.9761 - Epoch Loss: 8881.2258 - Avg Loss: 161.4768\n",
            "Epoch [15/50] - Batch loss: 159.8210 - Epoch Loss: 9041.0468 - Avg Loss: 161.4473\n",
            "Epoch [15/50] - Batch loss: 156.4530 - Epoch Loss: 9197.4998 - Avg Loss: 161.3596\n",
            "Epoch [15/50] - Batch loss: 166.4981 - Epoch Loss: 9363.9979 - Avg Loss: 161.4482\n",
            "Epoch [15/50] - Batch loss: 164.3361 - Epoch Loss: 9528.3340 - Avg Loss: 161.4972\n",
            "Epoch [15/50] - Batch loss: 156.7521 - Epoch Loss: 9685.0861 - Avg Loss: 161.4181\n",
            "Epoch [15/50] - Batch loss: 160.1706 - Epoch Loss: 9845.2567 - Avg Loss: 161.3977\n",
            "Epoch [15/50] - Batch loss: 165.6438 - Epoch Loss: 10010.9004 - Avg Loss: 161.4661\n",
            "Epoch [15/50] - Batch loss: 159.6443 - Epoch Loss: 10170.5448 - Avg Loss: 161.4372\n",
            "Epoch [15/50] - Batch loss: 143.4530 - Epoch Loss: 10313.9978 - Avg Loss: 161.1562\n",
            "Epoch [15/50] - Batch loss: 168.2112 - Epoch Loss: 10482.2090 - Avg Loss: 161.2648\n",
            "Epoch [15/50] - Batch loss: 159.8299 - Epoch Loss: 10642.0390 - Avg Loss: 161.2430\n",
            "Epoch [15/50] - Batch loss: 156.6554 - Epoch Loss: 10798.6944 - Avg Loss: 161.1745\n",
            "Epoch [15/50] - Batch loss: 162.2425 - Epoch Loss: 10960.9369 - Avg Loss: 161.1902\n",
            "Epoch [15/50] - Batch loss: 155.0735 - Epoch Loss: 11116.0104 - Avg Loss: 161.1016\n",
            "Epoch [15/50] - Batch loss: 162.7057 - Epoch Loss: 11278.7161 - Avg Loss: 161.1245\n",
            "Epoch [15/50] - Batch loss: 162.5888 - Epoch Loss: 11441.3049 - Avg Loss: 161.1451\n",
            "Epoch [15/50] - Batch loss: 155.9102 - Epoch Loss: 11597.2151 - Avg Loss: 161.0724\n",
            "Epoch [15/50] - Batch loss: 164.1935 - Epoch Loss: 11761.4085 - Avg Loss: 161.1152\n",
            "Epoch [15/50] - Batch loss: 157.5548 - Epoch Loss: 11918.9633 - Avg Loss: 161.0671\n",
            "Epoch [15/50] - Batch loss: 163.3402 - Epoch Loss: 12082.3036 - Avg Loss: 161.0974\n",
            "Epoch [15/50] - Batch loss: 163.0132 - Epoch Loss: 12245.3167 - Avg Loss: 161.1226\n",
            "Epoch [15/50] - Batch loss: 158.1699 - Epoch Loss: 12403.4866 - Avg Loss: 161.0842\n",
            "Epoch [15/50] - Batch loss: 158.3538 - Epoch Loss: 12561.8404 - Avg Loss: 161.0492\n",
            "Epoch [15/50] - Batch loss: 163.1161 - Epoch Loss: 12724.9566 - Avg Loss: 161.0754\n",
            "Epoch [15/50] - Batch loss: 162.1366 - Epoch Loss: 12887.0932 - Avg Loss: 161.0887\n",
            "Epoch [15/50] - Batch loss: 150.7122 - Epoch Loss: 13037.8054 - Avg Loss: 160.9606\n",
            "Epoch [15/50] - Batch loss: 149.9187 - Epoch Loss: 13187.7241 - Avg Loss: 160.8259\n",
            "Epoch [15/50] - Batch loss: 160.2542 - Epoch Loss: 13347.9782 - Avg Loss: 160.8190\n",
            "Epoch [15/50] - Batch loss: 156.4804 - Epoch Loss: 13504.4586 - Avg Loss: 160.7674\n",
            "Epoch [15/50] - Batch loss: 156.8080 - Epoch Loss: 13661.2666 - Avg Loss: 160.7208\n",
            "Epoch [15/50] - Batch loss: 160.1890 - Epoch Loss: 13821.4556 - Avg Loss: 160.7146\n",
            "Epoch [15/50] - Batch loss: 163.6237 - Epoch Loss: 13985.0793 - Avg Loss: 160.7480\n",
            "Epoch [15/50] - Batch loss: 167.9372 - Epoch Loss: 14153.0165 - Avg Loss: 160.8297\n",
            "Epoch [15/50] - Batch loss: 166.6685 - Epoch Loss: 14319.6850 - Avg Loss: 160.8953\n",
            "Epoch [15/50] - Batch loss: 152.6121 - Epoch Loss: 14472.2972 - Avg Loss: 160.8033\n",
            "Epoch [15/50] - Batch loss: 163.5498 - Epoch Loss: 14635.8470 - Avg Loss: 160.8335\n",
            "Epoch [15/50] - Batch loss: 152.8932 - Epoch Loss: 14788.7402 - Avg Loss: 160.7472\n",
            "Epoch [15/50] - Batch loss: 159.2884 - Epoch Loss: 14948.0286 - Avg Loss: 160.7315\n",
            "Epoch [15/50] - Batch loss: 153.0024 - Epoch Loss: 15101.0310 - Avg Loss: 160.6493\n",
            "Epoch [15/50] - Batch loss: 160.3640 - Epoch Loss: 15261.3950 - Avg Loss: 160.6463\n",
            "Epoch [15/50] - Batch loss: 156.0095 - Epoch Loss: 15417.4045 - Avg Loss: 160.5980\n",
            "Epoch [15/50] - Batch loss: 159.2678 - Epoch Loss: 15576.6723 - Avg Loss: 160.5843\n",
            "Epoch [15/50] - Batch loss: 161.0316 - Epoch Loss: 15737.7038 - Avg Loss: 160.5888\n",
            "Epoch [15/50] - Batch loss: 161.8661 - Epoch Loss: 15899.5699 - Avg Loss: 160.6017\n",
            "Epoch [15/50] - Batch loss: 157.2672 - Epoch Loss: 16056.8371 - Avg Loss: 160.5684\n",
            "Epoch [15/50] - Batch loss: 164.6168 - Epoch Loss: 16221.4539 - Avg Loss: 160.6085\n",
            "Epoch [15/50] - Batch loss: 157.0591 - Epoch Loss: 16378.5130 - Avg Loss: 160.5737\n",
            "Epoch [15/50] - Batch loss: 161.6785 - Epoch Loss: 16540.1915 - Avg Loss: 160.5844\n",
            "Epoch [15/50] - Batch loss: 163.2863 - Epoch Loss: 16703.4778 - Avg Loss: 160.6104\n",
            "Epoch [15/50] - Batch loss: 158.4151 - Epoch Loss: 16861.8929 - Avg Loss: 160.5895\n",
            "Epoch [15/50] - Batch loss: 162.4655 - Epoch Loss: 17024.3585 - Avg Loss: 160.6072\n",
            "Epoch [15/50] - Batch loss: 164.2973 - Epoch Loss: 17188.6557 - Avg Loss: 160.6416\n",
            "Epoch [15/50] - Batch loss: 166.5002 - Epoch Loss: 17355.1559 - Avg Loss: 160.6959\n",
            "Epoch [15/50] - Batch loss: 157.7407 - Epoch Loss: 17512.8966 - Avg Loss: 160.6688\n",
            "Epoch [15/50] - Batch loss: 160.5677 - Epoch Loss: 17673.4643 - Avg Loss: 160.6679\n",
            "Epoch [15/50] - Batch loss: 161.7980 - Epoch Loss: 17835.2623 - Avg Loss: 160.6780\n",
            "Epoch [15/50] - Batch loss: 158.9218 - Epoch Loss: 17994.1841 - Avg Loss: 160.6624\n",
            "Epoch [15/50] - Batch loss: 160.0755 - Epoch Loss: 18154.2596 - Avg Loss: 160.6572\n",
            "Epoch [15/50] - Batch loss: 157.7906 - Epoch Loss: 18312.0502 - Avg Loss: 160.6320\n",
            "Epoch [15/50] - Batch loss: 157.8477 - Epoch Loss: 18469.8979 - Avg Loss: 160.6078\n",
            "Epoch [15/50] - Batch loss: 163.4316 - Epoch Loss: 18633.3295 - Avg Loss: 160.6322\n",
            "Epoch [15/50] - Batch loss: 163.7415 - Epoch Loss: 18797.0709 - Avg Loss: 160.6587\n",
            "Epoch [15/50] - Batch loss: 155.7712 - Epoch Loss: 18952.8421 - Avg Loss: 160.6173\n",
            "Epoch [15/50] - Batch loss: 156.1386 - Epoch Loss: 19108.9808 - Avg Loss: 160.5797\n",
            "Epoch [15/50] - Batch loss: 168.9890 - Epoch Loss: 19277.9698 - Avg Loss: 160.6497\n",
            "Epoch [15/50] - Batch loss: 165.5918 - Epoch Loss: 19443.5616 - Avg Loss: 160.6906\n",
            "Epoch [15/50] - Batch loss: 159.2894 - Epoch Loss: 19602.8510 - Avg Loss: 160.6791\n",
            "Epoch [15/50] - Batch loss: 156.3560 - Epoch Loss: 19759.2070 - Avg Loss: 160.6440\n",
            "Epoch [15/50] - Batch loss: 166.5794 - Epoch Loss: 19925.7864 - Avg Loss: 160.6918\n",
            "Epoch [15/50] - Batch loss: 161.6203 - Epoch Loss: 20087.4067 - Avg Loss: 160.6993\n",
            "Epoch [15/50] - Batch loss: 158.1399 - Epoch Loss: 20245.5467 - Avg Loss: 160.6789\n",
            "Epoch [15/50] - Batch loss: 163.1011 - Epoch Loss: 20408.6477 - Avg Loss: 160.6980\n",
            "Epoch [15/50] - Batch loss: 150.2171 - Epoch Loss: 20558.8649 - Avg Loss: 160.6161\n",
            "Epoch [15/50] - Batch loss: 164.5030 - Epoch Loss: 20723.3679 - Avg Loss: 160.6463\n",
            "Epoch [15/50] - Batch loss: 159.7785 - Epoch Loss: 20883.1464 - Avg Loss: 160.6396\n",
            "Epoch [15/50] - Batch loss: 160.5745 - Epoch Loss: 21043.7209 - Avg Loss: 160.6391\n",
            "Epoch [15/50] - Batch loss: 162.8602 - Epoch Loss: 21206.5811 - Avg Loss: 160.6559\n",
            "Epoch [15/50] - Batch loss: 165.1353 - Epoch Loss: 21371.7165 - Avg Loss: 160.6896\n",
            "Epoch [15/50] - Batch loss: 163.5775 - Epoch Loss: 21535.2939 - Avg Loss: 160.7111\n",
            "Epoch [15/50] - Batch loss: 153.8764 - Epoch Loss: 21689.1704 - Avg Loss: 160.6605\n",
            "Epoch [15/50] - Batch loss: 167.8445 - Epoch Loss: 21857.0149 - Avg Loss: 160.7133\n",
            "Epoch [15/50] - Batch loss: 162.5676 - Epoch Loss: 22019.5825 - Avg Loss: 160.7269\n",
            "Epoch [15/50] - Batch loss: 165.4407 - Epoch Loss: 22185.0232 - Avg Loss: 160.7610\n",
            "Epoch [15/50] - Batch loss: 164.6568 - Epoch Loss: 22349.6800 - Avg Loss: 160.7891\n",
            "Epoch [15/50] - Batch loss: 164.5369 - Epoch Loss: 22514.2169 - Avg Loss: 160.8158\n",
            "Epoch [15/50] - Batch loss: 168.5013 - Epoch Loss: 22682.7182 - Avg Loss: 160.8703\n",
            "Epoch [15/50] - Batch loss: 157.4595 - Epoch Loss: 22840.1777 - Avg Loss: 160.8463\n",
            "Epoch [15/50] - Batch loss: 158.8825 - Epoch Loss: 22999.0602 - Avg Loss: 160.8326\n",
            "Epoch [15/50] - Batch loss: 154.6963 - Epoch Loss: 23153.7565 - Avg Loss: 160.7900\n",
            "Epoch [15/50] - Batch loss: 158.7737 - Epoch Loss: 23312.5302 - Avg Loss: 160.7761\n",
            "Epoch [15/50] - Batch loss: 162.9922 - Epoch Loss: 23475.5224 - Avg Loss: 160.7912\n",
            "Epoch [15/50] - Batch loss: 164.5403 - Epoch Loss: 23640.0627 - Avg Loss: 160.8168\n",
            "Epoch [15/50] - Batch loss: 157.1572 - Epoch Loss: 23797.2199 - Avg Loss: 160.7920\n",
            "Epoch [15/50] - Batch loss: 160.8953 - Epoch Loss: 23958.1152 - Avg Loss: 160.7927\n",
            "Epoch [15/50] - Batch loss: 171.5157 - Epoch Loss: 24129.6310 - Avg Loss: 160.8642\n",
            "Epoch [15/50] - Batch loss: 154.0905 - Epoch Loss: 24283.7214 - Avg Loss: 160.8193\n",
            "Epoch [15/50] - Batch loss: 160.3446 - Epoch Loss: 24444.0660 - Avg Loss: 160.8162\n",
            "Epoch [15/50] - Batch loss: 160.6456 - Epoch Loss: 24604.7116 - Avg Loss: 160.8151\n",
            "Epoch [15/50] - Batch loss: 158.7008 - Epoch Loss: 24763.4124 - Avg Loss: 160.8014\n",
            "Epoch [15/50] - Batch loss: 163.4172 - Epoch Loss: 24926.8297 - Avg Loss: 160.8183\n",
            "Epoch [15/50] - Batch loss: 154.2253 - Epoch Loss: 25081.0549 - Avg Loss: 160.7760\n",
            "Epoch [15/50] - Batch loss: 159.2477 - Epoch Loss: 25240.3026 - Avg Loss: 160.7663\n",
            "Epoch [15/50] - Batch loss: 159.8482 - Epoch Loss: 25400.1508 - Avg Loss: 160.7604\n",
            "Epoch [15/50] - Batch loss: 162.5577 - Epoch Loss: 25562.7085 - Avg Loss: 160.7718\n",
            "Epoch [15/50] - Batch loss: 162.0893 - Epoch Loss: 25724.7978 - Avg Loss: 160.7800\n",
            "Epoch [15/50] - Batch loss: 155.2150 - Epoch Loss: 25880.0128 - Avg Loss: 160.7454\n",
            "Epoch [15/50] - Batch loss: 165.5299 - Epoch Loss: 26045.5427 - Avg Loss: 160.7750\n",
            "Epoch [15/50] - Batch loss: 152.6425 - Epoch Loss: 26198.1853 - Avg Loss: 160.7251\n",
            "Epoch [15/50] - Batch loss: 153.2323 - Epoch Loss: 26351.4176 - Avg Loss: 160.6794\n",
            "Epoch [15/50] - Batch loss: 161.4193 - Epoch Loss: 26512.8369 - Avg Loss: 160.6839\n",
            "Epoch [15/50] - Batch loss: 152.2830 - Epoch Loss: 26665.1199 - Avg Loss: 160.6333\n",
            "Epoch [15/50] - Batch loss: 156.7893 - Epoch Loss: 26821.9092 - Avg Loss: 160.6102\n",
            "Epoch [15/50] - Batch loss: 154.5089 - Epoch Loss: 26976.4181 - Avg Loss: 160.5739\n",
            "Epoch [15/50] - Batch loss: 165.0438 - Epoch Loss: 27141.4619 - Avg Loss: 160.6004\n",
            "Epoch [15/50] - Batch loss: 153.8557 - Epoch Loss: 27295.3176 - Avg Loss: 160.5607\n",
            "Epoch [15/50] - Batch loss: 160.5300 - Epoch Loss: 27455.8476 - Avg Loss: 160.5605\n",
            "Epoch [15/50] - Batch loss: 165.5563 - Epoch Loss: 27621.4039 - Avg Loss: 160.5896\n",
            "Epoch [15/50] - Batch loss: 164.8205 - Epoch Loss: 27786.2244 - Avg Loss: 160.6140\n",
            "Epoch [15/50] - Batch loss: 165.9482 - Epoch Loss: 27952.1727 - Avg Loss: 160.6447\n",
            "Epoch [15/50] - Batch loss: 151.7178 - Epoch Loss: 28103.8905 - Avg Loss: 160.5937\n",
            "Epoch [15/50] - Batch loss: 162.7440 - Epoch Loss: 28266.6345 - Avg Loss: 160.6059\n",
            "Epoch [15/50] - Batch loss: 161.1192 - Epoch Loss: 28427.7537 - Avg Loss: 160.6088\n",
            "Epoch [15/50] - Batch loss: 168.9123 - Epoch Loss: 28596.6660 - Avg Loss: 160.6554\n",
            "Epoch [15/50] - Batch loss: 158.6923 - Epoch Loss: 28755.3583 - Avg Loss: 160.6445\n",
            "Epoch [15/50] - Batch loss: 159.2421 - Epoch Loss: 28914.6005 - Avg Loss: 160.6367\n",
            "Epoch [15/50] - Batch loss: 153.6361 - Epoch Loss: 29068.2366 - Avg Loss: 160.5980\n",
            "Epoch [15/50] - Batch loss: 156.0578 - Epoch Loss: 29224.2944 - Avg Loss: 160.5730\n",
            "Epoch [15/50] - Batch loss: 158.1897 - Epoch Loss: 29382.4841 - Avg Loss: 160.5600\n",
            "Epoch [15/50] - Batch loss: 161.4819 - Epoch Loss: 29543.9659 - Avg Loss: 160.5650\n",
            "Epoch [15/50] - Batch loss: 163.0406 - Epoch Loss: 29707.0066 - Avg Loss: 160.5784\n",
            "Epoch [15/50] - Batch loss: 159.7634 - Epoch Loss: 29866.7699 - Avg Loss: 160.5740\n",
            "Epoch [15/50] - Batch loss: 165.9279 - Epoch Loss: 30032.6978 - Avg Loss: 160.6027\n",
            "Epoch [15/50] - Batch loss: 160.6250 - Epoch Loss: 30193.3229 - Avg Loss: 160.6028\n",
            "Epoch [15/50] - Batch loss: 167.1596 - Epoch Loss: 30360.4825 - Avg Loss: 160.6375\n",
            "Epoch [15/50] - Batch loss: 158.7758 - Epoch Loss: 30519.2582 - Avg Loss: 160.6277\n",
            "Epoch [15/50] - Batch loss: 157.6760 - Epoch Loss: 30676.9342 - Avg Loss: 160.6122\n",
            "Epoch [15/50] - Batch loss: 160.3635 - Epoch Loss: 30837.2977 - Avg Loss: 160.6109\n",
            "Epoch [15/50] - Batch loss: 152.1239 - Epoch Loss: 30989.4216 - Avg Loss: 160.5670\n",
            "Epoch [15/50] - Batch loss: 160.0076 - Epoch Loss: 31149.4292 - Avg Loss: 160.5641\n",
            "Epoch [15/50] - Batch loss: 163.5355 - Epoch Loss: 31312.9647 - Avg Loss: 160.5793\n",
            "Epoch [15/50] - Batch loss: 156.8522 - Epoch Loss: 31469.8170 - Avg Loss: 160.5603\n",
            "Epoch [15/50] - Batch loss: 157.5624 - Epoch Loss: 31627.3793 - Avg Loss: 160.5451\n",
            "Epoch [15/50] - Batch loss: 162.8917 - Epoch Loss: 31790.2711 - Avg Loss: 160.5569\n",
            "Epoch [15/50] - Batch loss: 158.1687 - Epoch Loss: 31948.4398 - Avg Loss: 160.5449\n",
            "Epoch [15/50] - Batch loss: 163.3222 - Epoch Loss: 32111.7620 - Avg Loss: 160.5588\n",
            "Epoch [15/50] - Batch loss: 151.9445 - Epoch Loss: 32263.7065 - Avg Loss: 160.5160\n",
            "Epoch [15/50] - Batch loss: 158.3844 - Epoch Loss: 32422.0909 - Avg Loss: 160.5054\n",
            "Epoch [15/50] - Batch loss: 162.4593 - Epoch Loss: 32584.5502 - Avg Loss: 160.5150\n",
            "Epoch [15/50] - Batch loss: 163.0450 - Epoch Loss: 32747.5952 - Avg Loss: 160.5274\n",
            "Epoch [15/50] - Batch loss: 165.2046 - Epoch Loss: 32912.7998 - Avg Loss: 160.5502\n",
            "Epoch [15/50] - Batch loss: 167.3256 - Epoch Loss: 33080.1254 - Avg Loss: 160.5831\n",
            "Epoch [15/50] - Batch loss: 150.8957 - Epoch Loss: 33231.0211 - Avg Loss: 160.5363\n",
            "Epoch [15/50] - Batch loss: 169.4691 - Epoch Loss: 33400.4902 - Avg Loss: 160.5793\n",
            "Epoch [15/50] - Batch loss: 159.6594 - Epoch Loss: 33560.1496 - Avg Loss: 160.5749\n",
            "Epoch [15/50] - Batch loss: 159.5356 - Epoch Loss: 33719.6853 - Avg Loss: 160.5699\n",
            "Epoch [15/50] - Batch loss: 163.0319 - Epoch Loss: 33882.7172 - Avg Loss: 160.5816\n",
            "Epoch [15/50] - Batch loss: 158.8288 - Epoch Loss: 34041.5460 - Avg Loss: 160.5733\n",
            "Epoch [15/50] - Batch loss: 168.1345 - Epoch Loss: 34209.6804 - Avg Loss: 160.6088\n",
            "Epoch [15/50] - Batch loss: 171.9326 - Epoch Loss: 34381.6131 - Avg Loss: 160.6617\n",
            "Epoch [15/50] - Batch loss: 165.2016 - Epoch Loss: 34546.8146 - Avg Loss: 160.6829\n",
            "Epoch [15/50] - Batch loss: 156.4293 - Epoch Loss: 34703.2439 - Avg Loss: 160.6632\n",
            "Epoch [15/50] - Batch loss: 162.5893 - Epoch Loss: 34865.8332 - Avg Loss: 160.6720\n",
            "Epoch [15/50] - Batch loss: 161.2975 - Epoch Loss: 35027.1308 - Avg Loss: 160.6749\n",
            "Epoch [15/50] - Batch loss: 163.5250 - Epoch Loss: 35190.6558 - Avg Loss: 160.6879\n",
            "Epoch [15/50] - Batch loss: 158.6124 - Epoch Loss: 35349.2682 - Avg Loss: 160.6785\n",
            "Epoch [15/50] - Batch loss: 163.0452 - Epoch Loss: 35512.3134 - Avg Loss: 160.6892\n",
            "Epoch [15/50] - Batch loss: 163.8555 - Epoch Loss: 35676.1688 - Avg Loss: 160.7035\n",
            "Epoch [15/50] - Batch loss: 161.6499 - Epoch Loss: 35837.8187 - Avg Loss: 160.7077\n",
            "Epoch [15/50] - Batch loss: 166.3558 - Epoch Loss: 36004.1745 - Avg Loss: 160.7329\n",
            "Epoch [15/50] - Batch loss: 163.6446 - Epoch Loss: 36167.8192 - Avg Loss: 160.7459\n",
            "Epoch [15/50] - Batch loss: 158.1962 - Epoch Loss: 36326.0153 - Avg Loss: 160.7346\n",
            "Epoch [15/50] - Batch loss: 158.7492 - Epoch Loss: 36484.7645 - Avg Loss: 160.7258\n",
            "Epoch [15/50] - Batch loss: 155.0406 - Epoch Loss: 36639.8051 - Avg Loss: 160.7009\n",
            "Epoch [15/50] - Batch loss: 162.9033 - Epoch Loss: 36802.7084 - Avg Loss: 160.7105\n",
            "Epoch [15/50] - Batch loss: 164.4105 - Epoch Loss: 36967.1189 - Avg Loss: 160.7266\n",
            "Epoch [15/50] - Batch loss: 152.6336 - Epoch Loss: 37119.7525 - Avg Loss: 160.6916\n",
            "Epoch [15/50] - Batch loss: 155.6316 - Epoch Loss: 37275.3841 - Avg Loss: 160.6698\n",
            "Epoch [15/50] - Batch loss: 158.3710 - Epoch Loss: 37433.7551 - Avg Loss: 160.6599\n",
            "Epoch [15/50] - Batch loss: 160.1526 - Epoch Loss: 37593.9077 - Avg Loss: 160.6577\n",
            "Epoch [15/50] - Batch loss: 164.3981 - Epoch Loss: 37758.3058 - Avg Loss: 160.6736\n",
            "Epoch [15/50] - Batch loss: 162.9827 - Epoch Loss: 37921.2885 - Avg Loss: 160.6834\n",
            "Epoch [15/50] - Batch loss: 169.1631 - Epoch Loss: 38090.4516 - Avg Loss: 160.7192\n",
            "Epoch [15/50] - Batch loss: 162.4285 - Epoch Loss: 38252.8801 - Avg Loss: 160.7264\n",
            "Epoch [15/50] - Batch loss: 161.9916 - Epoch Loss: 38414.8718 - Avg Loss: 160.7317\n",
            "Epoch [15/50] - Batch loss: 170.2714 - Epoch Loss: 38585.1432 - Avg Loss: 160.7714\n",
            "Epoch [15/50] - Batch loss: 160.4071 - Epoch Loss: 38745.5503 - Avg Loss: 160.7699\n",
            "Epoch [15/50] - Batch loss: 164.4093 - Epoch Loss: 38909.9596 - Avg Loss: 160.7850\n",
            "Epoch [15/50] - Batch loss: 163.1365 - Epoch Loss: 39073.0961 - Avg Loss: 160.7946\n",
            "Epoch [15/50] - Batch loss: 158.9626 - Epoch Loss: 39232.0586 - Avg Loss: 160.7871\n",
            "Epoch [15/50] - Batch loss: 162.7047 - Epoch Loss: 39394.7633 - Avg Loss: 160.7950\n",
            "Epoch [15/50] - Batch loss: 159.3262 - Epoch Loss: 39554.0895 - Avg Loss: 160.7890\n",
            "Epoch [15/50] - Batch loss: 159.3405 - Epoch Loss: 39713.4300 - Avg Loss: 160.7831\n",
            "Epoch [15/50] - Batch loss: 157.9563 - Epoch Loss: 39871.3862 - Avg Loss: 160.7717\n",
            "Epoch [15/50] - Batch loss: 161.0827 - Epoch Loss: 40032.4689 - Avg Loss: 160.7730\n",
            "Epoch [15/50] - Batch loss: 157.3940 - Epoch Loss: 40189.8629 - Avg Loss: 160.7595\n",
            "Epoch [15/50] - Batch loss: 156.6078 - Epoch Loss: 40346.4706 - Avg Loss: 160.7429\n",
            "Epoch [15/50] - Batch loss: 159.3750 - Epoch Loss: 40505.8456 - Avg Loss: 160.7375\n",
            "Epoch [15/50] - Batch loss: 157.3188 - Epoch Loss: 40663.1644 - Avg Loss: 160.7240\n",
            "Epoch [15/50] - Batch loss: 166.6717 - Epoch Loss: 40829.8360 - Avg Loss: 160.7474\n",
            "Epoch [15/50] - Batch loss: 154.0627 - Epoch Loss: 40983.8987 - Avg Loss: 160.7212\n",
            "Epoch [15/50] - Batch loss: 159.8765 - Epoch Loss: 41143.7752 - Avg Loss: 160.7179\n",
            "Epoch [15/50] - Batch loss: 164.4641 - Epoch Loss: 41308.2393 - Avg Loss: 160.7324\n",
            "Epoch [15/50] - Batch loss: 151.4129 - Epoch Loss: 41459.6523 - Avg Loss: 160.6963\n",
            "Epoch [15/50] - Batch loss: 157.4767 - Epoch Loss: 41617.1290 - Avg Loss: 160.6839\n",
            "Epoch [15/50] - Batch loss: 161.3881 - Epoch Loss: 41778.5170 - Avg Loss: 160.6866\n",
            "Epoch [15/50] - Batch loss: 167.3173 - Epoch Loss: 41945.8343 - Avg Loss: 160.7120\n",
            "Epoch [15/50] - Batch loss: 158.2192 - Epoch Loss: 42104.0535 - Avg Loss: 160.7025\n",
            "Epoch [15/50] - Batch loss: 159.2712 - Epoch Loss: 42263.3247 - Avg Loss: 160.6971\n",
            "Epoch [15/50] - Batch loss: 161.4995 - Epoch Loss: 42424.8242 - Avg Loss: 160.7001\n",
            "Epoch [15/50] - Batch loss: 157.5347 - Epoch Loss: 42582.3589 - Avg Loss: 160.6881\n",
            "Epoch [15/50] - Batch loss: 152.5592 - Epoch Loss: 42734.9181 - Avg Loss: 160.6576\n",
            "Epoch [15/50] - Batch loss: 163.0240 - Epoch Loss: 42897.9421 - Avg Loss: 160.6664\n",
            "Epoch [15/50] - Batch loss: 173.1568 - Epoch Loss: 43071.0989 - Avg Loss: 160.7131\n",
            "Epoch [15/50] - Batch loss: 158.5796 - Epoch Loss: 43229.6785 - Avg Loss: 160.7051\n",
            "Epoch [15/50] - Batch loss: 163.1421 - Epoch Loss: 43392.8206 - Avg Loss: 160.7142\n",
            "Epoch [15/50] - Batch loss: 162.3510 - Epoch Loss: 43555.1716 - Avg Loss: 160.7202\n",
            "Epoch [15/50] - Batch loss: 164.2601 - Epoch Loss: 43719.4317 - Avg Loss: 160.7332\n",
            "Epoch [15/50] - Batch loss: 168.6299 - Epoch Loss: 43888.0616 - Avg Loss: 160.7621\n",
            "Epoch [15/50] - Batch loss: 160.7329 - Epoch Loss: 44048.7945 - Avg Loss: 160.7620\n",
            "Epoch [15/50] - Batch loss: 160.9131 - Epoch Loss: 44209.7076 - Avg Loss: 160.7626\n",
            "Epoch [15/50] - Batch loss: 156.2392 - Epoch Loss: 44365.9467 - Avg Loss: 160.7462\n",
            "Epoch [15/50] - Batch loss: 150.9404 - Epoch Loss: 44516.8871 - Avg Loss: 160.7108\n",
            "Epoch [15/50] - Batch loss: 156.9531 - Epoch Loss: 44673.8402 - Avg Loss: 160.6973\n",
            "Epoch [15/50] - Batch loss: 154.1152 - Epoch Loss: 44827.9554 - Avg Loss: 160.6737\n",
            "Epoch [15/50] - Batch loss: 153.8171 - Epoch Loss: 44981.7725 - Avg Loss: 160.6492\n",
            "Epoch [15/50] - Batch loss: 167.2948 - Epoch Loss: 45149.0673 - Avg Loss: 160.6728\n",
            "Epoch [15/50] - Batch loss: 160.5197 - Epoch Loss: 45309.5870 - Avg Loss: 160.6723\n",
            "Epoch [15/50] - Batch loss: 160.1849 - Epoch Loss: 45469.7719 - Avg Loss: 160.6706\n",
            "Epoch [15/50] - Batch loss: 156.9316 - Epoch Loss: 45626.7035 - Avg Loss: 160.6574\n",
            "Epoch [15/50] - Batch loss: 161.7489 - Epoch Loss: 45788.4523 - Avg Loss: 160.6612\n",
            "Epoch [15/50] - Batch loss: 160.7537 - Epoch Loss: 45949.2061 - Avg Loss: 160.6616\n",
            "Epoch [15/50] - Batch loss: 162.4826 - Epoch Loss: 46111.6886 - Avg Loss: 160.6679\n",
            "Epoch [15/50] - Batch loss: 168.0463 - Epoch Loss: 46279.7350 - Avg Loss: 160.6935\n",
            "Epoch [15/50] - Batch loss: 164.0139 - Epoch Loss: 46443.7489 - Avg Loss: 160.7050\n",
            "Epoch [15/50] - Batch loss: 164.2505 - Epoch Loss: 46607.9994 - Avg Loss: 160.7172\n",
            "Epoch [15/50] - Batch loss: 152.1184 - Epoch Loss: 46760.1178 - Avg Loss: 160.6877\n",
            "Epoch [15/50] - Batch loss: 157.4866 - Epoch Loss: 46917.6044 - Avg Loss: 160.6767\n",
            "Epoch [15/50] - Batch loss: 162.4419 - Epoch Loss: 47080.0463 - Avg Loss: 160.6828\n",
            "Epoch [15/50] - Batch loss: 157.6794 - Epoch Loss: 47237.7257 - Avg Loss: 160.6725\n",
            "Epoch [15/50] - Batch loss: 167.4164 - Epoch Loss: 47405.1421 - Avg Loss: 160.6954\n",
            "Epoch [15/50] - Batch loss: 164.0783 - Epoch Loss: 47569.2204 - Avg Loss: 160.7068\n",
            "Epoch [15/50] - Batch loss: 163.1145 - Epoch Loss: 47732.3349 - Avg Loss: 160.7149\n",
            "Epoch [15/50] - Batch loss: 166.4330 - Epoch Loss: 47898.7679 - Avg Loss: 160.7341\n",
            "Epoch [15/50] - Batch loss: 164.7863 - Epoch Loss: 48063.5541 - Avg Loss: 160.7477\n",
            "Epoch [15/50] - Batch loss: 153.8064 - Epoch Loss: 48217.3605 - Avg Loss: 160.7245\n",
            "Epoch [15/50] - Batch loss: 165.3842 - Epoch Loss: 48382.7448 - Avg Loss: 160.7400\n",
            "Epoch [15/50] - Batch loss: 157.8111 - Epoch Loss: 48540.5559 - Avg Loss: 160.7303\n",
            "Epoch [15/50] - Batch loss: 163.6455 - Epoch Loss: 48704.2014 - Avg Loss: 160.7399\n",
            "Epoch [15/50] - Batch loss: 165.5586 - Epoch Loss: 48869.7600 - Avg Loss: 160.7558\n",
            "Epoch [15/50] - Batch loss: 161.1097 - Epoch Loss: 49030.8697 - Avg Loss: 160.7569\n",
            "Epoch [15/50] - Batch loss: 164.1910 - Epoch Loss: 49195.0607 - Avg Loss: 160.7682\n",
            "Epoch [15/50] - Batch loss: 161.4571 - Epoch Loss: 49356.5179 - Avg Loss: 160.7704\n",
            "Epoch [15/50] - Batch loss: 161.9600 - Epoch Loss: 49518.4778 - Avg Loss: 160.7743\n",
            "Epoch [15/50] - Batch loss: 170.0672 - Epoch Loss: 49688.5451 - Avg Loss: 160.8044\n",
            "Epoch [15/50] - Batch loss: 159.9812 - Epoch Loss: 49848.5263 - Avg Loss: 160.8017\n",
            "Epoch [15/50] - Batch loss: 159.2369 - Epoch Loss: 50007.7632 - Avg Loss: 160.7967\n",
            "Epoch [15/50] - Batch loss: 162.2545 - Epoch Loss: 50170.0177 - Avg Loss: 160.8013\n",
            "Epoch [15/50] - Batch loss: 159.8568 - Epoch Loss: 50329.8745 - Avg Loss: 160.7983\n",
            "Epoch [15/50] - Batch loss: 161.7760 - Epoch Loss: 50491.6505 - Avg Loss: 160.8014\n",
            "Epoch [15/50] - Batch loss: 158.7774 - Epoch Loss: 50650.4280 - Avg Loss: 160.7950\n",
            "Epoch [15/50] - Batch loss: 151.2758 - Epoch Loss: 50801.7038 - Avg Loss: 160.7649\n",
            "Epoch [15/50] - Batch loss: 166.3056 - Epoch Loss: 50968.0094 - Avg Loss: 160.7824\n",
            "Epoch [15/50] - Batch loss: 156.4515 - Epoch Loss: 51124.4609 - Avg Loss: 160.7687\n",
            "Epoch [15/50] - Batch loss: 169.7865 - Epoch Loss: 51294.2474 - Avg Loss: 160.7970\n",
            "Epoch [15/50] - Batch loss: 158.1616 - Epoch Loss: 51452.4090 - Avg Loss: 160.7888\n",
            "Epoch [15/50] - Batch loss: 158.0934 - Epoch Loss: 51610.5024 - Avg Loss: 160.7804\n",
            "Epoch [15/50] - Batch loss: 166.7749 - Epoch Loss: 51777.2773 - Avg Loss: 160.7990\n",
            "Epoch [15/50] - Batch loss: 155.5181 - Epoch Loss: 51932.7954 - Avg Loss: 160.7826\n",
            "Epoch [15/50] - Batch loss: 160.4521 - Epoch Loss: 52093.2475 - Avg Loss: 160.7816\n",
            "Epoch [15/50] - Batch loss: 156.9055 - Epoch Loss: 52250.1530 - Avg Loss: 160.7697\n",
            "Epoch [15/50] - Batch loss: 162.0381 - Epoch Loss: 52412.1911 - Avg Loss: 160.7736\n",
            "Epoch [15/50] - Batch loss: 153.1679 - Epoch Loss: 52565.3590 - Avg Loss: 160.7503\n",
            "Epoch [15/50] - Batch loss: 156.9413 - Epoch Loss: 52722.3003 - Avg Loss: 160.7387\n",
            "Epoch [15/50] - Batch loss: 156.3940 - Epoch Loss: 52878.6943 - Avg Loss: 160.7255\n",
            "Epoch [15/50] - Batch loss: 161.5253 - Epoch Loss: 53040.2196 - Avg Loss: 160.7279\n",
            "Epoch [15/50] - Batch loss: 152.7389 - Epoch Loss: 53192.9585 - Avg Loss: 160.7038\n",
            "Epoch [15/50] - Batch loss: 160.8068 - Epoch Loss: 53353.7653 - Avg Loss: 160.7041\n",
            "Epoch [15/50] - Batch loss: 162.1473 - Epoch Loss: 53515.9125 - Avg Loss: 160.7084\n",
            "Epoch [15/50] - Batch loss: 153.6024 - Epoch Loss: 53669.5150 - Avg Loss: 160.6872\n",
            "Epoch [15/50] - Batch loss: 165.2231 - Epoch Loss: 53834.7380 - Avg Loss: 160.7007\n",
            "Epoch [15/50] - Batch loss: 162.4458 - Epoch Loss: 53997.1838 - Avg Loss: 160.7059\n",
            "Epoch [15/50] - Batch loss: 161.9171 - Epoch Loss: 54159.1009 - Avg Loss: 160.7095\n",
            "Epoch [15/50] - Batch loss: 161.1236 - Epoch Loss: 54320.2245 - Avg Loss: 160.7107\n",
            "Epoch [15/50] - Batch loss: 163.4730 - Epoch Loss: 54483.6975 - Avg Loss: 160.7189\n",
            "Epoch [15/50] - Batch loss: 167.8081 - Epoch Loss: 54651.5056 - Avg Loss: 160.7397\n",
            "Epoch [15/50] - Batch loss: 152.9014 - Epoch Loss: 54804.4070 - Avg Loss: 160.7167\n",
            "Epoch [15/50] - Batch loss: 162.3250 - Epoch Loss: 54966.7320 - Avg Loss: 160.7214\n",
            "Epoch [15/50] - Batch loss: 159.5737 - Epoch Loss: 55126.3057 - Avg Loss: 160.7181\n",
            "Epoch [15/50] - Batch loss: 159.0064 - Epoch Loss: 55285.3121 - Avg Loss: 160.7131\n",
            "Epoch [15/50] - Batch loss: 160.3051 - Epoch Loss: 55445.6172 - Avg Loss: 160.7119\n",
            "Epoch [15/50] - Batch loss: 167.6538 - Epoch Loss: 55613.2710 - Avg Loss: 160.7320\n",
            "Epoch [15/50] - Batch loss: 158.2197 - Epoch Loss: 55771.4907 - Avg Loss: 160.7248\n",
            "Epoch [15/50] - Batch loss: 158.8262 - Epoch Loss: 55930.3169 - Avg Loss: 160.7193\n",
            "Epoch [15/50] - Batch loss: 160.9501 - Epoch Loss: 56091.2669 - Avg Loss: 160.7200\n",
            "Epoch [15/50] - Batch loss: 152.5759 - Epoch Loss: 56243.8428 - Avg Loss: 160.6967\n",
            "Epoch [15/50] - Batch loss: 159.4198 - Epoch Loss: 56403.2626 - Avg Loss: 160.6931\n",
            "Epoch [15/50] - Batch loss: 161.9351 - Epoch Loss: 56565.1978 - Avg Loss: 160.6966\n",
            "Epoch [15/50] - Batch loss: 165.0367 - Epoch Loss: 56730.2344 - Avg Loss: 160.7089\n",
            "Epoch [15/50] - Batch loss: 162.3273 - Epoch Loss: 56892.5617 - Avg Loss: 160.7135\n",
            "Epoch [15/50] - Batch loss: 160.0493 - Epoch Loss: 57052.6110 - Avg Loss: 160.7116\n",
            "Epoch [15/50] - Batch loss: 158.8970 - Epoch Loss: 57211.5080 - Avg Loss: 160.7065\n",
            "Epoch [15/50] - Batch loss: 155.0241 - Epoch Loss: 57366.5321 - Avg Loss: 160.6906\n",
            "Epoch [15/50] - Batch loss: 160.0811 - Epoch Loss: 57526.6132 - Avg Loss: 160.6889\n",
            "Epoch [15/50] - Batch loss: 162.8898 - Epoch Loss: 57689.5030 - Avg Loss: 160.6950\n",
            "Epoch [15/50] - Batch loss: 158.9471 - Epoch Loss: 57848.4501 - Avg Loss: 160.6901\n",
            "Epoch [15/50] - Batch loss: 153.6637 - Epoch Loss: 58002.1138 - Avg Loss: 160.6707\n",
            "Epoch [15/50] - Batch loss: 165.6248 - Epoch Loss: 58167.7386 - Avg Loss: 160.6844\n",
            "Epoch [15/50] - Batch loss: 155.4973 - Epoch Loss: 58323.2359 - Avg Loss: 160.6701\n",
            "Epoch [15/50] - Batch loss: 167.0476 - Epoch Loss: 58490.2835 - Avg Loss: 160.6876\n",
            "Epoch [15/50] - Batch loss: 160.9074 - Epoch Loss: 58651.1909 - Avg Loss: 160.6882\n",
            "Epoch [15/50] - Batch loss: 156.1261 - Epoch Loss: 58807.3170 - Avg Loss: 160.6757\n",
            "Epoch [15/50] - Batch loss: 169.0302 - Epoch Loss: 58976.3472 - Avg Loss: 160.6985\n",
            "Epoch [15/50] - Batch loss: 160.9924 - Epoch Loss: 59137.3395 - Avg Loss: 160.6993\n",
            "Epoch [15/50] - Batch loss: 161.4698 - Epoch Loss: 59298.8093 - Avg Loss: 160.7014\n",
            "Epoch [15/50] - Batch loss: 160.6398 - Epoch Loss: 59459.4491 - Avg Loss: 160.7012\n",
            "Epoch [15/50] - Batch loss: 155.7269 - Epoch Loss: 59615.1760 - Avg Loss: 160.6878\n",
            "Epoch [15/50] - Batch loss: 157.6244 - Epoch Loss: 59772.8004 - Avg Loss: 160.6796\n",
            "Epoch [15/50] - Batch loss: 159.2107 - Epoch Loss: 59932.0111 - Avg Loss: 160.6756\n",
            "Epoch [15/50] - Batch loss: 161.8928 - Epoch Loss: 60093.9039 - Avg Loss: 160.6789\n",
            "Epoch [15/50] - Batch loss: 160.9034 - Epoch Loss: 60254.8073 - Avg Loss: 160.6795\n",
            "Epoch [15/50] - Batch loss: 151.9098 - Epoch Loss: 60406.7170 - Avg Loss: 160.6562\n",
            "Epoch [15/50] - Batch loss: 158.8453 - Epoch Loss: 60565.5623 - Avg Loss: 160.6514\n",
            "Epoch [15/50] - Batch loss: 159.0249 - Epoch Loss: 60724.5873 - Avg Loss: 160.6471\n",
            "Epoch [15/50] - Batch loss: 161.5881 - Epoch Loss: 60886.1753 - Avg Loss: 160.6495\n",
            "Epoch [15/50] - Batch loss: 158.2394 - Epoch Loss: 61044.4147 - Avg Loss: 160.6432\n",
            "Epoch [15/50] - Batch loss: 161.5707 - Epoch Loss: 61205.9855 - Avg Loss: 160.6456\n",
            "Epoch [15/50] - Batch loss: 160.0385 - Epoch Loss: 61366.0240 - Avg Loss: 160.6440\n",
            "Epoch [15/50] - Batch loss: 157.2128 - Epoch Loss: 61523.2368 - Avg Loss: 160.6351\n",
            "Epoch [15/50] - Batch loss: 161.5622 - Epoch Loss: 61684.7990 - Avg Loss: 160.6375\n",
            "Epoch [15/50] - Batch loss: 158.3718 - Epoch Loss: 61843.1709 - Avg Loss: 160.6316\n",
            "Epoch [15/50] - Batch loss: 163.5444 - Epoch Loss: 62006.7152 - Avg Loss: 160.6392\n",
            "Epoch [15/50] - Batch loss: 152.5105 - Epoch Loss: 62159.2257 - Avg Loss: 160.6182\n",
            "Epoch [15/50] - Batch loss: 162.4100 - Epoch Loss: 62321.6357 - Avg Loss: 160.6228\n",
            "Epoch [15/50] - Batch loss: 153.9874 - Epoch Loss: 62475.6230 - Avg Loss: 160.6057\n",
            "Epoch [15/50] - Batch loss: 155.6318 - Epoch Loss: 62631.2549 - Avg Loss: 160.5930\n",
            "Epoch [15/50] - Batch loss: 160.8754 - Epoch Loss: 62792.1302 - Avg Loss: 160.5937\n",
            "Epoch [15/50] - Batch loss: 163.2920 - Epoch Loss: 62955.4222 - Avg Loss: 160.6006\n",
            "Epoch [15/50] - Batch loss: 166.2440 - Epoch Loss: 63121.6662 - Avg Loss: 160.6149\n",
            "Epoch [15/50] - Batch loss: 156.5998 - Epoch Loss: 63278.2661 - Avg Loss: 160.6047\n",
            "Epoch [15/50] - Batch loss: 157.0821 - Epoch Loss: 63435.3481 - Avg Loss: 160.5958\n",
            "Epoch [15/50] - Batch loss: 164.5412 - Epoch Loss: 63599.8894 - Avg Loss: 160.6058\n",
            "Epoch [15/50] - Batch loss: 159.6909 - Epoch Loss: 63759.5803 - Avg Loss: 160.6035\n",
            "Epoch [15/50] - Batch loss: 162.5969 - Epoch Loss: 63922.1771 - Avg Loss: 160.6085\n",
            "Epoch [15/50] - Batch loss: 168.6876 - Epoch Loss: 64090.8648 - Avg Loss: 160.6287\n",
            "Epoch [15/50] - Batch loss: 158.6035 - Epoch Loss: 64249.4683 - Avg Loss: 160.6237\n",
            "Epoch [15/50] - Batch loss: 154.7754 - Epoch Loss: 64404.2437 - Avg Loss: 160.6091\n",
            "Epoch [15/50] - Batch loss: 161.6800 - Epoch Loss: 64565.9237 - Avg Loss: 160.6118\n",
            "Epoch [15/50] - Batch loss: 159.2996 - Epoch Loss: 64725.2233 - Avg Loss: 160.6085\n",
            "Epoch [15/50] - Batch loss: 161.9965 - Epoch Loss: 64887.2198 - Avg Loss: 160.6119\n",
            "Epoch [15/50] - Batch loss: 158.8209 - Epoch Loss: 65046.0407 - Avg Loss: 160.6075\n",
            "Epoch [15/50] - Batch loss: 163.8911 - Epoch Loss: 65209.9318 - Avg Loss: 160.6156\n",
            "Epoch [15/50] - Batch loss: 164.8229 - Epoch Loss: 65374.7547 - Avg Loss: 160.6259\n",
            "Epoch [15/50] - Batch loss: 162.5688 - Epoch Loss: 65537.3235 - Avg Loss: 160.6307\n",
            "Epoch [15/50] - Batch loss: 160.6217 - Epoch Loss: 65697.9452 - Avg Loss: 160.6307\n",
            "Epoch [15/50] - Batch loss: 166.3332 - Epoch Loss: 65864.2784 - Avg Loss: 160.6446\n",
            "Epoch [15/50] - Batch loss: 162.5996 - Epoch Loss: 66026.8780 - Avg Loss: 160.6493\n",
            "Epoch [15/50] - Batch loss: 157.1183 - Epoch Loss: 66183.9962 - Avg Loss: 160.6408\n",
            "Epoch [15/50] - Batch loss: 163.5368 - Epoch Loss: 66347.5331 - Avg Loss: 160.6478\n",
            "Epoch [15/50] - Batch loss: 164.3750 - Epoch Loss: 66511.9081 - Avg Loss: 160.6568\n",
            "Epoch [15/50] - Batch loss: 162.8920 - Epoch Loss: 66674.8001 - Avg Loss: 160.6622\n",
            "Epoch [15/50] - Batch loss: 163.0587 - Epoch Loss: 66837.8587 - Avg Loss: 160.6679\n",
            "Epoch [15/50] - Batch loss: 165.1748 - Epoch Loss: 67003.0335 - Avg Loss: 160.6787\n",
            "Epoch [15/50] - Batch loss: 160.8223 - Epoch Loss: 67163.8558 - Avg Loss: 160.6791\n",
            "Epoch [15/50] - Batch loss: 162.0637 - Epoch Loss: 67325.9195 - Avg Loss: 160.6824\n",
            "Epoch [15/50] - Batch loss: 155.6377 - Epoch Loss: 67481.5572 - Avg Loss: 160.6704\n",
            "Epoch [15/50] - Batch loss: 157.3622 - Epoch Loss: 67638.9194 - Avg Loss: 160.6625\n",
            "Epoch [15/50] - Batch loss: 155.1568 - Epoch Loss: 67794.0762 - Avg Loss: 160.6495\n",
            "Epoch [15/50] - Batch loss: 162.1907 - Epoch Loss: 67956.2669 - Avg Loss: 160.6531\n",
            "Epoch [15/50] - Batch loss: 155.4371 - Epoch Loss: 68111.7039 - Avg Loss: 160.6408\n",
            "Epoch [15/50] - Batch loss: 156.9934 - Epoch Loss: 68268.6973 - Avg Loss: 160.6322\n",
            "Epoch [15/50] - Batch loss: 172.0472 - Epoch Loss: 68440.7445 - Avg Loss: 160.6590\n",
            "Epoch [15/50] - Batch loss: 162.0991 - Epoch Loss: 68602.8436 - Avg Loss: 160.6624\n",
            "Epoch [15/50] - Batch loss: 164.5205 - Epoch Loss: 68767.3641 - Avg Loss: 160.6714\n",
            "Epoch [15/50] - Batch loss: 161.0632 - Epoch Loss: 68928.4273 - Avg Loss: 160.6723\n",
            "Epoch [15/50] - Batch loss: 160.2200 - Epoch Loss: 69088.6473 - Avg Loss: 160.6713\n",
            "Epoch [15/50] - Batch loss: 169.7536 - Epoch Loss: 69258.4009 - Avg Loss: 160.6923\n",
            "Epoch [15/50] - Batch loss: 158.8132 - Epoch Loss: 69417.2142 - Avg Loss: 160.6880\n",
            "Epoch [15/50] - Batch loss: 163.6680 - Epoch Loss: 69580.8821 - Avg Loss: 160.6949\n",
            "Epoch [15/50] - Batch loss: 161.2205 - Epoch Loss: 69742.1026 - Avg Loss: 160.6961\n",
            "Epoch [15/50] - Batch loss: 160.3877 - Epoch Loss: 69902.4903 - Avg Loss: 160.6954\n",
            "Epoch [15/50] - Batch loss: 161.3981 - Epoch Loss: 70063.8884 - Avg Loss: 160.6970\n",
            "Epoch [15/50] - Batch loss: 158.7186 - Epoch Loss: 70222.6070 - Avg Loss: 160.6925\n",
            "Epoch [15/50] - Batch loss: 164.3255 - Epoch Loss: 70386.9326 - Avg Loss: 160.7008\n",
            "Epoch [15/50] - Batch loss: 163.5730 - Epoch Loss: 70550.5056 - Avg Loss: 160.7073\n",
            "Epoch [15/50] - Batch loss: 161.5846 - Epoch Loss: 70712.0902 - Avg Loss: 160.7093\n",
            "Epoch [15/50] - Batch loss: 161.9176 - Epoch Loss: 70874.0078 - Avg Loss: 160.7120\n",
            "Epoch [15/50] - Batch loss: 165.9758 - Epoch Loss: 71039.9836 - Avg Loss: 160.7239\n",
            "Epoch [15/50] - Batch loss: 159.2293 - Epoch Loss: 71199.2129 - Avg Loss: 160.7206\n",
            "Epoch [15/50] - Batch loss: 165.5755 - Epoch Loss: 71364.7884 - Avg Loss: 160.7315\n",
            "Epoch [15/50] - Batch loss: 153.4550 - Epoch Loss: 71518.2434 - Avg Loss: 160.7152\n",
            "Epoch [15/50] - Batch loss: 168.5482 - Epoch Loss: 71686.7916 - Avg Loss: 160.7327\n",
            "Epoch [15/50] - Batch loss: 169.5762 - Epoch Loss: 71856.3678 - Avg Loss: 160.7525\n",
            "Epoch [15/50] - Batch loss: 174.0300 - Epoch Loss: 72030.3977 - Avg Loss: 160.7821\n",
            "Epoch [15/50] - Batch loss: 163.2399 - Epoch Loss: 72193.6376 - Avg Loss: 160.7876\n",
            "Epoch [15/50] - Batch loss: 155.4096 - Epoch Loss: 72349.0472 - Avg Loss: 160.7757\n",
            "Epoch [15/50] - Batch loss: 163.3473 - Epoch Loss: 72512.3945 - Avg Loss: 160.7814\n",
            "Epoch [15/50] - Batch loss: 155.3875 - Epoch Loss: 72667.7820 - Avg Loss: 160.7694\n",
            "Epoch [15/50] - Batch loss: 157.7174 - Epoch Loss: 72825.4994 - Avg Loss: 160.7627\n",
            "Epoch [15/50] - Batch loss: 154.1714 - Epoch Loss: 72979.6708 - Avg Loss: 160.7482\n",
            "Epoch [15/50] - Batch loss: 160.2089 - Epoch Loss: 73139.8797 - Avg Loss: 160.7470\n",
            "Epoch [15/50] - Batch loss: 160.9476 - Epoch Loss: 73300.8273 - Avg Loss: 160.7474\n",
            "Epoch [15/50] - Batch loss: 160.6093 - Epoch Loss: 73461.4366 - Avg Loss: 160.7471\n",
            "Epoch [15/50] - Batch loss: 164.7225 - Epoch Loss: 73626.1592 - Avg Loss: 160.7558\n",
            "Epoch [15/50] - Batch loss: 158.2305 - Epoch Loss: 73784.3897 - Avg Loss: 160.7503\n",
            "Epoch [15/50] - Batch loss: 156.7620 - Epoch Loss: 73941.1517 - Avg Loss: 160.7416\n",
            "Epoch [15/50] - Batch loss: 162.4371 - Epoch Loss: 74103.5888 - Avg Loss: 160.7453\n",
            "Epoch [15/50] - Batch loss: 161.5390 - Epoch Loss: 74265.1278 - Avg Loss: 160.7470\n",
            "Epoch [15/50] - Batch loss: 162.4141 - Epoch Loss: 74427.5419 - Avg Loss: 160.7506\n",
            "Epoch [15/50] - Batch loss: 151.6600 - Epoch Loss: 74579.2019 - Avg Loss: 160.7310\n",
            "Epoch [15/50] - Batch loss: 159.5890 - Epoch Loss: 74738.7909 - Avg Loss: 160.7286\n",
            "Epoch [15/50] - Batch loss: 162.8732 - Epoch Loss: 74901.6642 - Avg Loss: 160.7332\n",
            "Epoch [15/50] - Batch loss: 161.3734 - Epoch Loss: 75063.0376 - Avg Loss: 160.7346\n",
            "Epoch [15/50] - Batch loss: 163.3572 - Epoch Loss: 75226.3947 - Avg Loss: 160.7402\n",
            "Epoch [15/50] - Batch loss: 154.1685 - Epoch Loss: 75380.5632 - Avg Loss: 160.7261\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 16/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88ffbf07fd9b453b9a17ef5124dd5cbb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/50] - Batch loss: 156.2225 - Epoch Loss: 156.2225 - Avg Loss: 156.2225\n",
            "Epoch [16/50] - Batch loss: 163.4615 - Epoch Loss: 319.6840 - Avg Loss: 159.8420\n",
            "Epoch [16/50] - Batch loss: 165.9136 - Epoch Loss: 485.5976 - Avg Loss: 161.8659\n",
            "Epoch [16/50] - Batch loss: 159.1483 - Epoch Loss: 644.7460 - Avg Loss: 161.1865\n",
            "Epoch [16/50] - Batch loss: 152.6583 - Epoch Loss: 797.4043 - Avg Loss: 159.4809\n",
            "Epoch [16/50] - Batch loss: 163.1798 - Epoch Loss: 960.5841 - Avg Loss: 160.0973\n",
            "Epoch [16/50] - Batch loss: 169.7111 - Epoch Loss: 1130.2951 - Avg Loss: 161.4707\n",
            "Epoch [16/50] - Batch loss: 160.0354 - Epoch Loss: 1290.3305 - Avg Loss: 161.2913\n",
            "Epoch [16/50] - Batch loss: 165.2948 - Epoch Loss: 1455.6253 - Avg Loss: 161.7361\n",
            "Epoch [16/50] - Batch loss: 155.3918 - Epoch Loss: 1611.0171 - Avg Loss: 161.1017\n",
            "Epoch [16/50] - Batch loss: 162.7076 - Epoch Loss: 1773.7246 - Avg Loss: 161.2477\n",
            "Epoch [16/50] - Batch loss: 153.2807 - Epoch Loss: 1927.0053 - Avg Loss: 160.5838\n",
            "Epoch [16/50] - Batch loss: 168.6411 - Epoch Loss: 2095.6464 - Avg Loss: 161.2036\n",
            "Epoch [16/50] - Batch loss: 159.9956 - Epoch Loss: 2255.6420 - Avg Loss: 161.1173\n",
            "Epoch [16/50] - Batch loss: 157.8715 - Epoch Loss: 2413.5135 - Avg Loss: 160.9009\n",
            "Epoch [16/50] - Batch loss: 164.1385 - Epoch Loss: 2577.6520 - Avg Loss: 161.1033\n",
            "Epoch [16/50] - Batch loss: 161.7987 - Epoch Loss: 2739.4507 - Avg Loss: 161.1442\n",
            "Epoch [16/50] - Batch loss: 165.9515 - Epoch Loss: 2905.4022 - Avg Loss: 161.4112\n",
            "Epoch [16/50] - Batch loss: 165.8896 - Epoch Loss: 3071.2918 - Avg Loss: 161.6469\n",
            "Epoch [16/50] - Batch loss: 163.3443 - Epoch Loss: 3234.6361 - Avg Loss: 161.7318\n",
            "Epoch [16/50] - Batch loss: 162.4673 - Epoch Loss: 3397.1034 - Avg Loss: 161.7668\n",
            "Epoch [16/50] - Batch loss: 161.9416 - Epoch Loss: 3559.0450 - Avg Loss: 161.7748\n",
            "Epoch [16/50] - Batch loss: 160.2945 - Epoch Loss: 3719.3395 - Avg Loss: 161.7104\n",
            "Epoch [16/50] - Batch loss: 160.7411 - Epoch Loss: 3880.0806 - Avg Loss: 161.6700\n",
            "Epoch [16/50] - Batch loss: 165.8178 - Epoch Loss: 4045.8984 - Avg Loss: 161.8359\n",
            "Epoch [16/50] - Batch loss: 153.7822 - Epoch Loss: 4199.6806 - Avg Loss: 161.5262\n",
            "Epoch [16/50] - Batch loss: 157.4724 - Epoch Loss: 4357.1530 - Avg Loss: 161.3760\n",
            "Epoch [16/50] - Batch loss: 165.1049 - Epoch Loss: 4522.2579 - Avg Loss: 161.5092\n",
            "Epoch [16/50] - Batch loss: 168.8595 - Epoch Loss: 4691.1174 - Avg Loss: 161.7627\n",
            "Epoch [16/50] - Batch loss: 152.8639 - Epoch Loss: 4843.9813 - Avg Loss: 161.4660\n",
            "Epoch [16/50] - Batch loss: 169.4625 - Epoch Loss: 5013.4438 - Avg Loss: 161.7240\n",
            "Epoch [16/50] - Batch loss: 154.6402 - Epoch Loss: 5168.0840 - Avg Loss: 161.5026\n",
            "Epoch [16/50] - Batch loss: 162.5946 - Epoch Loss: 5330.6786 - Avg Loss: 161.5357\n",
            "Epoch [16/50] - Batch loss: 162.6530 - Epoch Loss: 5493.3315 - Avg Loss: 161.5686\n",
            "Epoch [16/50] - Batch loss: 158.5077 - Epoch Loss: 5651.8392 - Avg Loss: 161.4811\n",
            "Epoch [16/50] - Batch loss: 162.3529 - Epoch Loss: 5814.1921 - Avg Loss: 161.5053\n",
            "Epoch [16/50] - Batch loss: 153.1884 - Epoch Loss: 5967.3806 - Avg Loss: 161.2806\n",
            "Epoch [16/50] - Batch loss: 164.4840 - Epoch Loss: 6131.8646 - Avg Loss: 161.3649\n",
            "Epoch [16/50] - Batch loss: 155.5502 - Epoch Loss: 6287.4148 - Avg Loss: 161.2158\n",
            "Epoch [16/50] - Batch loss: 156.7464 - Epoch Loss: 6444.1613 - Avg Loss: 161.1040\n",
            "Epoch [16/50] - Batch loss: 162.8164 - Epoch Loss: 6606.9776 - Avg Loss: 161.1458\n",
            "Epoch [16/50] - Batch loss: 159.4893 - Epoch Loss: 6766.4670 - Avg Loss: 161.1064\n",
            "Epoch [16/50] - Batch loss: 160.9953 - Epoch Loss: 6927.4623 - Avg Loss: 161.1038\n",
            "Epoch [16/50] - Batch loss: 157.4207 - Epoch Loss: 7084.8830 - Avg Loss: 161.0201\n",
            "Epoch [16/50] - Batch loss: 165.9301 - Epoch Loss: 7250.8131 - Avg Loss: 161.1292\n",
            "Epoch [16/50] - Batch loss: 169.6378 - Epoch Loss: 7420.4509 - Avg Loss: 161.3141\n",
            "Epoch [16/50] - Batch loss: 166.0494 - Epoch Loss: 7586.5003 - Avg Loss: 161.4149\n",
            "Epoch [16/50] - Batch loss: 160.4947 - Epoch Loss: 7746.9950 - Avg Loss: 161.3957\n",
            "Epoch [16/50] - Batch loss: 169.8771 - Epoch Loss: 7916.8720 - Avg Loss: 161.5688\n",
            "Epoch [16/50] - Batch loss: 166.8851 - Epoch Loss: 8083.7572 - Avg Loss: 161.6751\n",
            "Epoch [16/50] - Batch loss: 159.5802 - Epoch Loss: 8243.3373 - Avg Loss: 161.6341\n",
            "Epoch [16/50] - Batch loss: 167.4023 - Epoch Loss: 8410.7396 - Avg Loss: 161.7450\n",
            "Epoch [16/50] - Batch loss: 155.9713 - Epoch Loss: 8566.7109 - Avg Loss: 161.6361\n",
            "Epoch [16/50] - Batch loss: 162.4262 - Epoch Loss: 8729.1371 - Avg Loss: 161.6507\n",
            "Epoch [16/50] - Batch loss: 164.3245 - Epoch Loss: 8893.4616 - Avg Loss: 161.6993\n",
            "Epoch [16/50] - Batch loss: 168.8576 - Epoch Loss: 9062.3192 - Avg Loss: 161.8271\n",
            "Epoch [16/50] - Batch loss: 167.0817 - Epoch Loss: 9229.4009 - Avg Loss: 161.9193\n",
            "Epoch [16/50] - Batch loss: 170.4391 - Epoch Loss: 9399.8400 - Avg Loss: 162.0662\n",
            "Epoch [16/50] - Batch loss: 165.8702 - Epoch Loss: 9565.7102 - Avg Loss: 162.1307\n",
            "Epoch [16/50] - Batch loss: 165.3239 - Epoch Loss: 9731.0341 - Avg Loss: 162.1839\n",
            "Epoch [16/50] - Batch loss: 157.2827 - Epoch Loss: 9888.3168 - Avg Loss: 162.1036\n",
            "Epoch [16/50] - Batch loss: 162.8200 - Epoch Loss: 10051.1369 - Avg Loss: 162.1151\n",
            "Epoch [16/50] - Batch loss: 169.4713 - Epoch Loss: 10220.6082 - Avg Loss: 162.2319\n",
            "Epoch [16/50] - Batch loss: 163.7937 - Epoch Loss: 10384.4019 - Avg Loss: 162.2563\n",
            "Epoch [16/50] - Batch loss: 163.0293 - Epoch Loss: 10547.4312 - Avg Loss: 162.2682\n",
            "Epoch [16/50] - Batch loss: 158.9872 - Epoch Loss: 10706.4184 - Avg Loss: 162.2185\n",
            "Epoch [16/50] - Batch loss: 164.3148 - Epoch Loss: 10870.7332 - Avg Loss: 162.2497\n",
            "Epoch [16/50] - Batch loss: 165.7898 - Epoch Loss: 11036.5230 - Avg Loss: 162.3018\n",
            "Epoch [16/50] - Batch loss: 156.0883 - Epoch Loss: 11192.6113 - Avg Loss: 162.2118\n",
            "Epoch [16/50] - Batch loss: 163.1680 - Epoch Loss: 11355.7793 - Avg Loss: 162.2254\n",
            "Epoch [16/50] - Batch loss: 154.2615 - Epoch Loss: 11510.0408 - Avg Loss: 162.1133\n",
            "Epoch [16/50] - Batch loss: 165.1722 - Epoch Loss: 11675.2130 - Avg Loss: 162.1557\n",
            "Epoch [16/50] - Batch loss: 168.8200 - Epoch Loss: 11844.0330 - Avg Loss: 162.2470\n",
            "Epoch [16/50] - Batch loss: 158.5204 - Epoch Loss: 12002.5534 - Avg Loss: 162.1967\n",
            "Epoch [16/50] - Batch loss: 168.9578 - Epoch Loss: 12171.5112 - Avg Loss: 162.2868\n",
            "Epoch [16/50] - Batch loss: 161.3928 - Epoch Loss: 12332.9040 - Avg Loss: 162.2751\n",
            "Epoch [16/50] - Batch loss: 160.9091 - Epoch Loss: 12493.8130 - Avg Loss: 162.2573\n",
            "Epoch [16/50] - Batch loss: 165.1417 - Epoch Loss: 12658.9548 - Avg Loss: 162.2943\n",
            "Epoch [16/50] - Batch loss: 161.1807 - Epoch Loss: 12820.1354 - Avg Loss: 162.2802\n",
            "Epoch [16/50] - Batch loss: 159.4514 - Epoch Loss: 12979.5868 - Avg Loss: 162.2448\n",
            "Epoch [16/50] - Batch loss: 159.8611 - Epoch Loss: 13139.4479 - Avg Loss: 162.2154\n",
            "Epoch [16/50] - Batch loss: 154.0733 - Epoch Loss: 13293.5213 - Avg Loss: 162.1161\n",
            "Epoch [16/50] - Batch loss: 163.0854 - Epoch Loss: 13456.6066 - Avg Loss: 162.1278\n",
            "Epoch [16/50] - Batch loss: 161.0136 - Epoch Loss: 13617.6203 - Avg Loss: 162.1145\n",
            "Epoch [16/50] - Batch loss: 160.5131 - Epoch Loss: 13778.1334 - Avg Loss: 162.0957\n",
            "Epoch [16/50] - Batch loss: 164.1537 - Epoch Loss: 13942.2871 - Avg Loss: 162.1196\n",
            "Epoch [16/50] - Batch loss: 161.8581 - Epoch Loss: 14104.1452 - Avg Loss: 162.1166\n",
            "Epoch [16/50] - Batch loss: 162.1629 - Epoch Loss: 14266.3081 - Avg Loss: 162.1171\n",
            "Epoch [16/50] - Batch loss: 164.8293 - Epoch Loss: 14431.1374 - Avg Loss: 162.1476\n",
            "Epoch [16/50] - Batch loss: 162.0858 - Epoch Loss: 14593.2232 - Avg Loss: 162.1469\n",
            "Epoch [16/50] - Batch loss: 168.3243 - Epoch Loss: 14761.5475 - Avg Loss: 162.2148\n",
            "Epoch [16/50] - Batch loss: 153.2494 - Epoch Loss: 14914.7969 - Avg Loss: 162.1174\n",
            "Epoch [16/50] - Batch loss: 168.6533 - Epoch Loss: 15083.4502 - Avg Loss: 162.1876\n",
            "Epoch [16/50] - Batch loss: 163.6855 - Epoch Loss: 15247.1357 - Avg Loss: 162.2036\n",
            "Epoch [16/50] - Batch loss: 166.9325 - Epoch Loss: 15414.0682 - Avg Loss: 162.2533\n",
            "Epoch [16/50] - Batch loss: 159.7039 - Epoch Loss: 15573.7721 - Avg Loss: 162.2268\n",
            "Epoch [16/50] - Batch loss: 167.0703 - Epoch Loss: 15740.8424 - Avg Loss: 162.2767\n",
            "Epoch [16/50] - Batch loss: 168.8111 - Epoch Loss: 15909.6536 - Avg Loss: 162.3434\n",
            "Epoch [16/50] - Batch loss: 164.7988 - Epoch Loss: 16074.4523 - Avg Loss: 162.3682\n",
            "Epoch [16/50] - Batch loss: 157.5410 - Epoch Loss: 16231.9933 - Avg Loss: 162.3199\n",
            "Epoch [16/50] - Batch loss: 155.8058 - Epoch Loss: 16387.7991 - Avg Loss: 162.2554\n",
            "Epoch [16/50] - Batch loss: 154.9028 - Epoch Loss: 16542.7019 - Avg Loss: 162.1834\n",
            "Epoch [16/50] - Batch loss: 162.7597 - Epoch Loss: 16705.4616 - Avg Loss: 162.1889\n",
            "Epoch [16/50] - Batch loss: 166.7685 - Epoch Loss: 16872.2301 - Avg Loss: 162.2330\n",
            "Epoch [16/50] - Batch loss: 163.7412 - Epoch Loss: 17035.9713 - Avg Loss: 162.2473\n",
            "Epoch [16/50] - Batch loss: 156.7209 - Epoch Loss: 17192.6923 - Avg Loss: 162.1952\n",
            "Epoch [16/50] - Batch loss: 160.0268 - Epoch Loss: 17352.7191 - Avg Loss: 162.1749\n",
            "Epoch [16/50] - Batch loss: 164.6417 - Epoch Loss: 17517.3608 - Avg Loss: 162.1978\n",
            "Epoch [16/50] - Batch loss: 163.9679 - Epoch Loss: 17681.3288 - Avg Loss: 162.2140\n",
            "Epoch [16/50] - Batch loss: 159.0911 - Epoch Loss: 17840.4199 - Avg Loss: 162.1856\n",
            "Epoch [16/50] - Batch loss: 156.3003 - Epoch Loss: 17996.7202 - Avg Loss: 162.1326\n",
            "Epoch [16/50] - Batch loss: 165.3519 - Epoch Loss: 18162.0721 - Avg Loss: 162.1614\n",
            "Epoch [16/50] - Batch loss: 171.4515 - Epoch Loss: 18333.5235 - Avg Loss: 162.2436\n",
            "Epoch [16/50] - Batch loss: 157.4512 - Epoch Loss: 18490.9747 - Avg Loss: 162.2015\n",
            "Epoch [16/50] - Batch loss: 160.3198 - Epoch Loss: 18651.2945 - Avg Loss: 162.1852\n",
            "Epoch [16/50] - Batch loss: 159.5293 - Epoch Loss: 18810.8238 - Avg Loss: 162.1623\n",
            "Epoch [16/50] - Batch loss: 158.0127 - Epoch Loss: 18968.8365 - Avg Loss: 162.1268\n",
            "Epoch [16/50] - Batch loss: 160.7888 - Epoch Loss: 19129.6253 - Avg Loss: 162.1155\n",
            "Epoch [16/50] - Batch loss: 151.9279 - Epoch Loss: 19281.5531 - Avg Loss: 162.0299\n",
            "Epoch [16/50] - Batch loss: 157.5573 - Epoch Loss: 19439.1105 - Avg Loss: 161.9926\n",
            "Epoch [16/50] - Batch loss: 155.9579 - Epoch Loss: 19595.0684 - Avg Loss: 161.9427\n",
            "Epoch [16/50] - Batch loss: 156.8837 - Epoch Loss: 19751.9521 - Avg Loss: 161.9012\n",
            "Epoch [16/50] - Batch loss: 164.5376 - Epoch Loss: 19916.4897 - Avg Loss: 161.9227\n",
            "Epoch [16/50] - Batch loss: 158.0630 - Epoch Loss: 20074.5527 - Avg Loss: 161.8916\n",
            "Epoch [16/50] - Batch loss: 164.3874 - Epoch Loss: 20238.9402 - Avg Loss: 161.9115\n",
            "Epoch [16/50] - Batch loss: 160.3678 - Epoch Loss: 20399.3079 - Avg Loss: 161.8993\n",
            "Epoch [16/50] - Batch loss: 163.2280 - Epoch Loss: 20562.5359 - Avg Loss: 161.9097\n",
            "Epoch [16/50] - Batch loss: 164.1358 - Epoch Loss: 20726.6717 - Avg Loss: 161.9271\n",
            "Epoch [16/50] - Batch loss: 160.7798 - Epoch Loss: 20887.4515 - Avg Loss: 161.9182\n",
            "Epoch [16/50] - Batch loss: 166.6853 - Epoch Loss: 21054.1367 - Avg Loss: 161.9549\n",
            "Epoch [16/50] - Batch loss: 162.4989 - Epoch Loss: 21216.6356 - Avg Loss: 161.9591\n",
            "Epoch [16/50] - Batch loss: 163.7345 - Epoch Loss: 21380.3701 - Avg Loss: 161.9725\n",
            "Epoch [16/50] - Batch loss: 151.7149 - Epoch Loss: 21532.0850 - Avg Loss: 161.8954\n",
            "Epoch [16/50] - Batch loss: 161.2716 - Epoch Loss: 21693.3566 - Avg Loss: 161.8907\n",
            "Epoch [16/50] - Batch loss: 163.4633 - Epoch Loss: 21856.8199 - Avg Loss: 161.9024\n",
            "Epoch [16/50] - Batch loss: 162.7133 - Epoch Loss: 22019.5331 - Avg Loss: 161.9083\n",
            "Epoch [16/50] - Batch loss: 162.5347 - Epoch Loss: 22182.0678 - Avg Loss: 161.9129\n",
            "Epoch [16/50] - Batch loss: 155.9789 - Epoch Loss: 22338.0468 - Avg Loss: 161.8699\n",
            "Epoch [16/50] - Batch loss: 157.6135 - Epoch Loss: 22495.6602 - Avg Loss: 161.8393\n",
            "Epoch [16/50] - Batch loss: 169.0696 - Epoch Loss: 22664.7298 - Avg Loss: 161.8909\n",
            "Epoch [16/50] - Batch loss: 158.3622 - Epoch Loss: 22823.0920 - Avg Loss: 161.8659\n",
            "Epoch [16/50] - Batch loss: 165.4287 - Epoch Loss: 22988.5207 - Avg Loss: 161.8910\n",
            "Epoch [16/50] - Batch loss: 158.1573 - Epoch Loss: 23146.6780 - Avg Loss: 161.8649\n",
            "Epoch [16/50] - Batch loss: 164.3573 - Epoch Loss: 23311.0354 - Avg Loss: 161.8822\n",
            "Epoch [16/50] - Batch loss: 159.1681 - Epoch Loss: 23470.2035 - Avg Loss: 161.8635\n",
            "Epoch [16/50] - Batch loss: 166.8143 - Epoch Loss: 23637.0177 - Avg Loss: 161.8974\n",
            "Epoch [16/50] - Batch loss: 161.8697 - Epoch Loss: 23798.8874 - Avg Loss: 161.8972\n",
            "Epoch [16/50] - Batch loss: 169.2432 - Epoch Loss: 23968.1306 - Avg Loss: 161.9468\n",
            "Epoch [16/50] - Batch loss: 158.5927 - Epoch Loss: 24126.7233 - Avg Loss: 161.9243\n",
            "Epoch [16/50] - Batch loss: 159.2317 - Epoch Loss: 24285.9550 - Avg Loss: 161.9064\n",
            "Epoch [16/50] - Batch loss: 160.6311 - Epoch Loss: 24446.5862 - Avg Loss: 161.8979\n",
            "Epoch [16/50] - Batch loss: 161.2119 - Epoch Loss: 24607.7981 - Avg Loss: 161.8934\n",
            "Epoch [16/50] - Batch loss: 161.0934 - Epoch Loss: 24768.8916 - Avg Loss: 161.8882\n",
            "Epoch [16/50] - Batch loss: 155.7382 - Epoch Loss: 24924.6297 - Avg Loss: 161.8482\n",
            "Epoch [16/50] - Batch loss: 157.5945 - Epoch Loss: 25082.2243 - Avg Loss: 161.8208\n",
            "Epoch [16/50] - Batch loss: 162.8153 - Epoch Loss: 25245.0396 - Avg Loss: 161.8272\n",
            "Epoch [16/50] - Batch loss: 160.6542 - Epoch Loss: 25405.6937 - Avg Loss: 161.8197\n",
            "Epoch [16/50] - Batch loss: 150.3609 - Epoch Loss: 25556.0546 - Avg Loss: 161.7472\n",
            "Epoch [16/50] - Batch loss: 156.9737 - Epoch Loss: 25713.0283 - Avg Loss: 161.7172\n",
            "Epoch [16/50] - Batch loss: 162.0713 - Epoch Loss: 25875.0996 - Avg Loss: 161.7194\n",
            "Epoch [16/50] - Batch loss: 161.3212 - Epoch Loss: 26036.4208 - Avg Loss: 161.7169\n",
            "Epoch [16/50] - Batch loss: 163.4200 - Epoch Loss: 26199.8408 - Avg Loss: 161.7274\n",
            "Epoch [16/50] - Batch loss: 161.2337 - Epoch Loss: 26361.0745 - Avg Loss: 161.7244\n",
            "Epoch [16/50] - Batch loss: 162.3562 - Epoch Loss: 26523.4307 - Avg Loss: 161.7282\n",
            "Epoch [16/50] - Batch loss: 161.1019 - Epoch Loss: 26684.5326 - Avg Loss: 161.7244\n",
            "Epoch [16/50] - Batch loss: 158.0447 - Epoch Loss: 26842.5773 - Avg Loss: 161.7023\n",
            "Epoch [16/50] - Batch loss: 163.2163 - Epoch Loss: 27005.7935 - Avg Loss: 161.7113\n",
            "Epoch [16/50] - Batch loss: 160.3179 - Epoch Loss: 27166.1115 - Avg Loss: 161.7030\n",
            "Epoch [16/50] - Batch loss: 159.2120 - Epoch Loss: 27325.3235 - Avg Loss: 161.6883\n",
            "Epoch [16/50] - Batch loss: 163.8465 - Epoch Loss: 27489.1700 - Avg Loss: 161.7010\n",
            "Epoch [16/50] - Batch loss: 157.0346 - Epoch Loss: 27646.2046 - Avg Loss: 161.6737\n",
            "Epoch [16/50] - Batch loss: 158.3194 - Epoch Loss: 27804.5240 - Avg Loss: 161.6542\n",
            "Epoch [16/50] - Batch loss: 163.5341 - Epoch Loss: 27968.0581 - Avg Loss: 161.6651\n",
            "Epoch [16/50] - Batch loss: 166.5063 - Epoch Loss: 28134.5644 - Avg Loss: 161.6929\n",
            "Epoch [16/50] - Batch loss: 157.0116 - Epoch Loss: 28291.5760 - Avg Loss: 161.6661\n",
            "Epoch [16/50] - Batch loss: 161.5590 - Epoch Loss: 28453.1350 - Avg Loss: 161.6655\n",
            "Epoch [16/50] - Batch loss: 160.9601 - Epoch Loss: 28614.0951 - Avg Loss: 161.6616\n",
            "Epoch [16/50] - Batch loss: 167.2950 - Epoch Loss: 28781.3901 - Avg Loss: 161.6932\n",
            "Epoch [16/50] - Batch loss: 166.1550 - Epoch Loss: 28947.5452 - Avg Loss: 161.7181\n",
            "Epoch [16/50] - Batch loss: 171.3424 - Epoch Loss: 29118.8876 - Avg Loss: 161.7716\n",
            "Epoch [16/50] - Batch loss: 158.8624 - Epoch Loss: 29277.7500 - Avg Loss: 161.7555\n",
            "Epoch [16/50] - Batch loss: 155.2783 - Epoch Loss: 29433.0282 - Avg Loss: 161.7199\n",
            "Epoch [16/50] - Batch loss: 168.1578 - Epoch Loss: 29601.1860 - Avg Loss: 161.7551\n",
            "Epoch [16/50] - Batch loss: 155.0984 - Epoch Loss: 29756.2844 - Avg Loss: 161.7189\n",
            "Epoch [16/50] - Batch loss: 166.4445 - Epoch Loss: 29922.7289 - Avg Loss: 161.7445\n",
            "Epoch [16/50] - Batch loss: 164.5302 - Epoch Loss: 30087.2591 - Avg Loss: 161.7595\n",
            "Epoch [16/50] - Batch loss: 161.5339 - Epoch Loss: 30248.7930 - Avg Loss: 161.7583\n",
            "Epoch [16/50] - Batch loss: 158.4706 - Epoch Loss: 30407.2636 - Avg Loss: 161.7408\n",
            "Epoch [16/50] - Batch loss: 165.0778 - Epoch Loss: 30572.3414 - Avg Loss: 161.7584\n",
            "Epoch [16/50] - Batch loss: 166.6390 - Epoch Loss: 30738.9805 - Avg Loss: 161.7841\n",
            "Epoch [16/50] - Batch loss: 163.3335 - Epoch Loss: 30902.3140 - Avg Loss: 161.7922\n",
            "Epoch [16/50] - Batch loss: 164.9007 - Epoch Loss: 31067.2146 - Avg Loss: 161.8084\n",
            "Epoch [16/50] - Batch loss: 160.1585 - Epoch Loss: 31227.3732 - Avg Loss: 161.7999\n",
            "Epoch [16/50] - Batch loss: 162.1139 - Epoch Loss: 31389.4870 - Avg Loss: 161.8015\n",
            "Epoch [16/50] - Batch loss: 157.0905 - Epoch Loss: 31546.5775 - Avg Loss: 161.7773\n",
            "Epoch [16/50] - Batch loss: 167.0903 - Epoch Loss: 31713.6678 - Avg Loss: 161.8044\n",
            "Epoch [16/50] - Batch loss: 162.0469 - Epoch Loss: 31875.7147 - Avg Loss: 161.8057\n",
            "Epoch [16/50] - Batch loss: 163.8522 - Epoch Loss: 32039.5670 - Avg Loss: 161.8160\n",
            "Epoch [16/50] - Batch loss: 162.7541 - Epoch Loss: 32202.3211 - Avg Loss: 161.8207\n",
            "Epoch [16/50] - Batch loss: 163.7245 - Epoch Loss: 32366.0456 - Avg Loss: 161.8302\n",
            "Epoch [16/50] - Batch loss: 161.4316 - Epoch Loss: 32527.4772 - Avg Loss: 161.8282\n",
            "Epoch [16/50] - Batch loss: 165.7732 - Epoch Loss: 32693.2504 - Avg Loss: 161.8478\n",
            "Epoch [16/50] - Batch loss: 161.9322 - Epoch Loss: 32855.1826 - Avg Loss: 161.8482\n",
            "Epoch [16/50] - Batch loss: 165.9233 - Epoch Loss: 33021.1059 - Avg Loss: 161.8682\n",
            "Epoch [16/50] - Batch loss: 162.5691 - Epoch Loss: 33183.6750 - Avg Loss: 161.8716\n",
            "Epoch [16/50] - Batch loss: 161.9361 - Epoch Loss: 33345.6112 - Avg Loss: 161.8719\n",
            "Epoch [16/50] - Batch loss: 168.2419 - Epoch Loss: 33513.8530 - Avg Loss: 161.9027\n",
            "Epoch [16/50] - Batch loss: 166.7635 - Epoch Loss: 33680.6166 - Avg Loss: 161.9260\n",
            "Epoch [16/50] - Batch loss: 165.8641 - Epoch Loss: 33846.4807 - Avg Loss: 161.9449\n",
            "Epoch [16/50] - Batch loss: 148.1658 - Epoch Loss: 33994.6465 - Avg Loss: 161.8793\n",
            "Epoch [16/50] - Batch loss: 157.4550 - Epoch Loss: 34152.1015 - Avg Loss: 161.8583\n",
            "Epoch [16/50] - Batch loss: 161.8090 - Epoch Loss: 34313.9105 - Avg Loss: 161.8581\n",
            "Epoch [16/50] - Batch loss: 162.4980 - Epoch Loss: 34476.4085 - Avg Loss: 161.8611\n",
            "Epoch [16/50] - Batch loss: 166.5214 - Epoch Loss: 34642.9299 - Avg Loss: 161.8828\n",
            "Epoch [16/50] - Batch loss: 155.3737 - Epoch Loss: 34798.3036 - Avg Loss: 161.8526\n",
            "Epoch [16/50] - Batch loss: 165.7175 - Epoch Loss: 34964.0211 - Avg Loss: 161.8705\n",
            "Epoch [16/50] - Batch loss: 159.9634 - Epoch Loss: 35123.9845 - Avg Loss: 161.8617\n",
            "Epoch [16/50] - Batch loss: 167.9708 - Epoch Loss: 35291.9554 - Avg Loss: 161.8897\n",
            "Epoch [16/50] - Batch loss: 161.6934 - Epoch Loss: 35453.6487 - Avg Loss: 161.8888\n",
            "Epoch [16/50] - Batch loss: 171.6084 - Epoch Loss: 35625.2571 - Avg Loss: 161.9330\n",
            "Epoch [16/50] - Batch loss: 162.6260 - Epoch Loss: 35787.8831 - Avg Loss: 161.9361\n",
            "Epoch [16/50] - Batch loss: 161.5092 - Epoch Loss: 35949.3923 - Avg Loss: 161.9342\n",
            "Epoch [16/50] - Batch loss: 150.8877 - Epoch Loss: 36100.2801 - Avg Loss: 161.8847\n",
            "Epoch [16/50] - Batch loss: 159.7428 - Epoch Loss: 36260.0229 - Avg Loss: 161.8751\n",
            "Epoch [16/50] - Batch loss: 158.6685 - Epoch Loss: 36418.6913 - Avg Loss: 161.8609\n",
            "Epoch [16/50] - Batch loss: 160.7680 - Epoch Loss: 36579.4594 - Avg Loss: 161.8560\n",
            "Epoch [16/50] - Batch loss: 161.2106 - Epoch Loss: 36740.6699 - Avg Loss: 161.8532\n",
            "Epoch [16/50] - Batch loss: 155.1157 - Epoch Loss: 36895.7856 - Avg Loss: 161.8236\n",
            "Epoch [16/50] - Batch loss: 165.7799 - Epoch Loss: 37061.5654 - Avg Loss: 161.8409\n",
            "Epoch [16/50] - Batch loss: 156.1442 - Epoch Loss: 37217.7096 - Avg Loss: 161.8161\n",
            "Epoch [16/50] - Batch loss: 162.9063 - Epoch Loss: 37380.6159 - Avg Loss: 161.8208\n",
            "Epoch [16/50] - Batch loss: 161.3323 - Epoch Loss: 37541.9482 - Avg Loss: 161.8187\n",
            "Epoch [16/50] - Batch loss: 160.6787 - Epoch Loss: 37702.6269 - Avg Loss: 161.8138\n",
            "Epoch [16/50] - Batch loss: 157.3549 - Epoch Loss: 37859.9819 - Avg Loss: 161.7948\n",
            "Epoch [16/50] - Batch loss: 160.2844 - Epoch Loss: 38020.2663 - Avg Loss: 161.7884\n",
            "Epoch [16/50] - Batch loss: 164.7901 - Epoch Loss: 38185.0563 - Avg Loss: 161.8011\n",
            "Epoch [16/50] - Batch loss: 159.8687 - Epoch Loss: 38344.9250 - Avg Loss: 161.7929\n",
            "Epoch [16/50] - Batch loss: 163.7916 - Epoch Loss: 38508.7167 - Avg Loss: 161.8013\n",
            "Epoch [16/50] - Batch loss: 158.8158 - Epoch Loss: 38667.5325 - Avg Loss: 161.7888\n",
            "Epoch [16/50] - Batch loss: 165.0341 - Epoch Loss: 38832.5666 - Avg Loss: 161.8024\n",
            "Epoch [16/50] - Batch loss: 169.8884 - Epoch Loss: 39002.4550 - Avg Loss: 161.8359\n",
            "Epoch [16/50] - Batch loss: 164.3689 - Epoch Loss: 39166.8238 - Avg Loss: 161.8464\n",
            "Epoch [16/50] - Batch loss: 161.7372 - Epoch Loss: 39328.5611 - Avg Loss: 161.8459\n",
            "Epoch [16/50] - Batch loss: 160.0967 - Epoch Loss: 39488.6578 - Avg Loss: 161.8388\n",
            "Epoch [16/50] - Batch loss: 162.5453 - Epoch Loss: 39651.2031 - Avg Loss: 161.8416\n",
            "Epoch [16/50] - Batch loss: 159.5162 - Epoch Loss: 39810.7193 - Avg Loss: 161.8322\n",
            "Epoch [16/50] - Batch loss: 159.3317 - Epoch Loss: 39970.0510 - Avg Loss: 161.8221\n",
            "Epoch [16/50] - Batch loss: 155.7210 - Epoch Loss: 40125.7719 - Avg Loss: 161.7975\n",
            "Epoch [16/50] - Batch loss: 152.2628 - Epoch Loss: 40278.0348 - Avg Loss: 161.7592\n",
            "Epoch [16/50] - Batch loss: 162.1500 - Epoch Loss: 40440.1847 - Avg Loss: 161.7607\n",
            "Epoch [16/50] - Batch loss: 166.8062 - Epoch Loss: 40606.9910 - Avg Loss: 161.7808\n",
            "Epoch [16/50] - Batch loss: 163.3614 - Epoch Loss: 40770.3523 - Avg Loss: 161.7871\n",
            "Epoch [16/50] - Batch loss: 162.6156 - Epoch Loss: 40932.9680 - Avg Loss: 161.7904\n",
            "Epoch [16/50] - Batch loss: 162.0319 - Epoch Loss: 41094.9999 - Avg Loss: 161.7913\n",
            "Epoch [16/50] - Batch loss: 164.5499 - Epoch Loss: 41259.5498 - Avg Loss: 161.8022\n",
            "Epoch [16/50] - Batch loss: 161.7271 - Epoch Loss: 41421.2769 - Avg Loss: 161.8019\n",
            "Epoch [16/50] - Batch loss: 157.1072 - Epoch Loss: 41578.3841 - Avg Loss: 161.7836\n",
            "Epoch [16/50] - Batch loss: 158.2130 - Epoch Loss: 41736.5971 - Avg Loss: 161.7698\n",
            "Epoch [16/50] - Batch loss: 150.6086 - Epoch Loss: 41887.2057 - Avg Loss: 161.7267\n",
            "Epoch [16/50] - Batch loss: 161.3746 - Epoch Loss: 42048.5803 - Avg Loss: 161.7253\n",
            "Epoch [16/50] - Batch loss: 154.9626 - Epoch Loss: 42203.5428 - Avg Loss: 161.6994\n",
            "Epoch [16/50] - Batch loss: 168.7903 - Epoch Loss: 42372.3331 - Avg Loss: 161.7265\n",
            "Epoch [16/50] - Batch loss: 156.3198 - Epoch Loss: 42528.6529 - Avg Loss: 161.7059\n",
            "Epoch [16/50] - Batch loss: 160.3712 - Epoch Loss: 42689.0241 - Avg Loss: 161.7008\n",
            "Epoch [16/50] - Batch loss: 163.9705 - Epoch Loss: 42852.9946 - Avg Loss: 161.7094\n",
            "Epoch [16/50] - Batch loss: 167.9395 - Epoch Loss: 43020.9341 - Avg Loss: 161.7328\n",
            "Epoch [16/50] - Batch loss: 161.8864 - Epoch Loss: 43182.8205 - Avg Loss: 161.7334\n",
            "Epoch [16/50] - Batch loss: 157.3918 - Epoch Loss: 43340.2124 - Avg Loss: 161.7172\n",
            "Epoch [16/50] - Batch loss: 165.6070 - Epoch Loss: 43505.8194 - Avg Loss: 161.7317\n",
            "Epoch [16/50] - Batch loss: 163.2167 - Epoch Loss: 43669.0361 - Avg Loss: 161.7372\n",
            "Epoch [16/50] - Batch loss: 160.5704 - Epoch Loss: 43829.6065 - Avg Loss: 161.7329\n",
            "Epoch [16/50] - Batch loss: 168.0232 - Epoch Loss: 43997.6297 - Avg Loss: 161.7560\n",
            "Epoch [16/50] - Batch loss: 165.9348 - Epoch Loss: 44163.5645 - Avg Loss: 161.7713\n",
            "Epoch [16/50] - Batch loss: 161.4403 - Epoch Loss: 44325.0048 - Avg Loss: 161.7701\n",
            "Epoch [16/50] - Batch loss: 166.7776 - Epoch Loss: 44491.7824 - Avg Loss: 161.7883\n",
            "Epoch [16/50] - Batch loss: 168.3052 - Epoch Loss: 44660.0876 - Avg Loss: 161.8119\n",
            "Epoch [16/50] - Batch loss: 161.1891 - Epoch Loss: 44821.2766 - Avg Loss: 161.8097\n",
            "Epoch [16/50] - Batch loss: 155.1855 - Epoch Loss: 44976.4621 - Avg Loss: 161.7858\n",
            "Epoch [16/50] - Batch loss: 164.9577 - Epoch Loss: 45141.4199 - Avg Loss: 161.7972\n",
            "Epoch [16/50] - Batch loss: 158.7142 - Epoch Loss: 45300.1341 - Avg Loss: 161.7862\n",
            "Epoch [16/50] - Batch loss: 154.8635 - Epoch Loss: 45454.9975 - Avg Loss: 161.7616\n",
            "Epoch [16/50] - Batch loss: 153.8230 - Epoch Loss: 45608.8206 - Avg Loss: 161.7334\n",
            "Epoch [16/50] - Batch loss: 164.2692 - Epoch Loss: 45773.0898 - Avg Loss: 161.7424\n",
            "Epoch [16/50] - Batch loss: 163.1913 - Epoch Loss: 45936.2811 - Avg Loss: 161.7475\n",
            "Epoch [16/50] - Batch loss: 166.0732 - Epoch Loss: 46102.3543 - Avg Loss: 161.7626\n",
            "Epoch [16/50] - Batch loss: 162.7870 - Epoch Loss: 46265.1412 - Avg Loss: 161.7662\n",
            "Epoch [16/50] - Batch loss: 154.8506 - Epoch Loss: 46419.9918 - Avg Loss: 161.7421\n",
            "Epoch [16/50] - Batch loss: 161.7875 - Epoch Loss: 46581.7793 - Avg Loss: 161.7423\n",
            "Epoch [16/50] - Batch loss: 161.1551 - Epoch Loss: 46742.9343 - Avg Loss: 161.7403\n",
            "Epoch [16/50] - Batch loss: 161.1695 - Epoch Loss: 46904.1039 - Avg Loss: 161.7383\n",
            "Epoch [16/50] - Batch loss: 158.4100 - Epoch Loss: 47062.5139 - Avg Loss: 161.7269\n",
            "Epoch [16/50] - Batch loss: 157.9246 - Epoch Loss: 47220.4384 - Avg Loss: 161.7138\n",
            "Epoch [16/50] - Batch loss: 161.1944 - Epoch Loss: 47381.6328 - Avg Loss: 161.7121\n",
            "Epoch [16/50] - Batch loss: 161.3623 - Epoch Loss: 47542.9951 - Avg Loss: 161.7109\n",
            "Epoch [16/50] - Batch loss: 155.5211 - Epoch Loss: 47698.5162 - Avg Loss: 161.6899\n",
            "Epoch [16/50] - Batch loss: 153.4416 - Epoch Loss: 47851.9577 - Avg Loss: 161.6620\n",
            "Epoch [16/50] - Batch loss: 165.4757 - Epoch Loss: 48017.4334 - Avg Loss: 161.6749\n",
            "Epoch [16/50] - Batch loss: 163.3213 - Epoch Loss: 48180.7547 - Avg Loss: 161.6804\n",
            "Epoch [16/50] - Batch loss: 162.6485 - Epoch Loss: 48343.4032 - Avg Loss: 161.6836\n",
            "Epoch [16/50] - Batch loss: 157.7515 - Epoch Loss: 48501.1547 - Avg Loss: 161.6705\n",
            "Epoch [16/50] - Batch loss: 156.7361 - Epoch Loss: 48657.8909 - Avg Loss: 161.6541\n",
            "Epoch [16/50] - Batch loss: 158.7345 - Epoch Loss: 48816.6254 - Avg Loss: 161.6445\n",
            "Epoch [16/50] - Batch loss: 168.9793 - Epoch Loss: 48985.6047 - Avg Loss: 161.6687\n",
            "Epoch [16/50] - Batch loss: 164.8095 - Epoch Loss: 49150.4142 - Avg Loss: 161.6790\n",
            "Epoch [16/50] - Batch loss: 161.8559 - Epoch Loss: 49312.2701 - Avg Loss: 161.6796\n",
            "Epoch [16/50] - Batch loss: 156.9571 - Epoch Loss: 49469.2271 - Avg Loss: 161.6641\n",
            "Epoch [16/50] - Batch loss: 173.2276 - Epoch Loss: 49642.4547 - Avg Loss: 161.7018\n",
            "Epoch [16/50] - Batch loss: 156.1617 - Epoch Loss: 49798.6164 - Avg Loss: 161.6838\n",
            "Epoch [16/50] - Batch loss: 163.1956 - Epoch Loss: 49961.8120 - Avg Loss: 161.6887\n",
            "Epoch [16/50] - Batch loss: 164.2105 - Epoch Loss: 50126.0225 - Avg Loss: 161.6968\n",
            "Epoch [16/50] - Batch loss: 159.3915 - Epoch Loss: 50285.4140 - Avg Loss: 161.6894\n",
            "Epoch [16/50] - Batch loss: 162.0644 - Epoch Loss: 50447.4784 - Avg Loss: 161.6906\n",
            "Epoch [16/50] - Batch loss: 162.2070 - Epoch Loss: 50609.6854 - Avg Loss: 161.6923\n",
            "Epoch [16/50] - Batch loss: 165.1783 - Epoch Loss: 50774.8637 - Avg Loss: 161.7034\n",
            "Epoch [16/50] - Batch loss: 160.2313 - Epoch Loss: 50935.0950 - Avg Loss: 161.6987\n",
            "Epoch [16/50] - Batch loss: 159.5668 - Epoch Loss: 51094.6618 - Avg Loss: 161.6920\n",
            "Epoch [16/50] - Batch loss: 157.5974 - Epoch Loss: 51252.2592 - Avg Loss: 161.6791\n",
            "Epoch [16/50] - Batch loss: 151.3942 - Epoch Loss: 51403.6534 - Avg Loss: 161.6467\n",
            "Epoch [16/50] - Batch loss: 158.2450 - Epoch Loss: 51561.8984 - Avg Loss: 161.6360\n",
            "Epoch [16/50] - Batch loss: 163.9111 - Epoch Loss: 51725.8095 - Avg Loss: 161.6432\n",
            "Epoch [16/50] - Batch loss: 167.4536 - Epoch Loss: 51893.2631 - Avg Loss: 161.6613\n",
            "Epoch [16/50] - Batch loss: 161.9935 - Epoch Loss: 52055.2566 - Avg Loss: 161.6623\n",
            "Epoch [16/50] - Batch loss: 158.5188 - Epoch Loss: 52213.7754 - Avg Loss: 161.6526\n",
            "Epoch [16/50] - Batch loss: 152.8132 - Epoch Loss: 52366.5885 - Avg Loss: 161.6253\n",
            "Epoch [16/50] - Batch loss: 163.3774 - Epoch Loss: 52529.9659 - Avg Loss: 161.6307\n",
            "Epoch [16/50] - Batch loss: 158.3589 - Epoch Loss: 52688.3248 - Avg Loss: 161.6206\n",
            "Epoch [16/50] - Batch loss: 161.3304 - Epoch Loss: 52849.6552 - Avg Loss: 161.6197\n",
            "Epoch [16/50] - Batch loss: 166.8683 - Epoch Loss: 53016.5235 - Avg Loss: 161.6357\n",
            "Epoch [16/50] - Batch loss: 169.5203 - Epoch Loss: 53186.0438 - Avg Loss: 161.6597\n",
            "Epoch [16/50] - Batch loss: 161.4778 - Epoch Loss: 53347.5215 - Avg Loss: 161.6592\n",
            "Epoch [16/50] - Batch loss: 155.6784 - Epoch Loss: 53503.2000 - Avg Loss: 161.6411\n",
            "Epoch [16/50] - Batch loss: 161.8350 - Epoch Loss: 53665.0349 - Avg Loss: 161.6417\n",
            "Epoch [16/50] - Batch loss: 158.3805 - Epoch Loss: 53823.4155 - Avg Loss: 161.6319\n",
            "Epoch [16/50] - Batch loss: 162.1382 - Epoch Loss: 53985.5537 - Avg Loss: 161.6334\n",
            "Epoch [16/50] - Batch loss: 159.7928 - Epoch Loss: 54145.3465 - Avg Loss: 161.6279\n",
            "Epoch [16/50] - Batch loss: 163.3780 - Epoch Loss: 54308.7245 - Avg Loss: 161.6331\n",
            "Epoch [16/50] - Batch loss: 161.2785 - Epoch Loss: 54470.0030 - Avg Loss: 161.6321\n",
            "Epoch [16/50] - Batch loss: 164.4234 - Epoch Loss: 54634.4264 - Avg Loss: 161.6403\n",
            "Epoch [16/50] - Batch loss: 158.0220 - Epoch Loss: 54792.4484 - Avg Loss: 161.6296\n",
            "Epoch [16/50] - Batch loss: 171.5352 - Epoch Loss: 54963.9837 - Avg Loss: 161.6588\n",
            "Epoch [16/50] - Batch loss: 160.6088 - Epoch Loss: 55124.5925 - Avg Loss: 161.6557\n",
            "Epoch [16/50] - Batch loss: 151.7724 - Epoch Loss: 55276.3649 - Avg Loss: 161.6268\n",
            "Epoch [16/50] - Batch loss: 163.9340 - Epoch Loss: 55440.2989 - Avg Loss: 161.6335\n",
            "Epoch [16/50] - Batch loss: 155.5091 - Epoch Loss: 55595.8080 - Avg Loss: 161.6157\n",
            "Epoch [16/50] - Batch loss: 160.2155 - Epoch Loss: 55756.0235 - Avg Loss: 161.6117\n",
            "Epoch [16/50] - Batch loss: 157.6977 - Epoch Loss: 55913.7212 - Avg Loss: 161.6004\n",
            "Epoch [16/50] - Batch loss: 159.8992 - Epoch Loss: 56073.6204 - Avg Loss: 161.5954\n",
            "Epoch [16/50] - Batch loss: 164.2492 - Epoch Loss: 56237.8696 - Avg Loss: 161.6031\n",
            "Epoch [16/50] - Batch loss: 161.1575 - Epoch Loss: 56399.0271 - Avg Loss: 161.6018\n",
            "Epoch [16/50] - Batch loss: 152.9879 - Epoch Loss: 56552.0150 - Avg Loss: 161.5772\n",
            "Epoch [16/50] - Batch loss: 161.2008 - Epoch Loss: 56713.2158 - Avg Loss: 161.5761\n",
            "Epoch [16/50] - Batch loss: 168.8007 - Epoch Loss: 56882.0165 - Avg Loss: 161.5966\n",
            "Epoch [16/50] - Batch loss: 153.4158 - Epoch Loss: 57035.4323 - Avg Loss: 161.5735\n",
            "Epoch [16/50] - Batch loss: 154.0098 - Epoch Loss: 57189.4420 - Avg Loss: 161.5521\n",
            "Epoch [16/50] - Batch loss: 161.5118 - Epoch Loss: 57350.9539 - Avg Loss: 161.5520\n",
            "Epoch [16/50] - Batch loss: 161.4916 - Epoch Loss: 57512.4455 - Avg Loss: 161.5518\n",
            "Epoch [16/50] - Batch loss: 164.7316 - Epoch Loss: 57677.1771 - Avg Loss: 161.5607\n",
            "Epoch [16/50] - Batch loss: 156.5844 - Epoch Loss: 57833.7615 - Avg Loss: 161.5468\n",
            "Epoch [16/50] - Batch loss: 160.7721 - Epoch Loss: 57994.5336 - Avg Loss: 161.5447\n",
            "Epoch [16/50] - Batch loss: 169.3459 - Epoch Loss: 58163.8794 - Avg Loss: 161.5663\n",
            "Epoch [16/50] - Batch loss: 165.7449 - Epoch Loss: 58329.6244 - Avg Loss: 161.5779\n",
            "Epoch [16/50] - Batch loss: 155.8734 - Epoch Loss: 58485.4978 - Avg Loss: 161.5621\n",
            "Epoch [16/50] - Batch loss: 151.5224 - Epoch Loss: 58637.0202 - Avg Loss: 161.5345\n",
            "Epoch [16/50] - Batch loss: 166.5569 - Epoch Loss: 58803.5771 - Avg Loss: 161.5483\n",
            "Epoch [16/50] - Batch loss: 156.9635 - Epoch Loss: 58960.5406 - Avg Loss: 161.5357\n",
            "Epoch [16/50] - Batch loss: 158.7004 - Epoch Loss: 59119.2409 - Avg Loss: 161.5280\n",
            "Epoch [16/50] - Batch loss: 161.9868 - Epoch Loss: 59281.2277 - Avg Loss: 161.5292\n",
            "Epoch [16/50] - Batch loss: 153.7171 - Epoch Loss: 59434.9449 - Avg Loss: 161.5080\n",
            "Epoch [16/50] - Batch loss: 160.0294 - Epoch Loss: 59594.9743 - Avg Loss: 161.5040\n",
            "Epoch [16/50] - Batch loss: 157.6086 - Epoch Loss: 59752.5829 - Avg Loss: 161.4935\n",
            "Epoch [16/50] - Batch loss: 156.2548 - Epoch Loss: 59908.8377 - Avg Loss: 161.4793\n",
            "Epoch [16/50] - Batch loss: 155.8101 - Epoch Loss: 60064.6477 - Avg Loss: 161.4641\n",
            "Epoch [16/50] - Batch loss: 161.9369 - Epoch Loss: 60226.5846 - Avg Loss: 161.4654\n",
            "Epoch [16/50] - Batch loss: 162.7666 - Epoch Loss: 60389.3512 - Avg Loss: 161.4689\n",
            "Epoch [16/50] - Batch loss: 157.3398 - Epoch Loss: 60546.6910 - Avg Loss: 161.4578\n",
            "Epoch [16/50] - Batch loss: 160.7308 - Epoch Loss: 60707.4219 - Avg Loss: 161.4559\n",
            "Epoch [16/50] - Batch loss: 161.9744 - Epoch Loss: 60869.3963 - Avg Loss: 161.4573\n",
            "Epoch [16/50] - Batch loss: 152.1787 - Epoch Loss: 61021.5750 - Avg Loss: 161.4327\n",
            "Epoch [16/50] - Batch loss: 159.9990 - Epoch Loss: 61181.5740 - Avg Loss: 161.4290\n",
            "Epoch [16/50] - Batch loss: 155.3842 - Epoch Loss: 61336.9582 - Avg Loss: 161.4130\n",
            "Epoch [16/50] - Batch loss: 151.9467 - Epoch Loss: 61488.9050 - Avg Loss: 161.3882\n",
            "Epoch [16/50] - Batch loss: 157.9339 - Epoch Loss: 61646.8388 - Avg Loss: 161.3792\n",
            "Epoch [16/50] - Batch loss: 154.9538 - Epoch Loss: 61801.7927 - Avg Loss: 161.3624\n",
            "Epoch [16/50] - Batch loss: 159.9034 - Epoch Loss: 61961.6960 - Avg Loss: 161.3586\n",
            "Epoch [16/50] - Batch loss: 170.0869 - Epoch Loss: 62131.7829 - Avg Loss: 161.3813\n",
            "Epoch [16/50] - Batch loss: 161.2430 - Epoch Loss: 62293.0259 - Avg Loss: 161.3809\n",
            "Epoch [16/50] - Batch loss: 160.8963 - Epoch Loss: 62453.9223 - Avg Loss: 161.3796\n",
            "Epoch [16/50] - Batch loss: 151.0344 - Epoch Loss: 62604.9567 - Avg Loss: 161.3530\n",
            "Epoch [16/50] - Batch loss: 157.9470 - Epoch Loss: 62762.9037 - Avg Loss: 161.3442\n",
            "Epoch [16/50] - Batch loss: 153.0174 - Epoch Loss: 62915.9211 - Avg Loss: 161.3229\n",
            "Epoch [16/50] - Batch loss: 151.1205 - Epoch Loss: 63067.0416 - Avg Loss: 161.2968\n",
            "Epoch [16/50] - Batch loss: 158.9886 - Epoch Loss: 63226.0302 - Avg Loss: 161.2909\n",
            "Epoch [16/50] - Batch loss: 151.0933 - Epoch Loss: 63377.1234 - Avg Loss: 161.2649\n",
            "Epoch [16/50] - Batch loss: 165.5997 - Epoch Loss: 63542.7231 - Avg Loss: 161.2759\n",
            "Epoch [16/50] - Batch loss: 164.9727 - Epoch Loss: 63707.6958 - Avg Loss: 161.2853\n",
            "Epoch [16/50] - Batch loss: 153.2503 - Epoch Loss: 63860.9461 - Avg Loss: 161.2650\n",
            "Epoch [16/50] - Batch loss: 160.0788 - Epoch Loss: 64021.0249 - Avg Loss: 161.2620\n",
            "Epoch [16/50] - Batch loss: 163.5858 - Epoch Loss: 64184.6107 - Avg Loss: 161.2679\n",
            "Epoch [16/50] - Batch loss: 156.9617 - Epoch Loss: 64341.5724 - Avg Loss: 161.2571\n",
            "Epoch [16/50] - Batch loss: 157.8446 - Epoch Loss: 64499.4170 - Avg Loss: 161.2485\n",
            "Epoch [16/50] - Batch loss: 158.5251 - Epoch Loss: 64657.9421 - Avg Loss: 161.2418\n",
            "Epoch [16/50] - Batch loss: 156.6116 - Epoch Loss: 64814.5537 - Avg Loss: 161.2302\n",
            "Epoch [16/50] - Batch loss: 169.1380 - Epoch Loss: 64983.6917 - Avg Loss: 161.2499\n",
            "Epoch [16/50] - Batch loss: 157.6387 - Epoch Loss: 65141.3303 - Avg Loss: 161.2409\n",
            "Epoch [16/50] - Batch loss: 163.2074 - Epoch Loss: 65304.5378 - Avg Loss: 161.2458\n",
            "Epoch [16/50] - Batch loss: 166.3627 - Epoch Loss: 65470.9005 - Avg Loss: 161.2584\n",
            "Epoch [16/50] - Batch loss: 159.6093 - Epoch Loss: 65630.5098 - Avg Loss: 161.2543\n",
            "Epoch [16/50] - Batch loss: 156.3551 - Epoch Loss: 65786.8649 - Avg Loss: 161.2423\n",
            "Epoch [16/50] - Batch loss: 164.0148 - Epoch Loss: 65950.8797 - Avg Loss: 161.2491\n",
            "Epoch [16/50] - Batch loss: 159.9389 - Epoch Loss: 66110.8186 - Avg Loss: 161.2459\n",
            "Epoch [16/50] - Batch loss: 160.0750 - Epoch Loss: 66270.8936 - Avg Loss: 161.2431\n",
            "Epoch [16/50] - Batch loss: 162.0656 - Epoch Loss: 66432.9592 - Avg Loss: 161.2450\n",
            "Epoch [16/50] - Batch loss: 165.2233 - Epoch Loss: 66598.1826 - Avg Loss: 161.2547\n",
            "Epoch [16/50] - Batch loss: 158.0256 - Epoch Loss: 66756.2082 - Avg Loss: 161.2469\n",
            "Epoch [16/50] - Batch loss: 165.5408 - Epoch Loss: 66921.7489 - Avg Loss: 161.2572\n",
            "Epoch [16/50] - Batch loss: 166.6661 - Epoch Loss: 67088.4150 - Avg Loss: 161.2702\n",
            "Epoch [16/50] - Batch loss: 154.3529 - Epoch Loss: 67242.7679 - Avg Loss: 161.2536\n",
            "Epoch [16/50] - Batch loss: 161.5403 - Epoch Loss: 67404.3081 - Avg Loss: 161.2543\n",
            "Epoch [16/50] - Batch loss: 156.7997 - Epoch Loss: 67561.1078 - Avg Loss: 161.2437\n",
            "Epoch [16/50] - Batch loss: 156.6582 - Epoch Loss: 67717.7660 - Avg Loss: 161.2328\n",
            "Epoch [16/50] - Batch loss: 165.0297 - Epoch Loss: 67882.7957 - Avg Loss: 161.2418\n",
            "Epoch [16/50] - Batch loss: 153.3987 - Epoch Loss: 68036.1944 - Avg Loss: 161.2232\n",
            "Epoch [16/50] - Batch loss: 157.7312 - Epoch Loss: 68193.9256 - Avg Loss: 161.2150\n",
            "Epoch [16/50] - Batch loss: 162.8587 - Epoch Loss: 68356.7843 - Avg Loss: 161.2188\n",
            "Epoch [16/50] - Batch loss: 161.5239 - Epoch Loss: 68518.3082 - Avg Loss: 161.2195\n",
            "Epoch [16/50] - Batch loss: 159.4845 - Epoch Loss: 68677.7927 - Avg Loss: 161.2155\n",
            "Epoch [16/50] - Batch loss: 156.3306 - Epoch Loss: 68834.1234 - Avg Loss: 161.2040\n",
            "Epoch [16/50] - Batch loss: 155.9537 - Epoch Loss: 68990.0771 - Avg Loss: 161.1918\n",
            "Epoch [16/50] - Batch loss: 152.4109 - Epoch Loss: 69142.4880 - Avg Loss: 161.1713\n",
            "Epoch [16/50] - Batch loss: 165.0416 - Epoch Loss: 69307.5296 - Avg Loss: 161.1803\n",
            "Epoch [16/50] - Batch loss: 165.0930 - Epoch Loss: 69472.6226 - Avg Loss: 161.1894\n",
            "Epoch [16/50] - Batch loss: 148.8632 - Epoch Loss: 69621.4858 - Avg Loss: 161.1608\n",
            "Epoch [16/50] - Batch loss: 166.8799 - Epoch Loss: 69788.3657 - Avg Loss: 161.1741\n",
            "Epoch [16/50] - Batch loss: 156.4549 - Epoch Loss: 69944.8206 - Avg Loss: 161.1632\n",
            "Epoch [16/50] - Batch loss: 162.9151 - Epoch Loss: 70107.7357 - Avg Loss: 161.1672\n",
            "Epoch [16/50] - Batch loss: 163.1065 - Epoch Loss: 70270.8422 - Avg Loss: 161.1717\n",
            "Epoch [16/50] - Batch loss: 165.9245 - Epoch Loss: 70436.7668 - Avg Loss: 161.1825\n",
            "Epoch [16/50] - Batch loss: 157.2035 - Epoch Loss: 70593.9703 - Avg Loss: 161.1734\n",
            "Epoch [16/50] - Batch loss: 163.2426 - Epoch Loss: 70757.2129 - Avg Loss: 161.1782\n",
            "Epoch [16/50] - Batch loss: 163.4092 - Epoch Loss: 70920.6221 - Avg Loss: 161.1832\n",
            "Epoch [16/50] - Batch loss: 168.4871 - Epoch Loss: 71089.1092 - Avg Loss: 161.1998\n",
            "Epoch [16/50] - Batch loss: 159.8674 - Epoch Loss: 71248.9766 - Avg Loss: 161.1968\n",
            "Epoch [16/50] - Batch loss: 159.7789 - Epoch Loss: 71408.7555 - Avg Loss: 161.1936\n",
            "Epoch [16/50] - Batch loss: 158.4984 - Epoch Loss: 71567.2539 - Avg Loss: 161.1875\n",
            "Epoch [16/50] - Batch loss: 165.8093 - Epoch Loss: 71733.0632 - Avg Loss: 161.1979\n",
            "Epoch [16/50] - Batch loss: 161.7388 - Epoch Loss: 71894.8020 - Avg Loss: 161.1991\n",
            "Epoch [16/50] - Batch loss: 158.3971 - Epoch Loss: 72053.1992 - Avg Loss: 161.1928\n",
            "Epoch [16/50] - Batch loss: 157.6329 - Epoch Loss: 72210.8321 - Avg Loss: 161.1849\n",
            "Epoch [16/50] - Batch loss: 160.7205 - Epoch Loss: 72371.5525 - Avg Loss: 161.1839\n",
            "Epoch [16/50] - Batch loss: 158.7324 - Epoch Loss: 72530.2849 - Avg Loss: 161.1784\n",
            "Epoch [16/50] - Batch loss: 156.1436 - Epoch Loss: 72686.4285 - Avg Loss: 161.1672\n",
            "Epoch [16/50] - Batch loss: 153.7567 - Epoch Loss: 72840.1852 - Avg Loss: 161.1509\n",
            "Epoch [16/50] - Batch loss: 165.3439 - Epoch Loss: 73005.5291 - Avg Loss: 161.1601\n",
            "Epoch [16/50] - Batch loss: 159.7119 - Epoch Loss: 73165.2411 - Avg Loss: 161.1569\n",
            "Epoch [16/50] - Batch loss: 153.9327 - Epoch Loss: 73319.1738 - Avg Loss: 161.1410\n",
            "Epoch [16/50] - Batch loss: 157.6289 - Epoch Loss: 73476.8027 - Avg Loss: 161.1333\n",
            "Epoch [16/50] - Batch loss: 164.1089 - Epoch Loss: 73640.9116 - Avg Loss: 161.1399\n",
            "Epoch [16/50] - Batch loss: 158.7558 - Epoch Loss: 73799.6674 - Avg Loss: 161.1346\n",
            "Epoch [16/50] - Batch loss: 160.6730 - Epoch Loss: 73960.3404 - Avg Loss: 161.1336\n",
            "Epoch [16/50] - Batch loss: 160.9463 - Epoch Loss: 74121.2868 - Avg Loss: 161.1332\n",
            "Epoch [16/50] - Batch loss: 153.0813 - Epoch Loss: 74274.3681 - Avg Loss: 161.1158\n",
            "Epoch [16/50] - Batch loss: 162.3809 - Epoch Loss: 74436.7490 - Avg Loss: 161.1185\n",
            "Epoch [16/50] - Batch loss: 164.3412 - Epoch Loss: 74601.0901 - Avg Loss: 161.1255\n",
            "Epoch [16/50] - Batch loss: 159.4915 - Epoch Loss: 74760.5816 - Avg Loss: 161.1219\n",
            "Epoch [16/50] - Batch loss: 159.8385 - Epoch Loss: 74920.4201 - Avg Loss: 161.1192\n",
            "Epoch [16/50] - Batch loss: 158.5380 - Epoch Loss: 75078.9581 - Avg Loss: 161.1136\n",
            "Epoch [16/50] - Batch loss: 152.4087 - Epoch Loss: 75231.3668 - Avg Loss: 161.0950\n",
            "Epoch [16/50] - Batch loss: 157.8288 - Epoch Loss: 75389.1956 - Avg Loss: 161.0880\n",
            "Epoch [16/50] - Batch loss: 160.1823 - Epoch Loss: 75549.3779 - Avg Loss: 161.0861\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 17/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3320b9b595e146ada64953f5a232d93a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/50] - Batch loss: 163.4405 - Epoch Loss: 163.4405 - Avg Loss: 163.4405\n",
            "Epoch [17/50] - Batch loss: 154.1047 - Epoch Loss: 317.5452 - Avg Loss: 158.7726\n",
            "Epoch [17/50] - Batch loss: 158.1220 - Epoch Loss: 475.6672 - Avg Loss: 158.5557\n",
            "Epoch [17/50] - Batch loss: 162.1675 - Epoch Loss: 637.8347 - Avg Loss: 159.4587\n",
            "Epoch [17/50] - Batch loss: 160.4864 - Epoch Loss: 798.3211 - Avg Loss: 159.6642\n",
            "Epoch [17/50] - Batch loss: 162.9622 - Epoch Loss: 961.2833 - Avg Loss: 160.2139\n",
            "Epoch [17/50] - Batch loss: 165.7158 - Epoch Loss: 1126.9991 - Avg Loss: 160.9999\n",
            "Epoch [17/50] - Batch loss: 167.4101 - Epoch Loss: 1294.4092 - Avg Loss: 161.8011\n",
            "Epoch [17/50] - Batch loss: 155.5072 - Epoch Loss: 1449.9164 - Avg Loss: 161.1018\n",
            "Epoch [17/50] - Batch loss: 159.4155 - Epoch Loss: 1609.3318 - Avg Loss: 160.9332\n",
            "Epoch [17/50] - Batch loss: 171.9694 - Epoch Loss: 1781.3012 - Avg Loss: 161.9365\n",
            "Epoch [17/50] - Batch loss: 158.1896 - Epoch Loss: 1939.4908 - Avg Loss: 161.6242\n",
            "Epoch [17/50] - Batch loss: 157.3914 - Epoch Loss: 2096.8822 - Avg Loss: 161.2986\n",
            "Epoch [17/50] - Batch loss: 162.9026 - Epoch Loss: 2259.7848 - Avg Loss: 161.4132\n",
            "Epoch [17/50] - Batch loss: 164.1562 - Epoch Loss: 2423.9410 - Avg Loss: 161.5961\n",
            "Epoch [17/50] - Batch loss: 156.2523 - Epoch Loss: 2580.1933 - Avg Loss: 161.2621\n",
            "Epoch [17/50] - Batch loss: 154.2121 - Epoch Loss: 2734.4053 - Avg Loss: 160.8474\n",
            "Epoch [17/50] - Batch loss: 164.6497 - Epoch Loss: 2899.0550 - Avg Loss: 161.0586\n",
            "Epoch [17/50] - Batch loss: 150.3843 - Epoch Loss: 3049.4393 - Avg Loss: 160.4968\n",
            "Epoch [17/50] - Batch loss: 154.2107 - Epoch Loss: 3203.6499 - Avg Loss: 160.1825\n",
            "Epoch [17/50] - Batch loss: 153.8041 - Epoch Loss: 3357.4541 - Avg Loss: 159.8788\n",
            "Epoch [17/50] - Batch loss: 152.2665 - Epoch Loss: 3509.7206 - Avg Loss: 159.5328\n",
            "Epoch [17/50] - Batch loss: 159.6320 - Epoch Loss: 3669.3526 - Avg Loss: 159.5371\n",
            "Epoch [17/50] - Batch loss: 156.4137 - Epoch Loss: 3825.7663 - Avg Loss: 159.4069\n",
            "Epoch [17/50] - Batch loss: 149.7664 - Epoch Loss: 3975.5327 - Avg Loss: 159.0213\n",
            "Epoch [17/50] - Batch loss: 157.5352 - Epoch Loss: 4133.0679 - Avg Loss: 158.9641\n",
            "Epoch [17/50] - Batch loss: 151.4901 - Epoch Loss: 4284.5580 - Avg Loss: 158.6873\n",
            "Epoch [17/50] - Batch loss: 154.8427 - Epoch Loss: 4439.4007 - Avg Loss: 158.5500\n",
            "Epoch [17/50] - Batch loss: 161.6780 - Epoch Loss: 4601.0787 - Avg Loss: 158.6579\n",
            "Epoch [17/50] - Batch loss: 159.6684 - Epoch Loss: 4760.7471 - Avg Loss: 158.6916\n",
            "Epoch [17/50] - Batch loss: 149.7570 - Epoch Loss: 4910.5041 - Avg Loss: 158.4034\n",
            "Epoch [17/50] - Batch loss: 164.5732 - Epoch Loss: 5075.0773 - Avg Loss: 158.5962\n",
            "Epoch [17/50] - Batch loss: 167.7789 - Epoch Loss: 5242.8562 - Avg Loss: 158.8744\n",
            "Epoch [17/50] - Batch loss: 162.9054 - Epoch Loss: 5405.7616 - Avg Loss: 158.9930\n",
            "Epoch [17/50] - Batch loss: 163.4722 - Epoch Loss: 5569.2338 - Avg Loss: 159.1210\n",
            "Epoch [17/50] - Batch loss: 155.8944 - Epoch Loss: 5725.1282 - Avg Loss: 159.0313\n",
            "Epoch [17/50] - Batch loss: 158.8099 - Epoch Loss: 5883.9381 - Avg Loss: 159.0254\n",
            "Epoch [17/50] - Batch loss: 156.4415 - Epoch Loss: 6040.3795 - Avg Loss: 158.9574\n",
            "Epoch [17/50] - Batch loss: 162.1668 - Epoch Loss: 6202.5463 - Avg Loss: 159.0396\n",
            "Epoch [17/50] - Batch loss: 160.4457 - Epoch Loss: 6362.9920 - Avg Loss: 159.0748\n",
            "Epoch [17/50] - Batch loss: 155.4884 - Epoch Loss: 6518.4804 - Avg Loss: 158.9873\n",
            "Epoch [17/50] - Batch loss: 160.1818 - Epoch Loss: 6678.6622 - Avg Loss: 159.0158\n",
            "Epoch [17/50] - Batch loss: 158.1608 - Epoch Loss: 6836.8230 - Avg Loss: 158.9959\n",
            "Epoch [17/50] - Batch loss: 158.2811 - Epoch Loss: 6995.1041 - Avg Loss: 158.9796\n",
            "Epoch [17/50] - Batch loss: 162.2028 - Epoch Loss: 7157.3069 - Avg Loss: 159.0513\n",
            "Epoch [17/50] - Batch loss: 159.6277 - Epoch Loss: 7316.9347 - Avg Loss: 159.0638\n",
            "Epoch [17/50] - Batch loss: 163.4415 - Epoch Loss: 7480.3762 - Avg Loss: 159.1569\n",
            "Epoch [17/50] - Batch loss: 160.0173 - Epoch Loss: 7640.3934 - Avg Loss: 159.1749\n",
            "Epoch [17/50] - Batch loss: 160.5334 - Epoch Loss: 7800.9269 - Avg Loss: 159.2026\n",
            "Epoch [17/50] - Batch loss: 162.6568 - Epoch Loss: 7963.5836 - Avg Loss: 159.2717\n",
            "Epoch [17/50] - Batch loss: 162.6805 - Epoch Loss: 8126.2641 - Avg Loss: 159.3385\n",
            "Epoch [17/50] - Batch loss: 154.7638 - Epoch Loss: 8281.0279 - Avg Loss: 159.2505\n",
            "Epoch [17/50] - Batch loss: 159.7775 - Epoch Loss: 8440.8054 - Avg Loss: 159.2605\n",
            "Epoch [17/50] - Batch loss: 154.1207 - Epoch Loss: 8594.9261 - Avg Loss: 159.1653\n",
            "Epoch [17/50] - Batch loss: 158.3353 - Epoch Loss: 8753.2614 - Avg Loss: 159.1502\n",
            "Epoch [17/50] - Batch loss: 156.2926 - Epoch Loss: 8909.5540 - Avg Loss: 159.0992\n",
            "Epoch [17/50] - Batch loss: 162.1181 - Epoch Loss: 9071.6722 - Avg Loss: 159.1521\n",
            "Epoch [17/50] - Batch loss: 158.5906 - Epoch Loss: 9230.2628 - Avg Loss: 159.1425\n",
            "Epoch [17/50] - Batch loss: 153.8616 - Epoch Loss: 9384.1244 - Avg Loss: 159.0530\n",
            "Epoch [17/50] - Batch loss: 159.1200 - Epoch Loss: 9543.2444 - Avg Loss: 159.0541\n",
            "Epoch [17/50] - Batch loss: 165.7460 - Epoch Loss: 9708.9904 - Avg Loss: 159.1638\n",
            "Epoch [17/50] - Batch loss: 164.2860 - Epoch Loss: 9873.2764 - Avg Loss: 159.2464\n",
            "Epoch [17/50] - Batch loss: 152.3702 - Epoch Loss: 10025.6467 - Avg Loss: 159.1372\n",
            "Epoch [17/50] - Batch loss: 163.2402 - Epoch Loss: 10188.8868 - Avg Loss: 159.2014\n",
            "Epoch [17/50] - Batch loss: 152.8800 - Epoch Loss: 10341.7668 - Avg Loss: 159.1041\n",
            "Epoch [17/50] - Batch loss: 161.2513 - Epoch Loss: 10503.0181 - Avg Loss: 159.1366\n",
            "Epoch [17/50] - Batch loss: 165.3679 - Epoch Loss: 10668.3860 - Avg Loss: 159.2296\n",
            "Epoch [17/50] - Batch loss: 157.7142 - Epoch Loss: 10826.1002 - Avg Loss: 159.2074\n",
            "Epoch [17/50] - Batch loss: 166.4636 - Epoch Loss: 10992.5638 - Avg Loss: 159.3125\n",
            "Epoch [17/50] - Batch loss: 152.6105 - Epoch Loss: 11145.1743 - Avg Loss: 159.2168\n",
            "Epoch [17/50] - Batch loss: 161.3934 - Epoch Loss: 11306.5677 - Avg Loss: 159.2474\n",
            "Epoch [17/50] - Batch loss: 157.0980 - Epoch Loss: 11463.6657 - Avg Loss: 159.2176\n",
            "Epoch [17/50] - Batch loss: 158.6888 - Epoch Loss: 11622.3544 - Avg Loss: 159.2103\n",
            "Epoch [17/50] - Batch loss: 158.5664 - Epoch Loss: 11780.9208 - Avg Loss: 159.2016\n",
            "Epoch [17/50] - Batch loss: 156.7447 - Epoch Loss: 11937.6655 - Avg Loss: 159.1689\n",
            "Epoch [17/50] - Batch loss: 162.4886 - Epoch Loss: 12100.1541 - Avg Loss: 159.2126\n",
            "Epoch [17/50] - Batch loss: 166.5076 - Epoch Loss: 12266.6617 - Avg Loss: 159.3073\n",
            "Epoch [17/50] - Batch loss: 157.7579 - Epoch Loss: 12424.4196 - Avg Loss: 159.2874\n",
            "Epoch [17/50] - Batch loss: 160.6128 - Epoch Loss: 12585.0324 - Avg Loss: 159.3042\n",
            "Epoch [17/50] - Batch loss: 160.1867 - Epoch Loss: 12745.2191 - Avg Loss: 159.3152\n",
            "Epoch [17/50] - Batch loss: 152.7859 - Epoch Loss: 12898.0049 - Avg Loss: 159.2346\n",
            "Epoch [17/50] - Batch loss: 152.0954 - Epoch Loss: 13050.1003 - Avg Loss: 159.1476\n",
            "Epoch [17/50] - Batch loss: 158.5447 - Epoch Loss: 13208.6450 - Avg Loss: 159.1403\n",
            "Epoch [17/50] - Batch loss: 165.7768 - Epoch Loss: 13374.4218 - Avg Loss: 159.2193\n",
            "Epoch [17/50] - Batch loss: 161.2240 - Epoch Loss: 13535.6458 - Avg Loss: 159.2429\n",
            "Epoch [17/50] - Batch loss: 160.9813 - Epoch Loss: 13696.6271 - Avg Loss: 159.2631\n",
            "Epoch [17/50] - Batch loss: 163.3199 - Epoch Loss: 13859.9471 - Avg Loss: 159.3097\n",
            "Epoch [17/50] - Batch loss: 161.8292 - Epoch Loss: 14021.7763 - Avg Loss: 159.3384\n",
            "Epoch [17/50] - Batch loss: 153.6984 - Epoch Loss: 14175.4746 - Avg Loss: 159.2750\n",
            "Epoch [17/50] - Batch loss: 154.9327 - Epoch Loss: 14330.4073 - Avg Loss: 159.2267\n",
            "Epoch [17/50] - Batch loss: 168.7329 - Epoch Loss: 14499.1402 - Avg Loss: 159.3312\n",
            "Epoch [17/50] - Batch loss: 160.6408 - Epoch Loss: 14659.7810 - Avg Loss: 159.3454\n",
            "Epoch [17/50] - Batch loss: 164.3906 - Epoch Loss: 14824.1716 - Avg Loss: 159.3997\n",
            "Epoch [17/50] - Batch loss: 158.9756 - Epoch Loss: 14983.1472 - Avg Loss: 159.3952\n",
            "Epoch [17/50] - Batch loss: 162.0576 - Epoch Loss: 15145.2048 - Avg Loss: 159.4232\n",
            "Epoch [17/50] - Batch loss: 159.1694 - Epoch Loss: 15304.3742 - Avg Loss: 159.4206\n",
            "Epoch [17/50] - Batch loss: 164.0823 - Epoch Loss: 15468.4565 - Avg Loss: 159.4686\n",
            "Epoch [17/50] - Batch loss: 161.9792 - Epoch Loss: 15630.4357 - Avg Loss: 159.4942\n",
            "Epoch [17/50] - Batch loss: 155.7890 - Epoch Loss: 15786.2247 - Avg Loss: 159.4568\n",
            "Epoch [17/50] - Batch loss: 162.1031 - Epoch Loss: 15948.3277 - Avg Loss: 159.4833\n",
            "Epoch [17/50] - Batch loss: 153.8124 - Epoch Loss: 16102.1402 - Avg Loss: 159.4271\n",
            "Epoch [17/50] - Batch loss: 165.7494 - Epoch Loss: 16267.8895 - Avg Loss: 159.4891\n",
            "Epoch [17/50] - Batch loss: 160.3750 - Epoch Loss: 16428.2645 - Avg Loss: 159.4977\n",
            "Epoch [17/50] - Batch loss: 159.2687 - Epoch Loss: 16587.5332 - Avg Loss: 159.4955\n",
            "Epoch [17/50] - Batch loss: 159.4658 - Epoch Loss: 16746.9990 - Avg Loss: 159.4952\n",
            "Epoch [17/50] - Batch loss: 156.9134 - Epoch Loss: 16903.9125 - Avg Loss: 159.4709\n",
            "Epoch [17/50] - Batch loss: 156.4109 - Epoch Loss: 17060.3233 - Avg Loss: 159.4423\n",
            "Epoch [17/50] - Batch loss: 165.1811 - Epoch Loss: 17225.5045 - Avg Loss: 159.4954\n",
            "Epoch [17/50] - Batch loss: 165.7150 - Epoch Loss: 17391.2194 - Avg Loss: 159.5525\n",
            "Epoch [17/50] - Batch loss: 158.4095 - Epoch Loss: 17549.6289 - Avg Loss: 159.5421\n",
            "Epoch [17/50] - Batch loss: 158.3512 - Epoch Loss: 17707.9801 - Avg Loss: 159.5314\n",
            "Epoch [17/50] - Batch loss: 169.6199 - Epoch Loss: 17877.5999 - Avg Loss: 159.6214\n",
            "Epoch [17/50] - Batch loss: 165.4763 - Epoch Loss: 18043.0762 - Avg Loss: 159.6732\n",
            "Epoch [17/50] - Batch loss: 161.0133 - Epoch Loss: 18204.0896 - Avg Loss: 159.6850\n",
            "Epoch [17/50] - Batch loss: 159.6882 - Epoch Loss: 18363.7778 - Avg Loss: 159.6850\n",
            "Epoch [17/50] - Batch loss: 159.8699 - Epoch Loss: 18523.6477 - Avg Loss: 159.6866\n",
            "Epoch [17/50] - Batch loss: 169.3514 - Epoch Loss: 18692.9991 - Avg Loss: 159.7692\n",
            "Epoch [17/50] - Batch loss: 156.8361 - Epoch Loss: 18849.8353 - Avg Loss: 159.7444\n",
            "Epoch [17/50] - Batch loss: 164.8806 - Epoch Loss: 19014.7159 - Avg Loss: 159.7875\n",
            "Epoch [17/50] - Batch loss: 164.9302 - Epoch Loss: 19179.6461 - Avg Loss: 159.8304\n",
            "Epoch [17/50] - Batch loss: 172.7128 - Epoch Loss: 19352.3588 - Avg Loss: 159.9368\n",
            "Epoch [17/50] - Batch loss: 160.9304 - Epoch Loss: 19513.2892 - Avg Loss: 159.9450\n",
            "Epoch [17/50] - Batch loss: 147.3800 - Epoch Loss: 19660.6692 - Avg Loss: 159.8428\n",
            "Epoch [17/50] - Batch loss: 167.3997 - Epoch Loss: 19828.0689 - Avg Loss: 159.9038\n",
            "Epoch [17/50] - Batch loss: 169.0705 - Epoch Loss: 19997.1395 - Avg Loss: 159.9771\n",
            "Epoch [17/50] - Batch loss: 157.2671 - Epoch Loss: 20154.4066 - Avg Loss: 159.9556\n",
            "Epoch [17/50] - Batch loss: 161.7268 - Epoch Loss: 20316.1334 - Avg Loss: 159.9696\n",
            "Epoch [17/50] - Batch loss: 159.5209 - Epoch Loss: 20475.6542 - Avg Loss: 159.9660\n",
            "Epoch [17/50] - Batch loss: 157.0432 - Epoch Loss: 20632.6974 - Avg Loss: 159.9434\n",
            "Epoch [17/50] - Batch loss: 154.3570 - Epoch Loss: 20787.0544 - Avg Loss: 159.9004\n",
            "Epoch [17/50] - Batch loss: 167.3026 - Epoch Loss: 20954.3569 - Avg Loss: 159.9569\n",
            "Epoch [17/50] - Batch loss: 165.1381 - Epoch Loss: 21119.4950 - Avg Loss: 159.9962\n",
            "Epoch [17/50] - Batch loss: 156.2360 - Epoch Loss: 21275.7310 - Avg Loss: 159.9679\n",
            "Epoch [17/50] - Batch loss: 154.3879 - Epoch Loss: 21430.1189 - Avg Loss: 159.9263\n",
            "Epoch [17/50] - Batch loss: 144.2821 - Epoch Loss: 21574.4010 - Avg Loss: 159.8104\n",
            "Epoch [17/50] - Batch loss: 156.3032 - Epoch Loss: 21730.7042 - Avg Loss: 159.7846\n",
            "Epoch [17/50] - Batch loss: 161.1218 - Epoch Loss: 21891.8261 - Avg Loss: 159.7944\n",
            "Epoch [17/50] - Batch loss: 159.3031 - Epoch Loss: 22051.1291 - Avg Loss: 159.7908\n",
            "Epoch [17/50] - Batch loss: 160.1881 - Epoch Loss: 22211.3172 - Avg Loss: 159.7936\n",
            "Epoch [17/50] - Batch loss: 160.6195 - Epoch Loss: 22371.9367 - Avg Loss: 159.7995\n",
            "Epoch [17/50] - Batch loss: 160.5800 - Epoch Loss: 22532.5167 - Avg Loss: 159.8051\n",
            "Epoch [17/50] - Batch loss: 156.3401 - Epoch Loss: 22688.8568 - Avg Loss: 159.7807\n",
            "Epoch [17/50] - Batch loss: 169.5915 - Epoch Loss: 22858.4483 - Avg Loss: 159.8493\n",
            "Epoch [17/50] - Batch loss: 160.7246 - Epoch Loss: 23019.1729 - Avg Loss: 159.8554\n",
            "Epoch [17/50] - Batch loss: 166.6358 - Epoch Loss: 23185.8087 - Avg Loss: 159.9021\n",
            "Epoch [17/50] - Batch loss: 160.4783 - Epoch Loss: 23346.2870 - Avg Loss: 159.9061\n",
            "Epoch [17/50] - Batch loss: 165.7154 - Epoch Loss: 23512.0024 - Avg Loss: 159.9456\n",
            "Epoch [17/50] - Batch loss: 158.6432 - Epoch Loss: 23670.6456 - Avg Loss: 159.9368\n",
            "Epoch [17/50] - Batch loss: 158.2700 - Epoch Loss: 23828.9155 - Avg Loss: 159.9256\n",
            "Epoch [17/50] - Batch loss: 153.9429 - Epoch Loss: 23982.8584 - Avg Loss: 159.8857\n",
            "Epoch [17/50] - Batch loss: 154.4848 - Epoch Loss: 24137.3432 - Avg Loss: 159.8500\n",
            "Epoch [17/50] - Batch loss: 154.1970 - Epoch Loss: 24291.5402 - Avg Loss: 159.8128\n",
            "Epoch [17/50] - Batch loss: 161.0639 - Epoch Loss: 24452.6041 - Avg Loss: 159.8209\n",
            "Epoch [17/50] - Batch loss: 156.2448 - Epoch Loss: 24608.8489 - Avg Loss: 159.7977\n",
            "Epoch [17/50] - Batch loss: 167.7526 - Epoch Loss: 24776.6015 - Avg Loss: 159.8490\n",
            "Epoch [17/50] - Batch loss: 153.8060 - Epoch Loss: 24930.4075 - Avg Loss: 159.8103\n",
            "Epoch [17/50] - Batch loss: 161.6461 - Epoch Loss: 25092.0536 - Avg Loss: 159.8220\n",
            "Epoch [17/50] - Batch loss: 158.4716 - Epoch Loss: 25250.5251 - Avg Loss: 159.8135\n",
            "Epoch [17/50] - Batch loss: 163.1475 - Epoch Loss: 25413.6727 - Avg Loss: 159.8344\n",
            "Epoch [17/50] - Batch loss: 166.5554 - Epoch Loss: 25580.2281 - Avg Loss: 159.8764\n",
            "Epoch [17/50] - Batch loss: 154.7040 - Epoch Loss: 25734.9321 - Avg Loss: 159.8443\n",
            "Epoch [17/50] - Batch loss: 154.9955 - Epoch Loss: 25889.9276 - Avg Loss: 159.8144\n",
            "Epoch [17/50] - Batch loss: 165.9430 - Epoch Loss: 26055.8707 - Avg Loss: 159.8520\n",
            "Epoch [17/50] - Batch loss: 167.9699 - Epoch Loss: 26223.8406 - Avg Loss: 159.9015\n",
            "Epoch [17/50] - Batch loss: 158.4209 - Epoch Loss: 26382.2615 - Avg Loss: 159.8925\n",
            "Epoch [17/50] - Batch loss: 162.5647 - Epoch Loss: 26544.8262 - Avg Loss: 159.9086\n",
            "Epoch [17/50] - Batch loss: 162.8003 - Epoch Loss: 26707.6265 - Avg Loss: 159.9259\n",
            "Epoch [17/50] - Batch loss: 157.5926 - Epoch Loss: 26865.2191 - Avg Loss: 159.9120\n",
            "Epoch [17/50] - Batch loss: 155.7352 - Epoch Loss: 27020.9544 - Avg Loss: 159.8873\n",
            "Epoch [17/50] - Batch loss: 161.1903 - Epoch Loss: 27182.1447 - Avg Loss: 159.8950\n",
            "Epoch [17/50] - Batch loss: 156.9187 - Epoch Loss: 27339.0633 - Avg Loss: 159.8776\n",
            "Epoch [17/50] - Batch loss: 154.1808 - Epoch Loss: 27493.2442 - Avg Loss: 159.8444\n",
            "Epoch [17/50] - Batch loss: 155.6601 - Epoch Loss: 27648.9042 - Avg Loss: 159.8203\n",
            "Epoch [17/50] - Batch loss: 160.4011 - Epoch Loss: 27809.3053 - Avg Loss: 159.8236\n",
            "Epoch [17/50] - Batch loss: 157.3710 - Epoch Loss: 27966.6763 - Avg Loss: 159.8096\n",
            "Epoch [17/50] - Batch loss: 156.8480 - Epoch Loss: 28123.5243 - Avg Loss: 159.7928\n",
            "Epoch [17/50] - Batch loss: 155.9121 - Epoch Loss: 28279.4364 - Avg Loss: 159.7708\n",
            "Epoch [17/50] - Batch loss: 150.6129 - Epoch Loss: 28430.0492 - Avg Loss: 159.7194\n",
            "Epoch [17/50] - Batch loss: 163.6910 - Epoch Loss: 28593.7402 - Avg Loss: 159.7416\n",
            "Epoch [17/50] - Batch loss: 151.0570 - Epoch Loss: 28744.7972 - Avg Loss: 159.6933\n",
            "Epoch [17/50] - Batch loss: 154.8825 - Epoch Loss: 28899.6797 - Avg Loss: 159.6667\n",
            "Epoch [17/50] - Batch loss: 158.5792 - Epoch Loss: 29058.2589 - Avg Loss: 159.6608\n",
            "Epoch [17/50] - Batch loss: 161.2890 - Epoch Loss: 29219.5479 - Avg Loss: 159.6697\n",
            "Epoch [17/50] - Batch loss: 159.4735 - Epoch Loss: 29379.0214 - Avg Loss: 159.6686\n",
            "Epoch [17/50] - Batch loss: 156.8314 - Epoch Loss: 29535.8528 - Avg Loss: 159.6533\n",
            "Epoch [17/50] - Batch loss: 155.3759 - Epoch Loss: 29691.2287 - Avg Loss: 159.6303\n",
            "Epoch [17/50] - Batch loss: 153.8825 - Epoch Loss: 29845.1112 - Avg Loss: 159.5995\n",
            "Epoch [17/50] - Batch loss: 162.2185 - Epoch Loss: 30007.3297 - Avg Loss: 159.6135\n",
            "Epoch [17/50] - Batch loss: 151.4091 - Epoch Loss: 30158.7388 - Avg Loss: 159.5700\n",
            "Epoch [17/50] - Batch loss: 162.2849 - Epoch Loss: 30321.0237 - Avg Loss: 159.5843\n",
            "Epoch [17/50] - Batch loss: 165.3010 - Epoch Loss: 30486.3247 - Avg Loss: 159.6143\n",
            "Epoch [17/50] - Batch loss: 160.2799 - Epoch Loss: 30646.6046 - Avg Loss: 159.6177\n",
            "Epoch [17/50] - Batch loss: 165.1074 - Epoch Loss: 30811.7121 - Avg Loss: 159.6462\n",
            "Epoch [17/50] - Batch loss: 166.3952 - Epoch Loss: 30978.1073 - Avg Loss: 159.6810\n",
            "Epoch [17/50] - Batch loss: 162.9710 - Epoch Loss: 31141.0783 - Avg Loss: 159.6978\n",
            "Epoch [17/50] - Batch loss: 158.7572 - Epoch Loss: 31299.8354 - Avg Loss: 159.6930\n",
            "Epoch [17/50] - Batch loss: 165.4543 - Epoch Loss: 31465.2897 - Avg Loss: 159.7223\n",
            "Epoch [17/50] - Batch loss: 148.2364 - Epoch Loss: 31613.5261 - Avg Loss: 159.6643\n",
            "Epoch [17/50] - Batch loss: 162.6302 - Epoch Loss: 31776.1563 - Avg Loss: 159.6792\n",
            "Epoch [17/50] - Batch loss: 156.9557 - Epoch Loss: 31933.1121 - Avg Loss: 159.6656\n",
            "Epoch [17/50] - Batch loss: 150.7228 - Epoch Loss: 32083.8349 - Avg Loss: 159.6211\n",
            "Epoch [17/50] - Batch loss: 157.5449 - Epoch Loss: 32241.3799 - Avg Loss: 159.6108\n",
            "Epoch [17/50] - Batch loss: 164.8852 - Epoch Loss: 32406.2650 - Avg Loss: 159.6368\n",
            "Epoch [17/50] - Batch loss: 159.0918 - Epoch Loss: 32565.3569 - Avg Loss: 159.6341\n",
            "Epoch [17/50] - Batch loss: 155.3600 - Epoch Loss: 32720.7169 - Avg Loss: 159.6133\n",
            "Epoch [17/50] - Batch loss: 155.8571 - Epoch Loss: 32876.5740 - Avg Loss: 159.5950\n",
            "Epoch [17/50] - Batch loss: 154.6805 - Epoch Loss: 33031.2544 - Avg Loss: 159.5713\n",
            "Epoch [17/50] - Batch loss: 161.7294 - Epoch Loss: 33192.9839 - Avg Loss: 159.5817\n",
            "Epoch [17/50] - Batch loss: 163.1991 - Epoch Loss: 33356.1830 - Avg Loss: 159.5990\n",
            "Epoch [17/50] - Batch loss: 153.8268 - Epoch Loss: 33510.0098 - Avg Loss: 159.5715\n",
            "Epoch [17/50] - Batch loss: 159.3160 - Epoch Loss: 33669.3257 - Avg Loss: 159.5703\n",
            "Epoch [17/50] - Batch loss: 157.0638 - Epoch Loss: 33826.3895 - Avg Loss: 159.5584\n",
            "Epoch [17/50] - Batch loss: 157.4921 - Epoch Loss: 33983.8816 - Avg Loss: 159.5487\n",
            "Epoch [17/50] - Batch loss: 155.3273 - Epoch Loss: 34139.2089 - Avg Loss: 159.5290\n",
            "Epoch [17/50] - Batch loss: 156.8630 - Epoch Loss: 34296.0719 - Avg Loss: 159.5166\n",
            "Epoch [17/50] - Batch loss: 161.1322 - Epoch Loss: 34457.2041 - Avg Loss: 159.5241\n",
            "Epoch [17/50] - Batch loss: 151.8265 - Epoch Loss: 34609.0306 - Avg Loss: 159.4886\n",
            "Epoch [17/50] - Batch loss: 168.5276 - Epoch Loss: 34777.5582 - Avg Loss: 159.5301\n",
            "Epoch [17/50] - Batch loss: 157.7033 - Epoch Loss: 34935.2615 - Avg Loss: 159.5217\n",
            "Epoch [17/50] - Batch loss: 156.6011 - Epoch Loss: 35091.8626 - Avg Loss: 159.5085\n",
            "Epoch [17/50] - Batch loss: 158.5524 - Epoch Loss: 35250.4150 - Avg Loss: 159.5041\n",
            "Epoch [17/50] - Batch loss: 161.6789 - Epoch Loss: 35412.0939 - Avg Loss: 159.5139\n",
            "Epoch [17/50] - Batch loss: 166.9724 - Epoch Loss: 35579.0663 - Avg Loss: 159.5474\n",
            "Epoch [17/50] - Batch loss: 156.0713 - Epoch Loss: 35735.1376 - Avg Loss: 159.5319\n",
            "Epoch [17/50] - Batch loss: 165.2178 - Epoch Loss: 35900.3554 - Avg Loss: 159.5571\n",
            "Epoch [17/50] - Batch loss: 164.8617 - Epoch Loss: 36065.2171 - Avg Loss: 159.5806\n",
            "Epoch [17/50] - Batch loss: 156.1730 - Epoch Loss: 36221.3901 - Avg Loss: 159.5656\n",
            "Epoch [17/50] - Batch loss: 153.1593 - Epoch Loss: 36374.5494 - Avg Loss: 159.5375\n",
            "Epoch [17/50] - Batch loss: 160.3731 - Epoch Loss: 36534.9225 - Avg Loss: 159.5411\n",
            "Epoch [17/50] - Batch loss: 160.5872 - Epoch Loss: 36695.5097 - Avg Loss: 159.5457\n",
            "Epoch [17/50] - Batch loss: 160.8516 - Epoch Loss: 36856.3613 - Avg Loss: 159.5513\n",
            "Epoch [17/50] - Batch loss: 160.1526 - Epoch Loss: 37016.5139 - Avg Loss: 159.5539\n",
            "Epoch [17/50] - Batch loss: 157.4606 - Epoch Loss: 37173.9745 - Avg Loss: 159.5450\n",
            "Epoch [17/50] - Batch loss: 161.8724 - Epoch Loss: 37335.8469 - Avg Loss: 159.5549\n",
            "Epoch [17/50] - Batch loss: 160.4643 - Epoch Loss: 37496.3112 - Avg Loss: 159.5588\n",
            "Epoch [17/50] - Batch loss: 163.1365 - Epoch Loss: 37659.4476 - Avg Loss: 159.5739\n",
            "Epoch [17/50] - Batch loss: 156.8150 - Epoch Loss: 37816.2626 - Avg Loss: 159.5623\n",
            "Epoch [17/50] - Batch loss: 163.8255 - Epoch Loss: 37980.0882 - Avg Loss: 159.5802\n",
            "Epoch [17/50] - Batch loss: 160.3019 - Epoch Loss: 38140.3900 - Avg Loss: 159.5832\n",
            "Epoch [17/50] - Batch loss: 163.8273 - Epoch Loss: 38304.2174 - Avg Loss: 159.6009\n",
            "Epoch [17/50] - Batch loss: 161.7216 - Epoch Loss: 38465.9389 - Avg Loss: 159.6097\n",
            "Epoch [17/50] - Batch loss: 157.6175 - Epoch Loss: 38623.5564 - Avg Loss: 159.6015\n",
            "Epoch [17/50] - Batch loss: 160.2956 - Epoch Loss: 38783.8521 - Avg Loss: 159.6043\n",
            "Epoch [17/50] - Batch loss: 163.2528 - Epoch Loss: 38947.1048 - Avg Loss: 159.6193\n",
            "Epoch [17/50] - Batch loss: 155.0670 - Epoch Loss: 39102.1718 - Avg Loss: 159.6007\n",
            "Epoch [17/50] - Batch loss: 156.6891 - Epoch Loss: 39258.8609 - Avg Loss: 159.5889\n",
            "Epoch [17/50] - Batch loss: 158.1477 - Epoch Loss: 39417.0085 - Avg Loss: 159.5830\n",
            "Epoch [17/50] - Batch loss: 158.4965 - Epoch Loss: 39575.5051 - Avg Loss: 159.5786\n",
            "Epoch [17/50] - Batch loss: 155.3357 - Epoch Loss: 39730.8408 - Avg Loss: 159.5616\n",
            "Epoch [17/50] - Batch loss: 154.0733 - Epoch Loss: 39884.9141 - Avg Loss: 159.5397\n",
            "Epoch [17/50] - Batch loss: 168.2748 - Epoch Loss: 40053.1889 - Avg Loss: 159.5745\n",
            "Epoch [17/50] - Batch loss: 166.7772 - Epoch Loss: 40219.9661 - Avg Loss: 159.6030\n",
            "Epoch [17/50] - Batch loss: 158.7271 - Epoch Loss: 40378.6932 - Avg Loss: 159.5996\n",
            "Epoch [17/50] - Batch loss: 151.2892 - Epoch Loss: 40529.9824 - Avg Loss: 159.5669\n",
            "Epoch [17/50] - Batch loss: 158.5164 - Epoch Loss: 40688.4988 - Avg Loss: 159.5627\n",
            "Epoch [17/50] - Batch loss: 160.6875 - Epoch Loss: 40849.1864 - Avg Loss: 159.5671\n",
            "Epoch [17/50] - Batch loss: 157.2332 - Epoch Loss: 41006.4195 - Avg Loss: 159.5581\n",
            "Epoch [17/50] - Batch loss: 160.5619 - Epoch Loss: 41166.9814 - Avg Loss: 159.5619\n",
            "Epoch [17/50] - Batch loss: 151.8685 - Epoch Loss: 41318.8499 - Avg Loss: 159.5322\n",
            "Epoch [17/50] - Batch loss: 156.2652 - Epoch Loss: 41475.1150 - Avg Loss: 159.5197\n",
            "Epoch [17/50] - Batch loss: 171.1018 - Epoch Loss: 41646.2168 - Avg Loss: 159.5640\n",
            "Epoch [17/50] - Batch loss: 155.9911 - Epoch Loss: 41802.2079 - Avg Loss: 159.5504\n",
            "Epoch [17/50] - Batch loss: 157.2260 - Epoch Loss: 41959.4339 - Avg Loss: 159.5416\n",
            "Epoch [17/50] - Batch loss: 152.7262 - Epoch Loss: 42112.1601 - Avg Loss: 159.5158\n",
            "Epoch [17/50] - Batch loss: 164.1031 - Epoch Loss: 42276.2632 - Avg Loss: 159.5331\n",
            "Epoch [17/50] - Batch loss: 154.4335 - Epoch Loss: 42430.6966 - Avg Loss: 159.5139\n",
            "Epoch [17/50] - Batch loss: 157.6213 - Epoch Loss: 42588.3179 - Avg Loss: 159.5068\n",
            "Epoch [17/50] - Batch loss: 157.9463 - Epoch Loss: 42746.2642 - Avg Loss: 159.5010\n",
            "Epoch [17/50] - Batch loss: 163.4272 - Epoch Loss: 42909.6914 - Avg Loss: 159.5156\n",
            "Epoch [17/50] - Batch loss: 159.6286 - Epoch Loss: 43069.3200 - Avg Loss: 159.5160\n",
            "Epoch [17/50] - Batch loss: 161.7701 - Epoch Loss: 43231.0900 - Avg Loss: 159.5243\n",
            "Epoch [17/50] - Batch loss: 162.7871 - Epoch Loss: 43393.8771 - Avg Loss: 159.5363\n",
            "Epoch [17/50] - Batch loss: 155.7550 - Epoch Loss: 43549.6321 - Avg Loss: 159.5225\n",
            "Epoch [17/50] - Batch loss: 162.5390 - Epoch Loss: 43712.1711 - Avg Loss: 159.5335\n",
            "Epoch [17/50] - Batch loss: 155.3441 - Epoch Loss: 43867.5152 - Avg Loss: 159.5182\n",
            "Epoch [17/50] - Batch loss: 160.6034 - Epoch Loss: 44028.1186 - Avg Loss: 159.5222\n",
            "Epoch [17/50] - Batch loss: 164.8040 - Epoch Loss: 44192.9226 - Avg Loss: 159.5412\n",
            "Epoch [17/50] - Batch loss: 164.3712 - Epoch Loss: 44357.2938 - Avg Loss: 159.5586\n",
            "Epoch [17/50] - Batch loss: 164.8257 - Epoch Loss: 44522.1195 - Avg Loss: 159.5775\n",
            "Epoch [17/50] - Batch loss: 171.2683 - Epoch Loss: 44693.3878 - Avg Loss: 159.6192\n",
            "Epoch [17/50] - Batch loss: 163.0734 - Epoch Loss: 44856.4612 - Avg Loss: 159.6315\n",
            "Epoch [17/50] - Batch loss: 158.2471 - Epoch Loss: 45014.7083 - Avg Loss: 159.6266\n",
            "Epoch [17/50] - Batch loss: 159.6881 - Epoch Loss: 45174.3964 - Avg Loss: 159.6268\n",
            "Epoch [17/50] - Batch loss: 157.5338 - Epoch Loss: 45331.9302 - Avg Loss: 159.6195\n",
            "Epoch [17/50] - Batch loss: 157.2445 - Epoch Loss: 45489.1747 - Avg Loss: 159.6111\n",
            "Epoch [17/50] - Batch loss: 158.2597 - Epoch Loss: 45647.4344 - Avg Loss: 159.6064\n",
            "Epoch [17/50] - Batch loss: 149.4287 - Epoch Loss: 45796.8631 - Avg Loss: 159.5710\n",
            "Epoch [17/50] - Batch loss: 160.1512 - Epoch Loss: 45957.0143 - Avg Loss: 159.5730\n",
            "Epoch [17/50] - Batch loss: 153.3006 - Epoch Loss: 46110.3148 - Avg Loss: 159.5513\n",
            "Epoch [17/50] - Batch loss: 152.2324 - Epoch Loss: 46262.5473 - Avg Loss: 159.5260\n",
            "Epoch [17/50] - Batch loss: 154.9931 - Epoch Loss: 46417.5404 - Avg Loss: 159.5104\n",
            "Epoch [17/50] - Batch loss: 161.4975 - Epoch Loss: 46579.0379 - Avg Loss: 159.5173\n",
            "Epoch [17/50] - Batch loss: 163.1425 - Epoch Loss: 46742.1804 - Avg Loss: 159.5296\n",
            "Epoch [17/50] - Batch loss: 155.3934 - Epoch Loss: 46897.5738 - Avg Loss: 159.5156\n",
            "Epoch [17/50] - Batch loss: 151.6633 - Epoch Loss: 47049.2371 - Avg Loss: 159.4889\n",
            "Epoch [17/50] - Batch loss: 151.0775 - Epoch Loss: 47200.3146 - Avg Loss: 159.4605\n",
            "Epoch [17/50] - Batch loss: 156.3567 - Epoch Loss: 47356.6713 - Avg Loss: 159.4501\n",
            "Epoch [17/50] - Batch loss: 157.9190 - Epoch Loss: 47514.5903 - Avg Loss: 159.4449\n",
            "Epoch [17/50] - Batch loss: 163.7157 - Epoch Loss: 47678.3060 - Avg Loss: 159.4592\n",
            "Epoch [17/50] - Batch loss: 158.6656 - Epoch Loss: 47836.9716 - Avg Loss: 159.4566\n",
            "Epoch [17/50] - Batch loss: 153.1923 - Epoch Loss: 47990.1639 - Avg Loss: 159.4358\n",
            "Epoch [17/50] - Batch loss: 159.9510 - Epoch Loss: 48150.1149 - Avg Loss: 159.4375\n",
            "Epoch [17/50] - Batch loss: 155.7832 - Epoch Loss: 48305.8982 - Avg Loss: 159.4254\n",
            "Epoch [17/50] - Batch loss: 160.0603 - Epoch Loss: 48465.9585 - Avg Loss: 159.4275\n",
            "Epoch [17/50] - Batch loss: 154.8090 - Epoch Loss: 48620.7675 - Avg Loss: 159.4124\n",
            "Epoch [17/50] - Batch loss: 163.4867 - Epoch Loss: 48784.2542 - Avg Loss: 159.4257\n",
            "Epoch [17/50] - Batch loss: 162.3949 - Epoch Loss: 48946.6491 - Avg Loss: 159.4353\n",
            "Epoch [17/50] - Batch loss: 150.8234 - Epoch Loss: 49097.4724 - Avg Loss: 159.4074\n",
            "Epoch [17/50] - Batch loss: 150.1545 - Epoch Loss: 49247.6270 - Avg Loss: 159.3774\n",
            "Epoch [17/50] - Batch loss: 165.4533 - Epoch Loss: 49413.0802 - Avg Loss: 159.3970\n",
            "Epoch [17/50] - Batch loss: 155.3253 - Epoch Loss: 49568.4056 - Avg Loss: 159.3839\n",
            "Epoch [17/50] - Batch loss: 158.6533 - Epoch Loss: 49727.0588 - Avg Loss: 159.3816\n",
            "Epoch [17/50] - Batch loss: 166.3816 - Epoch Loss: 49893.4404 - Avg Loss: 159.4040\n",
            "Epoch [17/50] - Batch loss: 167.1388 - Epoch Loss: 50060.5792 - Avg Loss: 159.4286\n",
            "Epoch [17/50] - Batch loss: 156.5920 - Epoch Loss: 50217.1711 - Avg Loss: 159.4196\n",
            "Epoch [17/50] - Batch loss: 151.7588 - Epoch Loss: 50368.9299 - Avg Loss: 159.3953\n",
            "Epoch [17/50] - Batch loss: 166.5265 - Epoch Loss: 50535.4564 - Avg Loss: 159.4178\n",
            "Epoch [17/50] - Batch loss: 162.5778 - Epoch Loss: 50698.0342 - Avg Loss: 159.4278\n",
            "Epoch [17/50] - Batch loss: 163.4848 - Epoch Loss: 50861.5190 - Avg Loss: 159.4405\n",
            "Epoch [17/50] - Batch loss: 156.9036 - Epoch Loss: 51018.4225 - Avg Loss: 159.4326\n",
            "Epoch [17/50] - Batch loss: 166.4799 - Epoch Loss: 51184.9025 - Avg Loss: 159.4545\n",
            "Epoch [17/50] - Batch loss: 159.1300 - Epoch Loss: 51344.0325 - Avg Loss: 159.4535\n",
            "Epoch [17/50] - Batch loss: 161.6238 - Epoch Loss: 51505.6563 - Avg Loss: 159.4602\n",
            "Epoch [17/50] - Batch loss: 164.6892 - Epoch Loss: 51670.3455 - Avg Loss: 159.4764\n",
            "Epoch [17/50] - Batch loss: 158.9991 - Epoch Loss: 51829.3446 - Avg Loss: 159.4749\n",
            "Epoch [17/50] - Batch loss: 160.2715 - Epoch Loss: 51989.6161 - Avg Loss: 159.4773\n",
            "Epoch [17/50] - Batch loss: 165.1472 - Epoch Loss: 52154.7632 - Avg Loss: 159.4947\n",
            "Epoch [17/50] - Batch loss: 156.0881 - Epoch Loss: 52310.8513 - Avg Loss: 159.4843\n",
            "Epoch [17/50] - Batch loss: 164.5015 - Epoch Loss: 52475.3528 - Avg Loss: 159.4996\n",
            "Epoch [17/50] - Batch loss: 160.2309 - Epoch Loss: 52635.5837 - Avg Loss: 159.5018\n",
            "Epoch [17/50] - Batch loss: 162.6285 - Epoch Loss: 52798.2122 - Avg Loss: 159.5112\n",
            "Epoch [17/50] - Batch loss: 161.4260 - Epoch Loss: 52959.6382 - Avg Loss: 159.5170\n",
            "Epoch [17/50] - Batch loss: 164.1385 - Epoch Loss: 53123.7767 - Avg Loss: 159.5309\n",
            "Epoch [17/50] - Batch loss: 153.3492 - Epoch Loss: 53277.1259 - Avg Loss: 159.5124\n",
            "Epoch [17/50] - Batch loss: 163.7375 - Epoch Loss: 53440.8634 - Avg Loss: 159.5250\n",
            "Epoch [17/50] - Batch loss: 161.2843 - Epoch Loss: 53602.1476 - Avg Loss: 159.5302\n",
            "Epoch [17/50] - Batch loss: 163.6557 - Epoch Loss: 53765.8034 - Avg Loss: 159.5424\n",
            "Epoch [17/50] - Batch loss: 158.0414 - Epoch Loss: 53923.8447 - Avg Loss: 159.5380\n",
            "Epoch [17/50] - Batch loss: 167.8100 - Epoch Loss: 54091.6547 - Avg Loss: 159.5624\n",
            "Epoch [17/50] - Batch loss: 164.1171 - Epoch Loss: 54255.7718 - Avg Loss: 159.5758\n",
            "Epoch [17/50] - Batch loss: 166.6487 - Epoch Loss: 54422.4205 - Avg Loss: 159.5965\n",
            "Epoch [17/50] - Batch loss: 155.8470 - Epoch Loss: 54578.2674 - Avg Loss: 159.5856\n",
            "Epoch [17/50] - Batch loss: 156.4641 - Epoch Loss: 54734.7315 - Avg Loss: 159.5765\n",
            "Epoch [17/50] - Batch loss: 160.0094 - Epoch Loss: 54894.7409 - Avg Loss: 159.5777\n",
            "Epoch [17/50] - Batch loss: 155.8454 - Epoch Loss: 55050.5863 - Avg Loss: 159.5669\n",
            "Epoch [17/50] - Batch loss: 166.7966 - Epoch Loss: 55217.3829 - Avg Loss: 159.5878\n",
            "Epoch [17/50] - Batch loss: 157.3057 - Epoch Loss: 55374.6886 - Avg Loss: 159.5812\n",
            "Epoch [17/50] - Batch loss: 153.1421 - Epoch Loss: 55527.8308 - Avg Loss: 159.5627\n",
            "Epoch [17/50] - Batch loss: 159.9891 - Epoch Loss: 55687.8199 - Avg Loss: 159.5640\n",
            "Epoch [17/50] - Batch loss: 152.1625 - Epoch Loss: 55839.9824 - Avg Loss: 159.5428\n",
            "Epoch [17/50] - Batch loss: 155.9300 - Epoch Loss: 55995.9124 - Avg Loss: 159.5325\n",
            "Epoch [17/50] - Batch loss: 167.8647 - Epoch Loss: 56163.7771 - Avg Loss: 159.5562\n",
            "Epoch [17/50] - Batch loss: 163.8096 - Epoch Loss: 56327.5867 - Avg Loss: 159.5682\n",
            "Epoch [17/50] - Batch loss: 157.8573 - Epoch Loss: 56485.4440 - Avg Loss: 159.5634\n",
            "Epoch [17/50] - Batch loss: 159.3144 - Epoch Loss: 56644.7584 - Avg Loss: 159.5627\n",
            "Epoch [17/50] - Batch loss: 154.9453 - Epoch Loss: 56799.7037 - Avg Loss: 159.5497\n",
            "Epoch [17/50] - Batch loss: 152.8455 - Epoch Loss: 56952.5492 - Avg Loss: 159.5310\n",
            "Epoch [17/50] - Batch loss: 153.9967 - Epoch Loss: 57106.5459 - Avg Loss: 159.5155\n",
            "Epoch [17/50] - Batch loss: 165.7430 - Epoch Loss: 57272.2889 - Avg Loss: 159.5328\n",
            "Epoch [17/50] - Batch loss: 160.1183 - Epoch Loss: 57432.4072 - Avg Loss: 159.5345\n",
            "Epoch [17/50] - Batch loss: 159.2765 - Epoch Loss: 57591.6837 - Avg Loss: 159.5337\n",
            "Epoch [17/50] - Batch loss: 161.2322 - Epoch Loss: 57752.9159 - Avg Loss: 159.5384\n",
            "Epoch [17/50] - Batch loss: 162.9655 - Epoch Loss: 57915.8813 - Avg Loss: 159.5479\n",
            "Epoch [17/50] - Batch loss: 159.1613 - Epoch Loss: 58075.0427 - Avg Loss: 159.5468\n",
            "Epoch [17/50] - Batch loss: 164.3531 - Epoch Loss: 58239.3958 - Avg Loss: 159.5600\n",
            "Epoch [17/50] - Batch loss: 161.1885 - Epoch Loss: 58400.5842 - Avg Loss: 159.5644\n",
            "Epoch [17/50] - Batch loss: 157.2752 - Epoch Loss: 58557.8594 - Avg Loss: 159.5582\n",
            "Epoch [17/50] - Batch loss: 158.4113 - Epoch Loss: 58716.2708 - Avg Loss: 159.5551\n",
            "Epoch [17/50] - Batch loss: 160.5991 - Epoch Loss: 58876.8699 - Avg Loss: 159.5579\n",
            "Epoch [17/50] - Batch loss: 162.3042 - Epoch Loss: 59039.1741 - Avg Loss: 159.5653\n",
            "Epoch [17/50] - Batch loss: 168.3047 - Epoch Loss: 59207.4788 - Avg Loss: 159.5889\n",
            "Epoch [17/50] - Batch loss: 162.3102 - Epoch Loss: 59369.7890 - Avg Loss: 159.5962\n",
            "Epoch [17/50] - Batch loss: 158.9710 - Epoch Loss: 59528.7600 - Avg Loss: 159.5945\n",
            "Epoch [17/50] - Batch loss: 162.5623 - Epoch Loss: 59691.3223 - Avg Loss: 159.6025\n",
            "Epoch [17/50] - Batch loss: 159.6555 - Epoch Loss: 59850.9778 - Avg Loss: 159.6026\n",
            "Epoch [17/50] - Batch loss: 159.2334 - Epoch Loss: 60010.2111 - Avg Loss: 159.6016\n",
            "Epoch [17/50] - Batch loss: 164.3854 - Epoch Loss: 60174.5965 - Avg Loss: 159.6143\n",
            "Epoch [17/50] - Batch loss: 161.8893 - Epoch Loss: 60336.4858 - Avg Loss: 159.6203\n",
            "Epoch [17/50] - Batch loss: 157.1281 - Epoch Loss: 60493.6139 - Avg Loss: 159.6138\n",
            "Epoch [17/50] - Batch loss: 158.7482 - Epoch Loss: 60652.3621 - Avg Loss: 159.6115\n",
            "Epoch [17/50] - Batch loss: 164.4709 - Epoch Loss: 60816.8330 - Avg Loss: 159.6242\n",
            "Epoch [17/50] - Batch loss: 159.5733 - Epoch Loss: 60976.4063 - Avg Loss: 159.6241\n",
            "Epoch [17/50] - Batch loss: 160.9395 - Epoch Loss: 61137.3458 - Avg Loss: 159.6275\n",
            "Epoch [17/50] - Batch loss: 149.7202 - Epoch Loss: 61287.0660 - Avg Loss: 159.6017\n",
            "Epoch [17/50] - Batch loss: 158.0312 - Epoch Loss: 61445.0972 - Avg Loss: 159.5977\n",
            "Epoch [17/50] - Batch loss: 160.4344 - Epoch Loss: 61605.5316 - Avg Loss: 159.5998\n",
            "Epoch [17/50] - Batch loss: 159.3266 - Epoch Loss: 61764.8582 - Avg Loss: 159.5991\n",
            "Epoch [17/50] - Batch loss: 159.9024 - Epoch Loss: 61924.7607 - Avg Loss: 159.5999\n",
            "Epoch [17/50] - Batch loss: 158.8098 - Epoch Loss: 62083.5705 - Avg Loss: 159.5979\n",
            "Epoch [17/50] - Batch loss: 162.1269 - Epoch Loss: 62245.6974 - Avg Loss: 159.6044\n",
            "Epoch [17/50] - Batch loss: 168.2053 - Epoch Loss: 62413.9027 - Avg Loss: 159.6263\n",
            "Epoch [17/50] - Batch loss: 158.8982 - Epoch Loss: 62572.8009 - Avg Loss: 159.6245\n",
            "Epoch [17/50] - Batch loss: 168.3990 - Epoch Loss: 62741.1999 - Avg Loss: 159.6468\n",
            "Epoch [17/50] - Batch loss: 173.9398 - Epoch Loss: 62915.1397 - Avg Loss: 159.6831\n",
            "Epoch [17/50] - Batch loss: 150.6833 - Epoch Loss: 63065.8230 - Avg Loss: 159.6603\n",
            "Epoch [17/50] - Batch loss: 163.6730 - Epoch Loss: 63229.4960 - Avg Loss: 159.6704\n",
            "Epoch [17/50] - Batch loss: 163.0193 - Epoch Loss: 63392.5153 - Avg Loss: 159.6789\n",
            "Epoch [17/50] - Batch loss: 156.3124 - Epoch Loss: 63548.8277 - Avg Loss: 159.6704\n",
            "Epoch [17/50] - Batch loss: 152.3758 - Epoch Loss: 63701.2035 - Avg Loss: 159.6521\n",
            "Epoch [17/50] - Batch loss: 155.7214 - Epoch Loss: 63856.9249 - Avg Loss: 159.6423\n",
            "Epoch [17/50] - Batch loss: 155.1475 - Epoch Loss: 64012.0724 - Avg Loss: 159.6311\n",
            "Epoch [17/50] - Batch loss: 151.6785 - Epoch Loss: 64163.7509 - Avg Loss: 159.6113\n",
            "Epoch [17/50] - Batch loss: 160.2717 - Epoch Loss: 64324.0225 - Avg Loss: 159.6130\n",
            "Epoch [17/50] - Batch loss: 161.1546 - Epoch Loss: 64485.1771 - Avg Loss: 159.6168\n",
            "Epoch [17/50] - Batch loss: 164.3497 - Epoch Loss: 64649.5268 - Avg Loss: 159.6285\n",
            "Epoch [17/50] - Batch loss: 154.7648 - Epoch Loss: 64804.2916 - Avg Loss: 159.6165\n",
            "Epoch [17/50] - Batch loss: 156.5826 - Epoch Loss: 64960.8741 - Avg Loss: 159.6090\n",
            "Epoch [17/50] - Batch loss: 165.0592 - Epoch Loss: 65125.9333 - Avg Loss: 159.6224\n",
            "Epoch [17/50] - Batch loss: 160.3846 - Epoch Loss: 65286.3179 - Avg Loss: 159.6242\n",
            "Epoch [17/50] - Batch loss: 161.7839 - Epoch Loss: 65448.1018 - Avg Loss: 159.6295\n",
            "Epoch [17/50] - Batch loss: 162.6288 - Epoch Loss: 65610.7307 - Avg Loss: 159.6368\n",
            "Epoch [17/50] - Batch loss: 165.9127 - Epoch Loss: 65776.6433 - Avg Loss: 159.6520\n",
            "Epoch [17/50] - Batch loss: 164.7724 - Epoch Loss: 65941.4158 - Avg Loss: 159.6644\n",
            "Epoch [17/50] - Batch loss: 158.5667 - Epoch Loss: 66099.9825 - Avg Loss: 159.6618\n",
            "Epoch [17/50] - Batch loss: 158.1308 - Epoch Loss: 66258.1133 - Avg Loss: 159.6581\n",
            "Epoch [17/50] - Batch loss: 160.1580 - Epoch Loss: 66418.2713 - Avg Loss: 159.6593\n",
            "Epoch [17/50] - Batch loss: 153.2724 - Epoch Loss: 66571.5437 - Avg Loss: 159.6440\n",
            "Epoch [17/50] - Batch loss: 157.2350 - Epoch Loss: 66728.7787 - Avg Loss: 159.6382\n",
            "Epoch [17/50] - Batch loss: 162.1710 - Epoch Loss: 66890.9498 - Avg Loss: 159.6443\n",
            "Epoch [17/50] - Batch loss: 158.0015 - Epoch Loss: 67048.9512 - Avg Loss: 159.6404\n",
            "Epoch [17/50] - Batch loss: 159.5320 - Epoch Loss: 67208.4832 - Avg Loss: 159.6401\n",
            "Epoch [17/50] - Batch loss: 161.4868 - Epoch Loss: 67369.9700 - Avg Loss: 159.6445\n",
            "Epoch [17/50] - Batch loss: 154.9361 - Epoch Loss: 67524.9061 - Avg Loss: 159.6333\n",
            "Epoch [17/50] - Batch loss: 163.3232 - Epoch Loss: 67688.2293 - Avg Loss: 159.6421\n",
            "Epoch [17/50] - Batch loss: 161.4977 - Epoch Loss: 67849.7271 - Avg Loss: 159.6464\n",
            "Epoch [17/50] - Batch loss: 169.1064 - Epoch Loss: 68018.8335 - Avg Loss: 159.6686\n",
            "Epoch [17/50] - Batch loss: 162.7058 - Epoch Loss: 68181.5393 - Avg Loss: 159.6757\n",
            "Epoch [17/50] - Batch loss: 156.7114 - Epoch Loss: 68338.2507 - Avg Loss: 159.6688\n",
            "Epoch [17/50] - Batch loss: 158.1124 - Epoch Loss: 68496.3631 - Avg Loss: 159.6652\n",
            "Epoch [17/50] - Batch loss: 154.3145 - Epoch Loss: 68650.6777 - Avg Loss: 159.6527\n",
            "Epoch [17/50] - Batch loss: 156.3833 - Epoch Loss: 68807.0610 - Avg Loss: 159.6452\n",
            "Epoch [17/50] - Batch loss: 170.0405 - Epoch Loss: 68977.1014 - Avg Loss: 159.6692\n",
            "Epoch [17/50] - Batch loss: 158.9224 - Epoch Loss: 69136.0238 - Avg Loss: 159.6675\n",
            "Epoch [17/50] - Batch loss: 155.8125 - Epoch Loss: 69291.8363 - Avg Loss: 159.6586\n",
            "Epoch [17/50] - Batch loss: 162.5621 - Epoch Loss: 69454.3984 - Avg Loss: 159.6653\n",
            "Epoch [17/50] - Batch loss: 159.1518 - Epoch Loss: 69613.5502 - Avg Loss: 159.6641\n",
            "Epoch [17/50] - Batch loss: 164.4253 - Epoch Loss: 69777.9755 - Avg Loss: 159.6750\n",
            "Epoch [17/50] - Batch loss: 153.5529 - Epoch Loss: 69931.5284 - Avg Loss: 159.6610\n",
            "Epoch [17/50] - Batch loss: 157.8113 - Epoch Loss: 70089.3397 - Avg Loss: 159.6568\n",
            "Epoch [17/50] - Batch loss: 160.5822 - Epoch Loss: 70249.9220 - Avg Loss: 159.6589\n",
            "Epoch [17/50] - Batch loss: 158.1743 - Epoch Loss: 70408.0962 - Avg Loss: 159.6555\n",
            "Epoch [17/50] - Batch loss: 156.3340 - Epoch Loss: 70564.4302 - Avg Loss: 159.6480\n",
            "Epoch [17/50] - Batch loss: 153.8501 - Epoch Loss: 70718.2803 - Avg Loss: 159.6349\n",
            "Epoch [17/50] - Batch loss: 156.8429 - Epoch Loss: 70875.1232 - Avg Loss: 159.6287\n",
            "Epoch [17/50] - Batch loss: 164.5101 - Epoch Loss: 71039.6333 - Avg Loss: 159.6396\n",
            "Epoch [17/50] - Batch loss: 150.6005 - Epoch Loss: 71190.2339 - Avg Loss: 159.6194\n",
            "Epoch [17/50] - Batch loss: 161.9201 - Epoch Loss: 71352.1540 - Avg Loss: 159.6245\n",
            "Epoch [17/50] - Batch loss: 160.1821 - Epoch Loss: 71512.3361 - Avg Loss: 159.6258\n",
            "Epoch [17/50] - Batch loss: 155.7900 - Epoch Loss: 71668.1261 - Avg Loss: 159.6172\n",
            "Epoch [17/50] - Batch loss: 154.7314 - Epoch Loss: 71822.8574 - Avg Loss: 159.6063\n",
            "Epoch [17/50] - Batch loss: 151.5625 - Epoch Loss: 71974.4199 - Avg Loss: 159.5885\n",
            "Epoch [17/50] - Batch loss: 153.4031 - Epoch Loss: 72127.8230 - Avg Loss: 159.5748\n",
            "Epoch [17/50] - Batch loss: 152.6178 - Epoch Loss: 72280.4408 - Avg Loss: 159.5595\n",
            "Epoch [17/50] - Batch loss: 156.4640 - Epoch Loss: 72436.9048 - Avg Loss: 159.5527\n",
            "Epoch [17/50] - Batch loss: 156.3226 - Epoch Loss: 72593.2274 - Avg Loss: 159.5456\n",
            "Epoch [17/50] - Batch loss: 162.0348 - Epoch Loss: 72755.2622 - Avg Loss: 159.5510\n",
            "Epoch [17/50] - Batch loss: 154.7517 - Epoch Loss: 72910.0139 - Avg Loss: 159.5405\n",
            "Epoch [17/50] - Batch loss: 162.9823 - Epoch Loss: 73072.9962 - Avg Loss: 159.5480\n",
            "Epoch [17/50] - Batch loss: 165.3137 - Epoch Loss: 73238.3099 - Avg Loss: 159.5606\n",
            "Epoch [17/50] - Batch loss: 164.1081 - Epoch Loss: 73402.4180 - Avg Loss: 159.5705\n",
            "Epoch [17/50] - Batch loss: 158.9673 - Epoch Loss: 73561.3853 - Avg Loss: 159.5692\n",
            "Epoch [17/50] - Batch loss: 165.0573 - Epoch Loss: 73726.4425 - Avg Loss: 159.5810\n",
            "Epoch [17/50] - Batch loss: 152.5336 - Epoch Loss: 73878.9762 - Avg Loss: 159.5658\n",
            "Epoch [17/50] - Batch loss: 155.8439 - Epoch Loss: 74034.8201 - Avg Loss: 159.5578\n",
            "Epoch [17/50] - Batch loss: 162.4815 - Epoch Loss: 74197.3016 - Avg Loss: 159.5641\n",
            "Epoch [17/50] - Batch loss: 165.2465 - Epoch Loss: 74362.5480 - Avg Loss: 159.5763\n",
            "Epoch [17/50] - Batch loss: 157.3181 - Epoch Loss: 74519.8661 - Avg Loss: 159.5714\n",
            "Epoch [17/50] - Batch loss: 157.9950 - Epoch Loss: 74677.8611 - Avg Loss: 159.5681\n",
            "Epoch [17/50] - Batch loss: 167.8766 - Epoch Loss: 74845.7377 - Avg Loss: 159.5858\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 18/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e70ce8253fa4190ada086ec0f578b16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/50] - Batch loss: 164.2543 - Epoch Loss: 164.2543 - Avg Loss: 164.2543\n",
            "Epoch [18/50] - Batch loss: 159.3770 - Epoch Loss: 323.6313 - Avg Loss: 161.8157\n",
            "Epoch [18/50] - Batch loss: 154.4932 - Epoch Loss: 478.1246 - Avg Loss: 159.3749\n",
            "Epoch [18/50] - Batch loss: 157.0175 - Epoch Loss: 635.1420 - Avg Loss: 158.7855\n",
            "Epoch [18/50] - Batch loss: 154.8710 - Epoch Loss: 790.0131 - Avg Loss: 158.0026\n",
            "Epoch [18/50] - Batch loss: 150.4485 - Epoch Loss: 940.4616 - Avg Loss: 156.7436\n",
            "Epoch [18/50] - Batch loss: 160.3927 - Epoch Loss: 1100.8543 - Avg Loss: 157.2649\n",
            "Epoch [18/50] - Batch loss: 159.6628 - Epoch Loss: 1260.5170 - Avg Loss: 157.5646\n",
            "Epoch [18/50] - Batch loss: 158.3754 - Epoch Loss: 1418.8924 - Avg Loss: 157.6547\n",
            "Epoch [18/50] - Batch loss: 162.9683 - Epoch Loss: 1581.8607 - Avg Loss: 158.1861\n",
            "Epoch [18/50] - Batch loss: 162.0037 - Epoch Loss: 1743.8643 - Avg Loss: 158.5331\n",
            "Epoch [18/50] - Batch loss: 158.3912 - Epoch Loss: 1902.2556 - Avg Loss: 158.5213\n",
            "Epoch [18/50] - Batch loss: 161.6133 - Epoch Loss: 2063.8689 - Avg Loss: 158.7591\n",
            "Epoch [18/50] - Batch loss: 155.4247 - Epoch Loss: 2219.2936 - Avg Loss: 158.5210\n",
            "Epoch [18/50] - Batch loss: 155.1467 - Epoch Loss: 2374.4403 - Avg Loss: 158.2960\n",
            "Epoch [18/50] - Batch loss: 156.7576 - Epoch Loss: 2531.1979 - Avg Loss: 158.1999\n",
            "Epoch [18/50] - Batch loss: 159.3090 - Epoch Loss: 2690.5069 - Avg Loss: 158.2651\n",
            "Epoch [18/50] - Batch loss: 154.3779 - Epoch Loss: 2844.8847 - Avg Loss: 158.0492\n",
            "Epoch [18/50] - Batch loss: 150.4687 - Epoch Loss: 2995.3535 - Avg Loss: 157.6502\n",
            "Epoch [18/50] - Batch loss: 154.0098 - Epoch Loss: 3149.3632 - Avg Loss: 157.4682\n",
            "Epoch [18/50] - Batch loss: 156.7718 - Epoch Loss: 3306.1350 - Avg Loss: 157.4350\n",
            "Epoch [18/50] - Batch loss: 160.5787 - Epoch Loss: 3466.7137 - Avg Loss: 157.5779\n",
            "Epoch [18/50] - Batch loss: 158.8522 - Epoch Loss: 3625.5659 - Avg Loss: 157.6333\n",
            "Epoch [18/50] - Batch loss: 157.1949 - Epoch Loss: 3782.7608 - Avg Loss: 157.6150\n",
            "Epoch [18/50] - Batch loss: 155.2738 - Epoch Loss: 3938.0346 - Avg Loss: 157.5214\n",
            "Epoch [18/50] - Batch loss: 164.2094 - Epoch Loss: 4102.2440 - Avg Loss: 157.7786\n",
            "Epoch [18/50] - Batch loss: 163.3854 - Epoch Loss: 4265.6294 - Avg Loss: 157.9863\n",
            "Epoch [18/50] - Batch loss: 164.1739 - Epoch Loss: 4429.8033 - Avg Loss: 158.2073\n",
            "Epoch [18/50] - Batch loss: 152.5128 - Epoch Loss: 4582.3161 - Avg Loss: 158.0109\n",
            "Epoch [18/50] - Batch loss: 159.6878 - Epoch Loss: 4742.0039 - Avg Loss: 158.0668\n",
            "Epoch [18/50] - Batch loss: 158.9063 - Epoch Loss: 4900.9102 - Avg Loss: 158.0939\n",
            "Epoch [18/50] - Batch loss: 160.8018 - Epoch Loss: 5061.7121 - Avg Loss: 158.1785\n",
            "Epoch [18/50] - Batch loss: 156.6030 - Epoch Loss: 5218.3151 - Avg Loss: 158.1308\n",
            "Epoch [18/50] - Batch loss: 160.8085 - Epoch Loss: 5379.1236 - Avg Loss: 158.2095\n",
            "Epoch [18/50] - Batch loss: 156.7298 - Epoch Loss: 5535.8534 - Avg Loss: 158.1672\n",
            "Epoch [18/50] - Batch loss: 158.9002 - Epoch Loss: 5694.7536 - Avg Loss: 158.1876\n",
            "Epoch [18/50] - Batch loss: 157.9454 - Epoch Loss: 5852.6990 - Avg Loss: 158.1811\n",
            "Epoch [18/50] - Batch loss: 159.2438 - Epoch Loss: 6011.9428 - Avg Loss: 158.2090\n",
            "Epoch [18/50] - Batch loss: 160.5404 - Epoch Loss: 6172.4832 - Avg Loss: 158.2688\n",
            "Epoch [18/50] - Batch loss: 154.1341 - Epoch Loss: 6326.6173 - Avg Loss: 158.1654\n",
            "Epoch [18/50] - Batch loss: 162.7881 - Epoch Loss: 6489.4054 - Avg Loss: 158.2782\n",
            "Epoch [18/50] - Batch loss: 167.1817 - Epoch Loss: 6656.5871 - Avg Loss: 158.4902\n",
            "Epoch [18/50] - Batch loss: 161.4238 - Epoch Loss: 6818.0109 - Avg Loss: 158.5584\n",
            "Epoch [18/50] - Batch loss: 150.9897 - Epoch Loss: 6969.0006 - Avg Loss: 158.3864\n",
            "Epoch [18/50] - Batch loss: 158.2842 - Epoch Loss: 7127.2848 - Avg Loss: 158.3841\n",
            "Epoch [18/50] - Batch loss: 164.2499 - Epoch Loss: 7291.5348 - Avg Loss: 158.5116\n",
            "Epoch [18/50] - Batch loss: 156.7774 - Epoch Loss: 7448.3121 - Avg Loss: 158.4747\n",
            "Epoch [18/50] - Batch loss: 155.5686 - Epoch Loss: 7603.8807 - Avg Loss: 158.4142\n",
            "Epoch [18/50] - Batch loss: 158.3900 - Epoch Loss: 7762.2707 - Avg Loss: 158.4137\n",
            "Epoch [18/50] - Batch loss: 163.1714 - Epoch Loss: 7925.4421 - Avg Loss: 158.5088\n",
            "Epoch [18/50] - Batch loss: 161.6904 - Epoch Loss: 8087.1325 - Avg Loss: 158.5712\n",
            "Epoch [18/50] - Batch loss: 160.3640 - Epoch Loss: 8247.4965 - Avg Loss: 158.6057\n",
            "Epoch [18/50] - Batch loss: 153.5260 - Epoch Loss: 8401.0225 - Avg Loss: 158.5099\n",
            "Epoch [18/50] - Batch loss: 163.7863 - Epoch Loss: 8564.8088 - Avg Loss: 158.6076\n",
            "Epoch [18/50] - Batch loss: 154.2195 - Epoch Loss: 8719.0283 - Avg Loss: 158.5278\n",
            "Epoch [18/50] - Batch loss: 161.3992 - Epoch Loss: 8880.4274 - Avg Loss: 158.5791\n",
            "Epoch [18/50] - Batch loss: 163.6612 - Epoch Loss: 9044.0886 - Avg Loss: 158.6682\n",
            "Epoch [18/50] - Batch loss: 164.1220 - Epoch Loss: 9208.2106 - Avg Loss: 158.7623\n",
            "Epoch [18/50] - Batch loss: 154.1393 - Epoch Loss: 9362.3499 - Avg Loss: 158.6839\n",
            "Epoch [18/50] - Batch loss: 153.2808 - Epoch Loss: 9515.6307 - Avg Loss: 158.5938\n",
            "Epoch [18/50] - Batch loss: 164.8628 - Epoch Loss: 9680.4935 - Avg Loss: 158.6966\n",
            "Epoch [18/50] - Batch loss: 163.5491 - Epoch Loss: 9844.0426 - Avg Loss: 158.7749\n",
            "Epoch [18/50] - Batch loss: 150.8861 - Epoch Loss: 9994.9288 - Avg Loss: 158.6497\n",
            "Epoch [18/50] - Batch loss: 158.7394 - Epoch Loss: 10153.6681 - Avg Loss: 158.6511\n",
            "Epoch [18/50] - Batch loss: 160.6382 - Epoch Loss: 10314.3063 - Avg Loss: 158.6816\n",
            "Epoch [18/50] - Batch loss: 157.2163 - Epoch Loss: 10471.5226 - Avg Loss: 158.6594\n",
            "Epoch [18/50] - Batch loss: 154.2296 - Epoch Loss: 10625.7522 - Avg Loss: 158.5933\n",
            "Epoch [18/50] - Batch loss: 161.1730 - Epoch Loss: 10786.9252 - Avg Loss: 158.6313\n",
            "Epoch [18/50] - Batch loss: 154.6586 - Epoch Loss: 10941.5838 - Avg Loss: 158.5737\n",
            "Epoch [18/50] - Batch loss: 159.5735 - Epoch Loss: 11101.1573 - Avg Loss: 158.5880\n",
            "Epoch [18/50] - Batch loss: 161.5630 - Epoch Loss: 11262.7203 - Avg Loss: 158.6299\n",
            "Epoch [18/50] - Batch loss: 155.0282 - Epoch Loss: 11417.7486 - Avg Loss: 158.5798\n",
            "Epoch [18/50] - Batch loss: 157.6129 - Epoch Loss: 11575.3614 - Avg Loss: 158.5666\n",
            "Epoch [18/50] - Batch loss: 156.2204 - Epoch Loss: 11731.5818 - Avg Loss: 158.5349\n",
            "Epoch [18/50] - Batch loss: 162.3880 - Epoch Loss: 11893.9698 - Avg Loss: 158.5863\n",
            "Epoch [18/50] - Batch loss: 156.2557 - Epoch Loss: 12050.2255 - Avg Loss: 158.5556\n",
            "Epoch [18/50] - Batch loss: 165.9220 - Epoch Loss: 12216.1475 - Avg Loss: 158.6513\n",
            "Epoch [18/50] - Batch loss: 162.3149 - Epoch Loss: 12378.4624 - Avg Loss: 158.6982\n",
            "Epoch [18/50] - Batch loss: 157.8055 - Epoch Loss: 12536.2679 - Avg Loss: 158.6869\n",
            "Epoch [18/50] - Batch loss: 159.5703 - Epoch Loss: 12695.8382 - Avg Loss: 158.6980\n",
            "Epoch [18/50] - Batch loss: 155.0156 - Epoch Loss: 12850.8539 - Avg Loss: 158.6525\n",
            "Epoch [18/50] - Batch loss: 158.8617 - Epoch Loss: 13009.7155 - Avg Loss: 158.6551\n",
            "Epoch [18/50] - Batch loss: 157.5935 - Epoch Loss: 13167.3091 - Avg Loss: 158.6423\n",
            "Epoch [18/50] - Batch loss: 163.4123 - Epoch Loss: 13330.7214 - Avg Loss: 158.6991\n",
            "Epoch [18/50] - Batch loss: 166.4350 - Epoch Loss: 13497.1564 - Avg Loss: 158.7901\n",
            "Epoch [18/50] - Batch loss: 154.8323 - Epoch Loss: 13651.9887 - Avg Loss: 158.7441\n",
            "Epoch [18/50] - Batch loss: 161.7479 - Epoch Loss: 13813.7366 - Avg Loss: 158.7786\n",
            "Epoch [18/50] - Batch loss: 151.8679 - Epoch Loss: 13965.6045 - Avg Loss: 158.7001\n",
            "Epoch [18/50] - Batch loss: 148.8397 - Epoch Loss: 14114.4442 - Avg Loss: 158.5893\n",
            "Epoch [18/50] - Batch loss: 163.4804 - Epoch Loss: 14277.9246 - Avg Loss: 158.6436\n",
            "Epoch [18/50] - Batch loss: 158.6264 - Epoch Loss: 14436.5510 - Avg Loss: 158.6434\n",
            "Epoch [18/50] - Batch loss: 165.0097 - Epoch Loss: 14601.5607 - Avg Loss: 158.7126\n",
            "Epoch [18/50] - Batch loss: 161.2222 - Epoch Loss: 14762.7829 - Avg Loss: 158.7396\n",
            "Epoch [18/50] - Batch loss: 160.5279 - Epoch Loss: 14923.3107 - Avg Loss: 158.7586\n",
            "Epoch [18/50] - Batch loss: 152.2018 - Epoch Loss: 15075.5125 - Avg Loss: 158.6896\n",
            "Epoch [18/50] - Batch loss: 166.0429 - Epoch Loss: 15241.5554 - Avg Loss: 158.7662\n",
            "Epoch [18/50] - Batch loss: 160.7279 - Epoch Loss: 15402.2833 - Avg Loss: 158.7864\n",
            "Epoch [18/50] - Batch loss: 160.1515 - Epoch Loss: 15562.4348 - Avg Loss: 158.8004\n",
            "Epoch [18/50] - Batch loss: 161.5495 - Epoch Loss: 15723.9843 - Avg Loss: 158.8281\n",
            "Epoch [18/50] - Batch loss: 163.5884 - Epoch Loss: 15887.5727 - Avg Loss: 158.8757\n",
            "Epoch [18/50] - Batch loss: 164.6305 - Epoch Loss: 16052.2032 - Avg Loss: 158.9327\n",
            "Epoch [18/50] - Batch loss: 159.1804 - Epoch Loss: 16211.3836 - Avg Loss: 158.9351\n",
            "Epoch [18/50] - Batch loss: 154.0824 - Epoch Loss: 16365.4660 - Avg Loss: 158.8880\n",
            "Epoch [18/50] - Batch loss: 157.4424 - Epoch Loss: 16522.9085 - Avg Loss: 158.8741\n",
            "Epoch [18/50] - Batch loss: 155.4078 - Epoch Loss: 16678.3162 - Avg Loss: 158.8411\n",
            "Epoch [18/50] - Batch loss: 160.4640 - Epoch Loss: 16838.7803 - Avg Loss: 158.8564\n",
            "Epoch [18/50] - Batch loss: 160.3751 - Epoch Loss: 16999.1553 - Avg Loss: 158.8706\n",
            "Epoch [18/50] - Batch loss: 157.5091 - Epoch Loss: 17156.6645 - Avg Loss: 158.8580\n",
            "Epoch [18/50] - Batch loss: 159.7941 - Epoch Loss: 17316.4585 - Avg Loss: 158.8666\n",
            "Epoch [18/50] - Batch loss: 162.2558 - Epoch Loss: 17478.7144 - Avg Loss: 158.8974\n",
            "Epoch [18/50] - Batch loss: 158.5071 - Epoch Loss: 17637.2215 - Avg Loss: 158.8939\n",
            "Epoch [18/50] - Batch loss: 156.8336 - Epoch Loss: 17794.0551 - Avg Loss: 158.8755\n",
            "Epoch [18/50] - Batch loss: 160.3398 - Epoch Loss: 17954.3949 - Avg Loss: 158.8885\n",
            "Epoch [18/50] - Batch loss: 160.0470 - Epoch Loss: 18114.4419 - Avg Loss: 158.8986\n",
            "Epoch [18/50] - Batch loss: 159.5339 - Epoch Loss: 18273.9758 - Avg Loss: 158.9041\n",
            "Epoch [18/50] - Batch loss: 156.7282 - Epoch Loss: 18430.7040 - Avg Loss: 158.8854\n",
            "Epoch [18/50] - Batch loss: 152.6918 - Epoch Loss: 18583.3958 - Avg Loss: 158.8324\n",
            "Epoch [18/50] - Batch loss: 161.7144 - Epoch Loss: 18745.1102 - Avg Loss: 158.8569\n",
            "Epoch [18/50] - Batch loss: 153.5735 - Epoch Loss: 18898.6837 - Avg Loss: 158.8125\n",
            "Epoch [18/50] - Batch loss: 165.0995 - Epoch Loss: 19063.7832 - Avg Loss: 158.8649\n",
            "Epoch [18/50] - Batch loss: 160.1138 - Epoch Loss: 19223.8970 - Avg Loss: 158.8752\n",
            "Epoch [18/50] - Batch loss: 153.2320 - Epoch Loss: 19377.1290 - Avg Loss: 158.8289\n",
            "Epoch [18/50] - Batch loss: 159.5566 - Epoch Loss: 19536.6856 - Avg Loss: 158.8348\n",
            "Epoch [18/50] - Batch loss: 161.6006 - Epoch Loss: 19698.2862 - Avg Loss: 158.8571\n",
            "Epoch [18/50] - Batch loss: 154.6835 - Epoch Loss: 19852.9697 - Avg Loss: 158.8238\n",
            "Epoch [18/50] - Batch loss: 162.8585 - Epoch Loss: 20015.8282 - Avg Loss: 158.8558\n",
            "Epoch [18/50] - Batch loss: 157.7316 - Epoch Loss: 20173.5598 - Avg Loss: 158.8469\n",
            "Epoch [18/50] - Batch loss: 156.3175 - Epoch Loss: 20329.8773 - Avg Loss: 158.8272\n",
            "Epoch [18/50] - Batch loss: 168.7651 - Epoch Loss: 20498.6424 - Avg Loss: 158.9042\n",
            "Epoch [18/50] - Batch loss: 161.3957 - Epoch Loss: 20660.0381 - Avg Loss: 158.9234\n",
            "Epoch [18/50] - Batch loss: 164.2099 - Epoch Loss: 20824.2480 - Avg Loss: 158.9637\n",
            "Epoch [18/50] - Batch loss: 162.6464 - Epoch Loss: 20986.8945 - Avg Loss: 158.9916\n",
            "Epoch [18/50] - Batch loss: 160.5752 - Epoch Loss: 21147.4696 - Avg Loss: 159.0035\n",
            "Epoch [18/50] - Batch loss: 162.9237 - Epoch Loss: 21310.3933 - Avg Loss: 159.0328\n",
            "Epoch [18/50] - Batch loss: 151.4050 - Epoch Loss: 21461.7983 - Avg Loss: 158.9763\n",
            "Epoch [18/50] - Batch loss: 161.9933 - Epoch Loss: 21623.7916 - Avg Loss: 158.9985\n",
            "Epoch [18/50] - Batch loss: 160.8137 - Epoch Loss: 21784.6054 - Avg Loss: 159.0117\n",
            "Epoch [18/50] - Batch loss: 161.3440 - Epoch Loss: 21945.9493 - Avg Loss: 159.0286\n",
            "Epoch [18/50] - Batch loss: 162.5513 - Epoch Loss: 22108.5006 - Avg Loss: 159.0540\n",
            "Epoch [18/50] - Batch loss: 164.0906 - Epoch Loss: 22272.5912 - Avg Loss: 159.0899\n",
            "Epoch [18/50] - Batch loss: 160.4291 - Epoch Loss: 22433.0203 - Avg Loss: 159.0994\n",
            "Epoch [18/50] - Batch loss: 161.0081 - Epoch Loss: 22594.0284 - Avg Loss: 159.1129\n",
            "Epoch [18/50] - Batch loss: 162.4807 - Epoch Loss: 22756.5090 - Avg Loss: 159.1364\n",
            "Epoch [18/50] - Batch loss: 157.4006 - Epoch Loss: 22913.9096 - Avg Loss: 159.1244\n",
            "Epoch [18/50] - Batch loss: 161.8135 - Epoch Loss: 23075.7231 - Avg Loss: 159.1429\n",
            "Epoch [18/50] - Batch loss: 160.4501 - Epoch Loss: 23236.1731 - Avg Loss: 159.1519\n",
            "Epoch [18/50] - Batch loss: 167.2137 - Epoch Loss: 23403.3868 - Avg Loss: 159.2067\n",
            "Epoch [18/50] - Batch loss: 158.1458 - Epoch Loss: 23561.5326 - Avg Loss: 159.1995\n",
            "Epoch [18/50] - Batch loss: 163.1887 - Epoch Loss: 23724.7214 - Avg Loss: 159.2263\n",
            "Epoch [18/50] - Batch loss: 165.7721 - Epoch Loss: 23890.4934 - Avg Loss: 159.2700\n",
            "Epoch [18/50] - Batch loss: 159.6092 - Epoch Loss: 24050.1026 - Avg Loss: 159.2722\n",
            "Epoch [18/50] - Batch loss: 156.2307 - Epoch Loss: 24206.3333 - Avg Loss: 159.2522\n",
            "Epoch [18/50] - Batch loss: 164.9763 - Epoch Loss: 24371.3096 - Avg Loss: 159.2896\n",
            "Epoch [18/50] - Batch loss: 156.2819 - Epoch Loss: 24527.5915 - Avg Loss: 159.2701\n",
            "Epoch [18/50] - Batch loss: 159.3413 - Epoch Loss: 24686.9328 - Avg Loss: 159.2705\n",
            "Epoch [18/50] - Batch loss: 159.0817 - Epoch Loss: 24846.0145 - Avg Loss: 159.2693\n",
            "Epoch [18/50] - Batch loss: 157.8538 - Epoch Loss: 25003.8683 - Avg Loss: 159.2603\n",
            "Epoch [18/50] - Batch loss: 165.2295 - Epoch Loss: 25169.0978 - Avg Loss: 159.2981\n",
            "Epoch [18/50] - Batch loss: 167.0582 - Epoch Loss: 25336.1559 - Avg Loss: 159.3469\n",
            "Epoch [18/50] - Batch loss: 153.2928 - Epoch Loss: 25489.4487 - Avg Loss: 159.3091\n",
            "Epoch [18/50] - Batch loss: 162.6837 - Epoch Loss: 25652.1325 - Avg Loss: 159.3300\n",
            "Epoch [18/50] - Batch loss: 159.7798 - Epoch Loss: 25811.9123 - Avg Loss: 159.3328\n",
            "Epoch [18/50] - Batch loss: 166.5221 - Epoch Loss: 25978.4343 - Avg Loss: 159.3769\n",
            "Epoch [18/50] - Batch loss: 164.2955 - Epoch Loss: 26142.7299 - Avg Loss: 159.4069\n",
            "Epoch [18/50] - Batch loss: 160.0518 - Epoch Loss: 26302.7817 - Avg Loss: 159.4108\n",
            "Epoch [18/50] - Batch loss: 161.9764 - Epoch Loss: 26464.7581 - Avg Loss: 159.4263\n",
            "Epoch [18/50] - Batch loss: 161.6073 - Epoch Loss: 26626.3654 - Avg Loss: 159.4393\n",
            "Epoch [18/50] - Batch loss: 162.6875 - Epoch Loss: 26789.0529 - Avg Loss: 159.4586\n",
            "Epoch [18/50] - Batch loss: 166.0867 - Epoch Loss: 26955.1396 - Avg Loss: 159.4979\n",
            "Epoch [18/50] - Batch loss: 159.6416 - Epoch Loss: 27114.7812 - Avg Loss: 159.4987\n",
            "Epoch [18/50] - Batch loss: 173.3219 - Epoch Loss: 27288.1030 - Avg Loss: 159.5795\n",
            "Epoch [18/50] - Batch loss: 169.1673 - Epoch Loss: 27457.2703 - Avg Loss: 159.6353\n",
            "Epoch [18/50] - Batch loss: 156.1355 - Epoch Loss: 27613.4058 - Avg Loss: 159.6151\n",
            "Epoch [18/50] - Batch loss: 167.0943 - Epoch Loss: 27780.5001 - Avg Loss: 159.6580\n",
            "Epoch [18/50] - Batch loss: 162.8537 - Epoch Loss: 27943.3539 - Avg Loss: 159.6763\n",
            "Epoch [18/50] - Batch loss: 167.9421 - Epoch Loss: 28111.2960 - Avg Loss: 159.7233\n",
            "Epoch [18/50] - Batch loss: 167.1709 - Epoch Loss: 28278.4669 - Avg Loss: 159.7653\n",
            "Epoch [18/50] - Batch loss: 161.1132 - Epoch Loss: 28439.5801 - Avg Loss: 159.7729\n",
            "Epoch [18/50] - Batch loss: 155.5004 - Epoch Loss: 28595.0806 - Avg Loss: 159.7491\n",
            "Epoch [18/50] - Batch loss: 160.8289 - Epoch Loss: 28755.9095 - Avg Loss: 159.7551\n",
            "Epoch [18/50] - Batch loss: 165.7872 - Epoch Loss: 28921.6967 - Avg Loss: 159.7884\n",
            "Epoch [18/50] - Batch loss: 155.9911 - Epoch Loss: 29077.6878 - Avg Loss: 159.7675\n",
            "Epoch [18/50] - Batch loss: 158.1674 - Epoch Loss: 29235.8552 - Avg Loss: 159.7588\n",
            "Epoch [18/50] - Batch loss: 164.8019 - Epoch Loss: 29400.6571 - Avg Loss: 159.7862\n",
            "Epoch [18/50] - Batch loss: 160.0578 - Epoch Loss: 29560.7149 - Avg Loss: 159.7876\n",
            "Epoch [18/50] - Batch loss: 161.3454 - Epoch Loss: 29722.0603 - Avg Loss: 159.7960\n",
            "Epoch [18/50] - Batch loss: 158.6703 - Epoch Loss: 29880.7306 - Avg Loss: 159.7900\n",
            "Epoch [18/50] - Batch loss: 154.2790 - Epoch Loss: 30035.0097 - Avg Loss: 159.7607\n",
            "Epoch [18/50] - Batch loss: 160.2508 - Epoch Loss: 30195.2605 - Avg Loss: 159.7633\n",
            "Epoch [18/50] - Batch loss: 156.2106 - Epoch Loss: 30351.4711 - Avg Loss: 159.7446\n",
            "Epoch [18/50] - Batch loss: 161.6609 - Epoch Loss: 30513.1319 - Avg Loss: 159.7546\n",
            "Epoch [18/50] - Batch loss: 163.4807 - Epoch Loss: 30676.6126 - Avg Loss: 159.7740\n",
            "Epoch [18/50] - Batch loss: 151.1264 - Epoch Loss: 30827.7390 - Avg Loss: 159.7292\n",
            "Epoch [18/50] - Batch loss: 163.8965 - Epoch Loss: 30991.6355 - Avg Loss: 159.7507\n",
            "Epoch [18/50] - Batch loss: 159.3380 - Epoch Loss: 31150.9734 - Avg Loss: 159.7486\n",
            "Epoch [18/50] - Batch loss: 157.5465 - Epoch Loss: 31308.5199 - Avg Loss: 159.7373\n",
            "Epoch [18/50] - Batch loss: 165.8090 - Epoch Loss: 31474.3289 - Avg Loss: 159.7682\n",
            "Epoch [18/50] - Batch loss: 156.2236 - Epoch Loss: 31630.5526 - Avg Loss: 159.7503\n",
            "Epoch [18/50] - Batch loss: 161.9387 - Epoch Loss: 31792.4913 - Avg Loss: 159.7613\n",
            "Epoch [18/50] - Batch loss: 160.0829 - Epoch Loss: 31952.5742 - Avg Loss: 159.7629\n",
            "Epoch [18/50] - Batch loss: 142.7187 - Epoch Loss: 32095.2929 - Avg Loss: 159.6781\n",
            "Epoch [18/50] - Batch loss: 159.0172 - Epoch Loss: 32254.3101 - Avg Loss: 159.6748\n",
            "Epoch [18/50] - Batch loss: 165.7467 - Epoch Loss: 32420.0568 - Avg Loss: 159.7047\n",
            "Epoch [18/50] - Batch loss: 162.1035 - Epoch Loss: 32582.1603 - Avg Loss: 159.7165\n",
            "Epoch [18/50] - Batch loss: 165.6465 - Epoch Loss: 32747.8069 - Avg Loss: 159.7454\n",
            "Epoch [18/50] - Batch loss: 168.6745 - Epoch Loss: 32916.4814 - Avg Loss: 159.7887\n",
            "Epoch [18/50] - Batch loss: 160.4521 - Epoch Loss: 33076.9335 - Avg Loss: 159.7919\n",
            "Epoch [18/50] - Batch loss: 162.6567 - Epoch Loss: 33239.5902 - Avg Loss: 159.8057\n",
            "Epoch [18/50] - Batch loss: 166.0807 - Epoch Loss: 33405.6709 - Avg Loss: 159.8357\n",
            "Epoch [18/50] - Batch loss: 159.4637 - Epoch Loss: 33565.1346 - Avg Loss: 159.8340\n",
            "Epoch [18/50] - Batch loss: 154.3961 - Epoch Loss: 33719.5307 - Avg Loss: 159.8082\n",
            "Epoch [18/50] - Batch loss: 161.4478 - Epoch Loss: 33880.9785 - Avg Loss: 159.8159\n",
            "Epoch [18/50] - Batch loss: 153.2261 - Epoch Loss: 34034.2046 - Avg Loss: 159.7850\n",
            "Epoch [18/50] - Batch loss: 160.8155 - Epoch Loss: 34195.0201 - Avg Loss: 159.7898\n",
            "Epoch [18/50] - Batch loss: 156.3439 - Epoch Loss: 34351.3640 - Avg Loss: 159.7738\n",
            "Epoch [18/50] - Batch loss: 156.6246 - Epoch Loss: 34507.9886 - Avg Loss: 159.7592\n",
            "Epoch [18/50] - Batch loss: 155.9232 - Epoch Loss: 34663.9118 - Avg Loss: 159.7415\n",
            "Epoch [18/50] - Batch loss: 160.2536 - Epoch Loss: 34824.1654 - Avg Loss: 159.7439\n",
            "Epoch [18/50] - Batch loss: 167.4898 - Epoch Loss: 34991.6552 - Avg Loss: 159.7792\n",
            "Epoch [18/50] - Batch loss: 159.3508 - Epoch Loss: 35151.0060 - Avg Loss: 159.7773\n",
            "Epoch [18/50] - Batch loss: 165.0862 - Epoch Loss: 35316.0922 - Avg Loss: 159.8013\n",
            "Epoch [18/50] - Batch loss: 160.9737 - Epoch Loss: 35477.0659 - Avg Loss: 159.8066\n",
            "Epoch [18/50] - Batch loss: 152.4172 - Epoch Loss: 35629.4831 - Avg Loss: 159.7735\n",
            "Epoch [18/50] - Batch loss: 156.3642 - Epoch Loss: 35785.8472 - Avg Loss: 159.7582\n",
            "Epoch [18/50] - Batch loss: 160.8954 - Epoch Loss: 35946.7426 - Avg Loss: 159.7633\n",
            "Epoch [18/50] - Batch loss: 166.2791 - Epoch Loss: 36113.0217 - Avg Loss: 159.7921\n",
            "Epoch [18/50] - Batch loss: 165.1457 - Epoch Loss: 36278.1674 - Avg Loss: 159.8157\n",
            "Epoch [18/50] - Batch loss: 161.4252 - Epoch Loss: 36439.5926 - Avg Loss: 159.8228\n",
            "Epoch [18/50] - Batch loss: 158.9875 - Epoch Loss: 36598.5801 - Avg Loss: 159.8191\n",
            "Epoch [18/50] - Batch loss: 156.8932 - Epoch Loss: 36755.4734 - Avg Loss: 159.8064\n",
            "Epoch [18/50] - Batch loss: 160.7565 - Epoch Loss: 36916.2299 - Avg Loss: 159.8105\n",
            "Epoch [18/50] - Batch loss: 159.2177 - Epoch Loss: 37075.4476 - Avg Loss: 159.8080\n",
            "Epoch [18/50] - Batch loss: 163.4615 - Epoch Loss: 37238.9091 - Avg Loss: 159.8236\n",
            "Epoch [18/50] - Batch loss: 164.5025 - Epoch Loss: 37403.4117 - Avg Loss: 159.8436\n",
            "Epoch [18/50] - Batch loss: 165.4173 - Epoch Loss: 37568.8290 - Avg Loss: 159.8674\n",
            "Epoch [18/50] - Batch loss: 155.2161 - Epoch Loss: 37724.0451 - Avg Loss: 159.8476\n",
            "Epoch [18/50] - Batch loss: 161.2169 - Epoch Loss: 37885.2621 - Avg Loss: 159.8534\n",
            "Epoch [18/50] - Batch loss: 152.6536 - Epoch Loss: 38037.9157 - Avg Loss: 159.8232\n",
            "Epoch [18/50] - Batch loss: 163.7226 - Epoch Loss: 38201.6382 - Avg Loss: 159.8395\n",
            "Epoch [18/50] - Batch loss: 163.3634 - Epoch Loss: 38365.0016 - Avg Loss: 159.8542\n",
            "Epoch [18/50] - Batch loss: 166.0376 - Epoch Loss: 38531.0392 - Avg Loss: 159.8798\n",
            "Epoch [18/50] - Batch loss: 158.1269 - Epoch Loss: 38689.1662 - Avg Loss: 159.8726\n",
            "Epoch [18/50] - Batch loss: 171.4751 - Epoch Loss: 38860.6412 - Avg Loss: 159.9203\n",
            "Epoch [18/50] - Batch loss: 166.2963 - Epoch Loss: 39026.9375 - Avg Loss: 159.9465\n",
            "Epoch [18/50] - Batch loss: 161.6898 - Epoch Loss: 39188.6274 - Avg Loss: 159.9536\n",
            "Epoch [18/50] - Batch loss: 160.6641 - Epoch Loss: 39349.2915 - Avg Loss: 159.9565\n",
            "Epoch [18/50] - Batch loss: 158.9023 - Epoch Loss: 39508.1937 - Avg Loss: 159.9522\n",
            "Epoch [18/50] - Batch loss: 159.0320 - Epoch Loss: 39667.2257 - Avg Loss: 159.9485\n",
            "Epoch [18/50] - Batch loss: 154.6826 - Epoch Loss: 39821.9083 - Avg Loss: 159.9273\n",
            "Epoch [18/50] - Batch loss: 160.3808 - Epoch Loss: 39982.2891 - Avg Loss: 159.9292\n",
            "Epoch [18/50] - Batch loss: 160.2269 - Epoch Loss: 40142.5160 - Avg Loss: 159.9303\n",
            "Epoch [18/50] - Batch loss: 168.5429 - Epoch Loss: 40311.0589 - Avg Loss: 159.9645\n",
            "Epoch [18/50] - Batch loss: 158.0601 - Epoch Loss: 40469.1190 - Avg Loss: 159.9570\n",
            "Epoch [18/50] - Batch loss: 168.2477 - Epoch Loss: 40637.3667 - Avg Loss: 159.9896\n",
            "Epoch [18/50] - Batch loss: 160.0913 - Epoch Loss: 40797.4580 - Avg Loss: 159.9900\n",
            "Epoch [18/50] - Batch loss: 157.2205 - Epoch Loss: 40954.6785 - Avg Loss: 159.9792\n",
            "Epoch [18/50] - Batch loss: 161.5457 - Epoch Loss: 41116.2242 - Avg Loss: 159.9853\n",
            "Epoch [18/50] - Batch loss: 159.8443 - Epoch Loss: 41276.0684 - Avg Loss: 159.9848\n",
            "Epoch [18/50] - Batch loss: 160.3361 - Epoch Loss: 41436.4045 - Avg Loss: 159.9861\n",
            "Epoch [18/50] - Batch loss: 159.5383 - Epoch Loss: 41595.9428 - Avg Loss: 159.9844\n",
            "Epoch [18/50] - Batch loss: 156.6082 - Epoch Loss: 41752.5511 - Avg Loss: 159.9715\n",
            "Epoch [18/50] - Batch loss: 161.2461 - Epoch Loss: 41913.7972 - Avg Loss: 159.9763\n",
            "Epoch [18/50] - Batch loss: 163.1583 - Epoch Loss: 42076.9555 - Avg Loss: 159.9884\n",
            "Epoch [18/50] - Batch loss: 162.5901 - Epoch Loss: 42239.5455 - Avg Loss: 159.9983\n",
            "Epoch [18/50] - Batch loss: 164.8539 - Epoch Loss: 42404.3994 - Avg Loss: 160.0166\n",
            "Epoch [18/50] - Batch loss: 166.7686 - Epoch Loss: 42571.1680 - Avg Loss: 160.0420\n",
            "Epoch [18/50] - Batch loss: 154.7507 - Epoch Loss: 42725.9187 - Avg Loss: 160.0222\n",
            "Epoch [18/50] - Batch loss: 158.8174 - Epoch Loss: 42884.7361 - Avg Loss: 160.0177\n",
            "Epoch [18/50] - Batch loss: 158.3263 - Epoch Loss: 43043.0623 - Avg Loss: 160.0114\n",
            "Epoch [18/50] - Batch loss: 165.6367 - Epoch Loss: 43208.6990 - Avg Loss: 160.0322\n",
            "Epoch [18/50] - Batch loss: 166.4409 - Epoch Loss: 43375.1400 - Avg Loss: 160.0559\n",
            "Epoch [18/50] - Batch loss: 164.5349 - Epoch Loss: 43539.6749 - Avg Loss: 160.0723\n",
            "Epoch [18/50] - Batch loss: 161.3765 - Epoch Loss: 43701.0514 - Avg Loss: 160.0771\n",
            "Epoch [18/50] - Batch loss: 160.4971 - Epoch Loss: 43861.5485 - Avg Loss: 160.0786\n",
            "Epoch [18/50] - Batch loss: 160.8047 - Epoch Loss: 44022.3532 - Avg Loss: 160.0813\n",
            "Epoch [18/50] - Batch loss: 160.4076 - Epoch Loss: 44182.7607 - Avg Loss: 160.0825\n",
            "Epoch [18/50] - Batch loss: 166.5670 - Epoch Loss: 44349.3277 - Avg Loss: 160.1059\n",
            "Epoch [18/50] - Batch loss: 168.7583 - Epoch Loss: 44518.0860 - Avg Loss: 160.1370\n",
            "Epoch [18/50] - Batch loss: 162.6154 - Epoch Loss: 44680.7014 - Avg Loss: 160.1459\n",
            "Epoch [18/50] - Batch loss: 157.0565 - Epoch Loss: 44837.7579 - Avg Loss: 160.1348\n",
            "Epoch [18/50] - Batch loss: 162.9140 - Epoch Loss: 45000.6720 - Avg Loss: 160.1447\n",
            "Epoch [18/50] - Batch loss: 163.3342 - Epoch Loss: 45164.0062 - Avg Loss: 160.1561\n",
            "Epoch [18/50] - Batch loss: 166.5133 - Epoch Loss: 45330.5195 - Avg Loss: 160.1785\n",
            "Epoch [18/50] - Batch loss: 165.3498 - Epoch Loss: 45495.8693 - Avg Loss: 160.1967\n",
            "Epoch [18/50] - Batch loss: 154.5974 - Epoch Loss: 45650.4667 - Avg Loss: 160.1771\n",
            "Epoch [18/50] - Batch loss: 158.0205 - Epoch Loss: 45808.4872 - Avg Loss: 160.1695\n",
            "Epoch [18/50] - Batch loss: 157.9541 - Epoch Loss: 45966.4413 - Avg Loss: 160.1618\n",
            "Epoch [18/50] - Batch loss: 163.3351 - Epoch Loss: 46129.7764 - Avg Loss: 160.1728\n",
            "Epoch [18/50] - Batch loss: 162.1127 - Epoch Loss: 46291.8890 - Avg Loss: 160.1795\n",
            "Epoch [18/50] - Batch loss: 162.2759 - Epoch Loss: 46454.1649 - Avg Loss: 160.1868\n",
            "Epoch [18/50] - Batch loss: 165.2053 - Epoch Loss: 46619.3702 - Avg Loss: 160.2040\n",
            "Epoch [18/50] - Batch loss: 155.9618 - Epoch Loss: 46775.3320 - Avg Loss: 160.1895\n",
            "Epoch [18/50] - Batch loss: 160.7034 - Epoch Loss: 46936.0354 - Avg Loss: 160.1912\n",
            "Epoch [18/50] - Batch loss: 164.8780 - Epoch Loss: 47100.9134 - Avg Loss: 160.2072\n",
            "Epoch [18/50] - Batch loss: 167.3659 - Epoch Loss: 47268.2793 - Avg Loss: 160.2315\n",
            "Epoch [18/50] - Batch loss: 152.6653 - Epoch Loss: 47420.9445 - Avg Loss: 160.2059\n",
            "Epoch [18/50] - Batch loss: 153.6444 - Epoch Loss: 47574.5889 - Avg Loss: 160.1838\n",
            "Epoch [18/50] - Batch loss: 167.6517 - Epoch Loss: 47742.2407 - Avg Loss: 160.2089\n",
            "Epoch [18/50] - Batch loss: 164.4064 - Epoch Loss: 47906.6471 - Avg Loss: 160.2229\n",
            "Epoch [18/50] - Batch loss: 157.7697 - Epoch Loss: 48064.4168 - Avg Loss: 160.2147\n",
            "Epoch [18/50] - Batch loss: 167.4003 - Epoch Loss: 48231.8172 - Avg Loss: 160.2386\n",
            "Epoch [18/50] - Batch loss: 162.3992 - Epoch Loss: 48394.2164 - Avg Loss: 160.2457\n",
            "Epoch [18/50] - Batch loss: 153.8582 - Epoch Loss: 48548.0745 - Avg Loss: 160.2247\n",
            "Epoch [18/50] - Batch loss: 157.0750 - Epoch Loss: 48705.1496 - Avg Loss: 160.2143\n",
            "Epoch [18/50] - Batch loss: 151.6774 - Epoch Loss: 48856.8270 - Avg Loss: 160.1863\n",
            "Epoch [18/50] - Batch loss: 158.9785 - Epoch Loss: 49015.8055 - Avg Loss: 160.1824\n",
            "Epoch [18/50] - Batch loss: 157.8886 - Epoch Loss: 49173.6940 - Avg Loss: 160.1749\n",
            "Epoch [18/50] - Batch loss: 162.9940 - Epoch Loss: 49336.6880 - Avg Loss: 160.1841\n",
            "Epoch [18/50] - Batch loss: 162.3150 - Epoch Loss: 49499.0031 - Avg Loss: 160.1909\n",
            "Epoch [18/50] - Batch loss: 161.4161 - Epoch Loss: 49660.4192 - Avg Loss: 160.1949\n",
            "Epoch [18/50] - Batch loss: 157.1760 - Epoch Loss: 49817.5952 - Avg Loss: 160.1852\n",
            "Epoch [18/50] - Batch loss: 161.1062 - Epoch Loss: 49978.7014 - Avg Loss: 160.1881\n",
            "Epoch [18/50] - Batch loss: 159.6620 - Epoch Loss: 50138.3634 - Avg Loss: 160.1865\n",
            "Epoch [18/50] - Batch loss: 152.4875 - Epoch Loss: 50290.8510 - Avg Loss: 160.1619\n",
            "Epoch [18/50] - Batch loss: 155.4254 - Epoch Loss: 50446.2764 - Avg Loss: 160.1469\n",
            "Epoch [18/50] - Batch loss: 157.1836 - Epoch Loss: 50603.4599 - Avg Loss: 160.1375\n",
            "Epoch [18/50] - Batch loss: 154.0666 - Epoch Loss: 50757.5265 - Avg Loss: 160.1184\n",
            "Epoch [18/50] - Batch loss: 160.4263 - Epoch Loss: 50917.9528 - Avg Loss: 160.1193\n",
            "Epoch [18/50] - Batch loss: 165.0321 - Epoch Loss: 51082.9849 - Avg Loss: 160.1347\n",
            "Epoch [18/50] - Batch loss: 162.8314 - Epoch Loss: 51245.8163 - Avg Loss: 160.1432\n",
            "Epoch [18/50] - Batch loss: 155.8738 - Epoch Loss: 51401.6901 - Avg Loss: 160.1299\n",
            "Epoch [18/50] - Batch loss: 155.3025 - Epoch Loss: 51556.9927 - Avg Loss: 160.1149\n",
            "Epoch [18/50] - Batch loss: 159.7459 - Epoch Loss: 51716.7386 - Avg Loss: 160.1137\n",
            "Epoch [18/50] - Batch loss: 163.4131 - Epoch Loss: 51880.1517 - Avg Loss: 160.1239\n",
            "Epoch [18/50] - Batch loss: 167.3534 - Epoch Loss: 52047.5051 - Avg Loss: 160.1462\n",
            "Epoch [18/50] - Batch loss: 162.0277 - Epoch Loss: 52209.5328 - Avg Loss: 160.1519\n",
            "Epoch [18/50] - Batch loss: 156.8798 - Epoch Loss: 52366.4126 - Avg Loss: 160.1419\n",
            "Epoch [18/50] - Batch loss: 153.9435 - Epoch Loss: 52520.3560 - Avg Loss: 160.1230\n",
            "Epoch [18/50] - Batch loss: 156.6891 - Epoch Loss: 52677.0451 - Avg Loss: 160.1126\n",
            "Epoch [18/50] - Batch loss: 162.4587 - Epoch Loss: 52839.5038 - Avg Loss: 160.1197\n",
            "Epoch [18/50] - Batch loss: 160.2007 - Epoch Loss: 52999.7045 - Avg Loss: 160.1200\n",
            "Epoch [18/50] - Batch loss: 167.7722 - Epoch Loss: 53167.4767 - Avg Loss: 160.1430\n",
            "Epoch [18/50] - Batch loss: 164.3755 - Epoch Loss: 53331.8522 - Avg Loss: 160.1557\n",
            "Epoch [18/50] - Batch loss: 160.0809 - Epoch Loss: 53491.9331 - Avg Loss: 160.1555\n",
            "Epoch [18/50] - Batch loss: 158.8167 - Epoch Loss: 53650.7497 - Avg Loss: 160.1515\n",
            "Epoch [18/50] - Batch loss: 156.5573 - Epoch Loss: 53807.3070 - Avg Loss: 160.1408\n",
            "Epoch [18/50] - Batch loss: 159.0166 - Epoch Loss: 53966.3237 - Avg Loss: 160.1375\n",
            "Epoch [18/50] - Batch loss: 158.8700 - Epoch Loss: 54125.1937 - Avg Loss: 160.1337\n",
            "Epoch [18/50] - Batch loss: 167.0737 - Epoch Loss: 54292.2674 - Avg Loss: 160.1542\n",
            "Epoch [18/50] - Batch loss: 163.9585 - Epoch Loss: 54456.2259 - Avg Loss: 160.1654\n",
            "Epoch [18/50] - Batch loss: 160.2632 - Epoch Loss: 54616.4891 - Avg Loss: 160.1657\n",
            "Epoch [18/50] - Batch loss: 162.0480 - Epoch Loss: 54778.5371 - Avg Loss: 160.1712\n",
            "Epoch [18/50] - Batch loss: 165.3410 - Epoch Loss: 54943.8781 - Avg Loss: 160.1862\n",
            "Epoch [18/50] - Batch loss: 164.4267 - Epoch Loss: 55108.3048 - Avg Loss: 160.1986\n",
            "Epoch [18/50] - Batch loss: 152.8008 - Epoch Loss: 55261.1056 - Avg Loss: 160.1771\n",
            "Epoch [18/50] - Batch loss: 159.5242 - Epoch Loss: 55420.6298 - Avg Loss: 160.1752\n",
            "Epoch [18/50] - Batch loss: 156.4165 - Epoch Loss: 55577.0463 - Avg Loss: 160.1644\n",
            "Epoch [18/50] - Batch loss: 158.8062 - Epoch Loss: 55735.8525 - Avg Loss: 160.1605\n",
            "Epoch [18/50] - Batch loss: 165.1992 - Epoch Loss: 55901.0516 - Avg Loss: 160.1749\n",
            "Epoch [18/50] - Batch loss: 162.4967 - Epoch Loss: 56063.5483 - Avg Loss: 160.1816\n",
            "Epoch [18/50] - Batch loss: 162.6346 - Epoch Loss: 56226.1830 - Avg Loss: 160.1886\n",
            "Epoch [18/50] - Batch loss: 161.5966 - Epoch Loss: 56387.7796 - Avg Loss: 160.1926\n",
            "Epoch [18/50] - Batch loss: 157.9258 - Epoch Loss: 56545.7054 - Avg Loss: 160.1861\n",
            "Epoch [18/50] - Batch loss: 157.7776 - Epoch Loss: 56703.4829 - Avg Loss: 160.1793\n",
            "Epoch [18/50] - Batch loss: 151.3511 - Epoch Loss: 56854.8340 - Avg Loss: 160.1545\n",
            "Epoch [18/50] - Batch loss: 160.4531 - Epoch Loss: 57015.2871 - Avg Loss: 160.1553\n",
            "Epoch [18/50] - Batch loss: 160.3355 - Epoch Loss: 57175.6227 - Avg Loss: 160.1558\n",
            "Epoch [18/50] - Batch loss: 158.4830 - Epoch Loss: 57334.1057 - Avg Loss: 160.1511\n",
            "Epoch [18/50] - Batch loss: 154.9535 - Epoch Loss: 57489.0592 - Avg Loss: 160.1367\n",
            "Epoch [18/50] - Batch loss: 171.9240 - Epoch Loss: 57660.9832 - Avg Loss: 160.1694\n",
            "Epoch [18/50] - Batch loss: 158.0209 - Epoch Loss: 57819.0040 - Avg Loss: 160.1634\n",
            "Epoch [18/50] - Batch loss: 160.6250 - Epoch Loss: 57979.6290 - Avg Loss: 160.1647\n",
            "Epoch [18/50] - Batch loss: 163.1026 - Epoch Loss: 58142.7316 - Avg Loss: 160.1728\n",
            "Epoch [18/50] - Batch loss: 166.9930 - Epoch Loss: 58309.7247 - Avg Loss: 160.1916\n",
            "Epoch [18/50] - Batch loss: 158.3416 - Epoch Loss: 58468.0662 - Avg Loss: 160.1865\n",
            "Epoch [18/50] - Batch loss: 159.7970 - Epoch Loss: 58627.8632 - Avg Loss: 160.1854\n",
            "Epoch [18/50] - Batch loss: 157.1056 - Epoch Loss: 58784.9688 - Avg Loss: 160.1770\n",
            "Epoch [18/50] - Batch loss: 159.9411 - Epoch Loss: 58944.9098 - Avg Loss: 160.1764\n",
            "Epoch [18/50] - Batch loss: 164.8852 - Epoch Loss: 59109.7950 - Avg Loss: 160.1891\n",
            "Epoch [18/50] - Batch loss: 161.4118 - Epoch Loss: 59271.2068 - Avg Loss: 160.1925\n",
            "Epoch [18/50] - Batch loss: 162.2746 - Epoch Loss: 59433.4814 - Avg Loss: 160.1981\n",
            "Epoch [18/50] - Batch loss: 163.5862 - Epoch Loss: 59597.0677 - Avg Loss: 160.2072\n",
            "Epoch [18/50] - Batch loss: 165.1412 - Epoch Loss: 59762.2089 - Avg Loss: 160.2204\n",
            "Epoch [18/50] - Batch loss: 155.1239 - Epoch Loss: 59917.3327 - Avg Loss: 160.2068\n",
            "Epoch [18/50] - Batch loss: 155.8102 - Epoch Loss: 60073.1430 - Avg Loss: 160.1950\n",
            "Epoch [18/50] - Batch loss: 160.7589 - Epoch Loss: 60233.9019 - Avg Loss: 160.1965\n",
            "Epoch [18/50] - Batch loss: 165.0181 - Epoch Loss: 60398.9200 - Avg Loss: 160.2093\n",
            "Epoch [18/50] - Batch loss: 163.3785 - Epoch Loss: 60562.2985 - Avg Loss: 160.2177\n",
            "Epoch [18/50] - Batch loss: 164.4381 - Epoch Loss: 60726.7366 - Avg Loss: 160.2289\n",
            "Epoch [18/50] - Batch loss: 154.7603 - Epoch Loss: 60881.4969 - Avg Loss: 160.2145\n",
            "Epoch [18/50] - Batch loss: 157.7638 - Epoch Loss: 61039.2608 - Avg Loss: 160.2080\n",
            "Epoch [18/50] - Batch loss: 161.5730 - Epoch Loss: 61200.8337 - Avg Loss: 160.2116\n",
            "Epoch [18/50] - Batch loss: 161.6571 - Epoch Loss: 61362.4908 - Avg Loss: 160.2154\n",
            "Epoch [18/50] - Batch loss: 164.8102 - Epoch Loss: 61527.3010 - Avg Loss: 160.2273\n",
            "Epoch [18/50] - Batch loss: 161.7435 - Epoch Loss: 61689.0445 - Avg Loss: 160.2313\n",
            "Epoch [18/50] - Batch loss: 166.8338 - Epoch Loss: 61855.8783 - Avg Loss: 160.2484\n",
            "Epoch [18/50] - Batch loss: 157.4650 - Epoch Loss: 62013.3433 - Avg Loss: 160.2412\n",
            "Epoch [18/50] - Batch loss: 158.5722 - Epoch Loss: 62171.9155 - Avg Loss: 160.2369\n",
            "Epoch [18/50] - Batch loss: 164.8354 - Epoch Loss: 62336.7509 - Avg Loss: 160.2487\n",
            "Epoch [18/50] - Batch loss: 164.4791 - Epoch Loss: 62501.2301 - Avg Loss: 160.2596\n",
            "Epoch [18/50] - Batch loss: 154.7014 - Epoch Loss: 62655.9315 - Avg Loss: 160.2453\n",
            "Epoch [18/50] - Batch loss: 148.2557 - Epoch Loss: 62804.1871 - Avg Loss: 160.2148\n",
            "Epoch [18/50] - Batch loss: 154.0585 - Epoch Loss: 62958.2456 - Avg Loss: 160.1991\n",
            "Epoch [18/50] - Batch loss: 160.6642 - Epoch Loss: 63118.9098 - Avg Loss: 160.2003\n",
            "Epoch [18/50] - Batch loss: 151.0536 - Epoch Loss: 63269.9634 - Avg Loss: 160.1771\n",
            "Epoch [18/50] - Batch loss: 165.2165 - Epoch Loss: 63435.1799 - Avg Loss: 160.1898\n",
            "Epoch [18/50] - Batch loss: 152.2423 - Epoch Loss: 63587.4221 - Avg Loss: 160.1698\n",
            "Epoch [18/50] - Batch loss: 159.8580 - Epoch Loss: 63747.2801 - Avg Loss: 160.1690\n",
            "Epoch [18/50] - Batch loss: 163.0479 - Epoch Loss: 63910.3280 - Avg Loss: 160.1763\n",
            "Epoch [18/50] - Batch loss: 149.7276 - Epoch Loss: 64060.0556 - Avg Loss: 160.1501\n",
            "Epoch [18/50] - Batch loss: 159.2891 - Epoch Loss: 64219.3447 - Avg Loss: 160.1480\n",
            "Epoch [18/50] - Batch loss: 156.3854 - Epoch Loss: 64375.7300 - Avg Loss: 160.1386\n",
            "Epoch [18/50] - Batch loss: 155.2403 - Epoch Loss: 64530.9704 - Avg Loss: 160.1265\n",
            "Epoch [18/50] - Batch loss: 151.9622 - Epoch Loss: 64682.9326 - Avg Loss: 160.1063\n",
            "Epoch [18/50] - Batch loss: 162.7686 - Epoch Loss: 64845.7012 - Avg Loss: 160.1128\n",
            "Epoch [18/50] - Batch loss: 154.7114 - Epoch Loss: 65000.4126 - Avg Loss: 160.0995\n",
            "Epoch [18/50] - Batch loss: 163.1269 - Epoch Loss: 65163.5395 - Avg Loss: 160.1070\n",
            "Epoch [18/50] - Batch loss: 153.1505 - Epoch Loss: 65316.6900 - Avg Loss: 160.0899\n",
            "Epoch [18/50] - Batch loss: 163.7355 - Epoch Loss: 65480.4256 - Avg Loss: 160.0988\n",
            "Epoch [18/50] - Batch loss: 157.0675 - Epoch Loss: 65637.4931 - Avg Loss: 160.0914\n",
            "Epoch [18/50] - Batch loss: 166.8467 - Epoch Loss: 65804.3398 - Avg Loss: 160.1079\n",
            "Epoch [18/50] - Batch loss: 154.4352 - Epoch Loss: 65958.7749 - Avg Loss: 160.0941\n",
            "Epoch [18/50] - Batch loss: 157.3662 - Epoch Loss: 66116.1411 - Avg Loss: 160.0875\n",
            "Epoch [18/50] - Batch loss: 172.0955 - Epoch Loss: 66288.2366 - Avg Loss: 160.1165\n",
            "Epoch [18/50] - Batch loss: 161.4432 - Epoch Loss: 66449.6798 - Avg Loss: 160.1197\n",
            "Epoch [18/50] - Batch loss: 159.9736 - Epoch Loss: 66609.6535 - Avg Loss: 160.1194\n",
            "Epoch [18/50] - Batch loss: 156.9696 - Epoch Loss: 66766.6230 - Avg Loss: 160.1118\n",
            "Epoch [18/50] - Batch loss: 164.2269 - Epoch Loss: 66930.8499 - Avg Loss: 160.1217\n",
            "Epoch [18/50] - Batch loss: 161.4634 - Epoch Loss: 67092.3133 - Avg Loss: 160.1249\n",
            "Epoch [18/50] - Batch loss: 161.1862 - Epoch Loss: 67253.4995 - Avg Loss: 160.1274\n",
            "Epoch [18/50] - Batch loss: 157.9264 - Epoch Loss: 67411.4259 - Avg Loss: 160.1222\n",
            "Epoch [18/50] - Batch loss: 164.6754 - Epoch Loss: 67576.1013 - Avg Loss: 160.1329\n",
            "Epoch [18/50] - Batch loss: 156.4620 - Epoch Loss: 67732.5633 - Avg Loss: 160.1243\n",
            "Epoch [18/50] - Batch loss: 162.8252 - Epoch Loss: 67895.3885 - Avg Loss: 160.1306\n",
            "Epoch [18/50] - Batch loss: 153.4554 - Epoch Loss: 68048.8440 - Avg Loss: 160.1149\n",
            "Epoch [18/50] - Batch loss: 160.4972 - Epoch Loss: 68209.3412 - Avg Loss: 160.1158\n",
            "Epoch [18/50] - Batch loss: 152.1720 - Epoch Loss: 68361.5132 - Avg Loss: 160.0972\n",
            "Epoch [18/50] - Batch loss: 153.4745 - Epoch Loss: 68514.9877 - Avg Loss: 160.0817\n",
            "Epoch [18/50] - Batch loss: 162.1298 - Epoch Loss: 68677.1175 - Avg Loss: 160.0865\n",
            "Epoch [18/50] - Batch loss: 155.6589 - Epoch Loss: 68832.7764 - Avg Loss: 160.0762\n",
            "Epoch [18/50] - Batch loss: 156.0299 - Epoch Loss: 68988.8064 - Avg Loss: 160.0668\n",
            "Epoch [18/50] - Batch loss: 161.1401 - Epoch Loss: 69149.9465 - Avg Loss: 160.0693\n",
            "Epoch [18/50] - Batch loss: 162.2238 - Epoch Loss: 69312.1703 - Avg Loss: 160.0743\n",
            "Epoch [18/50] - Batch loss: 161.3518 - Epoch Loss: 69473.5221 - Avg Loss: 160.0772\n",
            "Epoch [18/50] - Batch loss: 165.1406 - Epoch Loss: 69638.6627 - Avg Loss: 160.0889\n",
            "Epoch [18/50] - Batch loss: 158.9730 - Epoch Loss: 69797.6357 - Avg Loss: 160.0863\n",
            "Epoch [18/50] - Batch loss: 155.0044 - Epoch Loss: 69952.6401 - Avg Loss: 160.0747\n",
            "Epoch [18/50] - Batch loss: 153.8956 - Epoch Loss: 70106.5357 - Avg Loss: 160.0606\n",
            "Epoch [18/50] - Batch loss: 154.8804 - Epoch Loss: 70261.4161 - Avg Loss: 160.0488\n",
            "Epoch [18/50] - Batch loss: 160.6465 - Epoch Loss: 70422.0626 - Avg Loss: 160.0501\n",
            "Epoch [18/50] - Batch loss: 159.6770 - Epoch Loss: 70581.7396 - Avg Loss: 160.0493\n",
            "Epoch [18/50] - Batch loss: 161.8003 - Epoch Loss: 70743.5400 - Avg Loss: 160.0533\n",
            "Epoch [18/50] - Batch loss: 149.9093 - Epoch Loss: 70893.4493 - Avg Loss: 160.0304\n",
            "Epoch [18/50] - Batch loss: 162.0726 - Epoch Loss: 71055.5219 - Avg Loss: 160.0350\n",
            "Epoch [18/50] - Batch loss: 167.5263 - Epoch Loss: 71223.0482 - Avg Loss: 160.0518\n",
            "Epoch [18/50] - Batch loss: 159.0084 - Epoch Loss: 71382.0565 - Avg Loss: 160.0495\n",
            "Epoch [18/50] - Batch loss: 160.8102 - Epoch Loss: 71542.8668 - Avg Loss: 160.0512\n",
            "Epoch [18/50] - Batch loss: 160.4741 - Epoch Loss: 71703.3409 - Avg Loss: 160.0521\n",
            "Epoch [18/50] - Batch loss: 152.9252 - Epoch Loss: 71856.2661 - Avg Loss: 160.0362\n",
            "Epoch [18/50] - Batch loss: 165.0087 - Epoch Loss: 72021.2747 - Avg Loss: 160.0473\n",
            "Epoch [18/50] - Batch loss: 160.0302 - Epoch Loss: 72181.3049 - Avg Loss: 160.0472\n",
            "Epoch [18/50] - Batch loss: 162.8572 - Epoch Loss: 72344.1621 - Avg Loss: 160.0535\n",
            "Epoch [18/50] - Batch loss: 158.9985 - Epoch Loss: 72503.1606 - Avg Loss: 160.0511\n",
            "Epoch [18/50] - Batch loss: 152.6622 - Epoch Loss: 72655.8228 - Avg Loss: 160.0349\n",
            "Epoch [18/50] - Batch loss: 160.7241 - Epoch Loss: 72816.5469 - Avg Loss: 160.0364\n",
            "Epoch [18/50] - Batch loss: 156.9371 - Epoch Loss: 72973.4840 - Avg Loss: 160.0296\n",
            "Epoch [18/50] - Batch loss: 153.5706 - Epoch Loss: 73127.0546 - Avg Loss: 160.0154\n",
            "Epoch [18/50] - Batch loss: 158.9678 - Epoch Loss: 73286.0225 - Avg Loss: 160.0131\n",
            "Epoch [18/50] - Batch loss: 160.4176 - Epoch Loss: 73446.4401 - Avg Loss: 160.0140\n",
            "Epoch [18/50] - Batch loss: 166.1644 - Epoch Loss: 73612.6045 - Avg Loss: 160.0274\n",
            "Epoch [18/50] - Batch loss: 158.2766 - Epoch Loss: 73770.8811 - Avg Loss: 160.0236\n",
            "Epoch [18/50] - Batch loss: 159.1301 - Epoch Loss: 73930.0112 - Avg Loss: 160.0217\n",
            "Epoch [18/50] - Batch loss: 162.4065 - Epoch Loss: 74092.4177 - Avg Loss: 160.0268\n",
            "Epoch [18/50] - Batch loss: 167.0293 - Epoch Loss: 74259.4469 - Avg Loss: 160.0419\n",
            "Epoch [18/50] - Batch loss: 155.6411 - Epoch Loss: 74415.0881 - Avg Loss: 160.0324\n",
            "Epoch [18/50] - Batch loss: 156.5088 - Epoch Loss: 74571.5969 - Avg Loss: 160.0249\n",
            "Epoch [18/50] - Batch loss: 155.0162 - Epoch Loss: 74726.6131 - Avg Loss: 160.0142\n",
            "Epoch [18/50] - Batch loss: 161.6662 - Epoch Loss: 74888.2793 - Avg Loss: 160.0177\n",
            "Epoch [18/50] - Batch loss: 157.0624 - Epoch Loss: 75045.3417 - Avg Loss: 160.0114\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 19/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7738fc61b7d34c4cae34cea1173c28e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/50] - Batch loss: 160.2097 - Epoch Loss: 160.2097 - Avg Loss: 160.2097\n",
            "Epoch [19/50] - Batch loss: 156.2896 - Epoch Loss: 316.4993 - Avg Loss: 158.2496\n",
            "Epoch [19/50] - Batch loss: 154.5231 - Epoch Loss: 471.0224 - Avg Loss: 157.0075\n",
            "Epoch [19/50] - Batch loss: 154.2970 - Epoch Loss: 625.3194 - Avg Loss: 156.3298\n",
            "Epoch [19/50] - Batch loss: 153.9803 - Epoch Loss: 779.2997 - Avg Loss: 155.8599\n",
            "Epoch [19/50] - Batch loss: 159.5882 - Epoch Loss: 938.8879 - Avg Loss: 156.4813\n",
            "Epoch [19/50] - Batch loss: 160.8410 - Epoch Loss: 1099.7289 - Avg Loss: 157.1041\n",
            "Epoch [19/50] - Batch loss: 154.5572 - Epoch Loss: 1254.2861 - Avg Loss: 156.7858\n",
            "Epoch [19/50] - Batch loss: 159.1732 - Epoch Loss: 1413.4593 - Avg Loss: 157.0510\n",
            "Epoch [19/50] - Batch loss: 158.5321 - Epoch Loss: 1571.9914 - Avg Loss: 157.1991\n",
            "Epoch [19/50] - Batch loss: 155.5549 - Epoch Loss: 1727.5463 - Avg Loss: 157.0497\n",
            "Epoch [19/50] - Batch loss: 158.5319 - Epoch Loss: 1886.0782 - Avg Loss: 157.1732\n",
            "Epoch [19/50] - Batch loss: 160.2619 - Epoch Loss: 2046.3401 - Avg Loss: 157.4108\n",
            "Epoch [19/50] - Batch loss: 151.4389 - Epoch Loss: 2197.7790 - Avg Loss: 156.9842\n",
            "Epoch [19/50] - Batch loss: 158.8976 - Epoch Loss: 2356.6765 - Avg Loss: 157.1118\n",
            "Epoch [19/50] - Batch loss: 164.5418 - Epoch Loss: 2521.2183 - Avg Loss: 157.5761\n",
            "Epoch [19/50] - Batch loss: 160.8348 - Epoch Loss: 2682.0531 - Avg Loss: 157.7678\n",
            "Epoch [19/50] - Batch loss: 157.7585 - Epoch Loss: 2839.8115 - Avg Loss: 157.7673\n",
            "Epoch [19/50] - Batch loss: 160.5613 - Epoch Loss: 3000.3728 - Avg Loss: 157.9144\n",
            "Epoch [19/50] - Batch loss: 157.8584 - Epoch Loss: 3158.2312 - Avg Loss: 157.9116\n",
            "Epoch [19/50] - Batch loss: 158.6755 - Epoch Loss: 3316.9067 - Avg Loss: 157.9479\n",
            "Epoch [19/50] - Batch loss: 156.9053 - Epoch Loss: 3473.8120 - Avg Loss: 157.9005\n",
            "Epoch [19/50] - Batch loss: 159.0020 - Epoch Loss: 3632.8139 - Avg Loss: 157.9484\n",
            "Epoch [19/50] - Batch loss: 162.3946 - Epoch Loss: 3795.2086 - Avg Loss: 158.1337\n",
            "Epoch [19/50] - Batch loss: 150.0462 - Epoch Loss: 3945.2548 - Avg Loss: 157.8102\n",
            "Epoch [19/50] - Batch loss: 156.2132 - Epoch Loss: 4101.4680 - Avg Loss: 157.7488\n",
            "Epoch [19/50] - Batch loss: 151.1969 - Epoch Loss: 4252.6649 - Avg Loss: 157.5061\n",
            "Epoch [19/50] - Batch loss: 164.8841 - Epoch Loss: 4417.5490 - Avg Loss: 157.7696\n",
            "Epoch [19/50] - Batch loss: 156.4887 - Epoch Loss: 4574.0378 - Avg Loss: 157.7254\n",
            "Epoch [19/50] - Batch loss: 156.7333 - Epoch Loss: 4730.7711 - Avg Loss: 157.6924\n",
            "Epoch [19/50] - Batch loss: 146.9758 - Epoch Loss: 4877.7468 - Avg Loss: 157.3467\n",
            "Epoch [19/50] - Batch loss: 157.2743 - Epoch Loss: 5035.0211 - Avg Loss: 157.3444\n",
            "Epoch [19/50] - Batch loss: 163.8888 - Epoch Loss: 5198.9100 - Avg Loss: 157.5427\n",
            "Epoch [19/50] - Batch loss: 158.1350 - Epoch Loss: 5357.0450 - Avg Loss: 157.5601\n",
            "Epoch [19/50] - Batch loss: 155.0117 - Epoch Loss: 5512.0567 - Avg Loss: 157.4873\n",
            "Epoch [19/50] - Batch loss: 153.7480 - Epoch Loss: 5665.8047 - Avg Loss: 157.3835\n",
            "Epoch [19/50] - Batch loss: 155.9347 - Epoch Loss: 5821.7394 - Avg Loss: 157.3443\n",
            "Epoch [19/50] - Batch loss: 150.7408 - Epoch Loss: 5972.4801 - Avg Loss: 157.1705\n",
            "Epoch [19/50] - Batch loss: 158.6650 - Epoch Loss: 6131.1452 - Avg Loss: 157.2089\n",
            "Epoch [19/50] - Batch loss: 159.8585 - Epoch Loss: 6291.0037 - Avg Loss: 157.2751\n",
            "Epoch [19/50] - Batch loss: 156.7201 - Epoch Loss: 6447.7238 - Avg Loss: 157.2616\n",
            "Epoch [19/50] - Batch loss: 158.5322 - Epoch Loss: 6606.2559 - Avg Loss: 157.2918\n",
            "Epoch [19/50] - Batch loss: 154.1459 - Epoch Loss: 6760.4018 - Avg Loss: 157.2186\n",
            "Epoch [19/50] - Batch loss: 162.2572 - Epoch Loss: 6922.6590 - Avg Loss: 157.3332\n",
            "Epoch [19/50] - Batch loss: 162.1934 - Epoch Loss: 7084.8524 - Avg Loss: 157.4412\n",
            "Epoch [19/50] - Batch loss: 163.8768 - Epoch Loss: 7248.7292 - Avg Loss: 157.5811\n",
            "Epoch [19/50] - Batch loss: 154.0953 - Epoch Loss: 7402.8245 - Avg Loss: 157.5069\n",
            "Epoch [19/50] - Batch loss: 151.4669 - Epoch Loss: 7554.2914 - Avg Loss: 157.3811\n",
            "Epoch [19/50] - Batch loss: 151.6777 - Epoch Loss: 7705.9690 - Avg Loss: 157.2647\n",
            "Epoch [19/50] - Batch loss: 158.1649 - Epoch Loss: 7864.1340 - Avg Loss: 157.2827\n",
            "Epoch [19/50] - Batch loss: 161.5031 - Epoch Loss: 8025.6371 - Avg Loss: 157.3654\n",
            "Epoch [19/50] - Batch loss: 163.5153 - Epoch Loss: 8189.1524 - Avg Loss: 157.4837\n",
            "Epoch [19/50] - Batch loss: 160.6716 - Epoch Loss: 8349.8241 - Avg Loss: 157.5439\n",
            "Epoch [19/50] - Batch loss: 156.7338 - Epoch Loss: 8506.5578 - Avg Loss: 157.5288\n",
            "Epoch [19/50] - Batch loss: 155.5362 - Epoch Loss: 8662.0941 - Avg Loss: 157.4926\n",
            "Epoch [19/50] - Batch loss: 165.9234 - Epoch Loss: 8828.0174 - Avg Loss: 157.6432\n",
            "Epoch [19/50] - Batch loss: 160.5152 - Epoch Loss: 8988.5326 - Avg Loss: 157.6936\n",
            "Epoch [19/50] - Batch loss: 164.8521 - Epoch Loss: 9153.3847 - Avg Loss: 157.8170\n",
            "Epoch [19/50] - Batch loss: 159.2764 - Epoch Loss: 9312.6611 - Avg Loss: 157.8417\n",
            "Epoch [19/50] - Batch loss: 156.1937 - Epoch Loss: 9468.8548 - Avg Loss: 157.8142\n",
            "Epoch [19/50] - Batch loss: 158.7472 - Epoch Loss: 9627.6020 - Avg Loss: 157.8295\n",
            "Epoch [19/50] - Batch loss: 158.6154 - Epoch Loss: 9786.2174 - Avg Loss: 157.8422\n",
            "Epoch [19/50] - Batch loss: 152.9334 - Epoch Loss: 9939.1508 - Avg Loss: 157.7643\n",
            "Epoch [19/50] - Batch loss: 163.2036 - Epoch Loss: 10102.3544 - Avg Loss: 157.8493\n",
            "Epoch [19/50] - Batch loss: 151.8222 - Epoch Loss: 10254.1766 - Avg Loss: 157.7566\n",
            "Epoch [19/50] - Batch loss: 157.3515 - Epoch Loss: 10411.5281 - Avg Loss: 157.7504\n",
            "Epoch [19/50] - Batch loss: 150.9404 - Epoch Loss: 10562.4684 - Avg Loss: 157.6488\n",
            "Epoch [19/50] - Batch loss: 165.6687 - Epoch Loss: 10728.1371 - Avg Loss: 157.7667\n",
            "Epoch [19/50] - Batch loss: 156.6295 - Epoch Loss: 10884.7665 - Avg Loss: 157.7502\n",
            "Epoch [19/50] - Batch loss: 164.3785 - Epoch Loss: 11049.1451 - Avg Loss: 157.8449\n",
            "Epoch [19/50] - Batch loss: 159.3171 - Epoch Loss: 11208.4621 - Avg Loss: 157.8657\n",
            "Epoch [19/50] - Batch loss: 167.8148 - Epoch Loss: 11376.2770 - Avg Loss: 158.0038\n",
            "Epoch [19/50] - Batch loss: 162.3511 - Epoch Loss: 11538.6280 - Avg Loss: 158.0634\n",
            "Epoch [19/50] - Batch loss: 167.0392 - Epoch Loss: 11705.6672 - Avg Loss: 158.1847\n",
            "Epoch [19/50] - Batch loss: 163.8847 - Epoch Loss: 11869.5519 - Avg Loss: 158.2607\n",
            "Epoch [19/50] - Batch loss: 162.2661 - Epoch Loss: 12031.8180 - Avg Loss: 158.3134\n",
            "Epoch [19/50] - Batch loss: 162.2755 - Epoch Loss: 12194.0935 - Avg Loss: 158.3649\n",
            "Epoch [19/50] - Batch loss: 160.9588 - Epoch Loss: 12355.0523 - Avg Loss: 158.3981\n",
            "Epoch [19/50] - Batch loss: 156.3743 - Epoch Loss: 12511.4267 - Avg Loss: 158.3725\n",
            "Epoch [19/50] - Batch loss: 164.7828 - Epoch Loss: 12676.2095 - Avg Loss: 158.4526\n",
            "Epoch [19/50] - Batch loss: 152.6074 - Epoch Loss: 12828.8168 - Avg Loss: 158.3805\n",
            "Epoch [19/50] - Batch loss: 161.2889 - Epoch Loss: 12990.1057 - Avg Loss: 158.4159\n",
            "Epoch [19/50] - Batch loss: 154.8389 - Epoch Loss: 13144.9447 - Avg Loss: 158.3728\n",
            "Epoch [19/50] - Batch loss: 163.1100 - Epoch Loss: 13308.0546 - Avg Loss: 158.4292\n",
            "Epoch [19/50] - Batch loss: 160.7334 - Epoch Loss: 13468.7880 - Avg Loss: 158.4563\n",
            "Epoch [19/50] - Batch loss: 156.1308 - Epoch Loss: 13624.9188 - Avg Loss: 158.4293\n",
            "Epoch [19/50] - Batch loss: 162.9988 - Epoch Loss: 13787.9176 - Avg Loss: 158.4818\n",
            "Epoch [19/50] - Batch loss: 161.0759 - Epoch Loss: 13948.9934 - Avg Loss: 158.5113\n",
            "Epoch [19/50] - Batch loss: 160.6954 - Epoch Loss: 14109.6889 - Avg Loss: 158.5358\n",
            "Epoch [19/50] - Batch loss: 157.7419 - Epoch Loss: 14267.4308 - Avg Loss: 158.5270\n",
            "Epoch [19/50] - Batch loss: 158.5852 - Epoch Loss: 14426.0160 - Avg Loss: 158.5276\n",
            "Epoch [19/50] - Batch loss: 156.9206 - Epoch Loss: 14582.9366 - Avg Loss: 158.5102\n",
            "Epoch [19/50] - Batch loss: 160.1033 - Epoch Loss: 14743.0398 - Avg Loss: 158.5273\n",
            "Epoch [19/50] - Batch loss: 159.1747 - Epoch Loss: 14902.2145 - Avg Loss: 158.5342\n",
            "Epoch [19/50] - Batch loss: 155.6015 - Epoch Loss: 15057.8160 - Avg Loss: 158.5033\n",
            "Epoch [19/50] - Batch loss: 158.4552 - Epoch Loss: 15216.2712 - Avg Loss: 158.5028\n",
            "Epoch [19/50] - Batch loss: 154.1592 - Epoch Loss: 15370.4304 - Avg Loss: 158.4580\n",
            "Epoch [19/50] - Batch loss: 158.7242 - Epoch Loss: 15529.1546 - Avg Loss: 158.4608\n",
            "Epoch [19/50] - Batch loss: 154.5485 - Epoch Loss: 15683.7030 - Avg Loss: 158.4212\n",
            "Epoch [19/50] - Batch loss: 161.6885 - Epoch Loss: 15845.3916 - Avg Loss: 158.4539\n",
            "Epoch [19/50] - Batch loss: 166.4642 - Epoch Loss: 16011.8558 - Avg Loss: 158.5332\n",
            "Epoch [19/50] - Batch loss: 158.6796 - Epoch Loss: 16170.5354 - Avg Loss: 158.5347\n",
            "Epoch [19/50] - Batch loss: 163.6754 - Epoch Loss: 16334.2108 - Avg Loss: 158.5846\n",
            "Epoch [19/50] - Batch loss: 154.0807 - Epoch Loss: 16488.2915 - Avg Loss: 158.5413\n",
            "Epoch [19/50] - Batch loss: 154.3915 - Epoch Loss: 16642.6830 - Avg Loss: 158.5017\n",
            "Epoch [19/50] - Batch loss: 156.5946 - Epoch Loss: 16799.2776 - Avg Loss: 158.4838\n",
            "Epoch [19/50] - Batch loss: 163.1631 - Epoch Loss: 16962.4407 - Avg Loss: 158.5275\n",
            "Epoch [19/50] - Batch loss: 159.4772 - Epoch Loss: 17121.9178 - Avg Loss: 158.5363\n",
            "Epoch [19/50] - Batch loss: 154.7219 - Epoch Loss: 17276.6398 - Avg Loss: 158.5013\n",
            "Epoch [19/50] - Batch loss: 162.3230 - Epoch Loss: 17438.9627 - Avg Loss: 158.5360\n",
            "Epoch [19/50] - Batch loss: 157.9252 - Epoch Loss: 17596.8879 - Avg Loss: 158.5305\n",
            "Epoch [19/50] - Batch loss: 155.9782 - Epoch Loss: 17752.8661 - Avg Loss: 158.5077\n",
            "Epoch [19/50] - Batch loss: 164.7006 - Epoch Loss: 17917.5667 - Avg Loss: 158.5625\n",
            "Epoch [19/50] - Batch loss: 159.9283 - Epoch Loss: 18077.4950 - Avg Loss: 158.5745\n",
            "Epoch [19/50] - Batch loss: 159.6801 - Epoch Loss: 18237.1751 - Avg Loss: 158.5841\n",
            "Epoch [19/50] - Batch loss: 164.2897 - Epoch Loss: 18401.4648 - Avg Loss: 158.6333\n",
            "Epoch [19/50] - Batch loss: 156.1064 - Epoch Loss: 18557.5712 - Avg Loss: 158.6117\n",
            "Epoch [19/50] - Batch loss: 158.3312 - Epoch Loss: 18715.9024 - Avg Loss: 158.6093\n",
            "Epoch [19/50] - Batch loss: 156.0412 - Epoch Loss: 18871.9436 - Avg Loss: 158.5878\n",
            "Epoch [19/50] - Batch loss: 156.4876 - Epoch Loss: 19028.4312 - Avg Loss: 158.5703\n",
            "Epoch [19/50] - Batch loss: 157.7445 - Epoch Loss: 19186.1757 - Avg Loss: 158.5634\n",
            "Epoch [19/50] - Batch loss: 157.3652 - Epoch Loss: 19343.5409 - Avg Loss: 158.5536\n",
            "Epoch [19/50] - Batch loss: 158.4724 - Epoch Loss: 19502.0134 - Avg Loss: 158.5530\n",
            "Epoch [19/50] - Batch loss: 152.9889 - Epoch Loss: 19655.0022 - Avg Loss: 158.5081\n",
            "Epoch [19/50] - Batch loss: 158.8709 - Epoch Loss: 19813.8732 - Avg Loss: 158.5110\n",
            "Epoch [19/50] - Batch loss: 156.5044 - Epoch Loss: 19970.3776 - Avg Loss: 158.4951\n",
            "Epoch [19/50] - Batch loss: 157.4757 - Epoch Loss: 20127.8533 - Avg Loss: 158.4870\n",
            "Epoch [19/50] - Batch loss: 155.0596 - Epoch Loss: 20282.9128 - Avg Loss: 158.4603\n",
            "Epoch [19/50] - Batch loss: 162.8819 - Epoch Loss: 20445.7947 - Avg Loss: 158.4945\n",
            "Epoch [19/50] - Batch loss: 151.4994 - Epoch Loss: 20597.2941 - Avg Loss: 158.4407\n",
            "Epoch [19/50] - Batch loss: 164.9619 - Epoch Loss: 20762.2560 - Avg Loss: 158.4905\n",
            "Epoch [19/50] - Batch loss: 159.4457 - Epoch Loss: 20921.7017 - Avg Loss: 158.4977\n",
            "Epoch [19/50] - Batch loss: 158.3254 - Epoch Loss: 21080.0271 - Avg Loss: 158.4964\n",
            "Epoch [19/50] - Batch loss: 158.6061 - Epoch Loss: 21238.6331 - Avg Loss: 158.4973\n",
            "Epoch [19/50] - Batch loss: 162.6534 - Epoch Loss: 21401.2865 - Avg Loss: 158.5280\n",
            "Epoch [19/50] - Batch loss: 151.4541 - Epoch Loss: 21552.7406 - Avg Loss: 158.4760\n",
            "Epoch [19/50] - Batch loss: 162.9818 - Epoch Loss: 21715.7224 - Avg Loss: 158.5089\n",
            "Epoch [19/50] - Batch loss: 151.7484 - Epoch Loss: 21867.4708 - Avg Loss: 158.4599\n",
            "Epoch [19/50] - Batch loss: 157.3499 - Epoch Loss: 22024.8207 - Avg Loss: 158.4519\n",
            "Epoch [19/50] - Batch loss: 153.3320 - Epoch Loss: 22178.1527 - Avg Loss: 158.4154\n",
            "Epoch [19/50] - Batch loss: 158.0604 - Epoch Loss: 22336.2131 - Avg Loss: 158.4129\n",
            "Epoch [19/50] - Batch loss: 158.9319 - Epoch Loss: 22495.1450 - Avg Loss: 158.4165\n",
            "Epoch [19/50] - Batch loss: 162.7690 - Epoch Loss: 22657.9140 - Avg Loss: 158.4470\n",
            "Epoch [19/50] - Batch loss: 156.8333 - Epoch Loss: 22814.7473 - Avg Loss: 158.4357\n",
            "Epoch [19/50] - Batch loss: 160.9119 - Epoch Loss: 22975.6593 - Avg Loss: 158.4528\n",
            "Epoch [19/50] - Batch loss: 158.0219 - Epoch Loss: 23133.6812 - Avg Loss: 158.4499\n",
            "Epoch [19/50] - Batch loss: 158.3894 - Epoch Loss: 23292.0705 - Avg Loss: 158.4495\n",
            "Epoch [19/50] - Batch loss: 167.5297 - Epoch Loss: 23459.6003 - Avg Loss: 158.5108\n",
            "Epoch [19/50] - Batch loss: 162.1677 - Epoch Loss: 23621.7679 - Avg Loss: 158.5354\n",
            "Epoch [19/50] - Batch loss: 155.0234 - Epoch Loss: 23776.7914 - Avg Loss: 158.5119\n",
            "Epoch [19/50] - Batch loss: 158.2380 - Epoch Loss: 23935.0294 - Avg Loss: 158.5101\n",
            "Epoch [19/50] - Batch loss: 157.0287 - Epoch Loss: 24092.0580 - Avg Loss: 158.5004\n",
            "Epoch [19/50] - Batch loss: 156.6873 - Epoch Loss: 24248.7453 - Avg Loss: 158.4885\n",
            "Epoch [19/50] - Batch loss: 155.4284 - Epoch Loss: 24404.1738 - Avg Loss: 158.4687\n",
            "Epoch [19/50] - Batch loss: 151.6353 - Epoch Loss: 24555.8091 - Avg Loss: 158.4246\n",
            "Epoch [19/50] - Batch loss: 163.8048 - Epoch Loss: 24719.6139 - Avg Loss: 158.4591\n",
            "Epoch [19/50] - Batch loss: 153.7012 - Epoch Loss: 24873.3150 - Avg Loss: 158.4288\n",
            "Epoch [19/50] - Batch loss: 160.8645 - Epoch Loss: 25034.1795 - Avg Loss: 158.4442\n",
            "Epoch [19/50] - Batch loss: 159.4343 - Epoch Loss: 25193.6139 - Avg Loss: 158.4504\n",
            "Epoch [19/50] - Batch loss: 163.5468 - Epoch Loss: 25357.1607 - Avg Loss: 158.4823\n",
            "Epoch [19/50] - Batch loss: 154.1607 - Epoch Loss: 25511.3214 - Avg Loss: 158.4554\n",
            "Epoch [19/50] - Batch loss: 149.3409 - Epoch Loss: 25660.6623 - Avg Loss: 158.3991\n",
            "Epoch [19/50] - Batch loss: 154.8103 - Epoch Loss: 25815.4725 - Avg Loss: 158.3771\n",
            "Epoch [19/50] - Batch loss: 164.5330 - Epoch Loss: 25980.0056 - Avg Loss: 158.4147\n",
            "Epoch [19/50] - Batch loss: 160.1392 - Epoch Loss: 26140.1447 - Avg Loss: 158.4251\n",
            "Epoch [19/50] - Batch loss: 153.9911 - Epoch Loss: 26294.1359 - Avg Loss: 158.3984\n",
            "Epoch [19/50] - Batch loss: 160.3355 - Epoch Loss: 26454.4714 - Avg Loss: 158.4100\n",
            "Epoch [19/50] - Batch loss: 165.0121 - Epoch Loss: 26619.4835 - Avg Loss: 158.4493\n",
            "Epoch [19/50] - Batch loss: 153.6257 - Epoch Loss: 26773.1092 - Avg Loss: 158.4208\n",
            "Epoch [19/50] - Batch loss: 155.9137 - Epoch Loss: 26929.0229 - Avg Loss: 158.4060\n",
            "Epoch [19/50] - Batch loss: 153.7436 - Epoch Loss: 27082.7664 - Avg Loss: 158.3788\n",
            "Epoch [19/50] - Batch loss: 165.2542 - Epoch Loss: 27248.0206 - Avg Loss: 158.4187\n",
            "Epoch [19/50] - Batch loss: 154.3897 - Epoch Loss: 27402.4103 - Avg Loss: 158.3954\n",
            "Epoch [19/50] - Batch loss: 159.2558 - Epoch Loss: 27561.6661 - Avg Loss: 158.4004\n",
            "Epoch [19/50] - Batch loss: 153.6976 - Epoch Loss: 27715.3636 - Avg Loss: 158.3735\n",
            "Epoch [19/50] - Batch loss: 161.4452 - Epoch Loss: 27876.8088 - Avg Loss: 158.3910\n",
            "Epoch [19/50] - Batch loss: 161.6860 - Epoch Loss: 28038.4948 - Avg Loss: 158.4096\n",
            "Epoch [19/50] - Batch loss: 157.6591 - Epoch Loss: 28196.1539 - Avg Loss: 158.4054\n",
            "Epoch [19/50] - Batch loss: 156.5268 - Epoch Loss: 28352.6807 - Avg Loss: 158.3949\n",
            "Epoch [19/50] - Batch loss: 165.3011 - Epoch Loss: 28517.9818 - Avg Loss: 158.4332\n",
            "Epoch [19/50] - Batch loss: 159.5335 - Epoch Loss: 28677.5153 - Avg Loss: 158.4393\n",
            "Epoch [19/50] - Batch loss: 149.0644 - Epoch Loss: 28826.5797 - Avg Loss: 158.3878\n",
            "Epoch [19/50] - Batch loss: 156.7070 - Epoch Loss: 28983.2867 - Avg Loss: 158.3786\n",
            "Epoch [19/50] - Batch loss: 165.4540 - Epoch Loss: 29148.7407 - Avg Loss: 158.4171\n",
            "Epoch [19/50] - Batch loss: 161.8103 - Epoch Loss: 29310.5511 - Avg Loss: 158.4354\n",
            "Epoch [19/50] - Batch loss: 160.3994 - Epoch Loss: 29470.9504 - Avg Loss: 158.4460\n",
            "Epoch [19/50] - Batch loss: 157.7681 - Epoch Loss: 29628.7185 - Avg Loss: 158.4423\n",
            "Epoch [19/50] - Batch loss: 161.0312 - Epoch Loss: 29789.7497 - Avg Loss: 158.4561\n",
            "Epoch [19/50] - Batch loss: 156.1101 - Epoch Loss: 29945.8597 - Avg Loss: 158.4437\n",
            "Epoch [19/50] - Batch loss: 157.7994 - Epoch Loss: 30103.6591 - Avg Loss: 158.4403\n",
            "Epoch [19/50] - Batch loss: 155.8282 - Epoch Loss: 30259.4873 - Avg Loss: 158.4266\n",
            "Epoch [19/50] - Batch loss: 159.8160 - Epoch Loss: 30419.3033 - Avg Loss: 158.4339\n",
            "Epoch [19/50] - Batch loss: 156.8379 - Epoch Loss: 30576.1412 - Avg Loss: 158.4256\n",
            "Epoch [19/50] - Batch loss: 154.1014 - Epoch Loss: 30730.2426 - Avg Loss: 158.4033\n",
            "Epoch [19/50] - Batch loss: 160.5281 - Epoch Loss: 30890.7707 - Avg Loss: 158.4142\n",
            "Epoch [19/50] - Batch loss: 162.3792 - Epoch Loss: 31053.1499 - Avg Loss: 158.4344\n",
            "Epoch [19/50] - Batch loss: 163.0819 - Epoch Loss: 31216.2318 - Avg Loss: 158.4580\n",
            "Epoch [19/50] - Batch loss: 163.5758 - Epoch Loss: 31379.8076 - Avg Loss: 158.4839\n",
            "Epoch [19/50] - Batch loss: 157.2057 - Epoch Loss: 31537.0133 - Avg Loss: 158.4775\n",
            "Epoch [19/50] - Batch loss: 165.2820 - Epoch Loss: 31702.2953 - Avg Loss: 158.5115\n",
            "Epoch [19/50] - Batch loss: 161.3791 - Epoch Loss: 31863.6744 - Avg Loss: 158.5257\n",
            "Epoch [19/50] - Batch loss: 160.9374 - Epoch Loss: 32024.6118 - Avg Loss: 158.5377\n",
            "Epoch [19/50] - Batch loss: 159.7669 - Epoch Loss: 32184.3787 - Avg Loss: 158.5437\n",
            "Epoch [19/50] - Batch loss: 162.5631 - Epoch Loss: 32346.9418 - Avg Loss: 158.5634\n",
            "Epoch [19/50] - Batch loss: 161.1972 - Epoch Loss: 32508.1390 - Avg Loss: 158.5763\n",
            "Epoch [19/50] - Batch loss: 150.1723 - Epoch Loss: 32658.3114 - Avg Loss: 158.5355\n",
            "Epoch [19/50] - Batch loss: 159.0035 - Epoch Loss: 32817.3148 - Avg Loss: 158.5378\n",
            "Epoch [19/50] - Batch loss: 161.5772 - Epoch Loss: 32978.8920 - Avg Loss: 158.5524\n",
            "Epoch [19/50] - Batch loss: 161.7122 - Epoch Loss: 33140.6042 - Avg Loss: 158.5675\n",
            "Epoch [19/50] - Batch loss: 158.6155 - Epoch Loss: 33299.2197 - Avg Loss: 158.5677\n",
            "Epoch [19/50] - Batch loss: 152.3772 - Epoch Loss: 33451.5969 - Avg Loss: 158.5384\n",
            "Epoch [19/50] - Batch loss: 157.0030 - Epoch Loss: 33608.5999 - Avg Loss: 158.5311\n",
            "Epoch [19/50] - Batch loss: 148.5866 - Epoch Loss: 33757.1865 - Avg Loss: 158.4844\n",
            "Epoch [19/50] - Batch loss: 156.1849 - Epoch Loss: 33913.3714 - Avg Loss: 158.4737\n",
            "Epoch [19/50] - Batch loss: 153.7424 - Epoch Loss: 34067.1137 - Avg Loss: 158.4517\n",
            "Epoch [19/50] - Batch loss: 154.2724 - Epoch Loss: 34221.3862 - Avg Loss: 158.4323\n",
            "Epoch [19/50] - Batch loss: 161.0169 - Epoch Loss: 34382.4031 - Avg Loss: 158.4443\n",
            "Epoch [19/50] - Batch loss: 163.9150 - Epoch Loss: 34546.3181 - Avg Loss: 158.4693\n",
            "Epoch [19/50] - Batch loss: 160.7424 - Epoch Loss: 34707.0605 - Avg Loss: 158.4797\n",
            "Epoch [19/50] - Batch loss: 168.4281 - Epoch Loss: 34875.4886 - Avg Loss: 158.5249\n",
            "Epoch [19/50] - Batch loss: 155.0947 - Epoch Loss: 35030.5832 - Avg Loss: 158.5094\n",
            "Epoch [19/50] - Batch loss: 159.3037 - Epoch Loss: 35189.8869 - Avg Loss: 158.5130\n",
            "Epoch [19/50] - Batch loss: 157.9296 - Epoch Loss: 35347.8165 - Avg Loss: 158.5104\n",
            "Epoch [19/50] - Batch loss: 157.6473 - Epoch Loss: 35505.4638 - Avg Loss: 158.5065\n",
            "Epoch [19/50] - Batch loss: 161.3063 - Epoch Loss: 35666.7702 - Avg Loss: 158.5190\n",
            "Epoch [19/50] - Batch loss: 154.8940 - Epoch Loss: 35821.6642 - Avg Loss: 158.5029\n",
            "Epoch [19/50] - Batch loss: 155.6625 - Epoch Loss: 35977.3267 - Avg Loss: 158.4904\n",
            "Epoch [19/50] - Batch loss: 155.5066 - Epoch Loss: 36132.8333 - Avg Loss: 158.4773\n",
            "Epoch [19/50] - Batch loss: 160.8253 - Epoch Loss: 36293.6586 - Avg Loss: 158.4876\n",
            "Epoch [19/50] - Batch loss: 163.1005 - Epoch Loss: 36456.7591 - Avg Loss: 158.5076\n",
            "Epoch [19/50] - Batch loss: 168.6029 - Epoch Loss: 36625.3619 - Avg Loss: 158.5514\n",
            "Epoch [19/50] - Batch loss: 164.9201 - Epoch Loss: 36790.2821 - Avg Loss: 158.5788\n",
            "Epoch [19/50] - Batch loss: 151.9851 - Epoch Loss: 36942.2671 - Avg Loss: 158.5505\n",
            "Epoch [19/50] - Batch loss: 143.4357 - Epoch Loss: 37085.7028 - Avg Loss: 158.4859\n",
            "Epoch [19/50] - Batch loss: 153.6372 - Epoch Loss: 37239.3399 - Avg Loss: 158.4653\n",
            "Epoch [19/50] - Batch loss: 148.0067 - Epoch Loss: 37387.3466 - Avg Loss: 158.4210\n",
            "Epoch [19/50] - Batch loss: 158.5561 - Epoch Loss: 37545.9028 - Avg Loss: 158.4215\n",
            "Epoch [19/50] - Batch loss: 161.5410 - Epoch Loss: 37707.4438 - Avg Loss: 158.4346\n",
            "Epoch [19/50] - Batch loss: 161.3106 - Epoch Loss: 37868.7543 - Avg Loss: 158.4467\n",
            "Epoch [19/50] - Batch loss: 159.5209 - Epoch Loss: 38028.2753 - Avg Loss: 158.4511\n",
            "Epoch [19/50] - Batch loss: 150.6081 - Epoch Loss: 38178.8834 - Avg Loss: 158.4186\n",
            "Epoch [19/50] - Batch loss: 157.9921 - Epoch Loss: 38336.8755 - Avg Loss: 158.4168\n",
            "Epoch [19/50] - Batch loss: 163.2996 - Epoch Loss: 38500.1751 - Avg Loss: 158.4369\n",
            "Epoch [19/50] - Batch loss: 157.9790 - Epoch Loss: 38658.1542 - Avg Loss: 158.4351\n",
            "Epoch [19/50] - Batch loss: 153.8979 - Epoch Loss: 38812.0521 - Avg Loss: 158.4165\n",
            "Epoch [19/50] - Batch loss: 157.0728 - Epoch Loss: 38969.1249 - Avg Loss: 158.4111\n",
            "Epoch [19/50] - Batch loss: 152.3874 - Epoch Loss: 39121.5123 - Avg Loss: 158.3867\n",
            "Epoch [19/50] - Batch loss: 161.5291 - Epoch Loss: 39283.0414 - Avg Loss: 158.3994\n",
            "Epoch [19/50] - Batch loss: 163.3119 - Epoch Loss: 39446.3533 - Avg Loss: 158.4191\n",
            "Epoch [19/50] - Batch loss: 152.7245 - Epoch Loss: 39599.0778 - Avg Loss: 158.3963\n",
            "Epoch [19/50] - Batch loss: 158.0937 - Epoch Loss: 39757.1716 - Avg Loss: 158.3951\n",
            "Epoch [19/50] - Batch loss: 156.3004 - Epoch Loss: 39913.4720 - Avg Loss: 158.3868\n",
            "Epoch [19/50] - Batch loss: 161.7720 - Epoch Loss: 40075.2440 - Avg Loss: 158.4002\n",
            "Epoch [19/50] - Batch loss: 163.9457 - Epoch Loss: 40239.1897 - Avg Loss: 158.4220\n",
            "Epoch [19/50] - Batch loss: 161.4408 - Epoch Loss: 40400.6306 - Avg Loss: 158.4338\n",
            "Epoch [19/50] - Batch loss: 153.5703 - Epoch Loss: 40554.2009 - Avg Loss: 158.4148\n",
            "Epoch [19/50] - Batch loss: 169.5276 - Epoch Loss: 40723.7285 - Avg Loss: 158.4581\n",
            "Epoch [19/50] - Batch loss: 160.3422 - Epoch Loss: 40884.0707 - Avg Loss: 158.4654\n",
            "Epoch [19/50] - Batch loss: 152.8406 - Epoch Loss: 41036.9113 - Avg Loss: 158.4437\n",
            "Epoch [19/50] - Batch loss: 159.1351 - Epoch Loss: 41196.0464 - Avg Loss: 158.4463\n",
            "Epoch [19/50] - Batch loss: 160.9380 - Epoch Loss: 41356.9844 - Avg Loss: 158.4559\n",
            "Epoch [19/50] - Batch loss: 157.5674 - Epoch Loss: 41514.5517 - Avg Loss: 158.4525\n",
            "Epoch [19/50] - Batch loss: 160.4227 - Epoch Loss: 41674.9744 - Avg Loss: 158.4600\n",
            "Epoch [19/50] - Batch loss: 154.2760 - Epoch Loss: 41829.2504 - Avg Loss: 158.4441\n",
            "Epoch [19/50] - Batch loss: 158.7955 - Epoch Loss: 41988.0458 - Avg Loss: 158.4455\n",
            "Epoch [19/50] - Batch loss: 154.5832 - Epoch Loss: 42142.6290 - Avg Loss: 158.4309\n",
            "Epoch [19/50] - Batch loss: 161.2176 - Epoch Loss: 42303.8466 - Avg Loss: 158.4414\n",
            "Epoch [19/50] - Batch loss: 161.1838 - Epoch Loss: 42465.0304 - Avg Loss: 158.4516\n",
            "Epoch [19/50] - Batch loss: 154.1026 - Epoch Loss: 42619.1331 - Avg Loss: 158.4354\n",
            "Epoch [19/50] - Batch loss: 168.6847 - Epoch Loss: 42787.8178 - Avg Loss: 158.4734\n",
            "Epoch [19/50] - Batch loss: 157.8178 - Epoch Loss: 42945.6356 - Avg Loss: 158.4710\n",
            "Epoch [19/50] - Batch loss: 159.6581 - Epoch Loss: 43105.2936 - Avg Loss: 158.4753\n",
            "Epoch [19/50] - Batch loss: 150.4337 - Epoch Loss: 43255.7273 - Avg Loss: 158.4459\n",
            "Epoch [19/50] - Batch loss: 159.5531 - Epoch Loss: 43415.2804 - Avg Loss: 158.4499\n",
            "Epoch [19/50] - Batch loss: 159.8277 - Epoch Loss: 43575.1081 - Avg Loss: 158.4549\n",
            "Epoch [19/50] - Batch loss: 160.8161 - Epoch Loss: 43735.9241 - Avg Loss: 158.4635\n",
            "Epoch [19/50] - Batch loss: 152.5165 - Epoch Loss: 43888.4406 - Avg Loss: 158.4420\n",
            "Epoch [19/50] - Batch loss: 152.2692 - Epoch Loss: 44040.7098 - Avg Loss: 158.4198\n",
            "Epoch [19/50] - Batch loss: 162.9321 - Epoch Loss: 44203.6420 - Avg Loss: 158.4360\n",
            "Epoch [19/50] - Batch loss: 158.9952 - Epoch Loss: 44362.6371 - Avg Loss: 158.4380\n",
            "Epoch [19/50] - Batch loss: 158.8530 - Epoch Loss: 44521.4902 - Avg Loss: 158.4395\n",
            "Epoch [19/50] - Batch loss: 149.0758 - Epoch Loss: 44670.5660 - Avg Loss: 158.4063\n",
            "Epoch [19/50] - Batch loss: 152.3772 - Epoch Loss: 44822.9432 - Avg Loss: 158.3850\n",
            "Epoch [19/50] - Batch loss: 172.7369 - Epoch Loss: 44995.6801 - Avg Loss: 158.4355\n",
            "Epoch [19/50] - Batch loss: 168.6048 - Epoch Loss: 45164.2849 - Avg Loss: 158.4712\n",
            "Epoch [19/50] - Batch loss: 159.8288 - Epoch Loss: 45324.1137 - Avg Loss: 158.4759\n",
            "Epoch [19/50] - Batch loss: 167.4966 - Epoch Loss: 45491.6104 - Avg Loss: 158.5074\n",
            "Epoch [19/50] - Batch loss: 151.4837 - Epoch Loss: 45643.0940 - Avg Loss: 158.4830\n",
            "Epoch [19/50] - Batch loss: 153.6167 - Epoch Loss: 45796.7108 - Avg Loss: 158.4661\n",
            "Epoch [19/50] - Batch loss: 162.6413 - Epoch Loss: 45959.3521 - Avg Loss: 158.4805\n",
            "Epoch [19/50] - Batch loss: 169.0444 - Epoch Loss: 46128.3964 - Avg Loss: 158.5168\n",
            "Epoch [19/50] - Batch loss: 158.3423 - Epoch Loss: 46286.7387 - Avg Loss: 158.5162\n",
            "Epoch [19/50] - Batch loss: 155.2287 - Epoch Loss: 46441.9674 - Avg Loss: 158.5050\n",
            "Epoch [19/50] - Batch loss: 158.5268 - Epoch Loss: 46600.4942 - Avg Loss: 158.5051\n",
            "Epoch [19/50] - Batch loss: 157.2706 - Epoch Loss: 46757.7649 - Avg Loss: 158.5009\n",
            "Epoch [19/50] - Batch loss: 155.4537 - Epoch Loss: 46913.2185 - Avg Loss: 158.4906\n",
            "Epoch [19/50] - Batch loss: 151.2950 - Epoch Loss: 47064.5135 - Avg Loss: 158.4664\n",
            "Epoch [19/50] - Batch loss: 156.9854 - Epoch Loss: 47221.4989 - Avg Loss: 158.4614\n",
            "Epoch [19/50] - Batch loss: 154.7805 - Epoch Loss: 47376.2794 - Avg Loss: 158.4491\n",
            "Epoch [19/50] - Batch loss: 168.2063 - Epoch Loss: 47544.4857 - Avg Loss: 158.4816\n",
            "Epoch [19/50] - Batch loss: 155.8425 - Epoch Loss: 47700.3282 - Avg Loss: 158.4729\n",
            "Epoch [19/50] - Batch loss: 152.9934 - Epoch Loss: 47853.3216 - Avg Loss: 158.4547\n",
            "Epoch [19/50] - Batch loss: 159.5059 - Epoch Loss: 48012.8275 - Avg Loss: 158.4582\n",
            "Epoch [19/50] - Batch loss: 157.1024 - Epoch Loss: 48169.9299 - Avg Loss: 158.4537\n",
            "Epoch [19/50] - Batch loss: 156.7563 - Epoch Loss: 48326.6862 - Avg Loss: 158.4482\n",
            "Epoch [19/50] - Batch loss: 168.7565 - Epoch Loss: 48495.4427 - Avg Loss: 158.4818\n",
            "Epoch [19/50] - Batch loss: 154.3214 - Epoch Loss: 48649.7641 - Avg Loss: 158.4683\n",
            "Epoch [19/50] - Batch loss: 170.4613 - Epoch Loss: 48820.2254 - Avg Loss: 158.5072\n",
            "Epoch [19/50] - Batch loss: 159.3539 - Epoch Loss: 48979.5794 - Avg Loss: 158.5100\n",
            "Epoch [19/50] - Batch loss: 163.6372 - Epoch Loss: 49143.2166 - Avg Loss: 158.5265\n",
            "Epoch [19/50] - Batch loss: 161.7287 - Epoch Loss: 49304.9453 - Avg Loss: 158.5368\n",
            "Epoch [19/50] - Batch loss: 161.3579 - Epoch Loss: 49466.3032 - Avg Loss: 158.5458\n",
            "Epoch [19/50] - Batch loss: 155.4978 - Epoch Loss: 49621.8011 - Avg Loss: 158.5361\n",
            "Epoch [19/50] - Batch loss: 156.9143 - Epoch Loss: 49778.7153 - Avg Loss: 158.5309\n",
            "Epoch [19/50] - Batch loss: 155.0744 - Epoch Loss: 49933.7898 - Avg Loss: 158.5200\n",
            "Epoch [19/50] - Batch loss: 158.3703 - Epoch Loss: 50092.1601 - Avg Loss: 158.5195\n",
            "Epoch [19/50] - Batch loss: 157.8680 - Epoch Loss: 50250.0281 - Avg Loss: 158.5174\n",
            "Epoch [19/50] - Batch loss: 153.1954 - Epoch Loss: 50403.2235 - Avg Loss: 158.5007\n",
            "Epoch [19/50] - Batch loss: 155.7418 - Epoch Loss: 50558.9653 - Avg Loss: 158.4921\n",
            "Epoch [19/50] - Batch loss: 161.9214 - Epoch Loss: 50720.8867 - Avg Loss: 158.5028\n",
            "Epoch [19/50] - Batch loss: 158.3913 - Epoch Loss: 50879.2780 - Avg Loss: 158.5024\n",
            "Epoch [19/50] - Batch loss: 168.2788 - Epoch Loss: 51047.5568 - Avg Loss: 158.5328\n",
            "Epoch [19/50] - Batch loss: 161.9130 - Epoch Loss: 51209.4698 - Avg Loss: 158.5433\n",
            "Epoch [19/50] - Batch loss: 154.2295 - Epoch Loss: 51363.6993 - Avg Loss: 158.5299\n",
            "Epoch [19/50] - Batch loss: 164.9849 - Epoch Loss: 51528.6842 - Avg Loss: 158.5498\n",
            "Epoch [19/50] - Batch loss: 158.2182 - Epoch Loss: 51686.9024 - Avg Loss: 158.5488\n",
            "Epoch [19/50] - Batch loss: 163.5341 - Epoch Loss: 51850.4366 - Avg Loss: 158.5640\n",
            "Epoch [19/50] - Batch loss: 155.7719 - Epoch Loss: 52006.2085 - Avg Loss: 158.5555\n",
            "Epoch [19/50] - Batch loss: 161.0923 - Epoch Loss: 52167.3008 - Avg Loss: 158.5632\n",
            "Epoch [19/50] - Batch loss: 156.4864 - Epoch Loss: 52323.7871 - Avg Loss: 158.5569\n",
            "Epoch [19/50] - Batch loss: 159.9603 - Epoch Loss: 52483.7474 - Avg Loss: 158.5612\n",
            "Epoch [19/50] - Batch loss: 160.1461 - Epoch Loss: 52643.8935 - Avg Loss: 158.5659\n",
            "Epoch [19/50] - Batch loss: 161.2027 - Epoch Loss: 52805.0963 - Avg Loss: 158.5739\n",
            "Epoch [19/50] - Batch loss: 161.9676 - Epoch Loss: 52967.0638 - Avg Loss: 158.5840\n",
            "Epoch [19/50] - Batch loss: 149.1053 - Epoch Loss: 53116.1692 - Avg Loss: 158.5557\n",
            "Epoch [19/50] - Batch loss: 156.5865 - Epoch Loss: 53272.7557 - Avg Loss: 158.5499\n",
            "Epoch [19/50] - Batch loss: 164.9454 - Epoch Loss: 53437.7011 - Avg Loss: 158.5688\n",
            "Epoch [19/50] - Batch loss: 161.4568 - Epoch Loss: 53599.1579 - Avg Loss: 158.5774\n",
            "Epoch [19/50] - Batch loss: 163.5166 - Epoch Loss: 53762.6746 - Avg Loss: 158.5920\n",
            "Epoch [19/50] - Batch loss: 162.2452 - Epoch Loss: 53924.9198 - Avg Loss: 158.6027\n",
            "Epoch [19/50] - Batch loss: 153.7939 - Epoch Loss: 54078.7137 - Avg Loss: 158.5886\n",
            "Epoch [19/50] - Batch loss: 162.0182 - Epoch Loss: 54240.7319 - Avg Loss: 158.5986\n",
            "Epoch [19/50] - Batch loss: 152.4954 - Epoch Loss: 54393.2273 - Avg Loss: 158.5808\n",
            "Epoch [19/50] - Batch loss: 157.7944 - Epoch Loss: 54551.0216 - Avg Loss: 158.5786\n",
            "Epoch [19/50] - Batch loss: 154.7892 - Epoch Loss: 54705.8109 - Avg Loss: 158.5676\n",
            "Epoch [19/50] - Batch loss: 164.0385 - Epoch Loss: 54869.8493 - Avg Loss: 158.5834\n",
            "Epoch [19/50] - Batch loss: 157.2051 - Epoch Loss: 55027.0544 - Avg Loss: 158.5794\n",
            "Epoch [19/50] - Batch loss: 163.5665 - Epoch Loss: 55190.6209 - Avg Loss: 158.5937\n",
            "Epoch [19/50] - Batch loss: 157.4245 - Epoch Loss: 55348.0455 - Avg Loss: 158.5904\n",
            "Epoch [19/50] - Batch loss: 159.1859 - Epoch Loss: 55507.2314 - Avg Loss: 158.5921\n",
            "Epoch [19/50] - Batch loss: 156.8444 - Epoch Loss: 55664.0758 - Avg Loss: 158.5871\n",
            "Epoch [19/50] - Batch loss: 153.1303 - Epoch Loss: 55817.2061 - Avg Loss: 158.5716\n",
            "Epoch [19/50] - Batch loss: 160.2220 - Epoch Loss: 55977.4281 - Avg Loss: 158.5763\n",
            "Epoch [19/50] - Batch loss: 166.5573 - Epoch Loss: 56143.9854 - Avg Loss: 158.5988\n",
            "Epoch [19/50] - Batch loss: 154.7227 - Epoch Loss: 56298.7081 - Avg Loss: 158.5879\n",
            "Epoch [19/50] - Batch loss: 156.7440 - Epoch Loss: 56455.4521 - Avg Loss: 158.5827\n",
            "Epoch [19/50] - Batch loss: 163.5652 - Epoch Loss: 56619.0173 - Avg Loss: 158.5967\n",
            "Epoch [19/50] - Batch loss: 152.9754 - Epoch Loss: 56771.9927 - Avg Loss: 158.5810\n",
            "Epoch [19/50] - Batch loss: 154.9831 - Epoch Loss: 56926.9758 - Avg Loss: 158.5710\n",
            "Epoch [19/50] - Batch loss: 160.8466 - Epoch Loss: 57087.8224 - Avg Loss: 158.5773\n",
            "Epoch [19/50] - Batch loss: 159.6578 - Epoch Loss: 57247.4801 - Avg Loss: 158.5803\n",
            "Epoch [19/50] - Batch loss: 151.6884 - Epoch Loss: 57399.1685 - Avg Loss: 158.5612\n",
            "Epoch [19/50] - Batch loss: 159.9519 - Epoch Loss: 57559.1204 - Avg Loss: 158.5651\n",
            "Epoch [19/50] - Batch loss: 160.7985 - Epoch Loss: 57719.9190 - Avg Loss: 158.5712\n",
            "Epoch [19/50] - Batch loss: 162.8082 - Epoch Loss: 57882.7271 - Avg Loss: 158.5828\n",
            "Epoch [19/50] - Batch loss: 164.3709 - Epoch Loss: 58047.0980 - Avg Loss: 158.5986\n",
            "Epoch [19/50] - Batch loss: 163.7015 - Epoch Loss: 58210.7995 - Avg Loss: 158.6125\n",
            "Epoch [19/50] - Batch loss: 158.0288 - Epoch Loss: 58368.8283 - Avg Loss: 158.6109\n",
            "Epoch [19/50] - Batch loss: 168.0951 - Epoch Loss: 58536.9233 - Avg Loss: 158.6366\n",
            "Epoch [19/50] - Batch loss: 154.7712 - Epoch Loss: 58691.6946 - Avg Loss: 158.6262\n",
            "Epoch [19/50] - Batch loss: 152.8439 - Epoch Loss: 58844.5385 - Avg Loss: 158.6106\n",
            "Epoch [19/50] - Batch loss: 161.2843 - Epoch Loss: 59005.8227 - Avg Loss: 158.6178\n",
            "Epoch [19/50] - Batch loss: 158.7633 - Epoch Loss: 59164.5860 - Avg Loss: 158.6182\n",
            "Epoch [19/50] - Batch loss: 157.7441 - Epoch Loss: 59322.3301 - Avg Loss: 158.6159\n",
            "Epoch [19/50] - Batch loss: 152.9622 - Epoch Loss: 59475.2923 - Avg Loss: 158.6008\n",
            "Epoch [19/50] - Batch loss: 160.0504 - Epoch Loss: 59635.3428 - Avg Loss: 158.6046\n",
            "Epoch [19/50] - Batch loss: 158.9307 - Epoch Loss: 59794.2735 - Avg Loss: 158.6055\n",
            "Epoch [19/50] - Batch loss: 161.2361 - Epoch Loss: 59955.5096 - Avg Loss: 158.6125\n",
            "Epoch [19/50] - Batch loss: 150.5179 - Epoch Loss: 60106.0275 - Avg Loss: 158.5911\n",
            "Epoch [19/50] - Batch loss: 163.3467 - Epoch Loss: 60269.3741 - Avg Loss: 158.6036\n",
            "Epoch [19/50] - Batch loss: 154.4805 - Epoch Loss: 60423.8547 - Avg Loss: 158.5928\n",
            "Epoch [19/50] - Batch loss: 167.9674 - Epoch Loss: 60591.8221 - Avg Loss: 158.6173\n",
            "Epoch [19/50] - Batch loss: 157.1209 - Epoch Loss: 60748.9430 - Avg Loss: 158.6134\n",
            "Epoch [19/50] - Batch loss: 155.3364 - Epoch Loss: 60904.2794 - Avg Loss: 158.6049\n",
            "Epoch [19/50] - Batch loss: 161.6967 - Epoch Loss: 61065.9761 - Avg Loss: 158.6129\n",
            "Epoch [19/50] - Batch loss: 163.7941 - Epoch Loss: 61229.7701 - Avg Loss: 158.6263\n",
            "Epoch [19/50] - Batch loss: 160.6644 - Epoch Loss: 61390.4346 - Avg Loss: 158.6316\n",
            "Epoch [19/50] - Batch loss: 164.3647 - Epoch Loss: 61554.7993 - Avg Loss: 158.6464\n",
            "Epoch [19/50] - Batch loss: 160.7295 - Epoch Loss: 61715.5288 - Avg Loss: 158.6517\n",
            "Epoch [19/50] - Batch loss: 162.2702 - Epoch Loss: 61877.7990 - Avg Loss: 158.6610\n",
            "Epoch [19/50] - Batch loss: 160.4876 - Epoch Loss: 62038.2866 - Avg Loss: 158.6657\n",
            "Epoch [19/50] - Batch loss: 155.3888 - Epoch Loss: 62193.6754 - Avg Loss: 158.6573\n",
            "Epoch [19/50] - Batch loss: 165.4908 - Epoch Loss: 62359.1663 - Avg Loss: 158.6747\n",
            "Epoch [19/50] - Batch loss: 153.8268 - Epoch Loss: 62512.9931 - Avg Loss: 158.6624\n",
            "Epoch [19/50] - Batch loss: 157.0206 - Epoch Loss: 62670.0137 - Avg Loss: 158.6583\n",
            "Epoch [19/50] - Batch loss: 162.7010 - Epoch Loss: 62832.7147 - Avg Loss: 158.6685\n",
            "Epoch [19/50] - Batch loss: 157.3924 - Epoch Loss: 62990.1071 - Avg Loss: 158.6653\n",
            "Epoch [19/50] - Batch loss: 159.9465 - Epoch Loss: 63150.0536 - Avg Loss: 158.6685\n",
            "Epoch [19/50] - Batch loss: 151.5564 - Epoch Loss: 63301.6101 - Avg Loss: 158.6507\n",
            "Epoch [19/50] - Batch loss: 161.4399 - Epoch Loss: 63463.0500 - Avg Loss: 158.6576\n",
            "Epoch [19/50] - Batch loss: 170.0168 - Epoch Loss: 63633.0667 - Avg Loss: 158.6860\n",
            "Epoch [19/50] - Batch loss: 161.4076 - Epoch Loss: 63794.4743 - Avg Loss: 158.6927\n",
            "Epoch [19/50] - Batch loss: 157.6900 - Epoch Loss: 63952.1644 - Avg Loss: 158.6902\n",
            "Epoch [19/50] - Batch loss: 163.6841 - Epoch Loss: 64115.8485 - Avg Loss: 158.7026\n",
            "Epoch [19/50] - Batch loss: 159.6601 - Epoch Loss: 64275.5086 - Avg Loss: 158.7050\n",
            "Epoch [19/50] - Batch loss: 155.6494 - Epoch Loss: 64431.1580 - Avg Loss: 158.6974\n",
            "Epoch [19/50] - Batch loss: 154.8180 - Epoch Loss: 64585.9760 - Avg Loss: 158.6879\n",
            "Epoch [19/50] - Batch loss: 159.9786 - Epoch Loss: 64745.9546 - Avg Loss: 158.6911\n",
            "Epoch [19/50] - Batch loss: 153.1022 - Epoch Loss: 64899.0567 - Avg Loss: 158.6774\n",
            "Epoch [19/50] - Batch loss: 166.7610 - Epoch Loss: 65065.8178 - Avg Loss: 158.6971\n",
            "Epoch [19/50] - Batch loss: 165.8223 - Epoch Loss: 65231.6401 - Avg Loss: 158.7145\n",
            "Epoch [19/50] - Batch loss: 164.9197 - Epoch Loss: 65396.5598 - Avg Loss: 158.7295\n",
            "Epoch [19/50] - Batch loss: 162.1765 - Epoch Loss: 65558.7363 - Avg Loss: 158.7379\n",
            "Epoch [19/50] - Batch loss: 158.1873 - Epoch Loss: 65716.9235 - Avg Loss: 158.7365\n",
            "Epoch [19/50] - Batch loss: 162.8709 - Epoch Loss: 65879.7944 - Avg Loss: 158.7465\n",
            "Epoch [19/50] - Batch loss: 163.8899 - Epoch Loss: 66043.6844 - Avg Loss: 158.7589\n",
            "Epoch [19/50] - Batch loss: 164.8932 - Epoch Loss: 66208.5775 - Avg Loss: 158.7736\n",
            "Epoch [19/50] - Batch loss: 159.8118 - Epoch Loss: 66368.3894 - Avg Loss: 158.7761\n",
            "Epoch [19/50] - Batch loss: 164.2652 - Epoch Loss: 66532.6545 - Avg Loss: 158.7892\n",
            "Epoch [19/50] - Batch loss: 160.9809 - Epoch Loss: 66693.6354 - Avg Loss: 158.7944\n",
            "Epoch [19/50] - Batch loss: 167.9844 - Epoch Loss: 66861.6197 - Avg Loss: 158.8162\n",
            "Epoch [19/50] - Batch loss: 158.4909 - Epoch Loss: 67020.1106 - Avg Loss: 158.8154\n",
            "Epoch [19/50] - Batch loss: 157.8672 - Epoch Loss: 67177.9778 - Avg Loss: 158.8132\n",
            "Epoch [19/50] - Batch loss: 158.5101 - Epoch Loss: 67336.4879 - Avg Loss: 158.8125\n",
            "Epoch [19/50] - Batch loss: 160.2654 - Epoch Loss: 67496.7533 - Avg Loss: 158.8159\n",
            "Epoch [19/50] - Batch loss: 166.2068 - Epoch Loss: 67662.9600 - Avg Loss: 158.8332\n",
            "Epoch [19/50] - Batch loss: 165.9176 - Epoch Loss: 67828.8776 - Avg Loss: 158.8498\n",
            "Epoch [19/50] - Batch loss: 152.3266 - Epoch Loss: 67981.2042 - Avg Loss: 158.8346\n",
            "Epoch [19/50] - Batch loss: 154.7235 - Epoch Loss: 68135.9277 - Avg Loss: 158.8250\n",
            "Epoch [19/50] - Batch loss: 152.5982 - Epoch Loss: 68288.5259 - Avg Loss: 158.8105\n",
            "Epoch [19/50] - Batch loss: 158.0152 - Epoch Loss: 68446.5411 - Avg Loss: 158.8087\n",
            "Epoch [19/50] - Batch loss: 155.4043 - Epoch Loss: 68601.9454 - Avg Loss: 158.8008\n",
            "Epoch [19/50] - Batch loss: 167.2708 - Epoch Loss: 68769.2162 - Avg Loss: 158.8204\n",
            "Epoch [19/50] - Batch loss: 161.5247 - Epoch Loss: 68930.7409 - Avg Loss: 158.8266\n",
            "Epoch [19/50] - Batch loss: 158.8714 - Epoch Loss: 69089.6122 - Avg Loss: 158.8267\n",
            "Epoch [19/50] - Batch loss: 157.5072 - Epoch Loss: 69247.1194 - Avg Loss: 158.8237\n",
            "Epoch [19/50] - Batch loss: 169.4765 - Epoch Loss: 69416.5959 - Avg Loss: 158.8480\n",
            "Epoch [19/50] - Batch loss: 158.8731 - Epoch Loss: 69575.4689 - Avg Loss: 158.8481\n",
            "Epoch [19/50] - Batch loss: 160.5063 - Epoch Loss: 69735.9753 - Avg Loss: 158.8519\n",
            "Epoch [19/50] - Batch loss: 150.7885 - Epoch Loss: 69886.7637 - Avg Loss: 158.8336\n",
            "Epoch [19/50] - Batch loss: 164.2699 - Epoch Loss: 70051.0337 - Avg Loss: 158.8459\n",
            "Epoch [19/50] - Batch loss: 156.3337 - Epoch Loss: 70207.3673 - Avg Loss: 158.8402\n",
            "Epoch [19/50] - Batch loss: 157.9449 - Epoch Loss: 70365.3122 - Avg Loss: 158.8382\n",
            "Epoch [19/50] - Batch loss: 157.8677 - Epoch Loss: 70523.1800 - Avg Loss: 158.8360\n",
            "Epoch [19/50] - Batch loss: 163.1241 - Epoch Loss: 70686.3040 - Avg Loss: 158.8456\n",
            "Epoch [19/50] - Batch loss: 159.2119 - Epoch Loss: 70845.5160 - Avg Loss: 158.8464\n",
            "Epoch [19/50] - Batch loss: 158.5905 - Epoch Loss: 71004.1065 - Avg Loss: 158.8459\n",
            "Epoch [19/50] - Batch loss: 163.1025 - Epoch Loss: 71167.2090 - Avg Loss: 158.8554\n",
            "Epoch [19/50] - Batch loss: 167.9452 - Epoch Loss: 71335.1541 - Avg Loss: 158.8756\n",
            "Epoch [19/50] - Batch loss: 160.2249 - Epoch Loss: 71495.3790 - Avg Loss: 158.8786\n",
            "Epoch [19/50] - Batch loss: 160.8397 - Epoch Loss: 71656.2188 - Avg Loss: 158.8830\n",
            "Epoch [19/50] - Batch loss: 157.0656 - Epoch Loss: 71813.2844 - Avg Loss: 158.8789\n",
            "Epoch [19/50] - Batch loss: 165.1835 - Epoch Loss: 71978.4679 - Avg Loss: 158.8929\n",
            "Epoch [19/50] - Batch loss: 162.3755 - Epoch Loss: 72140.8434 - Avg Loss: 158.9005\n",
            "Epoch [19/50] - Batch loss: 162.3765 - Epoch Loss: 72303.2199 - Avg Loss: 158.9082\n",
            "Epoch [19/50] - Batch loss: 158.1892 - Epoch Loss: 72461.4090 - Avg Loss: 158.9066\n",
            "Epoch [19/50] - Batch loss: 160.2614 - Epoch Loss: 72621.6705 - Avg Loss: 158.9096\n",
            "Epoch [19/50] - Batch loss: 162.3933 - Epoch Loss: 72784.0638 - Avg Loss: 158.9172\n",
            "Epoch [19/50] - Batch loss: 154.7380 - Epoch Loss: 72938.8018 - Avg Loss: 158.9081\n",
            "Epoch [19/50] - Batch loss: 157.9823 - Epoch Loss: 73096.7841 - Avg Loss: 158.9061\n",
            "Epoch [19/50] - Batch loss: 155.1127 - Epoch Loss: 73251.8968 - Avg Loss: 158.8978\n",
            "Epoch [19/50] - Batch loss: 162.2309 - Epoch Loss: 73414.1277 - Avg Loss: 158.9050\n",
            "Epoch [19/50] - Batch loss: 163.6004 - Epoch Loss: 73577.7281 - Avg Loss: 158.9152\n",
            "Epoch [19/50] - Batch loss: 162.0062 - Epoch Loss: 73739.7343 - Avg Loss: 158.9218\n",
            "Epoch [19/50] - Batch loss: 157.8787 - Epoch Loss: 73897.6130 - Avg Loss: 158.9196\n",
            "Epoch [19/50] - Batch loss: 157.9411 - Epoch Loss: 74055.5540 - Avg Loss: 158.9175\n",
            "Epoch [19/50] - Batch loss: 154.6014 - Epoch Loss: 74210.1554 - Avg Loss: 158.9083\n",
            "Epoch [19/50] - Batch loss: 153.9418 - Epoch Loss: 74364.0972 - Avg Loss: 158.8976\n",
            "Epoch [19/50] - Batch loss: 161.6945 - Epoch Loss: 74525.7918 - Avg Loss: 158.9036\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 20/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87fe475b86494a1c8609762612b317d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/50] - Batch loss: 159.2222 - Epoch Loss: 159.2222 - Avg Loss: 159.2222\n",
            "Epoch [20/50] - Batch loss: 167.4600 - Epoch Loss: 326.6822 - Avg Loss: 163.3411\n",
            "Epoch [20/50] - Batch loss: 155.3281 - Epoch Loss: 482.0103 - Avg Loss: 160.6701\n",
            "Epoch [20/50] - Batch loss: 156.3568 - Epoch Loss: 638.3671 - Avg Loss: 159.5918\n",
            "Epoch [20/50] - Batch loss: 158.6901 - Epoch Loss: 797.0572 - Avg Loss: 159.4114\n",
            "Epoch [20/50] - Batch loss: 158.6502 - Epoch Loss: 955.7074 - Avg Loss: 159.2846\n",
            "Epoch [20/50] - Batch loss: 156.1581 - Epoch Loss: 1111.8656 - Avg Loss: 158.8379\n",
            "Epoch [20/50] - Batch loss: 157.9469 - Epoch Loss: 1269.8124 - Avg Loss: 158.7266\n",
            "Epoch [20/50] - Batch loss: 154.4381 - Epoch Loss: 1424.2505 - Avg Loss: 158.2501\n",
            "Epoch [20/50] - Batch loss: 152.9432 - Epoch Loss: 1577.1937 - Avg Loss: 157.7194\n",
            "Epoch [20/50] - Batch loss: 158.0134 - Epoch Loss: 1735.2071 - Avg Loss: 157.7461\n",
            "Epoch [20/50] - Batch loss: 155.6082 - Epoch Loss: 1890.8152 - Avg Loss: 157.5679\n",
            "Epoch [20/50] - Batch loss: 163.2215 - Epoch Loss: 2054.0368 - Avg Loss: 158.0028\n",
            "Epoch [20/50] - Batch loss: 159.7571 - Epoch Loss: 2213.7939 - Avg Loss: 158.1281\n",
            "Epoch [20/50] - Batch loss: 155.9940 - Epoch Loss: 2369.7879 - Avg Loss: 157.9859\n",
            "Epoch [20/50] - Batch loss: 164.4719 - Epoch Loss: 2534.2598 - Avg Loss: 158.3912\n",
            "Epoch [20/50] - Batch loss: 162.0131 - Epoch Loss: 2696.2729 - Avg Loss: 158.6043\n",
            "Epoch [20/50] - Batch loss: 164.5903 - Epoch Loss: 2860.8632 - Avg Loss: 158.9368\n",
            "Epoch [20/50] - Batch loss: 163.1832 - Epoch Loss: 3024.0464 - Avg Loss: 159.1603\n",
            "Epoch [20/50] - Batch loss: 159.0589 - Epoch Loss: 3183.1054 - Avg Loss: 159.1553\n",
            "Epoch [20/50] - Batch loss: 159.8750 - Epoch Loss: 3342.9803 - Avg Loss: 159.1895\n",
            "Epoch [20/50] - Batch loss: 163.7391 - Epoch Loss: 3506.7195 - Avg Loss: 159.3963\n",
            "Epoch [20/50] - Batch loss: 161.4614 - Epoch Loss: 3668.1809 - Avg Loss: 159.4861\n",
            "Epoch [20/50] - Batch loss: 160.4824 - Epoch Loss: 3828.6633 - Avg Loss: 159.5276\n",
            "Epoch [20/50] - Batch loss: 167.5779 - Epoch Loss: 3996.2412 - Avg Loss: 159.8496\n",
            "Epoch [20/50] - Batch loss: 158.2718 - Epoch Loss: 4154.5130 - Avg Loss: 159.7890\n",
            "Epoch [20/50] - Batch loss: 165.9485 - Epoch Loss: 4320.4615 - Avg Loss: 160.0171\n",
            "Epoch [20/50] - Batch loss: 159.9844 - Epoch Loss: 4480.4459 - Avg Loss: 160.0159\n",
            "Epoch [20/50] - Batch loss: 162.2635 - Epoch Loss: 4642.7094 - Avg Loss: 160.0934\n",
            "Epoch [20/50] - Batch loss: 156.7712 - Epoch Loss: 4799.4807 - Avg Loss: 159.9827\n",
            "Epoch [20/50] - Batch loss: 163.0710 - Epoch Loss: 4962.5517 - Avg Loss: 160.0823\n",
            "Epoch [20/50] - Batch loss: 152.0339 - Epoch Loss: 5114.5856 - Avg Loss: 159.8308\n",
            "Epoch [20/50] - Batch loss: 162.6859 - Epoch Loss: 5277.2715 - Avg Loss: 159.9173\n",
            "Epoch [20/50] - Batch loss: 162.7092 - Epoch Loss: 5439.9807 - Avg Loss: 159.9994\n",
            "Epoch [20/50] - Batch loss: 151.1106 - Epoch Loss: 5591.0912 - Avg Loss: 159.7455\n",
            "Epoch [20/50] - Batch loss: 172.7713 - Epoch Loss: 5763.8626 - Avg Loss: 160.1073\n",
            "Epoch [20/50] - Batch loss: 163.3688 - Epoch Loss: 5927.2314 - Avg Loss: 160.1954\n",
            "Epoch [20/50] - Batch loss: 158.3445 - Epoch Loss: 6085.5759 - Avg Loss: 160.1467\n",
            "Epoch [20/50] - Batch loss: 155.1715 - Epoch Loss: 6240.7474 - Avg Loss: 160.0192\n",
            "Epoch [20/50] - Batch loss: 166.8738 - Epoch Loss: 6407.6211 - Avg Loss: 160.1905\n",
            "Epoch [20/50] - Batch loss: 156.4821 - Epoch Loss: 6564.1033 - Avg Loss: 160.1001\n",
            "Epoch [20/50] - Batch loss: 158.1167 - Epoch Loss: 6722.2200 - Avg Loss: 160.0529\n",
            "Epoch [20/50] - Batch loss: 172.3728 - Epoch Loss: 6894.5927 - Avg Loss: 160.3394\n",
            "Epoch [20/50] - Batch loss: 163.5383 - Epoch Loss: 7058.1310 - Avg Loss: 160.4121\n",
            "Epoch [20/50] - Batch loss: 164.9582 - Epoch Loss: 7223.0892 - Avg Loss: 160.5131\n",
            "Epoch [20/50] - Batch loss: 166.8827 - Epoch Loss: 7389.9718 - Avg Loss: 160.6516\n",
            "Epoch [20/50] - Batch loss: 167.3274 - Epoch Loss: 7557.2992 - Avg Loss: 160.7936\n",
            "Epoch [20/50] - Batch loss: 162.5665 - Epoch Loss: 7719.8657 - Avg Loss: 160.8305\n",
            "Epoch [20/50] - Batch loss: 159.8119 - Epoch Loss: 7879.6776 - Avg Loss: 160.8097\n",
            "Epoch [20/50] - Batch loss: 159.6712 - Epoch Loss: 8039.3488 - Avg Loss: 160.7870\n",
            "Epoch [20/50] - Batch loss: 166.8037 - Epoch Loss: 8206.1526 - Avg Loss: 160.9050\n",
            "Epoch [20/50] - Batch loss: 154.3745 - Epoch Loss: 8360.5271 - Avg Loss: 160.7794\n",
            "Epoch [20/50] - Batch loss: 155.8232 - Epoch Loss: 8516.3503 - Avg Loss: 160.6859\n",
            "Epoch [20/50] - Batch loss: 165.7530 - Epoch Loss: 8682.1033 - Avg Loss: 160.7797\n",
            "Epoch [20/50] - Batch loss: 161.3047 - Epoch Loss: 8843.4079 - Avg Loss: 160.7892\n",
            "Epoch [20/50] - Batch loss: 163.2602 - Epoch Loss: 9006.6681 - Avg Loss: 160.8334\n",
            "Epoch [20/50] - Batch loss: 160.8171 - Epoch Loss: 9167.4852 - Avg Loss: 160.8331\n",
            "Epoch [20/50] - Batch loss: 160.8929 - Epoch Loss: 9328.3781 - Avg Loss: 160.8341\n",
            "Epoch [20/50] - Batch loss: 162.7379 - Epoch Loss: 9491.1160 - Avg Loss: 160.8664\n",
            "Epoch [20/50] - Batch loss: 162.6301 - Epoch Loss: 9653.7461 - Avg Loss: 160.8958\n",
            "Epoch [20/50] - Batch loss: 159.6842 - Epoch Loss: 9813.4303 - Avg Loss: 160.8759\n",
            "Epoch [20/50] - Batch loss: 163.8185 - Epoch Loss: 9977.2488 - Avg Loss: 160.9234\n",
            "Epoch [20/50] - Batch loss: 160.5012 - Epoch Loss: 10137.7500 - Avg Loss: 160.9167\n",
            "Epoch [20/50] - Batch loss: 160.6325 - Epoch Loss: 10298.3825 - Avg Loss: 160.9122\n",
            "Epoch [20/50] - Batch loss: 152.7088 - Epoch Loss: 10451.0913 - Avg Loss: 160.7860\n",
            "Epoch [20/50] - Batch loss: 153.8528 - Epoch Loss: 10604.9441 - Avg Loss: 160.6810\n",
            "Epoch [20/50] - Batch loss: 159.3684 - Epoch Loss: 10764.3125 - Avg Loss: 160.6614\n",
            "Epoch [20/50] - Batch loss: 154.9605 - Epoch Loss: 10919.2730 - Avg Loss: 160.5775\n",
            "Epoch [20/50] - Batch loss: 161.1352 - Epoch Loss: 11080.4082 - Avg Loss: 160.5856\n",
            "Epoch [20/50] - Batch loss: 164.9349 - Epoch Loss: 11245.3431 - Avg Loss: 160.6478\n",
            "Epoch [20/50] - Batch loss: 159.3598 - Epoch Loss: 11404.7029 - Avg Loss: 160.6296\n",
            "Epoch [20/50] - Batch loss: 156.5452 - Epoch Loss: 11561.2481 - Avg Loss: 160.5729\n",
            "Epoch [20/50] - Batch loss: 163.7703 - Epoch Loss: 11725.0184 - Avg Loss: 160.6167\n",
            "Epoch [20/50] - Batch loss: 151.7832 - Epoch Loss: 11876.8015 - Avg Loss: 160.4973\n",
            "Epoch [20/50] - Batch loss: 161.8914 - Epoch Loss: 12038.6929 - Avg Loss: 160.5159\n",
            "Epoch [20/50] - Batch loss: 162.1075 - Epoch Loss: 12200.8004 - Avg Loss: 160.5368\n",
            "Epoch [20/50] - Batch loss: 165.5531 - Epoch Loss: 12366.3535 - Avg Loss: 160.6020\n",
            "Epoch [20/50] - Batch loss: 160.4326 - Epoch Loss: 12526.7861 - Avg Loss: 160.5998\n",
            "Epoch [20/50] - Batch loss: 162.7371 - Epoch Loss: 12689.5232 - Avg Loss: 160.6269\n",
            "Epoch [20/50] - Batch loss: 160.1013 - Epoch Loss: 12849.6245 - Avg Loss: 160.6203\n",
            "Epoch [20/50] - Batch loss: 153.6509 - Epoch Loss: 13003.2754 - Avg Loss: 160.5343\n",
            "Epoch [20/50] - Batch loss: 163.6181 - Epoch Loss: 13166.8935 - Avg Loss: 160.5719\n",
            "Epoch [20/50] - Batch loss: 167.9537 - Epoch Loss: 13334.8472 - Avg Loss: 160.6608\n",
            "Epoch [20/50] - Batch loss: 151.3206 - Epoch Loss: 13486.1679 - Avg Loss: 160.5496\n",
            "Epoch [20/50] - Batch loss: 161.1823 - Epoch Loss: 13647.3501 - Avg Loss: 160.5571\n",
            "Epoch [20/50] - Batch loss: 157.4175 - Epoch Loss: 13804.7677 - Avg Loss: 160.5206\n",
            "Epoch [20/50] - Batch loss: 157.5492 - Epoch Loss: 13962.3168 - Avg Loss: 160.4864\n",
            "Epoch [20/50] - Batch loss: 171.5670 - Epoch Loss: 14133.8839 - Avg Loss: 160.6123\n",
            "Epoch [20/50] - Batch loss: 168.9228 - Epoch Loss: 14302.8066 - Avg Loss: 160.7057\n",
            "Epoch [20/50] - Batch loss: 160.7567 - Epoch Loss: 14463.5633 - Avg Loss: 160.7063\n",
            "Epoch [20/50] - Batch loss: 168.7914 - Epoch Loss: 14632.3547 - Avg Loss: 160.7951\n",
            "Epoch [20/50] - Batch loss: 160.9450 - Epoch Loss: 14793.2998 - Avg Loss: 160.7967\n",
            "Epoch [20/50] - Batch loss: 162.1203 - Epoch Loss: 14955.4200 - Avg Loss: 160.8110\n",
            "Epoch [20/50] - Batch loss: 163.5680 - Epoch Loss: 15118.9880 - Avg Loss: 160.8403\n",
            "Epoch [20/50] - Batch loss: 167.3125 - Epoch Loss: 15286.3005 - Avg Loss: 160.9084\n",
            "Epoch [20/50] - Batch loss: 165.9215 - Epoch Loss: 15452.2220 - Avg Loss: 160.9606\n",
            "Epoch [20/50] - Batch loss: 167.1017 - Epoch Loss: 15619.3237 - Avg Loss: 161.0240\n",
            "Epoch [20/50] - Batch loss: 163.1325 - Epoch Loss: 15782.4562 - Avg Loss: 161.0455\n",
            "Epoch [20/50] - Batch loss: 160.1393 - Epoch Loss: 15942.5955 - Avg Loss: 161.0363\n",
            "Epoch [20/50] - Batch loss: 162.0408 - Epoch Loss: 16104.6362 - Avg Loss: 161.0464\n",
            "Epoch [20/50] - Batch loss: 167.8365 - Epoch Loss: 16272.4727 - Avg Loss: 161.1136\n",
            "Epoch [20/50] - Batch loss: 156.8916 - Epoch Loss: 16429.3643 - Avg Loss: 161.0722\n",
            "Epoch [20/50] - Batch loss: 166.8734 - Epoch Loss: 16596.2377 - Avg Loss: 161.1285\n",
            "Epoch [20/50] - Batch loss: 167.3320 - Epoch Loss: 16763.5697 - Avg Loss: 161.1882\n",
            "Epoch [20/50] - Batch loss: 155.4616 - Epoch Loss: 16919.0313 - Avg Loss: 161.1336\n",
            "Epoch [20/50] - Batch loss: 161.4724 - Epoch Loss: 17080.5037 - Avg Loss: 161.1368\n",
            "Epoch [20/50] - Batch loss: 161.1804 - Epoch Loss: 17241.6840 - Avg Loss: 161.1372\n",
            "Epoch [20/50] - Batch loss: 164.2386 - Epoch Loss: 17405.9226 - Avg Loss: 161.1660\n",
            "Epoch [20/50] - Batch loss: 159.2594 - Epoch Loss: 17565.1820 - Avg Loss: 161.1485\n",
            "Epoch [20/50] - Batch loss: 163.5556 - Epoch Loss: 17728.7376 - Avg Loss: 161.1703\n",
            "Epoch [20/50] - Batch loss: 165.7722 - Epoch Loss: 17894.5099 - Avg Loss: 161.2118\n",
            "Epoch [20/50] - Batch loss: 157.5884 - Epoch Loss: 18052.0982 - Avg Loss: 161.1794\n",
            "Epoch [20/50] - Batch loss: 154.4139 - Epoch Loss: 18206.5121 - Avg Loss: 161.1196\n",
            "Epoch [20/50] - Batch loss: 162.3319 - Epoch Loss: 18368.8440 - Avg Loss: 161.1302\n",
            "Epoch [20/50] - Batch loss: 167.8224 - Epoch Loss: 18536.6664 - Avg Loss: 161.1884\n",
            "Epoch [20/50] - Batch loss: 161.7307 - Epoch Loss: 18698.3971 - Avg Loss: 161.1931\n",
            "Epoch [20/50] - Batch loss: 162.8590 - Epoch Loss: 18861.2561 - Avg Loss: 161.2073\n",
            "Epoch [20/50] - Batch loss: 163.1514 - Epoch Loss: 19024.4076 - Avg Loss: 161.2238\n",
            "Epoch [20/50] - Batch loss: 160.4382 - Epoch Loss: 19184.8458 - Avg Loss: 161.2172\n",
            "Epoch [20/50] - Batch loss: 158.8444 - Epoch Loss: 19343.6903 - Avg Loss: 161.1974\n",
            "Epoch [20/50] - Batch loss: 157.8968 - Epoch Loss: 19501.5871 - Avg Loss: 161.1701\n",
            "Epoch [20/50] - Batch loss: 162.7014 - Epoch Loss: 19664.2885 - Avg Loss: 161.1827\n",
            "Epoch [20/50] - Batch loss: 162.8282 - Epoch Loss: 19827.1166 - Avg Loss: 161.1961\n",
            "Epoch [20/50] - Batch loss: 161.5009 - Epoch Loss: 19988.6175 - Avg Loss: 161.1985\n",
            "Epoch [20/50] - Batch loss: 165.0577 - Epoch Loss: 20153.6752 - Avg Loss: 161.2294\n",
            "Epoch [20/50] - Batch loss: 151.1573 - Epoch Loss: 20304.8325 - Avg Loss: 161.1495\n",
            "Epoch [20/50] - Batch loss: 169.1657 - Epoch Loss: 20473.9982 - Avg Loss: 161.2126\n",
            "Epoch [20/50] - Batch loss: 150.0181 - Epoch Loss: 20624.0163 - Avg Loss: 161.1251\n",
            "Epoch [20/50] - Batch loss: 155.0512 - Epoch Loss: 20779.0676 - Avg Loss: 161.0780\n",
            "Epoch [20/50] - Batch loss: 156.0400 - Epoch Loss: 20935.1076 - Avg Loss: 161.0393\n",
            "Epoch [20/50] - Batch loss: 155.1990 - Epoch Loss: 21090.3066 - Avg Loss: 160.9947\n",
            "Epoch [20/50] - Batch loss: 162.9664 - Epoch Loss: 21253.2730 - Avg Loss: 161.0096\n",
            "Epoch [20/50] - Batch loss: 156.7699 - Epoch Loss: 21410.0429 - Avg Loss: 160.9778\n",
            "Epoch [20/50] - Batch loss: 160.3547 - Epoch Loss: 21570.3976 - Avg Loss: 160.9731\n",
            "Epoch [20/50] - Batch loss: 153.0729 - Epoch Loss: 21723.4705 - Avg Loss: 160.9146\n",
            "Epoch [20/50] - Batch loss: 158.2704 - Epoch Loss: 21881.7409 - Avg Loss: 160.8952\n",
            "Epoch [20/50] - Batch loss: 168.4676 - Epoch Loss: 22050.2085 - Avg Loss: 160.9504\n",
            "Epoch [20/50] - Batch loss: 164.2329 - Epoch Loss: 22214.4414 - Avg Loss: 160.9742\n",
            "Epoch [20/50] - Batch loss: 153.8058 - Epoch Loss: 22368.2472 - Avg Loss: 160.9226\n",
            "Epoch [20/50] - Batch loss: 165.1566 - Epoch Loss: 22533.4038 - Avg Loss: 160.9529\n",
            "Epoch [20/50] - Batch loss: 158.9713 - Epoch Loss: 22692.3750 - Avg Loss: 160.9388\n",
            "Epoch [20/50] - Batch loss: 161.2339 - Epoch Loss: 22853.6089 - Avg Loss: 160.9409\n",
            "Epoch [20/50] - Batch loss: 158.0293 - Epoch Loss: 23011.6382 - Avg Loss: 160.9205\n",
            "Epoch [20/50] - Batch loss: 164.6900 - Epoch Loss: 23176.3283 - Avg Loss: 160.9467\n",
            "Epoch [20/50] - Batch loss: 159.1795 - Epoch Loss: 23335.5078 - Avg Loss: 160.9345\n",
            "Epoch [20/50] - Batch loss: 158.9404 - Epoch Loss: 23494.4482 - Avg Loss: 160.9209\n",
            "Epoch [20/50] - Batch loss: 168.2441 - Epoch Loss: 23662.6923 - Avg Loss: 160.9707\n",
            "Epoch [20/50] - Batch loss: 167.6240 - Epoch Loss: 23830.3163 - Avg Loss: 161.0157\n",
            "Epoch [20/50] - Batch loss: 163.4114 - Epoch Loss: 23993.7277 - Avg Loss: 161.0317\n",
            "Epoch [20/50] - Batch loss: 161.7919 - Epoch Loss: 24155.5195 - Avg Loss: 161.0368\n",
            "Epoch [20/50] - Batch loss: 158.5990 - Epoch Loss: 24314.1185 - Avg Loss: 161.0207\n",
            "Epoch [20/50] - Batch loss: 164.1750 - Epoch Loss: 24478.2936 - Avg Loss: 161.0414\n",
            "Epoch [20/50] - Batch loss: 156.1423 - Epoch Loss: 24634.4359 - Avg Loss: 161.0094\n",
            "Epoch [20/50] - Batch loss: 156.8631 - Epoch Loss: 24791.2990 - Avg Loss: 160.9825\n",
            "Epoch [20/50] - Batch loss: 157.3629 - Epoch Loss: 24948.6618 - Avg Loss: 160.9591\n",
            "Epoch [20/50] - Batch loss: 156.6043 - Epoch Loss: 25105.2661 - Avg Loss: 160.9312\n",
            "Epoch [20/50] - Batch loss: 161.3847 - Epoch Loss: 25266.6508 - Avg Loss: 160.9341\n",
            "Epoch [20/50] - Batch loss: 160.1373 - Epoch Loss: 25426.7882 - Avg Loss: 160.9290\n",
            "Epoch [20/50] - Batch loss: 162.9267 - Epoch Loss: 25589.7148 - Avg Loss: 160.9416\n",
            "Epoch [20/50] - Batch loss: 165.1001 - Epoch Loss: 25754.8149 - Avg Loss: 160.9676\n",
            "Epoch [20/50] - Batch loss: 149.8007 - Epoch Loss: 25904.6156 - Avg Loss: 160.8982\n",
            "Epoch [20/50] - Batch loss: 163.0944 - Epoch Loss: 26067.7100 - Avg Loss: 160.9118\n",
            "Epoch [20/50] - Batch loss: 168.8978 - Epoch Loss: 26236.6077 - Avg Loss: 160.9608\n",
            "Epoch [20/50] - Batch loss: 157.5029 - Epoch Loss: 26394.1106 - Avg Loss: 160.9397\n",
            "Epoch [20/50] - Batch loss: 161.2899 - Epoch Loss: 26555.4006 - Avg Loss: 160.9418\n",
            "Epoch [20/50] - Batch loss: 165.4284 - Epoch Loss: 26720.8290 - Avg Loss: 160.9688\n",
            "Epoch [20/50] - Batch loss: 156.3844 - Epoch Loss: 26877.2134 - Avg Loss: 160.9414\n",
            "Epoch [20/50] - Batch loss: 161.9956 - Epoch Loss: 27039.2090 - Avg Loss: 160.9477\n",
            "Epoch [20/50] - Batch loss: 157.3237 - Epoch Loss: 27196.5327 - Avg Loss: 160.9262\n",
            "Epoch [20/50] - Batch loss: 156.8413 - Epoch Loss: 27353.3741 - Avg Loss: 160.9022\n",
            "Epoch [20/50] - Batch loss: 163.6039 - Epoch Loss: 27516.9779 - Avg Loss: 160.9180\n",
            "Epoch [20/50] - Batch loss: 162.3598 - Epoch Loss: 27679.3377 - Avg Loss: 160.9264\n",
            "Epoch [20/50] - Batch loss: 154.0340 - Epoch Loss: 27833.3717 - Avg Loss: 160.8865\n",
            "Epoch [20/50] - Batch loss: 156.5176 - Epoch Loss: 27989.8893 - Avg Loss: 160.8614\n",
            "Epoch [20/50] - Batch loss: 163.8628 - Epoch Loss: 28153.7521 - Avg Loss: 160.8786\n",
            "Epoch [20/50] - Batch loss: 150.8409 - Epoch Loss: 28304.5930 - Avg Loss: 160.8216\n",
            "Epoch [20/50] - Batch loss: 150.1028 - Epoch Loss: 28454.6957 - Avg Loss: 160.7610\n",
            "Epoch [20/50] - Batch loss: 157.6365 - Epoch Loss: 28612.3323 - Avg Loss: 160.7434\n",
            "Epoch [20/50] - Batch loss: 159.2090 - Epoch Loss: 28771.5413 - Avg Loss: 160.7349\n",
            "Epoch [20/50] - Batch loss: 156.5915 - Epoch Loss: 28928.1328 - Avg Loss: 160.7118\n",
            "Epoch [20/50] - Batch loss: 148.5491 - Epoch Loss: 29076.6819 - Avg Loss: 160.6447\n",
            "Epoch [20/50] - Batch loss: 162.0932 - Epoch Loss: 29238.7751 - Avg Loss: 160.6526\n",
            "Epoch [20/50] - Batch loss: 168.7496 - Epoch Loss: 29407.5246 - Avg Loss: 160.6969\n",
            "Epoch [20/50] - Batch loss: 154.7874 - Epoch Loss: 29562.3121 - Avg Loss: 160.6647\n",
            "Epoch [20/50] - Batch loss: 158.3664 - Epoch Loss: 29720.6785 - Avg Loss: 160.6523\n",
            "Epoch [20/50] - Batch loss: 160.6049 - Epoch Loss: 29881.2834 - Avg Loss: 160.6521\n",
            "Epoch [20/50] - Batch loss: 159.6718 - Epoch Loss: 30040.9552 - Avg Loss: 160.6468\n",
            "Epoch [20/50] - Batch loss: 162.8846 - Epoch Loss: 30203.8398 - Avg Loss: 160.6587\n",
            "Epoch [20/50] - Batch loss: 151.8200 - Epoch Loss: 30355.6599 - Avg Loss: 160.6120\n",
            "Epoch [20/50] - Batch loss: 153.9111 - Epoch Loss: 30509.5710 - Avg Loss: 160.5767\n",
            "Epoch [20/50] - Batch loss: 155.2868 - Epoch Loss: 30664.8577 - Avg Loss: 160.5490\n",
            "Epoch [20/50] - Batch loss: 155.3285 - Epoch Loss: 30820.1862 - Avg Loss: 160.5218\n",
            "Epoch [20/50] - Batch loss: 164.7123 - Epoch Loss: 30984.8985 - Avg Loss: 160.5435\n",
            "Epoch [20/50] - Batch loss: 160.5324 - Epoch Loss: 31145.4309 - Avg Loss: 160.5435\n",
            "Epoch [20/50] - Batch loss: 160.7169 - Epoch Loss: 31306.1478 - Avg Loss: 160.5443\n",
            "Epoch [20/50] - Batch loss: 156.1409 - Epoch Loss: 31462.2887 - Avg Loss: 160.5219\n",
            "Epoch [20/50] - Batch loss: 161.0819 - Epoch Loss: 31623.3706 - Avg Loss: 160.5247\n",
            "Epoch [20/50] - Batch loss: 160.0627 - Epoch Loss: 31783.4333 - Avg Loss: 160.5224\n",
            "Epoch [20/50] - Batch loss: 159.6771 - Epoch Loss: 31943.1104 - Avg Loss: 160.5181\n",
            "Epoch [20/50] - Batch loss: 163.0912 - Epoch Loss: 32106.2016 - Avg Loss: 160.5310\n",
            "Epoch [20/50] - Batch loss: 162.3403 - Epoch Loss: 32268.5419 - Avg Loss: 160.5400\n",
            "Epoch [20/50] - Batch loss: 159.2864 - Epoch Loss: 32427.8283 - Avg Loss: 160.5338\n",
            "Epoch [20/50] - Batch loss: 165.1500 - Epoch Loss: 32592.9784 - Avg Loss: 160.5565\n",
            "Epoch [20/50] - Batch loss: 168.1509 - Epoch Loss: 32761.1292 - Avg Loss: 160.5938\n",
            "Epoch [20/50] - Batch loss: 159.9943 - Epoch Loss: 32921.1235 - Avg Loss: 160.5908\n",
            "Epoch [20/50] - Batch loss: 153.5118 - Epoch Loss: 33074.6354 - Avg Loss: 160.5565\n",
            "Epoch [20/50] - Batch loss: 159.3725 - Epoch Loss: 33234.0079 - Avg Loss: 160.5508\n",
            "Epoch [20/50] - Batch loss: 160.3062 - Epoch Loss: 33394.3140 - Avg Loss: 160.5496\n",
            "Epoch [20/50] - Batch loss: 163.6832 - Epoch Loss: 33557.9972 - Avg Loss: 160.5646\n",
            "Epoch [20/50] - Batch loss: 157.7034 - Epoch Loss: 33715.7006 - Avg Loss: 160.5510\n",
            "Epoch [20/50] - Batch loss: 161.1333 - Epoch Loss: 33876.8339 - Avg Loss: 160.5537\n",
            "Epoch [20/50] - Batch loss: 162.6082 - Epoch Loss: 34039.4422 - Avg Loss: 160.5634\n",
            "Epoch [20/50] - Batch loss: 158.7838 - Epoch Loss: 34198.2260 - Avg Loss: 160.5551\n",
            "Epoch [20/50] - Batch loss: 155.8819 - Epoch Loss: 34354.1079 - Avg Loss: 160.5332\n",
            "Epoch [20/50] - Batch loss: 155.2339 - Epoch Loss: 34509.3418 - Avg Loss: 160.5086\n",
            "Epoch [20/50] - Batch loss: 159.3217 - Epoch Loss: 34668.6635 - Avg Loss: 160.5031\n",
            "Epoch [20/50] - Batch loss: 159.3164 - Epoch Loss: 34827.9799 - Avg Loss: 160.4976\n",
            "Epoch [20/50] - Batch loss: 165.1664 - Epoch Loss: 34993.1462 - Avg Loss: 160.5190\n",
            "Epoch [20/50] - Batch loss: 164.2252 - Epoch Loss: 35157.3714 - Avg Loss: 160.5359\n",
            "Epoch [20/50] - Batch loss: 153.4577 - Epoch Loss: 35310.8291 - Avg Loss: 160.5038\n",
            "Epoch [20/50] - Batch loss: 160.1864 - Epoch Loss: 35471.0155 - Avg Loss: 160.5023\n",
            "Epoch [20/50] - Batch loss: 157.8756 - Epoch Loss: 35628.8911 - Avg Loss: 160.4905\n",
            "Epoch [20/50] - Batch loss: 161.1436 - Epoch Loss: 35790.0347 - Avg Loss: 160.4934\n",
            "Epoch [20/50] - Batch loss: 156.8196 - Epoch Loss: 35946.8543 - Avg Loss: 160.4770\n",
            "Epoch [20/50] - Batch loss: 158.8394 - Epoch Loss: 36105.6937 - Avg Loss: 160.4697\n",
            "Epoch [20/50] - Batch loss: 161.4045 - Epoch Loss: 36267.0982 - Avg Loss: 160.4739\n",
            "Epoch [20/50] - Batch loss: 158.0965 - Epoch Loss: 36425.1947 - Avg Loss: 160.4634\n",
            "Epoch [20/50] - Batch loss: 162.0488 - Epoch Loss: 36587.2435 - Avg Loss: 160.4704\n",
            "Epoch [20/50] - Batch loss: 146.6320 - Epoch Loss: 36733.8755 - Avg Loss: 160.4099\n",
            "Epoch [20/50] - Batch loss: 165.2320 - Epoch Loss: 36899.1075 - Avg Loss: 160.4309\n",
            "Epoch [20/50] - Batch loss: 157.5092 - Epoch Loss: 37056.6168 - Avg Loss: 160.4183\n",
            "Epoch [20/50] - Batch loss: 158.1594 - Epoch Loss: 37214.7761 - Avg Loss: 160.4085\n",
            "Epoch [20/50] - Batch loss: 161.4634 - Epoch Loss: 37376.2395 - Avg Loss: 160.4130\n",
            "Epoch [20/50] - Batch loss: 162.0095 - Epoch Loss: 37538.2491 - Avg Loss: 160.4199\n",
            "Epoch [20/50] - Batch loss: 160.6595 - Epoch Loss: 37698.9086 - Avg Loss: 160.4209\n",
            "Epoch [20/50] - Batch loss: 161.1626 - Epoch Loss: 37860.0712 - Avg Loss: 160.4240\n",
            "Epoch [20/50] - Batch loss: 159.0200 - Epoch Loss: 38019.0912 - Avg Loss: 160.4181\n",
            "Epoch [20/50] - Batch loss: 163.6291 - Epoch Loss: 38182.7203 - Avg Loss: 160.4316\n",
            "Epoch [20/50] - Batch loss: 163.2066 - Epoch Loss: 38345.9269 - Avg Loss: 160.4432\n",
            "Epoch [20/50] - Batch loss: 160.0439 - Epoch Loss: 38505.9708 - Avg Loss: 160.4415\n",
            "Epoch [20/50] - Batch loss: 157.0925 - Epoch Loss: 38663.0633 - Avg Loss: 160.4276\n",
            "Epoch [20/50] - Batch loss: 163.1294 - Epoch Loss: 38826.1928 - Avg Loss: 160.4388\n",
            "Epoch [20/50] - Batch loss: 154.9674 - Epoch Loss: 38981.1602 - Avg Loss: 160.4163\n",
            "Epoch [20/50] - Batch loss: 159.4952 - Epoch Loss: 39140.6554 - Avg Loss: 160.4125\n",
            "Epoch [20/50] - Batch loss: 145.2090 - Epoch Loss: 39285.8644 - Avg Loss: 160.3505\n",
            "Epoch [20/50] - Batch loss: 156.6887 - Epoch Loss: 39442.5531 - Avg Loss: 160.3356\n",
            "Epoch [20/50] - Batch loss: 163.7353 - Epoch Loss: 39606.2885 - Avg Loss: 160.3493\n",
            "Epoch [20/50] - Batch loss: 165.1872 - Epoch Loss: 39771.4757 - Avg Loss: 160.3689\n",
            "Epoch [20/50] - Batch loss: 165.1377 - Epoch Loss: 39936.6134 - Avg Loss: 160.3880\n",
            "Epoch [20/50] - Batch loss: 168.6046 - Epoch Loss: 40105.2180 - Avg Loss: 160.4209\n",
            "Epoch [20/50] - Batch loss: 153.3295 - Epoch Loss: 40258.5475 - Avg Loss: 160.3926\n",
            "Epoch [20/50] - Batch loss: 153.0001 - Epoch Loss: 40411.5476 - Avg Loss: 160.3633\n",
            "Epoch [20/50] - Batch loss: 168.0151 - Epoch Loss: 40579.5628 - Avg Loss: 160.3935\n",
            "Epoch [20/50] - Batch loss: 152.2201 - Epoch Loss: 40731.7829 - Avg Loss: 160.3613\n",
            "Epoch [20/50] - Batch loss: 157.1149 - Epoch Loss: 40888.8978 - Avg Loss: 160.3486\n",
            "Epoch [20/50] - Batch loss: 152.4866 - Epoch Loss: 41041.3844 - Avg Loss: 160.3179\n",
            "Epoch [20/50] - Batch loss: 155.1691 - Epoch Loss: 41196.5535 - Avg Loss: 160.2979\n",
            "Epoch [20/50] - Batch loss: 155.3416 - Epoch Loss: 41351.8952 - Avg Loss: 160.2787\n",
            "Epoch [20/50] - Batch loss: 154.1559 - Epoch Loss: 41506.0511 - Avg Loss: 160.2550\n",
            "Epoch [20/50] - Batch loss: 157.1084 - Epoch Loss: 41663.1595 - Avg Loss: 160.2429\n",
            "Epoch [20/50] - Batch loss: 160.3316 - Epoch Loss: 41823.4912 - Avg Loss: 160.2433\n",
            "Epoch [20/50] - Batch loss: 160.3446 - Epoch Loss: 41983.8357 - Avg Loss: 160.2436\n",
            "Epoch [20/50] - Batch loss: 151.3595 - Epoch Loss: 42135.1952 - Avg Loss: 160.2099\n",
            "Epoch [20/50] - Batch loss: 159.8020 - Epoch Loss: 42294.9972 - Avg Loss: 160.2083\n",
            "Epoch [20/50] - Batch loss: 154.9104 - Epoch Loss: 42449.9076 - Avg Loss: 160.1883\n",
            "Epoch [20/50] - Batch loss: 165.6476 - Epoch Loss: 42615.5552 - Avg Loss: 160.2089\n",
            "Epoch [20/50] - Batch loss: 163.7825 - Epoch Loss: 42779.3376 - Avg Loss: 160.2222\n",
            "Epoch [20/50] - Batch loss: 147.8904 - Epoch Loss: 42927.2280 - Avg Loss: 160.1762\n",
            "Epoch [20/50] - Batch loss: 160.9051 - Epoch Loss: 43088.1331 - Avg Loss: 160.1789\n",
            "Epoch [20/50] - Batch loss: 165.0005 - Epoch Loss: 43253.1337 - Avg Loss: 160.1968\n",
            "Epoch [20/50] - Batch loss: 167.2402 - Epoch Loss: 43420.3739 - Avg Loss: 160.2228\n",
            "Epoch [20/50] - Batch loss: 156.8071 - Epoch Loss: 43577.1811 - Avg Loss: 160.2102\n",
            "Epoch [20/50] - Batch loss: 159.1161 - Epoch Loss: 43736.2971 - Avg Loss: 160.2062\n",
            "Epoch [20/50] - Batch loss: 156.0829 - Epoch Loss: 43892.3801 - Avg Loss: 160.1912\n",
            "Epoch [20/50] - Batch loss: 159.2981 - Epoch Loss: 44051.6782 - Avg Loss: 160.1879\n",
            "Epoch [20/50] - Batch loss: 163.2784 - Epoch Loss: 44214.9566 - Avg Loss: 160.1991\n",
            "Epoch [20/50] - Batch loss: 164.9661 - Epoch Loss: 44379.9227 - Avg Loss: 160.2163\n",
            "Epoch [20/50] - Batch loss: 151.5681 - Epoch Loss: 44531.4908 - Avg Loss: 160.1852\n",
            "Epoch [20/50] - Batch loss: 160.5327 - Epoch Loss: 44692.0234 - Avg Loss: 160.1865\n",
            "Epoch [20/50] - Batch loss: 148.4853 - Epoch Loss: 44840.5088 - Avg Loss: 160.1447\n",
            "Epoch [20/50] - Batch loss: 153.4945 - Epoch Loss: 44994.0033 - Avg Loss: 160.1210\n",
            "Epoch [20/50] - Batch loss: 170.5106 - Epoch Loss: 45164.5139 - Avg Loss: 160.1579\n",
            "Epoch [20/50] - Batch loss: 155.5585 - Epoch Loss: 45320.0723 - Avg Loss: 160.1416\n",
            "Epoch [20/50] - Batch loss: 156.8360 - Epoch Loss: 45476.9084 - Avg Loss: 160.1300\n",
            "Epoch [20/50] - Batch loss: 155.2636 - Epoch Loss: 45632.1719 - Avg Loss: 160.1129\n",
            "Epoch [20/50] - Batch loss: 164.4865 - Epoch Loss: 45796.6584 - Avg Loss: 160.1282\n",
            "Epoch [20/50] - Batch loss: 165.1502 - Epoch Loss: 45961.8086 - Avg Loss: 160.1457\n",
            "Epoch [20/50] - Batch loss: 161.9030 - Epoch Loss: 46123.7116 - Avg Loss: 160.1518\n",
            "Epoch [20/50] - Batch loss: 162.3754 - Epoch Loss: 46286.0869 - Avg Loss: 160.1595\n",
            "Epoch [20/50] - Batch loss: 153.7937 - Epoch Loss: 46439.8806 - Avg Loss: 160.1375\n",
            "Epoch [20/50] - Batch loss: 155.3152 - Epoch Loss: 46595.1958 - Avg Loss: 160.1209\n",
            "Epoch [20/50] - Batch loss: 158.5798 - Epoch Loss: 46753.7755 - Avg Loss: 160.1157\n",
            "Epoch [20/50] - Batch loss: 153.4003 - Epoch Loss: 46907.1758 - Avg Loss: 160.0928\n",
            "Epoch [20/50] - Batch loss: 156.1399 - Epoch Loss: 47063.3157 - Avg Loss: 160.0793\n",
            "Epoch [20/50] - Batch loss: 164.9587 - Epoch Loss: 47228.2744 - Avg Loss: 160.0958\n",
            "Epoch [20/50] - Batch loss: 167.6182 - Epoch Loss: 47395.8926 - Avg Loss: 160.1213\n",
            "Epoch [20/50] - Batch loss: 155.1827 - Epoch Loss: 47551.0753 - Avg Loss: 160.1046\n",
            "Epoch [20/50] - Batch loss: 159.3156 - Epoch Loss: 47710.3909 - Avg Loss: 160.1020\n",
            "Epoch [20/50] - Batch loss: 161.1385 - Epoch Loss: 47871.5294 - Avg Loss: 160.1054\n",
            "Epoch [20/50] - Batch loss: 156.8913 - Epoch Loss: 48028.4208 - Avg Loss: 160.0947\n",
            "Epoch [20/50] - Batch loss: 156.5569 - Epoch Loss: 48184.9777 - Avg Loss: 160.0830\n",
            "Epoch [20/50] - Batch loss: 157.2513 - Epoch Loss: 48342.2290 - Avg Loss: 160.0736\n",
            "Epoch [20/50] - Batch loss: 155.5323 - Epoch Loss: 48497.7614 - Avg Loss: 160.0586\n",
            "Epoch [20/50] - Batch loss: 160.6080 - Epoch Loss: 48658.3694 - Avg Loss: 160.0604\n",
            "Epoch [20/50] - Batch loss: 154.8029 - Epoch Loss: 48813.1723 - Avg Loss: 160.0432\n",
            "Epoch [20/50] - Batch loss: 156.6895 - Epoch Loss: 48969.8618 - Avg Loss: 160.0322\n",
            "Epoch [20/50] - Batch loss: 161.9229 - Epoch Loss: 49131.7847 - Avg Loss: 160.0384\n",
            "Epoch [20/50] - Batch loss: 165.8850 - Epoch Loss: 49297.6697 - Avg Loss: 160.0574\n",
            "Epoch [20/50] - Batch loss: 154.6470 - Epoch Loss: 49452.3167 - Avg Loss: 160.0399\n",
            "Epoch [20/50] - Batch loss: 161.8760 - Epoch Loss: 49614.1927 - Avg Loss: 160.0458\n",
            "Epoch [20/50] - Batch loss: 163.9743 - Epoch Loss: 49778.1670 - Avg Loss: 160.0584\n",
            "Epoch [20/50] - Batch loss: 162.5773 - Epoch Loss: 49940.7443 - Avg Loss: 160.0665\n",
            "Epoch [20/50] - Batch loss: 163.3851 - Epoch Loss: 50104.1294 - Avg Loss: 160.0771\n",
            "Epoch [20/50] - Batch loss: 158.7504 - Epoch Loss: 50262.8799 - Avg Loss: 160.0729\n",
            "Epoch [20/50] - Batch loss: 161.4868 - Epoch Loss: 50424.3667 - Avg Loss: 160.0774\n",
            "Epoch [20/50] - Batch loss: 157.3246 - Epoch Loss: 50581.6913 - Avg Loss: 160.0686\n",
            "Epoch [20/50] - Batch loss: 161.0521 - Epoch Loss: 50742.7434 - Avg Loss: 160.0717\n",
            "Epoch [20/50] - Batch loss: 157.5698 - Epoch Loss: 50900.3132 - Avg Loss: 160.0639\n",
            "Epoch [20/50] - Batch loss: 157.3711 - Epoch Loss: 51057.6843 - Avg Loss: 160.0554\n",
            "Epoch [20/50] - Batch loss: 150.8003 - Epoch Loss: 51208.4847 - Avg Loss: 160.0265\n",
            "Epoch [20/50] - Batch loss: 156.8082 - Epoch Loss: 51365.2928 - Avg Loss: 160.0165\n",
            "Epoch [20/50] - Batch loss: 166.2882 - Epoch Loss: 51531.5811 - Avg Loss: 160.0360\n",
            "Epoch [20/50] - Batch loss: 160.1943 - Epoch Loss: 51691.7754 - Avg Loss: 160.0365\n",
            "Epoch [20/50] - Batch loss: 151.1340 - Epoch Loss: 51842.9094 - Avg Loss: 160.0090\n",
            "Epoch [20/50] - Batch loss: 159.9672 - Epoch Loss: 52002.8766 - Avg Loss: 160.0089\n",
            "Epoch [20/50] - Batch loss: 155.6222 - Epoch Loss: 52158.4988 - Avg Loss: 159.9954\n",
            "Epoch [20/50] - Batch loss: 160.8068 - Epoch Loss: 52319.3056 - Avg Loss: 159.9979\n",
            "Epoch [20/50] - Batch loss: 162.5225 - Epoch Loss: 52481.8281 - Avg Loss: 160.0056\n",
            "Epoch [20/50] - Batch loss: 158.8293 - Epoch Loss: 52640.6573 - Avg Loss: 160.0020\n",
            "Epoch [20/50] - Batch loss: 146.7724 - Epoch Loss: 52787.4298 - Avg Loss: 159.9619\n",
            "Epoch [20/50] - Batch loss: 164.8067 - Epoch Loss: 52952.2365 - Avg Loss: 159.9765\n",
            "Epoch [20/50] - Batch loss: 151.8881 - Epoch Loss: 53104.1246 - Avg Loss: 159.9522\n",
            "Epoch [20/50] - Batch loss: 157.7514 - Epoch Loss: 53261.8760 - Avg Loss: 159.9456\n",
            "Epoch [20/50] - Batch loss: 150.2226 - Epoch Loss: 53412.0986 - Avg Loss: 159.9165\n",
            "Epoch [20/50] - Batch loss: 162.4397 - Epoch Loss: 53574.5383 - Avg Loss: 159.9240\n",
            "Epoch [20/50] - Batch loss: 159.6405 - Epoch Loss: 53734.1788 - Avg Loss: 159.9232\n",
            "Epoch [20/50] - Batch loss: 160.5610 - Epoch Loss: 53894.7398 - Avg Loss: 159.9250\n",
            "Epoch [20/50] - Batch loss: 159.6943 - Epoch Loss: 54054.4342 - Avg Loss: 159.9244\n",
            "Epoch [20/50] - Batch loss: 157.5221 - Epoch Loss: 54211.9563 - Avg Loss: 159.9173\n",
            "Epoch [20/50] - Batch loss: 166.2108 - Epoch Loss: 54378.1670 - Avg Loss: 159.9358\n",
            "Epoch [20/50] - Batch loss: 155.0727 - Epoch Loss: 54533.2397 - Avg Loss: 159.9215\n",
            "Epoch [20/50] - Batch loss: 161.0884 - Epoch Loss: 54694.3282 - Avg Loss: 159.9249\n",
            "Epoch [20/50] - Batch loss: 154.7354 - Epoch Loss: 54849.0635 - Avg Loss: 159.9098\n",
            "Epoch [20/50] - Batch loss: 161.4244 - Epoch Loss: 55010.4880 - Avg Loss: 159.9142\n",
            "Epoch [20/50] - Batch loss: 164.7506 - Epoch Loss: 55175.2386 - Avg Loss: 159.9282\n",
            "Epoch [20/50] - Batch loss: 161.1788 - Epoch Loss: 55336.4174 - Avg Loss: 159.9318\n",
            "Epoch [20/50] - Batch loss: 150.0914 - Epoch Loss: 55486.5088 - Avg Loss: 159.9035\n",
            "Epoch [20/50] - Batch loss: 154.8257 - Epoch Loss: 55641.3345 - Avg Loss: 159.8889\n",
            "Epoch [20/50] - Batch loss: 159.3908 - Epoch Loss: 55800.7253 - Avg Loss: 159.8875\n",
            "Epoch [20/50] - Batch loss: 159.2846 - Epoch Loss: 55960.0099 - Avg Loss: 159.8857\n",
            "Epoch [20/50] - Batch loss: 157.3444 - Epoch Loss: 56117.3543 - Avg Loss: 159.8785\n",
            "Epoch [20/50] - Batch loss: 159.5119 - Epoch Loss: 56276.8662 - Avg Loss: 159.8775\n",
            "Epoch [20/50] - Batch loss: 159.9248 - Epoch Loss: 56436.7910 - Avg Loss: 159.8776\n",
            "Epoch [20/50] - Batch loss: 159.8715 - Epoch Loss: 56596.6625 - Avg Loss: 159.8776\n",
            "Epoch [20/50] - Batch loss: 153.3535 - Epoch Loss: 56750.0161 - Avg Loss: 159.8592\n",
            "Epoch [20/50] - Batch loss: 160.8836 - Epoch Loss: 56910.8997 - Avg Loss: 159.8621\n",
            "Epoch [20/50] - Batch loss: 165.3864 - Epoch Loss: 57076.2861 - Avg Loss: 159.8776\n",
            "Epoch [20/50] - Batch loss: 161.6560 - Epoch Loss: 57237.9421 - Avg Loss: 159.8825\n",
            "Epoch [20/50] - Batch loss: 164.2306 - Epoch Loss: 57402.1727 - Avg Loss: 159.8946\n",
            "Epoch [20/50] - Batch loss: 156.1613 - Epoch Loss: 57558.3340 - Avg Loss: 159.8843\n",
            "Epoch [20/50] - Batch loss: 163.8544 - Epoch Loss: 57722.1884 - Avg Loss: 159.8953\n",
            "Epoch [20/50] - Batch loss: 157.7896 - Epoch Loss: 57879.9780 - Avg Loss: 159.8894\n",
            "Epoch [20/50] - Batch loss: 160.9179 - Epoch Loss: 58040.8959 - Avg Loss: 159.8923\n",
            "Epoch [20/50] - Batch loss: 151.8167 - Epoch Loss: 58192.7126 - Avg Loss: 159.8701\n",
            "Epoch [20/50] - Batch loss: 163.0249 - Epoch Loss: 58355.7375 - Avg Loss: 159.8787\n",
            "Epoch [20/50] - Batch loss: 159.1357 - Epoch Loss: 58514.8732 - Avg Loss: 159.8767\n",
            "Epoch [20/50] - Batch loss: 164.7030 - Epoch Loss: 58679.5762 - Avg Loss: 159.8899\n",
            "Epoch [20/50] - Batch loss: 147.4537 - Epoch Loss: 58827.0299 - Avg Loss: 159.8561\n",
            "Epoch [20/50] - Batch loss: 158.1665 - Epoch Loss: 58985.1964 - Avg Loss: 159.8515\n",
            "Epoch [20/50] - Batch loss: 158.6278 - Epoch Loss: 59143.8242 - Avg Loss: 159.8482\n",
            "Epoch [20/50] - Batch loss: 152.8082 - Epoch Loss: 59296.6324 - Avg Loss: 159.8292\n",
            "Epoch [20/50] - Batch loss: 159.6273 - Epoch Loss: 59456.2597 - Avg Loss: 159.8287\n",
            "Epoch [20/50] - Batch loss: 165.5254 - Epoch Loss: 59621.7851 - Avg Loss: 159.8439\n",
            "Epoch [20/50] - Batch loss: 164.5808 - Epoch Loss: 59786.3659 - Avg Loss: 159.8566\n",
            "Epoch [20/50] - Batch loss: 153.9747 - Epoch Loss: 59940.3406 - Avg Loss: 159.8409\n",
            "Epoch [20/50] - Batch loss: 159.2701 - Epoch Loss: 60099.6107 - Avg Loss: 159.8394\n",
            "Epoch [20/50] - Batch loss: 164.4037 - Epoch Loss: 60264.0144 - Avg Loss: 159.8515\n",
            "Epoch [20/50] - Batch loss: 153.3233 - Epoch Loss: 60417.3377 - Avg Loss: 159.8342\n",
            "Epoch [20/50] - Batch loss: 160.4643 - Epoch Loss: 60577.8020 - Avg Loss: 159.8359\n",
            "Epoch [20/50] - Batch loss: 155.3514 - Epoch Loss: 60733.1534 - Avg Loss: 159.8241\n",
            "Epoch [20/50] - Batch loss: 159.6398 - Epoch Loss: 60892.7931 - Avg Loss: 159.8236\n",
            "Epoch [20/50] - Batch loss: 159.0290 - Epoch Loss: 61051.8222 - Avg Loss: 159.8215\n",
            "Epoch [20/50] - Batch loss: 165.9507 - Epoch Loss: 61217.7729 - Avg Loss: 159.8375\n",
            "Epoch [20/50] - Batch loss: 159.0971 - Epoch Loss: 61376.8700 - Avg Loss: 159.8356\n",
            "Epoch [20/50] - Batch loss: 149.3758 - Epoch Loss: 61526.2458 - Avg Loss: 159.8084\n",
            "Epoch [20/50] - Batch loss: 152.3232 - Epoch Loss: 61678.5690 - Avg Loss: 159.7890\n",
            "Epoch [20/50] - Batch loss: 157.3742 - Epoch Loss: 61835.9431 - Avg Loss: 159.7828\n",
            "Epoch [20/50] - Batch loss: 155.8381 - Epoch Loss: 61991.7813 - Avg Loss: 159.7726\n",
            "Epoch [20/50] - Batch loss: 153.3488 - Epoch Loss: 62145.1301 - Avg Loss: 159.7561\n",
            "Epoch [20/50] - Batch loss: 156.9767 - Epoch Loss: 62302.1068 - Avg Loss: 159.7490\n",
            "Epoch [20/50] - Batch loss: 153.9610 - Epoch Loss: 62456.0678 - Avg Loss: 159.7342\n",
            "Epoch [20/50] - Batch loss: 161.3872 - Epoch Loss: 62617.4550 - Avg Loss: 159.7384\n",
            "Epoch [20/50] - Batch loss: 163.1365 - Epoch Loss: 62780.5915 - Avg Loss: 159.7471\n",
            "Epoch [20/50] - Batch loss: 155.7843 - Epoch Loss: 62936.3758 - Avg Loss: 159.7370\n",
            "Epoch [20/50] - Batch loss: 164.3690 - Epoch Loss: 63100.7448 - Avg Loss: 159.7487\n",
            "Epoch [20/50] - Batch loss: 159.8943 - Epoch Loss: 63260.6391 - Avg Loss: 159.7491\n",
            "Epoch [20/50] - Batch loss: 157.6881 - Epoch Loss: 63418.3272 - Avg Loss: 159.7439\n",
            "Epoch [20/50] - Batch loss: 162.9500 - Epoch Loss: 63581.2773 - Avg Loss: 159.7520\n",
            "Epoch [20/50] - Batch loss: 153.1251 - Epoch Loss: 63734.4023 - Avg Loss: 159.7353\n",
            "Epoch [20/50] - Batch loss: 170.1908 - Epoch Loss: 63904.5932 - Avg Loss: 159.7615\n",
            "Epoch [20/50] - Batch loss: 158.2962 - Epoch Loss: 64062.8894 - Avg Loss: 159.7578\n",
            "Epoch [20/50] - Batch loss: 152.6274 - Epoch Loss: 64215.5168 - Avg Loss: 159.7401\n",
            "Epoch [20/50] - Batch loss: 154.7957 - Epoch Loss: 64370.3125 - Avg Loss: 159.7278\n",
            "Epoch [20/50] - Batch loss: 153.6967 - Epoch Loss: 64524.0092 - Avg Loss: 159.7129\n",
            "Epoch [20/50] - Batch loss: 160.6933 - Epoch Loss: 64684.7026 - Avg Loss: 159.7153\n",
            "Epoch [20/50] - Batch loss: 154.5336 - Epoch Loss: 64839.2362 - Avg Loss: 159.7026\n",
            "Epoch [20/50] - Batch loss: 155.8277 - Epoch Loss: 64995.0639 - Avg Loss: 159.6930\n",
            "Epoch [20/50] - Batch loss: 157.5798 - Epoch Loss: 65152.6437 - Avg Loss: 159.6879\n",
            "Epoch [20/50] - Batch loss: 158.1784 - Epoch Loss: 65310.8221 - Avg Loss: 159.6842\n",
            "Epoch [20/50] - Batch loss: 157.2084 - Epoch Loss: 65468.0305 - Avg Loss: 159.6781\n",
            "Epoch [20/50] - Batch loss: 161.5247 - Epoch Loss: 65629.5553 - Avg Loss: 159.6826\n",
            "Epoch [20/50] - Batch loss: 147.9869 - Epoch Loss: 65777.5421 - Avg Loss: 159.6542\n",
            "Epoch [20/50] - Batch loss: 152.8246 - Epoch Loss: 65930.3667 - Avg Loss: 159.6377\n",
            "Epoch [20/50] - Batch loss: 162.2997 - Epoch Loss: 66092.6664 - Avg Loss: 159.6441\n",
            "Epoch [20/50] - Batch loss: 162.2430 - Epoch Loss: 66254.9094 - Avg Loss: 159.6504\n",
            "Epoch [20/50] - Batch loss: 147.9793 - Epoch Loss: 66402.8887 - Avg Loss: 159.6223\n",
            "Epoch [20/50] - Batch loss: 161.3297 - Epoch Loss: 66564.2184 - Avg Loss: 159.6264\n",
            "Epoch [20/50] - Batch loss: 166.9547 - Epoch Loss: 66731.1731 - Avg Loss: 159.6440\n",
            "Epoch [20/50] - Batch loss: 153.4603 - Epoch Loss: 66884.6334 - Avg Loss: 159.6292\n",
            "Epoch [20/50] - Batch loss: 161.4243 - Epoch Loss: 67046.0577 - Avg Loss: 159.6335\n",
            "Epoch [20/50] - Batch loss: 160.1966 - Epoch Loss: 67206.2543 - Avg Loss: 159.6348\n",
            "Epoch [20/50] - Batch loss: 158.3727 - Epoch Loss: 67364.6270 - Avg Loss: 159.6318\n",
            "Epoch [20/50] - Batch loss: 158.4777 - Epoch Loss: 67523.1047 - Avg Loss: 159.6291\n",
            "Epoch [20/50] - Batch loss: 160.9080 - Epoch Loss: 67684.0127 - Avg Loss: 159.6321\n",
            "Epoch [20/50] - Batch loss: 169.2821 - Epoch Loss: 67853.2949 - Avg Loss: 159.6548\n",
            "Epoch [20/50] - Batch loss: 156.3238 - Epoch Loss: 68009.6187 - Avg Loss: 159.6470\n",
            "Epoch [20/50] - Batch loss: 161.9208 - Epoch Loss: 68171.5394 - Avg Loss: 159.6523\n",
            "Epoch [20/50] - Batch loss: 153.8944 - Epoch Loss: 68325.4339 - Avg Loss: 159.6389\n",
            "Epoch [20/50] - Batch loss: 166.5896 - Epoch Loss: 68492.0235 - Avg Loss: 159.6551\n",
            "Epoch [20/50] - Batch loss: 161.8772 - Epoch Loss: 68653.9006 - Avg Loss: 159.6602\n",
            "Epoch [20/50] - Batch loss: 166.7479 - Epoch Loss: 68820.6486 - Avg Loss: 159.6767\n",
            "Epoch [20/50] - Batch loss: 161.4421 - Epoch Loss: 68982.0906 - Avg Loss: 159.6808\n",
            "Epoch [20/50] - Batch loss: 163.6565 - Epoch Loss: 69145.7471 - Avg Loss: 159.6899\n",
            "Epoch [20/50] - Batch loss: 158.8837 - Epoch Loss: 69304.6308 - Avg Loss: 159.6881\n",
            "Epoch [20/50] - Batch loss: 167.5937 - Epoch Loss: 69472.2245 - Avg Loss: 159.7063\n",
            "Epoch [20/50] - Batch loss: 158.3621 - Epoch Loss: 69630.5866 - Avg Loss: 159.7032\n",
            "Epoch [20/50] - Batch loss: 158.8575 - Epoch Loss: 69789.4440 - Avg Loss: 159.7012\n",
            "Epoch [20/50] - Batch loss: 156.4991 - Epoch Loss: 69945.9431 - Avg Loss: 159.6939\n",
            "Epoch [20/50] - Batch loss: 165.0514 - Epoch Loss: 70110.9946 - Avg Loss: 159.7061\n",
            "Epoch [20/50] - Batch loss: 152.4236 - Epoch Loss: 70263.4181 - Avg Loss: 159.6896\n",
            "Epoch [20/50] - Batch loss: 153.9654 - Epoch Loss: 70417.3835 - Avg Loss: 159.6766\n",
            "Epoch [20/50] - Batch loss: 160.4713 - Epoch Loss: 70577.8548 - Avg Loss: 159.6784\n",
            "Epoch [20/50] - Batch loss: 162.5535 - Epoch Loss: 70740.4083 - Avg Loss: 159.6849\n",
            "Epoch [20/50] - Batch loss: 151.3073 - Epoch Loss: 70891.7156 - Avg Loss: 159.6660\n",
            "Epoch [20/50] - Batch loss: 153.6421 - Epoch Loss: 71045.3577 - Avg Loss: 159.6525\n",
            "Epoch [20/50] - Batch loss: 166.8968 - Epoch Loss: 71212.2545 - Avg Loss: 159.6687\n",
            "Epoch [20/50] - Batch loss: 161.1105 - Epoch Loss: 71373.3650 - Avg Loss: 159.6720\n",
            "Epoch [20/50] - Batch loss: 156.9615 - Epoch Loss: 71530.3265 - Avg Loss: 159.6659\n",
            "Epoch [20/50] - Batch loss: 158.4033 - Epoch Loss: 71688.7298 - Avg Loss: 159.6631\n",
            "Epoch [20/50] - Batch loss: 153.9295 - Epoch Loss: 71842.6593 - Avg Loss: 159.6504\n",
            "Epoch [20/50] - Batch loss: 159.2721 - Epoch Loss: 72001.9314 - Avg Loss: 159.6495\n",
            "Epoch [20/50] - Batch loss: 155.9741 - Epoch Loss: 72157.9055 - Avg Loss: 159.6414\n",
            "Epoch [20/50] - Batch loss: 162.7988 - Epoch Loss: 72320.7043 - Avg Loss: 159.6484\n",
            "Epoch [20/50] - Batch loss: 167.4730 - Epoch Loss: 72488.1773 - Avg Loss: 159.6656\n",
            "Epoch [20/50] - Batch loss: 162.0369 - Epoch Loss: 72650.2142 - Avg Loss: 159.6708\n",
            "Epoch [20/50] - Batch loss: 163.8349 - Epoch Loss: 72814.0491 - Avg Loss: 159.6799\n",
            "Epoch [20/50] - Batch loss: 158.9782 - Epoch Loss: 72973.0273 - Avg Loss: 159.6784\n",
            "Epoch [20/50] - Batch loss: 161.0295 - Epoch Loss: 73134.0568 - Avg Loss: 159.6813\n",
            "Epoch [20/50] - Batch loss: 159.6438 - Epoch Loss: 73293.7007 - Avg Loss: 159.6813\n",
            "Epoch [20/50] - Batch loss: 158.8775 - Epoch Loss: 73452.5782 - Avg Loss: 159.6795\n",
            "Epoch [20/50] - Batch loss: 161.6061 - Epoch Loss: 73614.1842 - Avg Loss: 159.6837\n",
            "Epoch [20/50] - Batch loss: 153.8050 - Epoch Loss: 73767.9893 - Avg Loss: 159.6710\n",
            "Epoch [20/50] - Batch loss: 158.1809 - Epoch Loss: 73926.1702 - Avg Loss: 159.6678\n",
            "Epoch [20/50] - Batch loss: 163.8183 - Epoch Loss: 74089.9884 - Avg Loss: 159.6767\n",
            "Epoch [20/50] - Batch loss: 158.4479 - Epoch Loss: 74248.4363 - Avg Loss: 159.6741\n",
            "Epoch [20/50] - Batch loss: 170.4609 - Epoch Loss: 74418.8972 - Avg Loss: 159.6972\n",
            "Epoch [20/50] - Batch loss: 166.2852 - Epoch Loss: 74585.1823 - Avg Loss: 159.7113\n",
            "Epoch [20/50] - Batch loss: 153.9032 - Epoch Loss: 74739.0855 - Avg Loss: 159.6989\n",
            "Epoch [20/50] - Batch loss: 162.4136 - Epoch Loss: 74901.4991 - Avg Loss: 159.7047\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 21/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3fe5addf0df458e979f2da7b30544df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/50] - Batch loss: 159.6362 - Epoch Loss: 159.6362 - Avg Loss: 159.6362\n",
            "Epoch [21/50] - Batch loss: 166.8687 - Epoch Loss: 326.5048 - Avg Loss: 163.2524\n",
            "Epoch [21/50] - Batch loss: 157.0697 - Epoch Loss: 483.5745 - Avg Loss: 161.1915\n",
            "Epoch [21/50] - Batch loss: 155.0239 - Epoch Loss: 638.5984 - Avg Loss: 159.6496\n",
            "Epoch [21/50] - Batch loss: 161.4959 - Epoch Loss: 800.0943 - Avg Loss: 160.0189\n",
            "Epoch [21/50] - Batch loss: 160.2307 - Epoch Loss: 960.3250 - Avg Loss: 160.0542\n",
            "Epoch [21/50] - Batch loss: 161.0199 - Epoch Loss: 1121.3448 - Avg Loss: 160.1921\n",
            "Epoch [21/50] - Batch loss: 159.1162 - Epoch Loss: 1280.4610 - Avg Loss: 160.0576\n",
            "Epoch [21/50] - Batch loss: 161.3283 - Epoch Loss: 1441.7893 - Avg Loss: 160.1988\n",
            "Epoch [21/50] - Batch loss: 160.0355 - Epoch Loss: 1601.8248 - Avg Loss: 160.1825\n",
            "Epoch [21/50] - Batch loss: 163.6079 - Epoch Loss: 1765.4327 - Avg Loss: 160.4939\n",
            "Epoch [21/50] - Batch loss: 164.9685 - Epoch Loss: 1930.4012 - Avg Loss: 160.8668\n",
            "Epoch [21/50] - Batch loss: 168.9767 - Epoch Loss: 2099.3779 - Avg Loss: 161.4906\n",
            "Epoch [21/50] - Batch loss: 160.4147 - Epoch Loss: 2259.7927 - Avg Loss: 161.4138\n",
            "Epoch [21/50] - Batch loss: 152.9745 - Epoch Loss: 2412.7672 - Avg Loss: 160.8511\n",
            "Epoch [21/50] - Batch loss: 162.8862 - Epoch Loss: 2575.6534 - Avg Loss: 160.9783\n",
            "Epoch [21/50] - Batch loss: 155.8246 - Epoch Loss: 2731.4781 - Avg Loss: 160.6752\n",
            "Epoch [21/50] - Batch loss: 162.0385 - Epoch Loss: 2893.5166 - Avg Loss: 160.7509\n",
            "Epoch [21/50] - Batch loss: 158.8930 - Epoch Loss: 3052.4096 - Avg Loss: 160.6531\n",
            "Epoch [21/50] - Batch loss: 159.2893 - Epoch Loss: 3211.6989 - Avg Loss: 160.5849\n",
            "Epoch [21/50] - Batch loss: 166.1459 - Epoch Loss: 3377.8448 - Avg Loss: 160.8498\n",
            "Epoch [21/50] - Batch loss: 163.8973 - Epoch Loss: 3541.7421 - Avg Loss: 160.9883\n",
            "Epoch [21/50] - Batch loss: 160.2692 - Epoch Loss: 3702.0114 - Avg Loss: 160.9570\n",
            "Epoch [21/50] - Batch loss: 172.3756 - Epoch Loss: 3874.3869 - Avg Loss: 161.4328\n",
            "Epoch [21/50] - Batch loss: 171.2754 - Epoch Loss: 4045.6623 - Avg Loss: 161.8265\n",
            "Epoch [21/50] - Batch loss: 165.5757 - Epoch Loss: 4211.2381 - Avg Loss: 161.9707\n",
            "Epoch [21/50] - Batch loss: 157.5660 - Epoch Loss: 4368.8041 - Avg Loss: 161.8076\n",
            "Epoch [21/50] - Batch loss: 160.9711 - Epoch Loss: 4529.7752 - Avg Loss: 161.7777\n",
            "Epoch [21/50] - Batch loss: 154.3889 - Epoch Loss: 4684.1641 - Avg Loss: 161.5229\n",
            "Epoch [21/50] - Batch loss: 161.3845 - Epoch Loss: 4845.5486 - Avg Loss: 161.5183\n",
            "Epoch [21/50] - Batch loss: 162.8358 - Epoch Loss: 5008.3843 - Avg Loss: 161.5608\n",
            "Epoch [21/50] - Batch loss: 159.0757 - Epoch Loss: 5167.4600 - Avg Loss: 161.4831\n",
            "Epoch [21/50] - Batch loss: 158.7698 - Epoch Loss: 5326.2298 - Avg Loss: 161.4009\n",
            "Epoch [21/50] - Batch loss: 151.8969 - Epoch Loss: 5478.1267 - Avg Loss: 161.1214\n",
            "Epoch [21/50] - Batch loss: 167.2968 - Epoch Loss: 5645.4235 - Avg Loss: 161.2978\n",
            "Epoch [21/50] - Batch loss: 158.3867 - Epoch Loss: 5803.8102 - Avg Loss: 161.2169\n",
            "Epoch [21/50] - Batch loss: 155.7480 - Epoch Loss: 5959.5582 - Avg Loss: 161.0691\n",
            "Epoch [21/50] - Batch loss: 152.1796 - Epoch Loss: 6111.7378 - Avg Loss: 160.8352\n",
            "Epoch [21/50] - Batch loss: 158.1847 - Epoch Loss: 6269.9225 - Avg Loss: 160.7672\n",
            "Epoch [21/50] - Batch loss: 164.5425 - Epoch Loss: 6434.4650 - Avg Loss: 160.8616\n",
            "Epoch [21/50] - Batch loss: 160.0812 - Epoch Loss: 6594.5462 - Avg Loss: 160.8426\n",
            "Epoch [21/50] - Batch loss: 154.5378 - Epoch Loss: 6749.0840 - Avg Loss: 160.6925\n",
            "Epoch [21/50] - Batch loss: 161.8293 - Epoch Loss: 6910.9133 - Avg Loss: 160.7189\n",
            "Epoch [21/50] - Batch loss: 159.6655 - Epoch Loss: 7070.5788 - Avg Loss: 160.6950\n",
            "Epoch [21/50] - Batch loss: 153.4140 - Epoch Loss: 7223.9928 - Avg Loss: 160.5332\n",
            "Epoch [21/50] - Batch loss: 161.2407 - Epoch Loss: 7385.2334 - Avg Loss: 160.5486\n",
            "Epoch [21/50] - Batch loss: 160.9827 - Epoch Loss: 7546.2162 - Avg Loss: 160.5578\n",
            "Epoch [21/50] - Batch loss: 161.2575 - Epoch Loss: 7707.4737 - Avg Loss: 160.5724\n",
            "Epoch [21/50] - Batch loss: 149.1142 - Epoch Loss: 7856.5878 - Avg Loss: 160.3385\n",
            "Epoch [21/50] - Batch loss: 155.1097 - Epoch Loss: 8011.6976 - Avg Loss: 160.2340\n",
            "Epoch [21/50] - Batch loss: 151.4868 - Epoch Loss: 8163.1844 - Avg Loss: 160.0624\n",
            "Epoch [21/50] - Batch loss: 165.2312 - Epoch Loss: 8328.4156 - Avg Loss: 160.1618\n",
            "Epoch [21/50] - Batch loss: 165.7775 - Epoch Loss: 8494.1931 - Avg Loss: 160.2678\n",
            "Epoch [21/50] - Batch loss: 164.4366 - Epoch Loss: 8658.6297 - Avg Loss: 160.3450\n",
            "Epoch [21/50] - Batch loss: 164.8095 - Epoch Loss: 8823.4393 - Avg Loss: 160.4262\n",
            "Epoch [21/50] - Batch loss: 161.4726 - Epoch Loss: 8984.9119 - Avg Loss: 160.4449\n",
            "Epoch [21/50] - Batch loss: 153.6545 - Epoch Loss: 9138.5664 - Avg Loss: 160.3257\n",
            "Epoch [21/50] - Batch loss: 158.8382 - Epoch Loss: 9297.4046 - Avg Loss: 160.3001\n",
            "Epoch [21/50] - Batch loss: 162.3927 - Epoch Loss: 9459.7973 - Avg Loss: 160.3355\n",
            "Epoch [21/50] - Batch loss: 161.2055 - Epoch Loss: 9621.0027 - Avg Loss: 160.3500\n",
            "Epoch [21/50] - Batch loss: 154.2612 - Epoch Loss: 9775.2639 - Avg Loss: 160.2502\n",
            "Epoch [21/50] - Batch loss: 161.0781 - Epoch Loss: 9936.3420 - Avg Loss: 160.2636\n",
            "Epoch [21/50] - Batch loss: 163.2114 - Epoch Loss: 10099.5534 - Avg Loss: 160.3104\n",
            "Epoch [21/50] - Batch loss: 157.3437 - Epoch Loss: 10256.8970 - Avg Loss: 160.2640\n",
            "Epoch [21/50] - Batch loss: 159.0166 - Epoch Loss: 10415.9136 - Avg Loss: 160.2448\n",
            "Epoch [21/50] - Batch loss: 156.3779 - Epoch Loss: 10572.2915 - Avg Loss: 160.1862\n",
            "Epoch [21/50] - Batch loss: 165.2161 - Epoch Loss: 10737.5076 - Avg Loss: 160.2613\n",
            "Epoch [21/50] - Batch loss: 159.6212 - Epoch Loss: 10897.1288 - Avg Loss: 160.2519\n",
            "Epoch [21/50] - Batch loss: 163.2556 - Epoch Loss: 11060.3844 - Avg Loss: 160.2954\n",
            "Epoch [21/50] - Batch loss: 163.8810 - Epoch Loss: 11224.2654 - Avg Loss: 160.3466\n",
            "Epoch [21/50] - Batch loss: 155.0444 - Epoch Loss: 11379.3098 - Avg Loss: 160.2720\n",
            "Epoch [21/50] - Batch loss: 156.1253 - Epoch Loss: 11535.4351 - Avg Loss: 160.2144\n",
            "Epoch [21/50] - Batch loss: 159.4410 - Epoch Loss: 11694.8760 - Avg Loss: 160.2038\n",
            "Epoch [21/50] - Batch loss: 151.9527 - Epoch Loss: 11846.8287 - Avg Loss: 160.0923\n",
            "Epoch [21/50] - Batch loss: 158.6490 - Epoch Loss: 12005.4777 - Avg Loss: 160.0730\n",
            "Epoch [21/50] - Batch loss: 156.3306 - Epoch Loss: 12161.8084 - Avg Loss: 160.0238\n",
            "Epoch [21/50] - Batch loss: 160.5787 - Epoch Loss: 12322.3871 - Avg Loss: 160.0310\n",
            "Epoch [21/50] - Batch loss: 162.0001 - Epoch Loss: 12484.3872 - Avg Loss: 160.0562\n",
            "Epoch [21/50] - Batch loss: 164.4777 - Epoch Loss: 12648.8649 - Avg Loss: 160.1122\n",
            "Epoch [21/50] - Batch loss: 161.1278 - Epoch Loss: 12809.9927 - Avg Loss: 160.1249\n",
            "Epoch [21/50] - Batch loss: 157.8969 - Epoch Loss: 12967.8896 - Avg Loss: 160.0974\n",
            "Epoch [21/50] - Batch loss: 163.1472 - Epoch Loss: 13131.0369 - Avg Loss: 160.1346\n",
            "Epoch [21/50] - Batch loss: 161.0087 - Epoch Loss: 13292.0456 - Avg Loss: 160.1451\n",
            "Epoch [21/50] - Batch loss: 160.4140 - Epoch Loss: 13452.4596 - Avg Loss: 160.1483\n",
            "Epoch [21/50] - Batch loss: 156.4951 - Epoch Loss: 13608.9547 - Avg Loss: 160.1053\n",
            "Epoch [21/50] - Batch loss: 150.9521 - Epoch Loss: 13759.9068 - Avg Loss: 159.9989\n",
            "Epoch [21/50] - Batch loss: 149.7339 - Epoch Loss: 13909.6406 - Avg Loss: 159.8809\n",
            "Epoch [21/50] - Batch loss: 165.9581 - Epoch Loss: 14075.5988 - Avg Loss: 159.9500\n",
            "Epoch [21/50] - Batch loss: 156.1318 - Epoch Loss: 14231.7306 - Avg Loss: 159.9071\n",
            "Epoch [21/50] - Batch loss: 159.5662 - Epoch Loss: 14391.2968 - Avg Loss: 159.9033\n",
            "Epoch [21/50] - Batch loss: 160.0354 - Epoch Loss: 14551.3322 - Avg Loss: 159.9047\n",
            "Epoch [21/50] - Batch loss: 162.0255 - Epoch Loss: 14713.3577 - Avg Loss: 159.9278\n",
            "Epoch [21/50] - Batch loss: 155.3629 - Epoch Loss: 14868.7206 - Avg Loss: 159.8787\n",
            "Epoch [21/50] - Batch loss: 163.3091 - Epoch Loss: 15032.0296 - Avg Loss: 159.9152\n",
            "Epoch [21/50] - Batch loss: 164.1395 - Epoch Loss: 15196.1691 - Avg Loss: 159.9597\n",
            "Epoch [21/50] - Batch loss: 169.0303 - Epoch Loss: 15365.1994 - Avg Loss: 160.0542\n",
            "Epoch [21/50] - Batch loss: 155.8432 - Epoch Loss: 15521.0426 - Avg Loss: 160.0107\n",
            "Epoch [21/50] - Batch loss: 158.1577 - Epoch Loss: 15679.2003 - Avg Loss: 159.9918\n",
            "Epoch [21/50] - Batch loss: 162.9529 - Epoch Loss: 15842.1532 - Avg Loss: 160.0217\n",
            "Epoch [21/50] - Batch loss: 162.6942 - Epoch Loss: 16004.8474 - Avg Loss: 160.0485\n",
            "Epoch [21/50] - Batch loss: 162.0824 - Epoch Loss: 16166.9297 - Avg Loss: 160.0686\n",
            "Epoch [21/50] - Batch loss: 152.4371 - Epoch Loss: 16319.3669 - Avg Loss: 159.9938\n",
            "Epoch [21/50] - Batch loss: 161.3388 - Epoch Loss: 16480.7056 - Avg Loss: 160.0069\n",
            "Epoch [21/50] - Batch loss: 162.6860 - Epoch Loss: 16643.3917 - Avg Loss: 160.0326\n",
            "Epoch [21/50] - Batch loss: 156.9570 - Epoch Loss: 16800.3487 - Avg Loss: 160.0033\n",
            "Epoch [21/50] - Batch loss: 159.6992 - Epoch Loss: 16960.0479 - Avg Loss: 160.0005\n",
            "Epoch [21/50] - Batch loss: 153.9270 - Epoch Loss: 17113.9749 - Avg Loss: 159.9437\n",
            "Epoch [21/50] - Batch loss: 165.5963 - Epoch Loss: 17279.5712 - Avg Loss: 159.9960\n",
            "Epoch [21/50] - Batch loss: 161.3590 - Epoch Loss: 17440.9302 - Avg Loss: 160.0085\n",
            "Epoch [21/50] - Batch loss: 160.9692 - Epoch Loss: 17601.8994 - Avg Loss: 160.0173\n",
            "Epoch [21/50] - Batch loss: 156.2858 - Epoch Loss: 17758.1852 - Avg Loss: 159.9837\n",
            "Epoch [21/50] - Batch loss: 160.4961 - Epoch Loss: 17918.6813 - Avg Loss: 159.9882\n",
            "Epoch [21/50] - Batch loss: 158.9391 - Epoch Loss: 18077.6204 - Avg Loss: 159.9789\n",
            "Epoch [21/50] - Batch loss: 158.2193 - Epoch Loss: 18235.8398 - Avg Loss: 159.9635\n",
            "Epoch [21/50] - Batch loss: 163.2855 - Epoch Loss: 18399.1252 - Avg Loss: 159.9924\n",
            "Epoch [21/50] - Batch loss: 148.5888 - Epoch Loss: 18547.7141 - Avg Loss: 159.8941\n",
            "Epoch [21/50] - Batch loss: 161.7472 - Epoch Loss: 18709.4612 - Avg Loss: 159.9099\n",
            "Epoch [21/50] - Batch loss: 158.6393 - Epoch Loss: 18868.1006 - Avg Loss: 159.8992\n",
            "Epoch [21/50] - Batch loss: 158.8500 - Epoch Loss: 19026.9506 - Avg Loss: 159.8903\n",
            "Epoch [21/50] - Batch loss: 165.5023 - Epoch Loss: 19192.4529 - Avg Loss: 159.9371\n",
            "Epoch [21/50] - Batch loss: 158.8170 - Epoch Loss: 19351.2699 - Avg Loss: 159.9279\n",
            "Epoch [21/50] - Batch loss: 159.2324 - Epoch Loss: 19510.5023 - Avg Loss: 159.9222\n",
            "Epoch [21/50] - Batch loss: 157.6161 - Epoch Loss: 19668.1185 - Avg Loss: 159.9034\n",
            "Epoch [21/50] - Batch loss: 160.6907 - Epoch Loss: 19828.8092 - Avg Loss: 159.9098\n",
            "Epoch [21/50] - Batch loss: 157.3928 - Epoch Loss: 19986.2020 - Avg Loss: 159.8896\n",
            "Epoch [21/50] - Batch loss: 159.2697 - Epoch Loss: 20145.4717 - Avg Loss: 159.8847\n",
            "Epoch [21/50] - Batch loss: 169.6511 - Epoch Loss: 20315.1227 - Avg Loss: 159.9616\n",
            "Epoch [21/50] - Batch loss: 151.7034 - Epoch Loss: 20466.8262 - Avg Loss: 159.8971\n",
            "Epoch [21/50] - Batch loss: 152.5387 - Epoch Loss: 20619.3648 - Avg Loss: 159.8400\n",
            "Epoch [21/50] - Batch loss: 156.0154 - Epoch Loss: 20775.3802 - Avg Loss: 159.8106\n",
            "Epoch [21/50] - Batch loss: 154.4980 - Epoch Loss: 20929.8782 - Avg Loss: 159.7701\n",
            "Epoch [21/50] - Batch loss: 156.6288 - Epoch Loss: 21086.5070 - Avg Loss: 159.7463\n",
            "Epoch [21/50] - Batch loss: 162.9005 - Epoch Loss: 21249.4075 - Avg Loss: 159.7700\n",
            "Epoch [21/50] - Batch loss: 156.6673 - Epoch Loss: 21406.0748 - Avg Loss: 159.7468\n",
            "Epoch [21/50] - Batch loss: 156.6710 - Epoch Loss: 21562.7458 - Avg Loss: 159.7240\n",
            "Epoch [21/50] - Batch loss: 157.8152 - Epoch Loss: 21720.5610 - Avg Loss: 159.7100\n",
            "Epoch [21/50] - Batch loss: 163.2388 - Epoch Loss: 21883.7998 - Avg Loss: 159.7358\n",
            "Epoch [21/50] - Batch loss: 161.1646 - Epoch Loss: 22044.9644 - Avg Loss: 159.7461\n",
            "Epoch [21/50] - Batch loss: 156.9133 - Epoch Loss: 22201.8777 - Avg Loss: 159.7257\n",
            "Epoch [21/50] - Batch loss: 159.9692 - Epoch Loss: 22361.8469 - Avg Loss: 159.7275\n",
            "Epoch [21/50] - Batch loss: 156.5011 - Epoch Loss: 22518.3480 - Avg Loss: 159.7046\n",
            "Epoch [21/50] - Batch loss: 160.2610 - Epoch Loss: 22678.6091 - Avg Loss: 159.7085\n",
            "Epoch [21/50] - Batch loss: 151.1648 - Epoch Loss: 22829.7738 - Avg Loss: 159.6488\n",
            "Epoch [21/50] - Batch loss: 165.1118 - Epoch Loss: 22994.8857 - Avg Loss: 159.6867\n",
            "Epoch [21/50] - Batch loss: 163.8501 - Epoch Loss: 23158.7358 - Avg Loss: 159.7154\n",
            "Epoch [21/50] - Batch loss: 153.8962 - Epoch Loss: 23312.6320 - Avg Loss: 159.6756\n",
            "Epoch [21/50] - Batch loss: 164.2295 - Epoch Loss: 23476.8616 - Avg Loss: 159.7065\n",
            "Epoch [21/50] - Batch loss: 153.2416 - Epoch Loss: 23630.1031 - Avg Loss: 159.6629\n",
            "Epoch [21/50] - Batch loss: 163.1223 - Epoch Loss: 23793.2255 - Avg Loss: 159.6861\n",
            "Epoch [21/50] - Batch loss: 156.3804 - Epoch Loss: 23949.6059 - Avg Loss: 159.6640\n",
            "Epoch [21/50] - Batch loss: 155.7164 - Epoch Loss: 24105.3223 - Avg Loss: 159.6379\n",
            "Epoch [21/50] - Batch loss: 159.4412 - Epoch Loss: 24264.7635 - Avg Loss: 159.6366\n",
            "Epoch [21/50] - Batch loss: 159.5406 - Epoch Loss: 24424.3041 - Avg Loss: 159.6360\n",
            "Epoch [21/50] - Batch loss: 159.6246 - Epoch Loss: 24583.9288 - Avg Loss: 159.6359\n",
            "Epoch [21/50] - Batch loss: 154.3362 - Epoch Loss: 24738.2649 - Avg Loss: 159.6017\n",
            "Epoch [21/50] - Batch loss: 150.4009 - Epoch Loss: 24888.6659 - Avg Loss: 159.5427\n",
            "Epoch [21/50] - Batch loss: 154.3748 - Epoch Loss: 25043.0407 - Avg Loss: 159.5098\n",
            "Epoch [21/50] - Batch loss: 164.0376 - Epoch Loss: 25207.0783 - Avg Loss: 159.5385\n",
            "Epoch [21/50] - Batch loss: 161.9465 - Epoch Loss: 25369.0247 - Avg Loss: 159.5536\n",
            "Epoch [21/50] - Batch loss: 161.9683 - Epoch Loss: 25530.9930 - Avg Loss: 159.5687\n",
            "Epoch [21/50] - Batch loss: 153.8445 - Epoch Loss: 25684.8375 - Avg Loss: 159.5332\n",
            "Epoch [21/50] - Batch loss: 152.6174 - Epoch Loss: 25837.4549 - Avg Loss: 159.4905\n",
            "Epoch [21/50] - Batch loss: 160.0186 - Epoch Loss: 25997.4735 - Avg Loss: 159.4937\n",
            "Epoch [21/50] - Batch loss: 156.0341 - Epoch Loss: 26153.5076 - Avg Loss: 159.4726\n",
            "Epoch [21/50] - Batch loss: 161.2872 - Epoch Loss: 26314.7949 - Avg Loss: 159.4836\n",
            "Epoch [21/50] - Batch loss: 160.3549 - Epoch Loss: 26475.1497 - Avg Loss: 159.4889\n",
            "Epoch [21/50] - Batch loss: 155.5336 - Epoch Loss: 26630.6833 - Avg Loss: 159.4652\n",
            "Epoch [21/50] - Batch loss: 160.8726 - Epoch Loss: 26791.5559 - Avg Loss: 159.4735\n",
            "Epoch [21/50] - Batch loss: 158.4858 - Epoch Loss: 26950.0417 - Avg Loss: 159.4677\n",
            "Epoch [21/50] - Batch loss: 158.1167 - Epoch Loss: 27108.1584 - Avg Loss: 159.4598\n",
            "Epoch [21/50] - Batch loss: 160.8524 - Epoch Loss: 27269.0108 - Avg Loss: 159.4679\n",
            "Epoch [21/50] - Batch loss: 159.8040 - Epoch Loss: 27428.8148 - Avg Loss: 159.4699\n",
            "Epoch [21/50] - Batch loss: 155.2142 - Epoch Loss: 27584.0291 - Avg Loss: 159.4453\n",
            "Epoch [21/50] - Batch loss: 155.9263 - Epoch Loss: 27739.9554 - Avg Loss: 159.4250\n",
            "Epoch [21/50] - Batch loss: 157.8750 - Epoch Loss: 27897.8304 - Avg Loss: 159.4162\n",
            "Epoch [21/50] - Batch loss: 157.0600 - Epoch Loss: 28054.8904 - Avg Loss: 159.4028\n",
            "Epoch [21/50] - Batch loss: 158.2136 - Epoch Loss: 28213.1040 - Avg Loss: 159.3961\n",
            "Epoch [21/50] - Batch loss: 153.1221 - Epoch Loss: 28366.2261 - Avg Loss: 159.3608\n",
            "Epoch [21/50] - Batch loss: 152.6518 - Epoch Loss: 28518.8779 - Avg Loss: 159.3233\n",
            "Epoch [21/50] - Batch loss: 150.9041 - Epoch Loss: 28669.7820 - Avg Loss: 159.2766\n",
            "Epoch [21/50] - Batch loss: 156.0498 - Epoch Loss: 28825.8318 - Avg Loss: 159.2587\n",
            "Epoch [21/50] - Batch loss: 159.1905 - Epoch Loss: 28985.0223 - Avg Loss: 159.2584\n",
            "Epoch [21/50] - Batch loss: 153.5041 - Epoch Loss: 29138.5264 - Avg Loss: 159.2269\n",
            "Epoch [21/50] - Batch loss: 151.6750 - Epoch Loss: 29290.2014 - Avg Loss: 159.1859\n",
            "Epoch [21/50] - Batch loss: 161.1766 - Epoch Loss: 29451.3779 - Avg Loss: 159.1966\n",
            "Epoch [21/50] - Batch loss: 155.9378 - Epoch Loss: 29607.3158 - Avg Loss: 159.1791\n",
            "Epoch [21/50] - Batch loss: 148.9966 - Epoch Loss: 29756.3124 - Avg Loss: 159.1247\n",
            "Epoch [21/50] - Batch loss: 162.5004 - Epoch Loss: 29918.8129 - Avg Loss: 159.1426\n",
            "Epoch [21/50] - Batch loss: 165.8784 - Epoch Loss: 30084.6912 - Avg Loss: 159.1783\n",
            "Epoch [21/50] - Batch loss: 158.1589 - Epoch Loss: 30242.8501 - Avg Loss: 159.1729\n",
            "Epoch [21/50] - Batch loss: 160.7253 - Epoch Loss: 30403.5754 - Avg Loss: 159.1810\n",
            "Epoch [21/50] - Batch loss: 163.4688 - Epoch Loss: 30567.0442 - Avg Loss: 159.2034\n",
            "Epoch [21/50] - Batch loss: 154.7346 - Epoch Loss: 30721.7787 - Avg Loss: 159.1802\n",
            "Epoch [21/50] - Batch loss: 149.2411 - Epoch Loss: 30871.0199 - Avg Loss: 159.1290\n",
            "Epoch [21/50] - Batch loss: 156.9556 - Epoch Loss: 31027.9754 - Avg Loss: 159.1178\n",
            "Epoch [21/50] - Batch loss: 159.7894 - Epoch Loss: 31187.7649 - Avg Loss: 159.1212\n",
            "Epoch [21/50] - Batch loss: 150.7074 - Epoch Loss: 31338.4723 - Avg Loss: 159.0785\n",
            "Epoch [21/50] - Batch loss: 161.0016 - Epoch Loss: 31499.4738 - Avg Loss: 159.0883\n",
            "Epoch [21/50] - Batch loss: 157.6796 - Epoch Loss: 31657.1535 - Avg Loss: 159.0812\n",
            "Epoch [21/50] - Batch loss: 170.9706 - Epoch Loss: 31828.1240 - Avg Loss: 159.1406\n",
            "Epoch [21/50] - Batch loss: 156.3566 - Epoch Loss: 31984.4806 - Avg Loss: 159.1268\n",
            "Epoch [21/50] - Batch loss: 157.5684 - Epoch Loss: 32142.0490 - Avg Loss: 159.1191\n",
            "Epoch [21/50] - Batch loss: 166.6054 - Epoch Loss: 32308.6544 - Avg Loss: 159.1559\n",
            "Epoch [21/50] - Batch loss: 158.8594 - Epoch Loss: 32467.5138 - Avg Loss: 159.1545\n",
            "Epoch [21/50] - Batch loss: 157.8416 - Epoch Loss: 32625.3554 - Avg Loss: 159.1481\n",
            "Epoch [21/50] - Batch loss: 156.2643 - Epoch Loss: 32781.6197 - Avg Loss: 159.1341\n",
            "Epoch [21/50] - Batch loss: 156.4799 - Epoch Loss: 32938.0996 - Avg Loss: 159.1213\n",
            "Epoch [21/50] - Batch loss: 161.0415 - Epoch Loss: 33099.1410 - Avg Loss: 159.1305\n",
            "Epoch [21/50] - Batch loss: 149.5335 - Epoch Loss: 33248.6745 - Avg Loss: 159.0846\n",
            "Epoch [21/50] - Batch loss: 157.0686 - Epoch Loss: 33405.7431 - Avg Loss: 159.0750\n",
            "Epoch [21/50] - Batch loss: 153.7233 - Epoch Loss: 33559.4664 - Avg Loss: 159.0496\n",
            "Epoch [21/50] - Batch loss: 156.3000 - Epoch Loss: 33715.7664 - Avg Loss: 159.0366\n",
            "Epoch [21/50] - Batch loss: 165.0095 - Epoch Loss: 33880.7759 - Avg Loss: 159.0647\n",
            "Epoch [21/50] - Batch loss: 163.4028 - Epoch Loss: 34044.1787 - Avg Loss: 159.0849\n",
            "Epoch [21/50] - Batch loss: 169.5569 - Epoch Loss: 34213.7356 - Avg Loss: 159.1337\n",
            "Epoch [21/50] - Batch loss: 151.2190 - Epoch Loss: 34364.9546 - Avg Loss: 159.0970\n",
            "Epoch [21/50] - Batch loss: 155.4856 - Epoch Loss: 34520.4402 - Avg Loss: 159.0804\n",
            "Epoch [21/50] - Batch loss: 158.5294 - Epoch Loss: 34678.9695 - Avg Loss: 159.0778\n",
            "Epoch [21/50] - Batch loss: 166.6978 - Epoch Loss: 34845.6674 - Avg Loss: 159.1126\n",
            "Epoch [21/50] - Batch loss: 157.0412 - Epoch Loss: 35002.7086 - Avg Loss: 159.1032\n",
            "Epoch [21/50] - Batch loss: 159.6842 - Epoch Loss: 35162.3928 - Avg Loss: 159.1058\n",
            "Epoch [21/50] - Batch loss: 163.1992 - Epoch Loss: 35325.5920 - Avg Loss: 159.1243\n",
            "Epoch [21/50] - Batch loss: 161.3182 - Epoch Loss: 35486.9102 - Avg Loss: 159.1341\n",
            "Epoch [21/50] - Batch loss: 159.1711 - Epoch Loss: 35646.0813 - Avg Loss: 159.1343\n",
            "Epoch [21/50] - Batch loss: 161.8870 - Epoch Loss: 35807.9683 - Avg Loss: 159.1465\n",
            "Epoch [21/50] - Batch loss: 157.8425 - Epoch Loss: 35965.8108 - Avg Loss: 159.1408\n",
            "Epoch [21/50] - Batch loss: 152.1231 - Epoch Loss: 36117.9339 - Avg Loss: 159.1098\n",
            "Epoch [21/50] - Batch loss: 160.1572 - Epoch Loss: 36278.0911 - Avg Loss: 159.1144\n",
            "Epoch [21/50] - Batch loss: 160.1878 - Epoch Loss: 36438.2789 - Avg Loss: 159.1191\n",
            "Epoch [21/50] - Batch loss: 152.2173 - Epoch Loss: 36590.4962 - Avg Loss: 159.0891\n",
            "Epoch [21/50] - Batch loss: 160.0575 - Epoch Loss: 36750.5537 - Avg Loss: 159.0933\n",
            "Epoch [21/50] - Batch loss: 161.3133 - Epoch Loss: 36911.8670 - Avg Loss: 159.1029\n",
            "Epoch [21/50] - Batch loss: 144.7321 - Epoch Loss: 37056.5992 - Avg Loss: 159.0412\n",
            "Epoch [21/50] - Batch loss: 161.9286 - Epoch Loss: 37218.5278 - Avg Loss: 159.0535\n",
            "Epoch [21/50] - Batch loss: 156.8465 - Epoch Loss: 37375.3743 - Avg Loss: 159.0441\n",
            "Epoch [21/50] - Batch loss: 162.3793 - Epoch Loss: 37537.7536 - Avg Loss: 159.0583\n",
            "Epoch [21/50] - Batch loss: 165.2393 - Epoch Loss: 37702.9930 - Avg Loss: 159.0844\n",
            "Epoch [21/50] - Batch loss: 155.3883 - Epoch Loss: 37858.3813 - Avg Loss: 159.0688\n",
            "Epoch [21/50] - Batch loss: 157.9018 - Epoch Loss: 38016.2831 - Avg Loss: 159.0639\n",
            "Epoch [21/50] - Batch loss: 154.2386 - Epoch Loss: 38170.5217 - Avg Loss: 159.0438\n",
            "Epoch [21/50] - Batch loss: 159.9992 - Epoch Loss: 38330.5209 - Avg Loss: 159.0478\n",
            "Epoch [21/50] - Batch loss: 159.3465 - Epoch Loss: 38489.8674 - Avg Loss: 159.0490\n",
            "Epoch [21/50] - Batch loss: 157.9604 - Epoch Loss: 38647.8277 - Avg Loss: 159.0446\n",
            "Epoch [21/50] - Batch loss: 156.8194 - Epoch Loss: 38804.6472 - Avg Loss: 159.0354\n",
            "Epoch [21/50] - Batch loss: 166.5522 - Epoch Loss: 38971.1993 - Avg Loss: 159.0661\n",
            "Epoch [21/50] - Batch loss: 159.4857 - Epoch Loss: 39130.6851 - Avg Loss: 159.0678\n",
            "Epoch [21/50] - Batch loss: 155.0663 - Epoch Loss: 39285.7514 - Avg Loss: 159.0516\n",
            "Epoch [21/50] - Batch loss: 157.9967 - Epoch Loss: 39443.7481 - Avg Loss: 159.0474\n",
            "Epoch [21/50] - Batch loss: 160.3941 - Epoch Loss: 39604.1422 - Avg Loss: 159.0528\n",
            "Epoch [21/50] - Batch loss: 163.8534 - Epoch Loss: 39767.9956 - Avg Loss: 159.0720\n",
            "Epoch [21/50] - Batch loss: 158.5695 - Epoch Loss: 39926.5651 - Avg Loss: 159.0700\n",
            "Epoch [21/50] - Batch loss: 160.5383 - Epoch Loss: 40087.1034 - Avg Loss: 159.0758\n",
            "Epoch [21/50] - Batch loss: 153.5074 - Epoch Loss: 40240.6108 - Avg Loss: 159.0538\n",
            "Epoch [21/50] - Batch loss: 157.4859 - Epoch Loss: 40398.0967 - Avg Loss: 159.0476\n",
            "Epoch [21/50] - Batch loss: 156.8154 - Epoch Loss: 40554.9122 - Avg Loss: 159.0389\n",
            "Epoch [21/50] - Batch loss: 157.2183 - Epoch Loss: 40712.1305 - Avg Loss: 159.0318\n",
            "Epoch [21/50] - Batch loss: 157.4337 - Epoch Loss: 40869.5642 - Avg Loss: 159.0255\n",
            "Epoch [21/50] - Batch loss: 154.5104 - Epoch Loss: 41024.0746 - Avg Loss: 159.0080\n",
            "Epoch [21/50] - Batch loss: 154.9429 - Epoch Loss: 41179.0174 - Avg Loss: 158.9923\n",
            "Epoch [21/50] - Batch loss: 153.2242 - Epoch Loss: 41332.2416 - Avg Loss: 158.9702\n",
            "Epoch [21/50] - Batch loss: 157.0863 - Epoch Loss: 41489.3279 - Avg Loss: 158.9629\n",
            "Epoch [21/50] - Batch loss: 156.9033 - Epoch Loss: 41646.2313 - Avg Loss: 158.9551\n",
            "Epoch [21/50] - Batch loss: 165.0850 - Epoch Loss: 41811.3162 - Avg Loss: 158.9784\n",
            "Epoch [21/50] - Batch loss: 162.4355 - Epoch Loss: 41973.7517 - Avg Loss: 158.9915\n",
            "Epoch [21/50] - Batch loss: 162.4301 - Epoch Loss: 42136.1818 - Avg Loss: 159.0045\n",
            "Epoch [21/50] - Batch loss: 155.9655 - Epoch Loss: 42292.1473 - Avg Loss: 158.9930\n",
            "Epoch [21/50] - Batch loss: 160.2562 - Epoch Loss: 42452.4034 - Avg Loss: 158.9978\n",
            "Epoch [21/50] - Batch loss: 157.5080 - Epoch Loss: 42609.9115 - Avg Loss: 158.9922\n",
            "Epoch [21/50] - Batch loss: 157.9275 - Epoch Loss: 42767.8390 - Avg Loss: 158.9882\n",
            "Epoch [21/50] - Batch loss: 155.9884 - Epoch Loss: 42923.8273 - Avg Loss: 158.9771\n",
            "Epoch [21/50] - Batch loss: 157.4622 - Epoch Loss: 43081.2896 - Avg Loss: 158.9715\n",
            "Epoch [21/50] - Batch loss: 157.2411 - Epoch Loss: 43238.5306 - Avg Loss: 158.9652\n",
            "Epoch [21/50] - Batch loss: 164.9599 - Epoch Loss: 43403.4906 - Avg Loss: 158.9871\n",
            "Epoch [21/50] - Batch loss: 161.0794 - Epoch Loss: 43564.5700 - Avg Loss: 158.9948\n",
            "Epoch [21/50] - Batch loss: 160.4886 - Epoch Loss: 43725.0585 - Avg Loss: 159.0002\n",
            "Epoch [21/50] - Batch loss: 156.7710 - Epoch Loss: 43881.8296 - Avg Loss: 158.9921\n",
            "Epoch [21/50] - Batch loss: 154.3648 - Epoch Loss: 44036.1944 - Avg Loss: 158.9754\n",
            "Epoch [21/50] - Batch loss: 162.9814 - Epoch Loss: 44199.1758 - Avg Loss: 158.9898\n",
            "Epoch [21/50] - Batch loss: 161.1361 - Epoch Loss: 44360.3119 - Avg Loss: 158.9975\n",
            "Epoch [21/50] - Batch loss: 157.6427 - Epoch Loss: 44517.9546 - Avg Loss: 158.9927\n",
            "Epoch [21/50] - Batch loss: 159.8485 - Epoch Loss: 44677.8031 - Avg Loss: 158.9957\n",
            "Epoch [21/50] - Batch loss: 165.6380 - Epoch Loss: 44843.4411 - Avg Loss: 159.0193\n",
            "Epoch [21/50] - Batch loss: 151.7008 - Epoch Loss: 44995.1419 - Avg Loss: 158.9934\n",
            "Epoch [21/50] - Batch loss: 163.5940 - Epoch Loss: 45158.7359 - Avg Loss: 159.0096\n",
            "Epoch [21/50] - Batch loss: 156.2074 - Epoch Loss: 45314.9434 - Avg Loss: 158.9998\n",
            "Epoch [21/50] - Batch loss: 151.8426 - Epoch Loss: 45466.7860 - Avg Loss: 158.9748\n",
            "Epoch [21/50] - Batch loss: 156.8863 - Epoch Loss: 45623.6723 - Avg Loss: 158.9675\n",
            "Epoch [21/50] - Batch loss: 155.1705 - Epoch Loss: 45778.8428 - Avg Loss: 158.9543\n",
            "Epoch [21/50] - Batch loss: 157.3694 - Epoch Loss: 45936.2122 - Avg Loss: 158.9488\n",
            "Epoch [21/50] - Batch loss: 148.4867 - Epoch Loss: 46084.6989 - Avg Loss: 158.9128\n",
            "Epoch [21/50] - Batch loss: 161.5533 - Epoch Loss: 46246.2522 - Avg Loss: 158.9218\n",
            "Epoch [21/50] - Batch loss: 160.9685 - Epoch Loss: 46407.2207 - Avg Loss: 158.9288\n",
            "Epoch [21/50] - Batch loss: 161.7017 - Epoch Loss: 46568.9224 - Avg Loss: 158.9383\n",
            "Epoch [21/50] - Batch loss: 160.3146 - Epoch Loss: 46729.2369 - Avg Loss: 158.9430\n",
            "Epoch [21/50] - Batch loss: 153.3703 - Epoch Loss: 46882.6072 - Avg Loss: 158.9241\n",
            "Epoch [21/50] - Batch loss: 151.1095 - Epoch Loss: 47033.7168 - Avg Loss: 158.8977\n",
            "Epoch [21/50] - Batch loss: 160.2868 - Epoch Loss: 47194.0035 - Avg Loss: 158.9024\n",
            "Epoch [21/50] - Batch loss: 157.5745 - Epoch Loss: 47351.5780 - Avg Loss: 158.8979\n",
            "Epoch [21/50] - Batch loss: 160.0725 - Epoch Loss: 47511.6505 - Avg Loss: 158.9018\n",
            "Epoch [21/50] - Batch loss: 161.2262 - Epoch Loss: 47672.8766 - Avg Loss: 158.9096\n",
            "Epoch [21/50] - Batch loss: 156.5288 - Epoch Loss: 47829.4054 - Avg Loss: 158.9017\n",
            "Epoch [21/50] - Batch loss: 158.0757 - Epoch Loss: 47987.4811 - Avg Loss: 158.8989\n",
            "Epoch [21/50] - Batch loss: 168.6882 - Epoch Loss: 48156.1693 - Avg Loss: 158.9313\n",
            "Epoch [21/50] - Batch loss: 154.4722 - Epoch Loss: 48310.6416 - Avg Loss: 158.9166\n",
            "Epoch [21/50] - Batch loss: 156.6359 - Epoch Loss: 48467.2775 - Avg Loss: 158.9091\n",
            "Epoch [21/50] - Batch loss: 156.6968 - Epoch Loss: 48623.9743 - Avg Loss: 158.9019\n",
            "Epoch [21/50] - Batch loss: 158.0749 - Epoch Loss: 48782.0491 - Avg Loss: 158.8992\n",
            "Epoch [21/50] - Batch loss: 156.4674 - Epoch Loss: 48938.5166 - Avg Loss: 158.8913\n",
            "Epoch [21/50] - Batch loss: 159.3514 - Epoch Loss: 49097.8679 - Avg Loss: 158.8928\n",
            "Epoch [21/50] - Batch loss: 154.7350 - Epoch Loss: 49252.6030 - Avg Loss: 158.8794\n",
            "Epoch [21/50] - Batch loss: 157.9657 - Epoch Loss: 49410.5687 - Avg Loss: 158.8764\n",
            "Epoch [21/50] - Batch loss: 159.2628 - Epoch Loss: 49569.8315 - Avg Loss: 158.8777\n",
            "Epoch [21/50] - Batch loss: 162.4128 - Epoch Loss: 49732.2443 - Avg Loss: 158.8890\n",
            "Epoch [21/50] - Batch loss: 154.8176 - Epoch Loss: 49887.0619 - Avg Loss: 158.8760\n",
            "Epoch [21/50] - Batch loss: 162.3931 - Epoch Loss: 50049.4549 - Avg Loss: 158.8872\n",
            "Epoch [21/50] - Batch loss: 153.9089 - Epoch Loss: 50203.3638 - Avg Loss: 158.8714\n",
            "Epoch [21/50] - Batch loss: 155.0732 - Epoch Loss: 50358.4370 - Avg Loss: 158.8594\n",
            "Epoch [21/50] - Batch loss: 157.1895 - Epoch Loss: 50515.6264 - Avg Loss: 158.8542\n",
            "Epoch [21/50] - Batch loss: 153.3138 - Epoch Loss: 50668.9402 - Avg Loss: 158.8368\n",
            "Epoch [21/50] - Batch loss: 162.2478 - Epoch Loss: 50831.1880 - Avg Loss: 158.8475\n",
            "Epoch [21/50] - Batch loss: 159.5147 - Epoch Loss: 50990.7027 - Avg Loss: 158.8495\n",
            "Epoch [21/50] - Batch loss: 152.3653 - Epoch Loss: 51143.0680 - Avg Loss: 158.8294\n",
            "Epoch [21/50] - Batch loss: 156.7182 - Epoch Loss: 51299.7862 - Avg Loss: 158.8229\n",
            "Epoch [21/50] - Batch loss: 156.3732 - Epoch Loss: 51456.1594 - Avg Loss: 158.8153\n",
            "Epoch [21/50] - Batch loss: 154.1935 - Epoch Loss: 51610.3529 - Avg Loss: 158.8011\n",
            "Epoch [21/50] - Batch loss: 155.8450 - Epoch Loss: 51766.1979 - Avg Loss: 158.7920\n",
            "Epoch [21/50] - Batch loss: 159.0962 - Epoch Loss: 51925.2941 - Avg Loss: 158.7929\n",
            "Epoch [21/50] - Batch loss: 166.2781 - Epoch Loss: 52091.5722 - Avg Loss: 158.8158\n",
            "Epoch [21/50] - Batch loss: 162.0280 - Epoch Loss: 52253.6002 - Avg Loss: 158.8255\n",
            "Epoch [21/50] - Batch loss: 157.9976 - Epoch Loss: 52411.5977 - Avg Loss: 158.8230\n",
            "Epoch [21/50] - Batch loss: 161.7776 - Epoch Loss: 52573.3754 - Avg Loss: 158.8319\n",
            "Epoch [21/50] - Batch loss: 158.9729 - Epoch Loss: 52732.3482 - Avg Loss: 158.8324\n",
            "Epoch [21/50] - Batch loss: 160.4148 - Epoch Loss: 52892.7630 - Avg Loss: 158.8371\n",
            "Epoch [21/50] - Batch loss: 162.1440 - Epoch Loss: 53054.9069 - Avg Loss: 158.8470\n",
            "Epoch [21/50] - Batch loss: 153.5846 - Epoch Loss: 53208.4915 - Avg Loss: 158.8313\n",
            "Epoch [21/50] - Batch loss: 157.3834 - Epoch Loss: 53365.8749 - Avg Loss: 158.8270\n",
            "Epoch [21/50] - Batch loss: 165.8274 - Epoch Loss: 53531.7023 - Avg Loss: 158.8478\n",
            "Epoch [21/50] - Batch loss: 159.4850 - Epoch Loss: 53691.1873 - Avg Loss: 158.8497\n",
            "Epoch [21/50] - Batch loss: 156.6530 - Epoch Loss: 53847.8403 - Avg Loss: 158.8432\n",
            "Epoch [21/50] - Batch loss: 159.3236 - Epoch Loss: 54007.1639 - Avg Loss: 158.8446\n",
            "Epoch [21/50] - Batch loss: 152.2758 - Epoch Loss: 54159.4397 - Avg Loss: 158.8253\n",
            "Epoch [21/50] - Batch loss: 157.1707 - Epoch Loss: 54316.6105 - Avg Loss: 158.8205\n",
            "Epoch [21/50] - Batch loss: 155.6098 - Epoch Loss: 54472.2203 - Avg Loss: 158.8111\n",
            "Epoch [21/50] - Batch loss: 160.6715 - Epoch Loss: 54632.8918 - Avg Loss: 158.8165\n",
            "Epoch [21/50] - Batch loss: 152.3107 - Epoch Loss: 54785.2025 - Avg Loss: 158.7977\n",
            "Epoch [21/50] - Batch loss: 161.8371 - Epoch Loss: 54947.0396 - Avg Loss: 158.8065\n",
            "Epoch [21/50] - Batch loss: 161.3210 - Epoch Loss: 55108.3606 - Avg Loss: 158.8137\n",
            "Epoch [21/50] - Batch loss: 157.4350 - Epoch Loss: 55265.7957 - Avg Loss: 158.8098\n",
            "Epoch [21/50] - Batch loss: 162.2369 - Epoch Loss: 55428.0326 - Avg Loss: 158.8196\n",
            "Epoch [21/50] - Batch loss: 157.0267 - Epoch Loss: 55585.0593 - Avg Loss: 158.8145\n",
            "Epoch [21/50] - Batch loss: 158.7092 - Epoch Loss: 55743.7684 - Avg Loss: 158.8142\n",
            "Epoch [21/50] - Batch loss: 162.7500 - Epoch Loss: 55906.5184 - Avg Loss: 158.8253\n",
            "Epoch [21/50] - Batch loss: 149.9168 - Epoch Loss: 56056.4352 - Avg Loss: 158.8001\n",
            "Epoch [21/50] - Batch loss: 158.3867 - Epoch Loss: 56214.8219 - Avg Loss: 158.7989\n",
            "Epoch [21/50] - Batch loss: 154.8606 - Epoch Loss: 56369.6825 - Avg Loss: 158.7878\n",
            "Epoch [21/50] - Batch loss: 160.0757 - Epoch Loss: 56529.7582 - Avg Loss: 158.7915\n",
            "Epoch [21/50] - Batch loss: 157.8673 - Epoch Loss: 56687.6255 - Avg Loss: 158.7889\n",
            "Epoch [21/50] - Batch loss: 162.8708 - Epoch Loss: 56850.4963 - Avg Loss: 158.8003\n",
            "Epoch [21/50] - Batch loss: 158.5545 - Epoch Loss: 57009.0508 - Avg Loss: 158.7996\n",
            "Epoch [21/50] - Batch loss: 164.0315 - Epoch Loss: 57173.0823 - Avg Loss: 158.8141\n",
            "Epoch [21/50] - Batch loss: 153.8357 - Epoch Loss: 57326.9180 - Avg Loss: 158.8003\n",
            "Epoch [21/50] - Batch loss: 158.1646 - Epoch Loss: 57485.0826 - Avg Loss: 158.7986\n",
            "Epoch [21/50] - Batch loss: 159.3523 - Epoch Loss: 57644.4349 - Avg Loss: 158.8001\n",
            "Epoch [21/50] - Batch loss: 164.1361 - Epoch Loss: 57808.5710 - Avg Loss: 158.8148\n",
            "Epoch [21/50] - Batch loss: 156.5941 - Epoch Loss: 57965.1651 - Avg Loss: 158.8087\n",
            "Epoch [21/50] - Batch loss: 159.3673 - Epoch Loss: 58124.5324 - Avg Loss: 158.8102\n",
            "Epoch [21/50] - Batch loss: 156.4720 - Epoch Loss: 58281.0043 - Avg Loss: 158.8038\n",
            "Epoch [21/50] - Batch loss: 155.3453 - Epoch Loss: 58436.3497 - Avg Loss: 158.7944\n",
            "Epoch [21/50] - Batch loss: 157.7932 - Epoch Loss: 58594.1429 - Avg Loss: 158.7917\n",
            "Epoch [21/50] - Batch loss: 155.1498 - Epoch Loss: 58749.2927 - Avg Loss: 158.7819\n",
            "Epoch [21/50] - Batch loss: 151.9919 - Epoch Loss: 58901.2846 - Avg Loss: 158.7636\n",
            "Epoch [21/50] - Batch loss: 169.9208 - Epoch Loss: 59071.2054 - Avg Loss: 158.7936\n",
            "Epoch [21/50] - Batch loss: 153.0999 - Epoch Loss: 59224.3053 - Avg Loss: 158.7783\n",
            "Epoch [21/50] - Batch loss: 162.3741 - Epoch Loss: 59386.6794 - Avg Loss: 158.7879\n",
            "Epoch [21/50] - Batch loss: 159.6975 - Epoch Loss: 59546.3770 - Avg Loss: 158.7903\n",
            "Epoch [21/50] - Batch loss: 155.9136 - Epoch Loss: 59702.2906 - Avg Loss: 158.7827\n",
            "Epoch [21/50] - Batch loss: 160.6384 - Epoch Loss: 59862.9290 - Avg Loss: 158.7876\n",
            "Epoch [21/50] - Batch loss: 165.4526 - Epoch Loss: 60028.3816 - Avg Loss: 158.8052\n",
            "Epoch [21/50] - Batch loss: 154.5388 - Epoch Loss: 60182.9204 - Avg Loss: 158.7940\n",
            "Epoch [21/50] - Batch loss: 158.9778 - Epoch Loss: 60341.8982 - Avg Loss: 158.7945\n",
            "Epoch [21/50] - Batch loss: 156.4976 - Epoch Loss: 60498.3958 - Avg Loss: 158.7884\n",
            "Epoch [21/50] - Batch loss: 155.4746 - Epoch Loss: 60653.8704 - Avg Loss: 158.7798\n",
            "Epoch [21/50] - Batch loss: 167.3768 - Epoch Loss: 60821.2472 - Avg Loss: 158.8022\n",
            "Epoch [21/50] - Batch loss: 160.5510 - Epoch Loss: 60981.7982 - Avg Loss: 158.8068\n",
            "Epoch [21/50] - Batch loss: 158.7100 - Epoch Loss: 61140.5082 - Avg Loss: 158.8065\n",
            "Epoch [21/50] - Batch loss: 157.5670 - Epoch Loss: 61298.0752 - Avg Loss: 158.8033\n",
            "Epoch [21/50] - Batch loss: 154.7148 - Epoch Loss: 61452.7900 - Avg Loss: 158.7927\n",
            "Epoch [21/50] - Batch loss: 153.1436 - Epoch Loss: 61605.9335 - Avg Loss: 158.7782\n",
            "Epoch [21/50] - Batch loss: 158.0684 - Epoch Loss: 61764.0019 - Avg Loss: 158.7764\n",
            "Epoch [21/50] - Batch loss: 154.1772 - Epoch Loss: 61918.1791 - Avg Loss: 158.7646\n",
            "Epoch [21/50] - Batch loss: 162.4050 - Epoch Loss: 62080.5842 - Avg Loss: 158.7739\n",
            "Epoch [21/50] - Batch loss: 160.2450 - Epoch Loss: 62240.8291 - Avg Loss: 158.7776\n",
            "Epoch [21/50] - Batch loss: 161.3374 - Epoch Loss: 62402.1665 - Avg Loss: 158.7841\n",
            "Epoch [21/50] - Batch loss: 159.2743 - Epoch Loss: 62561.4408 - Avg Loss: 158.7854\n",
            "Epoch [21/50] - Batch loss: 154.7359 - Epoch Loss: 62716.1766 - Avg Loss: 158.7751\n",
            "Epoch [21/50] - Batch loss: 159.0952 - Epoch Loss: 62875.2719 - Avg Loss: 158.7759\n",
            "Epoch [21/50] - Batch loss: 153.4542 - Epoch Loss: 63028.7260 - Avg Loss: 158.7625\n",
            "Epoch [21/50] - Batch loss: 153.8302 - Epoch Loss: 63182.5562 - Avg Loss: 158.7501\n",
            "Epoch [21/50] - Batch loss: 163.6440 - Epoch Loss: 63346.2003 - Avg Loss: 158.7624\n",
            "Epoch [21/50] - Batch loss: 161.4429 - Epoch Loss: 63507.6432 - Avg Loss: 158.7691\n",
            "Epoch [21/50] - Batch loss: 152.2750 - Epoch Loss: 63659.9182 - Avg Loss: 158.7529\n",
            "Epoch [21/50] - Batch loss: 162.9769 - Epoch Loss: 63822.8951 - Avg Loss: 158.7634\n",
            "Epoch [21/50] - Batch loss: 165.1565 - Epoch Loss: 63988.0516 - Avg Loss: 158.7793\n",
            "Epoch [21/50] - Batch loss: 159.7183 - Epoch Loss: 64147.7699 - Avg Loss: 158.7816\n",
            "Epoch [21/50] - Batch loss: 158.8779 - Epoch Loss: 64306.6477 - Avg Loss: 158.7818\n",
            "Epoch [21/50] - Batch loss: 156.4492 - Epoch Loss: 64463.0969 - Avg Loss: 158.7761\n",
            "Epoch [21/50] - Batch loss: 165.5135 - Epoch Loss: 64628.6104 - Avg Loss: 158.7927\n",
            "Epoch [21/50] - Batch loss: 167.6676 - Epoch Loss: 64796.2780 - Avg Loss: 158.8144\n",
            "Epoch [21/50] - Batch loss: 170.5378 - Epoch Loss: 64966.8159 - Avg Loss: 158.8431\n",
            "Epoch [21/50] - Batch loss: 163.3427 - Epoch Loss: 65130.1586 - Avg Loss: 158.8540\n",
            "Epoch [21/50] - Batch loss: 159.5829 - Epoch Loss: 65289.7415 - Avg Loss: 158.8558\n",
            "Epoch [21/50] - Batch loss: 150.9254 - Epoch Loss: 65440.6669 - Avg Loss: 158.8366\n",
            "Epoch [21/50] - Batch loss: 172.6682 - Epoch Loss: 65613.3351 - Avg Loss: 158.8701\n",
            "Epoch [21/50] - Batch loss: 158.7932 - Epoch Loss: 65772.1283 - Avg Loss: 158.8699\n",
            "Epoch [21/50] - Batch loss: 158.8641 - Epoch Loss: 65930.9924 - Avg Loss: 158.8699\n",
            "Epoch [21/50] - Batch loss: 161.4826 - Epoch Loss: 66092.4749 - Avg Loss: 158.8761\n",
            "Epoch [21/50] - Batch loss: 160.8702 - Epoch Loss: 66253.3452 - Avg Loss: 158.8809\n",
            "Epoch [21/50] - Batch loss: 158.3596 - Epoch Loss: 66411.7048 - Avg Loss: 158.8797\n",
            "Epoch [21/50] - Batch loss: 160.7636 - Epoch Loss: 66572.4684 - Avg Loss: 158.8842\n",
            "Epoch [21/50] - Batch loss: 172.4392 - Epoch Loss: 66744.9077 - Avg Loss: 158.9164\n",
            "Epoch [21/50] - Batch loss: 159.6135 - Epoch Loss: 66904.5211 - Avg Loss: 158.9181\n",
            "Epoch [21/50] - Batch loss: 164.0166 - Epoch Loss: 67068.5377 - Avg Loss: 158.9302\n",
            "Epoch [21/50] - Batch loss: 166.4849 - Epoch Loss: 67235.0226 - Avg Loss: 158.9480\n",
            "Epoch [21/50] - Batch loss: 166.6361 - Epoch Loss: 67401.6588 - Avg Loss: 158.9662\n",
            "Epoch [21/50] - Batch loss: 168.8984 - Epoch Loss: 67570.5572 - Avg Loss: 158.9895\n",
            "Epoch [21/50] - Batch loss: 166.6251 - Epoch Loss: 67737.1823 - Avg Loss: 159.0075\n",
            "Epoch [21/50] - Batch loss: 161.8762 - Epoch Loss: 67899.0584 - Avg Loss: 159.0142\n",
            "Epoch [21/50] - Batch loss: 157.8680 - Epoch Loss: 68056.9265 - Avg Loss: 159.0115\n",
            "Epoch [21/50] - Batch loss: 166.1493 - Epoch Loss: 68223.0757 - Avg Loss: 159.0281\n",
            "Epoch [21/50] - Batch loss: 165.6538 - Epoch Loss: 68388.7295 - Avg Loss: 159.0436\n",
            "Epoch [21/50] - Batch loss: 172.0806 - Epoch Loss: 68560.8101 - Avg Loss: 159.0738\n",
            "Epoch [21/50] - Batch loss: 160.9708 - Epoch Loss: 68721.7809 - Avg Loss: 159.0782\n",
            "Epoch [21/50] - Batch loss: 154.8093 - Epoch Loss: 68876.5902 - Avg Loss: 159.0683\n",
            "Epoch [21/50] - Batch loss: 167.7703 - Epoch Loss: 69044.3606 - Avg Loss: 159.0884\n",
            "Epoch [21/50] - Batch loss: 157.9988 - Epoch Loss: 69202.3594 - Avg Loss: 159.0859\n",
            "Epoch [21/50] - Batch loss: 152.0704 - Epoch Loss: 69354.4298 - Avg Loss: 159.0698\n",
            "Epoch [21/50] - Batch loss: 162.0746 - Epoch Loss: 69516.5045 - Avg Loss: 159.0767\n",
            "Epoch [21/50] - Batch loss: 161.1767 - Epoch Loss: 69677.6812 - Avg Loss: 159.0815\n",
            "Epoch [21/50] - Batch loss: 167.9649 - Epoch Loss: 69845.6460 - Avg Loss: 159.1017\n",
            "Epoch [21/50] - Batch loss: 163.2468 - Epoch Loss: 70008.8928 - Avg Loss: 159.1111\n",
            "Epoch [21/50] - Batch loss: 161.4307 - Epoch Loss: 70170.3235 - Avg Loss: 159.1164\n",
            "Epoch [21/50] - Batch loss: 166.3493 - Epoch Loss: 70336.6729 - Avg Loss: 159.1327\n",
            "Epoch [21/50] - Batch loss: 166.7627 - Epoch Loss: 70503.4356 - Avg Loss: 159.1500\n",
            "Epoch [21/50] - Batch loss: 151.7822 - Epoch Loss: 70655.2177 - Avg Loss: 159.1334\n",
            "Epoch [21/50] - Batch loss: 160.1861 - Epoch Loss: 70815.4038 - Avg Loss: 159.1357\n",
            "Epoch [21/50] - Batch loss: 169.3225 - Epoch Loss: 70984.7263 - Avg Loss: 159.1586\n",
            "Epoch [21/50] - Batch loss: 160.0939 - Epoch Loss: 71144.8202 - Avg Loss: 159.1607\n",
            "Epoch [21/50] - Batch loss: 163.8209 - Epoch Loss: 71308.6411 - Avg Loss: 159.1711\n",
            "Epoch [21/50] - Batch loss: 157.8506 - Epoch Loss: 71466.4917 - Avg Loss: 159.1681\n",
            "Epoch [21/50] - Batch loss: 159.1048 - Epoch Loss: 71625.5965 - Avg Loss: 159.1680\n",
            "Epoch [21/50] - Batch loss: 160.2452 - Epoch Loss: 71785.8417 - Avg Loss: 159.1704\n",
            "Epoch [21/50] - Batch loss: 161.4139 - Epoch Loss: 71947.2556 - Avg Loss: 159.1753\n",
            "Epoch [21/50] - Batch loss: 157.2782 - Epoch Loss: 72104.5338 - Avg Loss: 159.1712\n",
            "Epoch [21/50] - Batch loss: 159.5863 - Epoch Loss: 72264.1201 - Avg Loss: 159.1721\n",
            "Epoch [21/50] - Batch loss: 165.9154 - Epoch Loss: 72430.0355 - Avg Loss: 159.1869\n",
            "Epoch [21/50] - Batch loss: 164.8451 - Epoch Loss: 72594.8806 - Avg Loss: 159.1993\n",
            "Epoch [21/50] - Batch loss: 162.4727 - Epoch Loss: 72757.3532 - Avg Loss: 159.2065\n",
            "Epoch [21/50] - Batch loss: 164.8550 - Epoch Loss: 72922.2082 - Avg Loss: 159.2188\n",
            "Epoch [21/50] - Batch loss: 170.0506 - Epoch Loss: 73092.2588 - Avg Loss: 159.2424\n",
            "Epoch [21/50] - Batch loss: 157.5911 - Epoch Loss: 73249.8499 - Avg Loss: 159.2388\n",
            "Epoch [21/50] - Batch loss: 166.5099 - Epoch Loss: 73416.3598 - Avg Loss: 159.2546\n",
            "Epoch [21/50] - Batch loss: 172.3739 - Epoch Loss: 73588.7337 - Avg Loss: 159.2830\n",
            "Epoch [21/50] - Batch loss: 169.4468 - Epoch Loss: 73758.1805 - Avg Loss: 159.3049\n",
            "Epoch [21/50] - Batch loss: 163.5170 - Epoch Loss: 73921.6975 - Avg Loss: 159.3140\n",
            "Epoch [21/50] - Batch loss: 161.5591 - Epoch Loss: 74083.2566 - Avg Loss: 159.3188\n",
            "Epoch [21/50] - Batch loss: 157.8261 - Epoch Loss: 74241.0827 - Avg Loss: 159.3156\n",
            "Epoch [21/50] - Batch loss: 162.4790 - Epoch Loss: 74403.5617 - Avg Loss: 159.3224\n",
            "Epoch [21/50] - Batch loss: 164.2138 - Epoch Loss: 74567.7755 - Avg Loss: 159.3329\n",
            "Epoch [21/50] - Batch loss: 166.2970 - Epoch Loss: 74734.0725 - Avg Loss: 159.3477\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 22/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73c9de68f5be4269b838ad66daf6f227"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/50] - Batch loss: 159.5342 - Epoch Loss: 159.5342 - Avg Loss: 159.5342\n",
            "Epoch [22/50] - Batch loss: 160.5578 - Epoch Loss: 320.0920 - Avg Loss: 160.0460\n",
            "Epoch [22/50] - Batch loss: 173.8325 - Epoch Loss: 493.9245 - Avg Loss: 164.6415\n",
            "Epoch [22/50] - Batch loss: 169.1788 - Epoch Loss: 663.1033 - Avg Loss: 165.7758\n",
            "Epoch [22/50] - Batch loss: 162.2974 - Epoch Loss: 825.4007 - Avg Loss: 165.0801\n",
            "Epoch [22/50] - Batch loss: 173.7464 - Epoch Loss: 999.1470 - Avg Loss: 166.5245\n",
            "Epoch [22/50] - Batch loss: 168.1663 - Epoch Loss: 1167.3134 - Avg Loss: 166.7591\n",
            "Epoch [22/50] - Batch loss: 161.3879 - Epoch Loss: 1328.7013 - Avg Loss: 166.0877\n",
            "Epoch [22/50] - Batch loss: 161.5805 - Epoch Loss: 1490.2817 - Avg Loss: 165.5869\n",
            "Epoch [22/50] - Batch loss: 162.6983 - Epoch Loss: 1652.9800 - Avg Loss: 165.2980\n",
            "Epoch [22/50] - Batch loss: 157.1192 - Epoch Loss: 1810.0992 - Avg Loss: 164.5545\n",
            "Epoch [22/50] - Batch loss: 164.5589 - Epoch Loss: 1974.6581 - Avg Loss: 164.5548\n",
            "Epoch [22/50] - Batch loss: 157.2134 - Epoch Loss: 2131.8714 - Avg Loss: 163.9901\n",
            "Epoch [22/50] - Batch loss: 160.4486 - Epoch Loss: 2292.3201 - Avg Loss: 163.7371\n",
            "Epoch [22/50] - Batch loss: 164.3300 - Epoch Loss: 2456.6500 - Avg Loss: 163.7767\n",
            "Epoch [22/50] - Batch loss: 169.2441 - Epoch Loss: 2625.8941 - Avg Loss: 164.1184\n",
            "Epoch [22/50] - Batch loss: 161.4649 - Epoch Loss: 2787.3590 - Avg Loss: 163.9623\n",
            "Epoch [22/50] - Batch loss: 172.0918 - Epoch Loss: 2959.4508 - Avg Loss: 164.4139\n",
            "Epoch [22/50] - Batch loss: 162.0038 - Epoch Loss: 3121.4546 - Avg Loss: 164.2871\n",
            "Epoch [22/50] - Batch loss: 161.8551 - Epoch Loss: 3283.3097 - Avg Loss: 164.1655\n",
            "Epoch [22/50] - Batch loss: 156.5377 - Epoch Loss: 3439.8474 - Avg Loss: 163.8023\n",
            "Epoch [22/50] - Batch loss: 164.0408 - Epoch Loss: 3603.8882 - Avg Loss: 163.8131\n",
            "Epoch [22/50] - Batch loss: 161.9170 - Epoch Loss: 3765.8053 - Avg Loss: 163.7307\n",
            "Epoch [22/50] - Batch loss: 168.3029 - Epoch Loss: 3934.1081 - Avg Loss: 163.9212\n",
            "Epoch [22/50] - Batch loss: 165.0992 - Epoch Loss: 4099.2074 - Avg Loss: 163.9683\n",
            "Epoch [22/50] - Batch loss: 162.7408 - Epoch Loss: 4261.9481 - Avg Loss: 163.9211\n",
            "Epoch [22/50] - Batch loss: 170.7201 - Epoch Loss: 4432.6682 - Avg Loss: 164.1729\n",
            "Epoch [22/50] - Batch loss: 158.4373 - Epoch Loss: 4591.1055 - Avg Loss: 163.9681\n",
            "Epoch [22/50] - Batch loss: 166.4280 - Epoch Loss: 4757.5334 - Avg Loss: 164.0529\n",
            "Epoch [22/50] - Batch loss: 167.7382 - Epoch Loss: 4925.2716 - Avg Loss: 164.1757\n",
            "Epoch [22/50] - Batch loss: 157.5956 - Epoch Loss: 5082.8672 - Avg Loss: 163.9635\n",
            "Epoch [22/50] - Batch loss: 161.8548 - Epoch Loss: 5244.7220 - Avg Loss: 163.8976\n",
            "Epoch [22/50] - Batch loss: 169.7851 - Epoch Loss: 5414.5071 - Avg Loss: 164.0760\n",
            "Epoch [22/50] - Batch loss: 164.8307 - Epoch Loss: 5579.3378 - Avg Loss: 164.0982\n",
            "Epoch [22/50] - Batch loss: 161.5902 - Epoch Loss: 5740.9281 - Avg Loss: 164.0265\n",
            "Epoch [22/50] - Batch loss: 157.5713 - Epoch Loss: 5898.4993 - Avg Loss: 163.8472\n",
            "Epoch [22/50] - Batch loss: 161.7531 - Epoch Loss: 6060.2524 - Avg Loss: 163.7906\n",
            "Epoch [22/50] - Batch loss: 164.0764 - Epoch Loss: 6224.3288 - Avg Loss: 163.7981\n",
            "Epoch [22/50] - Batch loss: 169.1357 - Epoch Loss: 6393.4644 - Avg Loss: 163.9350\n",
            "Epoch [22/50] - Batch loss: 165.0498 - Epoch Loss: 6558.5143 - Avg Loss: 163.9629\n",
            "Epoch [22/50] - Batch loss: 162.3386 - Epoch Loss: 6720.8528 - Avg Loss: 163.9232\n",
            "Epoch [22/50] - Batch loss: 160.5161 - Epoch Loss: 6881.3689 - Avg Loss: 163.8421\n",
            "Epoch [22/50] - Batch loss: 174.2263 - Epoch Loss: 7055.5952 - Avg Loss: 164.0836\n",
            "Epoch [22/50] - Batch loss: 157.6009 - Epoch Loss: 7213.1961 - Avg Loss: 163.9363\n",
            "Epoch [22/50] - Batch loss: 168.9578 - Epoch Loss: 7382.1539 - Avg Loss: 164.0479\n",
            "Epoch [22/50] - Batch loss: 163.3659 - Epoch Loss: 7545.5198 - Avg Loss: 164.0330\n",
            "Epoch [22/50] - Batch loss: 166.7603 - Epoch Loss: 7712.2800 - Avg Loss: 164.0911\n",
            "Epoch [22/50] - Batch loss: 159.0361 - Epoch Loss: 7871.3161 - Avg Loss: 163.9858\n",
            "Epoch [22/50] - Batch loss: 170.8146 - Epoch Loss: 8042.1307 - Avg Loss: 164.1251\n",
            "Epoch [22/50] - Batch loss: 163.0172 - Epoch Loss: 8205.1479 - Avg Loss: 164.1030\n",
            "Epoch [22/50] - Batch loss: 160.0216 - Epoch Loss: 8365.1696 - Avg Loss: 164.0229\n",
            "Epoch [22/50] - Batch loss: 164.0195 - Epoch Loss: 8529.1891 - Avg Loss: 164.0229\n",
            "Epoch [22/50] - Batch loss: 166.8245 - Epoch Loss: 8696.0136 - Avg Loss: 164.0757\n",
            "Epoch [22/50] - Batch loss: 167.4184 - Epoch Loss: 8863.4320 - Avg Loss: 164.1376\n",
            "Epoch [22/50] - Batch loss: 160.7943 - Epoch Loss: 9024.2262 - Avg Loss: 164.0768\n",
            "Epoch [22/50] - Batch loss: 161.7504 - Epoch Loss: 9185.9766 - Avg Loss: 164.0353\n",
            "Epoch [22/50] - Batch loss: 156.9510 - Epoch Loss: 9342.9276 - Avg Loss: 163.9110\n",
            "Epoch [22/50] - Batch loss: 163.8874 - Epoch Loss: 9506.8150 - Avg Loss: 163.9106\n",
            "Epoch [22/50] - Batch loss: 162.9990 - Epoch Loss: 9669.8140 - Avg Loss: 163.8952\n",
            "Epoch [22/50] - Batch loss: 164.5272 - Epoch Loss: 9834.3412 - Avg Loss: 163.9057\n",
            "Epoch [22/50] - Batch loss: 157.7726 - Epoch Loss: 9992.1137 - Avg Loss: 163.8051\n",
            "Epoch [22/50] - Batch loss: 169.5857 - Epoch Loss: 10161.6995 - Avg Loss: 163.8984\n",
            "Epoch [22/50] - Batch loss: 169.8038 - Epoch Loss: 10331.5032 - Avg Loss: 163.9921\n",
            "Epoch [22/50] - Batch loss: 162.3491 - Epoch Loss: 10493.8523 - Avg Loss: 163.9664\n",
            "Epoch [22/50] - Batch loss: 157.3392 - Epoch Loss: 10651.1916 - Avg Loss: 163.8645\n",
            "Epoch [22/50] - Batch loss: 163.4309 - Epoch Loss: 10814.6225 - Avg Loss: 163.8579\n",
            "Epoch [22/50] - Batch loss: 158.6999 - Epoch Loss: 10973.3224 - Avg Loss: 163.7809\n",
            "Epoch [22/50] - Batch loss: 163.8627 - Epoch Loss: 11137.1852 - Avg Loss: 163.7821\n",
            "Epoch [22/50] - Batch loss: 164.0977 - Epoch Loss: 11301.2829 - Avg Loss: 163.7867\n",
            "Epoch [22/50] - Batch loss: 156.1013 - Epoch Loss: 11457.3842 - Avg Loss: 163.6769\n",
            "Epoch [22/50] - Batch loss: 165.6399 - Epoch Loss: 11623.0240 - Avg Loss: 163.7046\n",
            "Epoch [22/50] - Batch loss: 158.3058 - Epoch Loss: 11781.3299 - Avg Loss: 163.6296\n",
            "Epoch [22/50] - Batch loss: 159.2205 - Epoch Loss: 11940.5504 - Avg Loss: 163.5692\n",
            "Epoch [22/50] - Batch loss: 158.2552 - Epoch Loss: 12098.8055 - Avg Loss: 163.4974\n",
            "Epoch [22/50] - Batch loss: 158.1125 - Epoch Loss: 12256.9181 - Avg Loss: 163.4256\n",
            "Epoch [22/50] - Batch loss: 159.2181 - Epoch Loss: 12416.1362 - Avg Loss: 163.3702\n",
            "Epoch [22/50] - Batch loss: 161.5955 - Epoch Loss: 12577.7316 - Avg Loss: 163.3472\n",
            "Epoch [22/50] - Batch loss: 174.6761 - Epoch Loss: 12752.4077 - Avg Loss: 163.4924\n",
            "Epoch [22/50] - Batch loss: 150.7656 - Epoch Loss: 12903.1733 - Avg Loss: 163.3313\n",
            "Epoch [22/50] - Batch loss: 168.7124 - Epoch Loss: 13071.8857 - Avg Loss: 163.3986\n",
            "Epoch [22/50] - Batch loss: 154.9848 - Epoch Loss: 13226.8706 - Avg Loss: 163.2947\n",
            "Epoch [22/50] - Batch loss: 158.8110 - Epoch Loss: 13385.6816 - Avg Loss: 163.2400\n",
            "Epoch [22/50] - Batch loss: 162.1646 - Epoch Loss: 13547.8462 - Avg Loss: 163.2271\n",
            "Epoch [22/50] - Batch loss: 165.4654 - Epoch Loss: 13713.3116 - Avg Loss: 163.2537\n",
            "Epoch [22/50] - Batch loss: 158.9156 - Epoch Loss: 13872.2272 - Avg Loss: 163.2027\n",
            "Epoch [22/50] - Batch loss: 155.9050 - Epoch Loss: 14028.1322 - Avg Loss: 163.1178\n",
            "Epoch [22/50] - Batch loss: 165.7056 - Epoch Loss: 14193.8378 - Avg Loss: 163.1476\n",
            "Epoch [22/50] - Batch loss: 162.9125 - Epoch Loss: 14356.7502 - Avg Loss: 163.1449\n",
            "Epoch [22/50] - Batch loss: 163.9927 - Epoch Loss: 14520.7429 - Avg Loss: 163.1544\n",
            "Epoch [22/50] - Batch loss: 159.5901 - Epoch Loss: 14680.3331 - Avg Loss: 163.1148\n",
            "Epoch [22/50] - Batch loss: 165.9049 - Epoch Loss: 14846.2379 - Avg Loss: 163.1455\n",
            "Epoch [22/50] - Batch loss: 156.1605 - Epoch Loss: 15002.3985 - Avg Loss: 163.0695\n",
            "Epoch [22/50] - Batch loss: 154.4735 - Epoch Loss: 15156.8720 - Avg Loss: 162.9771\n",
            "Epoch [22/50] - Batch loss: 161.0641 - Epoch Loss: 15317.9361 - Avg Loss: 162.9568\n",
            "Epoch [22/50] - Batch loss: 145.7563 - Epoch Loss: 15463.6924 - Avg Loss: 162.7757\n",
            "Epoch [22/50] - Batch loss: 153.9722 - Epoch Loss: 15617.6645 - Avg Loss: 162.6840\n",
            "Epoch [22/50] - Batch loss: 162.2858 - Epoch Loss: 15779.9503 - Avg Loss: 162.6799\n",
            "Epoch [22/50] - Batch loss: 156.5459 - Epoch Loss: 15936.4962 - Avg Loss: 162.6173\n",
            "Epoch [22/50] - Batch loss: 159.9098 - Epoch Loss: 16096.4061 - Avg Loss: 162.5900\n",
            "Epoch [22/50] - Batch loss: 156.3043 - Epoch Loss: 16252.7104 - Avg Loss: 162.5271\n",
            "Epoch [22/50] - Batch loss: 163.0213 - Epoch Loss: 16415.7317 - Avg Loss: 162.5320\n",
            "Epoch [22/50] - Batch loss: 165.0546 - Epoch Loss: 16580.7863 - Avg Loss: 162.5567\n",
            "Epoch [22/50] - Batch loss: 161.8926 - Epoch Loss: 16742.6789 - Avg Loss: 162.5503\n",
            "Epoch [22/50] - Batch loss: 155.6306 - Epoch Loss: 16898.3095 - Avg Loss: 162.4837\n",
            "Epoch [22/50] - Batch loss: 161.4437 - Epoch Loss: 17059.7532 - Avg Loss: 162.4738\n",
            "Epoch [22/50] - Batch loss: 157.8640 - Epoch Loss: 17217.6172 - Avg Loss: 162.4304\n",
            "Epoch [22/50] - Batch loss: 165.2574 - Epoch Loss: 17382.8746 - Avg Loss: 162.4568\n",
            "Epoch [22/50] - Batch loss: 162.2032 - Epoch Loss: 17545.0778 - Avg Loss: 162.4544\n",
            "Epoch [22/50] - Batch loss: 153.4847 - Epoch Loss: 17698.5625 - Avg Loss: 162.3721\n",
            "Epoch [22/50] - Batch loss: 161.3136 - Epoch Loss: 17859.8761 - Avg Loss: 162.3625\n",
            "Epoch [22/50] - Batch loss: 158.9432 - Epoch Loss: 18018.8193 - Avg Loss: 162.3317\n",
            "Epoch [22/50] - Batch loss: 162.3421 - Epoch Loss: 18181.1614 - Avg Loss: 162.3318\n",
            "Epoch [22/50] - Batch loss: 164.4189 - Epoch Loss: 18345.5803 - Avg Loss: 162.3503\n",
            "Epoch [22/50] - Batch loss: 168.3105 - Epoch Loss: 18513.8909 - Avg Loss: 162.4026\n",
            "Epoch [22/50] - Batch loss: 159.0135 - Epoch Loss: 18672.9043 - Avg Loss: 162.3731\n",
            "Epoch [22/50] - Batch loss: 159.2460 - Epoch Loss: 18832.1503 - Avg Loss: 162.3461\n",
            "Epoch [22/50] - Batch loss: 162.9380 - Epoch Loss: 18995.0883 - Avg Loss: 162.3512\n",
            "Epoch [22/50] - Batch loss: 160.1505 - Epoch Loss: 19155.2388 - Avg Loss: 162.3325\n",
            "Epoch [22/50] - Batch loss: 151.4261 - Epoch Loss: 19306.6649 - Avg Loss: 162.2409\n",
            "Epoch [22/50] - Batch loss: 159.4106 - Epoch Loss: 19466.0756 - Avg Loss: 162.2173\n",
            "Epoch [22/50] - Batch loss: 165.0376 - Epoch Loss: 19631.1132 - Avg Loss: 162.2406\n",
            "Epoch [22/50] - Batch loss: 158.4913 - Epoch Loss: 19789.6044 - Avg Loss: 162.2099\n",
            "Epoch [22/50] - Batch loss: 159.4248 - Epoch Loss: 19949.0292 - Avg Loss: 162.1872\n",
            "Epoch [22/50] - Batch loss: 158.3594 - Epoch Loss: 20107.3886 - Avg Loss: 162.1564\n",
            "Epoch [22/50] - Batch loss: 161.4841 - Epoch Loss: 20268.8727 - Avg Loss: 162.1510\n",
            "Epoch [22/50] - Batch loss: 157.8645 - Epoch Loss: 20426.7372 - Avg Loss: 162.1170\n",
            "Epoch [22/50] - Batch loss: 160.1966 - Epoch Loss: 20586.9338 - Avg Loss: 162.1018\n",
            "Epoch [22/50] - Batch loss: 155.2868 - Epoch Loss: 20742.2206 - Avg Loss: 162.0486\n",
            "Epoch [22/50] - Batch loss: 153.2444 - Epoch Loss: 20895.4650 - Avg Loss: 161.9803\n",
            "Epoch [22/50] - Batch loss: 159.3625 - Epoch Loss: 21054.8275 - Avg Loss: 161.9602\n",
            "Epoch [22/50] - Batch loss: 162.0817 - Epoch Loss: 21216.9092 - Avg Loss: 161.9611\n",
            "Epoch [22/50] - Batch loss: 163.3369 - Epoch Loss: 21380.2461 - Avg Loss: 161.9716\n",
            "Epoch [22/50] - Batch loss: 165.3521 - Epoch Loss: 21545.5982 - Avg Loss: 161.9970\n",
            "Epoch [22/50] - Batch loss: 158.0946 - Epoch Loss: 21703.6929 - Avg Loss: 161.9679\n",
            "Epoch [22/50] - Batch loss: 157.5254 - Epoch Loss: 21861.2182 - Avg Loss: 161.9349\n",
            "Epoch [22/50] - Batch loss: 163.8735 - Epoch Loss: 22025.0917 - Avg Loss: 161.9492\n",
            "Epoch [22/50] - Batch loss: 165.6941 - Epoch Loss: 22190.7858 - Avg Loss: 161.9765\n",
            "Epoch [22/50] - Batch loss: 167.4203 - Epoch Loss: 22358.2061 - Avg Loss: 162.0160\n",
            "Epoch [22/50] - Batch loss: 167.4649 - Epoch Loss: 22525.6709 - Avg Loss: 162.0552\n",
            "Epoch [22/50] - Batch loss: 161.6905 - Epoch Loss: 22687.3615 - Avg Loss: 162.0526\n",
            "Epoch [22/50] - Batch loss: 165.4924 - Epoch Loss: 22852.8538 - Avg Loss: 162.0770\n",
            "Epoch [22/50] - Batch loss: 165.2075 - Epoch Loss: 23018.0614 - Avg Loss: 162.0990\n",
            "Epoch [22/50] - Batch loss: 163.2840 - Epoch Loss: 23181.3454 - Avg Loss: 162.1073\n",
            "Epoch [22/50] - Batch loss: 166.2329 - Epoch Loss: 23347.5782 - Avg Loss: 162.1360\n",
            "Epoch [22/50] - Batch loss: 160.2022 - Epoch Loss: 23507.7805 - Avg Loss: 162.1226\n",
            "Epoch [22/50] - Batch loss: 159.6088 - Epoch Loss: 23667.3893 - Avg Loss: 162.1054\n",
            "Epoch [22/50] - Batch loss: 160.8542 - Epoch Loss: 23828.2435 - Avg Loss: 162.0969\n",
            "Epoch [22/50] - Batch loss: 164.6249 - Epoch Loss: 23992.8684 - Avg Loss: 162.1140\n",
            "Epoch [22/50] - Batch loss: 156.1413 - Epoch Loss: 24149.0096 - Avg Loss: 162.0739\n",
            "Epoch [22/50] - Batch loss: 158.8386 - Epoch Loss: 24307.8483 - Avg Loss: 162.0523\n",
            "Epoch [22/50] - Batch loss: 157.1249 - Epoch Loss: 24464.9732 - Avg Loss: 162.0197\n",
            "Epoch [22/50] - Batch loss: 166.9433 - Epoch Loss: 24631.9165 - Avg Loss: 162.0521\n",
            "Epoch [22/50] - Batch loss: 168.3985 - Epoch Loss: 24800.3150 - Avg Loss: 162.0936\n",
            "Epoch [22/50] - Batch loss: 162.1134 - Epoch Loss: 24962.4284 - Avg Loss: 162.0937\n",
            "Epoch [22/50] - Batch loss: 153.8077 - Epoch Loss: 25116.2361 - Avg Loss: 162.0402\n",
            "Epoch [22/50] - Batch loss: 156.0963 - Epoch Loss: 25272.3324 - Avg Loss: 162.0021\n",
            "Epoch [22/50] - Batch loss: 156.5587 - Epoch Loss: 25428.8911 - Avg Loss: 161.9675\n",
            "Epoch [22/50] - Batch loss: 153.0397 - Epoch Loss: 25581.9308 - Avg Loss: 161.9110\n",
            "Epoch [22/50] - Batch loss: 161.5791 - Epoch Loss: 25743.5100 - Avg Loss: 161.9089\n",
            "Epoch [22/50] - Batch loss: 168.5253 - Epoch Loss: 25912.0352 - Avg Loss: 161.9502\n",
            "Epoch [22/50] - Batch loss: 162.6873 - Epoch Loss: 26074.7225 - Avg Loss: 161.9548\n",
            "Epoch [22/50] - Batch loss: 157.3638 - Epoch Loss: 26232.0863 - Avg Loss: 161.9265\n",
            "Epoch [22/50] - Batch loss: 153.3589 - Epoch Loss: 26385.4452 - Avg Loss: 161.8739\n",
            "Epoch [22/50] - Batch loss: 156.3157 - Epoch Loss: 26541.7609 - Avg Loss: 161.8400\n",
            "Epoch [22/50] - Batch loss: 160.2273 - Epoch Loss: 26701.9882 - Avg Loss: 161.8302\n",
            "Epoch [22/50] - Batch loss: 156.0570 - Epoch Loss: 26858.0453 - Avg Loss: 161.7955\n",
            "Epoch [22/50] - Batch loss: 165.0238 - Epoch Loss: 27023.0691 - Avg Loss: 161.8148\n",
            "Epoch [22/50] - Batch loss: 164.5105 - Epoch Loss: 27187.5795 - Avg Loss: 161.8308\n",
            "Epoch [22/50] - Batch loss: 155.8508 - Epoch Loss: 27343.4303 - Avg Loss: 161.7954\n",
            "Epoch [22/50] - Batch loss: 162.1059 - Epoch Loss: 27505.5362 - Avg Loss: 161.7973\n",
            "Epoch [22/50] - Batch loss: 164.3735 - Epoch Loss: 27669.9097 - Avg Loss: 161.8123\n",
            "Epoch [22/50] - Batch loss: 156.7863 - Epoch Loss: 27826.6960 - Avg Loss: 161.7831\n",
            "Epoch [22/50] - Batch loss: 158.6002 - Epoch Loss: 27985.2962 - Avg Loss: 161.7647\n",
            "Epoch [22/50] - Batch loss: 162.1983 - Epoch Loss: 28147.4945 - Avg Loss: 161.7672\n",
            "Epoch [22/50] - Batch loss: 153.6774 - Epoch Loss: 28301.1719 - Avg Loss: 161.7210\n",
            "Epoch [22/50] - Batch loss: 156.4749 - Epoch Loss: 28457.6468 - Avg Loss: 161.6912\n",
            "Epoch [22/50] - Batch loss: 156.7075 - Epoch Loss: 28614.3543 - Avg Loss: 161.6630\n",
            "Epoch [22/50] - Batch loss: 163.4216 - Epoch Loss: 28777.7759 - Avg Loss: 161.6729\n",
            "Epoch [22/50] - Batch loss: 163.2894 - Epoch Loss: 28941.0653 - Avg Loss: 161.6819\n",
            "Epoch [22/50] - Batch loss: 162.2158 - Epoch Loss: 29103.2810 - Avg Loss: 161.6849\n",
            "Epoch [22/50] - Batch loss: 160.8641 - Epoch Loss: 29264.1451 - Avg Loss: 161.6804\n",
            "Epoch [22/50] - Batch loss: 158.3012 - Epoch Loss: 29422.4463 - Avg Loss: 161.6618\n",
            "Epoch [22/50] - Batch loss: 156.5241 - Epoch Loss: 29578.9704 - Avg Loss: 161.6337\n",
            "Epoch [22/50] - Batch loss: 151.5897 - Epoch Loss: 29730.5601 - Avg Loss: 161.5791\n",
            "Epoch [22/50] - Batch loss: 159.5765 - Epoch Loss: 29890.1366 - Avg Loss: 161.5683\n",
            "Epoch [22/50] - Batch loss: 159.7985 - Epoch Loss: 30049.9351 - Avg Loss: 161.5588\n",
            "Epoch [22/50] - Batch loss: 161.2970 - Epoch Loss: 30211.2321 - Avg Loss: 161.5574\n",
            "Epoch [22/50] - Batch loss: 164.4367 - Epoch Loss: 30375.6688 - Avg Loss: 161.5727\n",
            "Epoch [22/50] - Batch loss: 150.7326 - Epoch Loss: 30526.4014 - Avg Loss: 161.5154\n",
            "Epoch [22/50] - Batch loss: 153.8579 - Epoch Loss: 30680.2593 - Avg Loss: 161.4750\n",
            "Epoch [22/50] - Batch loss: 162.7251 - Epoch Loss: 30842.9844 - Avg Loss: 161.4816\n",
            "Epoch [22/50] - Batch loss: 159.2094 - Epoch Loss: 31002.1939 - Avg Loss: 161.4698\n",
            "Epoch [22/50] - Batch loss: 169.3714 - Epoch Loss: 31171.5653 - Avg Loss: 161.5107\n",
            "Epoch [22/50] - Batch loss: 156.0206 - Epoch Loss: 31327.5859 - Avg Loss: 161.4824\n",
            "Epoch [22/50] - Batch loss: 160.3848 - Epoch Loss: 31487.9707 - Avg Loss: 161.4768\n",
            "Epoch [22/50] - Batch loss: 156.1376 - Epoch Loss: 31644.1083 - Avg Loss: 161.4495\n",
            "Epoch [22/50] - Batch loss: 162.3519 - Epoch Loss: 31806.4602 - Avg Loss: 161.4541\n",
            "Epoch [22/50] - Batch loss: 158.6247 - Epoch Loss: 31965.0849 - Avg Loss: 161.4398\n",
            "Epoch [22/50] - Batch loss: 154.1713 - Epoch Loss: 32119.2562 - Avg Loss: 161.4033\n",
            "Epoch [22/50] - Batch loss: 154.7102 - Epoch Loss: 32273.9664 - Avg Loss: 161.3698\n",
            "Epoch [22/50] - Batch loss: 160.9936 - Epoch Loss: 32434.9600 - Avg Loss: 161.3680\n",
            "Epoch [22/50] - Batch loss: 161.5482 - Epoch Loss: 32596.5082 - Avg Loss: 161.3689\n",
            "Epoch [22/50] - Batch loss: 154.8782 - Epoch Loss: 32751.3864 - Avg Loss: 161.3369\n",
            "Epoch [22/50] - Batch loss: 164.6406 - Epoch Loss: 32916.0270 - Avg Loss: 161.3531\n",
            "Epoch [22/50] - Batch loss: 155.0480 - Epoch Loss: 33071.0751 - Avg Loss: 161.3223\n",
            "Epoch [22/50] - Batch loss: 160.2571 - Epoch Loss: 33231.3322 - Avg Loss: 161.3171\n",
            "Epoch [22/50] - Batch loss: 158.3632 - Epoch Loss: 33389.6953 - Avg Loss: 161.3029\n",
            "Epoch [22/50] - Batch loss: 158.6806 - Epoch Loss: 33548.3760 - Avg Loss: 161.2903\n",
            "Epoch [22/50] - Batch loss: 160.5474 - Epoch Loss: 33708.9234 - Avg Loss: 161.2867\n",
            "Epoch [22/50] - Batch loss: 157.2963 - Epoch Loss: 33866.2197 - Avg Loss: 161.2677\n",
            "Epoch [22/50] - Batch loss: 157.0315 - Epoch Loss: 34023.2513 - Avg Loss: 161.2476\n",
            "Epoch [22/50] - Batch loss: 160.1008 - Epoch Loss: 34183.3520 - Avg Loss: 161.2422\n",
            "Epoch [22/50] - Batch loss: 165.4369 - Epoch Loss: 34348.7889 - Avg Loss: 161.2619\n",
            "Epoch [22/50] - Batch loss: 151.1874 - Epoch Loss: 34499.9763 - Avg Loss: 161.2148\n",
            "Epoch [22/50] - Batch loss: 151.4552 - Epoch Loss: 34651.4315 - Avg Loss: 161.1694\n",
            "Epoch [22/50] - Batch loss: 164.4501 - Epoch Loss: 34815.8816 - Avg Loss: 161.1846\n",
            "Epoch [22/50] - Batch loss: 157.9397 - Epoch Loss: 34973.8213 - Avg Loss: 161.1697\n",
            "Epoch [22/50] - Batch loss: 157.6314 - Epoch Loss: 35131.4527 - Avg Loss: 161.1535\n",
            "Epoch [22/50] - Batch loss: 161.0135 - Epoch Loss: 35292.4662 - Avg Loss: 161.1528\n",
            "Epoch [22/50] - Batch loss: 162.3222 - Epoch Loss: 35454.7884 - Avg Loss: 161.1581\n",
            "Epoch [22/50] - Batch loss: 152.6010 - Epoch Loss: 35607.3894 - Avg Loss: 161.1194\n",
            "Epoch [22/50] - Batch loss: 162.0310 - Epoch Loss: 35769.4204 - Avg Loss: 161.1235\n",
            "Epoch [22/50] - Batch loss: 154.1747 - Epoch Loss: 35923.5951 - Avg Loss: 161.0924\n",
            "Epoch [22/50] - Batch loss: 157.3123 - Epoch Loss: 36080.9073 - Avg Loss: 161.0755\n",
            "Epoch [22/50] - Batch loss: 170.7108 - Epoch Loss: 36251.6182 - Avg Loss: 161.1183\n",
            "Epoch [22/50] - Batch loss: 159.5735 - Epoch Loss: 36411.1917 - Avg Loss: 161.1115\n",
            "Epoch [22/50] - Batch loss: 160.9651 - Epoch Loss: 36572.1568 - Avg Loss: 161.1108\n",
            "Epoch [22/50] - Batch loss: 155.4528 - Epoch Loss: 36727.6097 - Avg Loss: 161.0860\n",
            "Epoch [22/50] - Batch loss: 153.6493 - Epoch Loss: 36881.2590 - Avg Loss: 161.0535\n",
            "Epoch [22/50] - Batch loss: 156.8719 - Epoch Loss: 37038.1309 - Avg Loss: 161.0354\n",
            "Epoch [22/50] - Batch loss: 163.7861 - Epoch Loss: 37201.9170 - Avg Loss: 161.0473\n",
            "Epoch [22/50] - Batch loss: 154.1436 - Epoch Loss: 37356.0606 - Avg Loss: 161.0175\n",
            "Epoch [22/50] - Batch loss: 158.5735 - Epoch Loss: 37514.6341 - Avg Loss: 161.0070\n",
            "Epoch [22/50] - Batch loss: 158.0371 - Epoch Loss: 37672.6712 - Avg Loss: 160.9943\n",
            "Epoch [22/50] - Batch loss: 161.3342 - Epoch Loss: 37834.0053 - Avg Loss: 160.9958\n",
            "Epoch [22/50] - Batch loss: 151.6491 - Epoch Loss: 37985.6545 - Avg Loss: 160.9562\n",
            "Epoch [22/50] - Batch loss: 152.5173 - Epoch Loss: 38138.1718 - Avg Loss: 160.9206\n",
            "Epoch [22/50] - Batch loss: 162.2452 - Epoch Loss: 38300.4170 - Avg Loss: 160.9261\n",
            "Epoch [22/50] - Batch loss: 153.3455 - Epoch Loss: 38453.7625 - Avg Loss: 160.8944\n",
            "Epoch [22/50] - Batch loss: 157.3152 - Epoch Loss: 38611.0777 - Avg Loss: 160.8795\n",
            "Epoch [22/50] - Batch loss: 155.9603 - Epoch Loss: 38767.0380 - Avg Loss: 160.8591\n",
            "Epoch [22/50] - Batch loss: 171.0820 - Epoch Loss: 38938.1199 - Avg Loss: 160.9013\n",
            "Epoch [22/50] - Batch loss: 155.7217 - Epoch Loss: 39093.8416 - Avg Loss: 160.8800\n",
            "Epoch [22/50] - Batch loss: 161.8593 - Epoch Loss: 39255.7009 - Avg Loss: 160.8840\n",
            "Epoch [22/50] - Batch loss: 160.4260 - Epoch Loss: 39416.1269 - Avg Loss: 160.8822\n",
            "Epoch [22/50] - Batch loss: 162.9533 - Epoch Loss: 39579.0802 - Avg Loss: 160.8906\n",
            "Epoch [22/50] - Batch loss: 162.9830 - Epoch Loss: 39742.0632 - Avg Loss: 160.8990\n",
            "Epoch [22/50] - Batch loss: 157.1228 - Epoch Loss: 39899.1860 - Avg Loss: 160.8838\n",
            "Epoch [22/50] - Batch loss: 164.3188 - Epoch Loss: 40063.5048 - Avg Loss: 160.8976\n",
            "Epoch [22/50] - Batch loss: 162.8319 - Epoch Loss: 40226.3367 - Avg Loss: 160.9053\n",
            "Epoch [22/50] - Batch loss: 157.4425 - Epoch Loss: 40383.7792 - Avg Loss: 160.8916\n",
            "Epoch [22/50] - Batch loss: 162.4643 - Epoch Loss: 40546.2435 - Avg Loss: 160.8978\n",
            "Epoch [22/50] - Batch loss: 158.6891 - Epoch Loss: 40704.9325 - Avg Loss: 160.8891\n",
            "Epoch [22/50] - Batch loss: 161.3257 - Epoch Loss: 40866.2582 - Avg Loss: 160.8908\n",
            "Epoch [22/50] - Batch loss: 160.3674 - Epoch Loss: 41026.6256 - Avg Loss: 160.8887\n",
            "Epoch [22/50] - Batch loss: 159.8444 - Epoch Loss: 41186.4700 - Avg Loss: 160.8846\n",
            "Epoch [22/50] - Batch loss: 158.1065 - Epoch Loss: 41344.5765 - Avg Loss: 160.8738\n",
            "Epoch [22/50] - Batch loss: 166.0117 - Epoch Loss: 41510.5882 - Avg Loss: 160.8938\n",
            "Epoch [22/50] - Batch loss: 160.8929 - Epoch Loss: 41671.4811 - Avg Loss: 160.8937\n",
            "Epoch [22/50] - Batch loss: 159.4237 - Epoch Loss: 41830.9048 - Avg Loss: 160.8881\n",
            "Epoch [22/50] - Batch loss: 158.1577 - Epoch Loss: 41989.0625 - Avg Loss: 160.8776\n",
            "Epoch [22/50] - Batch loss: 162.2430 - Epoch Loss: 42151.3054 - Avg Loss: 160.8828\n",
            "Epoch [22/50] - Batch loss: 161.3037 - Epoch Loss: 42312.6091 - Avg Loss: 160.8844\n",
            "Epoch [22/50] - Batch loss: 162.7225 - Epoch Loss: 42475.3316 - Avg Loss: 160.8914\n",
            "Epoch [22/50] - Batch loss: 157.5376 - Epoch Loss: 42632.8692 - Avg Loss: 160.8788\n",
            "Epoch [22/50] - Batch loss: 165.2287 - Epoch Loss: 42798.0979 - Avg Loss: 160.8951\n",
            "Epoch [22/50] - Batch loss: 165.9352 - Epoch Loss: 42964.0331 - Avg Loss: 160.9140\n",
            "Epoch [22/50] - Batch loss: 149.7330 - Epoch Loss: 43113.7661 - Avg Loss: 160.8723\n",
            "Epoch [22/50] - Batch loss: 161.8026 - Epoch Loss: 43275.5687 - Avg Loss: 160.8757\n",
            "Epoch [22/50] - Batch loss: 154.0703 - Epoch Loss: 43429.6390 - Avg Loss: 160.8505\n",
            "Epoch [22/50] - Batch loss: 153.9410 - Epoch Loss: 43583.5800 - Avg Loss: 160.8250\n",
            "Epoch [22/50] - Batch loss: 155.5072 - Epoch Loss: 43739.0872 - Avg Loss: 160.8055\n",
            "Epoch [22/50] - Batch loss: 160.7309 - Epoch Loss: 43899.8181 - Avg Loss: 160.8052\n",
            "Epoch [22/50] - Batch loss: 168.2349 - Epoch Loss: 44068.0530 - Avg Loss: 160.8323\n",
            "Epoch [22/50] - Batch loss: 159.5637 - Epoch Loss: 44227.6168 - Avg Loss: 160.8277\n",
            "Epoch [22/50] - Batch loss: 161.9036 - Epoch Loss: 44389.5204 - Avg Loss: 160.8316\n",
            "Epoch [22/50] - Batch loss: 159.4091 - Epoch Loss: 44548.9295 - Avg Loss: 160.8265\n",
            "Epoch [22/50] - Batch loss: 163.8291 - Epoch Loss: 44712.7585 - Avg Loss: 160.8373\n",
            "Epoch [22/50] - Batch loss: 164.3063 - Epoch Loss: 44877.0648 - Avg Loss: 160.8497\n",
            "Epoch [22/50] - Batch loss: 154.5986 - Epoch Loss: 45031.6634 - Avg Loss: 160.8274\n",
            "Epoch [22/50] - Batch loss: 159.7943 - Epoch Loss: 45191.4576 - Avg Loss: 160.8237\n",
            "Epoch [22/50] - Batch loss: 156.4794 - Epoch Loss: 45347.9370 - Avg Loss: 160.8083\n",
            "Epoch [22/50] - Batch loss: 156.3974 - Epoch Loss: 45504.3344 - Avg Loss: 160.7927\n",
            "Epoch [22/50] - Batch loss: 165.0143 - Epoch Loss: 45669.3487 - Avg Loss: 160.8076\n",
            "Epoch [22/50] - Batch loss: 162.4734 - Epoch Loss: 45831.8221 - Avg Loss: 160.8134\n",
            "Epoch [22/50] - Batch loss: 161.0243 - Epoch Loss: 45992.8464 - Avg Loss: 160.8141\n",
            "Epoch [22/50] - Batch loss: 153.2107 - Epoch Loss: 46146.0571 - Avg Loss: 160.7877\n",
            "Epoch [22/50] - Batch loss: 165.8954 - Epoch Loss: 46311.9525 - Avg Loss: 160.8054\n",
            "Epoch [22/50] - Batch loss: 156.9737 - Epoch Loss: 46468.9262 - Avg Loss: 160.7921\n",
            "Epoch [22/50] - Batch loss: 155.3720 - Epoch Loss: 46624.2982 - Avg Loss: 160.7734\n",
            "Epoch [22/50] - Batch loss: 154.1233 - Epoch Loss: 46778.4215 - Avg Loss: 160.7506\n",
            "Epoch [22/50] - Batch loss: 160.9510 - Epoch Loss: 46939.3724 - Avg Loss: 160.7513\n",
            "Epoch [22/50] - Batch loss: 154.6550 - Epoch Loss: 47094.0275 - Avg Loss: 160.7305\n",
            "Epoch [22/50] - Batch loss: 162.1107 - Epoch Loss: 47256.1381 - Avg Loss: 160.7352\n",
            "Epoch [22/50] - Batch loss: 166.9693 - Epoch Loss: 47423.1075 - Avg Loss: 160.7563\n",
            "Epoch [22/50] - Batch loss: 164.9406 - Epoch Loss: 47588.0481 - Avg Loss: 160.7704\n",
            "Epoch [22/50] - Batch loss: 162.1058 - Epoch Loss: 47750.1539 - Avg Loss: 160.7749\n",
            "Epoch [22/50] - Batch loss: 157.1183 - Epoch Loss: 47907.2722 - Avg Loss: 160.7627\n",
            "Epoch [22/50] - Batch loss: 166.4382 - Epoch Loss: 48073.7105 - Avg Loss: 160.7816\n",
            "Epoch [22/50] - Batch loss: 159.3783 - Epoch Loss: 48233.0887 - Avg Loss: 160.7770\n",
            "Epoch [22/50] - Batch loss: 162.9235 - Epoch Loss: 48396.0122 - Avg Loss: 160.7841\n",
            "Epoch [22/50] - Batch loss: 160.8225 - Epoch Loss: 48556.8347 - Avg Loss: 160.7842\n",
            "Epoch [22/50] - Batch loss: 157.9002 - Epoch Loss: 48714.7349 - Avg Loss: 160.7747\n",
            "Epoch [22/50] - Batch loss: 152.8100 - Epoch Loss: 48867.5449 - Avg Loss: 160.7485\n",
            "Epoch [22/50] - Batch loss: 149.1530 - Epoch Loss: 49016.6979 - Avg Loss: 160.7105\n",
            "Epoch [22/50] - Batch loss: 160.6926 - Epoch Loss: 49177.3905 - Avg Loss: 160.7104\n",
            "Epoch [22/50] - Batch loss: 157.2404 - Epoch Loss: 49334.6309 - Avg Loss: 160.6991\n",
            "Epoch [22/50] - Batch loss: 155.1018 - Epoch Loss: 49489.7327 - Avg Loss: 160.6810\n",
            "Epoch [22/50] - Batch loss: 164.8041 - Epoch Loss: 49654.5368 - Avg Loss: 160.6943\n",
            "Epoch [22/50] - Batch loss: 163.2141 - Epoch Loss: 49817.7509 - Avg Loss: 160.7024\n",
            "Epoch [22/50] - Batch loss: 162.6722 - Epoch Loss: 49980.4231 - Avg Loss: 160.7088\n",
            "Epoch [22/50] - Batch loss: 162.4901 - Epoch Loss: 50142.9133 - Avg Loss: 160.7145\n",
            "Epoch [22/50] - Batch loss: 171.9428 - Epoch Loss: 50314.8560 - Avg Loss: 160.7503\n",
            "Epoch [22/50] - Batch loss: 161.8097 - Epoch Loss: 50476.6658 - Avg Loss: 160.7537\n",
            "Epoch [22/50] - Batch loss: 163.8224 - Epoch Loss: 50640.4882 - Avg Loss: 160.7635\n",
            "Epoch [22/50] - Batch loss: 163.8298 - Epoch Loss: 50804.3180 - Avg Loss: 160.7732\n",
            "Epoch [22/50] - Batch loss: 158.5993 - Epoch Loss: 50962.9173 - Avg Loss: 160.7663\n",
            "Epoch [22/50] - Batch loss: 162.7982 - Epoch Loss: 51125.7155 - Avg Loss: 160.7727\n",
            "Epoch [22/50] - Batch loss: 158.8563 - Epoch Loss: 51284.5717 - Avg Loss: 160.7667\n",
            "Epoch [22/50] - Batch loss: 154.9281 - Epoch Loss: 51439.4998 - Avg Loss: 160.7484\n",
            "Epoch [22/50] - Batch loss: 162.1547 - Epoch Loss: 51601.6545 - Avg Loss: 160.7528\n",
            "Epoch [22/50] - Batch loss: 159.7936 - Epoch Loss: 51761.4482 - Avg Loss: 160.7498\n",
            "Epoch [22/50] - Batch loss: 166.3060 - Epoch Loss: 51927.7542 - Avg Loss: 160.7670\n",
            "Epoch [22/50] - Batch loss: 153.8941 - Epoch Loss: 52081.6483 - Avg Loss: 160.7458\n",
            "Epoch [22/50] - Batch loss: 166.9061 - Epoch Loss: 52248.5544 - Avg Loss: 160.7648\n",
            "Epoch [22/50] - Batch loss: 159.4389 - Epoch Loss: 52407.9934 - Avg Loss: 160.7607\n",
            "Epoch [22/50] - Batch loss: 166.1572 - Epoch Loss: 52574.1506 - Avg Loss: 160.7772\n",
            "Epoch [22/50] - Batch loss: 155.9577 - Epoch Loss: 52730.1083 - Avg Loss: 160.7625\n",
            "Epoch [22/50] - Batch loss: 153.2585 - Epoch Loss: 52883.3668 - Avg Loss: 160.7397\n",
            "Epoch [22/50] - Batch loss: 155.9053 - Epoch Loss: 53039.2720 - Avg Loss: 160.7251\n",
            "Epoch [22/50] - Batch loss: 153.3815 - Epoch Loss: 53192.6535 - Avg Loss: 160.7029\n",
            "Epoch [22/50] - Batch loss: 151.7111 - Epoch Loss: 53344.3646 - Avg Loss: 160.6758\n",
            "Epoch [22/50] - Batch loss: 155.3168 - Epoch Loss: 53499.6814 - Avg Loss: 160.6597\n",
            "Epoch [22/50] - Batch loss: 159.1756 - Epoch Loss: 53658.8570 - Avg Loss: 160.6553\n",
            "Epoch [22/50] - Batch loss: 159.7347 - Epoch Loss: 53818.5917 - Avg Loss: 160.6525\n",
            "Epoch [22/50] - Batch loss: 150.9471 - Epoch Loss: 53969.5387 - Avg Loss: 160.6236\n",
            "Epoch [22/50] - Batch loss: 150.9152 - Epoch Loss: 54120.4540 - Avg Loss: 160.5948\n",
            "Epoch [22/50] - Batch loss: 167.9648 - Epoch Loss: 54288.4188 - Avg Loss: 160.6166\n",
            "Epoch [22/50] - Batch loss: 157.3493 - Epoch Loss: 54445.7681 - Avg Loss: 160.6070\n",
            "Epoch [22/50] - Batch loss: 155.5611 - Epoch Loss: 54601.3291 - Avg Loss: 160.5921\n",
            "Epoch [22/50] - Batch loss: 156.2487 - Epoch Loss: 54757.5778 - Avg Loss: 160.5794\n",
            "Epoch [22/50] - Batch loss: 164.9904 - Epoch Loss: 54922.5682 - Avg Loss: 160.5923\n",
            "Epoch [22/50] - Batch loss: 150.5029 - Epoch Loss: 55073.0711 - Avg Loss: 160.5629\n",
            "Epoch [22/50] - Batch loss: 162.8895 - Epoch Loss: 55235.9606 - Avg Loss: 160.5697\n",
            "Epoch [22/50] - Batch loss: 154.3612 - Epoch Loss: 55390.3218 - Avg Loss: 160.5517\n",
            "Epoch [22/50] - Batch loss: 159.0872 - Epoch Loss: 55549.4090 - Avg Loss: 160.5474\n",
            "Epoch [22/50] - Batch loss: 162.2777 - Epoch Loss: 55711.6867 - Avg Loss: 160.5524\n",
            "Epoch [22/50] - Batch loss: 156.8177 - Epoch Loss: 55868.5044 - Avg Loss: 160.5417\n",
            "Epoch [22/50] - Batch loss: 167.6224 - Epoch Loss: 56036.1268 - Avg Loss: 160.5620\n",
            "Epoch [22/50] - Batch loss: 159.3718 - Epoch Loss: 56195.4986 - Avg Loss: 160.5586\n",
            "Epoch [22/50] - Batch loss: 161.2346 - Epoch Loss: 56356.7331 - Avg Loss: 160.5605\n",
            "Epoch [22/50] - Batch loss: 152.7362 - Epoch Loss: 56509.4693 - Avg Loss: 160.5383\n",
            "Epoch [22/50] - Batch loss: 160.3745 - Epoch Loss: 56669.8438 - Avg Loss: 160.5378\n",
            "Epoch [22/50] - Batch loss: 155.9319 - Epoch Loss: 56825.7757 - Avg Loss: 160.5248\n",
            "Epoch [22/50] - Batch loss: 164.0915 - Epoch Loss: 56989.8671 - Avg Loss: 160.5348\n",
            "Epoch [22/50] - Batch loss: 165.1689 - Epoch Loss: 57155.0360 - Avg Loss: 160.5479\n",
            "Epoch [22/50] - Batch loss: 160.7001 - Epoch Loss: 57315.7361 - Avg Loss: 160.5483\n",
            "Epoch [22/50] - Batch loss: 160.9985 - Epoch Loss: 57476.7346 - Avg Loss: 160.5495\n",
            "Epoch [22/50] - Batch loss: 163.6254 - Epoch Loss: 57640.3600 - Avg Loss: 160.5581\n",
            "Epoch [22/50] - Batch loss: 160.1167 - Epoch Loss: 57800.4767 - Avg Loss: 160.5569\n",
            "Epoch [22/50] - Batch loss: 157.0049 - Epoch Loss: 57957.4816 - Avg Loss: 160.5470\n",
            "Epoch [22/50] - Batch loss: 166.4673 - Epoch Loss: 58123.9489 - Avg Loss: 160.5634\n",
            "Epoch [22/50] - Batch loss: 159.7760 - Epoch Loss: 58283.7249 - Avg Loss: 160.5612\n",
            "Epoch [22/50] - Batch loss: 163.8410 - Epoch Loss: 58447.5659 - Avg Loss: 160.5702\n",
            "Epoch [22/50] - Batch loss: 161.0707 - Epoch Loss: 58608.6366 - Avg Loss: 160.5716\n",
            "Epoch [22/50] - Batch loss: 165.2861 - Epoch Loss: 58773.9228 - Avg Loss: 160.5845\n",
            "Epoch [22/50] - Batch loss: 161.8484 - Epoch Loss: 58935.7712 - Avg Loss: 160.5879\n",
            "Epoch [22/50] - Batch loss: 156.6165 - Epoch Loss: 59092.3877 - Avg Loss: 160.5771\n",
            "Epoch [22/50] - Batch loss: 159.3849 - Epoch Loss: 59251.7727 - Avg Loss: 160.5739\n",
            "Epoch [22/50] - Batch loss: 162.2744 - Epoch Loss: 59414.0471 - Avg Loss: 160.5785\n",
            "Epoch [22/50] - Batch loss: 165.1994 - Epoch Loss: 59579.2465 - Avg Loss: 160.5910\n",
            "Epoch [22/50] - Batch loss: 164.4722 - Epoch Loss: 59743.7187 - Avg Loss: 160.6014\n",
            "Epoch [22/50] - Batch loss: 157.7128 - Epoch Loss: 59901.4315 - Avg Loss: 160.5937\n",
            "Epoch [22/50] - Batch loss: 163.8804 - Epoch Loss: 60065.3118 - Avg Loss: 160.6024\n",
            "Epoch [22/50] - Batch loss: 160.2118 - Epoch Loss: 60225.5236 - Avg Loss: 160.6014\n",
            "Epoch [22/50] - Batch loss: 165.8329 - Epoch Loss: 60391.3566 - Avg Loss: 160.6153\n",
            "Epoch [22/50] - Batch loss: 153.6425 - Epoch Loss: 60544.9990 - Avg Loss: 160.5968\n",
            "Epoch [22/50] - Batch loss: 156.5794 - Epoch Loss: 60701.5784 - Avg Loss: 160.5862\n",
            "Epoch [22/50] - Batch loss: 162.9630 - Epoch Loss: 60864.5414 - Avg Loss: 160.5925\n",
            "Epoch [22/50] - Batch loss: 157.1690 - Epoch Loss: 61021.7104 - Avg Loss: 160.5834\n",
            "Epoch [22/50] - Batch loss: 166.1688 - Epoch Loss: 61187.8792 - Avg Loss: 160.5981\n",
            "Epoch [22/50] - Batch loss: 151.5233 - Epoch Loss: 61339.4025 - Avg Loss: 160.5744\n",
            "Epoch [22/50] - Batch loss: 150.2274 - Epoch Loss: 61489.6299 - Avg Loss: 160.5473\n",
            "Epoch [22/50] - Batch loss: 161.5794 - Epoch Loss: 61651.2093 - Avg Loss: 160.5500\n",
            "Epoch [22/50] - Batch loss: 163.7523 - Epoch Loss: 61814.9616 - Avg Loss: 160.5583\n",
            "Epoch [22/50] - Batch loss: 166.6711 - Epoch Loss: 61981.6327 - Avg Loss: 160.5742\n",
            "Epoch [22/50] - Batch loss: 158.5539 - Epoch Loss: 62140.1866 - Avg Loss: 160.5690\n",
            "Epoch [22/50] - Batch loss: 163.1587 - Epoch Loss: 62303.3453 - Avg Loss: 160.5756\n",
            "Epoch [22/50] - Batch loss: 160.6264 - Epoch Loss: 62463.9718 - Avg Loss: 160.5758\n",
            "Epoch [22/50] - Batch loss: 157.6799 - Epoch Loss: 62621.6516 - Avg Loss: 160.5683\n",
            "Epoch [22/50] - Batch loss: 158.4377 - Epoch Loss: 62780.0894 - Avg Loss: 160.5629\n",
            "Epoch [22/50] - Batch loss: 161.3590 - Epoch Loss: 62941.4483 - Avg Loss: 160.5649\n",
            "Epoch [22/50] - Batch loss: 163.7953 - Epoch Loss: 63105.2437 - Avg Loss: 160.5731\n",
            "Epoch [22/50] - Batch loss: 166.2525 - Epoch Loss: 63271.4962 - Avg Loss: 160.5876\n",
            "Epoch [22/50] - Batch loss: 162.7923 - Epoch Loss: 63434.2885 - Avg Loss: 160.5931\n",
            "Epoch [22/50] - Batch loss: 159.8769 - Epoch Loss: 63594.1654 - Avg Loss: 160.5913\n",
            "Epoch [22/50] - Batch loss: 167.8502 - Epoch Loss: 63762.0156 - Avg Loss: 160.6096\n",
            "Epoch [22/50] - Batch loss: 159.6704 - Epoch Loss: 63921.6860 - Avg Loss: 160.6073\n",
            "Epoch [22/50] - Batch loss: 167.5876 - Epoch Loss: 64089.2736 - Avg Loss: 160.6247\n",
            "Epoch [22/50] - Batch loss: 162.6642 - Epoch Loss: 64251.9379 - Avg Loss: 160.6298\n",
            "Epoch [22/50] - Batch loss: 163.8660 - Epoch Loss: 64415.8038 - Avg Loss: 160.6379\n",
            "Epoch [22/50] - Batch loss: 156.9459 - Epoch Loss: 64572.7497 - Avg Loss: 160.6287\n",
            "Epoch [22/50] - Batch loss: 164.9147 - Epoch Loss: 64737.6645 - Avg Loss: 160.6394\n",
            "Epoch [22/50] - Batch loss: 162.5126 - Epoch Loss: 64900.1771 - Avg Loss: 160.6440\n",
            "Epoch [22/50] - Batch loss: 158.4966 - Epoch Loss: 65058.6737 - Avg Loss: 160.6387\n",
            "Epoch [22/50] - Batch loss: 165.0939 - Epoch Loss: 65223.7676 - Avg Loss: 160.6497\n",
            "Epoch [22/50] - Batch loss: 173.5244 - Epoch Loss: 65397.2920 - Avg Loss: 160.6813\n",
            "Epoch [22/50] - Batch loss: 170.3892 - Epoch Loss: 65567.6812 - Avg Loss: 160.7051\n",
            "Epoch [22/50] - Batch loss: 161.1067 - Epoch Loss: 65728.7879 - Avg Loss: 160.7061\n",
            "Epoch [22/50] - Batch loss: 158.8466 - Epoch Loss: 65887.6345 - Avg Loss: 160.7015\n",
            "Epoch [22/50] - Batch loss: 167.2407 - Epoch Loss: 66054.8752 - Avg Loss: 160.7175\n",
            "Epoch [22/50] - Batch loss: 158.5839 - Epoch Loss: 66213.4591 - Avg Loss: 160.7123\n",
            "Epoch [22/50] - Batch loss: 167.1989 - Epoch Loss: 66380.6580 - Avg Loss: 160.7280\n",
            "Epoch [22/50] - Batch loss: 165.9155 - Epoch Loss: 66546.5735 - Avg Loss: 160.7405\n",
            "Epoch [22/50] - Batch loss: 159.1950 - Epoch Loss: 66705.7685 - Avg Loss: 160.7368\n",
            "Epoch [22/50] - Batch loss: 166.3281 - Epoch Loss: 66872.0966 - Avg Loss: 160.7502\n",
            "Epoch [22/50] - Batch loss: 166.8593 - Epoch Loss: 67038.9560 - Avg Loss: 160.7649\n",
            "Epoch [22/50] - Batch loss: 168.6335 - Epoch Loss: 67207.5894 - Avg Loss: 160.7837\n",
            "Epoch [22/50] - Batch loss: 165.3370 - Epoch Loss: 67372.9264 - Avg Loss: 160.7946\n",
            "Epoch [22/50] - Batch loss: 164.2822 - Epoch Loss: 67537.2086 - Avg Loss: 160.8029\n",
            "Epoch [22/50] - Batch loss: 160.7406 - Epoch Loss: 67697.9492 - Avg Loss: 160.8027\n",
            "Epoch [22/50] - Batch loss: 158.6291 - Epoch Loss: 67856.5783 - Avg Loss: 160.7976\n",
            "Epoch [22/50] - Batch loss: 156.9505 - Epoch Loss: 68013.5289 - Avg Loss: 160.7885\n",
            "Epoch [22/50] - Batch loss: 164.3299 - Epoch Loss: 68177.8588 - Avg Loss: 160.7968\n",
            "Epoch [22/50] - Batch loss: 169.1579 - Epoch Loss: 68347.0166 - Avg Loss: 160.8165\n",
            "Epoch [22/50] - Batch loss: 163.6413 - Epoch Loss: 68510.6579 - Avg Loss: 160.8231\n",
            "Epoch [22/50] - Batch loss: 159.6054 - Epoch Loss: 68670.2633 - Avg Loss: 160.8203\n",
            "Epoch [22/50] - Batch loss: 163.1571 - Epoch Loss: 68833.4204 - Avg Loss: 160.8257\n",
            "Epoch [22/50] - Batch loss: 166.2425 - Epoch Loss: 68999.6629 - Avg Loss: 160.8384\n",
            "Epoch [22/50] - Batch loss: 174.2209 - Epoch Loss: 69173.8837 - Avg Loss: 160.8695\n",
            "Epoch [22/50] - Batch loss: 157.6929 - Epoch Loss: 69331.5766 - Avg Loss: 160.8621\n",
            "Epoch [22/50] - Batch loss: 167.7561 - Epoch Loss: 69499.3327 - Avg Loss: 160.8781\n",
            "Epoch [22/50] - Batch loss: 168.9243 - Epoch Loss: 69668.2570 - Avg Loss: 160.8967\n",
            "Epoch [22/50] - Batch loss: 166.6465 - Epoch Loss: 69834.9035 - Avg Loss: 160.9099\n",
            "Epoch [22/50] - Batch loss: 169.3352 - Epoch Loss: 70004.2387 - Avg Loss: 160.9293\n",
            "Epoch [22/50] - Batch loss: 156.1026 - Epoch Loss: 70160.3414 - Avg Loss: 160.9182\n",
            "Epoch [22/50] - Batch loss: 159.9948 - Epoch Loss: 70320.3362 - Avg Loss: 160.9161\n",
            "Epoch [22/50] - Batch loss: 175.3699 - Epoch Loss: 70495.7060 - Avg Loss: 160.9491\n",
            "Epoch [22/50] - Batch loss: 155.2311 - Epoch Loss: 70650.9372 - Avg Loss: 160.9361\n",
            "Epoch [22/50] - Batch loss: 167.0216 - Epoch Loss: 70817.9587 - Avg Loss: 160.9499\n",
            "Epoch [22/50] - Batch loss: 158.6958 - Epoch Loss: 70976.6546 - Avg Loss: 160.9448\n",
            "Epoch [22/50] - Batch loss: 166.5072 - Epoch Loss: 71143.1618 - Avg Loss: 160.9574\n",
            "Epoch [22/50] - Batch loss: 172.5087 - Epoch Loss: 71315.6705 - Avg Loss: 160.9835\n",
            "Epoch [22/50] - Batch loss: 165.5795 - Epoch Loss: 71481.2500 - Avg Loss: 160.9938\n",
            "Epoch [22/50] - Batch loss: 164.3211 - Epoch Loss: 71645.5711 - Avg Loss: 161.0013\n",
            "Epoch [22/50] - Batch loss: 155.7056 - Epoch Loss: 71801.2767 - Avg Loss: 160.9894\n",
            "Epoch [22/50] - Batch loss: 161.8829 - Epoch Loss: 71963.1596 - Avg Loss: 160.9914\n",
            "Epoch [22/50] - Batch loss: 159.6847 - Epoch Loss: 72122.8443 - Avg Loss: 160.9885\n",
            "Epoch [22/50] - Batch loss: 168.7657 - Epoch Loss: 72291.6099 - Avg Loss: 161.0058\n",
            "Epoch [22/50] - Batch loss: 164.7904 - Epoch Loss: 72456.4003 - Avg Loss: 161.0142\n",
            "Epoch [22/50] - Batch loss: 169.1291 - Epoch Loss: 72625.5294 - Avg Loss: 161.0322\n",
            "Epoch [22/50] - Batch loss: 165.1525 - Epoch Loss: 72790.6819 - Avg Loss: 161.0413\n",
            "Epoch [22/50] - Batch loss: 162.7312 - Epoch Loss: 72953.4131 - Avg Loss: 161.0451\n",
            "Epoch [22/50] - Batch loss: 164.3932 - Epoch Loss: 73117.8064 - Avg Loss: 161.0524\n",
            "Epoch [22/50] - Batch loss: 157.1096 - Epoch Loss: 73274.9160 - Avg Loss: 161.0438\n",
            "Epoch [22/50] - Batch loss: 172.3799 - Epoch Loss: 73447.2958 - Avg Loss: 161.0686\n",
            "Epoch [22/50] - Batch loss: 165.3442 - Epoch Loss: 73612.6400 - Avg Loss: 161.0780\n",
            "Epoch [22/50] - Batch loss: 162.5933 - Epoch Loss: 73775.2334 - Avg Loss: 161.0813\n",
            "Epoch [22/50] - Batch loss: 164.7527 - Epoch Loss: 73939.9860 - Avg Loss: 161.0893\n",
            "Epoch [22/50] - Batch loss: 156.7506 - Epoch Loss: 74096.7366 - Avg Loss: 161.0799\n",
            "Epoch [22/50] - Batch loss: 159.7104 - Epoch Loss: 74256.4470 - Avg Loss: 161.0769\n",
            "Epoch [22/50] - Batch loss: 164.8749 - Epoch Loss: 74421.3219 - Avg Loss: 161.0851\n",
            "Epoch [22/50] - Batch loss: 169.9660 - Epoch Loss: 74591.2878 - Avg Loss: 161.1043\n",
            "Epoch [22/50] - Batch loss: 160.4197 - Epoch Loss: 74751.7076 - Avg Loss: 161.1028\n",
            "Epoch [22/50] - Batch loss: 160.6141 - Epoch Loss: 74912.3217 - Avg Loss: 161.1018\n",
            "Epoch [22/50] - Batch loss: 162.3250 - Epoch Loss: 75074.6467 - Avg Loss: 161.1044\n",
            "Epoch [22/50] - Batch loss: 163.6039 - Epoch Loss: 75238.2506 - Avg Loss: 161.1097\n",
            "Epoch [22/50] - Batch loss: 157.0017 - Epoch Loss: 75395.2523 - Avg Loss: 161.1010\n",
            "Epoch [22/50] - Batch loss: 153.0026 - Epoch Loss: 75548.2548 - Avg Loss: 161.0837\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 23/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "095da23dda0141e3a64271455c55d866"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/50] - Batch loss: 166.5769 - Epoch Loss: 166.5769 - Avg Loss: 166.5769\n",
            "Epoch [23/50] - Batch loss: 160.8557 - Epoch Loss: 327.4326 - Avg Loss: 163.7163\n",
            "Epoch [23/50] - Batch loss: 165.6903 - Epoch Loss: 493.1229 - Avg Loss: 164.3743\n",
            "Epoch [23/50] - Batch loss: 152.8587 - Epoch Loss: 645.9816 - Avg Loss: 161.4954\n",
            "Epoch [23/50] - Batch loss: 158.3891 - Epoch Loss: 804.3707 - Avg Loss: 160.8741\n",
            "Epoch [23/50] - Batch loss: 162.7432 - Epoch Loss: 967.1138 - Avg Loss: 161.1856\n",
            "Epoch [23/50] - Batch loss: 166.6704 - Epoch Loss: 1133.7843 - Avg Loss: 161.9692\n",
            "Epoch [23/50] - Batch loss: 165.1281 - Epoch Loss: 1298.9124 - Avg Loss: 162.3640\n",
            "Epoch [23/50] - Batch loss: 152.7750 - Epoch Loss: 1451.6874 - Avg Loss: 161.2986\n",
            "Epoch [23/50] - Batch loss: 161.4789 - Epoch Loss: 1613.1663 - Avg Loss: 161.3166\n",
            "Epoch [23/50] - Batch loss: 161.9662 - Epoch Loss: 1775.1326 - Avg Loss: 161.3757\n",
            "Epoch [23/50] - Batch loss: 165.6331 - Epoch Loss: 1940.7657 - Avg Loss: 161.7305\n",
            "Epoch [23/50] - Batch loss: 163.1214 - Epoch Loss: 2103.8871 - Avg Loss: 161.8375\n",
            "Epoch [23/50] - Batch loss: 158.5641 - Epoch Loss: 2262.4512 - Avg Loss: 161.6037\n",
            "Epoch [23/50] - Batch loss: 155.9611 - Epoch Loss: 2418.4123 - Avg Loss: 161.2275\n",
            "Epoch [23/50] - Batch loss: 164.1744 - Epoch Loss: 2582.5867 - Avg Loss: 161.4117\n",
            "Epoch [23/50] - Batch loss: 175.7833 - Epoch Loss: 2758.3699 - Avg Loss: 162.2571\n",
            "Epoch [23/50] - Batch loss: 156.7662 - Epoch Loss: 2915.1361 - Avg Loss: 161.9520\n",
            "Epoch [23/50] - Batch loss: 162.1820 - Epoch Loss: 3077.3181 - Avg Loss: 161.9641\n",
            "Epoch [23/50] - Batch loss: 170.7122 - Epoch Loss: 3248.0304 - Avg Loss: 162.4015\n",
            "Epoch [23/50] - Batch loss: 164.2908 - Epoch Loss: 3412.3212 - Avg Loss: 162.4915\n",
            "Epoch [23/50] - Batch loss: 163.7166 - Epoch Loss: 3576.0378 - Avg Loss: 162.5472\n",
            "Epoch [23/50] - Batch loss: 154.4796 - Epoch Loss: 3730.5173 - Avg Loss: 162.1964\n",
            "Epoch [23/50] - Batch loss: 160.6887 - Epoch Loss: 3891.2060 - Avg Loss: 162.1336\n",
            "Epoch [23/50] - Batch loss: 169.4655 - Epoch Loss: 4060.6716 - Avg Loss: 162.4269\n",
            "Epoch [23/50] - Batch loss: 159.2633 - Epoch Loss: 4219.9348 - Avg Loss: 162.3052\n",
            "Epoch [23/50] - Batch loss: 153.9875 - Epoch Loss: 4373.9223 - Avg Loss: 161.9971\n",
            "Epoch [23/50] - Batch loss: 154.1080 - Epoch Loss: 4528.0303 - Avg Loss: 161.7154\n",
            "Epoch [23/50] - Batch loss: 163.5365 - Epoch Loss: 4691.5668 - Avg Loss: 161.7782\n",
            "Epoch [23/50] - Batch loss: 162.7927 - Epoch Loss: 4854.3595 - Avg Loss: 161.8120\n",
            "Epoch [23/50] - Batch loss: 155.8489 - Epoch Loss: 5010.2084 - Avg Loss: 161.6196\n",
            "Epoch [23/50] - Batch loss: 163.1802 - Epoch Loss: 5173.3886 - Avg Loss: 161.6684\n",
            "Epoch [23/50] - Batch loss: 167.6103 - Epoch Loss: 5340.9989 - Avg Loss: 161.8485\n",
            "Epoch [23/50] - Batch loss: 157.8452 - Epoch Loss: 5498.8441 - Avg Loss: 161.7307\n",
            "Epoch [23/50] - Batch loss: 162.6741 - Epoch Loss: 5661.5182 - Avg Loss: 161.7577\n",
            "Epoch [23/50] - Batch loss: 159.5440 - Epoch Loss: 5821.0623 - Avg Loss: 161.6962\n",
            "Epoch [23/50] - Batch loss: 164.7115 - Epoch Loss: 5985.7738 - Avg Loss: 161.7777\n",
            "Epoch [23/50] - Batch loss: 163.2240 - Epoch Loss: 6148.9978 - Avg Loss: 161.8157\n",
            "Epoch [23/50] - Batch loss: 155.5457 - Epoch Loss: 6304.5435 - Avg Loss: 161.6550\n",
            "Epoch [23/50] - Batch loss: 154.7800 - Epoch Loss: 6459.3235 - Avg Loss: 161.4831\n",
            "Epoch [23/50] - Batch loss: 161.4458 - Epoch Loss: 6620.7693 - Avg Loss: 161.4822\n",
            "Epoch [23/50] - Batch loss: 156.6107 - Epoch Loss: 6777.3800 - Avg Loss: 161.3662\n",
            "Epoch [23/50] - Batch loss: 165.0448 - Epoch Loss: 6942.4248 - Avg Loss: 161.4517\n",
            "Epoch [23/50] - Batch loss: 157.8152 - Epoch Loss: 7100.2400 - Avg Loss: 161.3691\n",
            "Epoch [23/50] - Batch loss: 150.9169 - Epoch Loss: 7251.1570 - Avg Loss: 161.1368\n",
            "Epoch [23/50] - Batch loss: 163.0776 - Epoch Loss: 7414.2346 - Avg Loss: 161.1790\n",
            "Epoch [23/50] - Batch loss: 171.9298 - Epoch Loss: 7586.1643 - Avg Loss: 161.4078\n",
            "Epoch [23/50] - Batch loss: 151.3188 - Epoch Loss: 7737.4832 - Avg Loss: 161.1976\n",
            "Epoch [23/50] - Batch loss: 162.1677 - Epoch Loss: 7899.6509 - Avg Loss: 161.2174\n",
            "Epoch [23/50] - Batch loss: 167.5150 - Epoch Loss: 8067.1659 - Avg Loss: 161.3433\n",
            "Epoch [23/50] - Batch loss: 166.4883 - Epoch Loss: 8233.6542 - Avg Loss: 161.4442\n",
            "Epoch [23/50] - Batch loss: 169.8288 - Epoch Loss: 8403.4830 - Avg Loss: 161.6054\n",
            "Epoch [23/50] - Batch loss: 163.3093 - Epoch Loss: 8566.7923 - Avg Loss: 161.6376\n",
            "Epoch [23/50] - Batch loss: 160.1674 - Epoch Loss: 8726.9597 - Avg Loss: 161.6104\n",
            "Epoch [23/50] - Batch loss: 167.5196 - Epoch Loss: 8894.4793 - Avg Loss: 161.7178\n",
            "Epoch [23/50] - Batch loss: 162.9608 - Epoch Loss: 9057.4401 - Avg Loss: 161.7400\n",
            "Epoch [23/50] - Batch loss: 160.3073 - Epoch Loss: 9217.7474 - Avg Loss: 161.7149\n",
            "Epoch [23/50] - Batch loss: 159.5017 - Epoch Loss: 9377.2491 - Avg Loss: 161.6767\n",
            "Epoch [23/50] - Batch loss: 161.6748 - Epoch Loss: 9538.9239 - Avg Loss: 161.6767\n",
            "Epoch [23/50] - Batch loss: 163.2781 - Epoch Loss: 9702.2020 - Avg Loss: 161.7034\n",
            "Epoch [23/50] - Batch loss: 161.8279 - Epoch Loss: 9864.0299 - Avg Loss: 161.7054\n",
            "Epoch [23/50] - Batch loss: 159.5144 - Epoch Loss: 10023.5443 - Avg Loss: 161.6701\n",
            "Epoch [23/50] - Batch loss: 164.3500 - Epoch Loss: 10187.8944 - Avg Loss: 161.7126\n",
            "Epoch [23/50] - Batch loss: 170.8135 - Epoch Loss: 10358.7078 - Avg Loss: 161.8548\n",
            "Epoch [23/50] - Batch loss: 157.5407 - Epoch Loss: 10516.2485 - Avg Loss: 161.7884\n",
            "Epoch [23/50] - Batch loss: 164.1817 - Epoch Loss: 10680.4302 - Avg Loss: 161.8247\n",
            "Epoch [23/50] - Batch loss: 167.4589 - Epoch Loss: 10847.8891 - Avg Loss: 161.9088\n",
            "Epoch [23/50] - Batch loss: 163.3680 - Epoch Loss: 11011.2570 - Avg Loss: 161.9303\n",
            "Epoch [23/50] - Batch loss: 169.8769 - Epoch Loss: 11181.1340 - Avg Loss: 162.0454\n",
            "Epoch [23/50] - Batch loss: 167.3390 - Epoch Loss: 11348.4730 - Avg Loss: 162.1210\n",
            "Epoch [23/50] - Batch loss: 164.7416 - Epoch Loss: 11513.2145 - Avg Loss: 162.1580\n",
            "Epoch [23/50] - Batch loss: 154.4089 - Epoch Loss: 11667.6234 - Avg Loss: 162.0503\n",
            "Epoch [23/50] - Batch loss: 157.5723 - Epoch Loss: 11825.1957 - Avg Loss: 161.9890\n",
            "Epoch [23/50] - Batch loss: 155.1448 - Epoch Loss: 11980.3405 - Avg Loss: 161.8965\n",
            "Epoch [23/50] - Batch loss: 165.0685 - Epoch Loss: 12145.4090 - Avg Loss: 161.9388\n",
            "Epoch [23/50] - Batch loss: 157.4149 - Epoch Loss: 12302.8239 - Avg Loss: 161.8793\n",
            "Epoch [23/50] - Batch loss: 162.5358 - Epoch Loss: 12465.3597 - Avg Loss: 161.8878\n",
            "Epoch [23/50] - Batch loss: 171.5055 - Epoch Loss: 12636.8652 - Avg Loss: 162.0111\n",
            "Epoch [23/50] - Batch loss: 164.2772 - Epoch Loss: 12801.1424 - Avg Loss: 162.0398\n",
            "Epoch [23/50] - Batch loss: 155.3495 - Epoch Loss: 12956.4919 - Avg Loss: 161.9561\n",
            "Epoch [23/50] - Batch loss: 163.8921 - Epoch Loss: 13120.3840 - Avg Loss: 161.9800\n",
            "Epoch [23/50] - Batch loss: 157.7139 - Epoch Loss: 13278.0978 - Avg Loss: 161.9280\n",
            "Epoch [23/50] - Batch loss: 158.8271 - Epoch Loss: 13436.9249 - Avg Loss: 161.8907\n",
            "Epoch [23/50] - Batch loss: 157.3039 - Epoch Loss: 13594.2288 - Avg Loss: 161.8361\n",
            "Epoch [23/50] - Batch loss: 162.4595 - Epoch Loss: 13756.6883 - Avg Loss: 161.8434\n",
            "Epoch [23/50] - Batch loss: 167.0724 - Epoch Loss: 13923.7607 - Avg Loss: 161.9042\n",
            "Epoch [23/50] - Batch loss: 163.3399 - Epoch Loss: 14087.1006 - Avg Loss: 161.9207\n",
            "Epoch [23/50] - Batch loss: 162.3304 - Epoch Loss: 14249.4310 - Avg Loss: 161.9254\n",
            "Epoch [23/50] - Batch loss: 169.7029 - Epoch Loss: 14419.1339 - Avg Loss: 162.0127\n",
            "Epoch [23/50] - Batch loss: 167.9483 - Epoch Loss: 14587.0822 - Avg Loss: 162.0787\n",
            "Epoch [23/50] - Batch loss: 164.7339 - Epoch Loss: 14751.8161 - Avg Loss: 162.1079\n",
            "Epoch [23/50] - Batch loss: 165.5406 - Epoch Loss: 14917.3567 - Avg Loss: 162.1452\n",
            "Epoch [23/50] - Batch loss: 160.3576 - Epoch Loss: 15077.7143 - Avg Loss: 162.1260\n",
            "Epoch [23/50] - Batch loss: 165.3908 - Epoch Loss: 15243.1051 - Avg Loss: 162.1607\n",
            "Epoch [23/50] - Batch loss: 159.5490 - Epoch Loss: 15402.6542 - Avg Loss: 162.1332\n",
            "Epoch [23/50] - Batch loss: 159.7187 - Epoch Loss: 15562.3728 - Avg Loss: 162.1081\n",
            "Epoch [23/50] - Batch loss: 162.8797 - Epoch Loss: 15725.2525 - Avg Loss: 162.1160\n",
            "Epoch [23/50] - Batch loss: 168.7293 - Epoch Loss: 15893.9818 - Avg Loss: 162.1835\n",
            "Epoch [23/50] - Batch loss: 159.5626 - Epoch Loss: 16053.5444 - Avg Loss: 162.1570\n",
            "Epoch [23/50] - Batch loss: 165.6383 - Epoch Loss: 16219.1827 - Avg Loss: 162.1918\n",
            "Epoch [23/50] - Batch loss: 165.1274 - Epoch Loss: 16384.3102 - Avg Loss: 162.2209\n",
            "Epoch [23/50] - Batch loss: 160.5592 - Epoch Loss: 16544.8693 - Avg Loss: 162.2046\n",
            "Epoch [23/50] - Batch loss: 161.2269 - Epoch Loss: 16706.0963 - Avg Loss: 162.1951\n",
            "Epoch [23/50] - Batch loss: 161.5775 - Epoch Loss: 16867.6737 - Avg Loss: 162.1892\n",
            "Epoch [23/50] - Batch loss: 157.8545 - Epoch Loss: 17025.5282 - Avg Loss: 162.1479\n",
            "Epoch [23/50] - Batch loss: 166.1512 - Epoch Loss: 17191.6794 - Avg Loss: 162.1857\n",
            "Epoch [23/50] - Batch loss: 162.8468 - Epoch Loss: 17354.5262 - Avg Loss: 162.1918\n",
            "Epoch [23/50] - Batch loss: 166.0248 - Epoch Loss: 17520.5510 - Avg Loss: 162.2273\n",
            "Epoch [23/50] - Batch loss: 161.2855 - Epoch Loss: 17681.8365 - Avg Loss: 162.2187\n",
            "Epoch [23/50] - Batch loss: 165.4494 - Epoch Loss: 17847.2859 - Avg Loss: 162.2481\n",
            "Epoch [23/50] - Batch loss: 167.3152 - Epoch Loss: 18014.6012 - Avg Loss: 162.2937\n",
            "Epoch [23/50] - Batch loss: 167.2923 - Epoch Loss: 18181.8934 - Avg Loss: 162.3383\n",
            "Epoch [23/50] - Batch loss: 161.0593 - Epoch Loss: 18342.9528 - Avg Loss: 162.3270\n",
            "Epoch [23/50] - Batch loss: 161.6288 - Epoch Loss: 18504.5816 - Avg Loss: 162.3209\n",
            "Epoch [23/50] - Batch loss: 155.3977 - Epoch Loss: 18659.9793 - Avg Loss: 162.2607\n",
            "Epoch [23/50] - Batch loss: 160.4589 - Epoch Loss: 18820.4382 - Avg Loss: 162.2452\n",
            "Epoch [23/50] - Batch loss: 167.0688 - Epoch Loss: 18987.5069 - Avg Loss: 162.2864\n",
            "Epoch [23/50] - Batch loss: 156.7775 - Epoch Loss: 19144.2845 - Avg Loss: 162.2397\n",
            "Epoch [23/50] - Batch loss: 156.6893 - Epoch Loss: 19300.9738 - Avg Loss: 162.1931\n",
            "Epoch [23/50] - Batch loss: 160.1587 - Epoch Loss: 19461.1325 - Avg Loss: 162.1761\n",
            "Epoch [23/50] - Batch loss: 161.8760 - Epoch Loss: 19623.0085 - Avg Loss: 162.1736\n",
            "Epoch [23/50] - Batch loss: 167.9728 - Epoch Loss: 19790.9813 - Avg Loss: 162.2212\n",
            "Epoch [23/50] - Batch loss: 161.1938 - Epoch Loss: 19952.1750 - Avg Loss: 162.2128\n",
            "Epoch [23/50] - Batch loss: 160.1808 - Epoch Loss: 20112.3559 - Avg Loss: 162.1964\n",
            "Epoch [23/50] - Batch loss: 164.9119 - Epoch Loss: 20277.2678 - Avg Loss: 162.2181\n",
            "Epoch [23/50] - Batch loss: 158.9963 - Epoch Loss: 20436.2641 - Avg Loss: 162.1926\n",
            "Epoch [23/50] - Batch loss: 159.1451 - Epoch Loss: 20595.4091 - Avg Loss: 162.1686\n",
            "Epoch [23/50] - Batch loss: 152.7459 - Epoch Loss: 20748.1551 - Avg Loss: 162.0950\n",
            "Epoch [23/50] - Batch loss: 163.5350 - Epoch Loss: 20911.6901 - Avg Loss: 162.1061\n",
            "Epoch [23/50] - Batch loss: 154.4869 - Epoch Loss: 21066.1770 - Avg Loss: 162.0475\n",
            "Epoch [23/50] - Batch loss: 163.7679 - Epoch Loss: 21229.9450 - Avg Loss: 162.0606\n",
            "Epoch [23/50] - Batch loss: 163.0134 - Epoch Loss: 21392.9583 - Avg Loss: 162.0679\n",
            "Epoch [23/50] - Batch loss: 155.4963 - Epoch Loss: 21548.4547 - Avg Loss: 162.0185\n",
            "Epoch [23/50] - Batch loss: 162.0892 - Epoch Loss: 21710.5439 - Avg Loss: 162.0190\n",
            "Epoch [23/50] - Batch loss: 162.1986 - Epoch Loss: 21872.7424 - Avg Loss: 162.0203\n",
            "Epoch [23/50] - Batch loss: 159.9893 - Epoch Loss: 22032.7318 - Avg Loss: 162.0054\n",
            "Epoch [23/50] - Batch loss: 167.0052 - Epoch Loss: 22199.7370 - Avg Loss: 162.0419\n",
            "Epoch [23/50] - Batch loss: 167.9964 - Epoch Loss: 22367.7334 - Avg Loss: 162.0850\n",
            "Epoch [23/50] - Batch loss: 154.1768 - Epoch Loss: 22521.9102 - Avg Loss: 162.0281\n",
            "Epoch [23/50] - Batch loss: 160.4093 - Epoch Loss: 22682.3194 - Avg Loss: 162.0166\n",
            "Epoch [23/50] - Batch loss: 160.7858 - Epoch Loss: 22843.1052 - Avg Loss: 162.0078\n",
            "Epoch [23/50] - Batch loss: 163.8349 - Epoch Loss: 23006.9401 - Avg Loss: 162.0207\n",
            "Epoch [23/50] - Batch loss: 161.9884 - Epoch Loss: 23168.9286 - Avg Loss: 162.0205\n",
            "Epoch [23/50] - Batch loss: 169.8385 - Epoch Loss: 23338.7671 - Avg Loss: 162.0748\n",
            "Epoch [23/50] - Batch loss: 169.3728 - Epoch Loss: 23508.1399 - Avg Loss: 162.1251\n",
            "Epoch [23/50] - Batch loss: 162.1420 - Epoch Loss: 23670.2818 - Avg Loss: 162.1252\n",
            "Epoch [23/50] - Batch loss: 170.4090 - Epoch Loss: 23840.6908 - Avg Loss: 162.1816\n",
            "Epoch [23/50] - Batch loss: 155.2945 - Epoch Loss: 23995.9853 - Avg Loss: 162.1350\n",
            "Epoch [23/50] - Batch loss: 156.4745 - Epoch Loss: 24152.4598 - Avg Loss: 162.0970\n",
            "Epoch [23/50] - Batch loss: 170.3342 - Epoch Loss: 24322.7940 - Avg Loss: 162.1520\n",
            "Epoch [23/50] - Batch loss: 172.0305 - Epoch Loss: 24494.8246 - Avg Loss: 162.2174\n",
            "Epoch [23/50] - Batch loss: 154.0668 - Epoch Loss: 24648.8914 - Avg Loss: 162.1638\n",
            "Epoch [23/50] - Batch loss: 161.3223 - Epoch Loss: 24810.2138 - Avg Loss: 162.1583\n",
            "Epoch [23/50] - Batch loss: 161.1768 - Epoch Loss: 24971.3905 - Avg Loss: 162.1519\n",
            "Epoch [23/50] - Batch loss: 153.9500 - Epoch Loss: 25125.3405 - Avg Loss: 162.0990\n",
            "Epoch [23/50] - Batch loss: 162.5882 - Epoch Loss: 25287.9287 - Avg Loss: 162.1021\n",
            "Epoch [23/50] - Batch loss: 159.5574 - Epoch Loss: 25447.4861 - Avg Loss: 162.0859\n",
            "Epoch [23/50] - Batch loss: 168.1467 - Epoch Loss: 25615.6328 - Avg Loss: 162.1243\n",
            "Epoch [23/50] - Batch loss: 161.4855 - Epoch Loss: 25777.1183 - Avg Loss: 162.1202\n",
            "Epoch [23/50] - Batch loss: 160.7327 - Epoch Loss: 25937.8510 - Avg Loss: 162.1116\n",
            "Epoch [23/50] - Batch loss: 167.9863 - Epoch Loss: 26105.8374 - Avg Loss: 162.1481\n",
            "Epoch [23/50] - Batch loss: 156.7393 - Epoch Loss: 26262.5766 - Avg Loss: 162.1147\n",
            "Epoch [23/50] - Batch loss: 152.1653 - Epoch Loss: 26414.7419 - Avg Loss: 162.0536\n",
            "Epoch [23/50] - Batch loss: 163.4361 - Epoch Loss: 26578.1780 - Avg Loss: 162.0621\n",
            "Epoch [23/50] - Batch loss: 161.6979 - Epoch Loss: 26739.8759 - Avg Loss: 162.0599\n",
            "Epoch [23/50] - Batch loss: 160.3384 - Epoch Loss: 26900.2143 - Avg Loss: 162.0495\n",
            "Epoch [23/50] - Batch loss: 162.3851 - Epoch Loss: 27062.5993 - Avg Loss: 162.0515\n",
            "Epoch [23/50] - Batch loss: 159.9263 - Epoch Loss: 27222.5256 - Avg Loss: 162.0388\n",
            "Epoch [23/50] - Batch loss: 162.4334 - Epoch Loss: 27384.9591 - Avg Loss: 162.0412\n",
            "Epoch [23/50] - Batch loss: 161.6974 - Epoch Loss: 27546.6564 - Avg Loss: 162.0392\n",
            "Epoch [23/50] - Batch loss: 158.5777 - Epoch Loss: 27705.2341 - Avg Loss: 162.0189\n",
            "Epoch [23/50] - Batch loss: 163.5315 - Epoch Loss: 27868.7656 - Avg Loss: 162.0277\n",
            "Epoch [23/50] - Batch loss: 169.0694 - Epoch Loss: 28037.8349 - Avg Loss: 162.0684\n",
            "Epoch [23/50] - Batch loss: 161.8210 - Epoch Loss: 28199.6559 - Avg Loss: 162.0670\n",
            "Epoch [23/50] - Batch loss: 158.2937 - Epoch Loss: 28357.9496 - Avg Loss: 162.0454\n",
            "Epoch [23/50] - Batch loss: 155.6856 - Epoch Loss: 28513.6353 - Avg Loss: 162.0093\n",
            "Epoch [23/50] - Batch loss: 160.9880 - Epoch Loss: 28674.6232 - Avg Loss: 162.0035\n",
            "Epoch [23/50] - Batch loss: 159.2492 - Epoch Loss: 28833.8725 - Avg Loss: 161.9880\n",
            "Epoch [23/50] - Batch loss: 159.3352 - Epoch Loss: 28993.2076 - Avg Loss: 161.9732\n",
            "Epoch [23/50] - Batch loss: 158.3328 - Epoch Loss: 29151.5404 - Avg Loss: 161.9530\n",
            "Epoch [23/50] - Batch loss: 163.8708 - Epoch Loss: 29315.4112 - Avg Loss: 161.9636\n",
            "Epoch [23/50] - Batch loss: 170.3024 - Epoch Loss: 29485.7136 - Avg Loss: 162.0094\n",
            "Epoch [23/50] - Batch loss: 166.8991 - Epoch Loss: 29652.6127 - Avg Loss: 162.0361\n",
            "Epoch [23/50] - Batch loss: 170.0263 - Epoch Loss: 29822.6389 - Avg Loss: 162.0796\n",
            "Epoch [23/50] - Batch loss: 158.0618 - Epoch Loss: 29980.7008 - Avg Loss: 162.0578\n",
            "Epoch [23/50] - Batch loss: 165.9482 - Epoch Loss: 30146.6489 - Avg Loss: 162.0788\n",
            "Epoch [23/50] - Batch loss: 157.3451 - Epoch Loss: 30303.9940 - Avg Loss: 162.0534\n",
            "Epoch [23/50] - Batch loss: 165.4885 - Epoch Loss: 30469.4825 - Avg Loss: 162.0717\n",
            "Epoch [23/50] - Batch loss: 167.7093 - Epoch Loss: 30637.1919 - Avg Loss: 162.1015\n",
            "Epoch [23/50] - Batch loss: 155.5790 - Epoch Loss: 30792.7709 - Avg Loss: 162.0672\n",
            "Epoch [23/50] - Batch loss: 159.1688 - Epoch Loss: 30951.9397 - Avg Loss: 162.0520\n",
            "Epoch [23/50] - Batch loss: 160.0475 - Epoch Loss: 31111.9872 - Avg Loss: 162.0416\n",
            "Epoch [23/50] - Batch loss: 166.6830 - Epoch Loss: 31278.6702 - Avg Loss: 162.0656\n",
            "Epoch [23/50] - Batch loss: 166.7978 - Epoch Loss: 31445.4680 - Avg Loss: 162.0900\n",
            "Epoch [23/50] - Batch loss: 161.5424 - Epoch Loss: 31607.0104 - Avg Loss: 162.0872\n",
            "Epoch [23/50] - Batch loss: 164.6797 - Epoch Loss: 31771.6901 - Avg Loss: 162.1005\n",
            "Epoch [23/50] - Batch loss: 168.5098 - Epoch Loss: 31940.1998 - Avg Loss: 162.1330\n",
            "Epoch [23/50] - Batch loss: 162.3884 - Epoch Loss: 32102.5882 - Avg Loss: 162.1343\n",
            "Epoch [23/50] - Batch loss: 163.0753 - Epoch Loss: 32265.6635 - Avg Loss: 162.1390\n",
            "Epoch [23/50] - Batch loss: 160.8184 - Epoch Loss: 32426.4818 - Avg Loss: 162.1324\n",
            "Epoch [23/50] - Batch loss: 164.2481 - Epoch Loss: 32590.7299 - Avg Loss: 162.1429\n",
            "Epoch [23/50] - Batch loss: 168.5025 - Epoch Loss: 32759.2324 - Avg Loss: 162.1744\n",
            "Epoch [23/50] - Batch loss: 147.0762 - Epoch Loss: 32906.3086 - Avg Loss: 162.1000\n",
            "Epoch [23/50] - Batch loss: 157.7894 - Epoch Loss: 33064.0980 - Avg Loss: 162.0789\n",
            "Epoch [23/50] - Batch loss: 157.6440 - Epoch Loss: 33221.7420 - Avg Loss: 162.0573\n",
            "Epoch [23/50] - Batch loss: 163.1536 - Epoch Loss: 33384.8955 - Avg Loss: 162.0626\n",
            "Epoch [23/50] - Batch loss: 158.2203 - Epoch Loss: 33543.1158 - Avg Loss: 162.0440\n",
            "Epoch [23/50] - Batch loss: 162.4690 - Epoch Loss: 33705.5848 - Avg Loss: 162.0461\n",
            "Epoch [23/50] - Batch loss: 163.8406 - Epoch Loss: 33869.4254 - Avg Loss: 162.0547\n",
            "Epoch [23/50] - Batch loss: 162.3324 - Epoch Loss: 34031.7578 - Avg Loss: 162.0560\n",
            "Epoch [23/50] - Batch loss: 163.1271 - Epoch Loss: 34194.8849 - Avg Loss: 162.0611\n",
            "Epoch [23/50] - Batch loss: 159.1044 - Epoch Loss: 34353.9893 - Avg Loss: 162.0471\n",
            "Epoch [23/50] - Batch loss: 167.7820 - Epoch Loss: 34521.7713 - Avg Loss: 162.0740\n",
            "Epoch [23/50] - Batch loss: 160.2330 - Epoch Loss: 34682.0043 - Avg Loss: 162.0654\n",
            "Epoch [23/50] - Batch loss: 173.5575 - Epoch Loss: 34855.5618 - Avg Loss: 162.1189\n",
            "Epoch [23/50] - Batch loss: 164.5041 - Epoch Loss: 35020.0659 - Avg Loss: 162.1299\n",
            "Epoch [23/50] - Batch loss: 155.8792 - Epoch Loss: 35175.9451 - Avg Loss: 162.1011\n",
            "Epoch [23/50] - Batch loss: 158.3669 - Epoch Loss: 35334.3120 - Avg Loss: 162.0840\n",
            "Epoch [23/50] - Batch loss: 162.6395 - Epoch Loss: 35496.9514 - Avg Loss: 162.0865\n",
            "Epoch [23/50] - Batch loss: 160.1525 - Epoch Loss: 35657.1040 - Avg Loss: 162.0777\n",
            "Epoch [23/50] - Batch loss: 160.6221 - Epoch Loss: 35817.7261 - Avg Loss: 162.0712\n",
            "Epoch [23/50] - Batch loss: 166.3345 - Epoch Loss: 35984.0607 - Avg Loss: 162.0904\n",
            "Epoch [23/50] - Batch loss: 159.4351 - Epoch Loss: 36143.4958 - Avg Loss: 162.0785\n",
            "Epoch [23/50] - Batch loss: 166.5228 - Epoch Loss: 36310.0185 - Avg Loss: 162.0983\n",
            "Epoch [23/50] - Batch loss: 169.5374 - Epoch Loss: 36479.5559 - Avg Loss: 162.1314\n",
            "Epoch [23/50] - Batch loss: 162.5811 - Epoch Loss: 36642.1370 - Avg Loss: 162.1333\n",
            "Epoch [23/50] - Batch loss: 157.5054 - Epoch Loss: 36799.6424 - Avg Loss: 162.1130\n",
            "Epoch [23/50] - Batch loss: 165.6312 - Epoch Loss: 36965.2736 - Avg Loss: 162.1284\n",
            "Epoch [23/50] - Batch loss: 161.7899 - Epoch Loss: 37127.0635 - Avg Loss: 162.1269\n",
            "Epoch [23/50] - Batch loss: 154.3287 - Epoch Loss: 37281.3922 - Avg Loss: 162.0930\n",
            "Epoch [23/50] - Batch loss: 161.8524 - Epoch Loss: 37443.2446 - Avg Loss: 162.0920\n",
            "Epoch [23/50] - Batch loss: 156.5939 - Epoch Loss: 37599.8384 - Avg Loss: 162.0683\n",
            "Epoch [23/50] - Batch loss: 160.1809 - Epoch Loss: 37760.0193 - Avg Loss: 162.0602\n",
            "Epoch [23/50] - Batch loss: 161.2388 - Epoch Loss: 37921.2582 - Avg Loss: 162.0567\n",
            "Epoch [23/50] - Batch loss: 156.1235 - Epoch Loss: 38077.3816 - Avg Loss: 162.0314\n",
            "Epoch [23/50] - Batch loss: 159.7330 - Epoch Loss: 38237.1146 - Avg Loss: 162.0217\n",
            "Epoch [23/50] - Batch loss: 160.4215 - Epoch Loss: 38397.5361 - Avg Loss: 162.0149\n",
            "Epoch [23/50] - Batch loss: 166.3736 - Epoch Loss: 38563.9097 - Avg Loss: 162.0332\n",
            "Epoch [23/50] - Batch loss: 157.3251 - Epoch Loss: 38721.2349 - Avg Loss: 162.0135\n",
            "Epoch [23/50] - Batch loss: 161.4520 - Epoch Loss: 38882.6869 - Avg Loss: 162.0112\n",
            "Epoch [23/50] - Batch loss: 160.7666 - Epoch Loss: 39043.4535 - Avg Loss: 162.0060\n",
            "Epoch [23/50] - Batch loss: 166.9088 - Epoch Loss: 39210.3623 - Avg Loss: 162.0263\n",
            "Epoch [23/50] - Batch loss: 163.1690 - Epoch Loss: 39373.5314 - Avg Loss: 162.0310\n",
            "Epoch [23/50] - Batch loss: 161.1309 - Epoch Loss: 39534.6622 - Avg Loss: 162.0273\n",
            "Epoch [23/50] - Batch loss: 163.1648 - Epoch Loss: 39697.8270 - Avg Loss: 162.0319\n",
            "Epoch [23/50] - Batch loss: 164.4941 - Epoch Loss: 39862.3211 - Avg Loss: 162.0420\n",
            "Epoch [23/50] - Batch loss: 167.1947 - Epoch Loss: 40029.5157 - Avg Loss: 162.0628\n",
            "Epoch [23/50] - Batch loss: 159.2596 - Epoch Loss: 40188.7753 - Avg Loss: 162.0515\n",
            "Epoch [23/50] - Batch loss: 154.0545 - Epoch Loss: 40342.8297 - Avg Loss: 162.0194\n",
            "Epoch [23/50] - Batch loss: 157.8367 - Epoch Loss: 40500.6664 - Avg Loss: 162.0027\n",
            "Epoch [23/50] - Batch loss: 162.6733 - Epoch Loss: 40663.3398 - Avg Loss: 162.0053\n",
            "Epoch [23/50] - Batch loss: 160.8180 - Epoch Loss: 40824.1578 - Avg Loss: 162.0006\n",
            "Epoch [23/50] - Batch loss: 172.1666 - Epoch Loss: 40996.3244 - Avg Loss: 162.0408\n",
            "Epoch [23/50] - Batch loss: 162.5948 - Epoch Loss: 41158.9193 - Avg Loss: 162.0430\n",
            "Epoch [23/50] - Batch loss: 162.4957 - Epoch Loss: 41321.4150 - Avg Loss: 162.0448\n",
            "Epoch [23/50] - Batch loss: 165.0419 - Epoch Loss: 41486.4568 - Avg Loss: 162.0565\n",
            "Epoch [23/50] - Batch loss: 166.2710 - Epoch Loss: 41652.7278 - Avg Loss: 162.0729\n",
            "Epoch [23/50] - Batch loss: 151.4126 - Epoch Loss: 41804.1404 - Avg Loss: 162.0316\n",
            "Epoch [23/50] - Batch loss: 169.7421 - Epoch Loss: 41973.8825 - Avg Loss: 162.0613\n",
            "Epoch [23/50] - Batch loss: 165.0213 - Epoch Loss: 42138.9038 - Avg Loss: 162.0727\n",
            "Epoch [23/50] - Batch loss: 161.9373 - Epoch Loss: 42300.8411 - Avg Loss: 162.0722\n",
            "Epoch [23/50] - Batch loss: 171.2274 - Epoch Loss: 42472.0685 - Avg Loss: 162.1071\n",
            "Epoch [23/50] - Batch loss: 155.3280 - Epoch Loss: 42627.3965 - Avg Loss: 162.0814\n",
            "Epoch [23/50] - Batch loss: 151.0361 - Epoch Loss: 42778.4325 - Avg Loss: 162.0395\n",
            "Epoch [23/50] - Batch loss: 164.7908 - Epoch Loss: 42943.2233 - Avg Loss: 162.0499\n",
            "Epoch [23/50] - Batch loss: 168.2957 - Epoch Loss: 43111.5190 - Avg Loss: 162.0734\n",
            "Epoch [23/50] - Batch loss: 162.4517 - Epoch Loss: 43273.9707 - Avg Loss: 162.0748\n",
            "Epoch [23/50] - Batch loss: 160.5261 - Epoch Loss: 43434.4967 - Avg Loss: 162.0690\n",
            "Epoch [23/50] - Batch loss: 170.8926 - Epoch Loss: 43605.3894 - Avg Loss: 162.1018\n",
            "Epoch [23/50] - Batch loss: 169.3416 - Epoch Loss: 43774.7310 - Avg Loss: 162.1286\n",
            "Epoch [23/50] - Batch loss: 165.2400 - Epoch Loss: 43939.9710 - Avg Loss: 162.1401\n",
            "Epoch [23/50] - Batch loss: 158.0457 - Epoch Loss: 44098.0167 - Avg Loss: 162.1251\n",
            "Epoch [23/50] - Batch loss: 171.2344 - Epoch Loss: 44269.2511 - Avg Loss: 162.1584\n",
            "Epoch [23/50] - Batch loss: 162.4313 - Epoch Loss: 44431.6824 - Avg Loss: 162.1594\n",
            "Epoch [23/50] - Batch loss: 169.0691 - Epoch Loss: 44600.7515 - Avg Loss: 162.1846\n",
            "Epoch [23/50] - Batch loss: 159.4780 - Epoch Loss: 44760.2295 - Avg Loss: 162.1747\n",
            "Epoch [23/50] - Batch loss: 161.5238 - Epoch Loss: 44921.7533 - Avg Loss: 162.1724\n",
            "Epoch [23/50] - Batch loss: 159.6579 - Epoch Loss: 45081.4113 - Avg Loss: 162.1633\n",
            "Epoch [23/50] - Batch loss: 162.8680 - Epoch Loss: 45244.2793 - Avg Loss: 162.1659\n",
            "Epoch [23/50] - Batch loss: 164.2859 - Epoch Loss: 45408.5652 - Avg Loss: 162.1734\n",
            "Epoch [23/50] - Batch loss: 165.1722 - Epoch Loss: 45573.7374 - Avg Loss: 162.1841\n",
            "Epoch [23/50] - Batch loss: 175.6610 - Epoch Loss: 45749.3985 - Avg Loss: 162.2319\n",
            "Epoch [23/50] - Batch loss: 171.1807 - Epoch Loss: 45920.5792 - Avg Loss: 162.2635\n",
            "Epoch [23/50] - Batch loss: 165.3279 - Epoch Loss: 46085.9071 - Avg Loss: 162.2743\n",
            "Epoch [23/50] - Batch loss: 168.4190 - Epoch Loss: 46254.3261 - Avg Loss: 162.2959\n",
            "Epoch [23/50] - Batch loss: 158.5546 - Epoch Loss: 46412.8807 - Avg Loss: 162.2828\n",
            "Epoch [23/50] - Batch loss: 166.8422 - Epoch Loss: 46579.7229 - Avg Loss: 162.2987\n",
            "Epoch [23/50] - Batch loss: 162.8903 - Epoch Loss: 46742.6132 - Avg Loss: 162.3007\n",
            "Epoch [23/50] - Batch loss: 159.9134 - Epoch Loss: 46902.5267 - Avg Loss: 162.2925\n",
            "Epoch [23/50] - Batch loss: 164.8725 - Epoch Loss: 47067.3992 - Avg Loss: 162.3014\n",
            "Epoch [23/50] - Batch loss: 168.1758 - Epoch Loss: 47235.5750 - Avg Loss: 162.3216\n",
            "Epoch [23/50] - Batch loss: 157.8309 - Epoch Loss: 47393.4058 - Avg Loss: 162.3062\n",
            "Epoch [23/50] - Batch loss: 170.4515 - Epoch Loss: 47563.8573 - Avg Loss: 162.3340\n",
            "Epoch [23/50] - Batch loss: 163.4937 - Epoch Loss: 47727.3510 - Avg Loss: 162.3379\n",
            "Epoch [23/50] - Batch loss: 171.6527 - Epoch Loss: 47899.0038 - Avg Loss: 162.3695\n",
            "Epoch [23/50] - Batch loss: 161.4064 - Epoch Loss: 48060.4102 - Avg Loss: 162.3663\n",
            "Epoch [23/50] - Batch loss: 173.2985 - Epoch Loss: 48233.7087 - Avg Loss: 162.4031\n",
            "Epoch [23/50] - Batch loss: 156.6981 - Epoch Loss: 48390.4068 - Avg Loss: 162.3839\n",
            "Epoch [23/50] - Batch loss: 158.2289 - Epoch Loss: 48548.6357 - Avg Loss: 162.3700\n",
            "Epoch [23/50] - Batch loss: 161.2667 - Epoch Loss: 48709.9024 - Avg Loss: 162.3663\n",
            "Epoch [23/50] - Batch loss: 170.9297 - Epoch Loss: 48880.8321 - Avg Loss: 162.3948\n",
            "Epoch [23/50] - Batch loss: 158.1188 - Epoch Loss: 49038.9509 - Avg Loss: 162.3806\n",
            "Epoch [23/50] - Batch loss: 154.3956 - Epoch Loss: 49193.3465 - Avg Loss: 162.3543\n",
            "Epoch [23/50] - Batch loss: 168.0035 - Epoch Loss: 49361.3499 - Avg Loss: 162.3729\n",
            "Epoch [23/50] - Batch loss: 161.6136 - Epoch Loss: 49522.9636 - Avg Loss: 162.3704\n",
            "Epoch [23/50] - Batch loss: 155.1898 - Epoch Loss: 49678.1534 - Avg Loss: 162.3469\n",
            "Epoch [23/50] - Batch loss: 165.2517 - Epoch Loss: 49843.4052 - Avg Loss: 162.3564\n",
            "Epoch [23/50] - Batch loss: 165.4000 - Epoch Loss: 50008.8051 - Avg Loss: 162.3663\n",
            "Epoch [23/50] - Batch loss: 161.4796 - Epoch Loss: 50170.2847 - Avg Loss: 162.3634\n",
            "Epoch [23/50] - Batch loss: 170.8263 - Epoch Loss: 50341.1110 - Avg Loss: 162.3907\n",
            "Epoch [23/50] - Batch loss: 156.2745 - Epoch Loss: 50497.3855 - Avg Loss: 162.3710\n",
            "Epoch [23/50] - Batch loss: 156.9547 - Epoch Loss: 50654.3401 - Avg Loss: 162.3537\n",
            "Epoch [23/50] - Batch loss: 155.9829 - Epoch Loss: 50810.3230 - Avg Loss: 162.3333\n",
            "Epoch [23/50] - Batch loss: 159.2783 - Epoch Loss: 50969.6013 - Avg Loss: 162.3236\n",
            "Epoch [23/50] - Batch loss: 160.6176 - Epoch Loss: 51130.2189 - Avg Loss: 162.3182\n",
            "Epoch [23/50] - Batch loss: 165.8469 - Epoch Loss: 51296.0658 - Avg Loss: 162.3293\n",
            "Epoch [23/50] - Batch loss: 158.4272 - Epoch Loss: 51454.4931 - Avg Loss: 162.3170\n",
            "Epoch [23/50] - Batch loss: 156.4064 - Epoch Loss: 51610.8994 - Avg Loss: 162.2984\n",
            "Epoch [23/50] - Batch loss: 171.9619 - Epoch Loss: 51782.8613 - Avg Loss: 162.3287\n",
            "Epoch [23/50] - Batch loss: 163.6860 - Epoch Loss: 51946.5473 - Avg Loss: 162.3330\n",
            "Epoch [23/50] - Batch loss: 168.1092 - Epoch Loss: 52114.6566 - Avg Loss: 162.3510\n",
            "Epoch [23/50] - Batch loss: 166.3658 - Epoch Loss: 52281.0224 - Avg Loss: 162.3634\n",
            "Epoch [23/50] - Batch loss: 160.4203 - Epoch Loss: 52441.4427 - Avg Loss: 162.3574\n",
            "Epoch [23/50] - Batch loss: 160.2551 - Epoch Loss: 52601.6978 - Avg Loss: 162.3509\n",
            "Epoch [23/50] - Batch loss: 162.0950 - Epoch Loss: 52763.7928 - Avg Loss: 162.3501\n",
            "Epoch [23/50] - Batch loss: 166.2350 - Epoch Loss: 52930.0278 - Avg Loss: 162.3620\n",
            "Epoch [23/50] - Batch loss: 164.1272 - Epoch Loss: 53094.1550 - Avg Loss: 162.3674\n",
            "Epoch [23/50] - Batch loss: 168.9329 - Epoch Loss: 53263.0879 - Avg Loss: 162.3875\n",
            "Epoch [23/50] - Batch loss: 161.8838 - Epoch Loss: 53424.9717 - Avg Loss: 162.3859\n",
            "Epoch [23/50] - Batch loss: 159.3668 - Epoch Loss: 53584.3385 - Avg Loss: 162.3768\n",
            "Epoch [23/50] - Batch loss: 165.7847 - Epoch Loss: 53750.1233 - Avg Loss: 162.3871\n",
            "Epoch [23/50] - Batch loss: 155.6424 - Epoch Loss: 53905.7657 - Avg Loss: 162.3668\n",
            "Epoch [23/50] - Batch loss: 169.1099 - Epoch Loss: 54074.8756 - Avg Loss: 162.3870\n",
            "Epoch [23/50] - Batch loss: 166.1176 - Epoch Loss: 54240.9933 - Avg Loss: 162.3982\n",
            "Epoch [23/50] - Batch loss: 164.5090 - Epoch Loss: 54405.5022 - Avg Loss: 162.4045\n",
            "Epoch [23/50] - Batch loss: 158.4805 - Epoch Loss: 54563.9827 - Avg Loss: 162.3928\n",
            "Epoch [23/50] - Batch loss: 155.7781 - Epoch Loss: 54719.7608 - Avg Loss: 162.3732\n",
            "Epoch [23/50] - Batch loss: 165.6016 - Epoch Loss: 54885.3624 - Avg Loss: 162.3827\n",
            "Epoch [23/50] - Batch loss: 165.3723 - Epoch Loss: 55050.7347 - Avg Loss: 162.3915\n",
            "Epoch [23/50] - Batch loss: 163.3495 - Epoch Loss: 55214.0842 - Avg Loss: 162.3944\n",
            "Epoch [23/50] - Batch loss: 160.5938 - Epoch Loss: 55374.6779 - Avg Loss: 162.3891\n",
            "Epoch [23/50] - Batch loss: 154.0571 - Epoch Loss: 55528.7351 - Avg Loss: 162.3647\n",
            "Epoch [23/50] - Batch loss: 158.2317 - Epoch Loss: 55686.9667 - Avg Loss: 162.3527\n",
            "Epoch [23/50] - Batch loss: 159.5800 - Epoch Loss: 55846.5467 - Avg Loss: 162.3446\n",
            "Epoch [23/50] - Batch loss: 165.6560 - Epoch Loss: 56012.2027 - Avg Loss: 162.3542\n",
            "Epoch [23/50] - Batch loss: 155.9915 - Epoch Loss: 56168.1942 - Avg Loss: 162.3358\n",
            "Epoch [23/50] - Batch loss: 161.5355 - Epoch Loss: 56329.7297 - Avg Loss: 162.3335\n",
            "Epoch [23/50] - Batch loss: 149.1053 - Epoch Loss: 56478.8350 - Avg Loss: 162.2955\n",
            "Epoch [23/50] - Batch loss: 161.8188 - Epoch Loss: 56640.6538 - Avg Loss: 162.2941\n",
            "Epoch [23/50] - Batch loss: 165.5152 - Epoch Loss: 56806.1690 - Avg Loss: 162.3033\n",
            "Epoch [23/50] - Batch loss: 161.2624 - Epoch Loss: 56967.4314 - Avg Loss: 162.3004\n",
            "Epoch [23/50] - Batch loss: 159.9480 - Epoch Loss: 57127.3793 - Avg Loss: 162.2937\n",
            "Epoch [23/50] - Batch loss: 158.0748 - Epoch Loss: 57285.4542 - Avg Loss: 162.2817\n",
            "Epoch [23/50] - Batch loss: 163.0236 - Epoch Loss: 57448.4777 - Avg Loss: 162.2838\n",
            "Epoch [23/50] - Batch loss: 159.9258 - Epoch Loss: 57608.4035 - Avg Loss: 162.2772\n",
            "Epoch [23/50] - Batch loss: 160.6978 - Epoch Loss: 57769.1014 - Avg Loss: 162.2728\n",
            "Epoch [23/50] - Batch loss: 157.1204 - Epoch Loss: 57926.2218 - Avg Loss: 162.2583\n",
            "Epoch [23/50] - Batch loss: 163.6264 - Epoch Loss: 58089.8482 - Avg Loss: 162.2621\n",
            "Epoch [23/50] - Batch loss: 156.2369 - Epoch Loss: 58246.0851 - Avg Loss: 162.2454\n",
            "Epoch [23/50] - Batch loss: 157.5649 - Epoch Loss: 58403.6500 - Avg Loss: 162.2324\n",
            "Epoch [23/50] - Batch loss: 163.7127 - Epoch Loss: 58567.3628 - Avg Loss: 162.2365\n",
            "Epoch [23/50] - Batch loss: 168.9380 - Epoch Loss: 58736.3008 - Avg Loss: 162.2550\n",
            "Epoch [23/50] - Batch loss: 159.6598 - Epoch Loss: 58895.9606 - Avg Loss: 162.2478\n",
            "Epoch [23/50] - Batch loss: 155.9961 - Epoch Loss: 59051.9567 - Avg Loss: 162.2307\n",
            "Epoch [23/50] - Batch loss: 164.2390 - Epoch Loss: 59216.1957 - Avg Loss: 162.2362\n",
            "Epoch [23/50] - Batch loss: 161.2685 - Epoch Loss: 59377.4642 - Avg Loss: 162.2335\n",
            "Epoch [23/50] - Batch loss: 157.1585 - Epoch Loss: 59534.6227 - Avg Loss: 162.2197\n",
            "Epoch [23/50] - Batch loss: 159.5041 - Epoch Loss: 59694.1267 - Avg Loss: 162.2123\n",
            "Epoch [23/50] - Batch loss: 164.5236 - Epoch Loss: 59858.6503 - Avg Loss: 162.2186\n",
            "Epoch [23/50] - Batch loss: 162.4862 - Epoch Loss: 60021.1365 - Avg Loss: 162.2193\n",
            "Epoch [23/50] - Batch loss: 165.4289 - Epoch Loss: 60186.5654 - Avg Loss: 162.2279\n",
            "Epoch [23/50] - Batch loss: 155.4325 - Epoch Loss: 60341.9980 - Avg Loss: 162.2097\n",
            "Epoch [23/50] - Batch loss: 158.2729 - Epoch Loss: 60500.2709 - Avg Loss: 162.1991\n",
            "Epoch [23/50] - Batch loss: 154.3968 - Epoch Loss: 60654.6677 - Avg Loss: 162.1783\n",
            "Epoch [23/50] - Batch loss: 156.5981 - Epoch Loss: 60811.2658 - Avg Loss: 162.1634\n",
            "Epoch [23/50] - Batch loss: 164.3598 - Epoch Loss: 60975.6256 - Avg Loss: 162.1692\n",
            "Epoch [23/50] - Batch loss: 155.5250 - Epoch Loss: 61131.1505 - Avg Loss: 162.1516\n",
            "Epoch [23/50] - Batch loss: 147.3850 - Epoch Loss: 61278.5355 - Avg Loss: 162.1125\n",
            "Epoch [23/50] - Batch loss: 152.2527 - Epoch Loss: 61430.7882 - Avg Loss: 162.0865\n",
            "Epoch [23/50] - Batch loss: 157.5518 - Epoch Loss: 61588.3401 - Avg Loss: 162.0746\n",
            "Epoch [23/50] - Batch loss: 159.9120 - Epoch Loss: 61748.2521 - Avg Loss: 162.0689\n",
            "Epoch [23/50] - Batch loss: 166.0363 - Epoch Loss: 61914.2883 - Avg Loss: 162.0793\n",
            "Epoch [23/50] - Batch loss: 156.6277 - Epoch Loss: 62070.9160 - Avg Loss: 162.0651\n",
            "Epoch [23/50] - Batch loss: 156.1098 - Epoch Loss: 62227.0258 - Avg Loss: 162.0495\n",
            "Epoch [23/50] - Batch loss: 156.8109 - Epoch Loss: 62383.8367 - Avg Loss: 162.0359\n",
            "Epoch [23/50] - Batch loss: 164.3342 - Epoch Loss: 62548.1709 - Avg Loss: 162.0419\n",
            "Epoch [23/50] - Batch loss: 159.7724 - Epoch Loss: 62707.9433 - Avg Loss: 162.0360\n",
            "Epoch [23/50] - Batch loss: 160.4059 - Epoch Loss: 62868.3492 - Avg Loss: 162.0318\n",
            "Epoch [23/50] - Batch loss: 159.8315 - Epoch Loss: 63028.1808 - Avg Loss: 162.0262\n",
            "Epoch [23/50] - Batch loss: 163.8002 - Epoch Loss: 63191.9809 - Avg Loss: 162.0307\n",
            "Epoch [23/50] - Batch loss: 160.9971 - Epoch Loss: 63352.9780 - Avg Loss: 162.0281\n",
            "Epoch [23/50] - Batch loss: 161.8618 - Epoch Loss: 63514.8398 - Avg Loss: 162.0277\n",
            "Epoch [23/50] - Batch loss: 160.1611 - Epoch Loss: 63675.0009 - Avg Loss: 162.0229\n",
            "Epoch [23/50] - Batch loss: 153.0103 - Epoch Loss: 63828.0112 - Avg Loss: 162.0000\n",
            "Epoch [23/50] - Batch loss: 157.4148 - Epoch Loss: 63985.4260 - Avg Loss: 161.9884\n",
            "Epoch [23/50] - Batch loss: 159.6118 - Epoch Loss: 64145.0379 - Avg Loss: 161.9824\n",
            "Epoch [23/50] - Batch loss: 158.6722 - Epoch Loss: 64303.7101 - Avg Loss: 161.9741\n",
            "Epoch [23/50] - Batch loss: 160.2793 - Epoch Loss: 64463.9894 - Avg Loss: 161.9698\n",
            "Epoch [23/50] - Batch loss: 163.9230 - Epoch Loss: 64627.9124 - Avg Loss: 161.9747\n",
            "Epoch [23/50] - Batch loss: 159.4248 - Epoch Loss: 64787.3372 - Avg Loss: 161.9683\n",
            "Epoch [23/50] - Batch loss: 154.0098 - Epoch Loss: 64941.3471 - Avg Loss: 161.9485\n",
            "Epoch [23/50] - Batch loss: 156.6049 - Epoch Loss: 65097.9520 - Avg Loss: 161.9352\n",
            "Epoch [23/50] - Batch loss: 162.4191 - Epoch Loss: 65260.3710 - Avg Loss: 161.9364\n",
            "Epoch [23/50] - Batch loss: 157.4153 - Epoch Loss: 65417.7863 - Avg Loss: 161.9252\n",
            "Epoch [23/50] - Batch loss: 156.4675 - Epoch Loss: 65574.2538 - Avg Loss: 161.9117\n",
            "Epoch [23/50] - Batch loss: 160.0266 - Epoch Loss: 65734.2805 - Avg Loss: 161.9071\n",
            "Epoch [23/50] - Batch loss: 155.4029 - Epoch Loss: 65889.6834 - Avg Loss: 161.8911\n",
            "Epoch [23/50] - Batch loss: 164.5419 - Epoch Loss: 66054.2253 - Avg Loss: 161.8976\n",
            "Epoch [23/50] - Batch loss: 154.2903 - Epoch Loss: 66208.5155 - Avg Loss: 161.8790\n",
            "Epoch [23/50] - Batch loss: 157.9290 - Epoch Loss: 66366.4445 - Avg Loss: 161.8694\n",
            "Epoch [23/50] - Batch loss: 163.7043 - Epoch Loss: 66530.1488 - Avg Loss: 161.8738\n",
            "Epoch [23/50] - Batch loss: 160.2199 - Epoch Loss: 66690.3687 - Avg Loss: 161.8698\n",
            "Epoch [23/50] - Batch loss: 156.3509 - Epoch Loss: 66846.7196 - Avg Loss: 161.8565\n",
            "Epoch [23/50] - Batch loss: 153.3480 - Epoch Loss: 67000.0677 - Avg Loss: 161.8359\n",
            "Epoch [23/50] - Batch loss: 153.4422 - Epoch Loss: 67153.5099 - Avg Loss: 161.8157\n",
            "Epoch [23/50] - Batch loss: 163.6238 - Epoch Loss: 67317.1337 - Avg Loss: 161.8200\n",
            "Epoch [23/50] - Batch loss: 155.4870 - Epoch Loss: 67472.6207 - Avg Loss: 161.8048\n",
            "Epoch [23/50] - Batch loss: 164.6384 - Epoch Loss: 67637.2591 - Avg Loss: 161.8116\n",
            "Epoch [23/50] - Batch loss: 152.1839 - Epoch Loss: 67789.4430 - Avg Loss: 161.7886\n",
            "Epoch [23/50] - Batch loss: 155.6731 - Epoch Loss: 67945.1161 - Avg Loss: 161.7741\n",
            "Epoch [23/50] - Batch loss: 164.3898 - Epoch Loss: 68109.5059 - Avg Loss: 161.7803\n",
            "Epoch [23/50] - Batch loss: 158.8109 - Epoch Loss: 68268.3168 - Avg Loss: 161.7733\n",
            "Epoch [23/50] - Batch loss: 157.4867 - Epoch Loss: 68425.8035 - Avg Loss: 161.7631\n",
            "Epoch [23/50] - Batch loss: 162.8667 - Epoch Loss: 68588.6702 - Avg Loss: 161.7657\n",
            "Epoch [23/50] - Batch loss: 161.5486 - Epoch Loss: 68750.2189 - Avg Loss: 161.7652\n",
            "Epoch [23/50] - Batch loss: 157.8213 - Epoch Loss: 68908.0402 - Avg Loss: 161.7560\n",
            "Epoch [23/50] - Batch loss: 153.5933 - Epoch Loss: 69061.6335 - Avg Loss: 161.7368\n",
            "Epoch [23/50] - Batch loss: 159.9223 - Epoch Loss: 69221.5558 - Avg Loss: 161.7326\n",
            "Epoch [23/50] - Batch loss: 159.0199 - Epoch Loss: 69380.5757 - Avg Loss: 161.7263\n",
            "Epoch [23/50] - Batch loss: 155.8344 - Epoch Loss: 69536.4101 - Avg Loss: 161.7126\n",
            "Epoch [23/50] - Batch loss: 161.7503 - Epoch Loss: 69698.1605 - Avg Loss: 161.7127\n",
            "Epoch [23/50] - Batch loss: 161.1150 - Epoch Loss: 69859.2755 - Avg Loss: 161.7113\n",
            "Epoch [23/50] - Batch loss: 150.2602 - Epoch Loss: 70009.5356 - Avg Loss: 161.6848\n",
            "Epoch [23/50] - Batch loss: 154.3145 - Epoch Loss: 70163.8502 - Avg Loss: 161.6679\n",
            "Epoch [23/50] - Batch loss: 160.3320 - Epoch Loss: 70324.1821 - Avg Loss: 161.6648\n",
            "Epoch [23/50] - Batch loss: 164.0762 - Epoch Loss: 70488.2584 - Avg Loss: 161.6703\n",
            "Epoch [23/50] - Batch loss: 156.9773 - Epoch Loss: 70645.2357 - Avg Loss: 161.6596\n",
            "Epoch [23/50] - Batch loss: 169.5097 - Epoch Loss: 70814.7454 - Avg Loss: 161.6775\n",
            "Epoch [23/50] - Batch loss: 155.4228 - Epoch Loss: 70970.1682 - Avg Loss: 161.6633\n",
            "Epoch [23/50] - Batch loss: 169.5927 - Epoch Loss: 71139.7609 - Avg Loss: 161.6813\n",
            "Epoch [23/50] - Batch loss: 156.7200 - Epoch Loss: 71296.4809 - Avg Loss: 161.6700\n",
            "Epoch [23/50] - Batch loss: 159.3929 - Epoch Loss: 71455.8739 - Avg Loss: 161.6649\n",
            "Epoch [23/50] - Batch loss: 156.7774 - Epoch Loss: 71612.6513 - Avg Loss: 161.6538\n",
            "Epoch [23/50] - Batch loss: 158.4352 - Epoch Loss: 71771.0865 - Avg Loss: 161.6466\n",
            "Epoch [23/50] - Batch loss: 163.1063 - Epoch Loss: 71934.1928 - Avg Loss: 161.6499\n",
            "Epoch [23/50] - Batch loss: 166.4032 - Epoch Loss: 72100.5960 - Avg Loss: 161.6605\n",
            "Epoch [23/50] - Batch loss: 152.4983 - Epoch Loss: 72253.0943 - Avg Loss: 161.6400\n",
            "Epoch [23/50] - Batch loss: 151.9116 - Epoch Loss: 72405.0059 - Avg Loss: 161.6183\n",
            "Epoch [23/50] - Batch loss: 166.5622 - Epoch Loss: 72571.5681 - Avg Loss: 161.6293\n",
            "Epoch [23/50] - Batch loss: 155.3215 - Epoch Loss: 72726.8895 - Avg Loss: 161.6153\n",
            "Epoch [23/50] - Batch loss: 158.2349 - Epoch Loss: 72885.1245 - Avg Loss: 161.6078\n",
            "Epoch [23/50] - Batch loss: 157.9078 - Epoch Loss: 73043.0323 - Avg Loss: 161.5996\n",
            "Epoch [23/50] - Batch loss: 165.1962 - Epoch Loss: 73208.2285 - Avg Loss: 161.6076\n",
            "Epoch [23/50] - Batch loss: 166.5470 - Epoch Loss: 73374.7755 - Avg Loss: 161.6184\n",
            "Epoch [23/50] - Batch loss: 162.3619 - Epoch Loss: 73537.1374 - Avg Loss: 161.6201\n",
            "Epoch [23/50] - Batch loss: 161.6637 - Epoch Loss: 73698.8010 - Avg Loss: 161.6202\n",
            "Epoch [23/50] - Batch loss: 164.6622 - Epoch Loss: 73863.4633 - Avg Loss: 161.6268\n",
            "Epoch [23/50] - Batch loss: 165.2625 - Epoch Loss: 74028.7257 - Avg Loss: 161.6348\n",
            "Epoch [23/50] - Batch loss: 159.6437 - Epoch Loss: 74188.3694 - Avg Loss: 161.6304\n",
            "Epoch [23/50] - Batch loss: 160.2606 - Epoch Loss: 74348.6300 - Avg Loss: 161.6275\n",
            "Epoch [23/50] - Batch loss: 162.0260 - Epoch Loss: 74510.6561 - Avg Loss: 161.6283\n",
            "Epoch [23/50] - Batch loss: 162.4657 - Epoch Loss: 74673.1217 - Avg Loss: 161.6301\n",
            "Epoch [23/50] - Batch loss: 153.7372 - Epoch Loss: 74826.8589 - Avg Loss: 161.6131\n",
            "Epoch [23/50] - Batch loss: 152.2014 - Epoch Loss: 74979.0603 - Avg Loss: 161.5928\n",
            "Epoch [23/50] - Batch loss: 155.9777 - Epoch Loss: 75135.0380 - Avg Loss: 161.5807\n",
            "Epoch [23/50] - Batch loss: 154.0213 - Epoch Loss: 75289.0593 - Avg Loss: 161.5645\n",
            "Epoch [23/50] - Batch loss: 154.5920 - Epoch Loss: 75443.6513 - Avg Loss: 161.5496\n",
            "Epoch [23/50] - Batch loss: 161.9369 - Epoch Loss: 75605.5882 - Avg Loss: 161.5504\n",
            "Epoch [23/50] - Batch loss: 161.4064 - Epoch Loss: 75766.9946 - Avg Loss: 161.5501\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 24/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "411ce77955d5465b8b0393fb79a648b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/50] - Batch loss: 166.4318 - Epoch Loss: 166.4318 - Avg Loss: 166.4318\n",
            "Epoch [24/50] - Batch loss: 156.4114 - Epoch Loss: 322.8432 - Avg Loss: 161.4216\n",
            "Epoch [24/50] - Batch loss: 153.4017 - Epoch Loss: 476.2448 - Avg Loss: 158.7483\n",
            "Epoch [24/50] - Batch loss: 167.3584 - Epoch Loss: 643.6033 - Avg Loss: 160.9008\n",
            "Epoch [24/50] - Batch loss: 156.8341 - Epoch Loss: 800.4374 - Avg Loss: 160.0875\n",
            "Epoch [24/50] - Batch loss: 166.7894 - Epoch Loss: 967.2268 - Avg Loss: 161.2045\n",
            "Epoch [24/50] - Batch loss: 160.1267 - Epoch Loss: 1127.3535 - Avg Loss: 161.0505\n",
            "Epoch [24/50] - Batch loss: 148.5257 - Epoch Loss: 1275.8792 - Avg Loss: 159.4849\n",
            "Epoch [24/50] - Batch loss: 163.3227 - Epoch Loss: 1439.2019 - Avg Loss: 159.9113\n",
            "Epoch [24/50] - Batch loss: 156.6283 - Epoch Loss: 1595.8302 - Avg Loss: 159.5830\n",
            "Epoch [24/50] - Batch loss: 159.6449 - Epoch Loss: 1755.4752 - Avg Loss: 159.5887\n",
            "Epoch [24/50] - Batch loss: 158.2351 - Epoch Loss: 1913.7103 - Avg Loss: 159.4759\n",
            "Epoch [24/50] - Batch loss: 157.2710 - Epoch Loss: 2070.9813 - Avg Loss: 159.3063\n",
            "Epoch [24/50] - Batch loss: 163.9984 - Epoch Loss: 2234.9797 - Avg Loss: 159.6414\n",
            "Epoch [24/50] - Batch loss: 156.0603 - Epoch Loss: 2391.0400 - Avg Loss: 159.4027\n",
            "Epoch [24/50] - Batch loss: 163.7782 - Epoch Loss: 2554.8182 - Avg Loss: 159.6761\n",
            "Epoch [24/50] - Batch loss: 163.8025 - Epoch Loss: 2718.6207 - Avg Loss: 159.9189\n",
            "Epoch [24/50] - Batch loss: 157.4092 - Epoch Loss: 2876.0299 - Avg Loss: 159.7794\n",
            "Epoch [24/50] - Batch loss: 158.4261 - Epoch Loss: 3034.4560 - Avg Loss: 159.7082\n",
            "Epoch [24/50] - Batch loss: 161.3311 - Epoch Loss: 3195.7871 - Avg Loss: 159.7894\n",
            "Epoch [24/50] - Batch loss: 160.0180 - Epoch Loss: 3355.8051 - Avg Loss: 159.8002\n",
            "Epoch [24/50] - Batch loss: 157.0977 - Epoch Loss: 3512.9028 - Avg Loss: 159.6774\n",
            "Epoch [24/50] - Batch loss: 159.9610 - Epoch Loss: 3672.8639 - Avg Loss: 159.6897\n",
            "Epoch [24/50] - Batch loss: 156.4716 - Epoch Loss: 3829.3355 - Avg Loss: 159.5556\n",
            "Epoch [24/50] - Batch loss: 158.9741 - Epoch Loss: 3988.3096 - Avg Loss: 159.5324\n",
            "Epoch [24/50] - Batch loss: 157.7214 - Epoch Loss: 4146.0310 - Avg Loss: 159.4627\n",
            "Epoch [24/50] - Batch loss: 163.2097 - Epoch Loss: 4309.2407 - Avg Loss: 159.6015\n",
            "Epoch [24/50] - Batch loss: 168.0650 - Epoch Loss: 4477.3057 - Avg Loss: 159.9038\n",
            "Epoch [24/50] - Batch loss: 164.7854 - Epoch Loss: 4642.0911 - Avg Loss: 160.0721\n",
            "Epoch [24/50] - Batch loss: 163.3470 - Epoch Loss: 4805.4381 - Avg Loss: 160.1813\n",
            "Epoch [24/50] - Batch loss: 158.1868 - Epoch Loss: 4963.6249 - Avg Loss: 160.1169\n",
            "Epoch [24/50] - Batch loss: 159.6559 - Epoch Loss: 5123.2809 - Avg Loss: 160.1025\n",
            "Epoch [24/50] - Batch loss: 165.7531 - Epoch Loss: 5289.0340 - Avg Loss: 160.2738\n",
            "Epoch [24/50] - Batch loss: 163.0334 - Epoch Loss: 5452.0674 - Avg Loss: 160.3549\n",
            "Epoch [24/50] - Batch loss: 160.1980 - Epoch Loss: 5612.2654 - Avg Loss: 160.3504\n",
            "Epoch [24/50] - Batch loss: 151.1118 - Epoch Loss: 5763.3772 - Avg Loss: 160.0938\n",
            "Epoch [24/50] - Batch loss: 157.5156 - Epoch Loss: 5920.8928 - Avg Loss: 160.0241\n",
            "Epoch [24/50] - Batch loss: 159.8256 - Epoch Loss: 6080.7184 - Avg Loss: 160.0189\n",
            "Epoch [24/50] - Batch loss: 154.3383 - Epoch Loss: 6235.0567 - Avg Loss: 159.8732\n",
            "Epoch [24/50] - Batch loss: 151.4174 - Epoch Loss: 6386.4741 - Avg Loss: 159.6619\n",
            "Epoch [24/50] - Batch loss: 156.1755 - Epoch Loss: 6542.6496 - Avg Loss: 159.5768\n",
            "Epoch [24/50] - Batch loss: 155.8258 - Epoch Loss: 6698.4754 - Avg Loss: 159.4875\n",
            "Epoch [24/50] - Batch loss: 154.3732 - Epoch Loss: 6852.8486 - Avg Loss: 159.3686\n",
            "Epoch [24/50] - Batch loss: 164.0336 - Epoch Loss: 7016.8822 - Avg Loss: 159.4746\n",
            "Epoch [24/50] - Batch loss: 158.0628 - Epoch Loss: 7174.9451 - Avg Loss: 159.4432\n",
            "Epoch [24/50] - Batch loss: 157.3449 - Epoch Loss: 7332.2899 - Avg Loss: 159.3976\n",
            "Epoch [24/50] - Batch loss: 156.5455 - Epoch Loss: 7488.8355 - Avg Loss: 159.3369\n",
            "Epoch [24/50] - Batch loss: 157.3752 - Epoch Loss: 7646.2107 - Avg Loss: 159.2961\n",
            "Epoch [24/50] - Batch loss: 168.0900 - Epoch Loss: 7814.3006 - Avg Loss: 159.4755\n",
            "Epoch [24/50] - Batch loss: 158.9662 - Epoch Loss: 7973.2668 - Avg Loss: 159.4653\n",
            "Epoch [24/50] - Batch loss: 162.9096 - Epoch Loss: 8136.1765 - Avg Loss: 159.5329\n",
            "Epoch [24/50] - Batch loss: 161.5016 - Epoch Loss: 8297.6780 - Avg Loss: 159.5707\n",
            "Epoch [24/50] - Batch loss: 160.6613 - Epoch Loss: 8458.3393 - Avg Loss: 159.5913\n",
            "Epoch [24/50] - Batch loss: 162.0902 - Epoch Loss: 8620.4295 - Avg Loss: 159.6376\n",
            "Epoch [24/50] - Batch loss: 164.7620 - Epoch Loss: 8785.1915 - Avg Loss: 159.7308\n",
            "Epoch [24/50] - Batch loss: 163.6568 - Epoch Loss: 8948.8483 - Avg Loss: 159.8009\n",
            "Epoch [24/50] - Batch loss: 153.4977 - Epoch Loss: 9102.3461 - Avg Loss: 159.6903\n",
            "Epoch [24/50] - Batch loss: 170.2204 - Epoch Loss: 9272.5664 - Avg Loss: 159.8718\n",
            "Epoch [24/50] - Batch loss: 159.8408 - Epoch Loss: 9432.4073 - Avg Loss: 159.8713\n",
            "Epoch [24/50] - Batch loss: 165.0501 - Epoch Loss: 9597.4574 - Avg Loss: 159.9576\n",
            "Epoch [24/50] - Batch loss: 154.0396 - Epoch Loss: 9751.4970 - Avg Loss: 159.8606\n",
            "Epoch [24/50] - Batch loss: 157.9807 - Epoch Loss: 9909.4777 - Avg Loss: 159.8303\n",
            "Epoch [24/50] - Batch loss: 166.8120 - Epoch Loss: 10076.2897 - Avg Loss: 159.9411\n",
            "Epoch [24/50] - Batch loss: 158.5382 - Epoch Loss: 10234.8279 - Avg Loss: 159.9192\n",
            "Epoch [24/50] - Batch loss: 160.6662 - Epoch Loss: 10395.4940 - Avg Loss: 159.9307\n",
            "Epoch [24/50] - Batch loss: 154.8431 - Epoch Loss: 10550.3371 - Avg Loss: 159.8536\n",
            "Epoch [24/50] - Batch loss: 161.7581 - Epoch Loss: 10712.0952 - Avg Loss: 159.8820\n",
            "Epoch [24/50] - Batch loss: 164.6372 - Epoch Loss: 10876.7324 - Avg Loss: 159.9519\n",
            "Epoch [24/50] - Batch loss: 152.3947 - Epoch Loss: 11029.1270 - Avg Loss: 159.8424\n",
            "Epoch [24/50] - Batch loss: 158.2923 - Epoch Loss: 11187.4194 - Avg Loss: 159.8203\n",
            "Epoch [24/50] - Batch loss: 158.4101 - Epoch Loss: 11345.8295 - Avg Loss: 159.8004\n",
            "Epoch [24/50] - Batch loss: 156.4258 - Epoch Loss: 11502.2553 - Avg Loss: 159.7535\n",
            "Epoch [24/50] - Batch loss: 163.2716 - Epoch Loss: 11665.5269 - Avg Loss: 159.8017\n",
            "Epoch [24/50] - Batch loss: 156.0656 - Epoch Loss: 11821.5925 - Avg Loss: 159.7513\n",
            "Epoch [24/50] - Batch loss: 156.4330 - Epoch Loss: 11978.0255 - Avg Loss: 159.7070\n",
            "Epoch [24/50] - Batch loss: 162.0628 - Epoch Loss: 12140.0883 - Avg Loss: 159.7380\n",
            "Epoch [24/50] - Batch loss: 159.5115 - Epoch Loss: 12299.5998 - Avg Loss: 159.7351\n",
            "Epoch [24/50] - Batch loss: 154.1664 - Epoch Loss: 12453.7662 - Avg Loss: 159.6637\n",
            "Epoch [24/50] - Batch loss: 163.5724 - Epoch Loss: 12617.3386 - Avg Loss: 159.7131\n",
            "Epoch [24/50] - Batch loss: 157.4651 - Epoch Loss: 12774.8036 - Avg Loss: 159.6850\n",
            "Epoch [24/50] - Batch loss: 166.7689 - Epoch Loss: 12941.5725 - Avg Loss: 159.7725\n",
            "Epoch [24/50] - Batch loss: 155.9332 - Epoch Loss: 13097.5058 - Avg Loss: 159.7257\n",
            "Epoch [24/50] - Batch loss: 161.4998 - Epoch Loss: 13259.0056 - Avg Loss: 159.7471\n",
            "Epoch [24/50] - Batch loss: 153.9517 - Epoch Loss: 13412.9573 - Avg Loss: 159.6781\n",
            "Epoch [24/50] - Batch loss: 160.4834 - Epoch Loss: 13573.4407 - Avg Loss: 159.6875\n",
            "Epoch [24/50] - Batch loss: 165.8936 - Epoch Loss: 13739.3344 - Avg Loss: 159.7597\n",
            "Epoch [24/50] - Batch loss: 153.7572 - Epoch Loss: 13893.0915 - Avg Loss: 159.6907\n",
            "Epoch [24/50] - Batch loss: 151.8809 - Epoch Loss: 14044.9724 - Avg Loss: 159.6020\n",
            "Epoch [24/50] - Batch loss: 162.2160 - Epoch Loss: 14207.1885 - Avg Loss: 159.6313\n",
            "Epoch [24/50] - Batch loss: 158.0161 - Epoch Loss: 14365.2046 - Avg Loss: 159.6134\n",
            "Epoch [24/50] - Batch loss: 161.3190 - Epoch Loss: 14526.5236 - Avg Loss: 159.6321\n",
            "Epoch [24/50] - Batch loss: 158.1115 - Epoch Loss: 14684.6351 - Avg Loss: 159.6156\n",
            "Epoch [24/50] - Batch loss: 159.0378 - Epoch Loss: 14843.6729 - Avg Loss: 159.6094\n",
            "Epoch [24/50] - Batch loss: 153.1532 - Epoch Loss: 14996.8260 - Avg Loss: 159.5407\n",
            "Epoch [24/50] - Batch loss: 154.3727 - Epoch Loss: 15151.1987 - Avg Loss: 159.4863\n",
            "Epoch [24/50] - Batch loss: 158.6634 - Epoch Loss: 15309.8622 - Avg Loss: 159.4777\n",
            "Epoch [24/50] - Batch loss: 158.5058 - Epoch Loss: 15468.3679 - Avg Loss: 159.4677\n",
            "Epoch [24/50] - Batch loss: 159.7112 - Epoch Loss: 15628.0791 - Avg Loss: 159.4702\n",
            "Epoch [24/50] - Batch loss: 161.3763 - Epoch Loss: 15789.4554 - Avg Loss: 159.4894\n",
            "Epoch [24/50] - Batch loss: 160.2827 - Epoch Loss: 15949.7381 - Avg Loss: 159.4974\n",
            "Epoch [24/50] - Batch loss: 160.7159 - Epoch Loss: 16110.4540 - Avg Loss: 159.5094\n",
            "Epoch [24/50] - Batch loss: 152.6689 - Epoch Loss: 16263.1229 - Avg Loss: 159.4424\n",
            "Epoch [24/50] - Batch loss: 160.1780 - Epoch Loss: 16423.3009 - Avg Loss: 159.4495\n",
            "Epoch [24/50] - Batch loss: 151.0671 - Epoch Loss: 16574.3679 - Avg Loss: 159.3689\n",
            "Epoch [24/50] - Batch loss: 165.3684 - Epoch Loss: 16739.7363 - Avg Loss: 159.4261\n",
            "Epoch [24/50] - Batch loss: 160.3130 - Epoch Loss: 16900.0493 - Avg Loss: 159.4344\n",
            "Epoch [24/50] - Batch loss: 156.0200 - Epoch Loss: 17056.0693 - Avg Loss: 159.4025\n",
            "Epoch [24/50] - Batch loss: 161.3339 - Epoch Loss: 17217.4032 - Avg Loss: 159.4204\n",
            "Epoch [24/50] - Batch loss: 155.2146 - Epoch Loss: 17372.6178 - Avg Loss: 159.3818\n",
            "Epoch [24/50] - Batch loss: 158.2770 - Epoch Loss: 17530.8948 - Avg Loss: 159.3718\n",
            "Epoch [24/50] - Batch loss: 154.0398 - Epoch Loss: 17684.9346 - Avg Loss: 159.3237\n",
            "Epoch [24/50] - Batch loss: 164.4628 - Epoch Loss: 17849.3974 - Avg Loss: 159.3696\n",
            "Epoch [24/50] - Batch loss: 164.1282 - Epoch Loss: 18013.5256 - Avg Loss: 159.4117\n",
            "Epoch [24/50] - Batch loss: 157.4839 - Epoch Loss: 18171.0095 - Avg Loss: 159.3948\n",
            "Epoch [24/50] - Batch loss: 159.5427 - Epoch Loss: 18330.5522 - Avg Loss: 159.3961\n",
            "Epoch [24/50] - Batch loss: 158.1267 - Epoch Loss: 18488.6789 - Avg Loss: 159.3852\n",
            "Epoch [24/50] - Batch loss: 155.3583 - Epoch Loss: 18644.0372 - Avg Loss: 159.3507\n",
            "Epoch [24/50] - Batch loss: 159.9457 - Epoch Loss: 18803.9829 - Avg Loss: 159.3558\n",
            "Epoch [24/50] - Batch loss: 163.9869 - Epoch Loss: 18967.9698 - Avg Loss: 159.3947\n",
            "Epoch [24/50] - Batch loss: 154.5968 - Epoch Loss: 19122.5666 - Avg Loss: 159.3547\n",
            "Epoch [24/50] - Batch loss: 172.9342 - Epoch Loss: 19295.5008 - Avg Loss: 159.4669\n",
            "Epoch [24/50] - Batch loss: 154.5362 - Epoch Loss: 19450.0370 - Avg Loss: 159.4265\n",
            "Epoch [24/50] - Batch loss: 161.7215 - Epoch Loss: 19611.7585 - Avg Loss: 159.4452\n",
            "Epoch [24/50] - Batch loss: 154.9409 - Epoch Loss: 19766.6994 - Avg Loss: 159.4089\n",
            "Epoch [24/50] - Batch loss: 160.9017 - Epoch Loss: 19927.6011 - Avg Loss: 159.4208\n",
            "Epoch [24/50] - Batch loss: 163.6545 - Epoch Loss: 20091.2556 - Avg Loss: 159.4544\n",
            "Epoch [24/50] - Batch loss: 160.8952 - Epoch Loss: 20252.1509 - Avg Loss: 159.4658\n",
            "Epoch [24/50] - Batch loss: 154.4780 - Epoch Loss: 20406.6288 - Avg Loss: 159.4268\n",
            "Epoch [24/50] - Batch loss: 156.5210 - Epoch Loss: 20563.1498 - Avg Loss: 159.4043\n",
            "Epoch [24/50] - Batch loss: 158.0590 - Epoch Loss: 20721.2088 - Avg Loss: 159.3939\n",
            "Epoch [24/50] - Batch loss: 161.5469 - Epoch Loss: 20882.7556 - Avg Loss: 159.4103\n",
            "Epoch [24/50] - Batch loss: 156.2624 - Epoch Loss: 21039.0181 - Avg Loss: 159.3865\n",
            "Epoch [24/50] - Batch loss: 160.0438 - Epoch Loss: 21199.0619 - Avg Loss: 159.3914\n",
            "Epoch [24/50] - Batch loss: 156.1798 - Epoch Loss: 21355.2417 - Avg Loss: 159.3675\n",
            "Epoch [24/50] - Batch loss: 153.6801 - Epoch Loss: 21508.9217 - Avg Loss: 159.3253\n",
            "Epoch [24/50] - Batch loss: 164.8068 - Epoch Loss: 21673.7285 - Avg Loss: 159.3657\n",
            "Epoch [24/50] - Batch loss: 155.3486 - Epoch Loss: 21829.0771 - Avg Loss: 159.3363\n",
            "Epoch [24/50] - Batch loss: 159.0429 - Epoch Loss: 21988.1200 - Avg Loss: 159.3342\n",
            "Epoch [24/50] - Batch loss: 152.2487 - Epoch Loss: 22140.3688 - Avg Loss: 159.2832\n",
            "Epoch [24/50] - Batch loss: 160.6404 - Epoch Loss: 22301.0091 - Avg Loss: 159.2929\n",
            "Epoch [24/50] - Batch loss: 152.9501 - Epoch Loss: 22453.9592 - Avg Loss: 159.2479\n",
            "Epoch [24/50] - Batch loss: 156.4189 - Epoch Loss: 22610.3781 - Avg Loss: 159.2280\n",
            "Epoch [24/50] - Batch loss: 157.4683 - Epoch Loss: 22767.8465 - Avg Loss: 159.2157\n",
            "Epoch [24/50] - Batch loss: 155.3989 - Epoch Loss: 22923.2453 - Avg Loss: 159.1892\n",
            "Epoch [24/50] - Batch loss: 158.1170 - Epoch Loss: 23081.3623 - Avg Loss: 159.1818\n",
            "Epoch [24/50] - Batch loss: 159.4401 - Epoch Loss: 23240.8024 - Avg Loss: 159.1836\n",
            "Epoch [24/50] - Batch loss: 155.3498 - Epoch Loss: 23396.1522 - Avg Loss: 159.1575\n",
            "Epoch [24/50] - Batch loss: 158.5914 - Epoch Loss: 23554.7436 - Avg Loss: 159.1537\n",
            "Epoch [24/50] - Batch loss: 157.3056 - Epoch Loss: 23712.0492 - Avg Loss: 159.1413\n",
            "Epoch [24/50] - Batch loss: 156.6046 - Epoch Loss: 23868.6538 - Avg Loss: 159.1244\n",
            "Epoch [24/50] - Batch loss: 160.9940 - Epoch Loss: 24029.6478 - Avg Loss: 159.1367\n",
            "Epoch [24/50] - Batch loss: 156.0111 - Epoch Loss: 24185.6590 - Avg Loss: 159.1162\n",
            "Epoch [24/50] - Batch loss: 154.8755 - Epoch Loss: 24340.5345 - Avg Loss: 159.0885\n",
            "Epoch [24/50] - Batch loss: 155.2205 - Epoch Loss: 24495.7550 - Avg Loss: 159.0633\n",
            "Epoch [24/50] - Batch loss: 157.8327 - Epoch Loss: 24653.5876 - Avg Loss: 159.0554\n",
            "Epoch [24/50] - Batch loss: 156.8813 - Epoch Loss: 24810.4690 - Avg Loss: 159.0415\n",
            "Epoch [24/50] - Batch loss: 155.6362 - Epoch Loss: 24966.1052 - Avg Loss: 159.0198\n",
            "Epoch [24/50] - Batch loss: 155.0171 - Epoch Loss: 25121.1223 - Avg Loss: 158.9944\n",
            "Epoch [24/50] - Batch loss: 159.2206 - Epoch Loss: 25280.3428 - Avg Loss: 158.9959\n",
            "Epoch [24/50] - Batch loss: 158.4875 - Epoch Loss: 25438.8304 - Avg Loss: 158.9927\n",
            "Epoch [24/50] - Batch loss: 160.9016 - Epoch Loss: 25599.7319 - Avg Loss: 159.0045\n",
            "Epoch [24/50] - Batch loss: 157.2943 - Epoch Loss: 25757.0263 - Avg Loss: 158.9940\n",
            "Epoch [24/50] - Batch loss: 168.6457 - Epoch Loss: 25925.6720 - Avg Loss: 159.0532\n",
            "Epoch [24/50] - Batch loss: 163.5257 - Epoch Loss: 26089.1976 - Avg Loss: 159.0805\n",
            "Epoch [24/50] - Batch loss: 156.0950 - Epoch Loss: 26245.2927 - Avg Loss: 159.0624\n",
            "Epoch [24/50] - Batch loss: 154.6283 - Epoch Loss: 26399.9210 - Avg Loss: 159.0357\n",
            "Epoch [24/50] - Batch loss: 157.5124 - Epoch Loss: 26557.4334 - Avg Loss: 159.0265\n",
            "Epoch [24/50] - Batch loss: 158.2269 - Epoch Loss: 26715.6603 - Avg Loss: 159.0218\n",
            "Epoch [24/50] - Batch loss: 165.2344 - Epoch Loss: 26880.8947 - Avg Loss: 159.0585\n",
            "Epoch [24/50] - Batch loss: 155.6617 - Epoch Loss: 27036.5564 - Avg Loss: 159.0386\n",
            "Epoch [24/50] - Batch loss: 158.1197 - Epoch Loss: 27194.6761 - Avg Loss: 159.0332\n",
            "Epoch [24/50] - Batch loss: 153.2954 - Epoch Loss: 27347.9715 - Avg Loss: 158.9998\n",
            "Epoch [24/50] - Batch loss: 172.0895 - Epoch Loss: 27520.0611 - Avg Loss: 159.0755\n",
            "Epoch [24/50] - Batch loss: 160.2147 - Epoch Loss: 27680.2758 - Avg Loss: 159.0820\n",
            "Epoch [24/50] - Batch loss: 154.2242 - Epoch Loss: 27834.5000 - Avg Loss: 159.0543\n",
            "Epoch [24/50] - Batch loss: 156.6370 - Epoch Loss: 27991.1370 - Avg Loss: 159.0406\n",
            "Epoch [24/50] - Batch loss: 154.8584 - Epoch Loss: 28145.9955 - Avg Loss: 159.0169\n",
            "Epoch [24/50] - Batch loss: 152.7081 - Epoch Loss: 28298.7036 - Avg Loss: 158.9815\n",
            "Epoch [24/50] - Batch loss: 151.6297 - Epoch Loss: 28450.3332 - Avg Loss: 158.9404\n",
            "Epoch [24/50] - Batch loss: 153.3024 - Epoch Loss: 28603.6356 - Avg Loss: 158.9091\n",
            "Epoch [24/50] - Batch loss: 152.9861 - Epoch Loss: 28756.6217 - Avg Loss: 158.8764\n",
            "Epoch [24/50] - Batch loss: 159.4064 - Epoch Loss: 28916.0281 - Avg Loss: 158.8793\n",
            "Epoch [24/50] - Batch loss: 163.1049 - Epoch Loss: 29079.1330 - Avg Loss: 158.9024\n",
            "Epoch [24/50] - Batch loss: 155.5836 - Epoch Loss: 29234.7166 - Avg Loss: 158.8843\n",
            "Epoch [24/50] - Batch loss: 160.4213 - Epoch Loss: 29395.1380 - Avg Loss: 158.8926\n",
            "Epoch [24/50] - Batch loss: 167.9610 - Epoch Loss: 29563.0990 - Avg Loss: 158.9414\n",
            "Epoch [24/50] - Batch loss: 156.5041 - Epoch Loss: 29719.6031 - Avg Loss: 158.9284\n",
            "Epoch [24/50] - Batch loss: 164.3956 - Epoch Loss: 29883.9987 - Avg Loss: 158.9574\n",
            "Epoch [24/50] - Batch loss: 165.8651 - Epoch Loss: 30049.8638 - Avg Loss: 158.9940\n",
            "Epoch [24/50] - Batch loss: 164.2864 - Epoch Loss: 30214.1502 - Avg Loss: 159.0218\n",
            "Epoch [24/50] - Batch loss: 165.7289 - Epoch Loss: 30379.8791 - Avg Loss: 159.0570\n",
            "Epoch [24/50] - Batch loss: 156.3472 - Epoch Loss: 30536.2263 - Avg Loss: 159.0428\n",
            "Epoch [24/50] - Batch loss: 156.4711 - Epoch Loss: 30692.6973 - Avg Loss: 159.0295\n",
            "Epoch [24/50] - Batch loss: 156.3711 - Epoch Loss: 30849.0685 - Avg Loss: 159.0158\n",
            "Epoch [24/50] - Batch loss: 161.2110 - Epoch Loss: 31010.2794 - Avg Loss: 159.0271\n",
            "Epoch [24/50] - Batch loss: 165.1816 - Epoch Loss: 31175.4611 - Avg Loss: 159.0585\n",
            "Epoch [24/50] - Batch loss: 162.3532 - Epoch Loss: 31337.8143 - Avg Loss: 159.0752\n",
            "Epoch [24/50] - Batch loss: 161.7856 - Epoch Loss: 31499.5999 - Avg Loss: 159.0889\n",
            "Epoch [24/50] - Batch loss: 157.1010 - Epoch Loss: 31656.7008 - Avg Loss: 159.0789\n",
            "Epoch [24/50] - Batch loss: 159.8142 - Epoch Loss: 31816.5150 - Avg Loss: 159.0826\n",
            "Epoch [24/50] - Batch loss: 162.9685 - Epoch Loss: 31979.4835 - Avg Loss: 159.1019\n",
            "Epoch [24/50] - Batch loss: 154.8041 - Epoch Loss: 32134.2876 - Avg Loss: 159.0806\n",
            "Epoch [24/50] - Batch loss: 160.6355 - Epoch Loss: 32294.9232 - Avg Loss: 159.0883\n",
            "Epoch [24/50] - Batch loss: 159.8905 - Epoch Loss: 32454.8137 - Avg Loss: 159.0922\n",
            "Epoch [24/50] - Batch loss: 155.7708 - Epoch Loss: 32610.5845 - Avg Loss: 159.0760\n",
            "Epoch [24/50] - Batch loss: 154.5695 - Epoch Loss: 32765.1540 - Avg Loss: 159.0541\n",
            "Epoch [24/50] - Batch loss: 156.9504 - Epoch Loss: 32922.1044 - Avg Loss: 159.0440\n",
            "Epoch [24/50] - Batch loss: 160.0780 - Epoch Loss: 33082.1824 - Avg Loss: 159.0490\n",
            "Epoch [24/50] - Batch loss: 164.8854 - Epoch Loss: 33247.0678 - Avg Loss: 159.0769\n",
            "Epoch [24/50] - Batch loss: 159.2697 - Epoch Loss: 33406.3375 - Avg Loss: 159.0778\n",
            "Epoch [24/50] - Batch loss: 162.8598 - Epoch Loss: 33569.1973 - Avg Loss: 159.0957\n",
            "Epoch [24/50] - Batch loss: 156.7522 - Epoch Loss: 33725.9495 - Avg Loss: 159.0847\n",
            "Epoch [24/50] - Batch loss: 154.8886 - Epoch Loss: 33880.8381 - Avg Loss: 159.0650\n",
            "Epoch [24/50] - Batch loss: 162.2029 - Epoch Loss: 34043.0410 - Avg Loss: 159.0796\n",
            "Epoch [24/50] - Batch loss: 161.0732 - Epoch Loss: 34204.1142 - Avg Loss: 159.0889\n",
            "Epoch [24/50] - Batch loss: 167.8658 - Epoch Loss: 34371.9800 - Avg Loss: 159.1295\n",
            "Epoch [24/50] - Batch loss: 159.5247 - Epoch Loss: 34531.5048 - Avg Loss: 159.1314\n",
            "Epoch [24/50] - Batch loss: 160.6155 - Epoch Loss: 34692.1203 - Avg Loss: 159.1382\n",
            "Epoch [24/50] - Batch loss: 157.4548 - Epoch Loss: 34849.5751 - Avg Loss: 159.1305\n",
            "Epoch [24/50] - Batch loss: 158.4505 - Epoch Loss: 35008.0256 - Avg Loss: 159.1274\n",
            "Epoch [24/50] - Batch loss: 158.4565 - Epoch Loss: 35166.4821 - Avg Loss: 159.1244\n",
            "Epoch [24/50] - Batch loss: 155.6001 - Epoch Loss: 35322.0823 - Avg Loss: 159.1085\n",
            "Epoch [24/50] - Batch loss: 163.2939 - Epoch Loss: 35485.3762 - Avg Loss: 159.1272\n",
            "Epoch [24/50] - Batch loss: 166.6309 - Epoch Loss: 35652.0071 - Avg Loss: 159.1607\n",
            "Epoch [24/50] - Batch loss: 157.9198 - Epoch Loss: 35809.9270 - Avg Loss: 159.1552\n",
            "Epoch [24/50] - Batch loss: 164.7303 - Epoch Loss: 35974.6573 - Avg Loss: 159.1799\n",
            "Epoch [24/50] - Batch loss: 158.1174 - Epoch Loss: 36132.7747 - Avg Loss: 159.1752\n",
            "Epoch [24/50] - Batch loss: 154.1265 - Epoch Loss: 36286.9012 - Avg Loss: 159.1531\n",
            "Epoch [24/50] - Batch loss: 158.9783 - Epoch Loss: 36445.8795 - Avg Loss: 159.1523\n",
            "Epoch [24/50] - Batch loss: 158.2327 - Epoch Loss: 36604.1122 - Avg Loss: 159.1483\n",
            "Epoch [24/50] - Batch loss: 155.7776 - Epoch Loss: 36759.8898 - Avg Loss: 159.1337\n",
            "Epoch [24/50] - Batch loss: 158.4240 - Epoch Loss: 36918.3138 - Avg Loss: 159.1307\n",
            "Epoch [24/50] - Batch loss: 161.3624 - Epoch Loss: 37079.6762 - Avg Loss: 159.1402\n",
            "Epoch [24/50] - Batch loss: 154.1218 - Epoch Loss: 37233.7980 - Avg Loss: 159.1188\n",
            "Epoch [24/50] - Batch loss: 158.6625 - Epoch Loss: 37392.4605 - Avg Loss: 159.1169\n",
            "Epoch [24/50] - Batch loss: 157.9601 - Epoch Loss: 37550.4206 - Avg Loss: 159.1120\n",
            "Epoch [24/50] - Batch loss: 156.1237 - Epoch Loss: 37706.5443 - Avg Loss: 159.0993\n",
            "Epoch [24/50] - Batch loss: 165.9585 - Epoch Loss: 37872.5028 - Avg Loss: 159.1282\n",
            "Epoch [24/50] - Batch loss: 151.0302 - Epoch Loss: 38023.5331 - Avg Loss: 159.0943\n",
            "Epoch [24/50] - Batch loss: 154.2170 - Epoch Loss: 38177.7501 - Avg Loss: 159.0740\n",
            "Epoch [24/50] - Batch loss: 161.7876 - Epoch Loss: 38339.5377 - Avg Loss: 159.0852\n",
            "Epoch [24/50] - Batch loss: 159.5639 - Epoch Loss: 38499.1016 - Avg Loss: 159.0872\n",
            "Epoch [24/50] - Batch loss: 158.4622 - Epoch Loss: 38657.5639 - Avg Loss: 159.0846\n",
            "Epoch [24/50] - Batch loss: 157.3087 - Epoch Loss: 38814.8726 - Avg Loss: 159.0773\n",
            "Epoch [24/50] - Batch loss: 153.5318 - Epoch Loss: 38968.4044 - Avg Loss: 159.0547\n",
            "Epoch [24/50] - Batch loss: 161.5155 - Epoch Loss: 39129.9198 - Avg Loss: 159.0647\n",
            "Epoch [24/50] - Batch loss: 160.5815 - Epoch Loss: 39290.5014 - Avg Loss: 159.0709\n",
            "Epoch [24/50] - Batch loss: 168.6570 - Epoch Loss: 39459.1584 - Avg Loss: 159.1095\n",
            "Epoch [24/50] - Batch loss: 161.1288 - Epoch Loss: 39620.2872 - Avg Loss: 159.1176\n",
            "Epoch [24/50] - Batch loss: 161.6877 - Epoch Loss: 39781.9749 - Avg Loss: 159.1279\n",
            "Epoch [24/50] - Batch loss: 155.8064 - Epoch Loss: 39937.7812 - Avg Loss: 159.1147\n",
            "Epoch [24/50] - Batch loss: 158.2387 - Epoch Loss: 40096.0199 - Avg Loss: 159.1112\n",
            "Epoch [24/50] - Batch loss: 152.3901 - Epoch Loss: 40248.4100 - Avg Loss: 159.0846\n",
            "Epoch [24/50] - Batch loss: 158.8326 - Epoch Loss: 40407.2427 - Avg Loss: 159.0836\n",
            "Epoch [24/50] - Batch loss: 166.1714 - Epoch Loss: 40573.4141 - Avg Loss: 159.1114\n",
            "Epoch [24/50] - Batch loss: 156.2992 - Epoch Loss: 40729.7133 - Avg Loss: 159.1004\n",
            "Epoch [24/50] - Batch loss: 157.8567 - Epoch Loss: 40887.5700 - Avg Loss: 159.0956\n",
            "Epoch [24/50] - Batch loss: 156.0794 - Epoch Loss: 41043.6494 - Avg Loss: 159.0839\n",
            "Epoch [24/50] - Batch loss: 154.2237 - Epoch Loss: 41197.8731 - Avg Loss: 159.0651\n",
            "Epoch [24/50] - Batch loss: 156.4894 - Epoch Loss: 41354.3625 - Avg Loss: 159.0552\n",
            "Epoch [24/50] - Batch loss: 161.6966 - Epoch Loss: 41516.0591 - Avg Loss: 159.0654\n",
            "Epoch [24/50] - Batch loss: 149.0848 - Epoch Loss: 41665.1439 - Avg Loss: 159.0273\n",
            "Epoch [24/50] - Batch loss: 158.2581 - Epoch Loss: 41823.4019 - Avg Loss: 159.0243\n",
            "Epoch [24/50] - Batch loss: 153.8781 - Epoch Loss: 41977.2800 - Avg Loss: 159.0048\n",
            "Epoch [24/50] - Batch loss: 161.7031 - Epoch Loss: 42138.9831 - Avg Loss: 159.0150\n",
            "Epoch [24/50] - Batch loss: 159.0745 - Epoch Loss: 42298.0576 - Avg Loss: 159.0153\n",
            "Epoch [24/50] - Batch loss: 156.4948 - Epoch Loss: 42454.5524 - Avg Loss: 159.0058\n",
            "Epoch [24/50] - Batch loss: 158.4189 - Epoch Loss: 42612.9713 - Avg Loss: 159.0036\n",
            "Epoch [24/50] - Batch loss: 160.9855 - Epoch Loss: 42773.9568 - Avg Loss: 159.0110\n",
            "Epoch [24/50] - Batch loss: 162.2906 - Epoch Loss: 42936.2474 - Avg Loss: 159.0231\n",
            "Epoch [24/50] - Batch loss: 154.5720 - Epoch Loss: 43090.8194 - Avg Loss: 159.0067\n",
            "Epoch [24/50] - Batch loss: 161.2278 - Epoch Loss: 43252.0472 - Avg Loss: 159.0149\n",
            "Epoch [24/50] - Batch loss: 147.9000 - Epoch Loss: 43399.9472 - Avg Loss: 158.9742\n",
            "Epoch [24/50] - Batch loss: 167.5782 - Epoch Loss: 43567.5255 - Avg Loss: 159.0056\n",
            "Epoch [24/50] - Batch loss: 152.7975 - Epoch Loss: 43720.3229 - Avg Loss: 158.9830\n",
            "Epoch [24/50] - Batch loss: 155.8878 - Epoch Loss: 43876.2108 - Avg Loss: 158.9718\n",
            "Epoch [24/50] - Batch loss: 151.1566 - Epoch Loss: 44027.3674 - Avg Loss: 158.9436\n",
            "Epoch [24/50] - Batch loss: 161.9465 - Epoch Loss: 44189.3138 - Avg Loss: 158.9544\n",
            "Epoch [24/50] - Batch loss: 170.5487 - Epoch Loss: 44359.8626 - Avg Loss: 158.9959\n",
            "Epoch [24/50] - Batch loss: 157.8133 - Epoch Loss: 44517.6759 - Avg Loss: 158.9917\n",
            "Epoch [24/50] - Batch loss: 165.5931 - Epoch Loss: 44683.2690 - Avg Loss: 159.0152\n",
            "Epoch [24/50] - Batch loss: 161.9056 - Epoch Loss: 44845.1746 - Avg Loss: 159.0254\n",
            "Epoch [24/50] - Batch loss: 161.3967 - Epoch Loss: 45006.5713 - Avg Loss: 159.0338\n",
            "Epoch [24/50] - Batch loss: 160.0877 - Epoch Loss: 45166.6590 - Avg Loss: 159.0375\n",
            "Epoch [24/50] - Batch loss: 158.4552 - Epoch Loss: 45325.1142 - Avg Loss: 159.0355\n",
            "Epoch [24/50] - Batch loss: 156.1778 - Epoch Loss: 45481.2920 - Avg Loss: 159.0255\n",
            "Epoch [24/50] - Batch loss: 150.1295 - Epoch Loss: 45631.4215 - Avg Loss: 158.9945\n",
            "Epoch [24/50] - Batch loss: 163.1593 - Epoch Loss: 45794.5807 - Avg Loss: 159.0090\n",
            "Epoch [24/50] - Batch loss: 170.3951 - Epoch Loss: 45964.9758 - Avg Loss: 159.0484\n",
            "Epoch [24/50] - Batch loss: 166.4597 - Epoch Loss: 46131.4355 - Avg Loss: 159.0739\n",
            "Epoch [24/50] - Batch loss: 154.3802 - Epoch Loss: 46285.8157 - Avg Loss: 159.0578\n",
            "Epoch [24/50] - Batch loss: 157.1404 - Epoch Loss: 46442.9560 - Avg Loss: 159.0512\n",
            "Epoch [24/50] - Batch loss: 157.4218 - Epoch Loss: 46600.3778 - Avg Loss: 159.0457\n",
            "Epoch [24/50] - Batch loss: 160.1325 - Epoch Loss: 46760.5103 - Avg Loss: 159.0494\n",
            "Epoch [24/50] - Batch loss: 153.6030 - Epoch Loss: 46914.1134 - Avg Loss: 159.0309\n",
            "Epoch [24/50] - Batch loss: 147.9786 - Epoch Loss: 47062.0920 - Avg Loss: 158.9936\n",
            "Epoch [24/50] - Batch loss: 160.7849 - Epoch Loss: 47222.8768 - Avg Loss: 158.9996\n",
            "Epoch [24/50] - Batch loss: 158.7488 - Epoch Loss: 47381.6257 - Avg Loss: 158.9987\n",
            "Epoch [24/50] - Batch loss: 161.3308 - Epoch Loss: 47542.9565 - Avg Loss: 159.0065\n",
            "Epoch [24/50] - Batch loss: 159.4268 - Epoch Loss: 47702.3833 - Avg Loss: 159.0079\n",
            "Epoch [24/50] - Batch loss: 167.3491 - Epoch Loss: 47869.7324 - Avg Loss: 159.0357\n",
            "Epoch [24/50] - Batch loss: 160.7383 - Epoch Loss: 48030.4707 - Avg Loss: 159.0413\n",
            "Epoch [24/50] - Batch loss: 161.6118 - Epoch Loss: 48192.0825 - Avg Loss: 159.0498\n",
            "Epoch [24/50] - Batch loss: 160.2520 - Epoch Loss: 48352.3345 - Avg Loss: 159.0537\n",
            "Epoch [24/50] - Batch loss: 150.3820 - Epoch Loss: 48502.7166 - Avg Loss: 159.0253\n",
            "Epoch [24/50] - Batch loss: 149.7241 - Epoch Loss: 48652.4407 - Avg Loss: 158.9949\n",
            "Epoch [24/50] - Batch loss: 164.6244 - Epoch Loss: 48817.0651 - Avg Loss: 159.0132\n",
            "Epoch [24/50] - Batch loss: 160.7334 - Epoch Loss: 48977.7985 - Avg Loss: 159.0188\n",
            "Epoch [24/50] - Batch loss: 162.2358 - Epoch Loss: 49140.0343 - Avg Loss: 159.0292\n",
            "Epoch [24/50] - Batch loss: 163.6109 - Epoch Loss: 49303.6452 - Avg Loss: 159.0440\n",
            "Epoch [24/50] - Batch loss: 162.5299 - Epoch Loss: 49466.1751 - Avg Loss: 159.0552\n",
            "Epoch [24/50] - Batch loss: 163.5631 - Epoch Loss: 49629.7382 - Avg Loss: 159.0697\n",
            "Epoch [24/50] - Batch loss: 156.9785 - Epoch Loss: 49786.7166 - Avg Loss: 159.0630\n",
            "Epoch [24/50] - Batch loss: 169.5170 - Epoch Loss: 49956.2336 - Avg Loss: 159.0963\n",
            "Epoch [24/50] - Batch loss: 167.6003 - Epoch Loss: 50123.8340 - Avg Loss: 159.1233\n",
            "Epoch [24/50] - Batch loss: 154.9948 - Epoch Loss: 50278.8288 - Avg Loss: 159.1102\n",
            "Epoch [24/50] - Batch loss: 156.1569 - Epoch Loss: 50434.9857 - Avg Loss: 159.1009\n",
            "Epoch [24/50] - Batch loss: 163.2258 - Epoch Loss: 50598.2115 - Avg Loss: 159.1139\n",
            "Epoch [24/50] - Batch loss: 162.3480 - Epoch Loss: 50760.5594 - Avg Loss: 159.1240\n",
            "Epoch [24/50] - Batch loss: 173.0577 - Epoch Loss: 50933.6171 - Avg Loss: 159.1676\n",
            "Epoch [24/50] - Batch loss: 156.2588 - Epoch Loss: 51089.8759 - Avg Loss: 159.1585\n",
            "Epoch [24/50] - Batch loss: 161.5950 - Epoch Loss: 51251.4709 - Avg Loss: 159.1661\n",
            "Epoch [24/50] - Batch loss: 162.1206 - Epoch Loss: 51413.5915 - Avg Loss: 159.1752\n",
            "Epoch [24/50] - Batch loss: 164.6184 - Epoch Loss: 51578.2099 - Avg Loss: 159.1920\n",
            "Epoch [24/50] - Batch loss: 160.1499 - Epoch Loss: 51738.3598 - Avg Loss: 159.1950\n",
            "Epoch [24/50] - Batch loss: 159.4104 - Epoch Loss: 51897.7702 - Avg Loss: 159.1956\n",
            "Epoch [24/50] - Batch loss: 149.9728 - Epoch Loss: 52047.7430 - Avg Loss: 159.1674\n",
            "Epoch [24/50] - Batch loss: 163.7234 - Epoch Loss: 52211.4664 - Avg Loss: 159.1813\n",
            "Epoch [24/50] - Batch loss: 166.2405 - Epoch Loss: 52377.7069 - Avg Loss: 159.2028\n",
            "Epoch [24/50] - Batch loss: 156.3983 - Epoch Loss: 52534.1052 - Avg Loss: 159.1943\n",
            "Epoch [24/50] - Batch loss: 154.0395 - Epoch Loss: 52688.1447 - Avg Loss: 159.1787\n",
            "Epoch [24/50] - Batch loss: 165.9610 - Epoch Loss: 52854.1057 - Avg Loss: 159.1991\n",
            "Epoch [24/50] - Batch loss: 157.9308 - Epoch Loss: 53012.0365 - Avg Loss: 159.1953\n",
            "Epoch [24/50] - Batch loss: 148.1373 - Epoch Loss: 53160.1738 - Avg Loss: 159.1622\n",
            "Epoch [24/50] - Batch loss: 159.5919 - Epoch Loss: 53319.7657 - Avg Loss: 159.1635\n",
            "Epoch [24/50] - Batch loss: 163.2584 - Epoch Loss: 53483.0242 - Avg Loss: 159.1757\n",
            "Epoch [24/50] - Batch loss: 164.7426 - Epoch Loss: 53647.7668 - Avg Loss: 159.1922\n",
            "Epoch [24/50] - Batch loss: 155.8251 - Epoch Loss: 53803.5919 - Avg Loss: 159.1822\n",
            "Epoch [24/50] - Batch loss: 157.0223 - Epoch Loss: 53960.6142 - Avg Loss: 159.1759\n",
            "Epoch [24/50] - Batch loss: 156.8474 - Epoch Loss: 54117.4616 - Avg Loss: 159.1690\n",
            "Epoch [24/50] - Batch loss: 155.7812 - Epoch Loss: 54273.2428 - Avg Loss: 159.1591\n",
            "Epoch [24/50] - Batch loss: 155.9958 - Epoch Loss: 54429.2386 - Avg Loss: 159.1498\n",
            "Epoch [24/50] - Batch loss: 152.7803 - Epoch Loss: 54582.0189 - Avg Loss: 159.1313\n",
            "Epoch [24/50] - Batch loss: 157.9749 - Epoch Loss: 54739.9938 - Avg Loss: 159.1279\n",
            "Epoch [24/50] - Batch loss: 151.6501 - Epoch Loss: 54891.6439 - Avg Loss: 159.1062\n",
            "Epoch [24/50] - Batch loss: 157.5486 - Epoch Loss: 55049.1926 - Avg Loss: 159.1017\n",
            "Epoch [24/50] - Batch loss: 162.2628 - Epoch Loss: 55211.4553 - Avg Loss: 159.1108\n",
            "Epoch [24/50] - Batch loss: 160.9501 - Epoch Loss: 55372.4054 - Avg Loss: 159.1161\n",
            "Epoch [24/50] - Batch loss: 165.7389 - Epoch Loss: 55538.1444 - Avg Loss: 159.1351\n",
            "Epoch [24/50] - Batch loss: 152.3864 - Epoch Loss: 55690.5308 - Avg Loss: 159.1158\n",
            "Epoch [24/50] - Batch loss: 161.4667 - Epoch Loss: 55851.9975 - Avg Loss: 159.1225\n",
            "Epoch [24/50] - Batch loss: 157.6615 - Epoch Loss: 56009.6589 - Avg Loss: 159.1183\n",
            "Epoch [24/50] - Batch loss: 160.0751 - Epoch Loss: 56169.7340 - Avg Loss: 159.1211\n",
            "Epoch [24/50] - Batch loss: 164.3705 - Epoch Loss: 56334.1045 - Avg Loss: 159.1359\n",
            "Epoch [24/50] - Batch loss: 152.4077 - Epoch Loss: 56486.5122 - Avg Loss: 159.1169\n",
            "Epoch [24/50] - Batch loss: 160.4588 - Epoch Loss: 56646.9710 - Avg Loss: 159.1207\n",
            "Epoch [24/50] - Batch loss: 160.9584 - Epoch Loss: 56807.9294 - Avg Loss: 159.1259\n",
            "Epoch [24/50] - Batch loss: 159.7890 - Epoch Loss: 56967.7184 - Avg Loss: 159.1277\n",
            "Epoch [24/50] - Batch loss: 159.8481 - Epoch Loss: 57127.5665 - Avg Loss: 159.1297\n",
            "Epoch [24/50] - Batch loss: 155.6624 - Epoch Loss: 57283.2289 - Avg Loss: 159.1201\n",
            "Epoch [24/50] - Batch loss: 156.9116 - Epoch Loss: 57440.1405 - Avg Loss: 159.1140\n",
            "Epoch [24/50] - Batch loss: 160.1452 - Epoch Loss: 57600.2857 - Avg Loss: 159.1168\n",
            "Epoch [24/50] - Batch loss: 162.4499 - Epoch Loss: 57762.7356 - Avg Loss: 159.1260\n",
            "Epoch [24/50] - Batch loss: 162.1510 - Epoch Loss: 57924.8866 - Avg Loss: 159.1343\n",
            "Epoch [24/50] - Batch loss: 159.8903 - Epoch Loss: 58084.7769 - Avg Loss: 159.1364\n",
            "Epoch [24/50] - Batch loss: 169.6483 - Epoch Loss: 58254.4252 - Avg Loss: 159.1651\n",
            "Epoch [24/50] - Batch loss: 159.7925 - Epoch Loss: 58414.2177 - Avg Loss: 159.1668\n",
            "Epoch [24/50] - Batch loss: 163.0296 - Epoch Loss: 58577.2473 - Avg Loss: 159.1773\n",
            "Epoch [24/50] - Batch loss: 164.4996 - Epoch Loss: 58741.7469 - Avg Loss: 159.1917\n",
            "Epoch [24/50] - Batch loss: 148.1081 - Epoch Loss: 58889.8550 - Avg Loss: 159.1618\n",
            "Epoch [24/50] - Batch loss: 164.5659 - Epoch Loss: 59054.4209 - Avg Loss: 159.1763\n",
            "Epoch [24/50] - Batch loss: 160.5233 - Epoch Loss: 59214.9443 - Avg Loss: 159.1800\n",
            "Epoch [24/50] - Batch loss: 156.9987 - Epoch Loss: 59371.9429 - Avg Loss: 159.1741\n",
            "Epoch [24/50] - Batch loss: 155.4450 - Epoch Loss: 59527.3879 - Avg Loss: 159.1641\n",
            "Epoch [24/50] - Batch loss: 154.9805 - Epoch Loss: 59682.3684 - Avg Loss: 159.1530\n",
            "Epoch [24/50] - Batch loss: 161.9739 - Epoch Loss: 59844.3423 - Avg Loss: 159.1605\n",
            "Epoch [24/50] - Batch loss: 156.8544 - Epoch Loss: 60001.1967 - Avg Loss: 159.1544\n",
            "Epoch [24/50] - Batch loss: 156.1738 - Epoch Loss: 60157.3705 - Avg Loss: 159.1465\n",
            "Epoch [24/50] - Batch loss: 158.7353 - Epoch Loss: 60316.1058 - Avg Loss: 159.1454\n",
            "Epoch [24/50] - Batch loss: 159.7726 - Epoch Loss: 60475.8783 - Avg Loss: 159.1470\n",
            "Epoch [24/50] - Batch loss: 163.0009 - Epoch Loss: 60638.8793 - Avg Loss: 159.1572\n",
            "Epoch [24/50] - Batch loss: 151.2078 - Epoch Loss: 60790.0870 - Avg Loss: 159.1364\n",
            "Epoch [24/50] - Batch loss: 156.2133 - Epoch Loss: 60946.3004 - Avg Loss: 159.1287\n",
            "Epoch [24/50] - Batch loss: 157.0718 - Epoch Loss: 61103.3722 - Avg Loss: 159.1234\n",
            "Epoch [24/50] - Batch loss: 150.8447 - Epoch Loss: 61254.2169 - Avg Loss: 159.1019\n",
            "Epoch [24/50] - Batch loss: 158.8446 - Epoch Loss: 61413.0615 - Avg Loss: 159.1012\n",
            "Epoch [24/50] - Batch loss: 158.3411 - Epoch Loss: 61571.4026 - Avg Loss: 159.0992\n",
            "Epoch [24/50] - Batch loss: 160.2594 - Epoch Loss: 61731.6620 - Avg Loss: 159.1022\n",
            "Epoch [24/50] - Batch loss: 153.2970 - Epoch Loss: 61884.9589 - Avg Loss: 159.0873\n",
            "Epoch [24/50] - Batch loss: 160.2008 - Epoch Loss: 62045.1597 - Avg Loss: 159.0902\n",
            "Epoch [24/50] - Batch loss: 158.0624 - Epoch Loss: 62203.2222 - Avg Loss: 159.0875\n",
            "Epoch [24/50] - Batch loss: 161.4572 - Epoch Loss: 62364.6794 - Avg Loss: 159.0936\n",
            "Epoch [24/50] - Batch loss: 154.2391 - Epoch Loss: 62518.9185 - Avg Loss: 159.0812\n",
            "Epoch [24/50] - Batch loss: 157.1735 - Epoch Loss: 62676.0919 - Avg Loss: 159.0764\n",
            "Epoch [24/50] - Batch loss: 162.9179 - Epoch Loss: 62839.0099 - Avg Loss: 159.0861\n",
            "Epoch [24/50] - Batch loss: 157.3165 - Epoch Loss: 62996.3263 - Avg Loss: 159.0816\n",
            "Epoch [24/50] - Batch loss: 153.2863 - Epoch Loss: 63149.6127 - Avg Loss: 159.0670\n",
            "Epoch [24/50] - Batch loss: 156.4420 - Epoch Loss: 63306.0547 - Avg Loss: 159.0604\n",
            "Epoch [24/50] - Batch loss: 153.8600 - Epoch Loss: 63459.9147 - Avg Loss: 159.0474\n",
            "Epoch [24/50] - Batch loss: 153.0786 - Epoch Loss: 63612.9933 - Avg Loss: 159.0325\n",
            "Epoch [24/50] - Batch loss: 154.6019 - Epoch Loss: 63767.5952 - Avg Loss: 159.0214\n",
            "Epoch [24/50] - Batch loss: 159.2330 - Epoch Loss: 63926.8282 - Avg Loss: 159.0220\n",
            "Epoch [24/50] - Batch loss: 169.7565 - Epoch Loss: 64096.5846 - Avg Loss: 159.0486\n",
            "Epoch [24/50] - Batch loss: 160.5687 - Epoch Loss: 64257.1533 - Avg Loss: 159.0524\n",
            "Epoch [24/50] - Batch loss: 160.1794 - Epoch Loss: 64417.3326 - Avg Loss: 159.0551\n",
            "Epoch [24/50] - Batch loss: 168.5959 - Epoch Loss: 64585.9285 - Avg Loss: 159.0786\n",
            "Epoch [24/50] - Batch loss: 162.8151 - Epoch Loss: 64748.7436 - Avg Loss: 159.0878\n",
            "Epoch [24/50] - Batch loss: 163.4840 - Epoch Loss: 64912.2275 - Avg Loss: 159.0986\n",
            "Epoch [24/50] - Batch loss: 156.8418 - Epoch Loss: 65069.0694 - Avg Loss: 159.0931\n",
            "Epoch [24/50] - Batch loss: 164.2110 - Epoch Loss: 65233.2804 - Avg Loss: 159.1056\n",
            "Epoch [24/50] - Batch loss: 155.4955 - Epoch Loss: 65388.7759 - Avg Loss: 159.0968\n",
            "Epoch [24/50] - Batch loss: 159.0887 - Epoch Loss: 65547.8647 - Avg Loss: 159.0968\n",
            "Epoch [24/50] - Batch loss: 158.8233 - Epoch Loss: 65706.6880 - Avg Loss: 159.0961\n",
            "Epoch [24/50] - Batch loss: 159.5427 - Epoch Loss: 65866.2306 - Avg Loss: 159.0972\n",
            "Epoch [24/50] - Batch loss: 154.1302 - Epoch Loss: 66020.3608 - Avg Loss: 159.0852\n",
            "Epoch [24/50] - Batch loss: 157.1570 - Epoch Loss: 66177.5178 - Avg Loss: 159.0806\n",
            "Epoch [24/50] - Batch loss: 152.0490 - Epoch Loss: 66329.5667 - Avg Loss: 159.0637\n",
            "Epoch [24/50] - Batch loss: 155.0357 - Epoch Loss: 66484.6025 - Avg Loss: 159.0541\n",
            "Epoch [24/50] - Batch loss: 163.0871 - Epoch Loss: 66647.6895 - Avg Loss: 159.0637\n",
            "Epoch [24/50] - Batch loss: 163.9180 - Epoch Loss: 66811.6076 - Avg Loss: 159.0753\n",
            "Epoch [24/50] - Batch loss: 152.6889 - Epoch Loss: 66964.2965 - Avg Loss: 159.0601\n",
            "Epoch [24/50] - Batch loss: 157.0125 - Epoch Loss: 67121.3090 - Avg Loss: 159.0552\n",
            "Epoch [24/50] - Batch loss: 156.3369 - Epoch Loss: 67277.6459 - Avg Loss: 159.0488\n",
            "Epoch [24/50] - Batch loss: 158.2500 - Epoch Loss: 67435.8959 - Avg Loss: 159.0469\n",
            "Epoch [24/50] - Batch loss: 151.0851 - Epoch Loss: 67586.9810 - Avg Loss: 159.0282\n",
            "Epoch [24/50] - Batch loss: 162.8651 - Epoch Loss: 67749.8461 - Avg Loss: 159.0372\n",
            "Epoch [24/50] - Batch loss: 156.7679 - Epoch Loss: 67906.6140 - Avg Loss: 159.0319\n",
            "Epoch [24/50] - Batch loss: 164.1792 - Epoch Loss: 68070.7932 - Avg Loss: 159.0439\n",
            "Epoch [24/50] - Batch loss: 159.4049 - Epoch Loss: 68230.1980 - Avg Loss: 159.0448\n",
            "Epoch [24/50] - Batch loss: 162.4811 - Epoch Loss: 68392.6791 - Avg Loss: 159.0527\n",
            "Epoch [24/50] - Batch loss: 160.0983 - Epoch Loss: 68552.7774 - Avg Loss: 159.0552\n",
            "Epoch [24/50] - Batch loss: 153.7761 - Epoch Loss: 68706.5535 - Avg Loss: 159.0429\n",
            "Epoch [24/50] - Batch loss: 151.4739 - Epoch Loss: 68858.0274 - Avg Loss: 159.0255\n",
            "Epoch [24/50] - Batch loss: 158.1415 - Epoch Loss: 69016.1689 - Avg Loss: 159.0234\n",
            "Epoch [24/50] - Batch loss: 159.4905 - Epoch Loss: 69175.6594 - Avg Loss: 159.0245\n",
            "Epoch [24/50] - Batch loss: 162.3487 - Epoch Loss: 69338.0081 - Avg Loss: 159.0321\n",
            "Epoch [24/50] - Batch loss: 162.2682 - Epoch Loss: 69500.2762 - Avg Loss: 159.0395\n",
            "Epoch [24/50] - Batch loss: 157.8995 - Epoch Loss: 69658.1758 - Avg Loss: 159.0369\n",
            "Epoch [24/50] - Batch loss: 156.5811 - Epoch Loss: 69814.7569 - Avg Loss: 159.0313\n",
            "Epoch [24/50] - Batch loss: 157.5035 - Epoch Loss: 69972.2604 - Avg Loss: 159.0279\n",
            "Epoch [24/50] - Batch loss: 155.7293 - Epoch Loss: 70127.9897 - Avg Loss: 159.0204\n",
            "Epoch [24/50] - Batch loss: 167.2484 - Epoch Loss: 70295.2382 - Avg Loss: 159.0390\n",
            "Epoch [24/50] - Batch loss: 151.9069 - Epoch Loss: 70447.1451 - Avg Loss: 159.0229\n",
            "Epoch [24/50] - Batch loss: 157.6320 - Epoch Loss: 70604.7771 - Avg Loss: 159.0198\n",
            "Epoch [24/50] - Batch loss: 157.6093 - Epoch Loss: 70762.3864 - Avg Loss: 159.0166\n",
            "Epoch [24/50] - Batch loss: 154.5054 - Epoch Loss: 70916.8918 - Avg Loss: 159.0065\n",
            "Epoch [24/50] - Batch loss: 159.4464 - Epoch Loss: 71076.3382 - Avg Loss: 159.0075\n",
            "Epoch [24/50] - Batch loss: 158.1356 - Epoch Loss: 71234.4738 - Avg Loss: 159.0055\n",
            "Epoch [24/50] - Batch loss: 154.6695 - Epoch Loss: 71389.1433 - Avg Loss: 158.9959\n",
            "Epoch [24/50] - Batch loss: 159.0420 - Epoch Loss: 71548.1853 - Avg Loss: 158.9960\n",
            "Epoch [24/50] - Batch loss: 156.5023 - Epoch Loss: 71704.6876 - Avg Loss: 158.9904\n",
            "Epoch [24/50] - Batch loss: 158.9345 - Epoch Loss: 71863.6221 - Avg Loss: 158.9903\n",
            "Epoch [24/50] - Batch loss: 150.6875 - Epoch Loss: 72014.3096 - Avg Loss: 158.9720\n",
            "Epoch [24/50] - Batch loss: 163.6927 - Epoch Loss: 72178.0023 - Avg Loss: 158.9824\n",
            "Epoch [24/50] - Batch loss: 162.7541 - Epoch Loss: 72340.7563 - Avg Loss: 158.9907\n",
            "Epoch [24/50] - Batch loss: 152.1015 - Epoch Loss: 72492.8578 - Avg Loss: 158.9756\n",
            "Epoch [24/50] - Batch loss: 163.1794 - Epoch Loss: 72656.0372 - Avg Loss: 158.9848\n",
            "Epoch [24/50] - Batch loss: 163.7662 - Epoch Loss: 72819.8034 - Avg Loss: 158.9952\n",
            "Epoch [24/50] - Batch loss: 151.9329 - Epoch Loss: 72971.7362 - Avg Loss: 158.9798\n",
            "Epoch [24/50] - Batch loss: 158.6065 - Epoch Loss: 73130.3427 - Avg Loss: 158.9790\n",
            "Epoch [24/50] - Batch loss: 151.7635 - Epoch Loss: 73282.1063 - Avg Loss: 158.9634\n",
            "Epoch [24/50] - Batch loss: 155.8552 - Epoch Loss: 73437.9615 - Avg Loss: 158.9566\n",
            "Epoch [24/50] - Batch loss: 161.1551 - Epoch Loss: 73599.1165 - Avg Loss: 158.9614\n",
            "Epoch [24/50] - Batch loss: 151.0099 - Epoch Loss: 73750.1264 - Avg Loss: 158.9442\n",
            "Epoch [24/50] - Batch loss: 162.4669 - Epoch Loss: 73912.5933 - Avg Loss: 158.9518\n",
            "Epoch [24/50] - Batch loss: 158.0625 - Epoch Loss: 74070.6558 - Avg Loss: 158.9499\n",
            "Epoch [24/50] - Batch loss: 162.5801 - Epoch Loss: 74233.2359 - Avg Loss: 158.9577\n",
            "Epoch [24/50] - Batch loss: 151.6893 - Epoch Loss: 74384.9252 - Avg Loss: 158.9421\n",
            "Epoch [24/50] - Batch loss: 152.2054 - Epoch Loss: 74537.1306 - Avg Loss: 158.9278\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 25/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3275862e0cd4452a4cdaddd33a1af80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/50] - Batch loss: 160.8114 - Epoch Loss: 160.8114 - Avg Loss: 160.8114\n",
            "Epoch [25/50] - Batch loss: 145.1129 - Epoch Loss: 305.9243 - Avg Loss: 152.9622\n",
            "Epoch [25/50] - Batch loss: 151.6521 - Epoch Loss: 457.5764 - Avg Loss: 152.5255\n",
            "Epoch [25/50] - Batch loss: 160.5935 - Epoch Loss: 618.1699 - Avg Loss: 154.5425\n",
            "Epoch [25/50] - Batch loss: 156.2617 - Epoch Loss: 774.4317 - Avg Loss: 154.8863\n",
            "Epoch [25/50] - Batch loss: 158.9529 - Epoch Loss: 933.3845 - Avg Loss: 155.5641\n",
            "Epoch [25/50] - Batch loss: 155.5131 - Epoch Loss: 1088.8976 - Avg Loss: 155.5568\n",
            "Epoch [25/50] - Batch loss: 155.7683 - Epoch Loss: 1244.6660 - Avg Loss: 155.5832\n",
            "Epoch [25/50] - Batch loss: 164.5522 - Epoch Loss: 1409.2181 - Avg Loss: 156.5798\n",
            "Epoch [25/50] - Batch loss: 169.2448 - Epoch Loss: 1578.4629 - Avg Loss: 157.8463\n",
            "Epoch [25/50] - Batch loss: 149.8736 - Epoch Loss: 1728.3365 - Avg Loss: 157.1215\n",
            "Epoch [25/50] - Batch loss: 157.5609 - Epoch Loss: 1885.8974 - Avg Loss: 157.1581\n",
            "Epoch [25/50] - Batch loss: 159.4469 - Epoch Loss: 2045.3443 - Avg Loss: 157.3342\n",
            "Epoch [25/50] - Batch loss: 162.2958 - Epoch Loss: 2207.6400 - Avg Loss: 157.6886\n",
            "Epoch [25/50] - Batch loss: 162.2104 - Epoch Loss: 2369.8505 - Avg Loss: 157.9900\n",
            "Epoch [25/50] - Batch loss: 152.3920 - Epoch Loss: 2522.2424 - Avg Loss: 157.6402\n",
            "Epoch [25/50] - Batch loss: 155.3682 - Epoch Loss: 2677.6106 - Avg Loss: 157.5065\n",
            "Epoch [25/50] - Batch loss: 160.4392 - Epoch Loss: 2838.0498 - Avg Loss: 157.6694\n",
            "Epoch [25/50] - Batch loss: 155.9136 - Epoch Loss: 2993.9633 - Avg Loss: 157.5770\n",
            "Epoch [25/50] - Batch loss: 149.4758 - Epoch Loss: 3143.4391 - Avg Loss: 157.1720\n",
            "Epoch [25/50] - Batch loss: 157.8647 - Epoch Loss: 3301.3038 - Avg Loss: 157.2049\n",
            "Epoch [25/50] - Batch loss: 167.1105 - Epoch Loss: 3468.4143 - Avg Loss: 157.6552\n",
            "Epoch [25/50] - Batch loss: 162.8430 - Epoch Loss: 3631.2573 - Avg Loss: 157.8808\n",
            "Epoch [25/50] - Batch loss: 151.6415 - Epoch Loss: 3782.8988 - Avg Loss: 157.6208\n",
            "Epoch [25/50] - Batch loss: 157.0481 - Epoch Loss: 3939.9469 - Avg Loss: 157.5979\n",
            "Epoch [25/50] - Batch loss: 164.6402 - Epoch Loss: 4104.5871 - Avg Loss: 157.8687\n",
            "Epoch [25/50] - Batch loss: 149.8139 - Epoch Loss: 4254.4010 - Avg Loss: 157.5704\n",
            "Epoch [25/50] - Batch loss: 159.2367 - Epoch Loss: 4413.6377 - Avg Loss: 157.6299\n",
            "Epoch [25/50] - Batch loss: 165.7676 - Epoch Loss: 4579.4053 - Avg Loss: 157.9105\n",
            "Epoch [25/50] - Batch loss: 161.6122 - Epoch Loss: 4741.0174 - Avg Loss: 158.0339\n",
            "Epoch [25/50] - Batch loss: 166.8837 - Epoch Loss: 4907.9011 - Avg Loss: 158.3194\n",
            "Epoch [25/50] - Batch loss: 161.4029 - Epoch Loss: 5069.3040 - Avg Loss: 158.4158\n",
            "Epoch [25/50] - Batch loss: 161.4188 - Epoch Loss: 5230.7228 - Avg Loss: 158.5068\n",
            "Epoch [25/50] - Batch loss: 153.4861 - Epoch Loss: 5384.2089 - Avg Loss: 158.3591\n",
            "Epoch [25/50] - Batch loss: 164.4144 - Epoch Loss: 5548.6234 - Avg Loss: 158.5321\n",
            "Epoch [25/50] - Batch loss: 162.5690 - Epoch Loss: 5711.1924 - Avg Loss: 158.6442\n",
            "Epoch [25/50] - Batch loss: 159.8042 - Epoch Loss: 5870.9966 - Avg Loss: 158.6756\n",
            "Epoch [25/50] - Batch loss: 152.8645 - Epoch Loss: 6023.8611 - Avg Loss: 158.5227\n",
            "Epoch [25/50] - Batch loss: 159.2239 - Epoch Loss: 6183.0850 - Avg Loss: 158.5406\n",
            "Epoch [25/50] - Batch loss: 157.2307 - Epoch Loss: 6340.3157 - Avg Loss: 158.5079\n",
            "Epoch [25/50] - Batch loss: 162.0683 - Epoch Loss: 6502.3840 - Avg Loss: 158.5947\n",
            "Epoch [25/50] - Batch loss: 163.4375 - Epoch Loss: 6665.8214 - Avg Loss: 158.7100\n",
            "Epoch [25/50] - Batch loss: 161.3052 - Epoch Loss: 6827.1266 - Avg Loss: 158.7704\n",
            "Epoch [25/50] - Batch loss: 156.0688 - Epoch Loss: 6983.1954 - Avg Loss: 158.7090\n",
            "Epoch [25/50] - Batch loss: 160.6798 - Epoch Loss: 7143.8752 - Avg Loss: 158.7528\n",
            "Epoch [25/50] - Batch loss: 157.2180 - Epoch Loss: 7301.0932 - Avg Loss: 158.7194\n",
            "Epoch [25/50] - Batch loss: 162.7767 - Epoch Loss: 7463.8699 - Avg Loss: 158.8057\n",
            "Epoch [25/50] - Batch loss: 159.3220 - Epoch Loss: 7623.1919 - Avg Loss: 158.8165\n",
            "Epoch [25/50] - Batch loss: 163.5230 - Epoch Loss: 7786.7149 - Avg Loss: 158.9125\n",
            "Epoch [25/50] - Batch loss: 155.9196 - Epoch Loss: 7942.6345 - Avg Loss: 158.8527\n",
            "Epoch [25/50] - Batch loss: 153.7269 - Epoch Loss: 8096.3614 - Avg Loss: 158.7522\n",
            "Epoch [25/50] - Batch loss: 163.5343 - Epoch Loss: 8259.8957 - Avg Loss: 158.8441\n",
            "Epoch [25/50] - Batch loss: 153.6252 - Epoch Loss: 8413.5208 - Avg Loss: 158.7457\n",
            "Epoch [25/50] - Batch loss: 155.4562 - Epoch Loss: 8568.9771 - Avg Loss: 158.6848\n",
            "Epoch [25/50] - Batch loss: 169.0204 - Epoch Loss: 8737.9975 - Avg Loss: 158.8727\n",
            "Epoch [25/50] - Batch loss: 166.1906 - Epoch Loss: 8904.1880 - Avg Loss: 159.0034\n",
            "Epoch [25/50] - Batch loss: 167.8883 - Epoch Loss: 9072.0764 - Avg Loss: 159.1592\n",
            "Epoch [25/50] - Batch loss: 158.0638 - Epoch Loss: 9230.1402 - Avg Loss: 159.1403\n",
            "Epoch [25/50] - Batch loss: 163.2307 - Epoch Loss: 9393.3709 - Avg Loss: 159.2097\n",
            "Epoch [25/50] - Batch loss: 171.3283 - Epoch Loss: 9564.6992 - Avg Loss: 159.4117\n",
            "Epoch [25/50] - Batch loss: 153.6913 - Epoch Loss: 9718.3904 - Avg Loss: 159.3179\n",
            "Epoch [25/50] - Batch loss: 162.4003 - Epoch Loss: 9880.7908 - Avg Loss: 159.3676\n",
            "Epoch [25/50] - Batch loss: 157.2307 - Epoch Loss: 10038.0215 - Avg Loss: 159.3337\n",
            "Epoch [25/50] - Batch loss: 158.8268 - Epoch Loss: 10196.8483 - Avg Loss: 159.3258\n",
            "Epoch [25/50] - Batch loss: 162.7794 - Epoch Loss: 10359.6277 - Avg Loss: 159.3789\n",
            "Epoch [25/50] - Batch loss: 164.9486 - Epoch Loss: 10524.5763 - Avg Loss: 159.4633\n",
            "Epoch [25/50] - Batch loss: 161.4199 - Epoch Loss: 10685.9962 - Avg Loss: 159.4925\n",
            "Epoch [25/50] - Batch loss: 156.0931 - Epoch Loss: 10842.0893 - Avg Loss: 159.4425\n",
            "Epoch [25/50] - Batch loss: 163.4238 - Epoch Loss: 11005.5131 - Avg Loss: 159.5002\n",
            "Epoch [25/50] - Batch loss: 158.1499 - Epoch Loss: 11163.6630 - Avg Loss: 159.4809\n",
            "Epoch [25/50] - Batch loss: 158.7369 - Epoch Loss: 11322.3999 - Avg Loss: 159.4704\n",
            "Epoch [25/50] - Batch loss: 160.1083 - Epoch Loss: 11482.5082 - Avg Loss: 159.4793\n",
            "Epoch [25/50] - Batch loss: 158.3663 - Epoch Loss: 11640.8745 - Avg Loss: 159.4640\n",
            "Epoch [25/50] - Batch loss: 163.5354 - Epoch Loss: 11804.4100 - Avg Loss: 159.5191\n",
            "Epoch [25/50] - Batch loss: 170.2184 - Epoch Loss: 11974.6284 - Avg Loss: 159.6617\n",
            "Epoch [25/50] - Batch loss: 156.4546 - Epoch Loss: 12131.0830 - Avg Loss: 159.6195\n",
            "Epoch [25/50] - Batch loss: 163.2001 - Epoch Loss: 12294.2831 - Avg Loss: 159.6660\n",
            "Epoch [25/50] - Batch loss: 161.1854 - Epoch Loss: 12455.4685 - Avg Loss: 159.6855\n",
            "Epoch [25/50] - Batch loss: 171.5808 - Epoch Loss: 12627.0493 - Avg Loss: 159.8361\n",
            "Epoch [25/50] - Batch loss: 157.8964 - Epoch Loss: 12784.9457 - Avg Loss: 159.8118\n",
            "Epoch [25/50] - Batch loss: 159.0622 - Epoch Loss: 12944.0079 - Avg Loss: 159.8026\n",
            "Epoch [25/50] - Batch loss: 161.0646 - Epoch Loss: 13105.0725 - Avg Loss: 159.8180\n",
            "Epoch [25/50] - Batch loss: 163.8272 - Epoch Loss: 13268.8997 - Avg Loss: 159.8663\n",
            "Epoch [25/50] - Batch loss: 164.8531 - Epoch Loss: 13433.7528 - Avg Loss: 159.9256\n",
            "Epoch [25/50] - Batch loss: 168.0390 - Epoch Loss: 13601.7919 - Avg Loss: 160.0211\n",
            "Epoch [25/50] - Batch loss: 166.5554 - Epoch Loss: 13768.3472 - Avg Loss: 160.0971\n",
            "Epoch [25/50] - Batch loss: 159.9759 - Epoch Loss: 13928.3232 - Avg Loss: 160.0957\n",
            "Epoch [25/50] - Batch loss: 165.1732 - Epoch Loss: 14093.4964 - Avg Loss: 160.1534\n",
            "Epoch [25/50] - Batch loss: 165.8679 - Epoch Loss: 14259.3643 - Avg Loss: 160.2176\n",
            "Epoch [25/50] - Batch loss: 166.0290 - Epoch Loss: 14425.3933 - Avg Loss: 160.2821\n",
            "Epoch [25/50] - Batch loss: 162.1898 - Epoch Loss: 14587.5831 - Avg Loss: 160.3031\n",
            "Epoch [25/50] - Batch loss: 164.2389 - Epoch Loss: 14751.8221 - Avg Loss: 160.3459\n",
            "Epoch [25/50] - Batch loss: 166.7876 - Epoch Loss: 14918.6096 - Avg Loss: 160.4152\n",
            "Epoch [25/50] - Batch loss: 171.2637 - Epoch Loss: 15089.8734 - Avg Loss: 160.5306\n",
            "Epoch [25/50] - Batch loss: 170.0924 - Epoch Loss: 15259.9658 - Avg Loss: 160.6312\n",
            "Epoch [25/50] - Batch loss: 164.3462 - Epoch Loss: 15424.3120 - Avg Loss: 160.6699\n",
            "Epoch [25/50] - Batch loss: 168.6308 - Epoch Loss: 15592.9428 - Avg Loss: 160.7520\n",
            "Epoch [25/50] - Batch loss: 161.2394 - Epoch Loss: 15754.1822 - Avg Loss: 160.7570\n",
            "Epoch [25/50] - Batch loss: 165.0676 - Epoch Loss: 15919.2498 - Avg Loss: 160.8005\n",
            "Epoch [25/50] - Batch loss: 166.7287 - Epoch Loss: 16085.9786 - Avg Loss: 160.8598\n",
            "Epoch [25/50] - Batch loss: 165.1687 - Epoch Loss: 16251.1473 - Avg Loss: 160.9024\n",
            "Epoch [25/50] - Batch loss: 172.0503 - Epoch Loss: 16423.1976 - Avg Loss: 161.0117\n",
            "Epoch [25/50] - Batch loss: 170.5098 - Epoch Loss: 16593.7074 - Avg Loss: 161.1040\n",
            "Epoch [25/50] - Batch loss: 161.7031 - Epoch Loss: 16755.4105 - Avg Loss: 161.1097\n",
            "Epoch [25/50] - Batch loss: 168.6761 - Epoch Loss: 16924.0866 - Avg Loss: 161.1818\n",
            "Epoch [25/50] - Batch loss: 169.5414 - Epoch Loss: 17093.6281 - Avg Loss: 161.2606\n",
            "Epoch [25/50] - Batch loss: 171.0161 - Epoch Loss: 17264.6441 - Avg Loss: 161.3518\n",
            "Epoch [25/50] - Batch loss: 167.3950 - Epoch Loss: 17432.0391 - Avg Loss: 161.4078\n",
            "Epoch [25/50] - Batch loss: 162.7361 - Epoch Loss: 17594.7752 - Avg Loss: 161.4200\n",
            "Epoch [25/50] - Batch loss: 164.6595 - Epoch Loss: 17759.4347 - Avg Loss: 161.4494\n",
            "Epoch [25/50] - Batch loss: 170.3578 - Epoch Loss: 17929.7925 - Avg Loss: 161.5297\n",
            "Epoch [25/50] - Batch loss: 163.4322 - Epoch Loss: 18093.2247 - Avg Loss: 161.5466\n",
            "Epoch [25/50] - Batch loss: 167.9359 - Epoch Loss: 18261.1606 - Avg Loss: 161.6032\n",
            "Epoch [25/50] - Batch loss: 163.6534 - Epoch Loss: 18424.8141 - Avg Loss: 161.6212\n",
            "Epoch [25/50] - Batch loss: 158.0231 - Epoch Loss: 18582.8372 - Avg Loss: 161.5899\n",
            "Epoch [25/50] - Batch loss: 165.8925 - Epoch Loss: 18748.7297 - Avg Loss: 161.6270\n",
            "Epoch [25/50] - Batch loss: 171.1266 - Epoch Loss: 18919.8563 - Avg Loss: 161.7082\n",
            "Epoch [25/50] - Batch loss: 166.4890 - Epoch Loss: 19086.3452 - Avg Loss: 161.7487\n",
            "Epoch [25/50] - Batch loss: 165.3382 - Epoch Loss: 19251.6834 - Avg Loss: 161.7789\n",
            "Epoch [25/50] - Batch loss: 159.5741 - Epoch Loss: 19411.2575 - Avg Loss: 161.7605\n",
            "Epoch [25/50] - Batch loss: 172.9062 - Epoch Loss: 19584.1637 - Avg Loss: 161.8526\n",
            "Epoch [25/50] - Batch loss: 169.0704 - Epoch Loss: 19753.2342 - Avg Loss: 161.9118\n",
            "Epoch [25/50] - Batch loss: 166.5219 - Epoch Loss: 19919.7560 - Avg Loss: 161.9492\n",
            "Epoch [25/50] - Batch loss: 162.2959 - Epoch Loss: 20082.0520 - Avg Loss: 161.9520\n",
            "Epoch [25/50] - Batch loss: 171.1552 - Epoch Loss: 20253.2072 - Avg Loss: 162.0257\n",
            "Epoch [25/50] - Batch loss: 157.0593 - Epoch Loss: 20410.2665 - Avg Loss: 161.9862\n",
            "Epoch [25/50] - Batch loss: 162.3044 - Epoch Loss: 20572.5709 - Avg Loss: 161.9887\n",
            "Epoch [25/50] - Batch loss: 173.1757 - Epoch Loss: 20745.7466 - Avg Loss: 162.0761\n",
            "Epoch [25/50] - Batch loss: 169.9098 - Epoch Loss: 20915.6564 - Avg Loss: 162.1369\n",
            "Epoch [25/50] - Batch loss: 157.2450 - Epoch Loss: 21072.9014 - Avg Loss: 162.0992\n",
            "Epoch [25/50] - Batch loss: 160.7001 - Epoch Loss: 21233.6015 - Avg Loss: 162.0886\n",
            "Epoch [25/50] - Batch loss: 170.5026 - Epoch Loss: 21404.1041 - Avg Loss: 162.1523\n",
            "Epoch [25/50] - Batch loss: 174.4559 - Epoch Loss: 21578.5600 - Avg Loss: 162.2448\n",
            "Epoch [25/50] - Batch loss: 165.7139 - Epoch Loss: 21744.2739 - Avg Loss: 162.2707\n",
            "Epoch [25/50] - Batch loss: 162.0910 - Epoch Loss: 21906.3649 - Avg Loss: 162.2694\n",
            "Epoch [25/50] - Batch loss: 161.9268 - Epoch Loss: 22068.2917 - Avg Loss: 162.2669\n",
            "Epoch [25/50] - Batch loss: 160.3215 - Epoch Loss: 22228.6131 - Avg Loss: 162.2527\n",
            "Epoch [25/50] - Batch loss: 162.0226 - Epoch Loss: 22390.6358 - Avg Loss: 162.2510\n",
            "Epoch [25/50] - Batch loss: 163.5578 - Epoch Loss: 22554.1935 - Avg Loss: 162.2604\n",
            "Epoch [25/50] - Batch loss: 161.5738 - Epoch Loss: 22715.7674 - Avg Loss: 162.2555\n",
            "Epoch [25/50] - Batch loss: 169.4518 - Epoch Loss: 22885.2192 - Avg Loss: 162.3065\n",
            "Epoch [25/50] - Batch loss: 176.5534 - Epoch Loss: 23061.7726 - Avg Loss: 162.4068\n",
            "Epoch [25/50] - Batch loss: 162.9858 - Epoch Loss: 23224.7584 - Avg Loss: 162.4109\n",
            "Epoch [25/50] - Batch loss: 161.2812 - Epoch Loss: 23386.0397 - Avg Loss: 162.4031\n",
            "Epoch [25/50] - Batch loss: 161.9665 - Epoch Loss: 23548.0062 - Avg Loss: 162.4000\n",
            "Epoch [25/50] - Batch loss: 163.1075 - Epoch Loss: 23711.1137 - Avg Loss: 162.4049\n",
            "Epoch [25/50] - Batch loss: 167.3810 - Epoch Loss: 23878.4946 - Avg Loss: 162.4387\n",
            "Epoch [25/50] - Batch loss: 161.8626 - Epoch Loss: 24040.3572 - Avg Loss: 162.4348\n",
            "Epoch [25/50] - Batch loss: 170.8291 - Epoch Loss: 24211.1863 - Avg Loss: 162.4912\n",
            "Epoch [25/50] - Batch loss: 163.3657 - Epoch Loss: 24374.5520 - Avg Loss: 162.4970\n",
            "Epoch [25/50] - Batch loss: 160.0718 - Epoch Loss: 24534.6238 - Avg Loss: 162.4810\n",
            "Epoch [25/50] - Batch loss: 165.6230 - Epoch Loss: 24700.2468 - Avg Loss: 162.5016\n",
            "Epoch [25/50] - Batch loss: 167.8588 - Epoch Loss: 24868.1057 - Avg Loss: 162.5366\n",
            "Epoch [25/50] - Batch loss: 167.4905 - Epoch Loss: 25035.5961 - Avg Loss: 162.5688\n",
            "Epoch [25/50] - Batch loss: 163.2591 - Epoch Loss: 25198.8552 - Avg Loss: 162.5733\n",
            "Epoch [25/50] - Batch loss: 165.4341 - Epoch Loss: 25364.2893 - Avg Loss: 162.5916\n",
            "Epoch [25/50] - Batch loss: 168.4134 - Epoch Loss: 25532.7027 - Avg Loss: 162.6287\n",
            "Epoch [25/50] - Batch loss: 168.8117 - Epoch Loss: 25701.5144 - Avg Loss: 162.6678\n",
            "Epoch [25/50] - Batch loss: 165.2176 - Epoch Loss: 25866.7320 - Avg Loss: 162.6838\n",
            "Epoch [25/50] - Batch loss: 166.9472 - Epoch Loss: 26033.6792 - Avg Loss: 162.7105\n",
            "Epoch [25/50] - Batch loss: 163.6150 - Epoch Loss: 26197.2942 - Avg Loss: 162.7161\n",
            "Epoch [25/50] - Batch loss: 178.7865 - Epoch Loss: 26376.0807 - Avg Loss: 162.8153\n",
            "Epoch [25/50] - Batch loss: 164.3636 - Epoch Loss: 26540.4442 - Avg Loss: 162.8248\n",
            "Epoch [25/50] - Batch loss: 164.1259 - Epoch Loss: 26704.5701 - Avg Loss: 162.8327\n",
            "Epoch [25/50] - Batch loss: 166.2199 - Epoch Loss: 26870.7900 - Avg Loss: 162.8533\n",
            "Epoch [25/50] - Batch loss: 167.1140 - Epoch Loss: 27037.9040 - Avg Loss: 162.8789\n",
            "Epoch [25/50] - Batch loss: 168.6981 - Epoch Loss: 27206.6021 - Avg Loss: 162.9138\n",
            "Epoch [25/50] - Batch loss: 160.6251 - Epoch Loss: 27367.2272 - Avg Loss: 162.9002\n",
            "Epoch [25/50] - Batch loss: 164.9937 - Epoch Loss: 27532.2210 - Avg Loss: 162.9126\n",
            "Epoch [25/50] - Batch loss: 168.0152 - Epoch Loss: 27700.2362 - Avg Loss: 162.9426\n",
            "Epoch [25/50] - Batch loss: 163.6675 - Epoch Loss: 27863.9037 - Avg Loss: 162.9468\n",
            "Epoch [25/50] - Batch loss: 162.3662 - Epoch Loss: 28026.2699 - Avg Loss: 162.9434\n",
            "Epoch [25/50] - Batch loss: 163.0680 - Epoch Loss: 28189.3379 - Avg Loss: 162.9441\n",
            "Epoch [25/50] - Batch loss: 162.8982 - Epoch Loss: 28352.2361 - Avg Loss: 162.9439\n",
            "Epoch [25/50] - Batch loss: 162.5145 - Epoch Loss: 28514.7505 - Avg Loss: 162.9414\n",
            "Epoch [25/50] - Batch loss: 151.9450 - Epoch Loss: 28666.6956 - Avg Loss: 162.8790\n",
            "Epoch [25/50] - Batch loss: 158.0849 - Epoch Loss: 28824.7804 - Avg Loss: 162.8519\n",
            "Epoch [25/50] - Batch loss: 160.3453 - Epoch Loss: 28985.1257 - Avg Loss: 162.8378\n",
            "Epoch [25/50] - Batch loss: 161.7937 - Epoch Loss: 29146.9194 - Avg Loss: 162.8320\n",
            "Epoch [25/50] - Batch loss: 160.7143 - Epoch Loss: 29307.6338 - Avg Loss: 162.8202\n",
            "Epoch [25/50] - Batch loss: 163.9074 - Epoch Loss: 29471.5411 - Avg Loss: 162.8262\n",
            "Epoch [25/50] - Batch loss: 164.6005 - Epoch Loss: 29636.1416 - Avg Loss: 162.8359\n",
            "Epoch [25/50] - Batch loss: 163.6542 - Epoch Loss: 29799.7958 - Avg Loss: 162.8404\n",
            "Epoch [25/50] - Batch loss: 162.7320 - Epoch Loss: 29962.5278 - Avg Loss: 162.8398\n",
            "Epoch [25/50] - Batch loss: 167.1934 - Epoch Loss: 30129.7213 - Avg Loss: 162.8634\n",
            "Epoch [25/50] - Batch loss: 163.4296 - Epoch Loss: 30293.1509 - Avg Loss: 162.8664\n",
            "Epoch [25/50] - Batch loss: 160.8411 - Epoch Loss: 30453.9919 - Avg Loss: 162.8556\n",
            "Epoch [25/50] - Batch loss: 162.9379 - Epoch Loss: 30616.9299 - Avg Loss: 162.8560\n",
            "Epoch [25/50] - Batch loss: 168.4287 - Epoch Loss: 30785.3586 - Avg Loss: 162.8855\n",
            "Epoch [25/50] - Batch loss: 171.2357 - Epoch Loss: 30956.5943 - Avg Loss: 162.9294\n",
            "Epoch [25/50] - Batch loss: 166.3600 - Epoch Loss: 31122.9543 - Avg Loss: 162.9474\n",
            "Epoch [25/50] - Batch loss: 167.0268 - Epoch Loss: 31289.9811 - Avg Loss: 162.9687\n",
            "Epoch [25/50] - Batch loss: 166.7927 - Epoch Loss: 31456.7737 - Avg Loss: 162.9885\n",
            "Epoch [25/50] - Batch loss: 167.1215 - Epoch Loss: 31623.8953 - Avg Loss: 163.0098\n",
            "Epoch [25/50] - Batch loss: 167.6729 - Epoch Loss: 31791.5682 - Avg Loss: 163.0337\n",
            "Epoch [25/50] - Batch loss: 168.7880 - Epoch Loss: 31960.3562 - Avg Loss: 163.0630\n",
            "Epoch [25/50] - Batch loss: 166.4721 - Epoch Loss: 32126.8283 - Avg Loss: 163.0803\n",
            "Epoch [25/50] - Batch loss: 169.6501 - Epoch Loss: 32296.4784 - Avg Loss: 163.1135\n",
            "Epoch [25/50] - Batch loss: 153.6274 - Epoch Loss: 32450.1058 - Avg Loss: 163.0659\n",
            "Epoch [25/50] - Batch loss: 164.6019 - Epoch Loss: 32614.7077 - Avg Loss: 163.0735\n",
            "Epoch [25/50] - Batch loss: 167.4660 - Epoch Loss: 32782.1737 - Avg Loss: 163.0954\n",
            "Epoch [25/50] - Batch loss: 164.0484 - Epoch Loss: 32946.2221 - Avg Loss: 163.1001\n",
            "Epoch [25/50] - Batch loss: 164.6241 - Epoch Loss: 33110.8462 - Avg Loss: 163.1076\n",
            "Epoch [25/50] - Batch loss: 162.9272 - Epoch Loss: 33273.7734 - Avg Loss: 163.1067\n",
            "Epoch [25/50] - Batch loss: 162.3379 - Epoch Loss: 33436.1113 - Avg Loss: 163.1030\n",
            "Epoch [25/50] - Batch loss: 160.7387 - Epoch Loss: 33596.8500 - Avg Loss: 163.0915\n",
            "Epoch [25/50] - Batch loss: 167.3307 - Epoch Loss: 33764.1807 - Avg Loss: 163.1120\n",
            "Epoch [25/50] - Batch loss: 166.0819 - Epoch Loss: 33930.2626 - Avg Loss: 163.1263\n",
            "Epoch [25/50] - Batch loss: 156.4565 - Epoch Loss: 34086.7191 - Avg Loss: 163.0943\n",
            "Epoch [25/50] - Batch loss: 162.3694 - Epoch Loss: 34249.0885 - Avg Loss: 163.0909\n",
            "Epoch [25/50] - Batch loss: 160.0670 - Epoch Loss: 34409.1555 - Avg Loss: 163.0766\n",
            "Epoch [25/50] - Batch loss: 163.6226 - Epoch Loss: 34572.7781 - Avg Loss: 163.0791\n",
            "Epoch [25/50] - Batch loss: 151.3591 - Epoch Loss: 34724.1372 - Avg Loss: 163.0241\n",
            "Epoch [25/50] - Batch loss: 165.3604 - Epoch Loss: 34889.4976 - Avg Loss: 163.0350\n",
            "Epoch [25/50] - Batch loss: 159.2685 - Epoch Loss: 35048.7661 - Avg Loss: 163.0175\n",
            "Epoch [25/50] - Batch loss: 166.0185 - Epoch Loss: 35214.7845 - Avg Loss: 163.0314\n",
            "Epoch [25/50] - Batch loss: 161.7033 - Epoch Loss: 35376.4878 - Avg Loss: 163.0253\n",
            "Epoch [25/50] - Batch loss: 173.3288 - Epoch Loss: 35549.8166 - Avg Loss: 163.0726\n",
            "Epoch [25/50] - Batch loss: 160.6775 - Epoch Loss: 35710.4941 - Avg Loss: 163.0616\n",
            "Epoch [25/50] - Batch loss: 165.9449 - Epoch Loss: 35876.4390 - Avg Loss: 163.0747\n",
            "Epoch [25/50] - Batch loss: 160.0560 - Epoch Loss: 36036.4951 - Avg Loss: 163.0611\n",
            "Epoch [25/50] - Batch loss: 161.0974 - Epoch Loss: 36197.5924 - Avg Loss: 163.0522\n",
            "Epoch [25/50] - Batch loss: 161.7048 - Epoch Loss: 36359.2972 - Avg Loss: 163.0462\n",
            "Epoch [25/50] - Batch loss: 165.5834 - Epoch Loss: 36524.8806 - Avg Loss: 163.0575\n",
            "Epoch [25/50] - Batch loss: 155.5231 - Epoch Loss: 36680.4037 - Avg Loss: 163.0240\n",
            "Epoch [25/50] - Batch loss: 165.2406 - Epoch Loss: 36845.6444 - Avg Loss: 163.0338\n",
            "Epoch [25/50] - Batch loss: 164.0967 - Epoch Loss: 37009.7411 - Avg Loss: 163.0385\n",
            "Epoch [25/50] - Batch loss: 158.4423 - Epoch Loss: 37168.1833 - Avg Loss: 163.0183\n",
            "Epoch [25/50] - Batch loss: 166.0352 - Epoch Loss: 37334.2185 - Avg Loss: 163.0315\n",
            "Epoch [25/50] - Batch loss: 165.8376 - Epoch Loss: 37500.0561 - Avg Loss: 163.0437\n",
            "Epoch [25/50] - Batch loss: 162.0295 - Epoch Loss: 37662.0856 - Avg Loss: 163.0393\n",
            "Epoch [25/50] - Batch loss: 165.8506 - Epoch Loss: 37827.9362 - Avg Loss: 163.0514\n",
            "Epoch [25/50] - Batch loss: 160.2805 - Epoch Loss: 37988.2167 - Avg Loss: 163.0396\n",
            "Epoch [25/50] - Batch loss: 169.4313 - Epoch Loss: 38157.6479 - Avg Loss: 163.0669\n",
            "Epoch [25/50] - Batch loss: 167.7010 - Epoch Loss: 38325.3489 - Avg Loss: 163.0866\n",
            "Epoch [25/50] - Batch loss: 157.2306 - Epoch Loss: 38482.5795 - Avg Loss: 163.0618\n",
            "Epoch [25/50] - Batch loss: 162.8430 - Epoch Loss: 38645.4224 - Avg Loss: 163.0609\n",
            "Epoch [25/50] - Batch loss: 170.7425 - Epoch Loss: 38816.1649 - Avg Loss: 163.0931\n",
            "Epoch [25/50] - Batch loss: 153.9813 - Epoch Loss: 38970.1462 - Avg Loss: 163.0550\n",
            "Epoch [25/50] - Batch loss: 171.2550 - Epoch Loss: 39141.4012 - Avg Loss: 163.0892\n",
            "Epoch [25/50] - Batch loss: 166.0683 - Epoch Loss: 39307.4695 - Avg Loss: 163.1015\n",
            "Epoch [25/50] - Batch loss: 157.1809 - Epoch Loss: 39464.6503 - Avg Loss: 163.0771\n",
            "Epoch [25/50] - Batch loss: 166.7076 - Epoch Loss: 39631.3579 - Avg Loss: 163.0920\n",
            "Epoch [25/50] - Batch loss: 157.7735 - Epoch Loss: 39789.1314 - Avg Loss: 163.0702\n",
            "Epoch [25/50] - Batch loss: 161.8536 - Epoch Loss: 39950.9850 - Avg Loss: 163.0652\n",
            "Epoch [25/50] - Batch loss: 168.3370 - Epoch Loss: 40119.3220 - Avg Loss: 163.0867\n",
            "Epoch [25/50] - Batch loss: 165.3551 - Epoch Loss: 40284.6771 - Avg Loss: 163.0959\n",
            "Epoch [25/50] - Batch loss: 161.8150 - Epoch Loss: 40446.4921 - Avg Loss: 163.0907\n",
            "Epoch [25/50] - Batch loss: 169.8057 - Epoch Loss: 40616.2978 - Avg Loss: 163.1177\n",
            "Epoch [25/50] - Batch loss: 168.1149 - Epoch Loss: 40784.4127 - Avg Loss: 163.1377\n",
            "Epoch [25/50] - Batch loss: 174.3548 - Epoch Loss: 40958.7676 - Avg Loss: 163.1823\n",
            "Epoch [25/50] - Batch loss: 160.5522 - Epoch Loss: 41119.3198 - Avg Loss: 163.1719\n",
            "Epoch [25/50] - Batch loss: 165.5696 - Epoch Loss: 41284.8894 - Avg Loss: 163.1814\n",
            "Epoch [25/50] - Batch loss: 160.8670 - Epoch Loss: 41445.7564 - Avg Loss: 163.1723\n",
            "Epoch [25/50] - Batch loss: 160.8590 - Epoch Loss: 41606.6154 - Avg Loss: 163.1632\n",
            "Epoch [25/50] - Batch loss: 157.0525 - Epoch Loss: 41763.6678 - Avg Loss: 163.1393\n",
            "Epoch [25/50] - Batch loss: 169.2848 - Epoch Loss: 41932.9527 - Avg Loss: 163.1632\n",
            "Epoch [25/50] - Batch loss: 162.3723 - Epoch Loss: 42095.3250 - Avg Loss: 163.1602\n",
            "Epoch [25/50] - Batch loss: 164.5876 - Epoch Loss: 42259.9126 - Avg Loss: 163.1657\n",
            "Epoch [25/50] - Batch loss: 166.4049 - Epoch Loss: 42426.3175 - Avg Loss: 163.1781\n",
            "Epoch [25/50] - Batch loss: 171.9873 - Epoch Loss: 42598.3048 - Avg Loss: 163.2119\n",
            "Epoch [25/50] - Batch loss: 162.0389 - Epoch Loss: 42760.3437 - Avg Loss: 163.2074\n",
            "Epoch [25/50] - Batch loss: 166.3236 - Epoch Loss: 42926.6673 - Avg Loss: 163.2193\n",
            "Epoch [25/50] - Batch loss: 169.3593 - Epoch Loss: 43096.0266 - Avg Loss: 163.2425\n",
            "Epoch [25/50] - Batch loss: 162.9888 - Epoch Loss: 43259.0154 - Avg Loss: 163.2416\n",
            "Epoch [25/50] - Batch loss: 163.3060 - Epoch Loss: 43422.3214 - Avg Loss: 163.2418\n",
            "Epoch [25/50] - Batch loss: 162.2852 - Epoch Loss: 43584.6066 - Avg Loss: 163.2382\n",
            "Epoch [25/50] - Batch loss: 163.7603 - Epoch Loss: 43748.3669 - Avg Loss: 163.2402\n",
            "Epoch [25/50] - Batch loss: 174.6393 - Epoch Loss: 43923.0063 - Avg Loss: 163.2826\n",
            "Epoch [25/50] - Batch loss: 164.0777 - Epoch Loss: 44087.0840 - Avg Loss: 163.2855\n",
            "Epoch [25/50] - Batch loss: 163.4354 - Epoch Loss: 44250.5194 - Avg Loss: 163.2860\n",
            "Epoch [25/50] - Batch loss: 164.7694 - Epoch Loss: 44415.2889 - Avg Loss: 163.2915\n",
            "Epoch [25/50] - Batch loss: 157.5728 - Epoch Loss: 44572.8617 - Avg Loss: 163.2706\n",
            "Epoch [25/50] - Batch loss: 155.4856 - Epoch Loss: 44728.3473 - Avg Loss: 163.2421\n",
            "Epoch [25/50] - Batch loss: 166.8678 - Epoch Loss: 44895.2151 - Avg Loss: 163.2553\n",
            "Epoch [25/50] - Batch loss: 157.2121 - Epoch Loss: 45052.4272 - Avg Loss: 163.2334\n",
            "Epoch [25/50] - Batch loss: 171.4222 - Epoch Loss: 45223.8495 - Avg Loss: 163.2630\n",
            "Epoch [25/50] - Batch loss: 161.6635 - Epoch Loss: 45385.5130 - Avg Loss: 163.2572\n",
            "Epoch [25/50] - Batch loss: 155.9294 - Epoch Loss: 45541.4424 - Avg Loss: 163.2310\n",
            "Epoch [25/50] - Batch loss: 155.9212 - Epoch Loss: 45697.3636 - Avg Loss: 163.2049\n",
            "Epoch [25/50] - Batch loss: 155.8779 - Epoch Loss: 45853.2415 - Avg Loss: 163.1788\n",
            "Epoch [25/50] - Batch loss: 165.8957 - Epoch Loss: 46019.1372 - Avg Loss: 163.1884\n",
            "Epoch [25/50] - Batch loss: 164.8804 - Epoch Loss: 46184.0176 - Avg Loss: 163.1944\n",
            "Epoch [25/50] - Batch loss: 158.5243 - Epoch Loss: 46342.5419 - Avg Loss: 163.1780\n",
            "Epoch [25/50] - Batch loss: 160.7554 - Epoch Loss: 46503.2973 - Avg Loss: 163.1695\n",
            "Epoch [25/50] - Batch loss: 161.1917 - Epoch Loss: 46664.4889 - Avg Loss: 163.1625\n",
            "Epoch [25/50] - Batch loss: 159.7830 - Epoch Loss: 46824.2720 - Avg Loss: 163.1508\n",
            "Epoch [25/50] - Batch loss: 154.9861 - Epoch Loss: 46979.2580 - Avg Loss: 163.1224\n",
            "Epoch [25/50] - Batch loss: 160.1808 - Epoch Loss: 47139.4388 - Avg Loss: 163.1122\n",
            "Epoch [25/50] - Batch loss: 153.7814 - Epoch Loss: 47293.2202 - Avg Loss: 163.0801\n",
            "Epoch [25/50] - Batch loss: 154.8244 - Epoch Loss: 47448.0446 - Avg Loss: 163.0517\n",
            "Epoch [25/50] - Batch loss: 165.7457 - Epoch Loss: 47613.7903 - Avg Loss: 163.0609\n",
            "Epoch [25/50] - Batch loss: 165.2714 - Epoch Loss: 47779.0617 - Avg Loss: 163.0685\n",
            "Epoch [25/50] - Batch loss: 156.8662 - Epoch Loss: 47935.9279 - Avg Loss: 163.0474\n",
            "Epoch [25/50] - Batch loss: 168.4854 - Epoch Loss: 48104.4133 - Avg Loss: 163.0658\n",
            "Epoch [25/50] - Batch loss: 165.7741 - Epoch Loss: 48270.1874 - Avg Loss: 163.0750\n",
            "Epoch [25/50] - Batch loss: 156.4067 - Epoch Loss: 48426.5941 - Avg Loss: 163.0525\n",
            "Epoch [25/50] - Batch loss: 159.6862 - Epoch Loss: 48586.2803 - Avg Loss: 163.0412\n",
            "Epoch [25/50] - Batch loss: 167.6237 - Epoch Loss: 48753.9040 - Avg Loss: 163.0565\n",
            "Epoch [25/50] - Batch loss: 162.8508 - Epoch Loss: 48916.7549 - Avg Loss: 163.0558\n",
            "Epoch [25/50] - Batch loss: 153.2923 - Epoch Loss: 49070.0471 - Avg Loss: 163.0234\n",
            "Epoch [25/50] - Batch loss: 164.4012 - Epoch Loss: 49234.4484 - Avg Loss: 163.0280\n",
            "Epoch [25/50] - Batch loss: 167.0668 - Epoch Loss: 49401.5152 - Avg Loss: 163.0413\n",
            "Epoch [25/50] - Batch loss: 160.1870 - Epoch Loss: 49561.7021 - Avg Loss: 163.0319\n",
            "Epoch [25/50] - Batch loss: 164.3243 - Epoch Loss: 49726.0264 - Avg Loss: 163.0362\n",
            "Epoch [25/50] - Batch loss: 163.6701 - Epoch Loss: 49889.6965 - Avg Loss: 163.0382\n",
            "Epoch [25/50] - Batch loss: 155.9625 - Epoch Loss: 50045.6590 - Avg Loss: 163.0152\n",
            "Epoch [25/50] - Batch loss: 154.8014 - Epoch Loss: 50200.4604 - Avg Loss: 162.9885\n",
            "Epoch [25/50] - Batch loss: 159.4484 - Epoch Loss: 50359.9089 - Avg Loss: 162.9771\n",
            "Epoch [25/50] - Batch loss: 165.3192 - Epoch Loss: 50525.2280 - Avg Loss: 162.9846\n",
            "Epoch [25/50] - Batch loss: 153.2372 - Epoch Loss: 50678.4653 - Avg Loss: 162.9533\n",
            "Epoch [25/50] - Batch loss: 164.7454 - Epoch Loss: 50843.2107 - Avg Loss: 162.9590\n",
            "Epoch [25/50] - Batch loss: 162.6486 - Epoch Loss: 51005.8593 - Avg Loss: 162.9580\n",
            "Epoch [25/50] - Batch loss: 162.7969 - Epoch Loss: 51168.6562 - Avg Loss: 162.9575\n",
            "Epoch [25/50] - Batch loss: 161.5793 - Epoch Loss: 51330.2355 - Avg Loss: 162.9531\n",
            "Epoch [25/50] - Batch loss: 161.2612 - Epoch Loss: 51491.4967 - Avg Loss: 162.9478\n",
            "Epoch [25/50] - Batch loss: 166.5201 - Epoch Loss: 51658.0169 - Avg Loss: 162.9590\n",
            "Epoch [25/50] - Batch loss: 152.5545 - Epoch Loss: 51810.5714 - Avg Loss: 162.9263\n",
            "Epoch [25/50] - Batch loss: 164.0417 - Epoch Loss: 51974.6131 - Avg Loss: 162.9298\n",
            "Epoch [25/50] - Batch loss: 159.7732 - Epoch Loss: 52134.3863 - Avg Loss: 162.9200\n",
            "Epoch [25/50] - Batch loss: 158.5942 - Epoch Loss: 52292.9806 - Avg Loss: 162.9065\n",
            "Epoch [25/50] - Batch loss: 164.8723 - Epoch Loss: 52457.8528 - Avg Loss: 162.9126\n",
            "Epoch [25/50] - Batch loss: 161.4966 - Epoch Loss: 52619.3494 - Avg Loss: 162.9082\n",
            "Epoch [25/50] - Batch loss: 162.6227 - Epoch Loss: 52781.9721 - Avg Loss: 162.9073\n",
            "Epoch [25/50] - Batch loss: 162.5471 - Epoch Loss: 52944.5191 - Avg Loss: 162.9062\n",
            "Epoch [25/50] - Batch loss: 157.6194 - Epoch Loss: 53102.1385 - Avg Loss: 162.8900\n",
            "Epoch [25/50] - Batch loss: 161.5379 - Epoch Loss: 53263.6765 - Avg Loss: 162.8859\n",
            "Epoch [25/50] - Batch loss: 161.0830 - Epoch Loss: 53424.7595 - Avg Loss: 162.8804\n",
            "Epoch [25/50] - Batch loss: 152.6653 - Epoch Loss: 53577.4248 - Avg Loss: 162.8493\n",
            "Epoch [25/50] - Batch loss: 159.9290 - Epoch Loss: 53737.3538 - Avg Loss: 162.8405\n",
            "Epoch [25/50] - Batch loss: 161.1194 - Epoch Loss: 53898.4732 - Avg Loss: 162.8353\n",
            "Epoch [25/50] - Batch loss: 162.5893 - Epoch Loss: 54061.0625 - Avg Loss: 162.8345\n",
            "Epoch [25/50] - Batch loss: 168.6156 - Epoch Loss: 54229.6781 - Avg Loss: 162.8519\n",
            "Epoch [25/50] - Batch loss: 161.8329 - Epoch Loss: 54391.5110 - Avg Loss: 162.8488\n",
            "Epoch [25/50] - Batch loss: 149.1143 - Epoch Loss: 54540.6252 - Avg Loss: 162.8078\n",
            "Epoch [25/50] - Batch loss: 154.6163 - Epoch Loss: 54695.2415 - Avg Loss: 162.7835\n",
            "Epoch [25/50] - Batch loss: 157.6784 - Epoch Loss: 54852.9198 - Avg Loss: 162.7683\n",
            "Epoch [25/50] - Batch loss: 159.4154 - Epoch Loss: 55012.3352 - Avg Loss: 162.7584\n",
            "Epoch [25/50] - Batch loss: 158.0202 - Epoch Loss: 55170.3554 - Avg Loss: 162.7444\n",
            "Epoch [25/50] - Batch loss: 155.1058 - Epoch Loss: 55325.4612 - Avg Loss: 162.7219\n",
            "Epoch [25/50] - Batch loss: 165.5687 - Epoch Loss: 55491.0299 - Avg Loss: 162.7303\n",
            "Epoch [25/50] - Batch loss: 168.2957 - Epoch Loss: 55659.3256 - Avg Loss: 162.7466\n",
            "Epoch [25/50] - Batch loss: 158.9931 - Epoch Loss: 55818.3188 - Avg Loss: 162.7356\n",
            "Epoch [25/50] - Batch loss: 160.3023 - Epoch Loss: 55978.6211 - Avg Loss: 162.7285\n",
            "Epoch [25/50] - Batch loss: 164.9734 - Epoch Loss: 56143.5945 - Avg Loss: 162.7351\n",
            "Epoch [25/50] - Batch loss: 162.8128 - Epoch Loss: 56306.4073 - Avg Loss: 162.7353\n",
            "Epoch [25/50] - Batch loss: 158.2812 - Epoch Loss: 56464.6885 - Avg Loss: 162.7224\n",
            "Epoch [25/50] - Batch loss: 159.5657 - Epoch Loss: 56624.2542 - Avg Loss: 162.7134\n",
            "Epoch [25/50] - Batch loss: 160.7916 - Epoch Loss: 56785.0458 - Avg Loss: 162.7079\n",
            "Epoch [25/50] - Batch loss: 160.2986 - Epoch Loss: 56945.3445 - Avg Loss: 162.7010\n",
            "Epoch [25/50] - Batch loss: 161.3880 - Epoch Loss: 57106.7325 - Avg Loss: 162.6972\n",
            "Epoch [25/50] - Batch loss: 168.0874 - Epoch Loss: 57274.8199 - Avg Loss: 162.7126\n",
            "Epoch [25/50] - Batch loss: 162.4695 - Epoch Loss: 57437.2894 - Avg Loss: 162.7119\n",
            "Epoch [25/50] - Batch loss: 161.0204 - Epoch Loss: 57598.3098 - Avg Loss: 162.7071\n",
            "Epoch [25/50] - Batch loss: 153.6109 - Epoch Loss: 57751.9207 - Avg Loss: 162.6815\n",
            "Epoch [25/50] - Batch loss: 166.6195 - Epoch Loss: 57918.5401 - Avg Loss: 162.6925\n",
            "Epoch [25/50] - Batch loss: 155.8487 - Epoch Loss: 58074.3888 - Avg Loss: 162.6734\n",
            "Epoch [25/50] - Batch loss: 164.3666 - Epoch Loss: 58238.7554 - Avg Loss: 162.6781\n",
            "Epoch [25/50] - Batch loss: 161.9266 - Epoch Loss: 58400.6819 - Avg Loss: 162.6760\n",
            "Epoch [25/50] - Batch loss: 161.3432 - Epoch Loss: 58562.0251 - Avg Loss: 162.6723\n",
            "Epoch [25/50] - Batch loss: 170.8087 - Epoch Loss: 58732.8338 - Avg Loss: 162.6948\n",
            "Epoch [25/50] - Batch loss: 160.3981 - Epoch Loss: 58893.2319 - Avg Loss: 162.6885\n",
            "Epoch [25/50] - Batch loss: 156.7918 - Epoch Loss: 59050.0237 - Avg Loss: 162.6722\n",
            "Epoch [25/50] - Batch loss: 160.2599 - Epoch Loss: 59210.2836 - Avg Loss: 162.6656\n",
            "Epoch [25/50] - Batch loss: 169.6617 - Epoch Loss: 59379.9453 - Avg Loss: 162.6848\n",
            "Epoch [25/50] - Batch loss: 169.1934 - Epoch Loss: 59549.1387 - Avg Loss: 162.7026\n",
            "Epoch [25/50] - Batch loss: 152.8128 - Epoch Loss: 59701.9514 - Avg Loss: 162.6756\n",
            "Epoch [25/50] - Batch loss: 153.3291 - Epoch Loss: 59855.2806 - Avg Loss: 162.6502\n",
            "Epoch [25/50] - Batch loss: 153.7481 - Epoch Loss: 60009.0287 - Avg Loss: 162.6261\n",
            "Epoch [25/50] - Batch loss: 157.6632 - Epoch Loss: 60166.6918 - Avg Loss: 162.6127\n",
            "Epoch [25/50] - Batch loss: 168.2329 - Epoch Loss: 60334.9248 - Avg Loss: 162.6278\n",
            "Epoch [25/50] - Batch loss: 156.9910 - Epoch Loss: 60491.9158 - Avg Loss: 162.6127\n",
            "Epoch [25/50] - Batch loss: 157.1127 - Epoch Loss: 60649.0285 - Avg Loss: 162.5979\n",
            "Epoch [25/50] - Batch loss: 163.2897 - Epoch Loss: 60812.3183 - Avg Loss: 162.5998\n",
            "Epoch [25/50] - Batch loss: 158.6582 - Epoch Loss: 60970.9765 - Avg Loss: 162.5893\n",
            "Epoch [25/50] - Batch loss: 153.0182 - Epoch Loss: 61123.9946 - Avg Loss: 162.5638\n",
            "Epoch [25/50] - Batch loss: 154.3973 - Epoch Loss: 61278.3920 - Avg Loss: 162.5422\n",
            "Epoch [25/50] - Batch loss: 159.3756 - Epoch Loss: 61437.7675 - Avg Loss: 162.5338\n",
            "Epoch [25/50] - Batch loss: 159.7690 - Epoch Loss: 61597.5366 - Avg Loss: 162.5265\n",
            "Epoch [25/50] - Batch loss: 159.4227 - Epoch Loss: 61756.9593 - Avg Loss: 162.5183\n",
            "Epoch [25/50] - Batch loss: 160.4340 - Epoch Loss: 61917.3933 - Avg Loss: 162.5128\n",
            "Epoch [25/50] - Batch loss: 158.7319 - Epoch Loss: 62076.1252 - Avg Loss: 162.5029\n",
            "Epoch [25/50] - Batch loss: 154.5117 - Epoch Loss: 62230.6369 - Avg Loss: 162.4821\n",
            "Epoch [25/50] - Batch loss: 168.6025 - Epoch Loss: 62399.2395 - Avg Loss: 162.4980\n",
            "Epoch [25/50] - Batch loss: 160.0945 - Epoch Loss: 62559.3340 - Avg Loss: 162.4918\n",
            "Epoch [25/50] - Batch loss: 153.5615 - Epoch Loss: 62712.8954 - Avg Loss: 162.4686\n",
            "Epoch [25/50] - Batch loss: 167.1802 - Epoch Loss: 62880.0756 - Avg Loss: 162.4808\n",
            "Epoch [25/50] - Batch loss: 153.8033 - Epoch Loss: 63033.8788 - Avg Loss: 162.4585\n",
            "Epoch [25/50] - Batch loss: 151.0551 - Epoch Loss: 63184.9339 - Avg Loss: 162.4291\n",
            "Epoch [25/50] - Batch loss: 162.8929 - Epoch Loss: 63347.8269 - Avg Loss: 162.4303\n",
            "Epoch [25/50] - Batch loss: 153.3050 - Epoch Loss: 63501.1319 - Avg Loss: 162.4070\n",
            "Epoch [25/50] - Batch loss: 162.0658 - Epoch Loss: 63663.1976 - Avg Loss: 162.4061\n",
            "Epoch [25/50] - Batch loss: 164.8733 - Epoch Loss: 63828.0709 - Avg Loss: 162.4124\n",
            "Epoch [25/50] - Batch loss: 154.5945 - Epoch Loss: 63982.6654 - Avg Loss: 162.3926\n",
            "Epoch [25/50] - Batch loss: 153.9180 - Epoch Loss: 64136.5834 - Avg Loss: 162.3711\n",
            "Epoch [25/50] - Batch loss: 164.8275 - Epoch Loss: 64301.4110 - Avg Loss: 162.3773\n",
            "Epoch [25/50] - Batch loss: 156.5420 - Epoch Loss: 64457.9530 - Avg Loss: 162.3626\n",
            "Epoch [25/50] - Batch loss: 166.5662 - Epoch Loss: 64624.5192 - Avg Loss: 162.3732\n",
            "Epoch [25/50] - Batch loss: 162.1449 - Epoch Loss: 64786.6640 - Avg Loss: 162.3726\n",
            "Epoch [25/50] - Batch loss: 155.7672 - Epoch Loss: 64942.4312 - Avg Loss: 162.3561\n",
            "Epoch [25/50] - Batch loss: 160.1677 - Epoch Loss: 65102.5989 - Avg Loss: 162.3506\n",
            "Epoch [25/50] - Batch loss: 161.0507 - Epoch Loss: 65263.6496 - Avg Loss: 162.3474\n",
            "Epoch [25/50] - Batch loss: 162.1446 - Epoch Loss: 65425.7943 - Avg Loss: 162.3469\n",
            "Epoch [25/50] - Batch loss: 154.8666 - Epoch Loss: 65580.6608 - Avg Loss: 162.3284\n",
            "Epoch [25/50] - Batch loss: 156.8685 - Epoch Loss: 65737.5293 - Avg Loss: 162.3149\n",
            "Epoch [25/50] - Batch loss: 165.7133 - Epoch Loss: 65903.2427 - Avg Loss: 162.3233\n",
            "Epoch [25/50] - Batch loss: 159.8226 - Epoch Loss: 66063.0653 - Avg Loss: 162.3171\n",
            "Epoch [25/50] - Batch loss: 164.0790 - Epoch Loss: 66227.1442 - Avg Loss: 162.3214\n",
            "Epoch [25/50] - Batch loss: 160.6127 - Epoch Loss: 66387.7569 - Avg Loss: 162.3173\n",
            "Epoch [25/50] - Batch loss: 162.8734 - Epoch Loss: 66550.6303 - Avg Loss: 162.3186\n",
            "Epoch [25/50] - Batch loss: 157.5003 - Epoch Loss: 66708.1306 - Avg Loss: 162.3069\n",
            "Epoch [25/50] - Batch loss: 158.3983 - Epoch Loss: 66866.5289 - Avg Loss: 162.2974\n",
            "Epoch [25/50] - Batch loss: 154.8976 - Epoch Loss: 67021.4265 - Avg Loss: 162.2795\n",
            "Epoch [25/50] - Batch loss: 157.7412 - Epoch Loss: 67179.1676 - Avg Loss: 162.2685\n",
            "Epoch [25/50] - Batch loss: 151.7792 - Epoch Loss: 67330.9469 - Avg Loss: 162.2432\n",
            "Epoch [25/50] - Batch loss: 157.5262 - Epoch Loss: 67488.4731 - Avg Loss: 162.2319\n",
            "Epoch [25/50] - Batch loss: 156.8349 - Epoch Loss: 67645.3079 - Avg Loss: 162.2190\n",
            "Epoch [25/50] - Batch loss: 154.3380 - Epoch Loss: 67799.6460 - Avg Loss: 162.2001\n",
            "Epoch [25/50] - Batch loss: 160.3512 - Epoch Loss: 67959.9971 - Avg Loss: 162.1957\n",
            "Epoch [25/50] - Batch loss: 159.7150 - Epoch Loss: 68119.7121 - Avg Loss: 162.1898\n",
            "Epoch [25/50] - Batch loss: 160.4857 - Epoch Loss: 68280.1978 - Avg Loss: 162.1857\n",
            "Epoch [25/50] - Batch loss: 164.7233 - Epoch Loss: 68444.9211 - Avg Loss: 162.1918\n",
            "Epoch [25/50] - Batch loss: 160.4635 - Epoch Loss: 68605.3846 - Avg Loss: 162.1877\n",
            "Epoch [25/50] - Batch loss: 164.1643 - Epoch Loss: 68769.5489 - Avg Loss: 162.1923\n",
            "Epoch [25/50] - Batch loss: 170.1782 - Epoch Loss: 68939.7271 - Avg Loss: 162.2111\n",
            "Epoch [25/50] - Batch loss: 161.0290 - Epoch Loss: 69100.7561 - Avg Loss: 162.2083\n",
            "Epoch [25/50] - Batch loss: 159.1698 - Epoch Loss: 69259.9258 - Avg Loss: 162.2012\n",
            "Epoch [25/50] - Batch loss: 162.0567 - Epoch Loss: 69421.9826 - Avg Loss: 162.2009\n",
            "Epoch [25/50] - Batch loss: 154.8026 - Epoch Loss: 69576.7852 - Avg Loss: 162.1836\n",
            "Epoch [25/50] - Batch loss: 158.3775 - Epoch Loss: 69735.1627 - Avg Loss: 162.1748\n",
            "Epoch [25/50] - Batch loss: 161.4138 - Epoch Loss: 69896.5765 - Avg Loss: 162.1730\n",
            "Epoch [25/50] - Batch loss: 162.9347 - Epoch Loss: 70059.5112 - Avg Loss: 162.1748\n",
            "Epoch [25/50] - Batch loss: 166.9760 - Epoch Loss: 70226.4873 - Avg Loss: 162.1859\n",
            "Epoch [25/50] - Batch loss: 162.0680 - Epoch Loss: 70388.5553 - Avg Loss: 162.1856\n",
            "Epoch [25/50] - Batch loss: 155.2119 - Epoch Loss: 70543.7672 - Avg Loss: 162.1696\n",
            "Epoch [25/50] - Batch loss: 160.2607 - Epoch Loss: 70704.0279 - Avg Loss: 162.1652\n",
            "Epoch [25/50] - Batch loss: 153.3551 - Epoch Loss: 70857.3830 - Avg Loss: 162.1450\n",
            "Epoch [25/50] - Batch loss: 159.0358 - Epoch Loss: 71016.4189 - Avg Loss: 162.1379\n",
            "Epoch [25/50] - Batch loss: 150.5230 - Epoch Loss: 71166.9418 - Avg Loss: 162.1115\n",
            "Epoch [25/50] - Batch loss: 159.7789 - Epoch Loss: 71326.7207 - Avg Loss: 162.1062\n",
            "Epoch [25/50] - Batch loss: 158.0446 - Epoch Loss: 71484.7654 - Avg Loss: 162.0970\n",
            "Epoch [25/50] - Batch loss: 158.1495 - Epoch Loss: 71642.9148 - Avg Loss: 162.0880\n",
            "Epoch [25/50] - Batch loss: 155.5121 - Epoch Loss: 71798.4269 - Avg Loss: 162.0732\n",
            "Epoch [25/50] - Batch loss: 158.6036 - Epoch Loss: 71957.0305 - Avg Loss: 162.0654\n",
            "Epoch [25/50] - Batch loss: 150.3936 - Epoch Loss: 72107.4242 - Avg Loss: 162.0392\n",
            "Epoch [25/50] - Batch loss: 158.1653 - Epoch Loss: 72265.5895 - Avg Loss: 162.0305\n",
            "Epoch [25/50] - Batch loss: 158.2101 - Epoch Loss: 72423.7995 - Avg Loss: 162.0219\n",
            "Epoch [25/50] - Batch loss: 154.7839 - Epoch Loss: 72578.5834 - Avg Loss: 162.0058\n",
            "Epoch [25/50] - Batch loss: 148.3225 - Epoch Loss: 72726.9059 - Avg Loss: 161.9753\n",
            "Epoch [25/50] - Batch loss: 147.8525 - Epoch Loss: 72874.7585 - Avg Loss: 161.9439\n",
            "Epoch [25/50] - Batch loss: 153.6107 - Epoch Loss: 73028.3692 - Avg Loss: 161.9254\n",
            "Epoch [25/50] - Batch loss: 148.2787 - Epoch Loss: 73176.6479 - Avg Loss: 161.8952\n",
            "Epoch [25/50] - Batch loss: 167.2187 - Epoch Loss: 73343.8666 - Avg Loss: 161.9070\n",
            "Epoch [25/50] - Batch loss: 158.3980 - Epoch Loss: 73502.2646 - Avg Loss: 161.8993\n",
            "Epoch [25/50] - Batch loss: 161.1901 - Epoch Loss: 73663.4547 - Avg Loss: 161.8977\n",
            "Epoch [25/50] - Batch loss: 154.5860 - Epoch Loss: 73818.0408 - Avg Loss: 161.8817\n",
            "Epoch [25/50] - Batch loss: 163.9278 - Epoch Loss: 73981.9685 - Avg Loss: 161.8861\n",
            "Epoch [25/50] - Batch loss: 169.1788 - Epoch Loss: 74151.1474 - Avg Loss: 161.9021\n",
            "Epoch [25/50] - Batch loss: 159.2321 - Epoch Loss: 74310.3795 - Avg Loss: 161.8963\n",
            "Epoch [25/50] - Batch loss: 162.9043 - Epoch Loss: 74473.2838 - Avg Loss: 161.8984\n",
            "Epoch [25/50] - Batch loss: 157.8445 - Epoch Loss: 74631.1283 - Avg Loss: 161.8896\n",
            "Epoch [25/50] - Batch loss: 164.2536 - Epoch Loss: 74795.3818 - Avg Loss: 161.8948\n",
            "Epoch [25/50] - Batch loss: 157.8352 - Epoch Loss: 74953.2171 - Avg Loss: 161.8860\n",
            "Epoch [25/50] - Batch loss: 166.4064 - Epoch Loss: 75119.6235 - Avg Loss: 161.8957\n",
            "Epoch [25/50] - Batch loss: 154.1328 - Epoch Loss: 75273.7563 - Avg Loss: 161.8790\n",
            "Epoch [25/50] - Batch loss: 162.4888 - Epoch Loss: 75436.2451 - Avg Loss: 161.8804\n",
            "Epoch [25/50] - Batch loss: 152.3444 - Epoch Loss: 75588.5895 - Avg Loss: 161.8599\n",
            "Epoch [25/50] - Batch loss: 158.7550 - Epoch Loss: 75747.3445 - Avg Loss: 161.8533\n",
            "Epoch [25/50] - Batch loss: 163.2076 - Epoch Loss: 75910.5521 - Avg Loss: 161.8562\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 26/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "454a6c4458994d329be9af40606cdf21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26/50] - Batch loss: 162.4455 - Epoch Loss: 162.4455 - Avg Loss: 162.4455\n",
            "Epoch [26/50] - Batch loss: 157.1500 - Epoch Loss: 319.5955 - Avg Loss: 159.7978\n",
            "Epoch [26/50] - Batch loss: 152.9314 - Epoch Loss: 472.5269 - Avg Loss: 157.5090\n",
            "Epoch [26/50] - Batch loss: 157.2489 - Epoch Loss: 629.7757 - Avg Loss: 157.4439\n",
            "Epoch [26/50] - Batch loss: 154.5297 - Epoch Loss: 784.3054 - Avg Loss: 156.8611\n",
            "Epoch [26/50] - Batch loss: 153.2707 - Epoch Loss: 937.5761 - Avg Loss: 156.2627\n",
            "Epoch [26/50] - Batch loss: 153.8633 - Epoch Loss: 1091.4395 - Avg Loss: 155.9199\n",
            "Epoch [26/50] - Batch loss: 159.6944 - Epoch Loss: 1251.1338 - Avg Loss: 156.3917\n",
            "Epoch [26/50] - Batch loss: 155.7930 - Epoch Loss: 1406.9268 - Avg Loss: 156.3252\n",
            "Epoch [26/50] - Batch loss: 158.3533 - Epoch Loss: 1565.2801 - Avg Loss: 156.5280\n",
            "Epoch [26/50] - Batch loss: 162.4169 - Epoch Loss: 1727.6970 - Avg Loss: 157.0634\n",
            "Epoch [26/50] - Batch loss: 157.1201 - Epoch Loss: 1884.8171 - Avg Loss: 157.0681\n",
            "Epoch [26/50] - Batch loss: 154.2583 - Epoch Loss: 2039.0753 - Avg Loss: 156.8519\n",
            "Epoch [26/50] - Batch loss: 155.8546 - Epoch Loss: 2194.9300 - Avg Loss: 156.7807\n",
            "Epoch [26/50] - Batch loss: 155.5721 - Epoch Loss: 2350.5020 - Avg Loss: 156.7001\n",
            "Epoch [26/50] - Batch loss: 159.2119 - Epoch Loss: 2509.7140 - Avg Loss: 156.8571\n",
            "Epoch [26/50] - Batch loss: 160.1742 - Epoch Loss: 2669.8882 - Avg Loss: 157.0522\n",
            "Epoch [26/50] - Batch loss: 156.0004 - Epoch Loss: 2825.8886 - Avg Loss: 156.9938\n",
            "Epoch [26/50] - Batch loss: 155.2645 - Epoch Loss: 2981.1531 - Avg Loss: 156.9028\n",
            "Epoch [26/50] - Batch loss: 164.1222 - Epoch Loss: 3145.2753 - Avg Loss: 157.2638\n",
            "Epoch [26/50] - Batch loss: 152.7040 - Epoch Loss: 3297.9793 - Avg Loss: 157.0466\n",
            "Epoch [26/50] - Batch loss: 154.4392 - Epoch Loss: 3452.4185 - Avg Loss: 156.9281\n",
            "Epoch [26/50] - Batch loss: 160.5477 - Epoch Loss: 3612.9663 - Avg Loss: 157.0855\n",
            "Epoch [26/50] - Batch loss: 160.0694 - Epoch Loss: 3773.0356 - Avg Loss: 157.2098\n",
            "Epoch [26/50] - Batch loss: 155.9186 - Epoch Loss: 3928.9542 - Avg Loss: 157.1582\n",
            "Epoch [26/50] - Batch loss: 162.5780 - Epoch Loss: 4091.5322 - Avg Loss: 157.3666\n",
            "Epoch [26/50] - Batch loss: 151.4972 - Epoch Loss: 4243.0294 - Avg Loss: 157.1492\n",
            "Epoch [26/50] - Batch loss: 151.8418 - Epoch Loss: 4394.8712 - Avg Loss: 156.9597\n",
            "Epoch [26/50] - Batch loss: 157.2050 - Epoch Loss: 4552.0762 - Avg Loss: 156.9681\n",
            "Epoch [26/50] - Batch loss: 162.6104 - Epoch Loss: 4714.6866 - Avg Loss: 157.1562\n",
            "Epoch [26/50] - Batch loss: 156.4155 - Epoch Loss: 4871.1021 - Avg Loss: 157.1323\n",
            "Epoch [26/50] - Batch loss: 160.8608 - Epoch Loss: 5031.9629 - Avg Loss: 157.2488\n",
            "Epoch [26/50] - Batch loss: 153.4203 - Epoch Loss: 5185.3833 - Avg Loss: 157.1328\n",
            "Epoch [26/50] - Batch loss: 155.7484 - Epoch Loss: 5341.1317 - Avg Loss: 157.0921\n",
            "Epoch [26/50] - Batch loss: 163.8091 - Epoch Loss: 5504.9408 - Avg Loss: 157.2840\n",
            "Epoch [26/50] - Batch loss: 169.2920 - Epoch Loss: 5674.2328 - Avg Loss: 157.6176\n",
            "Epoch [26/50] - Batch loss: 153.5517 - Epoch Loss: 5827.7845 - Avg Loss: 157.5077\n",
            "Epoch [26/50] - Batch loss: 158.1374 - Epoch Loss: 5985.9219 - Avg Loss: 157.5243\n",
            "Epoch [26/50] - Batch loss: 161.6325 - Epoch Loss: 6147.5544 - Avg Loss: 157.6296\n",
            "Epoch [26/50] - Batch loss: 162.5174 - Epoch Loss: 6310.0718 - Avg Loss: 157.7518\n",
            "Epoch [26/50] - Batch loss: 152.5809 - Epoch Loss: 6462.6527 - Avg Loss: 157.6257\n",
            "Epoch [26/50] - Batch loss: 165.0730 - Epoch Loss: 6627.7257 - Avg Loss: 157.8030\n",
            "Epoch [26/50] - Batch loss: 163.6171 - Epoch Loss: 6791.3427 - Avg Loss: 157.9382\n",
            "Epoch [26/50] - Batch loss: 149.9028 - Epoch Loss: 6941.2456 - Avg Loss: 157.7556\n",
            "Epoch [26/50] - Batch loss: 160.1009 - Epoch Loss: 7101.3465 - Avg Loss: 157.8077\n",
            "Epoch [26/50] - Batch loss: 160.9124 - Epoch Loss: 7262.2589 - Avg Loss: 157.8752\n",
            "Epoch [26/50] - Batch loss: 162.6193 - Epoch Loss: 7424.8782 - Avg Loss: 157.9761\n",
            "Epoch [26/50] - Batch loss: 153.7887 - Epoch Loss: 7578.6669 - Avg Loss: 157.8889\n",
            "Epoch [26/50] - Batch loss: 154.8698 - Epoch Loss: 7733.5367 - Avg Loss: 157.8273\n",
            "Epoch [26/50] - Batch loss: 151.3155 - Epoch Loss: 7884.8522 - Avg Loss: 157.6970\n",
            "Epoch [26/50] - Batch loss: 167.4027 - Epoch Loss: 8052.2549 - Avg Loss: 157.8874\n",
            "Epoch [26/50] - Batch loss: 152.5347 - Epoch Loss: 8204.7895 - Avg Loss: 157.7844\n",
            "Epoch [26/50] - Batch loss: 156.8873 - Epoch Loss: 8361.6768 - Avg Loss: 157.7675\n",
            "Epoch [26/50] - Batch loss: 154.9854 - Epoch Loss: 8516.6622 - Avg Loss: 157.7160\n",
            "Epoch [26/50] - Batch loss: 157.8429 - Epoch Loss: 8674.5051 - Avg Loss: 157.7183\n",
            "Epoch [26/50] - Batch loss: 162.3128 - Epoch Loss: 8836.8179 - Avg Loss: 157.8003\n",
            "Epoch [26/50] - Batch loss: 152.7633 - Epoch Loss: 8989.5812 - Avg Loss: 157.7120\n",
            "Epoch [26/50] - Batch loss: 154.2382 - Epoch Loss: 9143.8194 - Avg Loss: 157.6521\n",
            "Epoch [26/50] - Batch loss: 154.1057 - Epoch Loss: 9297.9251 - Avg Loss: 157.5920\n",
            "Epoch [26/50] - Batch loss: 164.8473 - Epoch Loss: 9462.7724 - Avg Loss: 157.7129\n",
            "Epoch [26/50] - Batch loss: 158.7574 - Epoch Loss: 9621.5298 - Avg Loss: 157.7300\n",
            "Epoch [26/50] - Batch loss: 164.2012 - Epoch Loss: 9785.7310 - Avg Loss: 157.8344\n",
            "Epoch [26/50] - Batch loss: 153.4205 - Epoch Loss: 9939.1515 - Avg Loss: 157.7643\n",
            "Epoch [26/50] - Batch loss: 162.1518 - Epoch Loss: 10101.3033 - Avg Loss: 157.8329\n",
            "Epoch [26/50] - Batch loss: 157.9408 - Epoch Loss: 10259.2442 - Avg Loss: 157.8345\n",
            "Epoch [26/50] - Batch loss: 159.1661 - Epoch Loss: 10418.4103 - Avg Loss: 157.8547\n",
            "Epoch [26/50] - Batch loss: 157.6725 - Epoch Loss: 10576.0828 - Avg Loss: 157.8520\n",
            "Epoch [26/50] - Batch loss: 153.7379 - Epoch Loss: 10729.8207 - Avg Loss: 157.7915\n",
            "Epoch [26/50] - Batch loss: 159.9625 - Epoch Loss: 10889.7832 - Avg Loss: 157.8229\n",
            "Epoch [26/50] - Batch loss: 155.9366 - Epoch Loss: 11045.7198 - Avg Loss: 157.7960\n",
            "Epoch [26/50] - Batch loss: 154.4509 - Epoch Loss: 11200.1707 - Avg Loss: 157.7489\n",
            "Epoch [26/50] - Batch loss: 168.7802 - Epoch Loss: 11368.9509 - Avg Loss: 157.9021\n",
            "Epoch [26/50] - Batch loss: 157.4165 - Epoch Loss: 11526.3674 - Avg Loss: 157.8954\n",
            "Epoch [26/50] - Batch loss: 161.9470 - Epoch Loss: 11688.3144 - Avg Loss: 157.9502\n",
            "Epoch [26/50] - Batch loss: 154.8123 - Epoch Loss: 11843.1268 - Avg Loss: 157.9084\n",
            "Epoch [26/50] - Batch loss: 154.9059 - Epoch Loss: 11998.0327 - Avg Loss: 157.8689\n",
            "Epoch [26/50] - Batch loss: 161.6148 - Epoch Loss: 12159.6476 - Avg Loss: 157.9175\n",
            "Epoch [26/50] - Batch loss: 160.1653 - Epoch Loss: 12319.8129 - Avg Loss: 157.9463\n",
            "Epoch [26/50] - Batch loss: 162.5252 - Epoch Loss: 12482.3381 - Avg Loss: 158.0043\n",
            "Epoch [26/50] - Batch loss: 157.0385 - Epoch Loss: 12639.3766 - Avg Loss: 157.9922\n",
            "Epoch [26/50] - Batch loss: 153.3309 - Epoch Loss: 12792.7075 - Avg Loss: 157.9347\n",
            "Epoch [26/50] - Batch loss: 152.8387 - Epoch Loss: 12945.5462 - Avg Loss: 157.8725\n",
            "Epoch [26/50] - Batch loss: 158.6463 - Epoch Loss: 13104.1925 - Avg Loss: 157.8818\n",
            "Epoch [26/50] - Batch loss: 154.1126 - Epoch Loss: 13258.3051 - Avg Loss: 157.8370\n",
            "Epoch [26/50] - Batch loss: 158.6097 - Epoch Loss: 13416.9147 - Avg Loss: 157.8461\n",
            "Epoch [26/50] - Batch loss: 159.7800 - Epoch Loss: 13576.6947 - Avg Loss: 157.8685\n",
            "Epoch [26/50] - Batch loss: 156.0159 - Epoch Loss: 13732.7106 - Avg Loss: 157.8472\n",
            "Epoch [26/50] - Batch loss: 160.6636 - Epoch Loss: 13893.3743 - Avg Loss: 157.8793\n",
            "Epoch [26/50] - Batch loss: 154.7678 - Epoch Loss: 14048.1421 - Avg Loss: 157.8443\n",
            "Epoch [26/50] - Batch loss: 162.1888 - Epoch Loss: 14210.3309 - Avg Loss: 157.8926\n",
            "Epoch [26/50] - Batch loss: 160.3480 - Epoch Loss: 14370.6789 - Avg Loss: 157.9195\n",
            "Epoch [26/50] - Batch loss: 159.7133 - Epoch Loss: 14530.3923 - Avg Loss: 157.9390\n",
            "Epoch [26/50] - Batch loss: 158.8200 - Epoch Loss: 14689.2123 - Avg Loss: 157.9485\n",
            "Epoch [26/50] - Batch loss: 168.4497 - Epoch Loss: 14857.6620 - Avg Loss: 158.0602\n",
            "Epoch [26/50] - Batch loss: 158.1238 - Epoch Loss: 15015.7858 - Avg Loss: 158.0609\n",
            "Epoch [26/50] - Batch loss: 161.0997 - Epoch Loss: 15176.8855 - Avg Loss: 158.0926\n",
            "Epoch [26/50] - Batch loss: 158.8787 - Epoch Loss: 15335.7641 - Avg Loss: 158.1007\n",
            "Epoch [26/50] - Batch loss: 155.2820 - Epoch Loss: 15491.0462 - Avg Loss: 158.0719\n",
            "Epoch [26/50] - Batch loss: 158.8074 - Epoch Loss: 15649.8536 - Avg Loss: 158.0793\n",
            "Epoch [26/50] - Batch loss: 159.9408 - Epoch Loss: 15809.7944 - Avg Loss: 158.0979\n",
            "Epoch [26/50] - Batch loss: 154.2096 - Epoch Loss: 15964.0040 - Avg Loss: 158.0594\n",
            "Epoch [26/50] - Batch loss: 151.3432 - Epoch Loss: 16115.3471 - Avg Loss: 157.9936\n",
            "Epoch [26/50] - Batch loss: 160.8331 - Epoch Loss: 16276.1802 - Avg Loss: 158.0212\n",
            "Epoch [26/50] - Batch loss: 156.0150 - Epoch Loss: 16432.1951 - Avg Loss: 158.0019\n",
            "Epoch [26/50] - Batch loss: 159.1665 - Epoch Loss: 16591.3617 - Avg Loss: 158.0130\n",
            "Epoch [26/50] - Batch loss: 161.6367 - Epoch Loss: 16752.9984 - Avg Loss: 158.0472\n",
            "Epoch [26/50] - Batch loss: 160.6207 - Epoch Loss: 16913.6190 - Avg Loss: 158.0712\n",
            "Epoch [26/50] - Batch loss: 160.4416 - Epoch Loss: 17074.0606 - Avg Loss: 158.0932\n",
            "Epoch [26/50] - Batch loss: 156.0879 - Epoch Loss: 17230.1485 - Avg Loss: 158.0748\n",
            "Epoch [26/50] - Batch loss: 159.9920 - Epoch Loss: 17390.1405 - Avg Loss: 158.0922\n",
            "Epoch [26/50] - Batch loss: 152.4092 - Epoch Loss: 17542.5498 - Avg Loss: 158.0410\n",
            "Epoch [26/50] - Batch loss: 160.1591 - Epoch Loss: 17702.7088 - Avg Loss: 158.0599\n",
            "Epoch [26/50] - Batch loss: 163.4396 - Epoch Loss: 17866.1484 - Avg Loss: 158.1075\n",
            "Epoch [26/50] - Batch loss: 153.2981 - Epoch Loss: 18019.4465 - Avg Loss: 158.0653\n",
            "Epoch [26/50] - Batch loss: 158.2649 - Epoch Loss: 18177.7114 - Avg Loss: 158.0671\n",
            "Epoch [26/50] - Batch loss: 153.0899 - Epoch Loss: 18330.8013 - Avg Loss: 158.0241\n",
            "Epoch [26/50] - Batch loss: 159.9344 - Epoch Loss: 18490.7357 - Avg Loss: 158.0405\n",
            "Epoch [26/50] - Batch loss: 165.5622 - Epoch Loss: 18656.2979 - Avg Loss: 158.1042\n",
            "Epoch [26/50] - Batch loss: 165.4911 - Epoch Loss: 18821.7890 - Avg Loss: 158.1663\n",
            "Epoch [26/50] - Batch loss: 160.9689 - Epoch Loss: 18982.7579 - Avg Loss: 158.1896\n",
            "Epoch [26/50] - Batch loss: 157.3014 - Epoch Loss: 19140.0592 - Avg Loss: 158.1823\n",
            "Epoch [26/50] - Batch loss: 159.0239 - Epoch Loss: 19299.0831 - Avg Loss: 158.1892\n",
            "Epoch [26/50] - Batch loss: 165.0758 - Epoch Loss: 19464.1590 - Avg Loss: 158.2452\n",
            "Epoch [26/50] - Batch loss: 155.1296 - Epoch Loss: 19619.2885 - Avg Loss: 158.2201\n",
            "Epoch [26/50] - Batch loss: 161.0765 - Epoch Loss: 19780.3650 - Avg Loss: 158.2429\n",
            "Epoch [26/50] - Batch loss: 151.9852 - Epoch Loss: 19932.3502 - Avg Loss: 158.1933\n",
            "Epoch [26/50] - Batch loss: 154.4184 - Epoch Loss: 20086.7686 - Avg Loss: 158.1635\n",
            "Epoch [26/50] - Batch loss: 163.1099 - Epoch Loss: 20249.8785 - Avg Loss: 158.2022\n",
            "Epoch [26/50] - Batch loss: 161.2588 - Epoch Loss: 20411.1374 - Avg Loss: 158.2259\n",
            "Epoch [26/50] - Batch loss: 163.2620 - Epoch Loss: 20574.3994 - Avg Loss: 158.2646\n",
            "Epoch [26/50] - Batch loss: 152.8251 - Epoch Loss: 20727.2245 - Avg Loss: 158.2231\n",
            "Epoch [26/50] - Batch loss: 157.6523 - Epoch Loss: 20884.8768 - Avg Loss: 158.2188\n",
            "Epoch [26/50] - Batch loss: 159.3776 - Epoch Loss: 21044.2545 - Avg Loss: 158.2275\n",
            "Epoch [26/50] - Batch loss: 152.5362 - Epoch Loss: 21196.7907 - Avg Loss: 158.1850\n",
            "Epoch [26/50] - Batch loss: 156.6831 - Epoch Loss: 21353.4738 - Avg Loss: 158.1739\n",
            "Epoch [26/50] - Batch loss: 156.0772 - Epoch Loss: 21509.5509 - Avg Loss: 158.1585\n",
            "Epoch [26/50] - Batch loss: 165.9210 - Epoch Loss: 21675.4719 - Avg Loss: 158.2151\n",
            "Epoch [26/50] - Batch loss: 153.4723 - Epoch Loss: 21828.9442 - Avg Loss: 158.1808\n",
            "Epoch [26/50] - Batch loss: 165.0760 - Epoch Loss: 21994.0202 - Avg Loss: 158.2304\n",
            "Epoch [26/50] - Batch loss: 151.5336 - Epoch Loss: 22145.5538 - Avg Loss: 158.1825\n",
            "Epoch [26/50] - Batch loss: 157.3772 - Epoch Loss: 22302.9309 - Avg Loss: 158.1768\n",
            "Epoch [26/50] - Batch loss: 163.0589 - Epoch Loss: 22465.9898 - Avg Loss: 158.2112\n",
            "Epoch [26/50] - Batch loss: 164.2482 - Epoch Loss: 22630.2380 - Avg Loss: 158.2534\n",
            "Epoch [26/50] - Batch loss: 153.2374 - Epoch Loss: 22783.4754 - Avg Loss: 158.2186\n",
            "Epoch [26/50] - Batch loss: 155.7220 - Epoch Loss: 22939.1974 - Avg Loss: 158.2014\n",
            "Epoch [26/50] - Batch loss: 159.0690 - Epoch Loss: 23098.2663 - Avg Loss: 158.2073\n",
            "Epoch [26/50] - Batch loss: 157.7769 - Epoch Loss: 23256.0433 - Avg Loss: 158.2044\n",
            "Epoch [26/50] - Batch loss: 161.0717 - Epoch Loss: 23417.1149 - Avg Loss: 158.2237\n",
            "Epoch [26/50] - Batch loss: 155.5609 - Epoch Loss: 23572.6758 - Avg Loss: 158.2059\n",
            "Epoch [26/50] - Batch loss: 149.9851 - Epoch Loss: 23722.6609 - Avg Loss: 158.1511\n",
            "Epoch [26/50] - Batch loss: 156.5730 - Epoch Loss: 23879.2339 - Avg Loss: 158.1406\n",
            "Epoch [26/50] - Batch loss: 154.3538 - Epoch Loss: 24033.5877 - Avg Loss: 158.1157\n",
            "Epoch [26/50] - Batch loss: 161.3765 - Epoch Loss: 24194.9642 - Avg Loss: 158.1370\n",
            "Epoch [26/50] - Batch loss: 161.4986 - Epoch Loss: 24356.4628 - Avg Loss: 158.1588\n",
            "Epoch [26/50] - Batch loss: 159.3717 - Epoch Loss: 24515.8345 - Avg Loss: 158.1667\n",
            "Epoch [26/50] - Batch loss: 156.0340 - Epoch Loss: 24671.8685 - Avg Loss: 158.1530\n",
            "Epoch [26/50] - Batch loss: 157.5345 - Epoch Loss: 24829.4029 - Avg Loss: 158.1491\n",
            "Epoch [26/50] - Batch loss: 158.0578 - Epoch Loss: 24987.4607 - Avg Loss: 158.1485\n",
            "Epoch [26/50] - Batch loss: 161.3457 - Epoch Loss: 25148.8064 - Avg Loss: 158.1686\n",
            "Epoch [26/50] - Batch loss: 157.7024 - Epoch Loss: 25306.5088 - Avg Loss: 158.1657\n",
            "Epoch [26/50] - Batch loss: 163.8216 - Epoch Loss: 25470.3304 - Avg Loss: 158.2008\n",
            "Epoch [26/50] - Batch loss: 159.4996 - Epoch Loss: 25629.8300 - Avg Loss: 158.2088\n",
            "Epoch [26/50] - Batch loss: 160.5586 - Epoch Loss: 25790.3886 - Avg Loss: 158.2232\n",
            "Epoch [26/50] - Batch loss: 153.7306 - Epoch Loss: 25944.1192 - Avg Loss: 158.1958\n",
            "Epoch [26/50] - Batch loss: 155.9785 - Epoch Loss: 26100.0977 - Avg Loss: 158.1824\n",
            "Epoch [26/50] - Batch loss: 155.7899 - Epoch Loss: 26255.8876 - Avg Loss: 158.1680\n",
            "Epoch [26/50] - Batch loss: 158.7392 - Epoch Loss: 26414.6268 - Avg Loss: 158.1714\n",
            "Epoch [26/50] - Batch loss: 153.8897 - Epoch Loss: 26568.5165 - Avg Loss: 158.1459\n",
            "Epoch [26/50] - Batch loss: 161.2923 - Epoch Loss: 26729.8089 - Avg Loss: 158.1645\n",
            "Epoch [26/50] - Batch loss: 162.7096 - Epoch Loss: 26892.5185 - Avg Loss: 158.1913\n",
            "Epoch [26/50] - Batch loss: 150.3539 - Epoch Loss: 27042.8723 - Avg Loss: 158.1455\n",
            "Epoch [26/50] - Batch loss: 156.6283 - Epoch Loss: 27199.5006 - Avg Loss: 158.1366\n",
            "Epoch [26/50] - Batch loss: 158.8004 - Epoch Loss: 27358.3010 - Avg Loss: 158.1405\n",
            "Epoch [26/50] - Batch loss: 160.6537 - Epoch Loss: 27518.9547 - Avg Loss: 158.1549\n",
            "Epoch [26/50] - Batch loss: 153.0083 - Epoch Loss: 27671.9630 - Avg Loss: 158.1255\n",
            "Epoch [26/50] - Batch loss: 170.2623 - Epoch Loss: 27842.2253 - Avg Loss: 158.1945\n",
            "Epoch [26/50] - Batch loss: 164.8126 - Epoch Loss: 28007.0380 - Avg Loss: 158.2319\n",
            "Epoch [26/50] - Batch loss: 157.9210 - Epoch Loss: 28164.9589 - Avg Loss: 158.2301\n",
            "Epoch [26/50] - Batch loss: 165.2401 - Epoch Loss: 28330.1990 - Avg Loss: 158.2693\n",
            "Epoch [26/50] - Batch loss: 153.3851 - Epoch Loss: 28483.5841 - Avg Loss: 158.2421\n",
            "Epoch [26/50] - Batch loss: 157.5080 - Epoch Loss: 28641.0921 - Avg Loss: 158.2381\n",
            "Epoch [26/50] - Batch loss: 165.6039 - Epoch Loss: 28806.6959 - Avg Loss: 158.2785\n",
            "Epoch [26/50] - Batch loss: 158.7966 - Epoch Loss: 28965.4926 - Avg Loss: 158.2814\n",
            "Epoch [26/50] - Batch loss: 161.4019 - Epoch Loss: 29126.8945 - Avg Loss: 158.2983\n",
            "Epoch [26/50] - Batch loss: 153.7530 - Epoch Loss: 29280.6475 - Avg Loss: 158.2738\n",
            "Epoch [26/50] - Batch loss: 151.4961 - Epoch Loss: 29432.1436 - Avg Loss: 158.2373\n",
            "Epoch [26/50] - Batch loss: 167.1688 - Epoch Loss: 29599.3124 - Avg Loss: 158.2851\n",
            "Epoch [26/50] - Batch loss: 158.3851 - Epoch Loss: 29757.6976 - Avg Loss: 158.2856\n",
            "Epoch [26/50] - Batch loss: 158.5771 - Epoch Loss: 29916.2746 - Avg Loss: 158.2872\n",
            "Epoch [26/50] - Batch loss: 154.5004 - Epoch Loss: 30070.7750 - Avg Loss: 158.2672\n",
            "Epoch [26/50] - Batch loss: 163.2454 - Epoch Loss: 30234.0204 - Avg Loss: 158.2933\n",
            "Epoch [26/50] - Batch loss: 161.3198 - Epoch Loss: 30395.3403 - Avg Loss: 158.3091\n",
            "Epoch [26/50] - Batch loss: 160.5388 - Epoch Loss: 30555.8791 - Avg Loss: 158.3206\n",
            "Epoch [26/50] - Batch loss: 152.5600 - Epoch Loss: 30708.4390 - Avg Loss: 158.2909\n",
            "Epoch [26/50] - Batch loss: 150.1152 - Epoch Loss: 30858.5542 - Avg Loss: 158.2490\n",
            "Epoch [26/50] - Batch loss: 155.2015 - Epoch Loss: 31013.7558 - Avg Loss: 158.2334\n",
            "Epoch [26/50] - Batch loss: 165.0143 - Epoch Loss: 31178.7701 - Avg Loss: 158.2679\n",
            "Epoch [26/50] - Batch loss: 160.5249 - Epoch Loss: 31339.2950 - Avg Loss: 158.2793\n",
            "Epoch [26/50] - Batch loss: 157.6051 - Epoch Loss: 31496.9002 - Avg Loss: 158.2759\n",
            "Epoch [26/50] - Batch loss: 161.3739 - Epoch Loss: 31658.2741 - Avg Loss: 158.2914\n",
            "Epoch [26/50] - Batch loss: 160.1071 - Epoch Loss: 31818.3812 - Avg Loss: 158.3004\n",
            "Epoch [26/50] - Batch loss: 160.5435 - Epoch Loss: 31978.9247 - Avg Loss: 158.3115\n",
            "Epoch [26/50] - Batch loss: 158.7567 - Epoch Loss: 32137.6814 - Avg Loss: 158.3137\n",
            "Epoch [26/50] - Batch loss: 153.5164 - Epoch Loss: 32291.1978 - Avg Loss: 158.2902\n",
            "Epoch [26/50] - Batch loss: 157.5412 - Epoch Loss: 32448.7390 - Avg Loss: 158.2865\n",
            "Epoch [26/50] - Batch loss: 156.5989 - Epoch Loss: 32605.3379 - Avg Loss: 158.2783\n",
            "Epoch [26/50] - Batch loss: 157.1196 - Epoch Loss: 32762.4575 - Avg Loss: 158.2727\n",
            "Epoch [26/50] - Batch loss: 154.4778 - Epoch Loss: 32916.9353 - Avg Loss: 158.2545\n",
            "Epoch [26/50] - Batch loss: 160.9948 - Epoch Loss: 33077.9301 - Avg Loss: 158.2676\n",
            "Epoch [26/50] - Batch loss: 157.7813 - Epoch Loss: 33235.7113 - Avg Loss: 158.2653\n",
            "Epoch [26/50] - Batch loss: 152.6409 - Epoch Loss: 33388.3523 - Avg Loss: 158.2386\n",
            "Epoch [26/50] - Batch loss: 156.0376 - Epoch Loss: 33544.3898 - Avg Loss: 158.2283\n",
            "Epoch [26/50] - Batch loss: 155.5542 - Epoch Loss: 33699.9441 - Avg Loss: 158.2157\n",
            "Epoch [26/50] - Batch loss: 154.2417 - Epoch Loss: 33854.1857 - Avg Loss: 158.1971\n",
            "Epoch [26/50] - Batch loss: 156.7969 - Epoch Loss: 34010.9827 - Avg Loss: 158.1906\n",
            "Epoch [26/50] - Batch loss: 160.6446 - Epoch Loss: 34171.6272 - Avg Loss: 158.2020\n",
            "Epoch [26/50] - Batch loss: 150.6901 - Epoch Loss: 34322.3173 - Avg Loss: 158.1674\n",
            "Epoch [26/50] - Batch loss: 159.9697 - Epoch Loss: 34482.2870 - Avg Loss: 158.1756\n",
            "Epoch [26/50] - Batch loss: 158.3428 - Epoch Loss: 34640.6299 - Avg Loss: 158.1764\n",
            "Epoch [26/50] - Batch loss: 151.0321 - Epoch Loss: 34791.6620 - Avg Loss: 158.1439\n",
            "Epoch [26/50] - Batch loss: 158.1107 - Epoch Loss: 34949.7727 - Avg Loss: 158.1438\n",
            "Epoch [26/50] - Batch loss: 149.3708 - Epoch Loss: 35099.1435 - Avg Loss: 158.1042\n",
            "Epoch [26/50] - Batch loss: 158.9151 - Epoch Loss: 35258.0586 - Avg Loss: 158.1079\n",
            "Epoch [26/50] - Batch loss: 167.7832 - Epoch Loss: 35425.8418 - Avg Loss: 158.1511\n",
            "Epoch [26/50] - Batch loss: 155.7854 - Epoch Loss: 35581.6272 - Avg Loss: 158.1406\n",
            "Epoch [26/50] - Batch loss: 157.2570 - Epoch Loss: 35738.8843 - Avg Loss: 158.1367\n",
            "Epoch [26/50] - Batch loss: 155.7375 - Epoch Loss: 35894.6218 - Avg Loss: 158.1261\n",
            "Epoch [26/50] - Batch loss: 155.7307 - Epoch Loss: 36050.3524 - Avg Loss: 158.1156\n",
            "Epoch [26/50] - Batch loss: 158.2925 - Epoch Loss: 36208.6449 - Avg Loss: 158.1164\n",
            "Epoch [26/50] - Batch loss: 160.4084 - Epoch Loss: 36369.0533 - Avg Loss: 158.1263\n",
            "Epoch [26/50] - Batch loss: 160.7184 - Epoch Loss: 36529.7717 - Avg Loss: 158.1375\n",
            "Epoch [26/50] - Batch loss: 155.8575 - Epoch Loss: 36685.6292 - Avg Loss: 158.1277\n",
            "Epoch [26/50] - Batch loss: 157.3452 - Epoch Loss: 36842.9744 - Avg Loss: 158.1244\n",
            "Epoch [26/50] - Batch loss: 163.1107 - Epoch Loss: 37006.0852 - Avg Loss: 158.1457\n",
            "Epoch [26/50] - Batch loss: 156.8379 - Epoch Loss: 37162.9231 - Avg Loss: 158.1401\n",
            "Epoch [26/50] - Batch loss: 163.0508 - Epoch Loss: 37325.9739 - Avg Loss: 158.1609\n",
            "Epoch [26/50] - Batch loss: 155.8105 - Epoch Loss: 37481.7844 - Avg Loss: 158.1510\n",
            "Epoch [26/50] - Batch loss: 156.9937 - Epoch Loss: 37638.7781 - Avg Loss: 158.1461\n",
            "Epoch [26/50] - Batch loss: 150.7340 - Epoch Loss: 37789.5121 - Avg Loss: 158.1151\n",
            "Epoch [26/50] - Batch loss: 160.9677 - Epoch Loss: 37950.4798 - Avg Loss: 158.1270\n",
            "Epoch [26/50] - Batch loss: 151.9564 - Epoch Loss: 38102.4362 - Avg Loss: 158.1014\n",
            "Epoch [26/50] - Batch loss: 155.3812 - Epoch Loss: 38257.8174 - Avg Loss: 158.0902\n",
            "Epoch [26/50] - Batch loss: 162.5054 - Epoch Loss: 38420.3229 - Avg Loss: 158.1083\n",
            "Epoch [26/50] - Batch loss: 156.1532 - Epoch Loss: 38576.4761 - Avg Loss: 158.1003\n",
            "Epoch [26/50] - Batch loss: 158.0769 - Epoch Loss: 38734.5530 - Avg Loss: 158.1002\n",
            "Epoch [26/50] - Batch loss: 155.3526 - Epoch Loss: 38889.9055 - Avg Loss: 158.0890\n",
            "Epoch [26/50] - Batch loss: 154.2427 - Epoch Loss: 39044.1482 - Avg Loss: 158.0735\n",
            "Epoch [26/50] - Batch loss: 151.5200 - Epoch Loss: 39195.6682 - Avg Loss: 158.0470\n",
            "Epoch [26/50] - Batch loss: 159.0366 - Epoch Loss: 39354.7048 - Avg Loss: 158.0510\n",
            "Epoch [26/50] - Batch loss: 166.6339 - Epoch Loss: 39521.3387 - Avg Loss: 158.0854\n",
            "Epoch [26/50] - Batch loss: 157.3215 - Epoch Loss: 39678.6602 - Avg Loss: 158.0823\n",
            "Epoch [26/50] - Batch loss: 158.7901 - Epoch Loss: 39837.4503 - Avg Loss: 158.0851\n",
            "Epoch [26/50] - Batch loss: 160.8447 - Epoch Loss: 39998.2950 - Avg Loss: 158.0960\n",
            "Epoch [26/50] - Batch loss: 157.1301 - Epoch Loss: 40155.4251 - Avg Loss: 158.0922\n",
            "Epoch [26/50] - Batch loss: 149.9172 - Epoch Loss: 40305.3423 - Avg Loss: 158.0602\n",
            "Epoch [26/50] - Batch loss: 163.4190 - Epoch Loss: 40468.7613 - Avg Loss: 158.0811\n",
            "Epoch [26/50] - Batch loss: 159.0732 - Epoch Loss: 40627.8345 - Avg Loss: 158.0850\n",
            "Epoch [26/50] - Batch loss: 157.7156 - Epoch Loss: 40785.5501 - Avg Loss: 158.0835\n",
            "Epoch [26/50] - Batch loss: 160.8195 - Epoch Loss: 40946.3696 - Avg Loss: 158.0941\n",
            "Epoch [26/50] - Batch loss: 158.4401 - Epoch Loss: 41104.8097 - Avg Loss: 158.0954\n",
            "Epoch [26/50] - Batch loss: 157.9985 - Epoch Loss: 41262.8082 - Avg Loss: 158.0951\n",
            "Epoch [26/50] - Batch loss: 158.4556 - Epoch Loss: 41421.2638 - Avg Loss: 158.0964\n",
            "Epoch [26/50] - Batch loss: 159.8943 - Epoch Loss: 41581.1581 - Avg Loss: 158.1033\n",
            "Epoch [26/50] - Batch loss: 155.4783 - Epoch Loss: 41736.6365 - Avg Loss: 158.0933\n",
            "Epoch [26/50] - Batch loss: 154.0823 - Epoch Loss: 41890.7188 - Avg Loss: 158.0782\n",
            "Epoch [26/50] - Batch loss: 155.3315 - Epoch Loss: 42046.0503 - Avg Loss: 158.0679\n",
            "Epoch [26/50] - Batch loss: 161.6833 - Epoch Loss: 42207.7336 - Avg Loss: 158.0814\n",
            "Epoch [26/50] - Batch loss: 160.8571 - Epoch Loss: 42368.5908 - Avg Loss: 158.0918\n",
            "Epoch [26/50] - Batch loss: 156.1592 - Epoch Loss: 42524.7500 - Avg Loss: 158.0846\n",
            "Epoch [26/50] - Batch loss: 157.0772 - Epoch Loss: 42681.8272 - Avg Loss: 158.0808\n",
            "Epoch [26/50] - Batch loss: 153.0377 - Epoch Loss: 42834.8649 - Avg Loss: 158.0622\n",
            "Epoch [26/50] - Batch loss: 158.6285 - Epoch Loss: 42993.4934 - Avg Loss: 158.0643\n",
            "Epoch [26/50] - Batch loss: 158.1000 - Epoch Loss: 43151.5934 - Avg Loss: 158.0644\n",
            "Epoch [26/50] - Batch loss: 155.3984 - Epoch Loss: 43306.9918 - Avg Loss: 158.0547\n",
            "Epoch [26/50] - Batch loss: 158.4376 - Epoch Loss: 43465.4294 - Avg Loss: 158.0561\n",
            "Epoch [26/50] - Batch loss: 156.1488 - Epoch Loss: 43621.5782 - Avg Loss: 158.0492\n",
            "Epoch [26/50] - Batch loss: 159.1647 - Epoch Loss: 43780.7429 - Avg Loss: 158.0532\n",
            "Epoch [26/50] - Batch loss: 157.7457 - Epoch Loss: 43938.4886 - Avg Loss: 158.0521\n",
            "Epoch [26/50] - Batch loss: 151.9326 - Epoch Loss: 44090.4212 - Avg Loss: 158.0302\n",
            "Epoch [26/50] - Batch loss: 155.6502 - Epoch Loss: 44246.0714 - Avg Loss: 158.0217\n",
            "Epoch [26/50] - Batch loss: 162.1590 - Epoch Loss: 44408.2304 - Avg Loss: 158.0364\n",
            "Epoch [26/50] - Batch loss: 153.0191 - Epoch Loss: 44561.2495 - Avg Loss: 158.0186\n",
            "Epoch [26/50] - Batch loss: 157.6091 - Epoch Loss: 44718.8586 - Avg Loss: 158.0172\n",
            "Epoch [26/50] - Batch loss: 150.9765 - Epoch Loss: 44869.8352 - Avg Loss: 157.9924\n",
            "Epoch [26/50] - Batch loss: 168.9869 - Epoch Loss: 45038.8221 - Avg Loss: 158.0310\n",
            "Epoch [26/50] - Batch loss: 162.2176 - Epoch Loss: 45201.0397 - Avg Loss: 158.0456\n",
            "Epoch [26/50] - Batch loss: 156.8006 - Epoch Loss: 45357.8403 - Avg Loss: 158.0413\n",
            "Epoch [26/50] - Batch loss: 155.8740 - Epoch Loss: 45513.7144 - Avg Loss: 158.0337\n",
            "Epoch [26/50] - Batch loss: 164.6623 - Epoch Loss: 45678.3766 - Avg Loss: 158.0567\n",
            "Epoch [26/50] - Batch loss: 160.1961 - Epoch Loss: 45838.5728 - Avg Loss: 158.0640\n",
            "Epoch [26/50] - Batch loss: 157.9824 - Epoch Loss: 45996.5552 - Avg Loss: 158.0638\n",
            "Epoch [26/50] - Batch loss: 158.5907 - Epoch Loss: 46155.1459 - Avg Loss: 158.0656\n",
            "Epoch [26/50] - Batch loss: 162.8224 - Epoch Loss: 46317.9683 - Avg Loss: 158.0818\n",
            "Epoch [26/50] - Batch loss: 162.8979 - Epoch Loss: 46480.8662 - Avg Loss: 158.0982\n",
            "Epoch [26/50] - Batch loss: 151.2436 - Epoch Loss: 46632.1098 - Avg Loss: 158.0749\n",
            "Epoch [26/50] - Batch loss: 161.1990 - Epoch Loss: 46793.3088 - Avg Loss: 158.0855\n",
            "Epoch [26/50] - Batch loss: 160.2795 - Epoch Loss: 46953.5883 - Avg Loss: 158.0929\n",
            "Epoch [26/50] - Batch loss: 155.0484 - Epoch Loss: 47108.6367 - Avg Loss: 158.0827\n",
            "Epoch [26/50] - Batch loss: 158.0297 - Epoch Loss: 47266.6664 - Avg Loss: 158.0825\n",
            "Epoch [26/50] - Batch loss: 150.7913 - Epoch Loss: 47417.4577 - Avg Loss: 158.0582\n",
            "Epoch [26/50] - Batch loss: 160.2471 - Epoch Loss: 47577.7047 - Avg Loss: 158.0655\n",
            "Epoch [26/50] - Batch loss: 149.3325 - Epoch Loss: 47727.0372 - Avg Loss: 158.0365\n",
            "Epoch [26/50] - Batch loss: 152.7709 - Epoch Loss: 47879.8081 - Avg Loss: 158.0192\n",
            "Epoch [26/50] - Batch loss: 159.6057 - Epoch Loss: 48039.4138 - Avg Loss: 158.0244\n",
            "Epoch [26/50] - Batch loss: 155.9158 - Epoch Loss: 48195.3297 - Avg Loss: 158.0175\n",
            "Epoch [26/50] - Batch loss: 161.3987 - Epoch Loss: 48356.7284 - Avg Loss: 158.0285\n",
            "Epoch [26/50] - Batch loss: 162.3145 - Epoch Loss: 48519.0428 - Avg Loss: 158.0425\n",
            "Epoch [26/50] - Batch loss: 162.2893 - Epoch Loss: 48681.3321 - Avg Loss: 158.0563\n",
            "Epoch [26/50] - Batch loss: 156.1541 - Epoch Loss: 48837.4862 - Avg Loss: 158.0501\n",
            "Epoch [26/50] - Batch loss: 163.1672 - Epoch Loss: 49000.6534 - Avg Loss: 158.0666\n",
            "Epoch [26/50] - Batch loss: 149.8826 - Epoch Loss: 49150.5360 - Avg Loss: 158.0403\n",
            "Epoch [26/50] - Batch loss: 155.0618 - Epoch Loss: 49305.5978 - Avg Loss: 158.0308\n",
            "Epoch [26/50] - Batch loss: 159.4771 - Epoch Loss: 49465.0748 - Avg Loss: 158.0354\n",
            "Epoch [26/50] - Batch loss: 156.5917 - Epoch Loss: 49621.6665 - Avg Loss: 158.0308\n",
            "Epoch [26/50] - Batch loss: 153.8207 - Epoch Loss: 49775.4872 - Avg Loss: 158.0174\n",
            "Epoch [26/50] - Batch loss: 159.6521 - Epoch Loss: 49935.1394 - Avg Loss: 158.0226\n",
            "Epoch [26/50] - Batch loss: 153.9024 - Epoch Loss: 50089.0417 - Avg Loss: 158.0096\n",
            "Epoch [26/50] - Batch loss: 158.8988 - Epoch Loss: 50247.9405 - Avg Loss: 158.0124\n",
            "Epoch [26/50] - Batch loss: 151.7449 - Epoch Loss: 50399.6854 - Avg Loss: 157.9927\n",
            "Epoch [26/50] - Batch loss: 154.1139 - Epoch Loss: 50553.7993 - Avg Loss: 157.9806\n",
            "Epoch [26/50] - Batch loss: 162.0654 - Epoch Loss: 50715.8647 - Avg Loss: 157.9933\n",
            "Epoch [26/50] - Batch loss: 156.0748 - Epoch Loss: 50871.9395 - Avg Loss: 157.9874\n",
            "Epoch [26/50] - Batch loss: 160.4702 - Epoch Loss: 51032.4097 - Avg Loss: 157.9951\n",
            "Epoch [26/50] - Batch loss: 164.9080 - Epoch Loss: 51197.3177 - Avg Loss: 158.0164\n",
            "Epoch [26/50] - Batch loss: 152.6094 - Epoch Loss: 51349.9271 - Avg Loss: 157.9998\n",
            "Epoch [26/50] - Batch loss: 156.8837 - Epoch Loss: 51506.8108 - Avg Loss: 157.9964\n",
            "Epoch [26/50] - Batch loss: 155.0713 - Epoch Loss: 51661.8821 - Avg Loss: 157.9874\n",
            "Epoch [26/50] - Batch loss: 154.5121 - Epoch Loss: 51816.3942 - Avg Loss: 157.9768\n",
            "Epoch [26/50] - Batch loss: 159.4859 - Epoch Loss: 51975.8801 - Avg Loss: 157.9814\n",
            "Epoch [26/50] - Batch loss: 160.5704 - Epoch Loss: 52136.4505 - Avg Loss: 157.9892\n",
            "Epoch [26/50] - Batch loss: 154.1173 - Epoch Loss: 52290.5679 - Avg Loss: 157.9775\n",
            "Epoch [26/50] - Batch loss: 148.5990 - Epoch Loss: 52439.1669 - Avg Loss: 157.9493\n",
            "Epoch [26/50] - Batch loss: 157.8963 - Epoch Loss: 52597.0632 - Avg Loss: 157.9491\n",
            "Epoch [26/50] - Batch loss: 162.5477 - Epoch Loss: 52759.6109 - Avg Loss: 157.9629\n",
            "Epoch [26/50] - Batch loss: 156.0931 - Epoch Loss: 52915.7040 - Avg Loss: 157.9573\n",
            "Epoch [26/50] - Batch loss: 162.9432 - Epoch Loss: 53078.6472 - Avg Loss: 157.9722\n",
            "Epoch [26/50] - Batch loss: 158.9530 - Epoch Loss: 53237.6002 - Avg Loss: 157.9751\n",
            "Epoch [26/50] - Batch loss: 154.4484 - Epoch Loss: 53392.0486 - Avg Loss: 157.9646\n",
            "Epoch [26/50] - Batch loss: 163.2624 - Epoch Loss: 53555.3110 - Avg Loss: 157.9803\n",
            "Epoch [26/50] - Batch loss: 160.6480 - Epoch Loss: 53715.9591 - Avg Loss: 157.9881\n",
            "Epoch [26/50] - Batch loss: 161.0875 - Epoch Loss: 53877.0466 - Avg Loss: 157.9972\n",
            "Epoch [26/50] - Batch loss: 168.5431 - Epoch Loss: 54045.5896 - Avg Loss: 158.0280\n",
            "Epoch [26/50] - Batch loss: 151.9761 - Epoch Loss: 54197.5658 - Avg Loss: 158.0104\n",
            "Epoch [26/50] - Batch loss: 169.7014 - Epoch Loss: 54367.2671 - Avg Loss: 158.0444\n",
            "Epoch [26/50] - Batch loss: 154.1709 - Epoch Loss: 54521.4380 - Avg Loss: 158.0332\n",
            "Epoch [26/50] - Batch loss: 158.7227 - Epoch Loss: 54680.1608 - Avg Loss: 158.0351\n",
            "Epoch [26/50] - Batch loss: 163.4043 - Epoch Loss: 54843.5651 - Avg Loss: 158.0506\n",
            "Epoch [26/50] - Batch loss: 157.6411 - Epoch Loss: 55001.2062 - Avg Loss: 158.0494\n",
            "Epoch [26/50] - Batch loss: 160.4998 - Epoch Loss: 55161.7061 - Avg Loss: 158.0565\n",
            "Epoch [26/50] - Batch loss: 158.7386 - Epoch Loss: 55320.4447 - Avg Loss: 158.0584\n",
            "Epoch [26/50] - Batch loss: 159.8613 - Epoch Loss: 55480.3059 - Avg Loss: 158.0635\n",
            "Epoch [26/50] - Batch loss: 156.5730 - Epoch Loss: 55636.8789 - Avg Loss: 158.0593\n",
            "Epoch [26/50] - Batch loss: 156.5393 - Epoch Loss: 55793.4182 - Avg Loss: 158.0550\n",
            "Epoch [26/50] - Batch loss: 163.5542 - Epoch Loss: 55956.9724 - Avg Loss: 158.0705\n",
            "Epoch [26/50] - Batch loss: 159.4236 - Epoch Loss: 56116.3960 - Avg Loss: 158.0744\n",
            "Epoch [26/50] - Batch loss: 157.8700 - Epoch Loss: 56274.2660 - Avg Loss: 158.0738\n",
            "Epoch [26/50] - Batch loss: 161.5563 - Epoch Loss: 56435.8223 - Avg Loss: 158.0835\n",
            "Epoch [26/50] - Batch loss: 161.2583 - Epoch Loss: 56597.0806 - Avg Loss: 158.0924\n",
            "Epoch [26/50] - Batch loss: 156.1544 - Epoch Loss: 56753.2349 - Avg Loss: 158.0870\n",
            "Epoch [26/50] - Batch loss: 155.8873 - Epoch Loss: 56909.1222 - Avg Loss: 158.0809\n",
            "Epoch [26/50] - Batch loss: 152.1239 - Epoch Loss: 57061.2462 - Avg Loss: 158.0644\n",
            "Epoch [26/50] - Batch loss: 158.1609 - Epoch Loss: 57219.4071 - Avg Loss: 158.0647\n",
            "Epoch [26/50] - Batch loss: 159.0851 - Epoch Loss: 57378.4922 - Avg Loss: 158.0675\n",
            "Epoch [26/50] - Batch loss: 157.0592 - Epoch Loss: 57535.5513 - Avg Loss: 158.0647\n",
            "Epoch [26/50] - Batch loss: 161.2593 - Epoch Loss: 57696.8106 - Avg Loss: 158.0735\n",
            "Epoch [26/50] - Batch loss: 155.5066 - Epoch Loss: 57852.3172 - Avg Loss: 158.0664\n",
            "Epoch [26/50] - Batch loss: 156.5465 - Epoch Loss: 58008.8637 - Avg Loss: 158.0623\n",
            "Epoch [26/50] - Batch loss: 161.7399 - Epoch Loss: 58170.6037 - Avg Loss: 158.0723\n",
            "Epoch [26/50] - Batch loss: 156.4345 - Epoch Loss: 58327.0382 - Avg Loss: 158.0679\n",
            "Epoch [26/50] - Batch loss: 163.5033 - Epoch Loss: 58490.5415 - Avg Loss: 158.0825\n",
            "Epoch [26/50] - Batch loss: 156.4537 - Epoch Loss: 58646.9951 - Avg Loss: 158.0782\n",
            "Epoch [26/50] - Batch loss: 162.0216 - Epoch Loss: 58809.0168 - Avg Loss: 158.0888\n",
            "Epoch [26/50] - Batch loss: 162.6340 - Epoch Loss: 58971.6507 - Avg Loss: 158.1009\n",
            "Epoch [26/50] - Batch loss: 163.3770 - Epoch Loss: 59135.0278 - Avg Loss: 158.1150\n",
            "Epoch [26/50] - Batch loss: 158.6491 - Epoch Loss: 59293.6769 - Avg Loss: 158.1165\n",
            "Epoch [26/50] - Batch loss: 156.8028 - Epoch Loss: 59450.4797 - Avg Loss: 158.1130\n",
            "Epoch [26/50] - Batch loss: 154.2437 - Epoch Loss: 59604.7234 - Avg Loss: 158.1027\n",
            "Epoch [26/50] - Batch loss: 160.3996 - Epoch Loss: 59765.1230 - Avg Loss: 158.1088\n",
            "Epoch [26/50] - Batch loss: 163.3509 - Epoch Loss: 59928.4738 - Avg Loss: 158.1226\n",
            "Epoch [26/50] - Batch loss: 164.8886 - Epoch Loss: 60093.3624 - Avg Loss: 158.1404\n",
            "Epoch [26/50] - Batch loss: 155.1058 - Epoch Loss: 60248.4682 - Avg Loss: 158.1325\n",
            "Epoch [26/50] - Batch loss: 160.3516 - Epoch Loss: 60408.8198 - Avg Loss: 158.1383\n",
            "Epoch [26/50] - Batch loss: 154.5123 - Epoch Loss: 60563.3321 - Avg Loss: 158.1288\n",
            "Epoch [26/50] - Batch loss: 163.7894 - Epoch Loss: 60727.1214 - Avg Loss: 158.1435\n",
            "Epoch [26/50] - Batch loss: 161.2777 - Epoch Loss: 60888.3992 - Avg Loss: 158.1517\n",
            "Epoch [26/50] - Batch loss: 152.6764 - Epoch Loss: 61041.0756 - Avg Loss: 158.1375\n",
            "Epoch [26/50] - Batch loss: 155.4887 - Epoch Loss: 61196.5642 - Avg Loss: 158.1307\n",
            "Epoch [26/50] - Batch loss: 162.5811 - Epoch Loss: 61359.1453 - Avg Loss: 158.1421\n",
            "Epoch [26/50] - Batch loss: 157.3006 - Epoch Loss: 61516.4459 - Avg Loss: 158.1400\n",
            "Epoch [26/50] - Batch loss: 156.1114 - Epoch Loss: 61672.5573 - Avg Loss: 158.1348\n",
            "Epoch [26/50] - Batch loss: 161.7123 - Epoch Loss: 61834.2696 - Avg Loss: 158.1439\n",
            "Epoch [26/50] - Batch loss: 154.4075 - Epoch Loss: 61988.6771 - Avg Loss: 158.1344\n",
            "Epoch [26/50] - Batch loss: 155.5305 - Epoch Loss: 62144.2076 - Avg Loss: 158.1278\n",
            "Epoch [26/50] - Batch loss: 166.3630 - Epoch Loss: 62310.5705 - Avg Loss: 158.1487\n",
            "Epoch [26/50] - Batch loss: 161.9887 - Epoch Loss: 62472.5592 - Avg Loss: 158.1584\n",
            "Epoch [26/50] - Batch loss: 153.2220 - Epoch Loss: 62625.7813 - Avg Loss: 158.1459\n",
            "Epoch [26/50] - Batch loss: 161.2254 - Epoch Loss: 62787.0067 - Avg Loss: 158.1537\n",
            "Epoch [26/50] - Batch loss: 160.2008 - Epoch Loss: 62947.2075 - Avg Loss: 158.1588\n",
            "Epoch [26/50] - Batch loss: 150.7943 - Epoch Loss: 63098.0018 - Avg Loss: 158.1404\n",
            "Epoch [26/50] - Batch loss: 158.3545 - Epoch Loss: 63256.3563 - Avg Loss: 158.1409\n",
            "Epoch [26/50] - Batch loss: 163.2502 - Epoch Loss: 63419.6065 - Avg Loss: 158.1536\n",
            "Epoch [26/50] - Batch loss: 158.5936 - Epoch Loss: 63578.2001 - Avg Loss: 158.1547\n",
            "Epoch [26/50] - Batch loss: 150.3606 - Epoch Loss: 63728.5607 - Avg Loss: 158.1354\n",
            "Epoch [26/50] - Batch loss: 155.6804 - Epoch Loss: 63884.2411 - Avg Loss: 158.1293\n",
            "Epoch [26/50] - Batch loss: 165.0158 - Epoch Loss: 64049.2568 - Avg Loss: 158.1463\n",
            "Epoch [26/50] - Batch loss: 161.8740 - Epoch Loss: 64211.1309 - Avg Loss: 158.1555\n",
            "Epoch [26/50] - Batch loss: 156.9456 - Epoch Loss: 64368.0765 - Avg Loss: 158.1525\n",
            "Epoch [26/50] - Batch loss: 160.1402 - Epoch Loss: 64528.2167 - Avg Loss: 158.1574\n",
            "Epoch [26/50] - Batch loss: 148.7278 - Epoch Loss: 64676.9445 - Avg Loss: 158.1343\n",
            "Epoch [26/50] - Batch loss: 160.7526 - Epoch Loss: 64837.6971 - Avg Loss: 158.1407\n",
            "Epoch [26/50] - Batch loss: 154.1835 - Epoch Loss: 64991.8807 - Avg Loss: 158.1311\n",
            "Epoch [26/50] - Batch loss: 158.0448 - Epoch Loss: 65149.9254 - Avg Loss: 158.1309\n",
            "Epoch [26/50] - Batch loss: 161.6759 - Epoch Loss: 65311.6014 - Avg Loss: 158.1395\n",
            "Epoch [26/50] - Batch loss: 152.2058 - Epoch Loss: 65463.8072 - Avg Loss: 158.1251\n",
            "Epoch [26/50] - Batch loss: 149.8747 - Epoch Loss: 65613.6819 - Avg Loss: 158.1053\n",
            "Epoch [26/50] - Batch loss: 155.8415 - Epoch Loss: 65769.5235 - Avg Loss: 158.0998\n",
            "Epoch [26/50] - Batch loss: 161.6509 - Epoch Loss: 65931.1743 - Avg Loss: 158.1083\n",
            "Epoch [26/50] - Batch loss: 162.2438 - Epoch Loss: 66093.4181 - Avg Loss: 158.1182\n",
            "Epoch [26/50] - Batch loss: 157.0782 - Epoch Loss: 66250.4963 - Avg Loss: 158.1157\n",
            "Epoch [26/50] - Batch loss: 167.2606 - Epoch Loss: 66417.7569 - Avg Loss: 158.1375\n",
            "Epoch [26/50] - Batch loss: 152.0655 - Epoch Loss: 66569.8224 - Avg Loss: 158.1231\n",
            "Epoch [26/50] - Batch loss: 161.9979 - Epoch Loss: 66731.8203 - Avg Loss: 158.1323\n",
            "Epoch [26/50] - Batch loss: 155.5787 - Epoch Loss: 66887.3990 - Avg Loss: 158.1262\n",
            "Epoch [26/50] - Batch loss: 159.8805 - Epoch Loss: 67047.2795 - Avg Loss: 158.1304\n",
            "Epoch [26/50] - Batch loss: 152.1743 - Epoch Loss: 67199.4538 - Avg Loss: 158.1164\n",
            "Epoch [26/50] - Batch loss: 161.2050 - Epoch Loss: 67360.6588 - Avg Loss: 158.1236\n",
            "Epoch [26/50] - Batch loss: 158.1054 - Epoch Loss: 67518.7642 - Avg Loss: 158.1236\n",
            "Epoch [26/50] - Batch loss: 155.6050 - Epoch Loss: 67674.3691 - Avg Loss: 158.1177\n",
            "Epoch [26/50] - Batch loss: 160.8677 - Epoch Loss: 67835.2369 - Avg Loss: 158.1241\n",
            "Epoch [26/50] - Batch loss: 156.3944 - Epoch Loss: 67991.6313 - Avg Loss: 158.1201\n",
            "Epoch [26/50] - Batch loss: 160.3478 - Epoch Loss: 68151.9791 - Avg Loss: 158.1252\n",
            "Epoch [26/50] - Batch loss: 158.8788 - Epoch Loss: 68310.8579 - Avg Loss: 158.1270\n",
            "Epoch [26/50] - Batch loss: 161.3832 - Epoch Loss: 68472.2411 - Avg Loss: 158.1345\n",
            "Epoch [26/50] - Batch loss: 151.2094 - Epoch Loss: 68623.4505 - Avg Loss: 158.1185\n",
            "Epoch [26/50] - Batch loss: 154.7046 - Epoch Loss: 68778.1551 - Avg Loss: 158.1107\n",
            "Epoch [26/50] - Batch loss: 158.8346 - Epoch Loss: 68936.9897 - Avg Loss: 158.1124\n",
            "Epoch [26/50] - Batch loss: 150.6673 - Epoch Loss: 69087.6570 - Avg Loss: 158.0953\n",
            "Epoch [26/50] - Batch loss: 159.2768 - Epoch Loss: 69246.9338 - Avg Loss: 158.0980\n",
            "Epoch [26/50] - Batch loss: 148.0607 - Epoch Loss: 69394.9945 - Avg Loss: 158.0752\n",
            "Epoch [26/50] - Batch loss: 152.0275 - Epoch Loss: 69547.0220 - Avg Loss: 158.0614\n",
            "Epoch [26/50] - Batch loss: 165.2212 - Epoch Loss: 69712.2431 - Avg Loss: 158.0776\n",
            "Epoch [26/50] - Batch loss: 161.1702 - Epoch Loss: 69873.4133 - Avg Loss: 158.0846\n",
            "Epoch [26/50] - Batch loss: 153.8579 - Epoch Loss: 70027.2712 - Avg Loss: 158.0751\n",
            "Epoch [26/50] - Batch loss: 165.4251 - Epoch Loss: 70192.6963 - Avg Loss: 158.0917\n",
            "Epoch [26/50] - Batch loss: 160.2433 - Epoch Loss: 70352.9395 - Avg Loss: 158.0965\n",
            "Epoch [26/50] - Batch loss: 157.7240 - Epoch Loss: 70510.6636 - Avg Loss: 158.0957\n",
            "Epoch [26/50] - Batch loss: 156.3455 - Epoch Loss: 70667.0091 - Avg Loss: 158.0917\n",
            "Epoch [26/50] - Batch loss: 155.5322 - Epoch Loss: 70822.5413 - Avg Loss: 158.0860\n",
            "Epoch [26/50] - Batch loss: 159.2860 - Epoch Loss: 70981.8274 - Avg Loss: 158.0887\n",
            "Epoch [26/50] - Batch loss: 156.9894 - Epoch Loss: 71138.8168 - Avg Loss: 158.0863\n",
            "Epoch [26/50] - Batch loss: 161.3404 - Epoch Loss: 71300.1572 - Avg Loss: 158.0935\n",
            "Epoch [26/50] - Batch loss: 155.2518 - Epoch Loss: 71455.4089 - Avg Loss: 158.0872\n",
            "Epoch [26/50] - Batch loss: 154.0846 - Epoch Loss: 71609.4936 - Avg Loss: 158.0784\n",
            "Epoch [26/50] - Batch loss: 150.3423 - Epoch Loss: 71759.8359 - Avg Loss: 158.0613\n",
            "Epoch [26/50] - Batch loss: 158.2570 - Epoch Loss: 71918.0928 - Avg Loss: 158.0617\n",
            "Epoch [26/50] - Batch loss: 151.9010 - Epoch Loss: 72069.9939 - Avg Loss: 158.0482\n",
            "Epoch [26/50] - Batch loss: 164.4678 - Epoch Loss: 72234.4617 - Avg Loss: 158.0623\n",
            "Epoch [26/50] - Batch loss: 155.4885 - Epoch Loss: 72389.9501 - Avg Loss: 158.0567\n",
            "Epoch [26/50] - Batch loss: 155.4115 - Epoch Loss: 72545.3616 - Avg Loss: 158.0509\n",
            "Epoch [26/50] - Batch loss: 163.3814 - Epoch Loss: 72708.7431 - Avg Loss: 158.0625\n",
            "Epoch [26/50] - Batch loss: 161.5810 - Epoch Loss: 72870.3241 - Avg Loss: 158.0701\n",
            "Epoch [26/50] - Batch loss: 154.6087 - Epoch Loss: 73024.9327 - Avg Loss: 158.0626\n",
            "Epoch [26/50] - Batch loss: 154.7074 - Epoch Loss: 73179.6401 - Avg Loss: 158.0554\n",
            "Epoch [26/50] - Batch loss: 156.3492 - Epoch Loss: 73335.9893 - Avg Loss: 158.0517\n",
            "Epoch [26/50] - Batch loss: 157.2127 - Epoch Loss: 73493.2020 - Avg Loss: 158.0499\n",
            "Epoch [26/50] - Batch loss: 162.8364 - Epoch Loss: 73656.0384 - Avg Loss: 158.0602\n",
            "Epoch [26/50] - Batch loss: 154.1270 - Epoch Loss: 73810.1654 - Avg Loss: 158.0517\n",
            "Epoch [26/50] - Batch loss: 164.6808 - Epoch Loss: 73974.8462 - Avg Loss: 158.0659\n",
            "Epoch [26/50] - Batch loss: 153.4990 - Epoch Loss: 74128.3452 - Avg Loss: 158.0562\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 27/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45b41b0e7b7149e1b850f5bbe82ae52e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27/50] - Batch loss: 161.2353 - Epoch Loss: 161.2353 - Avg Loss: 161.2353\n",
            "Epoch [27/50] - Batch loss: 162.3239 - Epoch Loss: 323.5592 - Avg Loss: 161.7796\n",
            "Epoch [27/50] - Batch loss: 152.0954 - Epoch Loss: 475.6545 - Avg Loss: 158.5515\n",
            "Epoch [27/50] - Batch loss: 162.9066 - Epoch Loss: 638.5611 - Avg Loss: 159.6403\n",
            "Epoch [27/50] - Batch loss: 162.0780 - Epoch Loss: 800.6391 - Avg Loss: 160.1278\n",
            "Epoch [27/50] - Batch loss: 157.5284 - Epoch Loss: 958.1675 - Avg Loss: 159.6946\n",
            "Epoch [27/50] - Batch loss: 159.1364 - Epoch Loss: 1117.3040 - Avg Loss: 159.6149\n",
            "Epoch [27/50] - Batch loss: 161.7927 - Epoch Loss: 1279.0966 - Avg Loss: 159.8871\n",
            "Epoch [27/50] - Batch loss: 160.9107 - Epoch Loss: 1440.0073 - Avg Loss: 160.0008\n",
            "Epoch [27/50] - Batch loss: 163.7014 - Epoch Loss: 1603.7087 - Avg Loss: 160.3709\n",
            "Epoch [27/50] - Batch loss: 154.9479 - Epoch Loss: 1758.6566 - Avg Loss: 159.8779\n",
            "Epoch [27/50] - Batch loss: 168.0336 - Epoch Loss: 1926.6902 - Avg Loss: 160.5575\n",
            "Epoch [27/50] - Batch loss: 155.3297 - Epoch Loss: 2082.0199 - Avg Loss: 160.1554\n",
            "Epoch [27/50] - Batch loss: 156.0016 - Epoch Loss: 2238.0215 - Avg Loss: 159.8587\n",
            "Epoch [27/50] - Batch loss: 159.8719 - Epoch Loss: 2397.8934 - Avg Loss: 159.8596\n",
            "Epoch [27/50] - Batch loss: 161.0328 - Epoch Loss: 2558.9262 - Avg Loss: 159.9329\n",
            "Epoch [27/50] - Batch loss: 159.0173 - Epoch Loss: 2717.9435 - Avg Loss: 159.8790\n",
            "Epoch [27/50] - Batch loss: 154.1828 - Epoch Loss: 2872.1263 - Avg Loss: 159.5626\n",
            "Epoch [27/50] - Batch loss: 152.4082 - Epoch Loss: 3024.5345 - Avg Loss: 159.1860\n",
            "Epoch [27/50] - Batch loss: 161.4541 - Epoch Loss: 3185.9886 - Avg Loss: 159.2994\n",
            "Epoch [27/50] - Batch loss: 149.7575 - Epoch Loss: 3335.7460 - Avg Loss: 158.8450\n",
            "Epoch [27/50] - Batch loss: 162.5500 - Epoch Loss: 3498.2960 - Avg Loss: 159.0135\n",
            "Epoch [27/50] - Batch loss: 150.6481 - Epoch Loss: 3648.9441 - Avg Loss: 158.6497\n",
            "Epoch [27/50] - Batch loss: 153.1930 - Epoch Loss: 3802.1371 - Avg Loss: 158.4224\n",
            "Epoch [27/50] - Batch loss: 158.2371 - Epoch Loss: 3960.3742 - Avg Loss: 158.4150\n",
            "Epoch [27/50] - Batch loss: 148.1250 - Epoch Loss: 4108.4992 - Avg Loss: 158.0192\n",
            "Epoch [27/50] - Batch loss: 155.7648 - Epoch Loss: 4264.2640 - Avg Loss: 157.9357\n",
            "Epoch [27/50] - Batch loss: 163.1713 - Epoch Loss: 4427.4353 - Avg Loss: 158.1227\n",
            "Epoch [27/50] - Batch loss: 165.7043 - Epoch Loss: 4593.1396 - Avg Loss: 158.3841\n",
            "Epoch [27/50] - Batch loss: 156.3730 - Epoch Loss: 4749.5126 - Avg Loss: 158.3171\n",
            "Epoch [27/50] - Batch loss: 153.2707 - Epoch Loss: 4902.7834 - Avg Loss: 158.1543\n",
            "Epoch [27/50] - Batch loss: 159.3726 - Epoch Loss: 5062.1559 - Avg Loss: 158.1924\n",
            "Epoch [27/50] - Batch loss: 154.5961 - Epoch Loss: 5216.7520 - Avg Loss: 158.0834\n",
            "Epoch [27/50] - Batch loss: 163.6815 - Epoch Loss: 5380.4336 - Avg Loss: 158.2480\n",
            "Epoch [27/50] - Batch loss: 152.0645 - Epoch Loss: 5532.4980 - Avg Loss: 158.0714\n",
            "Epoch [27/50] - Batch loss: 162.9595 - Epoch Loss: 5695.4575 - Avg Loss: 158.2072\n",
            "Epoch [27/50] - Batch loss: 151.5874 - Epoch Loss: 5847.0450 - Avg Loss: 158.0282\n",
            "Epoch [27/50] - Batch loss: 161.6149 - Epoch Loss: 6008.6599 - Avg Loss: 158.1226\n",
            "Epoch [27/50] - Batch loss: 160.3642 - Epoch Loss: 6169.0241 - Avg Loss: 158.1801\n",
            "Epoch [27/50] - Batch loss: 160.5641 - Epoch Loss: 6329.5882 - Avg Loss: 158.2397\n",
            "Epoch [27/50] - Batch loss: 151.9418 - Epoch Loss: 6481.5300 - Avg Loss: 158.0861\n",
            "Epoch [27/50] - Batch loss: 155.8295 - Epoch Loss: 6637.3594 - Avg Loss: 158.0324\n",
            "Epoch [27/50] - Batch loss: 151.6168 - Epoch Loss: 6788.9763 - Avg Loss: 157.8832\n",
            "Epoch [27/50] - Batch loss: 156.9565 - Epoch Loss: 6945.9328 - Avg Loss: 157.8621\n",
            "Epoch [27/50] - Batch loss: 156.1868 - Epoch Loss: 7102.1196 - Avg Loss: 157.8249\n",
            "Epoch [27/50] - Batch loss: 158.2762 - Epoch Loss: 7260.3958 - Avg Loss: 157.8347\n",
            "Epoch [27/50] - Batch loss: 158.5925 - Epoch Loss: 7418.9883 - Avg Loss: 157.8508\n",
            "Epoch [27/50] - Batch loss: 157.2614 - Epoch Loss: 7576.2498 - Avg Loss: 157.8385\n",
            "Epoch [27/50] - Batch loss: 154.6503 - Epoch Loss: 7730.9000 - Avg Loss: 157.7735\n",
            "Epoch [27/50] - Batch loss: 161.3354 - Epoch Loss: 7892.2354 - Avg Loss: 157.8447\n",
            "Epoch [27/50] - Batch loss: 166.6354 - Epoch Loss: 8058.8708 - Avg Loss: 158.0171\n",
            "Epoch [27/50] - Batch loss: 160.4781 - Epoch Loss: 8219.3488 - Avg Loss: 158.0644\n",
            "Epoch [27/50] - Batch loss: 160.4718 - Epoch Loss: 8379.8207 - Avg Loss: 158.1098\n",
            "Epoch [27/50] - Batch loss: 157.2618 - Epoch Loss: 8537.0825 - Avg Loss: 158.0941\n",
            "Epoch [27/50] - Batch loss: 153.7943 - Epoch Loss: 8690.8768 - Avg Loss: 158.0159\n",
            "Epoch [27/50] - Batch loss: 158.8590 - Epoch Loss: 8849.7358 - Avg Loss: 158.0310\n",
            "Epoch [27/50] - Batch loss: 159.2892 - Epoch Loss: 9009.0249 - Avg Loss: 158.0531\n",
            "Epoch [27/50] - Batch loss: 161.6013 - Epoch Loss: 9170.6263 - Avg Loss: 158.1142\n",
            "Epoch [27/50] - Batch loss: 156.0783 - Epoch Loss: 9326.7046 - Avg Loss: 158.0797\n",
            "Epoch [27/50] - Batch loss: 153.0045 - Epoch Loss: 9479.7091 - Avg Loss: 157.9952\n",
            "Epoch [27/50] - Batch loss: 168.4913 - Epoch Loss: 9648.2004 - Avg Loss: 158.1672\n",
            "Epoch [27/50] - Batch loss: 157.9050 - Epoch Loss: 9806.1054 - Avg Loss: 158.1630\n",
            "Epoch [27/50] - Batch loss: 162.5997 - Epoch Loss: 9968.7051 - Avg Loss: 158.2334\n",
            "Epoch [27/50] - Batch loss: 158.6885 - Epoch Loss: 10127.3936 - Avg Loss: 158.2405\n",
            "Epoch [27/50] - Batch loss: 160.6804 - Epoch Loss: 10288.0740 - Avg Loss: 158.2781\n",
            "Epoch [27/50] - Batch loss: 159.8056 - Epoch Loss: 10447.8796 - Avg Loss: 158.3012\n",
            "Epoch [27/50] - Batch loss: 153.5814 - Epoch Loss: 10601.4610 - Avg Loss: 158.2308\n",
            "Epoch [27/50] - Batch loss: 155.2750 - Epoch Loss: 10756.7360 - Avg Loss: 158.1873\n",
            "Epoch [27/50] - Batch loss: 159.0123 - Epoch Loss: 10915.7482 - Avg Loss: 158.1992\n",
            "Epoch [27/50] - Batch loss: 166.2485 - Epoch Loss: 11081.9967 - Avg Loss: 158.3142\n",
            "Epoch [27/50] - Batch loss: 154.9397 - Epoch Loss: 11236.9364 - Avg Loss: 158.2667\n",
            "Epoch [27/50] - Batch loss: 156.2804 - Epoch Loss: 11393.2168 - Avg Loss: 158.2391\n",
            "Epoch [27/50] - Batch loss: 160.1914 - Epoch Loss: 11553.4083 - Avg Loss: 158.2659\n",
            "Epoch [27/50] - Batch loss: 158.8850 - Epoch Loss: 11712.2933 - Avg Loss: 158.2742\n",
            "Epoch [27/50] - Batch loss: 152.6064 - Epoch Loss: 11864.8997 - Avg Loss: 158.1987\n",
            "Epoch [27/50] - Batch loss: 155.6751 - Epoch Loss: 12020.5748 - Avg Loss: 158.1655\n",
            "Epoch [27/50] - Batch loss: 162.2422 - Epoch Loss: 12182.8170 - Avg Loss: 158.2184\n",
            "Epoch [27/50] - Batch loss: 162.3047 - Epoch Loss: 12345.1217 - Avg Loss: 158.2708\n",
            "Epoch [27/50] - Batch loss: 162.2582 - Epoch Loss: 12507.3799 - Avg Loss: 158.3213\n",
            "Epoch [27/50] - Batch loss: 157.1548 - Epoch Loss: 12664.5347 - Avg Loss: 158.3067\n",
            "Epoch [27/50] - Batch loss: 159.0497 - Epoch Loss: 12823.5844 - Avg Loss: 158.3159\n",
            "Epoch [27/50] - Batch loss: 162.6840 - Epoch Loss: 12986.2685 - Avg Loss: 158.3691\n",
            "Epoch [27/50] - Batch loss: 163.6073 - Epoch Loss: 13149.8757 - Avg Loss: 158.4322\n",
            "Epoch [27/50] - Batch loss: 151.6164 - Epoch Loss: 13301.4921 - Avg Loss: 158.3511\n",
            "Epoch [27/50] - Batch loss: 153.7351 - Epoch Loss: 13455.2272 - Avg Loss: 158.2968\n",
            "Epoch [27/50] - Batch loss: 155.3995 - Epoch Loss: 13610.6268 - Avg Loss: 158.2631\n",
            "Epoch [27/50] - Batch loss: 156.4303 - Epoch Loss: 13767.0571 - Avg Loss: 158.2420\n",
            "Epoch [27/50] - Batch loss: 159.9971 - Epoch Loss: 13927.0542 - Avg Loss: 158.2620\n",
            "Epoch [27/50] - Batch loss: 155.7852 - Epoch Loss: 14082.8394 - Avg Loss: 158.2342\n",
            "Epoch [27/50] - Batch loss: 159.0293 - Epoch Loss: 14241.8687 - Avg Loss: 158.2430\n",
            "Epoch [27/50] - Batch loss: 159.1836 - Epoch Loss: 14401.0523 - Avg Loss: 158.2533\n",
            "Epoch [27/50] - Batch loss: 161.5170 - Epoch Loss: 14562.5693 - Avg Loss: 158.2888\n",
            "Epoch [27/50] - Batch loss: 157.5836 - Epoch Loss: 14720.1529 - Avg Loss: 158.2812\n",
            "Epoch [27/50] - Batch loss: 158.0346 - Epoch Loss: 14878.1875 - Avg Loss: 158.2786\n",
            "Epoch [27/50] - Batch loss: 150.6546 - Epoch Loss: 15028.8421 - Avg Loss: 158.1983\n",
            "Epoch [27/50] - Batch loss: 161.4939 - Epoch Loss: 15190.3361 - Avg Loss: 158.2327\n",
            "Epoch [27/50] - Batch loss: 162.2688 - Epoch Loss: 15352.6049 - Avg Loss: 158.2743\n",
            "Epoch [27/50] - Batch loss: 161.5243 - Epoch Loss: 15514.1292 - Avg Loss: 158.3074\n",
            "Epoch [27/50] - Batch loss: 153.9140 - Epoch Loss: 15668.0432 - Avg Loss: 158.2631\n",
            "Epoch [27/50] - Batch loss: 158.9750 - Epoch Loss: 15827.0182 - Avg Loss: 158.2702\n",
            "Epoch [27/50] - Batch loss: 162.6504 - Epoch Loss: 15989.6686 - Avg Loss: 158.3136\n",
            "Epoch [27/50] - Batch loss: 153.7001 - Epoch Loss: 16143.3687 - Avg Loss: 158.2683\n",
            "Epoch [27/50] - Batch loss: 145.7961 - Epoch Loss: 16289.1649 - Avg Loss: 158.1472\n",
            "Epoch [27/50] - Batch loss: 161.3218 - Epoch Loss: 16450.4867 - Avg Loss: 158.1778\n",
            "Epoch [27/50] - Batch loss: 159.1590 - Epoch Loss: 16609.6457 - Avg Loss: 158.1871\n",
            "Epoch [27/50] - Batch loss: 154.2867 - Epoch Loss: 16763.9324 - Avg Loss: 158.1503\n",
            "Epoch [27/50] - Batch loss: 168.5659 - Epoch Loss: 16932.4982 - Avg Loss: 158.2476\n",
            "Epoch [27/50] - Batch loss: 156.2278 - Epoch Loss: 17088.7260 - Avg Loss: 158.2289\n",
            "Epoch [27/50] - Batch loss: 154.5677 - Epoch Loss: 17243.2937 - Avg Loss: 158.1954\n",
            "Epoch [27/50] - Batch loss: 157.7218 - Epoch Loss: 17401.0155 - Avg Loss: 158.1911\n",
            "Epoch [27/50] - Batch loss: 162.8640 - Epoch Loss: 17563.8795 - Avg Loss: 158.2331\n",
            "Epoch [27/50] - Batch loss: 157.7751 - Epoch Loss: 17721.6546 - Avg Loss: 158.2291\n",
            "Epoch [27/50] - Batch loss: 155.5657 - Epoch Loss: 17877.2203 - Avg Loss: 158.2055\n",
            "Epoch [27/50] - Batch loss: 157.0246 - Epoch Loss: 18034.2450 - Avg Loss: 158.1951\n",
            "Epoch [27/50] - Batch loss: 153.3565 - Epoch Loss: 18187.6015 - Avg Loss: 158.1531\n",
            "Epoch [27/50] - Batch loss: 162.4735 - Epoch Loss: 18350.0750 - Avg Loss: 158.1903\n",
            "Epoch [27/50] - Batch loss: 161.9521 - Epoch Loss: 18512.0271 - Avg Loss: 158.2225\n",
            "Epoch [27/50] - Batch loss: 158.5377 - Epoch Loss: 18670.5648 - Avg Loss: 158.2251\n",
            "Epoch [27/50] - Batch loss: 152.6942 - Epoch Loss: 18823.2591 - Avg Loss: 158.1786\n",
            "Epoch [27/50] - Batch loss: 155.1171 - Epoch Loss: 18978.3761 - Avg Loss: 158.1531\n",
            "Epoch [27/50] - Batch loss: 163.7714 - Epoch Loss: 19142.1476 - Avg Loss: 158.1996\n",
            "Epoch [27/50] - Batch loss: 154.7219 - Epoch Loss: 19296.8694 - Avg Loss: 158.1711\n",
            "Epoch [27/50] - Batch loss: 157.1415 - Epoch Loss: 19454.0109 - Avg Loss: 158.1627\n",
            "Epoch [27/50] - Batch loss: 158.6953 - Epoch Loss: 19612.7063 - Avg Loss: 158.1670\n",
            "Epoch [27/50] - Batch loss: 160.7552 - Epoch Loss: 19773.4615 - Avg Loss: 158.1877\n",
            "Epoch [27/50] - Batch loss: 159.1829 - Epoch Loss: 19932.6443 - Avg Loss: 158.1956\n",
            "Epoch [27/50] - Batch loss: 165.0653 - Epoch Loss: 20097.7097 - Avg Loss: 158.2497\n",
            "Epoch [27/50] - Batch loss: 155.8912 - Epoch Loss: 20253.6008 - Avg Loss: 158.2313\n",
            "Epoch [27/50] - Batch loss: 152.9384 - Epoch Loss: 20406.5393 - Avg Loss: 158.1902\n",
            "Epoch [27/50] - Batch loss: 158.4613 - Epoch Loss: 20565.0006 - Avg Loss: 158.1923\n",
            "Epoch [27/50] - Batch loss: 156.9721 - Epoch Loss: 20721.9727 - Avg Loss: 158.1830\n",
            "Epoch [27/50] - Batch loss: 161.8774 - Epoch Loss: 20883.8501 - Avg Loss: 158.2110\n",
            "Epoch [27/50] - Batch loss: 152.2759 - Epoch Loss: 21036.1260 - Avg Loss: 158.1664\n",
            "Epoch [27/50] - Batch loss: 159.8298 - Epoch Loss: 21195.9558 - Avg Loss: 158.1788\n",
            "Epoch [27/50] - Batch loss: 160.9039 - Epoch Loss: 21356.8597 - Avg Loss: 158.1990\n",
            "Epoch [27/50] - Batch loss: 159.6826 - Epoch Loss: 21516.5423 - Avg Loss: 158.2099\n",
            "Epoch [27/50] - Batch loss: 155.8181 - Epoch Loss: 21672.3603 - Avg Loss: 158.1924\n",
            "Epoch [27/50] - Batch loss: 151.7801 - Epoch Loss: 21824.1404 - Avg Loss: 158.1459\n",
            "Epoch [27/50] - Batch loss: 158.7146 - Epoch Loss: 21982.8551 - Avg Loss: 158.1500\n",
            "Epoch [27/50] - Batch loss: 149.0028 - Epoch Loss: 22131.8579 - Avg Loss: 158.0847\n",
            "Epoch [27/50] - Batch loss: 163.1373 - Epoch Loss: 22294.9952 - Avg Loss: 158.1205\n",
            "Epoch [27/50] - Batch loss: 163.3792 - Epoch Loss: 22458.3745 - Avg Loss: 158.1576\n",
            "Epoch [27/50] - Batch loss: 162.6256 - Epoch Loss: 22621.0000 - Avg Loss: 158.1888\n",
            "Epoch [27/50] - Batch loss: 153.6926 - Epoch Loss: 22774.6926 - Avg Loss: 158.1576\n",
            "Epoch [27/50] - Batch loss: 160.8007 - Epoch Loss: 22935.4934 - Avg Loss: 158.1758\n",
            "Epoch [27/50] - Batch loss: 154.0248 - Epoch Loss: 23089.5182 - Avg Loss: 158.1474\n",
            "Epoch [27/50] - Batch loss: 155.9966 - Epoch Loss: 23245.5148 - Avg Loss: 158.1328\n",
            "Epoch [27/50] - Batch loss: 160.7323 - Epoch Loss: 23406.2470 - Avg Loss: 158.1503\n",
            "Epoch [27/50] - Batch loss: 156.5732 - Epoch Loss: 23562.8203 - Avg Loss: 158.1397\n",
            "Epoch [27/50] - Batch loss: 155.2118 - Epoch Loss: 23718.0321 - Avg Loss: 158.1202\n",
            "Epoch [27/50] - Batch loss: 158.7705 - Epoch Loss: 23876.8026 - Avg Loss: 158.1245\n",
            "Epoch [27/50] - Batch loss: 160.5370 - Epoch Loss: 24037.3396 - Avg Loss: 158.1404\n",
            "Epoch [27/50] - Batch loss: 156.4725 - Epoch Loss: 24193.8121 - Avg Loss: 158.1295\n",
            "Epoch [27/50] - Batch loss: 164.0163 - Epoch Loss: 24357.8284 - Avg Loss: 158.1677\n",
            "Epoch [27/50] - Batch loss: 154.6279 - Epoch Loss: 24512.4563 - Avg Loss: 158.1449\n",
            "Epoch [27/50] - Batch loss: 160.0667 - Epoch Loss: 24672.5230 - Avg Loss: 158.1572\n",
            "Epoch [27/50] - Batch loss: 157.8961 - Epoch Loss: 24830.4191 - Avg Loss: 158.1555\n",
            "Epoch [27/50] - Batch loss: 156.9069 - Epoch Loss: 24987.3260 - Avg Loss: 158.1476\n",
            "Epoch [27/50] - Batch loss: 158.8940 - Epoch Loss: 25146.2200 - Avg Loss: 158.1523\n",
            "Epoch [27/50] - Batch loss: 155.9301 - Epoch Loss: 25302.1501 - Avg Loss: 158.1384\n",
            "Epoch [27/50] - Batch loss: 154.6950 - Epoch Loss: 25456.8451 - Avg Loss: 158.1171\n",
            "Epoch [27/50] - Batch loss: 157.3569 - Epoch Loss: 25614.2020 - Avg Loss: 158.1124\n",
            "Epoch [27/50] - Batch loss: 166.7279 - Epoch Loss: 25780.9299 - Avg Loss: 158.1652\n",
            "Epoch [27/50] - Batch loss: 159.8099 - Epoch Loss: 25940.7398 - Avg Loss: 158.1752\n",
            "Epoch [27/50] - Batch loss: 159.5521 - Epoch Loss: 26100.2919 - Avg Loss: 158.1836\n",
            "Epoch [27/50] - Batch loss: 153.8625 - Epoch Loss: 26254.1544 - Avg Loss: 158.1576\n",
            "Epoch [27/50] - Batch loss: 152.5897 - Epoch Loss: 26406.7441 - Avg Loss: 158.1242\n",
            "Epoch [27/50] - Batch loss: 161.4787 - Epoch Loss: 26568.2227 - Avg Loss: 158.1442\n",
            "Epoch [27/50] - Batch loss: 164.2390 - Epoch Loss: 26732.4617 - Avg Loss: 158.1802\n",
            "Epoch [27/50] - Batch loss: 155.1578 - Epoch Loss: 26887.6196 - Avg Loss: 158.1625\n",
            "Epoch [27/50] - Batch loss: 154.6553 - Epoch Loss: 27042.2749 - Avg Loss: 158.1420\n",
            "Epoch [27/50] - Batch loss: 157.3224 - Epoch Loss: 27199.5973 - Avg Loss: 158.1372\n",
            "Epoch [27/50] - Batch loss: 156.9304 - Epoch Loss: 27356.5277 - Avg Loss: 158.1302\n",
            "Epoch [27/50] - Batch loss: 163.3173 - Epoch Loss: 27519.8450 - Avg Loss: 158.1600\n",
            "Epoch [27/50] - Batch loss: 151.8797 - Epoch Loss: 27671.7247 - Avg Loss: 158.1241\n",
            "Epoch [27/50] - Batch loss: 152.2932 - Epoch Loss: 27824.0179 - Avg Loss: 158.0910\n",
            "Epoch [27/50] - Batch loss: 157.4490 - Epoch Loss: 27981.4669 - Avg Loss: 158.0874\n",
            "Epoch [27/50] - Batch loss: 163.8360 - Epoch Loss: 28145.3030 - Avg Loss: 158.1197\n",
            "Epoch [27/50] - Batch loss: 165.6626 - Epoch Loss: 28310.9656 - Avg Loss: 158.1618\n",
            "Epoch [27/50] - Batch loss: 166.4147 - Epoch Loss: 28477.3803 - Avg Loss: 158.2077\n",
            "Epoch [27/50] - Batch loss: 157.1486 - Epoch Loss: 28634.5289 - Avg Loss: 158.2018\n",
            "Epoch [27/50] - Batch loss: 162.4856 - Epoch Loss: 28797.0145 - Avg Loss: 158.2254\n",
            "Epoch [27/50] - Batch loss: 155.8484 - Epoch Loss: 28952.8629 - Avg Loss: 158.2124\n",
            "Epoch [27/50] - Batch loss: 158.1641 - Epoch Loss: 29111.0271 - Avg Loss: 158.2121\n",
            "Epoch [27/50] - Batch loss: 158.9400 - Epoch Loss: 29269.9671 - Avg Loss: 158.2160\n",
            "Epoch [27/50] - Batch loss: 156.9422 - Epoch Loss: 29426.9093 - Avg Loss: 158.2092\n",
            "Epoch [27/50] - Batch loss: 161.4086 - Epoch Loss: 29588.3179 - Avg Loss: 158.2263\n",
            "Epoch [27/50] - Batch loss: 163.0698 - Epoch Loss: 29751.3876 - Avg Loss: 158.2521\n",
            "Epoch [27/50] - Batch loss: 157.5553 - Epoch Loss: 29908.9429 - Avg Loss: 158.2484\n",
            "Epoch [27/50] - Batch loss: 152.8472 - Epoch Loss: 30061.7901 - Avg Loss: 158.2199\n",
            "Epoch [27/50] - Batch loss: 155.4221 - Epoch Loss: 30217.2123 - Avg Loss: 158.2053\n",
            "Epoch [27/50] - Batch loss: 159.9745 - Epoch Loss: 30377.1868 - Avg Loss: 158.2145\n",
            "Epoch [27/50] - Batch loss: 158.6577 - Epoch Loss: 30535.8445 - Avg Loss: 158.2168\n",
            "Epoch [27/50] - Batch loss: 154.2567 - Epoch Loss: 30690.1011 - Avg Loss: 158.1964\n",
            "Epoch [27/50] - Batch loss: 167.6873 - Epoch Loss: 30857.7884 - Avg Loss: 158.2451\n",
            "Epoch [27/50] - Batch loss: 166.9529 - Epoch Loss: 31024.7413 - Avg Loss: 158.2895\n",
            "Epoch [27/50] - Batch loss: 157.5515 - Epoch Loss: 31182.2928 - Avg Loss: 158.2858\n",
            "Epoch [27/50] - Batch loss: 164.0078 - Epoch Loss: 31346.3006 - Avg Loss: 158.3146\n",
            "Epoch [27/50] - Batch loss: 158.3677 - Epoch Loss: 31504.6684 - Avg Loss: 158.3149\n",
            "Epoch [27/50] - Batch loss: 160.3467 - Epoch Loss: 31665.0150 - Avg Loss: 158.3251\n",
            "Epoch [27/50] - Batch loss: 158.3121 - Epoch Loss: 31823.3271 - Avg Loss: 158.3250\n",
            "Epoch [27/50] - Batch loss: 161.0374 - Epoch Loss: 31984.3645 - Avg Loss: 158.3384\n",
            "Epoch [27/50] - Batch loss: 154.9550 - Epoch Loss: 32139.3194 - Avg Loss: 158.3218\n",
            "Epoch [27/50] - Batch loss: 156.8555 - Epoch Loss: 32296.1749 - Avg Loss: 158.3146\n",
            "Epoch [27/50] - Batch loss: 153.3921 - Epoch Loss: 32449.5670 - Avg Loss: 158.2906\n",
            "Epoch [27/50] - Batch loss: 158.4149 - Epoch Loss: 32607.9819 - Avg Loss: 158.2912\n",
            "Epoch [27/50] - Batch loss: 154.6478 - Epoch Loss: 32762.6297 - Avg Loss: 158.2736\n",
            "Epoch [27/50] - Batch loss: 161.3037 - Epoch Loss: 32923.9334 - Avg Loss: 158.2881\n",
            "Epoch [27/50] - Batch loss: 160.9757 - Epoch Loss: 33084.9091 - Avg Loss: 158.3010\n",
            "Epoch [27/50] - Batch loss: 160.8144 - Epoch Loss: 33245.7235 - Avg Loss: 158.3130\n",
            "Epoch [27/50] - Batch loss: 155.0412 - Epoch Loss: 33400.7647 - Avg Loss: 158.2975\n",
            "Epoch [27/50] - Batch loss: 158.3842 - Epoch Loss: 33559.1489 - Avg Loss: 158.2979\n",
            "Epoch [27/50] - Batch loss: 163.6385 - Epoch Loss: 33722.7874 - Avg Loss: 158.3229\n",
            "Epoch [27/50] - Batch loss: 156.0715 - Epoch Loss: 33878.8589 - Avg Loss: 158.3124\n",
            "Epoch [27/50] - Batch loss: 158.1570 - Epoch Loss: 34037.0158 - Avg Loss: 158.3117\n",
            "Epoch [27/50] - Batch loss: 158.7093 - Epoch Loss: 34195.7251 - Avg Loss: 158.3135\n",
            "Epoch [27/50] - Batch loss: 159.2678 - Epoch Loss: 34354.9929 - Avg Loss: 158.3179\n",
            "Epoch [27/50] - Batch loss: 160.0408 - Epoch Loss: 34515.0337 - Avg Loss: 158.3258\n",
            "Epoch [27/50] - Batch loss: 148.1364 - Epoch Loss: 34663.1701 - Avg Loss: 158.2793\n",
            "Epoch [27/50] - Batch loss: 169.4366 - Epoch Loss: 34832.6066 - Avg Loss: 158.3300\n",
            "Epoch [27/50] - Batch loss: 164.8504 - Epoch Loss: 34997.4570 - Avg Loss: 158.3595\n",
            "Epoch [27/50] - Batch loss: 171.2845 - Epoch Loss: 35168.7415 - Avg Loss: 158.4178\n",
            "Epoch [27/50] - Batch loss: 163.5564 - Epoch Loss: 35332.2979 - Avg Loss: 158.4408\n",
            "Epoch [27/50] - Batch loss: 159.4874 - Epoch Loss: 35491.7853 - Avg Loss: 158.4455\n",
            "Epoch [27/50] - Batch loss: 165.7051 - Epoch Loss: 35657.4904 - Avg Loss: 158.4777\n",
            "Epoch [27/50] - Batch loss: 162.5086 - Epoch Loss: 35819.9990 - Avg Loss: 158.4956\n",
            "Epoch [27/50] - Batch loss: 156.7370 - Epoch Loss: 35976.7360 - Avg Loss: 158.4878\n",
            "Epoch [27/50] - Batch loss: 168.7300 - Epoch Loss: 36145.4660 - Avg Loss: 158.5327\n",
            "Epoch [27/50] - Batch loss: 160.5483 - Epoch Loss: 36306.0143 - Avg Loss: 158.5415\n",
            "Epoch [27/50] - Batch loss: 161.8042 - Epoch Loss: 36467.8185 - Avg Loss: 158.5557\n",
            "Epoch [27/50] - Batch loss: 161.7017 - Epoch Loss: 36629.5202 - Avg Loss: 158.5694\n",
            "Epoch [27/50] - Batch loss: 166.8284 - Epoch Loss: 36796.3485 - Avg Loss: 158.6050\n",
            "Epoch [27/50] - Batch loss: 155.6830 - Epoch Loss: 36952.0316 - Avg Loss: 158.5924\n",
            "Epoch [27/50] - Batch loss: 162.1220 - Epoch Loss: 37114.1536 - Avg Loss: 158.6075\n",
            "Epoch [27/50] - Batch loss: 152.3665 - Epoch Loss: 37266.5201 - Avg Loss: 158.5809\n",
            "Epoch [27/50] - Batch loss: 172.4876 - Epoch Loss: 37439.0077 - Avg Loss: 158.6399\n",
            "Epoch [27/50] - Batch loss: 164.1098 - Epoch Loss: 37603.1176 - Avg Loss: 158.6629\n",
            "Epoch [27/50] - Batch loss: 166.1435 - Epoch Loss: 37769.2611 - Avg Loss: 158.6944\n",
            "Epoch [27/50] - Batch loss: 161.1509 - Epoch Loss: 37930.4120 - Avg Loss: 158.7047\n",
            "Epoch [27/50] - Batch loss: 165.1069 - Epoch Loss: 38095.5189 - Avg Loss: 158.7313\n",
            "Epoch [27/50] - Batch loss: 163.9436 - Epoch Loss: 38259.4625 - Avg Loss: 158.7530\n",
            "Epoch [27/50] - Batch loss: 150.1608 - Epoch Loss: 38409.6233 - Avg Loss: 158.7175\n",
            "Epoch [27/50] - Batch loss: 158.1535 - Epoch Loss: 38567.7768 - Avg Loss: 158.7151\n",
            "Epoch [27/50] - Batch loss: 161.8795 - Epoch Loss: 38729.6563 - Avg Loss: 158.7281\n",
            "Epoch [27/50] - Batch loss: 154.4157 - Epoch Loss: 38884.0720 - Avg Loss: 158.7105\n",
            "Epoch [27/50] - Batch loss: 166.2162 - Epoch Loss: 39050.2882 - Avg Loss: 158.7410\n",
            "Epoch [27/50] - Batch loss: 160.6826 - Epoch Loss: 39210.9708 - Avg Loss: 158.7489\n",
            "Epoch [27/50] - Batch loss: 165.1038 - Epoch Loss: 39376.0746 - Avg Loss: 158.7745\n",
            "Epoch [27/50] - Batch loss: 161.8252 - Epoch Loss: 39537.8998 - Avg Loss: 158.7867\n",
            "Epoch [27/50] - Batch loss: 164.7592 - Epoch Loss: 39702.6590 - Avg Loss: 158.8106\n",
            "Epoch [27/50] - Batch loss: 163.1259 - Epoch Loss: 39865.7848 - Avg Loss: 158.8278\n",
            "Epoch [27/50] - Batch loss: 164.2560 - Epoch Loss: 40030.0408 - Avg Loss: 158.8494\n",
            "Epoch [27/50] - Batch loss: 154.5003 - Epoch Loss: 40184.5411 - Avg Loss: 158.8322\n",
            "Epoch [27/50] - Batch loss: 163.0215 - Epoch Loss: 40347.5626 - Avg Loss: 158.8487\n",
            "Epoch [27/50] - Batch loss: 161.6620 - Epoch Loss: 40509.2246 - Avg Loss: 158.8597\n",
            "Epoch [27/50] - Batch loss: 160.8060 - Epoch Loss: 40670.0306 - Avg Loss: 158.8673\n",
            "Epoch [27/50] - Batch loss: 162.2678 - Epoch Loss: 40832.2984 - Avg Loss: 158.8805\n",
            "Epoch [27/50] - Batch loss: 153.3757 - Epoch Loss: 40985.6741 - Avg Loss: 158.8592\n",
            "Epoch [27/50] - Batch loss: 164.0677 - Epoch Loss: 41149.7417 - Avg Loss: 158.8793\n",
            "Epoch [27/50] - Batch loss: 167.5026 - Epoch Loss: 41317.2443 - Avg Loss: 158.9125\n",
            "Epoch [27/50] - Batch loss: 160.6028 - Epoch Loss: 41477.8471 - Avg Loss: 158.9190\n",
            "Epoch [27/50] - Batch loss: 162.9356 - Epoch Loss: 41640.7827 - Avg Loss: 158.9343\n",
            "Epoch [27/50] - Batch loss: 163.1206 - Epoch Loss: 41803.9033 - Avg Loss: 158.9502\n",
            "Epoch [27/50] - Batch loss: 160.7657 - Epoch Loss: 41964.6690 - Avg Loss: 158.9571\n",
            "Epoch [27/50] - Batch loss: 157.7412 - Epoch Loss: 42122.4102 - Avg Loss: 158.9525\n",
            "Epoch [27/50] - Batch loss: 164.5725 - Epoch Loss: 42286.9827 - Avg Loss: 158.9736\n",
            "Epoch [27/50] - Batch loss: 161.7413 - Epoch Loss: 42448.7239 - Avg Loss: 158.9840\n",
            "Epoch [27/50] - Batch loss: 162.2094 - Epoch Loss: 42610.9334 - Avg Loss: 158.9960\n",
            "Epoch [27/50] - Batch loss: 161.1628 - Epoch Loss: 42772.0961 - Avg Loss: 159.0041\n",
            "Epoch [27/50] - Batch loss: 153.4631 - Epoch Loss: 42925.5593 - Avg Loss: 158.9836\n",
            "Epoch [27/50] - Batch loss: 158.9059 - Epoch Loss: 43084.4652 - Avg Loss: 158.9833\n",
            "Epoch [27/50] - Batch loss: 148.9163 - Epoch Loss: 43233.3815 - Avg Loss: 158.9463\n",
            "Epoch [27/50] - Batch loss: 164.1780 - Epoch Loss: 43397.5596 - Avg Loss: 158.9654\n",
            "Epoch [27/50] - Batch loss: 159.0181 - Epoch Loss: 43556.5777 - Avg Loss: 158.9656\n",
            "Epoch [27/50] - Batch loss: 162.9763 - Epoch Loss: 43719.5540 - Avg Loss: 158.9802\n",
            "Epoch [27/50] - Batch loss: 156.9407 - Epoch Loss: 43876.4947 - Avg Loss: 158.9728\n",
            "Epoch [27/50] - Batch loss: 160.4330 - Epoch Loss: 44036.9277 - Avg Loss: 158.9781\n",
            "Epoch [27/50] - Batch loss: 154.4878 - Epoch Loss: 44191.4155 - Avg Loss: 158.9619\n",
            "Epoch [27/50] - Batch loss: 164.7501 - Epoch Loss: 44356.1655 - Avg Loss: 158.9827\n",
            "Epoch [27/50] - Batch loss: 157.6895 - Epoch Loss: 44513.8550 - Avg Loss: 158.9781\n",
            "Epoch [27/50] - Batch loss: 163.7078 - Epoch Loss: 44677.5628 - Avg Loss: 158.9949\n",
            "Epoch [27/50] - Batch loss: 160.8277 - Epoch Loss: 44838.3905 - Avg Loss: 159.0014\n",
            "Epoch [27/50] - Batch loss: 163.5996 - Epoch Loss: 45001.9902 - Avg Loss: 159.0176\n",
            "Epoch [27/50] - Batch loss: 153.3703 - Epoch Loss: 45155.3604 - Avg Loss: 158.9977\n",
            "Epoch [27/50] - Batch loss: 157.7474 - Epoch Loss: 45313.1078 - Avg Loss: 158.9934\n",
            "Epoch [27/50] - Batch loss: 172.3625 - Epoch Loss: 45485.4703 - Avg Loss: 159.0401\n",
            "Epoch [27/50] - Batch loss: 166.7250 - Epoch Loss: 45652.1953 - Avg Loss: 159.0669\n",
            "Epoch [27/50] - Batch loss: 154.8998 - Epoch Loss: 45807.0951 - Avg Loss: 159.0524\n",
            "Epoch [27/50] - Batch loss: 160.0875 - Epoch Loss: 45967.1826 - Avg Loss: 159.0560\n",
            "Epoch [27/50] - Batch loss: 154.5918 - Epoch Loss: 46121.7744 - Avg Loss: 159.0406\n",
            "Epoch [27/50] - Batch loss: 160.3096 - Epoch Loss: 46282.0840 - Avg Loss: 159.0450\n",
            "Epoch [27/50] - Batch loss: 163.9537 - Epoch Loss: 46446.0377 - Avg Loss: 159.0618\n",
            "Epoch [27/50] - Batch loss: 161.5616 - Epoch Loss: 46607.5993 - Avg Loss: 159.0703\n",
            "Epoch [27/50] - Batch loss: 166.1174 - Epoch Loss: 46773.7167 - Avg Loss: 159.0943\n",
            "Epoch [27/50] - Batch loss: 165.0910 - Epoch Loss: 46938.8076 - Avg Loss: 159.1146\n",
            "Epoch [27/50] - Batch loss: 160.4435 - Epoch Loss: 47099.2511 - Avg Loss: 159.1191\n",
            "Epoch [27/50] - Batch loss: 167.2561 - Epoch Loss: 47266.5072 - Avg Loss: 159.1465\n",
            "Epoch [27/50] - Batch loss: 166.1471 - Epoch Loss: 47432.6543 - Avg Loss: 159.1700\n",
            "Epoch [27/50] - Batch loss: 168.0744 - Epoch Loss: 47600.7287 - Avg Loss: 159.1998\n",
            "Epoch [27/50] - Batch loss: 157.3115 - Epoch Loss: 47758.0403 - Avg Loss: 159.1935\n",
            "Epoch [27/50] - Batch loss: 169.2458 - Epoch Loss: 47927.2861 - Avg Loss: 159.2269\n",
            "Epoch [27/50] - Batch loss: 160.9919 - Epoch Loss: 48088.2780 - Avg Loss: 159.2327\n",
            "Epoch [27/50] - Batch loss: 165.5594 - Epoch Loss: 48253.8374 - Avg Loss: 159.2536\n",
            "Epoch [27/50] - Batch loss: 153.2884 - Epoch Loss: 48407.1258 - Avg Loss: 159.2340\n",
            "Epoch [27/50] - Batch loss: 163.4773 - Epoch Loss: 48570.6032 - Avg Loss: 159.2479\n",
            "Epoch [27/50] - Batch loss: 160.4054 - Epoch Loss: 48731.0086 - Avg Loss: 159.2517\n",
            "Epoch [27/50] - Batch loss: 165.8236 - Epoch Loss: 48896.8322 - Avg Loss: 159.2731\n",
            "Epoch [27/50] - Batch loss: 154.2614 - Epoch Loss: 49051.0936 - Avg Loss: 159.2568\n",
            "Epoch [27/50] - Batch loss: 164.0435 - Epoch Loss: 49215.1371 - Avg Loss: 159.2723\n",
            "Epoch [27/50] - Batch loss: 167.9317 - Epoch Loss: 49383.0687 - Avg Loss: 159.3002\n",
            "Epoch [27/50] - Batch loss: 159.6613 - Epoch Loss: 49542.7301 - Avg Loss: 159.3014\n",
            "Epoch [27/50] - Batch loss: 167.0794 - Epoch Loss: 49709.8095 - Avg Loss: 159.3263\n",
            "Epoch [27/50] - Batch loss: 153.0212 - Epoch Loss: 49862.8307 - Avg Loss: 159.3062\n",
            "Epoch [27/50] - Batch loss: 160.6441 - Epoch Loss: 50023.4749 - Avg Loss: 159.3104\n",
            "Epoch [27/50] - Batch loss: 153.1481 - Epoch Loss: 50176.6229 - Avg Loss: 159.2909\n",
            "Epoch [27/50] - Batch loss: 161.2592 - Epoch Loss: 50337.8822 - Avg Loss: 159.2971\n",
            "Epoch [27/50] - Batch loss: 169.5925 - Epoch Loss: 50507.4747 - Avg Loss: 159.3296\n",
            "Epoch [27/50] - Batch loss: 162.4251 - Epoch Loss: 50669.8998 - Avg Loss: 159.3393\n",
            "Epoch [27/50] - Batch loss: 160.9090 - Epoch Loss: 50830.8088 - Avg Loss: 159.3442\n",
            "Epoch [27/50] - Batch loss: 171.9190 - Epoch Loss: 51002.7278 - Avg Loss: 159.3835\n",
            "Epoch [27/50] - Batch loss: 159.2730 - Epoch Loss: 51162.0008 - Avg Loss: 159.3832\n",
            "Epoch [27/50] - Batch loss: 169.3321 - Epoch Loss: 51331.3328 - Avg Loss: 159.4141\n",
            "Epoch [27/50] - Batch loss: 162.9919 - Epoch Loss: 51494.3247 - Avg Loss: 159.4252\n",
            "Epoch [27/50] - Batch loss: 160.0208 - Epoch Loss: 51654.3454 - Avg Loss: 159.4270\n",
            "Epoch [27/50] - Batch loss: 157.9217 - Epoch Loss: 51812.2672 - Avg Loss: 159.4224\n",
            "Epoch [27/50] - Batch loss: 160.6613 - Epoch Loss: 51972.9285 - Avg Loss: 159.4262\n",
            "Epoch [27/50] - Batch loss: 164.1875 - Epoch Loss: 52137.1160 - Avg Loss: 159.4407\n",
            "Epoch [27/50] - Batch loss: 156.7976 - Epoch Loss: 52293.9136 - Avg Loss: 159.4327\n",
            "Epoch [27/50] - Batch loss: 166.9870 - Epoch Loss: 52460.9006 - Avg Loss: 159.4556\n",
            "Epoch [27/50] - Batch loss: 171.5175 - Epoch Loss: 52632.4181 - Avg Loss: 159.4922\n",
            "Epoch [27/50] - Batch loss: 161.9412 - Epoch Loss: 52794.3593 - Avg Loss: 159.4996\n",
            "Epoch [27/50] - Batch loss: 160.0326 - Epoch Loss: 52954.3919 - Avg Loss: 159.5012\n",
            "Epoch [27/50] - Batch loss: 162.3810 - Epoch Loss: 53116.7729 - Avg Loss: 159.5098\n",
            "Epoch [27/50] - Batch loss: 166.6921 - Epoch Loss: 53283.4650 - Avg Loss: 159.5313\n",
            "Epoch [27/50] - Batch loss: 167.0305 - Epoch Loss: 53450.4955 - Avg Loss: 159.5537\n",
            "Epoch [27/50] - Batch loss: 165.3789 - Epoch Loss: 53615.8744 - Avg Loss: 159.5711\n",
            "Epoch [27/50] - Batch loss: 164.9300 - Epoch Loss: 53780.8043 - Avg Loss: 159.5870\n",
            "Epoch [27/50] - Batch loss: 162.4764 - Epoch Loss: 53943.2807 - Avg Loss: 159.5955\n",
            "Epoch [27/50] - Batch loss: 162.5410 - Epoch Loss: 54105.8217 - Avg Loss: 159.6042\n",
            "Epoch [27/50] - Batch loss: 152.9173 - Epoch Loss: 54258.7390 - Avg Loss: 159.5845\n",
            "Epoch [27/50] - Batch loss: 157.9249 - Epoch Loss: 54416.6639 - Avg Loss: 159.5797\n",
            "Epoch [27/50] - Batch loss: 158.6386 - Epoch Loss: 54575.3025 - Avg Loss: 159.5769\n",
            "Epoch [27/50] - Batch loss: 164.4942 - Epoch Loss: 54739.7968 - Avg Loss: 159.5912\n",
            "Epoch [27/50] - Batch loss: 160.2836 - Epoch Loss: 54900.0803 - Avg Loss: 159.5933\n",
            "Epoch [27/50] - Batch loss: 159.2821 - Epoch Loss: 55059.3624 - Avg Loss: 159.5924\n",
            "Epoch [27/50] - Batch loss: 161.2601 - Epoch Loss: 55220.6225 - Avg Loss: 159.5972\n",
            "Epoch [27/50] - Batch loss: 156.8454 - Epoch Loss: 55377.4680 - Avg Loss: 159.5892\n",
            "Epoch [27/50] - Batch loss: 162.6786 - Epoch Loss: 55540.1466 - Avg Loss: 159.5981\n",
            "Epoch [27/50] - Batch loss: 166.6107 - Epoch Loss: 55706.7572 - Avg Loss: 159.6182\n",
            "Epoch [27/50] - Batch loss: 167.8425 - Epoch Loss: 55874.5997 - Avg Loss: 159.6417\n",
            "Epoch [27/50] - Batch loss: 169.9609 - Epoch Loss: 56044.5606 - Avg Loss: 159.6711\n",
            "Epoch [27/50] - Batch loss: 162.4913 - Epoch Loss: 56207.0519 - Avg Loss: 159.6791\n",
            "Epoch [27/50] - Batch loss: 162.1221 - Epoch Loss: 56369.1740 - Avg Loss: 159.6860\n",
            "Epoch [27/50] - Batch loss: 158.7153 - Epoch Loss: 56527.8893 - Avg Loss: 159.6833\n",
            "Epoch [27/50] - Batch loss: 168.6364 - Epoch Loss: 56696.5256 - Avg Loss: 159.7085\n",
            "Epoch [27/50] - Batch loss: 161.3303 - Epoch Loss: 56857.8559 - Avg Loss: 159.7131\n",
            "Epoch [27/50] - Batch loss: 159.8314 - Epoch Loss: 57017.6873 - Avg Loss: 159.7134\n",
            "Epoch [27/50] - Batch loss: 169.9417 - Epoch Loss: 57187.6290 - Avg Loss: 159.7420\n",
            "Epoch [27/50] - Batch loss: 166.3538 - Epoch Loss: 57353.9828 - Avg Loss: 159.7604\n",
            "Epoch [27/50] - Batch loss: 158.2452 - Epoch Loss: 57512.2280 - Avg Loss: 159.7562\n",
            "Epoch [27/50] - Batch loss: 163.4700 - Epoch Loss: 57675.6980 - Avg Loss: 159.7665\n",
            "Epoch [27/50] - Batch loss: 163.6962 - Epoch Loss: 57839.3942 - Avg Loss: 159.7773\n",
            "Epoch [27/50] - Batch loss: 162.7064 - Epoch Loss: 58002.1006 - Avg Loss: 159.7854\n",
            "Epoch [27/50] - Batch loss: 168.1543 - Epoch Loss: 58170.2549 - Avg Loss: 159.8084\n",
            "Epoch [27/50] - Batch loss: 160.6992 - Epoch Loss: 58330.9541 - Avg Loss: 159.8108\n",
            "Epoch [27/50] - Batch loss: 166.7475 - Epoch Loss: 58497.7015 - Avg Loss: 159.8298\n",
            "Epoch [27/50] - Batch loss: 159.3203 - Epoch Loss: 58657.0218 - Avg Loss: 159.8284\n",
            "Epoch [27/50] - Batch loss: 155.2464 - Epoch Loss: 58812.2682 - Avg Loss: 159.8159\n",
            "Epoch [27/50] - Batch loss: 156.1618 - Epoch Loss: 58968.4300 - Avg Loss: 159.8060\n",
            "Epoch [27/50] - Batch loss: 162.4590 - Epoch Loss: 59130.8890 - Avg Loss: 159.8132\n",
            "Epoch [27/50] - Batch loss: 160.7052 - Epoch Loss: 59291.5942 - Avg Loss: 159.8156\n",
            "Epoch [27/50] - Batch loss: 160.7756 - Epoch Loss: 59452.3698 - Avg Loss: 159.8182\n",
            "Epoch [27/50] - Batch loss: 159.3227 - Epoch Loss: 59611.6925 - Avg Loss: 159.8169\n",
            "Epoch [27/50] - Batch loss: 163.7967 - Epoch Loss: 59775.4892 - Avg Loss: 159.8275\n",
            "Epoch [27/50] - Batch loss: 154.8982 - Epoch Loss: 59930.3874 - Avg Loss: 159.8144\n",
            "Epoch [27/50] - Batch loss: 162.7388 - Epoch Loss: 60093.1262 - Avg Loss: 159.8221\n",
            "Epoch [27/50] - Batch loss: 158.7574 - Epoch Loss: 60251.8837 - Avg Loss: 159.8193\n",
            "Epoch [27/50] - Batch loss: 152.4548 - Epoch Loss: 60404.3385 - Avg Loss: 159.7998\n",
            "Epoch [27/50] - Batch loss: 161.3395 - Epoch Loss: 60565.6780 - Avg Loss: 159.8039\n",
            "Epoch [27/50] - Batch loss: 161.5262 - Epoch Loss: 60727.2042 - Avg Loss: 159.8084\n",
            "Epoch [27/50] - Batch loss: 165.7451 - Epoch Loss: 60892.9493 - Avg Loss: 159.8240\n",
            "Epoch [27/50] - Batch loss: 160.7479 - Epoch Loss: 61053.6972 - Avg Loss: 159.8264\n",
            "Epoch [27/50] - Batch loss: 157.8015 - Epoch Loss: 61211.4987 - Avg Loss: 159.8211\n",
            "Epoch [27/50] - Batch loss: 160.7648 - Epoch Loss: 61372.2635 - Avg Loss: 159.8236\n",
            "Epoch [27/50] - Batch loss: 163.3961 - Epoch Loss: 61535.6596 - Avg Loss: 159.8329\n",
            "Epoch [27/50] - Batch loss: 161.7975 - Epoch Loss: 61697.4571 - Avg Loss: 159.8380\n",
            "Epoch [27/50] - Batch loss: 158.7923 - Epoch Loss: 61856.2494 - Avg Loss: 159.8353\n",
            "Epoch [27/50] - Batch loss: 160.0021 - Epoch Loss: 62016.2515 - Avg Loss: 159.8357\n",
            "Epoch [27/50] - Batch loss: 161.5937 - Epoch Loss: 62177.8453 - Avg Loss: 159.8402\n",
            "Epoch [27/50] - Batch loss: 166.1266 - Epoch Loss: 62343.9719 - Avg Loss: 159.8563\n",
            "Epoch [27/50] - Batch loss: 155.6744 - Epoch Loss: 62499.6463 - Avg Loss: 159.8456\n",
            "Epoch [27/50] - Batch loss: 160.6605 - Epoch Loss: 62660.3068 - Avg Loss: 159.8477\n",
            "Epoch [27/50] - Batch loss: 159.7842 - Epoch Loss: 62820.0910 - Avg Loss: 159.8476\n",
            "Epoch [27/50] - Batch loss: 154.5707 - Epoch Loss: 62974.6617 - Avg Loss: 159.8342\n",
            "Epoch [27/50] - Batch loss: 159.2573 - Epoch Loss: 63133.9190 - Avg Loss: 159.8327\n",
            "Epoch [27/50] - Batch loss: 166.0757 - Epoch Loss: 63299.9947 - Avg Loss: 159.8485\n",
            "Epoch [27/50] - Batch loss: 164.4549 - Epoch Loss: 63464.4496 - Avg Loss: 159.8601\n",
            "Epoch [27/50] - Batch loss: 161.0177 - Epoch Loss: 63625.4673 - Avg Loss: 159.8630\n",
            "Epoch [27/50] - Batch loss: 171.5809 - Epoch Loss: 63797.0482 - Avg Loss: 159.8924\n",
            "Epoch [27/50] - Batch loss: 155.9483 - Epoch Loss: 63952.9965 - Avg Loss: 159.8825\n",
            "Epoch [27/50] - Batch loss: 156.6111 - Epoch Loss: 64109.6076 - Avg Loss: 159.8743\n",
            "Epoch [27/50] - Batch loss: 169.4005 - Epoch Loss: 64279.0081 - Avg Loss: 159.8980\n",
            "Epoch [27/50] - Batch loss: 161.3169 - Epoch Loss: 64440.3250 - Avg Loss: 159.9016\n",
            "Epoch [27/50] - Batch loss: 160.8854 - Epoch Loss: 64601.2104 - Avg Loss: 159.9040\n",
            "Epoch [27/50] - Batch loss: 163.3619 - Epoch Loss: 64764.5723 - Avg Loss: 159.9125\n",
            "Epoch [27/50] - Batch loss: 162.2574 - Epoch Loss: 64926.8298 - Avg Loss: 159.9183\n",
            "Epoch [27/50] - Batch loss: 158.4548 - Epoch Loss: 65085.2845 - Avg Loss: 159.9147\n",
            "Epoch [27/50] - Batch loss: 164.5670 - Epoch Loss: 65249.8515 - Avg Loss: 159.9261\n",
            "Epoch [27/50] - Batch loss: 155.2369 - Epoch Loss: 65405.0885 - Avg Loss: 159.9146\n",
            "Epoch [27/50] - Batch loss: 160.0540 - Epoch Loss: 65565.1425 - Avg Loss: 159.9150\n",
            "Epoch [27/50] - Batch loss: 163.8188 - Epoch Loss: 65728.9613 - Avg Loss: 159.9245\n",
            "Epoch [27/50] - Batch loss: 162.3515 - Epoch Loss: 65891.3129 - Avg Loss: 159.9304\n",
            "Epoch [27/50] - Batch loss: 158.4445 - Epoch Loss: 66049.7573 - Avg Loss: 159.9268\n",
            "Epoch [27/50] - Batch loss: 151.7839 - Epoch Loss: 66201.5413 - Avg Loss: 159.9071\n",
            "Epoch [27/50] - Batch loss: 169.6387 - Epoch Loss: 66371.1799 - Avg Loss: 159.9306\n",
            "Epoch [27/50] - Batch loss: 162.6432 - Epoch Loss: 66533.8231 - Avg Loss: 159.9371\n",
            "Epoch [27/50] - Batch loss: 163.4739 - Epoch Loss: 66697.2970 - Avg Loss: 159.9456\n",
            "Epoch [27/50] - Batch loss: 163.3852 - Epoch Loss: 66860.6822 - Avg Loss: 159.9538\n",
            "Epoch [27/50] - Batch loss: 165.8283 - Epoch Loss: 67026.5105 - Avg Loss: 159.9678\n",
            "Epoch [27/50] - Batch loss: 162.6791 - Epoch Loss: 67189.1896 - Avg Loss: 159.9743\n",
            "Epoch [27/50] - Batch loss: 162.1327 - Epoch Loss: 67351.3223 - Avg Loss: 159.9794\n",
            "Epoch [27/50] - Batch loss: 165.3228 - Epoch Loss: 67516.6451 - Avg Loss: 159.9921\n",
            "Epoch [27/50] - Batch loss: 159.0620 - Epoch Loss: 67675.7071 - Avg Loss: 159.9899\n",
            "Epoch [27/50] - Batch loss: 154.9373 - Epoch Loss: 67830.6444 - Avg Loss: 159.9779\n",
            "Epoch [27/50] - Batch loss: 162.7630 - Epoch Loss: 67993.4074 - Avg Loss: 159.9845\n",
            "Epoch [27/50] - Batch loss: 161.1902 - Epoch Loss: 68154.5976 - Avg Loss: 159.9873\n",
            "Epoch [27/50] - Batch loss: 156.1210 - Epoch Loss: 68310.7186 - Avg Loss: 159.9783\n",
            "Epoch [27/50] - Batch loss: 165.6902 - Epoch Loss: 68476.4087 - Avg Loss: 159.9916\n",
            "Epoch [27/50] - Batch loss: 164.2220 - Epoch Loss: 68640.6307 - Avg Loss: 160.0015\n",
            "Epoch [27/50] - Batch loss: 158.6092 - Epoch Loss: 68799.2399 - Avg Loss: 159.9982\n",
            "Epoch [27/50] - Batch loss: 159.9203 - Epoch Loss: 68959.1603 - Avg Loss: 159.9981\n",
            "Epoch [27/50] - Batch loss: 167.1119 - Epoch Loss: 69126.2722 - Avg Loss: 160.0145\n",
            "Epoch [27/50] - Batch loss: 165.2260 - Epoch Loss: 69291.4982 - Avg Loss: 160.0266\n",
            "Epoch [27/50] - Batch loss: 159.8811 - Epoch Loss: 69451.3793 - Avg Loss: 160.0262\n",
            "Epoch [27/50] - Batch loss: 154.4882 - Epoch Loss: 69605.8676 - Avg Loss: 160.0135\n",
            "Epoch [27/50] - Batch loss: 156.4710 - Epoch Loss: 69762.3386 - Avg Loss: 160.0054\n",
            "Epoch [27/50] - Batch loss: 165.0323 - Epoch Loss: 69927.3709 - Avg Loss: 160.0169\n",
            "Epoch [27/50] - Batch loss: 158.3739 - Epoch Loss: 70085.7448 - Avg Loss: 160.0131\n",
            "Epoch [27/50] - Batch loss: 163.4431 - Epoch Loss: 70249.1879 - Avg Loss: 160.0209\n",
            "Epoch [27/50] - Batch loss: 166.6104 - Epoch Loss: 70415.7984 - Avg Loss: 160.0359\n",
            "Epoch [27/50] - Batch loss: 157.9026 - Epoch Loss: 70573.7009 - Avg Loss: 160.0311\n",
            "Epoch [27/50] - Batch loss: 166.1933 - Epoch Loss: 70739.8942 - Avg Loss: 160.0450\n",
            "Epoch [27/50] - Batch loss: 161.9076 - Epoch Loss: 70901.8018 - Avg Loss: 160.0492\n",
            "Epoch [27/50] - Batch loss: 158.4794 - Epoch Loss: 71060.2812 - Avg Loss: 160.0457\n",
            "Epoch [27/50] - Batch loss: 161.2211 - Epoch Loss: 71221.5023 - Avg Loss: 160.0483\n",
            "Epoch [27/50] - Batch loss: 158.3855 - Epoch Loss: 71379.8878 - Avg Loss: 160.0446\n",
            "Epoch [27/50] - Batch loss: 166.8004 - Epoch Loss: 71546.6882 - Avg Loss: 160.0597\n",
            "Epoch [27/50] - Batch loss: 171.6608 - Epoch Loss: 71718.3489 - Avg Loss: 160.0856\n",
            "Epoch [27/50] - Batch loss: 165.0636 - Epoch Loss: 71883.4125 - Avg Loss: 160.0967\n",
            "Epoch [27/50] - Batch loss: 152.8938 - Epoch Loss: 72036.3063 - Avg Loss: 160.0807\n",
            "Epoch [27/50] - Batch loss: 162.1747 - Epoch Loss: 72198.4810 - Avg Loss: 160.0853\n",
            "Epoch [27/50] - Batch loss: 155.1597 - Epoch Loss: 72353.6407 - Avg Loss: 160.0744\n",
            "Epoch [27/50] - Batch loss: 158.1040 - Epoch Loss: 72511.7448 - Avg Loss: 160.0701\n",
            "Epoch [27/50] - Batch loss: 167.7120 - Epoch Loss: 72679.4568 - Avg Loss: 160.0869\n",
            "Epoch [27/50] - Batch loss: 146.9006 - Epoch Loss: 72826.3573 - Avg Loss: 160.0579\n",
            "Epoch [27/50] - Batch loss: 155.1995 - Epoch Loss: 72981.5568 - Avg Loss: 160.0473\n",
            "Epoch [27/50] - Batch loss: 161.2617 - Epoch Loss: 73142.8186 - Avg Loss: 160.0499\n",
            "Epoch [27/50] - Batch loss: 159.6315 - Epoch Loss: 73302.4501 - Avg Loss: 160.0490\n",
            "Epoch [27/50] - Batch loss: 155.1593 - Epoch Loss: 73457.6093 - Avg Loss: 160.0384\n",
            "Epoch [27/50] - Batch loss: 161.4393 - Epoch Loss: 73619.0486 - Avg Loss: 160.0414\n",
            "Epoch [27/50] - Batch loss: 171.2732 - Epoch Loss: 73790.3218 - Avg Loss: 160.0658\n",
            "Epoch [27/50] - Batch loss: 157.7289 - Epoch Loss: 73948.0507 - Avg Loss: 160.0607\n",
            "Epoch [27/50] - Batch loss: 166.7923 - Epoch Loss: 74114.8430 - Avg Loss: 160.0753\n",
            "Epoch [27/50] - Batch loss: 164.4314 - Epoch Loss: 74279.2744 - Avg Loss: 160.0846\n",
            "Epoch [27/50] - Batch loss: 158.3216 - Epoch Loss: 74437.5961 - Avg Loss: 160.0809\n",
            "Epoch [27/50] - Batch loss: 158.2214 - Epoch Loss: 74595.8174 - Avg Loss: 160.0769\n",
            "Epoch [27/50] - Batch loss: 156.5418 - Epoch Loss: 74752.3592 - Avg Loss: 160.0693\n",
            "Epoch [27/50] - Batch loss: 166.3198 - Epoch Loss: 74918.6791 - Avg Loss: 160.0826\n",
            "Epoch [27/50] - Batch loss: 161.5134 - Epoch Loss: 75080.1925 - Avg Loss: 160.0857\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 28/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0547caab71064515a84c3b99aeea6b56"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28/50] - Batch loss: 159.9576 - Epoch Loss: 159.9576 - Avg Loss: 159.9576\n",
            "Epoch [28/50] - Batch loss: 156.7536 - Epoch Loss: 316.7112 - Avg Loss: 158.3556\n",
            "Epoch [28/50] - Batch loss: 159.4501 - Epoch Loss: 476.1613 - Avg Loss: 158.7204\n",
            "Epoch [28/50] - Batch loss: 160.9225 - Epoch Loss: 637.0837 - Avg Loss: 159.2709\n",
            "Epoch [28/50] - Batch loss: 164.6130 - Epoch Loss: 801.6968 - Avg Loss: 160.3394\n",
            "Epoch [28/50] - Batch loss: 162.6212 - Epoch Loss: 964.3180 - Avg Loss: 160.7197\n",
            "Epoch [28/50] - Batch loss: 158.8609 - Epoch Loss: 1123.1789 - Avg Loss: 160.4541\n",
            "Epoch [28/50] - Batch loss: 159.1638 - Epoch Loss: 1282.3426 - Avg Loss: 160.2928\n",
            "Epoch [28/50] - Batch loss: 158.5344 - Epoch Loss: 1440.8771 - Avg Loss: 160.0975\n",
            "Epoch [28/50] - Batch loss: 160.2709 - Epoch Loss: 1601.1480 - Avg Loss: 160.1148\n",
            "Epoch [28/50] - Batch loss: 162.1824 - Epoch Loss: 1763.3304 - Avg Loss: 160.3028\n",
            "Epoch [28/50] - Batch loss: 159.7072 - Epoch Loss: 1923.0376 - Avg Loss: 160.2531\n",
            "Epoch [28/50] - Batch loss: 163.3023 - Epoch Loss: 2086.3399 - Avg Loss: 160.4877\n",
            "Epoch [28/50] - Batch loss: 155.2969 - Epoch Loss: 2241.6368 - Avg Loss: 160.1169\n",
            "Epoch [28/50] - Batch loss: 163.4162 - Epoch Loss: 2405.0529 - Avg Loss: 160.3369\n",
            "Epoch [28/50] - Batch loss: 168.7955 - Epoch Loss: 2573.8484 - Avg Loss: 160.8655\n",
            "Epoch [28/50] - Batch loss: 159.2331 - Epoch Loss: 2733.0815 - Avg Loss: 160.7695\n",
            "Epoch [28/50] - Batch loss: 156.4101 - Epoch Loss: 2889.4916 - Avg Loss: 160.5273\n",
            "Epoch [28/50] - Batch loss: 159.5991 - Epoch Loss: 3049.0907 - Avg Loss: 160.4785\n",
            "Epoch [28/50] - Batch loss: 163.6340 - Epoch Loss: 3212.7247 - Avg Loss: 160.6362\n",
            "Epoch [28/50] - Batch loss: 166.9816 - Epoch Loss: 3379.7063 - Avg Loss: 160.9384\n",
            "Epoch [28/50] - Batch loss: 161.4543 - Epoch Loss: 3541.1606 - Avg Loss: 160.9618\n",
            "Epoch [28/50] - Batch loss: 157.5851 - Epoch Loss: 3698.7457 - Avg Loss: 160.8150\n",
            "Epoch [28/50] - Batch loss: 157.3909 - Epoch Loss: 3856.1365 - Avg Loss: 160.6724\n",
            "Epoch [28/50] - Batch loss: 160.7432 - Epoch Loss: 4016.8797 - Avg Loss: 160.6752\n",
            "Epoch [28/50] - Batch loss: 168.6143 - Epoch Loss: 4185.4940 - Avg Loss: 160.9805\n",
            "Epoch [28/50] - Batch loss: 160.3470 - Epoch Loss: 4345.8410 - Avg Loss: 160.9571\n",
            "Epoch [28/50] - Batch loss: 159.9919 - Epoch Loss: 4505.8329 - Avg Loss: 160.9226\n",
            "Epoch [28/50] - Batch loss: 157.2132 - Epoch Loss: 4663.0461 - Avg Loss: 160.7947\n",
            "Epoch [28/50] - Batch loss: 158.6542 - Epoch Loss: 4821.7003 - Avg Loss: 160.7233\n",
            "Epoch [28/50] - Batch loss: 163.3783 - Epoch Loss: 4985.0786 - Avg Loss: 160.8090\n",
            "Epoch [28/50] - Batch loss: 166.3296 - Epoch Loss: 5151.4082 - Avg Loss: 160.9815\n",
            "Epoch [28/50] - Batch loss: 152.7928 - Epoch Loss: 5304.2010 - Avg Loss: 160.7334\n",
            "Epoch [28/50] - Batch loss: 155.0482 - Epoch Loss: 5459.2492 - Avg Loss: 160.5662\n",
            "Epoch [28/50] - Batch loss: 157.8994 - Epoch Loss: 5617.1486 - Avg Loss: 160.4900\n",
            "Epoch [28/50] - Batch loss: 159.7545 - Epoch Loss: 5776.9031 - Avg Loss: 160.4695\n",
            "Epoch [28/50] - Batch loss: 158.6978 - Epoch Loss: 5935.6008 - Avg Loss: 160.4216\n",
            "Epoch [28/50] - Batch loss: 163.4256 - Epoch Loss: 6099.0264 - Avg Loss: 160.5007\n",
            "Epoch [28/50] - Batch loss: 162.5375 - Epoch Loss: 6261.5639 - Avg Loss: 160.5529\n",
            "Epoch [28/50] - Batch loss: 159.2326 - Epoch Loss: 6420.7965 - Avg Loss: 160.5199\n",
            "Epoch [28/50] - Batch loss: 163.0594 - Epoch Loss: 6583.8559 - Avg Loss: 160.5819\n",
            "Epoch [28/50] - Batch loss: 156.2873 - Epoch Loss: 6740.1432 - Avg Loss: 160.4796\n",
            "Epoch [28/50] - Batch loss: 155.2429 - Epoch Loss: 6895.3861 - Avg Loss: 160.3578\n",
            "Epoch [28/50] - Batch loss: 157.2403 - Epoch Loss: 7052.6264 - Avg Loss: 160.2870\n",
            "Epoch [28/50] - Batch loss: 160.6074 - Epoch Loss: 7213.2337 - Avg Loss: 160.2941\n",
            "Epoch [28/50] - Batch loss: 153.0266 - Epoch Loss: 7366.2603 - Avg Loss: 160.1361\n",
            "Epoch [28/50] - Batch loss: 162.2165 - Epoch Loss: 7528.4768 - Avg Loss: 160.1804\n",
            "Epoch [28/50] - Batch loss: 154.8931 - Epoch Loss: 7683.3699 - Avg Loss: 160.0702\n",
            "Epoch [28/50] - Batch loss: 161.3195 - Epoch Loss: 7844.6894 - Avg Loss: 160.0957\n",
            "Epoch [28/50] - Batch loss: 166.4200 - Epoch Loss: 8011.1094 - Avg Loss: 160.2222\n",
            "Epoch [28/50] - Batch loss: 166.4607 - Epoch Loss: 8177.5701 - Avg Loss: 160.3445\n",
            "Epoch [28/50] - Batch loss: 156.5743 - Epoch Loss: 8334.1444 - Avg Loss: 160.2720\n",
            "Epoch [28/50] - Batch loss: 166.5652 - Epoch Loss: 8500.7095 - Avg Loss: 160.3907\n",
            "Epoch [28/50] - Batch loss: 157.7983 - Epoch Loss: 8658.5078 - Avg Loss: 160.3427\n",
            "Epoch [28/50] - Batch loss: 158.2282 - Epoch Loss: 8816.7361 - Avg Loss: 160.3043\n",
            "Epoch [28/50] - Batch loss: 158.8767 - Epoch Loss: 8975.6128 - Avg Loss: 160.2788\n",
            "Epoch [28/50] - Batch loss: 154.6231 - Epoch Loss: 9130.2359 - Avg Loss: 160.1796\n",
            "Epoch [28/50] - Batch loss: 159.9263 - Epoch Loss: 9290.1622 - Avg Loss: 160.1752\n",
            "Epoch [28/50] - Batch loss: 159.3219 - Epoch Loss: 9449.4841 - Avg Loss: 160.1607\n",
            "Epoch [28/50] - Batch loss: 154.8158 - Epoch Loss: 9604.2999 - Avg Loss: 160.0717\n",
            "Epoch [28/50] - Batch loss: 162.6104 - Epoch Loss: 9766.9102 - Avg Loss: 160.1133\n",
            "Epoch [28/50] - Batch loss: 157.5139 - Epoch Loss: 9924.4241 - Avg Loss: 160.0714\n",
            "Epoch [28/50] - Batch loss: 152.4520 - Epoch Loss: 10076.8761 - Avg Loss: 159.9504\n",
            "Epoch [28/50] - Batch loss: 159.3507 - Epoch Loss: 10236.2269 - Avg Loss: 159.9410\n",
            "Epoch [28/50] - Batch loss: 151.3322 - Epoch Loss: 10387.5591 - Avg Loss: 159.8086\n",
            "Epoch [28/50] - Batch loss: 158.2011 - Epoch Loss: 10545.7602 - Avg Loss: 159.7842\n",
            "Epoch [28/50] - Batch loss: 162.9982 - Epoch Loss: 10708.7584 - Avg Loss: 159.8322\n",
            "Epoch [28/50] - Batch loss: 168.0507 - Epoch Loss: 10876.8091 - Avg Loss: 159.9531\n",
            "Epoch [28/50] - Batch loss: 165.6655 - Epoch Loss: 11042.4747 - Avg Loss: 160.0359\n",
            "Epoch [28/50] - Batch loss: 157.5431 - Epoch Loss: 11200.0177 - Avg Loss: 160.0003\n",
            "Epoch [28/50] - Batch loss: 169.3824 - Epoch Loss: 11369.4001 - Avg Loss: 160.1324\n",
            "Epoch [28/50] - Batch loss: 154.4885 - Epoch Loss: 11523.8886 - Avg Loss: 160.0540\n",
            "Epoch [28/50] - Batch loss: 162.4282 - Epoch Loss: 11686.3168 - Avg Loss: 160.0865\n",
            "Epoch [28/50] - Batch loss: 158.7561 - Epoch Loss: 11845.0729 - Avg Loss: 160.0686\n",
            "Epoch [28/50] - Batch loss: 164.9889 - Epoch Loss: 12010.0618 - Avg Loss: 160.1342\n",
            "Epoch [28/50] - Batch loss: 157.8477 - Epoch Loss: 12167.9095 - Avg Loss: 160.1041\n",
            "Epoch [28/50] - Batch loss: 161.4427 - Epoch Loss: 12329.3522 - Avg Loss: 160.1215\n",
            "Epoch [28/50] - Batch loss: 161.2785 - Epoch Loss: 12490.6307 - Avg Loss: 160.1363\n",
            "Epoch [28/50] - Batch loss: 151.3444 - Epoch Loss: 12641.9751 - Avg Loss: 160.0250\n",
            "Epoch [28/50] - Batch loss: 160.4058 - Epoch Loss: 12802.3809 - Avg Loss: 160.0298\n",
            "Epoch [28/50] - Batch loss: 156.4778 - Epoch Loss: 12958.8587 - Avg Loss: 159.9859\n",
            "Epoch [28/50] - Batch loss: 161.0835 - Epoch Loss: 13119.9422 - Avg Loss: 159.9993\n",
            "Epoch [28/50] - Batch loss: 159.6185 - Epoch Loss: 13279.5607 - Avg Loss: 159.9947\n",
            "Epoch [28/50] - Batch loss: 151.9271 - Epoch Loss: 13431.4878 - Avg Loss: 159.8987\n",
            "Epoch [28/50] - Batch loss: 163.0909 - Epoch Loss: 13594.5787 - Avg Loss: 159.9362\n",
            "Epoch [28/50] - Batch loss: 155.6207 - Epoch Loss: 13750.1994 - Avg Loss: 159.8860\n",
            "Epoch [28/50] - Batch loss: 154.8499 - Epoch Loss: 13905.0493 - Avg Loss: 159.8282\n",
            "Epoch [28/50] - Batch loss: 161.1916 - Epoch Loss: 14066.2410 - Avg Loss: 159.8436\n",
            "Epoch [28/50] - Batch loss: 158.9237 - Epoch Loss: 14225.1646 - Avg Loss: 159.8333\n",
            "Epoch [28/50] - Batch loss: 160.3960 - Epoch Loss: 14385.5607 - Avg Loss: 159.8396\n",
            "Epoch [28/50] - Batch loss: 150.2144 - Epoch Loss: 14535.7751 - Avg Loss: 159.7338\n",
            "Epoch [28/50] - Batch loss: 158.7284 - Epoch Loss: 14694.5035 - Avg Loss: 159.7229\n",
            "Epoch [28/50] - Batch loss: 162.4296 - Epoch Loss: 14856.9331 - Avg Loss: 159.7520\n",
            "Epoch [28/50] - Batch loss: 160.5181 - Epoch Loss: 15017.4512 - Avg Loss: 159.7601\n",
            "Epoch [28/50] - Batch loss: 153.4420 - Epoch Loss: 15170.8932 - Avg Loss: 159.6936\n",
            "Epoch [28/50] - Batch loss: 156.2990 - Epoch Loss: 15327.1921 - Avg Loss: 159.6583\n",
            "Epoch [28/50] - Batch loss: 156.2820 - Epoch Loss: 15483.4742 - Avg Loss: 159.6234\n",
            "Epoch [28/50] - Batch loss: 156.5270 - Epoch Loss: 15640.0012 - Avg Loss: 159.5918\n",
            "Epoch [28/50] - Batch loss: 161.1897 - Epoch Loss: 15801.1909 - Avg Loss: 159.6080\n",
            "Epoch [28/50] - Batch loss: 161.1298 - Epoch Loss: 15962.3207 - Avg Loss: 159.6232\n",
            "Epoch [28/50] - Batch loss: 170.6622 - Epoch Loss: 16132.9829 - Avg Loss: 159.7325\n",
            "Epoch [28/50] - Batch loss: 159.6458 - Epoch Loss: 16292.6287 - Avg Loss: 159.7317\n",
            "Epoch [28/50] - Batch loss: 156.7205 - Epoch Loss: 16449.3492 - Avg Loss: 159.7024\n",
            "Epoch [28/50] - Batch loss: 156.7151 - Epoch Loss: 16606.0643 - Avg Loss: 159.6737\n",
            "Epoch [28/50] - Batch loss: 160.8035 - Epoch Loss: 16766.8677 - Avg Loss: 159.6845\n",
            "Epoch [28/50] - Batch loss: 165.7360 - Epoch Loss: 16932.6038 - Avg Loss: 159.7415\n",
            "Epoch [28/50] - Batch loss: 166.1147 - Epoch Loss: 17098.7185 - Avg Loss: 159.8011\n",
            "Epoch [28/50] - Batch loss: 154.1679 - Epoch Loss: 17252.8863 - Avg Loss: 159.7489\n",
            "Epoch [28/50] - Batch loss: 162.1573 - Epoch Loss: 17415.0436 - Avg Loss: 159.7710\n",
            "Epoch [28/50] - Batch loss: 153.2149 - Epoch Loss: 17568.2585 - Avg Loss: 159.7114\n",
            "Epoch [28/50] - Batch loss: 151.8720 - Epoch Loss: 17720.1305 - Avg Loss: 159.6408\n",
            "Epoch [28/50] - Batch loss: 164.2564 - Epoch Loss: 17884.3869 - Avg Loss: 159.6820\n",
            "Epoch [28/50] - Batch loss: 146.4506 - Epoch Loss: 18030.8374 - Avg Loss: 159.5649\n",
            "Epoch [28/50] - Batch loss: 159.7894 - Epoch Loss: 18190.6269 - Avg Loss: 159.5669\n",
            "Epoch [28/50] - Batch loss: 161.0109 - Epoch Loss: 18351.6378 - Avg Loss: 159.5795\n",
            "Epoch [28/50] - Batch loss: 153.5801 - Epoch Loss: 18505.2179 - Avg Loss: 159.5277\n",
            "Epoch [28/50] - Batch loss: 167.3899 - Epoch Loss: 18672.6078 - Avg Loss: 159.5949\n",
            "Epoch [28/50] - Batch loss: 162.1432 - Epoch Loss: 18834.7509 - Avg Loss: 159.6165\n",
            "Epoch [28/50] - Batch loss: 158.6180 - Epoch Loss: 18993.3689 - Avg Loss: 159.6081\n",
            "Epoch [28/50] - Batch loss: 154.4796 - Epoch Loss: 19147.8485 - Avg Loss: 159.5654\n",
            "Epoch [28/50] - Batch loss: 150.0867 - Epoch Loss: 19297.9353 - Avg Loss: 159.4871\n",
            "Epoch [28/50] - Batch loss: 154.2912 - Epoch Loss: 19452.2265 - Avg Loss: 159.4445\n",
            "Epoch [28/50] - Batch loss: 160.1518 - Epoch Loss: 19612.3783 - Avg Loss: 159.4502\n",
            "Epoch [28/50] - Batch loss: 153.1772 - Epoch Loss: 19765.5555 - Avg Loss: 159.3996\n",
            "Epoch [28/50] - Batch loss: 154.3527 - Epoch Loss: 19919.9082 - Avg Loss: 159.3593\n",
            "Epoch [28/50] - Batch loss: 165.5388 - Epoch Loss: 20085.4470 - Avg Loss: 159.4083\n",
            "Epoch [28/50] - Batch loss: 154.7123 - Epoch Loss: 20240.1593 - Avg Loss: 159.3713\n",
            "Epoch [28/50] - Batch loss: 160.3276 - Epoch Loss: 20400.4868 - Avg Loss: 159.3788\n",
            "Epoch [28/50] - Batch loss: 159.5896 - Epoch Loss: 20560.0764 - Avg Loss: 159.3804\n",
            "Epoch [28/50] - Batch loss: 162.3970 - Epoch Loss: 20722.4734 - Avg Loss: 159.4036\n",
            "Epoch [28/50] - Batch loss: 159.0719 - Epoch Loss: 20881.5454 - Avg Loss: 159.4011\n",
            "Epoch [28/50] - Batch loss: 153.8484 - Epoch Loss: 21035.3938 - Avg Loss: 159.3590\n",
            "Epoch [28/50] - Batch loss: 156.4151 - Epoch Loss: 21191.8088 - Avg Loss: 159.3369\n",
            "Epoch [28/50] - Batch loss: 158.1467 - Epoch Loss: 21349.9556 - Avg Loss: 159.3280\n",
            "Epoch [28/50] - Batch loss: 156.9455 - Epoch Loss: 21506.9011 - Avg Loss: 159.3104\n",
            "Epoch [28/50] - Batch loss: 155.9302 - Epoch Loss: 21662.8313 - Avg Loss: 159.2855\n",
            "Epoch [28/50] - Batch loss: 154.9673 - Epoch Loss: 21817.7986 - Avg Loss: 159.2540\n",
            "Epoch [28/50] - Batch loss: 158.9515 - Epoch Loss: 21976.7501 - Avg Loss: 159.2518\n",
            "Epoch [28/50] - Batch loss: 160.0542 - Epoch Loss: 22136.8043 - Avg Loss: 159.2576\n",
            "Epoch [28/50] - Batch loss: 161.4979 - Epoch Loss: 22298.3022 - Avg Loss: 159.2736\n",
            "Epoch [28/50] - Batch loss: 163.9217 - Epoch Loss: 22462.2239 - Avg Loss: 159.3066\n",
            "Epoch [28/50] - Batch loss: 159.0634 - Epoch Loss: 22621.2874 - Avg Loss: 159.3048\n",
            "Epoch [28/50] - Batch loss: 152.9242 - Epoch Loss: 22774.2116 - Avg Loss: 159.2602\n",
            "Epoch [28/50] - Batch loss: 155.8484 - Epoch Loss: 22930.0600 - Avg Loss: 159.2365\n",
            "Epoch [28/50] - Batch loss: 161.2729 - Epoch Loss: 23091.3330 - Avg Loss: 159.2506\n",
            "Epoch [28/50] - Batch loss: 156.7818 - Epoch Loss: 23248.1148 - Avg Loss: 159.2337\n",
            "Epoch [28/50] - Batch loss: 149.9455 - Epoch Loss: 23398.0603 - Avg Loss: 159.1705\n",
            "Epoch [28/50] - Batch loss: 159.2290 - Epoch Loss: 23557.2892 - Avg Loss: 159.1709\n",
            "Epoch [28/50] - Batch loss: 157.4691 - Epoch Loss: 23714.7583 - Avg Loss: 159.1595\n",
            "Epoch [28/50] - Batch loss: 162.3921 - Epoch Loss: 23877.1505 - Avg Loss: 159.1810\n",
            "Epoch [28/50] - Batch loss: 156.7142 - Epoch Loss: 24033.8646 - Avg Loss: 159.1647\n",
            "Epoch [28/50] - Batch loss: 159.2624 - Epoch Loss: 24193.1270 - Avg Loss: 159.1653\n",
            "Epoch [28/50] - Batch loss: 164.0921 - Epoch Loss: 24357.2191 - Avg Loss: 159.1975\n",
            "Epoch [28/50] - Batch loss: 166.1709 - Epoch Loss: 24523.3900 - Avg Loss: 159.2428\n",
            "Epoch [28/50] - Batch loss: 167.9288 - Epoch Loss: 24691.3188 - Avg Loss: 159.2988\n",
            "Epoch [28/50] - Batch loss: 160.4913 - Epoch Loss: 24851.8100 - Avg Loss: 159.3065\n",
            "Epoch [28/50] - Batch loss: 156.2927 - Epoch Loss: 25008.1028 - Avg Loss: 159.2873\n",
            "Epoch [28/50] - Batch loss: 157.3219 - Epoch Loss: 25165.4246 - Avg Loss: 159.2748\n",
            "Epoch [28/50] - Batch loss: 163.1692 - Epoch Loss: 25328.5938 - Avg Loss: 159.2993\n",
            "Epoch [28/50] - Batch loss: 157.9487 - Epoch Loss: 25486.5425 - Avg Loss: 159.2909\n",
            "Epoch [28/50] - Batch loss: 162.4467 - Epoch Loss: 25648.9892 - Avg Loss: 159.3105\n",
            "Epoch [28/50] - Batch loss: 161.9113 - Epoch Loss: 25810.9005 - Avg Loss: 159.3265\n",
            "Epoch [28/50] - Batch loss: 167.0585 - Epoch Loss: 25977.9590 - Avg Loss: 159.3740\n",
            "Epoch [28/50] - Batch loss: 156.8605 - Epoch Loss: 26134.8195 - Avg Loss: 159.3587\n",
            "Epoch [28/50] - Batch loss: 162.4780 - Epoch Loss: 26297.2975 - Avg Loss: 159.3776\n",
            "Epoch [28/50] - Batch loss: 161.4645 - Epoch Loss: 26458.7620 - Avg Loss: 159.3901\n",
            "Epoch [28/50] - Batch loss: 155.0843 - Epoch Loss: 26613.8463 - Avg Loss: 159.3643\n",
            "Epoch [28/50] - Batch loss: 160.8755 - Epoch Loss: 26774.7218 - Avg Loss: 159.3733\n",
            "Epoch [28/50] - Batch loss: 156.2617 - Epoch Loss: 26930.9836 - Avg Loss: 159.3549\n",
            "Epoch [28/50] - Batch loss: 156.1682 - Epoch Loss: 27087.1517 - Avg Loss: 159.3362\n",
            "Epoch [28/50] - Batch loss: 165.1851 - Epoch Loss: 27252.3368 - Avg Loss: 159.3704\n",
            "Epoch [28/50] - Batch loss: 162.1473 - Epoch Loss: 27414.4841 - Avg Loss: 159.3865\n",
            "Epoch [28/50] - Batch loss: 156.0091 - Epoch Loss: 27570.4931 - Avg Loss: 159.3670\n",
            "Epoch [28/50] - Batch loss: 159.9008 - Epoch Loss: 27730.3940 - Avg Loss: 159.3701\n",
            "Epoch [28/50] - Batch loss: 158.3292 - Epoch Loss: 27888.7231 - Avg Loss: 159.3641\n",
            "Epoch [28/50] - Batch loss: 159.7340 - Epoch Loss: 28048.4572 - Avg Loss: 159.3662\n",
            "Epoch [28/50] - Batch loss: 153.9786 - Epoch Loss: 28202.4358 - Avg Loss: 159.3358\n",
            "Epoch [28/50] - Batch loss: 150.8713 - Epoch Loss: 28353.3071 - Avg Loss: 159.2882\n",
            "Epoch [28/50] - Batch loss: 160.4327 - Epoch Loss: 28513.7398 - Avg Loss: 159.2946\n",
            "Epoch [28/50] - Batch loss: 159.4561 - Epoch Loss: 28673.1959 - Avg Loss: 159.2955\n",
            "Epoch [28/50] - Batch loss: 162.0000 - Epoch Loss: 28835.1959 - Avg Loss: 159.3105\n",
            "Epoch [28/50] - Batch loss: 154.4057 - Epoch Loss: 28989.6016 - Avg Loss: 159.2835\n",
            "Epoch [28/50] - Batch loss: 157.3338 - Epoch Loss: 29146.9355 - Avg Loss: 159.2729\n",
            "Epoch [28/50] - Batch loss: 166.2565 - Epoch Loss: 29313.1920 - Avg Loss: 159.3108\n",
            "Epoch [28/50] - Batch loss: 156.6949 - Epoch Loss: 29469.8869 - Avg Loss: 159.2967\n",
            "Epoch [28/50] - Batch loss: 158.6935 - Epoch Loss: 29628.5804 - Avg Loss: 159.2934\n",
            "Epoch [28/50] - Batch loss: 158.5329 - Epoch Loss: 29787.1133 - Avg Loss: 159.2894\n",
            "Epoch [28/50] - Batch loss: 156.9182 - Epoch Loss: 29944.0316 - Avg Loss: 159.2768\n",
            "Epoch [28/50] - Batch loss: 159.5566 - Epoch Loss: 30103.5882 - Avg Loss: 159.2782\n",
            "Epoch [28/50] - Batch loss: 155.1770 - Epoch Loss: 30258.7652 - Avg Loss: 159.2567\n",
            "Epoch [28/50] - Batch loss: 160.8279 - Epoch Loss: 30419.5932 - Avg Loss: 159.2649\n",
            "Epoch [28/50] - Batch loss: 154.9919 - Epoch Loss: 30574.5850 - Avg Loss: 159.2426\n",
            "Epoch [28/50] - Batch loss: 155.8013 - Epoch Loss: 30730.3863 - Avg Loss: 159.2248\n",
            "Epoch [28/50] - Batch loss: 158.1724 - Epoch Loss: 30888.5587 - Avg Loss: 159.2194\n",
            "Epoch [28/50] - Batch loss: 154.5461 - Epoch Loss: 31043.1049 - Avg Loss: 159.1954\n",
            "Epoch [28/50] - Batch loss: 151.8935 - Epoch Loss: 31194.9983 - Avg Loss: 159.1582\n",
            "Epoch [28/50] - Batch loss: 155.7625 - Epoch Loss: 31350.7608 - Avg Loss: 159.1409\n",
            "Epoch [28/50] - Batch loss: 160.9634 - Epoch Loss: 31511.7242 - Avg Loss: 159.1501\n",
            "Epoch [28/50] - Batch loss: 157.2351 - Epoch Loss: 31668.9592 - Avg Loss: 159.1405\n",
            "Epoch [28/50] - Batch loss: 153.8460 - Epoch Loss: 31822.8053 - Avg Loss: 159.1140\n",
            "Epoch [28/50] - Batch loss: 161.9011 - Epoch Loss: 31984.7063 - Avg Loss: 159.1279\n",
            "Epoch [28/50] - Batch loss: 150.9370 - Epoch Loss: 32135.6433 - Avg Loss: 159.0873\n",
            "Epoch [28/50] - Batch loss: 159.3750 - Epoch Loss: 32295.0182 - Avg Loss: 159.0888\n",
            "Epoch [28/50] - Batch loss: 159.4454 - Epoch Loss: 32454.4636 - Avg Loss: 159.0905\n",
            "Epoch [28/50] - Batch loss: 168.8133 - Epoch Loss: 32623.2769 - Avg Loss: 159.1379\n",
            "Epoch [28/50] - Batch loss: 160.1360 - Epoch Loss: 32783.4129 - Avg Loss: 159.1428\n",
            "Epoch [28/50] - Batch loss: 161.6442 - Epoch Loss: 32945.0571 - Avg Loss: 159.1549\n",
            "Epoch [28/50] - Batch loss: 171.1019 - Epoch Loss: 33116.1590 - Avg Loss: 159.2123\n",
            "Epoch [28/50] - Batch loss: 157.5026 - Epoch Loss: 33273.6615 - Avg Loss: 159.2041\n",
            "Epoch [28/50] - Batch loss: 154.8727 - Epoch Loss: 33428.5343 - Avg Loss: 159.1835\n",
            "Epoch [28/50] - Batch loss: 153.9538 - Epoch Loss: 33582.4881 - Avg Loss: 159.1587\n",
            "Epoch [28/50] - Batch loss: 164.3997 - Epoch Loss: 33746.8878 - Avg Loss: 159.1834\n",
            "Epoch [28/50] - Batch loss: 158.4184 - Epoch Loss: 33905.3062 - Avg Loss: 159.1798\n",
            "Epoch [28/50] - Batch loss: 150.5706 - Epoch Loss: 34055.8769 - Avg Loss: 159.1396\n",
            "Epoch [28/50] - Batch loss: 157.6402 - Epoch Loss: 34213.5171 - Avg Loss: 159.1326\n",
            "Epoch [28/50] - Batch loss: 160.1580 - Epoch Loss: 34373.6751 - Avg Loss: 159.1374\n",
            "Epoch [28/50] - Batch loss: 165.7975 - Epoch Loss: 34539.4726 - Avg Loss: 159.1681\n",
            "Epoch [28/50] - Batch loss: 151.0939 - Epoch Loss: 34690.5664 - Avg Loss: 159.1310\n",
            "Epoch [28/50] - Batch loss: 158.7315 - Epoch Loss: 34849.2979 - Avg Loss: 159.1292\n",
            "Epoch [28/50] - Batch loss: 164.1950 - Epoch Loss: 35013.4930 - Avg Loss: 159.1522\n",
            "Epoch [28/50] - Batch loss: 167.4747 - Epoch Loss: 35180.9676 - Avg Loss: 159.1899\n",
            "Epoch [28/50] - Batch loss: 161.5677 - Epoch Loss: 35342.5353 - Avg Loss: 159.2006\n",
            "Epoch [28/50] - Batch loss: 158.7928 - Epoch Loss: 35501.3280 - Avg Loss: 159.1988\n",
            "Epoch [28/50] - Batch loss: 163.5793 - Epoch Loss: 35664.9073 - Avg Loss: 159.2183\n",
            "Epoch [28/50] - Batch loss: 160.3283 - Epoch Loss: 35825.2356 - Avg Loss: 159.2233\n",
            "Epoch [28/50] - Batch loss: 152.6997 - Epoch Loss: 35977.9353 - Avg Loss: 159.1944\n",
            "Epoch [28/50] - Batch loss: 161.1087 - Epoch Loss: 36139.0440 - Avg Loss: 159.2028\n",
            "Epoch [28/50] - Batch loss: 154.4504 - Epoch Loss: 36293.4944 - Avg Loss: 159.1820\n",
            "Epoch [28/50] - Batch loss: 150.7809 - Epoch Loss: 36444.2754 - Avg Loss: 159.1453\n",
            "Epoch [28/50] - Batch loss: 157.3393 - Epoch Loss: 36601.6147 - Avg Loss: 159.1375\n",
            "Epoch [28/50] - Batch loss: 159.3654 - Epoch Loss: 36760.9800 - Avg Loss: 159.1384\n",
            "Epoch [28/50] - Batch loss: 150.1827 - Epoch Loss: 36911.1627 - Avg Loss: 159.0998\n",
            "Epoch [28/50] - Batch loss: 158.6926 - Epoch Loss: 37069.8553 - Avg Loss: 159.0981\n",
            "Epoch [28/50] - Batch loss: 161.4902 - Epoch Loss: 37231.3455 - Avg Loss: 159.1083\n",
            "Epoch [28/50] - Batch loss: 157.6162 - Epoch Loss: 37388.9617 - Avg Loss: 159.1020\n",
            "Epoch [28/50] - Batch loss: 154.4632 - Epoch Loss: 37543.4249 - Avg Loss: 159.0823\n",
            "Epoch [28/50] - Batch loss: 156.1525 - Epoch Loss: 37699.5774 - Avg Loss: 159.0699\n",
            "Epoch [28/50] - Batch loss: 154.2940 - Epoch Loss: 37853.8714 - Avg Loss: 159.0499\n",
            "Epoch [28/50] - Batch loss: 164.8844 - Epoch Loss: 38018.7558 - Avg Loss: 159.0743\n",
            "Epoch [28/50] - Batch loss: 154.0978 - Epoch Loss: 38172.8536 - Avg Loss: 159.0536\n",
            "Epoch [28/50] - Batch loss: 149.8582 - Epoch Loss: 38322.7118 - Avg Loss: 159.0154\n",
            "Epoch [28/50] - Batch loss: 160.4962 - Epoch Loss: 38483.2080 - Avg Loss: 159.0215\n",
            "Epoch [28/50] - Batch loss: 159.9788 - Epoch Loss: 38643.1868 - Avg Loss: 159.0255\n",
            "Epoch [28/50] - Batch loss: 159.9185 - Epoch Loss: 38803.1053 - Avg Loss: 159.0291\n",
            "Epoch [28/50] - Batch loss: 158.3015 - Epoch Loss: 38961.4069 - Avg Loss: 159.0262\n",
            "Epoch [28/50] - Batch loss: 154.9808 - Epoch Loss: 39116.3877 - Avg Loss: 159.0097\n",
            "Epoch [28/50] - Batch loss: 165.9706 - Epoch Loss: 39282.3583 - Avg Loss: 159.0379\n",
            "Epoch [28/50] - Batch loss: 152.7352 - Epoch Loss: 39435.0935 - Avg Loss: 159.0125\n",
            "Epoch [28/50] - Batch loss: 158.1650 - Epoch Loss: 39593.2585 - Avg Loss: 159.0091\n",
            "Epoch [28/50] - Batch loss: 153.6581 - Epoch Loss: 39746.9166 - Avg Loss: 158.9877\n",
            "Epoch [28/50] - Batch loss: 159.7432 - Epoch Loss: 39906.6598 - Avg Loss: 158.9907\n",
            "Epoch [28/50] - Batch loss: 162.8151 - Epoch Loss: 40069.4749 - Avg Loss: 159.0059\n",
            "Epoch [28/50] - Batch loss: 165.4155 - Epoch Loss: 40234.8904 - Avg Loss: 159.0312\n",
            "Epoch [28/50] - Batch loss: 161.3218 - Epoch Loss: 40396.2122 - Avg Loss: 159.0402\n",
            "Epoch [28/50] - Batch loss: 156.9672 - Epoch Loss: 40553.1794 - Avg Loss: 159.0321\n",
            "Epoch [28/50] - Batch loss: 162.7350 - Epoch Loss: 40715.9144 - Avg Loss: 159.0465\n",
            "Epoch [28/50] - Batch loss: 159.5569 - Epoch Loss: 40875.4713 - Avg Loss: 159.0485\n",
            "Epoch [28/50] - Batch loss: 159.4677 - Epoch Loss: 41034.9390 - Avg Loss: 159.0502\n",
            "Epoch [28/50] - Batch loss: 159.9451 - Epoch Loss: 41194.8841 - Avg Loss: 159.0536\n",
            "Epoch [28/50] - Batch loss: 153.9234 - Epoch Loss: 41348.8075 - Avg Loss: 159.0339\n",
            "Epoch [28/50] - Batch loss: 152.2617 - Epoch Loss: 41501.0692 - Avg Loss: 159.0079\n",
            "Epoch [28/50] - Batch loss: 159.1532 - Epoch Loss: 41660.2223 - Avg Loss: 159.0085\n",
            "Epoch [28/50] - Batch loss: 155.7564 - Epoch Loss: 41815.9787 - Avg Loss: 158.9961\n",
            "Epoch [28/50] - Batch loss: 159.9072 - Epoch Loss: 41975.8859 - Avg Loss: 158.9996\n",
            "Epoch [28/50] - Batch loss: 161.9105 - Epoch Loss: 42137.7964 - Avg Loss: 159.0106\n",
            "Epoch [28/50] - Batch loss: 155.8433 - Epoch Loss: 42293.6397 - Avg Loss: 158.9986\n",
            "Epoch [28/50] - Batch loss: 157.5485 - Epoch Loss: 42451.1882 - Avg Loss: 158.9932\n",
            "Epoch [28/50] - Batch loss: 154.4146 - Epoch Loss: 42605.6028 - Avg Loss: 158.9761\n",
            "Epoch [28/50] - Batch loss: 149.2963 - Epoch Loss: 42754.8991 - Avg Loss: 158.9401\n",
            "Epoch [28/50] - Batch loss: 152.8392 - Epoch Loss: 42907.7383 - Avg Loss: 158.9175\n",
            "Epoch [28/50] - Batch loss: 156.1168 - Epoch Loss: 43063.8551 - Avg Loss: 158.9072\n",
            "Epoch [28/50] - Batch loss: 160.3569 - Epoch Loss: 43224.2120 - Avg Loss: 158.9125\n",
            "Epoch [28/50] - Batch loss: 162.6306 - Epoch Loss: 43386.8426 - Avg Loss: 158.9262\n",
            "Epoch [28/50] - Batch loss: 156.2448 - Epoch Loss: 43543.0875 - Avg Loss: 158.9164\n",
            "Epoch [28/50] - Batch loss: 158.1315 - Epoch Loss: 43701.2190 - Avg Loss: 158.9135\n",
            "Epoch [28/50] - Batch loss: 157.5229 - Epoch Loss: 43858.7418 - Avg Loss: 158.9085\n",
            "Epoch [28/50] - Batch loss: 157.3884 - Epoch Loss: 44016.1302 - Avg Loss: 158.9030\n",
            "Epoch [28/50] - Batch loss: 149.4875 - Epoch Loss: 44165.6177 - Avg Loss: 158.8691\n",
            "Epoch [28/50] - Batch loss: 164.3495 - Epoch Loss: 44329.9671 - Avg Loss: 158.8888\n",
            "Epoch [28/50] - Batch loss: 157.9653 - Epoch Loss: 44487.9324 - Avg Loss: 158.8855\n",
            "Epoch [28/50] - Batch loss: 162.8595 - Epoch Loss: 44650.7919 - Avg Loss: 158.8996\n",
            "Epoch [28/50] - Batch loss: 159.0706 - Epoch Loss: 44809.8625 - Avg Loss: 158.9002\n",
            "Epoch [28/50] - Batch loss: 153.7973 - Epoch Loss: 44963.6598 - Avg Loss: 158.8822\n",
            "Epoch [28/50] - Batch loss: 158.0599 - Epoch Loss: 45121.7198 - Avg Loss: 158.8793\n",
            "Epoch [28/50] - Batch loss: 160.0938 - Epoch Loss: 45281.8135 - Avg Loss: 158.8836\n",
            "Epoch [28/50] - Batch loss: 162.4374 - Epoch Loss: 45444.2509 - Avg Loss: 158.8960\n",
            "Epoch [28/50] - Batch loss: 156.5416 - Epoch Loss: 45600.7925 - Avg Loss: 158.8878\n",
            "Epoch [28/50] - Batch loss: 161.9469 - Epoch Loss: 45762.7394 - Avg Loss: 158.8984\n",
            "Epoch [28/50] - Batch loss: 159.8045 - Epoch Loss: 45922.5439 - Avg Loss: 158.9015\n",
            "Epoch [28/50] - Batch loss: 161.2613 - Epoch Loss: 46083.8052 - Avg Loss: 158.9097\n",
            "Epoch [28/50] - Batch loss: 159.5590 - Epoch Loss: 46243.3642 - Avg Loss: 158.9119\n",
            "Epoch [28/50] - Batch loss: 153.2308 - Epoch Loss: 46396.5950 - Avg Loss: 158.8924\n",
            "Epoch [28/50] - Batch loss: 161.8845 - Epoch Loss: 46558.4794 - Avg Loss: 158.9027\n",
            "Epoch [28/50] - Batch loss: 165.9458 - Epoch Loss: 46724.4252 - Avg Loss: 158.9266\n",
            "Epoch [28/50] - Batch loss: 156.8769 - Epoch Loss: 46881.3021 - Avg Loss: 158.9197\n",
            "Epoch [28/50] - Batch loss: 158.3685 - Epoch Loss: 47039.6706 - Avg Loss: 158.9178\n",
            "Epoch [28/50] - Batch loss: 152.0618 - Epoch Loss: 47191.7323 - Avg Loss: 158.8947\n",
            "Epoch [28/50] - Batch loss: 152.9344 - Epoch Loss: 47344.6667 - Avg Loss: 158.8747\n",
            "Epoch [28/50] - Batch loss: 163.3151 - Epoch Loss: 47507.9818 - Avg Loss: 158.8896\n",
            "Epoch [28/50] - Batch loss: 161.2601 - Epoch Loss: 47669.2419 - Avg Loss: 158.8975\n",
            "Epoch [28/50] - Batch loss: 157.7423 - Epoch Loss: 47826.9842 - Avg Loss: 158.8936\n",
            "Epoch [28/50] - Batch loss: 163.1652 - Epoch Loss: 47990.1494 - Avg Loss: 158.9078\n",
            "Epoch [28/50] - Batch loss: 158.8646 - Epoch Loss: 48149.0140 - Avg Loss: 158.9076\n",
            "Epoch [28/50] - Batch loss: 162.9205 - Epoch Loss: 48311.9346 - Avg Loss: 158.9208\n",
            "Epoch [28/50] - Batch loss: 154.1009 - Epoch Loss: 48466.0354 - Avg Loss: 158.9050\n",
            "Epoch [28/50] - Batch loss: 157.5497 - Epoch Loss: 48623.5851 - Avg Loss: 158.9006\n",
            "Epoch [28/50] - Batch loss: 154.0062 - Epoch Loss: 48777.5913 - Avg Loss: 158.8847\n",
            "Epoch [28/50] - Batch loss: 163.7870 - Epoch Loss: 48941.3783 - Avg Loss: 158.9006\n",
            "Epoch [28/50] - Batch loss: 160.2668 - Epoch Loss: 49101.6451 - Avg Loss: 158.9050\n",
            "Epoch [28/50] - Batch loss: 159.3666 - Epoch Loss: 49261.0117 - Avg Loss: 158.9065\n",
            "Epoch [28/50] - Batch loss: 160.2709 - Epoch Loss: 49421.2827 - Avg Loss: 158.9109\n",
            "Epoch [28/50] - Batch loss: 151.7669 - Epoch Loss: 49573.0496 - Avg Loss: 158.8880\n",
            "Epoch [28/50] - Batch loss: 158.1062 - Epoch Loss: 49731.1558 - Avg Loss: 158.8855\n",
            "Epoch [28/50] - Batch loss: 161.8556 - Epoch Loss: 49893.0114 - Avg Loss: 158.8949\n",
            "Epoch [28/50] - Batch loss: 154.9939 - Epoch Loss: 50048.0053 - Avg Loss: 158.8826\n",
            "Epoch [28/50] - Batch loss: 170.1646 - Epoch Loss: 50218.1699 - Avg Loss: 158.9183\n",
            "Epoch [28/50] - Batch loss: 153.4101 - Epoch Loss: 50371.5800 - Avg Loss: 158.9009\n",
            "Epoch [28/50] - Batch loss: 157.5387 - Epoch Loss: 50529.1187 - Avg Loss: 158.8966\n",
            "Epoch [28/50] - Batch loss: 148.1745 - Epoch Loss: 50677.2932 - Avg Loss: 158.8630\n",
            "Epoch [28/50] - Batch loss: 158.2112 - Epoch Loss: 50835.5044 - Avg Loss: 158.8610\n",
            "Epoch [28/50] - Batch loss: 158.6350 - Epoch Loss: 50994.1394 - Avg Loss: 158.8602\n",
            "Epoch [28/50] - Batch loss: 161.8990 - Epoch Loss: 51156.0384 - Avg Loss: 158.8697\n",
            "Epoch [28/50] - Batch loss: 154.9555 - Epoch Loss: 51310.9939 - Avg Loss: 158.8576\n",
            "Epoch [28/50] - Batch loss: 154.7155 - Epoch Loss: 51465.7094 - Avg Loss: 158.8448\n",
            "Epoch [28/50] - Batch loss: 157.7675 - Epoch Loss: 51623.4769 - Avg Loss: 158.8415\n",
            "Epoch [28/50] - Batch loss: 161.2171 - Epoch Loss: 51784.6940 - Avg Loss: 158.8488\n",
            "Epoch [28/50] - Batch loss: 155.0633 - Epoch Loss: 51939.7573 - Avg Loss: 158.8372\n",
            "Epoch [28/50] - Batch loss: 156.8480 - Epoch Loss: 52096.6054 - Avg Loss: 158.8311\n",
            "Epoch [28/50] - Batch loss: 158.4307 - Epoch Loss: 52255.0361 - Avg Loss: 158.8299\n",
            "Epoch [28/50] - Batch loss: 159.7498 - Epoch Loss: 52414.7858 - Avg Loss: 158.8327\n",
            "Epoch [28/50] - Batch loss: 155.5295 - Epoch Loss: 52570.3153 - Avg Loss: 158.8227\n",
            "Epoch [28/50] - Batch loss: 163.8131 - Epoch Loss: 52734.1284 - Avg Loss: 158.8377\n",
            "Epoch [28/50] - Batch loss: 154.8631 - Epoch Loss: 52888.9915 - Avg Loss: 158.8258\n",
            "Epoch [28/50] - Batch loss: 163.0178 - Epoch Loss: 53052.0093 - Avg Loss: 158.8384\n",
            "Epoch [28/50] - Batch loss: 167.0766 - Epoch Loss: 53219.0859 - Avg Loss: 158.8629\n",
            "Epoch [28/50] - Batch loss: 160.7747 - Epoch Loss: 53379.8606 - Avg Loss: 158.8686\n",
            "Epoch [28/50] - Batch loss: 164.1315 - Epoch Loss: 53543.9921 - Avg Loss: 158.8842\n",
            "Epoch [28/50] - Batch loss: 160.2588 - Epoch Loss: 53704.2509 - Avg Loss: 158.8883\n",
            "Epoch [28/50] - Batch loss: 159.5815 - Epoch Loss: 53863.8323 - Avg Loss: 158.8904\n",
            "Epoch [28/50] - Batch loss: 157.1203 - Epoch Loss: 54020.9527 - Avg Loss: 158.8852\n",
            "Epoch [28/50] - Batch loss: 158.7149 - Epoch Loss: 54179.6676 - Avg Loss: 158.8847\n",
            "Epoch [28/50] - Batch loss: 158.0136 - Epoch Loss: 54337.6812 - Avg Loss: 158.8821\n",
            "Epoch [28/50] - Batch loss: 156.6174 - Epoch Loss: 54494.2985 - Avg Loss: 158.8755\n",
            "Epoch [28/50] - Batch loss: 154.3833 - Epoch Loss: 54648.6819 - Avg Loss: 158.8624\n",
            "Epoch [28/50] - Batch loss: 154.5028 - Epoch Loss: 54803.1846 - Avg Loss: 158.8498\n",
            "Epoch [28/50] - Batch loss: 161.5177 - Epoch Loss: 54964.7024 - Avg Loss: 158.8575\n",
            "Epoch [28/50] - Batch loss: 165.7023 - Epoch Loss: 55130.4047 - Avg Loss: 158.8772\n",
            "Epoch [28/50] - Batch loss: 155.8259 - Epoch Loss: 55286.2305 - Avg Loss: 158.8685\n",
            "Epoch [28/50] - Batch loss: 159.8479 - Epoch Loss: 55446.0784 - Avg Loss: 158.8713\n",
            "Epoch [28/50] - Batch loss: 156.8484 - Epoch Loss: 55602.9268 - Avg Loss: 158.8655\n",
            "Epoch [28/50] - Batch loss: 155.3292 - Epoch Loss: 55758.2561 - Avg Loss: 158.8554\n",
            "Epoch [28/50] - Batch loss: 158.5016 - Epoch Loss: 55916.7576 - Avg Loss: 158.8544\n",
            "Epoch [28/50] - Batch loss: 158.2108 - Epoch Loss: 56074.9685 - Avg Loss: 158.8526\n",
            "Epoch [28/50] - Batch loss: 157.5262 - Epoch Loss: 56232.4947 - Avg Loss: 158.8489\n",
            "Epoch [28/50] - Batch loss: 159.5518 - Epoch Loss: 56392.0465 - Avg Loss: 158.8508\n",
            "Epoch [28/50] - Batch loss: 157.2762 - Epoch Loss: 56549.3226 - Avg Loss: 158.8464\n",
            "Epoch [28/50] - Batch loss: 161.8280 - Epoch Loss: 56711.1507 - Avg Loss: 158.8548\n",
            "Epoch [28/50] - Batch loss: 160.6332 - Epoch Loss: 56871.7838 - Avg Loss: 158.8597\n",
            "Epoch [28/50] - Batch loss: 152.7754 - Epoch Loss: 57024.5592 - Avg Loss: 158.8428\n",
            "Epoch [28/50] - Batch loss: 161.7755 - Epoch Loss: 57186.3347 - Avg Loss: 158.8509\n",
            "Epoch [28/50] - Batch loss: 163.4535 - Epoch Loss: 57349.7882 - Avg Loss: 158.8637\n",
            "Epoch [28/50] - Batch loss: 153.9939 - Epoch Loss: 57503.7821 - Avg Loss: 158.8502\n",
            "Epoch [28/50] - Batch loss: 157.5118 - Epoch Loss: 57661.2938 - Avg Loss: 158.8465\n",
            "Epoch [28/50] - Batch loss: 168.0330 - Epoch Loss: 57829.3268 - Avg Loss: 158.8718\n",
            "Epoch [28/50] - Batch loss: 159.8893 - Epoch Loss: 57989.2161 - Avg Loss: 158.8746\n",
            "Epoch [28/50] - Batch loss: 154.0860 - Epoch Loss: 58143.3021 - Avg Loss: 158.8615\n",
            "Epoch [28/50] - Batch loss: 155.4131 - Epoch Loss: 58298.7152 - Avg Loss: 158.8521\n",
            "Epoch [28/50] - Batch loss: 156.4511 - Epoch Loss: 58455.1663 - Avg Loss: 158.8456\n",
            "Epoch [28/50] - Batch loss: 165.6223 - Epoch Loss: 58620.7886 - Avg Loss: 158.8639\n",
            "Epoch [28/50] - Batch loss: 160.9658 - Epoch Loss: 58781.7544 - Avg Loss: 158.8696\n",
            "Epoch [28/50] - Batch loss: 166.5476 - Epoch Loss: 58948.3020 - Avg Loss: 158.8903\n",
            "Epoch [28/50] - Batch loss: 155.3531 - Epoch Loss: 59103.6551 - Avg Loss: 158.8808\n",
            "Epoch [28/50] - Batch loss: 156.4489 - Epoch Loss: 59260.1040 - Avg Loss: 158.8743\n",
            "Epoch [28/50] - Batch loss: 157.0176 - Epoch Loss: 59417.1216 - Avg Loss: 158.8693\n",
            "Epoch [28/50] - Batch loss: 154.0075 - Epoch Loss: 59571.1291 - Avg Loss: 158.8563\n",
            "Epoch [28/50] - Batch loss: 154.0970 - Epoch Loss: 59725.2261 - Avg Loss: 158.8437\n",
            "Epoch [28/50] - Batch loss: 163.9156 - Epoch Loss: 59889.1418 - Avg Loss: 158.8571\n",
            "Epoch [28/50] - Batch loss: 159.2826 - Epoch Loss: 60048.4243 - Avg Loss: 158.8583\n",
            "Epoch [28/50] - Batch loss: 155.1494 - Epoch Loss: 60203.5737 - Avg Loss: 158.8485\n",
            "Epoch [28/50] - Batch loss: 154.6472 - Epoch Loss: 60358.2209 - Avg Loss: 158.8374\n",
            "Epoch [28/50] - Batch loss: 155.2757 - Epoch Loss: 60513.4966 - Avg Loss: 158.8281\n",
            "Epoch [28/50] - Batch loss: 159.1429 - Epoch Loss: 60672.6394 - Avg Loss: 158.8289\n",
            "Epoch [28/50] - Batch loss: 159.1175 - Epoch Loss: 60831.7569 - Avg Loss: 158.8297\n",
            "Epoch [28/50] - Batch loss: 156.7410 - Epoch Loss: 60988.4979 - Avg Loss: 158.8242\n",
            "Epoch [28/50] - Batch loss: 153.9875 - Epoch Loss: 61142.4855 - Avg Loss: 158.8117\n",
            "Epoch [28/50] - Batch loss: 150.1260 - Epoch Loss: 61292.6115 - Avg Loss: 158.7891\n",
            "Epoch [28/50] - Batch loss: 170.4906 - Epoch Loss: 61463.1021 - Avg Loss: 158.8194\n",
            "Epoch [28/50] - Batch loss: 159.0126 - Epoch Loss: 61622.1147 - Avg Loss: 158.8199\n",
            "Epoch [28/50] - Batch loss: 155.4569 - Epoch Loss: 61777.5716 - Avg Loss: 158.8112\n",
            "Epoch [28/50] - Batch loss: 160.0005 - Epoch Loss: 61937.5720 - Avg Loss: 158.8143\n",
            "Epoch [28/50] - Batch loss: 153.2683 - Epoch Loss: 62090.8403 - Avg Loss: 158.8001\n",
            "Epoch [28/50] - Batch loss: 164.0295 - Epoch Loss: 62254.8699 - Avg Loss: 158.8134\n",
            "Epoch [28/50] - Batch loss: 157.1066 - Epoch Loss: 62411.9764 - Avg Loss: 158.8091\n",
            "Epoch [28/50] - Batch loss: 155.4849 - Epoch Loss: 62567.4613 - Avg Loss: 158.8007\n",
            "Epoch [28/50] - Batch loss: 170.0777 - Epoch Loss: 62737.5390 - Avg Loss: 158.8292\n",
            "Epoch [28/50] - Batch loss: 157.4971 - Epoch Loss: 62895.0361 - Avg Loss: 158.8258\n",
            "Epoch [28/50] - Batch loss: 155.7492 - Epoch Loss: 63050.7853 - Avg Loss: 158.8181\n",
            "Epoch [28/50] - Batch loss: 164.6219 - Epoch Loss: 63215.4073 - Avg Loss: 158.8327\n",
            "Epoch [28/50] - Batch loss: 168.4465 - Epoch Loss: 63383.8538 - Avg Loss: 158.8568\n",
            "Epoch [28/50] - Batch loss: 160.5489 - Epoch Loss: 63544.4027 - Avg Loss: 158.8610\n",
            "Epoch [28/50] - Batch loss: 159.3956 - Epoch Loss: 63703.7983 - Avg Loss: 158.8623\n",
            "Epoch [28/50] - Batch loss: 160.6225 - Epoch Loss: 63864.4208 - Avg Loss: 158.8667\n",
            "Epoch [28/50] - Batch loss: 162.6783 - Epoch Loss: 64027.0992 - Avg Loss: 158.8762\n",
            "Epoch [28/50] - Batch loss: 158.6873 - Epoch Loss: 64185.7865 - Avg Loss: 158.8757\n",
            "Epoch [28/50] - Batch loss: 155.7686 - Epoch Loss: 64341.5551 - Avg Loss: 158.8680\n",
            "Epoch [28/50] - Batch loss: 151.9365 - Epoch Loss: 64493.4915 - Avg Loss: 158.8510\n",
            "Epoch [28/50] - Batch loss: 155.7984 - Epoch Loss: 64649.2900 - Avg Loss: 158.8435\n",
            "Epoch [28/50] - Batch loss: 165.4001 - Epoch Loss: 64814.6901 - Avg Loss: 158.8595\n",
            "Epoch [28/50] - Batch loss: 163.7671 - Epoch Loss: 64978.4571 - Avg Loss: 158.8715\n",
            "Epoch [28/50] - Batch loss: 160.5292 - Epoch Loss: 65138.9863 - Avg Loss: 158.8756\n",
            "Epoch [28/50] - Batch loss: 157.9473 - Epoch Loss: 65296.9336 - Avg Loss: 158.8733\n",
            "Epoch [28/50] - Batch loss: 162.7674 - Epoch Loss: 65459.7011 - Avg Loss: 158.8828\n",
            "Epoch [28/50] - Batch loss: 161.8308 - Epoch Loss: 65621.5319 - Avg Loss: 158.8899\n",
            "Epoch [28/50] - Batch loss: 156.9713 - Epoch Loss: 65778.5031 - Avg Loss: 158.8853\n",
            "Epoch [28/50] - Batch loss: 164.5707 - Epoch Loss: 65943.0738 - Avg Loss: 158.8990\n",
            "Epoch [28/50] - Batch loss: 155.4192 - Epoch Loss: 66098.4930 - Avg Loss: 158.8906\n",
            "Epoch [28/50] - Batch loss: 157.7375 - Epoch Loss: 66256.2304 - Avg Loss: 158.8878\n",
            "Epoch [28/50] - Batch loss: 157.9078 - Epoch Loss: 66414.1382 - Avg Loss: 158.8855\n",
            "Epoch [28/50] - Batch loss: 159.9975 - Epoch Loss: 66574.1358 - Avg Loss: 158.8882\n",
            "Epoch [28/50] - Batch loss: 169.2962 - Epoch Loss: 66743.4320 - Avg Loss: 158.9129\n",
            "Epoch [28/50] - Batch loss: 157.6411 - Epoch Loss: 66901.0731 - Avg Loss: 158.9099\n",
            "Epoch [28/50] - Batch loss: 161.4423 - Epoch Loss: 67062.5154 - Avg Loss: 158.9159\n",
            "Epoch [28/50] - Batch loss: 159.1291 - Epoch Loss: 67221.6445 - Avg Loss: 158.9164\n",
            "Epoch [28/50] - Batch loss: 157.8045 - Epoch Loss: 67379.4490 - Avg Loss: 158.9138\n",
            "Epoch [28/50] - Batch loss: 168.6041 - Epoch Loss: 67548.0530 - Avg Loss: 158.9366\n",
            "Epoch [28/50] - Batch loss: 159.9145 - Epoch Loss: 67707.9675 - Avg Loss: 158.9389\n",
            "Epoch [28/50] - Batch loss: 164.6019 - Epoch Loss: 67872.5694 - Avg Loss: 158.9522\n",
            "Epoch [28/50] - Batch loss: 158.0836 - Epoch Loss: 68030.6531 - Avg Loss: 158.9501\n",
            "Epoch [28/50] - Batch loss: 156.3892 - Epoch Loss: 68187.0423 - Avg Loss: 158.9442\n",
            "Epoch [28/50] - Batch loss: 159.9755 - Epoch Loss: 68347.0178 - Avg Loss: 158.9466\n",
            "Epoch [28/50] - Batch loss: 158.9313 - Epoch Loss: 68505.9491 - Avg Loss: 158.9465\n",
            "Epoch [28/50] - Batch loss: 157.3340 - Epoch Loss: 68663.2831 - Avg Loss: 158.9428\n",
            "Epoch [28/50] - Batch loss: 151.2924 - Epoch Loss: 68814.5755 - Avg Loss: 158.9251\n",
            "Epoch [28/50] - Batch loss: 168.5533 - Epoch Loss: 68983.1288 - Avg Loss: 158.9473\n",
            "Epoch [28/50] - Batch loss: 163.5447 - Epoch Loss: 69146.6735 - Avg Loss: 158.9579\n",
            "Epoch [28/50] - Batch loss: 167.2413 - Epoch Loss: 69313.9148 - Avg Loss: 158.9769\n",
            "Epoch [28/50] - Batch loss: 165.9222 - Epoch Loss: 69479.8370 - Avg Loss: 158.9928\n",
            "Epoch [28/50] - Batch loss: 165.0399 - Epoch Loss: 69644.8768 - Avg Loss: 159.0066\n",
            "Epoch [28/50] - Batch loss: 165.7741 - Epoch Loss: 69810.6509 - Avg Loss: 159.0220\n",
            "Epoch [28/50] - Batch loss: 162.6840 - Epoch Loss: 69973.3349 - Avg Loss: 159.0303\n",
            "Epoch [28/50] - Batch loss: 163.2711 - Epoch Loss: 70136.6060 - Avg Loss: 159.0399\n",
            "Epoch [28/50] - Batch loss: 162.9150 - Epoch Loss: 70299.5211 - Avg Loss: 159.0487\n",
            "Epoch [28/50] - Batch loss: 161.1569 - Epoch Loss: 70460.6779 - Avg Loss: 159.0534\n",
            "Epoch [28/50] - Batch loss: 160.7947 - Epoch Loss: 70621.4727 - Avg Loss: 159.0574\n",
            "Epoch [28/50] - Batch loss: 161.8516 - Epoch Loss: 70783.3243 - Avg Loss: 159.0637\n",
            "Epoch [28/50] - Batch loss: 156.2185 - Epoch Loss: 70939.5427 - Avg Loss: 159.0573\n",
            "Epoch [28/50] - Batch loss: 156.5170 - Epoch Loss: 71096.0598 - Avg Loss: 159.0516\n",
            "Epoch [28/50] - Batch loss: 159.7689 - Epoch Loss: 71255.8287 - Avg Loss: 159.0532\n",
            "Epoch [28/50] - Batch loss: 164.0081 - Epoch Loss: 71419.8367 - Avg Loss: 159.0642\n",
            "Epoch [28/50] - Batch loss: 154.9354 - Epoch Loss: 71574.7722 - Avg Loss: 159.0550\n",
            "Epoch [28/50] - Batch loss: 155.7004 - Epoch Loss: 71730.4726 - Avg Loss: 159.0476\n",
            "Epoch [28/50] - Batch loss: 163.2258 - Epoch Loss: 71893.6984 - Avg Loss: 159.0569\n",
            "Epoch [28/50] - Batch loss: 154.0809 - Epoch Loss: 72047.7793 - Avg Loss: 159.0459\n",
            "Epoch [28/50] - Batch loss: 158.3916 - Epoch Loss: 72206.1710 - Avg Loss: 159.0444\n",
            "Epoch [28/50] - Batch loss: 156.7633 - Epoch Loss: 72362.9343 - Avg Loss: 159.0394\n",
            "Epoch [28/50] - Batch loss: 161.2065 - Epoch Loss: 72524.1408 - Avg Loss: 159.0442\n",
            "Epoch [28/50] - Batch loss: 160.9333 - Epoch Loss: 72685.0741 - Avg Loss: 159.0483\n",
            "Epoch [28/50] - Batch loss: 162.1672 - Epoch Loss: 72847.2412 - Avg Loss: 159.0551\n",
            "Epoch [28/50] - Batch loss: 154.9349 - Epoch Loss: 73002.1762 - Avg Loss: 159.0461\n",
            "Epoch [28/50] - Batch loss: 153.3961 - Epoch Loss: 73155.5723 - Avg Loss: 159.0339\n",
            "Epoch [28/50] - Batch loss: 167.6409 - Epoch Loss: 73323.2132 - Avg Loss: 159.0525\n",
            "Epoch [28/50] - Batch loss: 154.7363 - Epoch Loss: 73477.9495 - Avg Loss: 159.0432\n",
            "Epoch [28/50] - Batch loss: 166.0941 - Epoch Loss: 73644.0435 - Avg Loss: 159.0584\n",
            "Epoch [28/50] - Batch loss: 158.6167 - Epoch Loss: 73802.6602 - Avg Loss: 159.0575\n",
            "Epoch [28/50] - Batch loss: 144.6574 - Epoch Loss: 73947.3176 - Avg Loss: 159.0265\n",
            "Epoch [28/50] - Batch loss: 160.7243 - Epoch Loss: 74108.0419 - Avg Loss: 159.0301\n",
            "Epoch [28/50] - Batch loss: 164.4800 - Epoch Loss: 74272.5218 - Avg Loss: 159.0418\n",
            "Epoch [28/50] - Batch loss: 161.0822 - Epoch Loss: 74433.6040 - Avg Loss: 159.0462\n",
            "Epoch [28/50] - Batch loss: 160.8168 - Epoch Loss: 74594.4208 - Avg Loss: 159.0499\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 29/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "543c285d04574e808258b892f977c923"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [29/50] - Batch loss: 155.4335 - Epoch Loss: 155.4335 - Avg Loss: 155.4335\n",
            "Epoch [29/50] - Batch loss: 157.2507 - Epoch Loss: 312.6842 - Avg Loss: 156.3421\n",
            "Epoch [29/50] - Batch loss: 169.6927 - Epoch Loss: 482.3769 - Avg Loss: 160.7923\n",
            "Epoch [29/50] - Batch loss: 154.7130 - Epoch Loss: 637.0899 - Avg Loss: 159.2725\n",
            "Epoch [29/50] - Batch loss: 163.3383 - Epoch Loss: 800.4283 - Avg Loss: 160.0857\n",
            "Epoch [29/50] - Batch loss: 159.3115 - Epoch Loss: 959.7398 - Avg Loss: 159.9566\n",
            "Epoch [29/50] - Batch loss: 161.6375 - Epoch Loss: 1121.3772 - Avg Loss: 160.1967\n",
            "Epoch [29/50] - Batch loss: 155.4454 - Epoch Loss: 1276.8226 - Avg Loss: 159.6028\n",
            "Epoch [29/50] - Batch loss: 149.9540 - Epoch Loss: 1426.7766 - Avg Loss: 158.5307\n",
            "Epoch [29/50] - Batch loss: 149.0484 - Epoch Loss: 1575.8250 - Avg Loss: 157.5825\n",
            "Epoch [29/50] - Batch loss: 156.2021 - Epoch Loss: 1732.0271 - Avg Loss: 157.4570\n",
            "Epoch [29/50] - Batch loss: 155.3011 - Epoch Loss: 1887.3283 - Avg Loss: 157.2774\n",
            "Epoch [29/50] - Batch loss: 153.6257 - Epoch Loss: 2040.9540 - Avg Loss: 156.9965\n",
            "Epoch [29/50] - Batch loss: 165.1890 - Epoch Loss: 2206.1430 - Avg Loss: 157.5816\n",
            "Epoch [29/50] - Batch loss: 157.2204 - Epoch Loss: 2363.3634 - Avg Loss: 157.5576\n",
            "Epoch [29/50] - Batch loss: 163.2290 - Epoch Loss: 2526.5924 - Avg Loss: 157.9120\n",
            "Epoch [29/50] - Batch loss: 158.0261 - Epoch Loss: 2684.6184 - Avg Loss: 157.9187\n",
            "Epoch [29/50] - Batch loss: 162.6431 - Epoch Loss: 2847.2616 - Avg Loss: 158.1812\n",
            "Epoch [29/50] - Batch loss: 158.7529 - Epoch Loss: 3006.0145 - Avg Loss: 158.2113\n",
            "Epoch [29/50] - Batch loss: 156.6785 - Epoch Loss: 3162.6930 - Avg Loss: 158.1347\n",
            "Epoch [29/50] - Batch loss: 147.7648 - Epoch Loss: 3310.4578 - Avg Loss: 157.6408\n",
            "Epoch [29/50] - Batch loss: 160.9384 - Epoch Loss: 3471.3962 - Avg Loss: 157.7907\n",
            "Epoch [29/50] - Batch loss: 154.9923 - Epoch Loss: 3626.3885 - Avg Loss: 157.6691\n",
            "Epoch [29/50] - Batch loss: 156.3856 - Epoch Loss: 3782.7742 - Avg Loss: 157.6156\n",
            "Epoch [29/50] - Batch loss: 158.5469 - Epoch Loss: 3941.3211 - Avg Loss: 157.6528\n",
            "Epoch [29/50] - Batch loss: 156.0996 - Epoch Loss: 4097.4207 - Avg Loss: 157.5931\n",
            "Epoch [29/50] - Batch loss: 156.3657 - Epoch Loss: 4253.7864 - Avg Loss: 157.5476\n",
            "Epoch [29/50] - Batch loss: 157.5425 - Epoch Loss: 4411.3289 - Avg Loss: 157.5475\n",
            "Epoch [29/50] - Batch loss: 159.2823 - Epoch Loss: 4570.6113 - Avg Loss: 157.6073\n",
            "Epoch [29/50] - Batch loss: 160.3473 - Epoch Loss: 4730.9586 - Avg Loss: 157.6986\n",
            "Epoch [29/50] - Batch loss: 163.2195 - Epoch Loss: 4894.1781 - Avg Loss: 157.8767\n",
            "Epoch [29/50] - Batch loss: 153.8837 - Epoch Loss: 5048.0617 - Avg Loss: 157.7519\n",
            "Epoch [29/50] - Batch loss: 159.2752 - Epoch Loss: 5207.3369 - Avg Loss: 157.7981\n",
            "Epoch [29/50] - Batch loss: 165.2411 - Epoch Loss: 5372.5780 - Avg Loss: 158.0170\n",
            "Epoch [29/50] - Batch loss: 160.7542 - Epoch Loss: 5533.3322 - Avg Loss: 158.0952\n",
            "Epoch [29/50] - Batch loss: 167.2037 - Epoch Loss: 5700.5358 - Avg Loss: 158.3482\n",
            "Epoch [29/50] - Batch loss: 158.1149 - Epoch Loss: 5858.6507 - Avg Loss: 158.3419\n",
            "Epoch [29/50] - Batch loss: 155.7966 - Epoch Loss: 6014.4473 - Avg Loss: 158.2749\n",
            "Epoch [29/50] - Batch loss: 156.1107 - Epoch Loss: 6170.5579 - Avg Loss: 158.2194\n",
            "Epoch [29/50] - Batch loss: 149.8613 - Epoch Loss: 6320.4192 - Avg Loss: 158.0105\n",
            "Epoch [29/50] - Batch loss: 153.3118 - Epoch Loss: 6473.7310 - Avg Loss: 157.8959\n",
            "Epoch [29/50] - Batch loss: 158.7421 - Epoch Loss: 6632.4731 - Avg Loss: 157.9160\n",
            "Epoch [29/50] - Batch loss: 155.6433 - Epoch Loss: 6788.1164 - Avg Loss: 157.8632\n",
            "Epoch [29/50] - Batch loss: 152.1484 - Epoch Loss: 6940.2648 - Avg Loss: 157.7333\n",
            "Epoch [29/50] - Batch loss: 162.2205 - Epoch Loss: 7102.4852 - Avg Loss: 157.8330\n",
            "Epoch [29/50] - Batch loss: 159.5031 - Epoch Loss: 7261.9884 - Avg Loss: 157.8693\n",
            "Epoch [29/50] - Batch loss: 157.6632 - Epoch Loss: 7419.6516 - Avg Loss: 157.8649\n",
            "Epoch [29/50] - Batch loss: 154.7084 - Epoch Loss: 7574.3600 - Avg Loss: 157.7992\n",
            "Epoch [29/50] - Batch loss: 159.8179 - Epoch Loss: 7734.1779 - Avg Loss: 157.8404\n",
            "Epoch [29/50] - Batch loss: 163.7608 - Epoch Loss: 7897.9387 - Avg Loss: 157.9588\n",
            "Epoch [29/50] - Batch loss: 157.1670 - Epoch Loss: 8055.1056 - Avg Loss: 157.9432\n",
            "Epoch [29/50] - Batch loss: 155.3705 - Epoch Loss: 8210.4761 - Avg Loss: 157.8938\n",
            "Epoch [29/50] - Batch loss: 158.7534 - Epoch Loss: 8369.2295 - Avg Loss: 157.9100\n",
            "Epoch [29/50] - Batch loss: 157.9379 - Epoch Loss: 8527.1674 - Avg Loss: 157.9105\n",
            "Epoch [29/50] - Batch loss: 158.1077 - Epoch Loss: 8685.2751 - Avg Loss: 157.9141\n",
            "Epoch [29/50] - Batch loss: 157.1625 - Epoch Loss: 8842.4377 - Avg Loss: 157.9007\n",
            "Epoch [29/50] - Batch loss: 156.9682 - Epoch Loss: 8999.4059 - Avg Loss: 157.8843\n",
            "Epoch [29/50] - Batch loss: 156.0757 - Epoch Loss: 9155.4816 - Avg Loss: 157.8531\n",
            "Epoch [29/50] - Batch loss: 157.5024 - Epoch Loss: 9312.9840 - Avg Loss: 157.8472\n",
            "Epoch [29/50] - Batch loss: 163.1028 - Epoch Loss: 9476.0867 - Avg Loss: 157.9348\n",
            "Epoch [29/50] - Batch loss: 160.0138 - Epoch Loss: 9636.1006 - Avg Loss: 157.9689\n",
            "Epoch [29/50] - Batch loss: 152.6897 - Epoch Loss: 9788.7903 - Avg Loss: 157.8837\n",
            "Epoch [29/50] - Batch loss: 153.3011 - Epoch Loss: 9942.0913 - Avg Loss: 157.8110\n",
            "Epoch [29/50] - Batch loss: 152.1391 - Epoch Loss: 10094.2304 - Avg Loss: 157.7224\n",
            "Epoch [29/50] - Batch loss: 160.3679 - Epoch Loss: 10254.5983 - Avg Loss: 157.7631\n",
            "Epoch [29/50] - Batch loss: 158.8115 - Epoch Loss: 10413.4099 - Avg Loss: 157.7789\n",
            "Epoch [29/50] - Batch loss: 161.1773 - Epoch Loss: 10574.5872 - Avg Loss: 157.8297\n",
            "Epoch [29/50] - Batch loss: 157.4702 - Epoch Loss: 10732.0573 - Avg Loss: 157.8244\n",
            "Epoch [29/50] - Batch loss: 154.4014 - Epoch Loss: 10886.4587 - Avg Loss: 157.7748\n",
            "Epoch [29/50] - Batch loss: 162.5944 - Epoch Loss: 11049.0531 - Avg Loss: 157.8436\n",
            "Epoch [29/50] - Batch loss: 167.9416 - Epoch Loss: 11216.9947 - Avg Loss: 157.9858\n",
            "Epoch [29/50] - Batch loss: 156.4238 - Epoch Loss: 11373.4185 - Avg Loss: 157.9641\n",
            "Epoch [29/50] - Batch loss: 156.0312 - Epoch Loss: 11529.4498 - Avg Loss: 157.9377\n",
            "Epoch [29/50] - Batch loss: 163.1418 - Epoch Loss: 11692.5915 - Avg Loss: 158.0080\n",
            "Epoch [29/50] - Batch loss: 159.4718 - Epoch Loss: 11852.0634 - Avg Loss: 158.0275\n",
            "Epoch [29/50] - Batch loss: 156.7746 - Epoch Loss: 12008.8380 - Avg Loss: 158.0110\n",
            "Epoch [29/50] - Batch loss: 156.6706 - Epoch Loss: 12165.5086 - Avg Loss: 157.9936\n",
            "Epoch [29/50] - Batch loss: 154.5603 - Epoch Loss: 12320.0688 - Avg Loss: 157.9496\n",
            "Epoch [29/50] - Batch loss: 157.3341 - Epoch Loss: 12477.4029 - Avg Loss: 157.9418\n",
            "Epoch [29/50] - Batch loss: 153.7656 - Epoch Loss: 12631.1685 - Avg Loss: 157.8896\n",
            "Epoch [29/50] - Batch loss: 155.0295 - Epoch Loss: 12786.1981 - Avg Loss: 157.8543\n",
            "Epoch [29/50] - Batch loss: 165.8315 - Epoch Loss: 12952.0296 - Avg Loss: 157.9516\n",
            "Epoch [29/50] - Batch loss: 151.7238 - Epoch Loss: 13103.7533 - Avg Loss: 157.8765\n",
            "Epoch [29/50] - Batch loss: 161.0865 - Epoch Loss: 13264.8398 - Avg Loss: 157.9148\n",
            "Epoch [29/50] - Batch loss: 168.6961 - Epoch Loss: 13433.5359 - Avg Loss: 158.0416\n",
            "Epoch [29/50] - Batch loss: 162.2349 - Epoch Loss: 13595.7708 - Avg Loss: 158.0904\n",
            "Epoch [29/50] - Batch loss: 171.2312 - Epoch Loss: 13767.0020 - Avg Loss: 158.2414\n",
            "Epoch [29/50] - Batch loss: 168.7094 - Epoch Loss: 13935.7114 - Avg Loss: 158.3604\n",
            "Epoch [29/50] - Batch loss: 152.8308 - Epoch Loss: 14088.5422 - Avg Loss: 158.2982\n",
            "Epoch [29/50] - Batch loss: 165.5470 - Epoch Loss: 14254.0892 - Avg Loss: 158.3788\n",
            "Epoch [29/50] - Batch loss: 164.3922 - Epoch Loss: 14418.4815 - Avg Loss: 158.4449\n",
            "Epoch [29/50] - Batch loss: 159.8328 - Epoch Loss: 14578.3142 - Avg Loss: 158.4599\n",
            "Epoch [29/50] - Batch loss: 156.7384 - Epoch Loss: 14735.0526 - Avg Loss: 158.4414\n",
            "Epoch [29/50] - Batch loss: 163.7469 - Epoch Loss: 14898.7995 - Avg Loss: 158.4979\n",
            "Epoch [29/50] - Batch loss: 160.9534 - Epoch Loss: 15059.7529 - Avg Loss: 158.5237\n",
            "Epoch [29/50] - Batch loss: 173.1601 - Epoch Loss: 15232.9130 - Avg Loss: 158.6762\n",
            "Epoch [29/50] - Batch loss: 163.0143 - Epoch Loss: 15395.9273 - Avg Loss: 158.7209\n",
            "Epoch [29/50] - Batch loss: 168.4316 - Epoch Loss: 15564.3590 - Avg Loss: 158.8200\n",
            "Epoch [29/50] - Batch loss: 163.0269 - Epoch Loss: 15727.3858 - Avg Loss: 158.8625\n",
            "Epoch [29/50] - Batch loss: 164.0001 - Epoch Loss: 15891.3859 - Avg Loss: 158.9139\n",
            "Epoch [29/50] - Batch loss: 166.5542 - Epoch Loss: 16057.9401 - Avg Loss: 158.9895\n",
            "Epoch [29/50] - Batch loss: 157.3854 - Epoch Loss: 16215.3255 - Avg Loss: 158.9738\n",
            "Epoch [29/50] - Batch loss: 170.2219 - Epoch Loss: 16385.5473 - Avg Loss: 159.0830\n",
            "Epoch [29/50] - Batch loss: 159.9743 - Epoch Loss: 16545.5217 - Avg Loss: 159.0916\n",
            "Epoch [29/50] - Batch loss: 166.5440 - Epoch Loss: 16712.0657 - Avg Loss: 159.1625\n",
            "Epoch [29/50] - Batch loss: 171.1192 - Epoch Loss: 16883.1849 - Avg Loss: 159.2753\n",
            "Epoch [29/50] - Batch loss: 163.6462 - Epoch Loss: 17046.8311 - Avg Loss: 159.3162\n",
            "Epoch [29/50] - Batch loss: 165.5288 - Epoch Loss: 17212.3599 - Avg Loss: 159.3737\n",
            "Epoch [29/50] - Batch loss: 167.8540 - Epoch Loss: 17380.2139 - Avg Loss: 159.4515\n",
            "Epoch [29/50] - Batch loss: 167.5779 - Epoch Loss: 17547.7918 - Avg Loss: 159.5254\n",
            "Epoch [29/50] - Batch loss: 161.6368 - Epoch Loss: 17709.4286 - Avg Loss: 159.5444\n",
            "Epoch [29/50] - Batch loss: 165.1955 - Epoch Loss: 17874.6241 - Avg Loss: 159.5949\n",
            "Epoch [29/50] - Batch loss: 166.0661 - Epoch Loss: 18040.6903 - Avg Loss: 159.6521\n",
            "Epoch [29/50] - Batch loss: 168.9416 - Epoch Loss: 18209.6318 - Avg Loss: 159.7336\n",
            "Epoch [29/50] - Batch loss: 167.9262 - Epoch Loss: 18377.5580 - Avg Loss: 159.8049\n",
            "Epoch [29/50] - Batch loss: 164.4675 - Epoch Loss: 18542.0255 - Avg Loss: 159.8450\n",
            "Epoch [29/50] - Batch loss: 165.6584 - Epoch Loss: 18707.6839 - Avg Loss: 159.8947\n",
            "Epoch [29/50] - Batch loss: 168.6276 - Epoch Loss: 18876.3115 - Avg Loss: 159.9687\n",
            "Epoch [29/50] - Batch loss: 168.7516 - Epoch Loss: 19045.0631 - Avg Loss: 160.0425\n",
            "Epoch [29/50] - Batch loss: 167.2220 - Epoch Loss: 19212.2851 - Avg Loss: 160.1024\n",
            "Epoch [29/50] - Batch loss: 156.5596 - Epoch Loss: 19368.8447 - Avg Loss: 160.0731\n",
            "Epoch [29/50] - Batch loss: 167.0228 - Epoch Loss: 19535.8674 - Avg Loss: 160.1301\n",
            "Epoch [29/50] - Batch loss: 165.7283 - Epoch Loss: 19701.5957 - Avg Loss: 160.1756\n",
            "Epoch [29/50] - Batch loss: 162.7701 - Epoch Loss: 19864.3658 - Avg Loss: 160.1965\n",
            "Epoch [29/50] - Batch loss: 161.1929 - Epoch Loss: 20025.5586 - Avg Loss: 160.2045\n",
            "Epoch [29/50] - Batch loss: 170.6772 - Epoch Loss: 20196.2358 - Avg Loss: 160.2876\n",
            "Epoch [29/50] - Batch loss: 164.5791 - Epoch Loss: 20360.8148 - Avg Loss: 160.3214\n",
            "Epoch [29/50] - Batch loss: 165.3480 - Epoch Loss: 20526.1629 - Avg Loss: 160.3606\n",
            "Epoch [29/50] - Batch loss: 167.0593 - Epoch Loss: 20693.2222 - Avg Loss: 160.4126\n",
            "Epoch [29/50] - Batch loss: 165.9148 - Epoch Loss: 20859.1370 - Avg Loss: 160.4549\n",
            "Epoch [29/50] - Batch loss: 167.9933 - Epoch Loss: 21027.1302 - Avg Loss: 160.5124\n",
            "Epoch [29/50] - Batch loss: 173.2529 - Epoch Loss: 21200.3832 - Avg Loss: 160.6090\n",
            "Epoch [29/50] - Batch loss: 164.5883 - Epoch Loss: 21364.9715 - Avg Loss: 160.6389\n",
            "Epoch [29/50] - Batch loss: 165.6304 - Epoch Loss: 21530.6019 - Avg Loss: 160.6761\n",
            "Epoch [29/50] - Batch loss: 164.6060 - Epoch Loss: 21695.2079 - Avg Loss: 160.7052\n",
            "Epoch [29/50] - Batch loss: 163.8518 - Epoch Loss: 21859.0597 - Avg Loss: 160.7284\n",
            "Epoch [29/50] - Batch loss: 162.5949 - Epoch Loss: 22021.6546 - Avg Loss: 160.7420\n",
            "Epoch [29/50] - Batch loss: 166.9729 - Epoch Loss: 22188.6275 - Avg Loss: 160.7872\n",
            "Epoch [29/50] - Batch loss: 168.9600 - Epoch Loss: 22357.5875 - Avg Loss: 160.8460\n",
            "Epoch [29/50] - Batch loss: 175.8224 - Epoch Loss: 22533.4099 - Avg Loss: 160.9529\n",
            "Epoch [29/50] - Batch loss: 167.9949 - Epoch Loss: 22701.4048 - Avg Loss: 161.0029\n",
            "Epoch [29/50] - Batch loss: 167.6203 - Epoch Loss: 22869.0251 - Avg Loss: 161.0495\n",
            "Epoch [29/50] - Batch loss: 163.5298 - Epoch Loss: 23032.5549 - Avg Loss: 161.0668\n",
            "Epoch [29/50] - Batch loss: 165.8679 - Epoch Loss: 23198.4228 - Avg Loss: 161.1002\n",
            "Epoch [29/50] - Batch loss: 163.4129 - Epoch Loss: 23361.8357 - Avg Loss: 161.1161\n",
            "Epoch [29/50] - Batch loss: 171.4495 - Epoch Loss: 23533.2852 - Avg Loss: 161.1869\n",
            "Epoch [29/50] - Batch loss: 160.9396 - Epoch Loss: 23694.2248 - Avg Loss: 161.1852\n",
            "Epoch [29/50] - Batch loss: 164.4100 - Epoch Loss: 23858.6348 - Avg Loss: 161.2070\n",
            "Epoch [29/50] - Batch loss: 169.6400 - Epoch Loss: 24028.2747 - Avg Loss: 161.2636\n",
            "Epoch [29/50] - Batch loss: 170.7843 - Epoch Loss: 24199.0591 - Avg Loss: 161.3271\n",
            "Epoch [29/50] - Batch loss: 160.4397 - Epoch Loss: 24359.4987 - Avg Loss: 161.3212\n",
            "Epoch [29/50] - Batch loss: 170.0965 - Epoch Loss: 24529.5952 - Avg Loss: 161.3789\n",
            "Epoch [29/50] - Batch loss: 166.6711 - Epoch Loss: 24696.2663 - Avg Loss: 161.4135\n",
            "Epoch [29/50] - Batch loss: 164.7253 - Epoch Loss: 24860.9916 - Avg Loss: 161.4350\n",
            "Epoch [29/50] - Batch loss: 164.2292 - Epoch Loss: 25025.2209 - Avg Loss: 161.4530\n",
            "Epoch [29/50] - Batch loss: 156.0163 - Epoch Loss: 25181.2372 - Avg Loss: 161.4182\n",
            "Epoch [29/50] - Batch loss: 165.6236 - Epoch Loss: 25346.8607 - Avg Loss: 161.4450\n",
            "Epoch [29/50] - Batch loss: 166.3311 - Epoch Loss: 25513.1918 - Avg Loss: 161.4759\n",
            "Epoch [29/50] - Batch loss: 165.7717 - Epoch Loss: 25678.9635 - Avg Loss: 161.5029\n",
            "Epoch [29/50] - Batch loss: 158.4523 - Epoch Loss: 25837.4158 - Avg Loss: 161.4838\n",
            "Epoch [29/50] - Batch loss: 166.7692 - Epoch Loss: 26004.1850 - Avg Loss: 161.5167\n",
            "Epoch [29/50] - Batch loss: 161.9449 - Epoch Loss: 26166.1300 - Avg Loss: 161.5193\n",
            "Epoch [29/50] - Batch loss: 161.5551 - Epoch Loss: 26327.6851 - Avg Loss: 161.5195\n",
            "Epoch [29/50] - Batch loss: 164.7374 - Epoch Loss: 26492.4225 - Avg Loss: 161.5392\n",
            "Epoch [29/50] - Batch loss: 158.7971 - Epoch Loss: 26651.2197 - Avg Loss: 161.5225\n",
            "Epoch [29/50] - Batch loss: 161.0394 - Epoch Loss: 26812.2590 - Avg Loss: 161.5196\n",
            "Epoch [29/50] - Batch loss: 164.2475 - Epoch Loss: 26976.5065 - Avg Loss: 161.5360\n",
            "Epoch [29/50] - Batch loss: 161.8285 - Epoch Loss: 27138.3350 - Avg Loss: 161.5377\n",
            "Epoch [29/50] - Batch loss: 159.4420 - Epoch Loss: 27297.7770 - Avg Loss: 161.5253\n",
            "Epoch [29/50] - Batch loss: 161.3262 - Epoch Loss: 27459.1031 - Avg Loss: 161.5241\n",
            "Epoch [29/50] - Batch loss: 163.5015 - Epoch Loss: 27622.6046 - Avg Loss: 161.5357\n",
            "Epoch [29/50] - Batch loss: 168.1160 - Epoch Loss: 27790.7207 - Avg Loss: 161.5740\n",
            "Epoch [29/50] - Batch loss: 164.7926 - Epoch Loss: 27955.5133 - Avg Loss: 161.5926\n",
            "Epoch [29/50] - Batch loss: 170.9834 - Epoch Loss: 28126.4967 - Avg Loss: 161.6465\n",
            "Epoch [29/50] - Batch loss: 166.0144 - Epoch Loss: 28292.5111 - Avg Loss: 161.6715\n",
            "Epoch [29/50] - Batch loss: 169.3005 - Epoch Loss: 28461.8116 - Avg Loss: 161.7148\n",
            "Epoch [29/50] - Batch loss: 164.4397 - Epoch Loss: 28626.2514 - Avg Loss: 161.7302\n",
            "Epoch [29/50] - Batch loss: 154.9448 - Epoch Loss: 28781.1962 - Avg Loss: 161.6921\n",
            "Epoch [29/50] - Batch loss: 157.0722 - Epoch Loss: 28938.2684 - Avg Loss: 161.6663\n",
            "Epoch [29/50] - Batch loss: 166.0879 - Epoch Loss: 29104.3563 - Avg Loss: 161.6909\n",
            "Epoch [29/50] - Batch loss: 162.5071 - Epoch Loss: 29266.8634 - Avg Loss: 161.6954\n",
            "Epoch [29/50] - Batch loss: 166.2240 - Epoch Loss: 29433.0875 - Avg Loss: 161.7203\n",
            "Epoch [29/50] - Batch loss: 160.8122 - Epoch Loss: 29593.8997 - Avg Loss: 161.7153\n",
            "Epoch [29/50] - Batch loss: 160.9596 - Epoch Loss: 29754.8593 - Avg Loss: 161.7112\n",
            "Epoch [29/50] - Batch loss: 164.9975 - Epoch Loss: 29919.8568 - Avg Loss: 161.7290\n",
            "Epoch [29/50] - Batch loss: 161.4716 - Epoch Loss: 30081.3284 - Avg Loss: 161.7276\n",
            "Epoch [29/50] - Batch loss: 158.6855 - Epoch Loss: 30240.0139 - Avg Loss: 161.7113\n",
            "Epoch [29/50] - Batch loss: 158.4328 - Epoch Loss: 30398.4467 - Avg Loss: 161.6939\n",
            "Epoch [29/50] - Batch loss: 162.7613 - Epoch Loss: 30561.2080 - Avg Loss: 161.6995\n",
            "Epoch [29/50] - Batch loss: 163.4116 - Epoch Loss: 30724.6196 - Avg Loss: 161.7085\n",
            "Epoch [29/50] - Batch loss: 164.0460 - Epoch Loss: 30888.6656 - Avg Loss: 161.7208\n",
            "Epoch [29/50] - Batch loss: 166.8642 - Epoch Loss: 31055.5298 - Avg Loss: 161.7476\n",
            "Epoch [29/50] - Batch loss: 162.1759 - Epoch Loss: 31217.7057 - Avg Loss: 161.7498\n",
            "Epoch [29/50] - Batch loss: 155.2720 - Epoch Loss: 31372.9776 - Avg Loss: 161.7164\n",
            "Epoch [29/50] - Batch loss: 160.9962 - Epoch Loss: 31533.9738 - Avg Loss: 161.7127\n",
            "Epoch [29/50] - Batch loss: 161.1626 - Epoch Loss: 31695.1364 - Avg Loss: 161.7099\n",
            "Epoch [29/50] - Batch loss: 168.3243 - Epoch Loss: 31863.4607 - Avg Loss: 161.7435\n",
            "Epoch [29/50] - Batch loss: 160.0377 - Epoch Loss: 32023.4985 - Avg Loss: 161.7348\n",
            "Epoch [29/50] - Batch loss: 167.0990 - Epoch Loss: 32190.5975 - Avg Loss: 161.7618\n",
            "Epoch [29/50] - Batch loss: 165.0881 - Epoch Loss: 32355.6856 - Avg Loss: 161.7784\n",
            "Epoch [29/50] - Batch loss: 159.1780 - Epoch Loss: 32514.8636 - Avg Loss: 161.7655\n",
            "Epoch [29/50] - Batch loss: 160.7689 - Epoch Loss: 32675.6325 - Avg Loss: 161.7606\n",
            "Epoch [29/50] - Batch loss: 165.7096 - Epoch Loss: 32841.3422 - Avg Loss: 161.7800\n",
            "Epoch [29/50] - Batch loss: 166.0876 - Epoch Loss: 33007.4298 - Avg Loss: 161.8011\n",
            "Epoch [29/50] - Batch loss: 160.7926 - Epoch Loss: 33168.2224 - Avg Loss: 161.7962\n",
            "Epoch [29/50] - Batch loss: 160.0126 - Epoch Loss: 33328.2350 - Avg Loss: 161.7875\n",
            "Epoch [29/50] - Batch loss: 167.3251 - Epoch Loss: 33495.5601 - Avg Loss: 161.8143\n",
            "Epoch [29/50] - Batch loss: 166.3859 - Epoch Loss: 33661.9460 - Avg Loss: 161.8363\n",
            "Epoch [29/50] - Batch loss: 163.7243 - Epoch Loss: 33825.6704 - Avg Loss: 161.8453\n",
            "Epoch [29/50] - Batch loss: 162.5552 - Epoch Loss: 33988.2256 - Avg Loss: 161.8487\n",
            "Epoch [29/50] - Batch loss: 161.1879 - Epoch Loss: 34149.4135 - Avg Loss: 161.8456\n",
            "Epoch [29/50] - Batch loss: 158.3327 - Epoch Loss: 34307.7462 - Avg Loss: 161.8290\n",
            "Epoch [29/50] - Batch loss: 159.4588 - Epoch Loss: 34467.2050 - Avg Loss: 161.8179\n",
            "Epoch [29/50] - Batch loss: 164.2251 - Epoch Loss: 34631.4301 - Avg Loss: 161.8291\n",
            "Epoch [29/50] - Batch loss: 161.2224 - Epoch Loss: 34792.6526 - Avg Loss: 161.8263\n",
            "Epoch [29/50] - Batch loss: 163.1802 - Epoch Loss: 34955.8328 - Avg Loss: 161.8326\n",
            "Epoch [29/50] - Batch loss: 163.9456 - Epoch Loss: 35119.7783 - Avg Loss: 161.8423\n",
            "Epoch [29/50] - Batch loss: 157.3723 - Epoch Loss: 35277.1506 - Avg Loss: 161.8218\n",
            "Epoch [29/50] - Batch loss: 163.9123 - Epoch Loss: 35441.0630 - Avg Loss: 161.8313\n",
            "Epoch [29/50] - Batch loss: 158.3460 - Epoch Loss: 35599.4090 - Avg Loss: 161.8155\n",
            "Epoch [29/50] - Batch loss: 164.6307 - Epoch Loss: 35764.0397 - Avg Loss: 161.8282\n",
            "Epoch [29/50] - Batch loss: 173.1382 - Epoch Loss: 35937.1779 - Avg Loss: 161.8792\n",
            "Epoch [29/50] - Batch loss: 157.8102 - Epoch Loss: 36094.9881 - Avg Loss: 161.8609\n",
            "Epoch [29/50] - Batch loss: 160.4696 - Epoch Loss: 36255.4577 - Avg Loss: 161.8547\n",
            "Epoch [29/50] - Batch loss: 161.7042 - Epoch Loss: 36417.1618 - Avg Loss: 161.8541\n",
            "Epoch [29/50] - Batch loss: 162.5229 - Epoch Loss: 36579.6848 - Avg Loss: 161.8570\n",
            "Epoch [29/50] - Batch loss: 156.3895 - Epoch Loss: 36736.0743 - Avg Loss: 161.8329\n",
            "Epoch [29/50] - Batch loss: 169.6458 - Epoch Loss: 36905.7201 - Avg Loss: 161.8672\n",
            "Epoch [29/50] - Batch loss: 159.5310 - Epoch Loss: 37065.2511 - Avg Loss: 161.8570\n",
            "Epoch [29/50] - Batch loss: 157.4541 - Epoch Loss: 37222.7052 - Avg Loss: 161.8378\n",
            "Epoch [29/50] - Batch loss: 154.3641 - Epoch Loss: 37377.0693 - Avg Loss: 161.8055\n",
            "Epoch [29/50] - Batch loss: 167.9558 - Epoch Loss: 37545.0251 - Avg Loss: 161.8320\n",
            "Epoch [29/50] - Batch loss: 155.7703 - Epoch Loss: 37700.7954 - Avg Loss: 161.8060\n",
            "Epoch [29/50] - Batch loss: 175.3318 - Epoch Loss: 37876.1272 - Avg Loss: 161.8638\n",
            "Epoch [29/50] - Batch loss: 164.5331 - Epoch Loss: 38040.6603 - Avg Loss: 161.8752\n",
            "Epoch [29/50] - Batch loss: 170.9452 - Epoch Loss: 38211.6055 - Avg Loss: 161.9136\n",
            "Epoch [29/50] - Batch loss: 165.9068 - Epoch Loss: 38377.5123 - Avg Loss: 161.9304\n",
            "Epoch [29/50] - Batch loss: 165.2498 - Epoch Loss: 38542.7621 - Avg Loss: 161.9444\n",
            "Epoch [29/50] - Batch loss: 161.5984 - Epoch Loss: 38704.3604 - Avg Loss: 161.9429\n",
            "Epoch [29/50] - Batch loss: 164.3826 - Epoch Loss: 38868.7430 - Avg Loss: 161.9531\n",
            "Epoch [29/50] - Batch loss: 162.4416 - Epoch Loss: 39031.1846 - Avg Loss: 161.9551\n",
            "Epoch [29/50] - Batch loss: 162.4003 - Epoch Loss: 39193.5849 - Avg Loss: 161.9570\n",
            "Epoch [29/50] - Batch loss: 159.6440 - Epoch Loss: 39353.2290 - Avg Loss: 161.9474\n",
            "Epoch [29/50] - Batch loss: 161.5887 - Epoch Loss: 39514.8177 - Avg Loss: 161.9460\n",
            "Epoch [29/50] - Batch loss: 177.4930 - Epoch Loss: 39692.3107 - Avg Loss: 162.0094\n",
            "Epoch [29/50] - Batch loss: 159.4307 - Epoch Loss: 39851.7413 - Avg Loss: 161.9989\n",
            "Epoch [29/50] - Batch loss: 163.3953 - Epoch Loss: 40015.1367 - Avg Loss: 162.0046\n",
            "Epoch [29/50] - Batch loss: 165.2293 - Epoch Loss: 40180.3660 - Avg Loss: 162.0176\n",
            "Epoch [29/50] - Batch loss: 160.1790 - Epoch Loss: 40340.5450 - Avg Loss: 162.0102\n",
            "Epoch [29/50] - Batch loss: 172.5104 - Epoch Loss: 40513.0554 - Avg Loss: 162.0522\n",
            "Epoch [29/50] - Batch loss: 161.2151 - Epoch Loss: 40674.2705 - Avg Loss: 162.0489\n",
            "Epoch [29/50] - Batch loss: 164.4138 - Epoch Loss: 40838.6843 - Avg Loss: 162.0583\n",
            "Epoch [29/50] - Batch loss: 156.5941 - Epoch Loss: 40995.2784 - Avg Loss: 162.0367\n",
            "Epoch [29/50] - Batch loss: 164.7625 - Epoch Loss: 41160.0410 - Avg Loss: 162.0474\n",
            "Epoch [29/50] - Batch loss: 170.1284 - Epoch Loss: 41330.1693 - Avg Loss: 162.0791\n",
            "Epoch [29/50] - Batch loss: 169.7661 - Epoch Loss: 41499.9354 - Avg Loss: 162.1091\n",
            "Epoch [29/50] - Batch loss: 165.5740 - Epoch Loss: 41665.5094 - Avg Loss: 162.1226\n",
            "Epoch [29/50] - Batch loss: 159.3210 - Epoch Loss: 41824.8303 - Avg Loss: 162.1117\n",
            "Epoch [29/50] - Batch loss: 152.2537 - Epoch Loss: 41977.0840 - Avg Loss: 162.0737\n",
            "Epoch [29/50] - Batch loss: 170.2639 - Epoch Loss: 42147.3480 - Avg Loss: 162.1052\n",
            "Epoch [29/50] - Batch loss: 167.2872 - Epoch Loss: 42314.6352 - Avg Loss: 162.1250\n",
            "Epoch [29/50] - Batch loss: 164.9560 - Epoch Loss: 42479.5912 - Avg Loss: 162.1358\n",
            "Epoch [29/50] - Batch loss: 163.2826 - Epoch Loss: 42642.8738 - Avg Loss: 162.1402\n",
            "Epoch [29/50] - Batch loss: 159.2264 - Epoch Loss: 42802.1002 - Avg Loss: 162.1292\n",
            "Epoch [29/50] - Batch loss: 156.9373 - Epoch Loss: 42959.0375 - Avg Loss: 162.1096\n",
            "Epoch [29/50] - Batch loss: 161.9654 - Epoch Loss: 43121.0029 - Avg Loss: 162.1090\n",
            "Epoch [29/50] - Batch loss: 165.6122 - Epoch Loss: 43286.6151 - Avg Loss: 162.1222\n",
            "Epoch [29/50] - Batch loss: 164.7705 - Epoch Loss: 43451.3856 - Avg Loss: 162.1320\n",
            "Epoch [29/50] - Batch loss: 158.9350 - Epoch Loss: 43610.3206 - Avg Loss: 162.1202\n",
            "Epoch [29/50] - Batch loss: 164.1089 - Epoch Loss: 43774.4295 - Avg Loss: 162.1275\n",
            "Epoch [29/50] - Batch loss: 157.1868 - Epoch Loss: 43931.6163 - Avg Loss: 162.1093\n",
            "Epoch [29/50] - Batch loss: 153.9748 - Epoch Loss: 44085.5911 - Avg Loss: 162.0794\n",
            "Epoch [29/50] - Batch loss: 170.1911 - Epoch Loss: 44255.7822 - Avg Loss: 162.1091\n",
            "Epoch [29/50] - Batch loss: 161.6047 - Epoch Loss: 44417.3869 - Avg Loss: 162.1073\n",
            "Epoch [29/50] - Batch loss: 165.0692 - Epoch Loss: 44582.4561 - Avg Loss: 162.1180\n",
            "Epoch [29/50] - Batch loss: 161.6251 - Epoch Loss: 44744.0812 - Avg Loss: 162.1162\n",
            "Epoch [29/50] - Batch loss: 158.1164 - Epoch Loss: 44902.1977 - Avg Loss: 162.1018\n",
            "Epoch [29/50] - Batch loss: 163.1318 - Epoch Loss: 45065.3294 - Avg Loss: 162.1055\n",
            "Epoch [29/50] - Batch loss: 156.9248 - Epoch Loss: 45222.2542 - Avg Loss: 162.0869\n",
            "Epoch [29/50] - Batch loss: 159.5297 - Epoch Loss: 45381.7839 - Avg Loss: 162.0778\n",
            "Epoch [29/50] - Batch loss: 162.9202 - Epoch Loss: 45544.7041 - Avg Loss: 162.0808\n",
            "Epoch [29/50] - Batch loss: 174.7531 - Epoch Loss: 45719.4572 - Avg Loss: 162.1257\n",
            "Epoch [29/50] - Batch loss: 155.0701 - Epoch Loss: 45874.5273 - Avg Loss: 162.1008\n",
            "Epoch [29/50] - Batch loss: 157.4848 - Epoch Loss: 46032.0121 - Avg Loss: 162.0845\n",
            "Epoch [29/50] - Batch loss: 155.5567 - Epoch Loss: 46187.5688 - Avg Loss: 162.0616\n",
            "Epoch [29/50] - Batch loss: 163.7766 - Epoch Loss: 46351.3454 - Avg Loss: 162.0676\n",
            "Epoch [29/50] - Batch loss: 161.9535 - Epoch Loss: 46513.2990 - Avg Loss: 162.0672\n",
            "Epoch [29/50] - Batch loss: 157.9756 - Epoch Loss: 46671.2745 - Avg Loss: 162.0530\n",
            "Epoch [29/50] - Batch loss: 162.4769 - Epoch Loss: 46833.7515 - Avg Loss: 162.0545\n",
            "Epoch [29/50] - Batch loss: 169.5081 - Epoch Loss: 47003.2596 - Avg Loss: 162.0802\n",
            "Epoch [29/50] - Batch loss: 159.3810 - Epoch Loss: 47162.6406 - Avg Loss: 162.0709\n",
            "Epoch [29/50] - Batch loss: 159.4077 - Epoch Loss: 47322.0483 - Avg Loss: 162.0618\n",
            "Epoch [29/50] - Batch loss: 157.8574 - Epoch Loss: 47479.9058 - Avg Loss: 162.0475\n",
            "Epoch [29/50] - Batch loss: 167.0576 - Epoch Loss: 47646.9634 - Avg Loss: 162.0645\n",
            "Epoch [29/50] - Batch loss: 159.7170 - Epoch Loss: 47806.6805 - Avg Loss: 162.0565\n",
            "Epoch [29/50] - Batch loss: 164.9849 - Epoch Loss: 47971.6654 - Avg Loss: 162.0664\n",
            "Epoch [29/50] - Batch loss: 159.1238 - Epoch Loss: 48130.7892 - Avg Loss: 162.0565\n",
            "Epoch [29/50] - Batch loss: 164.7360 - Epoch Loss: 48295.5252 - Avg Loss: 162.0655\n",
            "Epoch [29/50] - Batch loss: 158.0790 - Epoch Loss: 48453.6042 - Avg Loss: 162.0522\n",
            "Epoch [29/50] - Batch loss: 160.0063 - Epoch Loss: 48613.6105 - Avg Loss: 162.0454\n",
            "Epoch [29/50] - Batch loss: 160.4586 - Epoch Loss: 48774.0692 - Avg Loss: 162.0401\n",
            "Epoch [29/50] - Batch loss: 156.8196 - Epoch Loss: 48930.8888 - Avg Loss: 162.0228\n",
            "Epoch [29/50] - Batch loss: 165.7057 - Epoch Loss: 49096.5945 - Avg Loss: 162.0350\n",
            "Epoch [29/50] - Batch loss: 161.1560 - Epoch Loss: 49257.7505 - Avg Loss: 162.0321\n",
            "Epoch [29/50] - Batch loss: 163.2618 - Epoch Loss: 49421.0122 - Avg Loss: 162.0361\n",
            "Epoch [29/50] - Batch loss: 155.3324 - Epoch Loss: 49576.3446 - Avg Loss: 162.0142\n",
            "Epoch [29/50] - Batch loss: 151.7198 - Epoch Loss: 49728.0644 - Avg Loss: 161.9807\n",
            "Epoch [29/50] - Batch loss: 164.6549 - Epoch Loss: 49892.7193 - Avg Loss: 161.9893\n",
            "Epoch [29/50] - Batch loss: 161.0643 - Epoch Loss: 50053.7836 - Avg Loss: 161.9864\n",
            "Epoch [29/50] - Batch loss: 156.8471 - Epoch Loss: 50210.6306 - Avg Loss: 161.9698\n",
            "Epoch [29/50] - Batch loss: 155.1442 - Epoch Loss: 50365.7748 - Avg Loss: 161.9478\n",
            "Epoch [29/50] - Batch loss: 166.0285 - Epoch Loss: 50531.8034 - Avg Loss: 161.9609\n",
            "Epoch [29/50] - Batch loss: 164.2856 - Epoch Loss: 50696.0890 - Avg Loss: 161.9683\n",
            "Epoch [29/50] - Batch loss: 168.0790 - Epoch Loss: 50864.1680 - Avg Loss: 161.9878\n",
            "Epoch [29/50] - Batch loss: 158.0249 - Epoch Loss: 51022.1929 - Avg Loss: 161.9752\n",
            "Epoch [29/50] - Batch loss: 150.6142 - Epoch Loss: 51172.8071 - Avg Loss: 161.9393\n",
            "Epoch [29/50] - Batch loss: 162.6403 - Epoch Loss: 51335.4474 - Avg Loss: 161.9415\n",
            "Epoch [29/50] - Batch loss: 170.3685 - Epoch Loss: 51505.8159 - Avg Loss: 161.9680\n",
            "Epoch [29/50] - Batch loss: 161.1827 - Epoch Loss: 51666.9987 - Avg Loss: 161.9655\n",
            "Epoch [29/50] - Batch loss: 162.1239 - Epoch Loss: 51829.1226 - Avg Loss: 161.9660\n",
            "Epoch [29/50] - Batch loss: 151.6670 - Epoch Loss: 51980.7896 - Avg Loss: 161.9339\n",
            "Epoch [29/50] - Batch loss: 159.6932 - Epoch Loss: 52140.4827 - Avg Loss: 161.9270\n",
            "Epoch [29/50] - Batch loss: 154.5768 - Epoch Loss: 52295.0595 - Avg Loss: 161.9042\n",
            "Epoch [29/50] - Batch loss: 155.9322 - Epoch Loss: 52450.9917 - Avg Loss: 161.8858\n",
            "Epoch [29/50] - Batch loss: 161.7751 - Epoch Loss: 52612.7668 - Avg Loss: 161.8854\n",
            "Epoch [29/50] - Batch loss: 163.5108 - Epoch Loss: 52776.2776 - Avg Loss: 161.8904\n",
            "Epoch [29/50] - Batch loss: 156.6527 - Epoch Loss: 52932.9303 - Avg Loss: 161.8744\n",
            "Epoch [29/50] - Batch loss: 159.2490 - Epoch Loss: 53092.1793 - Avg Loss: 161.8664\n",
            "Epoch [29/50] - Batch loss: 161.7685 - Epoch Loss: 53253.9478 - Avg Loss: 161.8661\n",
            "Epoch [29/50] - Batch loss: 152.1426 - Epoch Loss: 53406.0904 - Avg Loss: 161.8366\n",
            "Epoch [29/50] - Batch loss: 158.3239 - Epoch Loss: 53564.4143 - Avg Loss: 161.8260\n",
            "Epoch [29/50] - Batch loss: 151.5789 - Epoch Loss: 53715.9932 - Avg Loss: 161.7952\n",
            "Epoch [29/50] - Batch loss: 163.3500 - Epoch Loss: 53879.3432 - Avg Loss: 161.7998\n",
            "Epoch [29/50] - Batch loss: 158.4565 - Epoch Loss: 54037.7997 - Avg Loss: 161.7898\n",
            "Epoch [29/50] - Batch loss: 167.5015 - Epoch Loss: 54205.3012 - Avg Loss: 161.8069\n",
            "Epoch [29/50] - Batch loss: 163.5365 - Epoch Loss: 54368.8377 - Avg Loss: 161.8120\n",
            "Epoch [29/50] - Batch loss: 156.8996 - Epoch Loss: 54525.7372 - Avg Loss: 161.7974\n",
            "Epoch [29/50] - Batch loss: 152.3790 - Epoch Loss: 54678.1162 - Avg Loss: 161.7696\n",
            "Epoch [29/50] - Batch loss: 158.8938 - Epoch Loss: 54837.0100 - Avg Loss: 161.7611\n",
            "Epoch [29/50] - Batch loss: 160.2072 - Epoch Loss: 54997.2173 - Avg Loss: 161.7565\n",
            "Epoch [29/50] - Batch loss: 165.4680 - Epoch Loss: 55162.6852 - Avg Loss: 161.7674\n",
            "Epoch [29/50] - Batch loss: 151.7825 - Epoch Loss: 55314.4677 - Avg Loss: 161.7382\n",
            "Epoch [29/50] - Batch loss: 162.4476 - Epoch Loss: 55476.9153 - Avg Loss: 161.7403\n",
            "Epoch [29/50] - Batch loss: 159.0741 - Epoch Loss: 55635.9893 - Avg Loss: 161.7325\n",
            "Epoch [29/50] - Batch loss: 155.8034 - Epoch Loss: 55791.7927 - Avg Loss: 161.7153\n",
            "Epoch [29/50] - Batch loss: 154.9688 - Epoch Loss: 55946.7615 - Avg Loss: 161.6958\n",
            "Epoch [29/50] - Batch loss: 159.4121 - Epoch Loss: 56106.1737 - Avg Loss: 161.6893\n",
            "Epoch [29/50] - Batch loss: 157.6466 - Epoch Loss: 56263.8203 - Avg Loss: 161.6776\n",
            "Epoch [29/50] - Batch loss: 169.6887 - Epoch Loss: 56433.5090 - Avg Loss: 161.7006\n",
            "Epoch [29/50] - Batch loss: 158.3711 - Epoch Loss: 56591.8801 - Avg Loss: 161.6911\n",
            "Epoch [29/50] - Batch loss: 159.8238 - Epoch Loss: 56751.7039 - Avg Loss: 161.6858\n",
            "Epoch [29/50] - Batch loss: 152.7584 - Epoch Loss: 56904.4622 - Avg Loss: 161.6604\n",
            "Epoch [29/50] - Batch loss: 163.5467 - Epoch Loss: 57068.0089 - Avg Loss: 161.6657\n",
            "Epoch [29/50] - Batch loss: 158.9725 - Epoch Loss: 57226.9814 - Avg Loss: 161.6581\n",
            "Epoch [29/50] - Batch loss: 156.5177 - Epoch Loss: 57383.4991 - Avg Loss: 161.6437\n",
            "Epoch [29/50] - Batch loss: 145.8719 - Epoch Loss: 57529.3710 - Avg Loss: 161.5994\n",
            "Epoch [29/50] - Batch loss: 149.2779 - Epoch Loss: 57678.6489 - Avg Loss: 161.5648\n",
            "Epoch [29/50] - Batch loss: 160.4284 - Epoch Loss: 57839.0773 - Avg Loss: 161.5617\n",
            "Epoch [29/50] - Batch loss: 168.7669 - Epoch Loss: 58007.8442 - Avg Loss: 161.5817\n",
            "Epoch [29/50] - Batch loss: 154.1334 - Epoch Loss: 58161.9776 - Avg Loss: 161.5610\n",
            "Epoch [29/50] - Batch loss: 154.7175 - Epoch Loss: 58316.6951 - Avg Loss: 161.5421\n",
            "Epoch [29/50] - Batch loss: 156.0777 - Epoch Loss: 58472.7728 - Avg Loss: 161.5270\n",
            "Epoch [29/50] - Batch loss: 152.9837 - Epoch Loss: 58625.7565 - Avg Loss: 161.5035\n",
            "Epoch [29/50] - Batch loss: 158.7688 - Epoch Loss: 58784.5253 - Avg Loss: 161.4959\n",
            "Epoch [29/50] - Batch loss: 157.6309 - Epoch Loss: 58942.1562 - Avg Loss: 161.4854\n",
            "Epoch [29/50] - Batch loss: 151.5505 - Epoch Loss: 59093.7066 - Avg Loss: 161.4582\n",
            "Epoch [29/50] - Batch loss: 161.2401 - Epoch Loss: 59254.9467 - Avg Loss: 161.4576\n",
            "Epoch [29/50] - Batch loss: 158.9296 - Epoch Loss: 59413.8764 - Avg Loss: 161.4508\n",
            "Epoch [29/50] - Batch loss: 153.5685 - Epoch Loss: 59567.4449 - Avg Loss: 161.4294\n",
            "Epoch [29/50] - Batch loss: 158.0815 - Epoch Loss: 59725.5264 - Avg Loss: 161.4203\n",
            "Epoch [29/50] - Batch loss: 163.8251 - Epoch Loss: 59889.3515 - Avg Loss: 161.4268\n",
            "Epoch [29/50] - Batch loss: 161.1174 - Epoch Loss: 60050.4689 - Avg Loss: 161.4260\n",
            "Epoch [29/50] - Batch loss: 161.9568 - Epoch Loss: 60212.4256 - Avg Loss: 161.4274\n",
            "Epoch [29/50] - Batch loss: 160.3049 - Epoch Loss: 60372.7306 - Avg Loss: 161.4244\n",
            "Epoch [29/50] - Batch loss: 162.0358 - Epoch Loss: 60534.7664 - Avg Loss: 161.4260\n",
            "Epoch [29/50] - Batch loss: 158.8246 - Epoch Loss: 60693.5910 - Avg Loss: 161.4191\n",
            "Epoch [29/50] - Batch loss: 155.1374 - Epoch Loss: 60848.7284 - Avg Loss: 161.4025\n",
            "Epoch [29/50] - Batch loss: 157.3539 - Epoch Loss: 61006.0823 - Avg Loss: 161.3918\n",
            "Epoch [29/50] - Batch loss: 162.2610 - Epoch Loss: 61168.3433 - Avg Loss: 161.3940\n",
            "Epoch [29/50] - Batch loss: 155.4673 - Epoch Loss: 61323.8106 - Avg Loss: 161.3784\n",
            "Epoch [29/50] - Batch loss: 163.0815 - Epoch Loss: 61486.8921 - Avg Loss: 161.3829\n",
            "Epoch [29/50] - Batch loss: 165.0284 - Epoch Loss: 61651.9206 - Avg Loss: 161.3925\n",
            "Epoch [29/50] - Batch loss: 161.2676 - Epoch Loss: 61813.1882 - Avg Loss: 161.3921\n",
            "Epoch [29/50] - Batch loss: 166.4863 - Epoch Loss: 61979.6745 - Avg Loss: 161.4054\n",
            "Epoch [29/50] - Batch loss: 156.8546 - Epoch Loss: 62136.5291 - Avg Loss: 161.3936\n",
            "Epoch [29/50] - Batch loss: 159.8442 - Epoch Loss: 62296.3733 - Avg Loss: 161.3896\n",
            "Epoch [29/50] - Batch loss: 172.0899 - Epoch Loss: 62468.4632 - Avg Loss: 161.4172\n",
            "Epoch [29/50] - Batch loss: 159.8377 - Epoch Loss: 62628.3009 - Avg Loss: 161.4131\n",
            "Epoch [29/50] - Batch loss: 156.8029 - Epoch Loss: 62785.1038 - Avg Loss: 161.4013\n",
            "Epoch [29/50] - Batch loss: 157.9839 - Epoch Loss: 62943.0877 - Avg Loss: 161.3925\n",
            "Epoch [29/50] - Batch loss: 157.5786 - Epoch Loss: 63100.6663 - Avg Loss: 161.3828\n",
            "Epoch [29/50] - Batch loss: 149.2265 - Epoch Loss: 63249.8929 - Avg Loss: 161.3518\n",
            "Epoch [29/50] - Batch loss: 165.7534 - Epoch Loss: 63415.6462 - Avg Loss: 161.3630\n",
            "Epoch [29/50] - Batch loss: 158.2690 - Epoch Loss: 63573.9152 - Avg Loss: 161.3551\n",
            "Epoch [29/50] - Batch loss: 157.0147 - Epoch Loss: 63730.9299 - Avg Loss: 161.3441\n",
            "Epoch [29/50] - Batch loss: 158.6427 - Epoch Loss: 63889.5726 - Avg Loss: 161.3373\n",
            "Epoch [29/50] - Batch loss: 162.8161 - Epoch Loss: 64052.3886 - Avg Loss: 161.3410\n",
            "Epoch [29/50] - Batch loss: 165.6975 - Epoch Loss: 64218.0862 - Avg Loss: 161.3520\n",
            "Epoch [29/50] - Batch loss: 157.9538 - Epoch Loss: 64376.0399 - Avg Loss: 161.3435\n",
            "Epoch [29/50] - Batch loss: 163.9665 - Epoch Loss: 64540.0065 - Avg Loss: 161.3500\n",
            "Epoch [29/50] - Batch loss: 151.4104 - Epoch Loss: 64691.4169 - Avg Loss: 161.3252\n",
            "Epoch [29/50] - Batch loss: 175.3738 - Epoch Loss: 64866.7907 - Avg Loss: 161.3602\n",
            "Epoch [29/50] - Batch loss: 153.5925 - Epoch Loss: 65020.3832 - Avg Loss: 161.3409\n",
            "Epoch [29/50] - Batch loss: 163.2939 - Epoch Loss: 65183.6770 - Avg Loss: 161.3457\n",
            "Epoch [29/50] - Batch loss: 151.2020 - Epoch Loss: 65334.8791 - Avg Loss: 161.3207\n",
            "Epoch [29/50] - Batch loss: 161.1179 - Epoch Loss: 65495.9969 - Avg Loss: 161.3202\n",
            "Epoch [29/50] - Batch loss: 170.0456 - Epoch Loss: 65666.0426 - Avg Loss: 161.3416\n",
            "Epoch [29/50] - Batch loss: 159.3148 - Epoch Loss: 65825.3573 - Avg Loss: 161.3367\n",
            "Epoch [29/50] - Batch loss: 157.8323 - Epoch Loss: 65983.1897 - Avg Loss: 161.3281\n",
            "Epoch [29/50] - Batch loss: 163.1323 - Epoch Loss: 66146.3220 - Avg Loss: 161.3325\n",
            "Epoch [29/50] - Batch loss: 155.6835 - Epoch Loss: 66302.0055 - Avg Loss: 161.3187\n",
            "Epoch [29/50] - Batch loss: 159.8775 - Epoch Loss: 66461.8830 - Avg Loss: 161.3152\n",
            "Epoch [29/50] - Batch loss: 151.9480 - Epoch Loss: 66613.8310 - Avg Loss: 161.2926\n",
            "Epoch [29/50] - Batch loss: 157.9474 - Epoch Loss: 66771.7784 - Avg Loss: 161.2845\n",
            "Epoch [29/50] - Batch loss: 159.8939 - Epoch Loss: 66931.6723 - Avg Loss: 161.2811\n",
            "Epoch [29/50] - Batch loss: 159.0307 - Epoch Loss: 67090.7030 - Avg Loss: 161.2757\n",
            "Epoch [29/50] - Batch loss: 157.8736 - Epoch Loss: 67248.5766 - Avg Loss: 161.2676\n",
            "Epoch [29/50] - Batch loss: 164.8230 - Epoch Loss: 67413.3996 - Avg Loss: 161.2761\n",
            "Epoch [29/50] - Batch loss: 157.1240 - Epoch Loss: 67570.5236 - Avg Loss: 161.2662\n",
            "Epoch [29/50] - Batch loss: 163.4353 - Epoch Loss: 67733.9589 - Avg Loss: 161.2713\n",
            "Epoch [29/50] - Batch loss: 148.0198 - Epoch Loss: 67881.9787 - Avg Loss: 161.2399\n",
            "Epoch [29/50] - Batch loss: 167.2932 - Epoch Loss: 68049.2719 - Avg Loss: 161.2542\n",
            "Epoch [29/50] - Batch loss: 163.2691 - Epoch Loss: 68212.5411 - Avg Loss: 161.2590\n",
            "Epoch [29/50] - Batch loss: 161.9076 - Epoch Loss: 68374.4487 - Avg Loss: 161.2605\n",
            "Epoch [29/50] - Batch loss: 165.4312 - Epoch Loss: 68539.8798 - Avg Loss: 161.2703\n",
            "Epoch [29/50] - Batch loss: 150.5603 - Epoch Loss: 68690.4401 - Avg Loss: 161.2452\n",
            "Epoch [29/50] - Batch loss: 165.7071 - Epoch Loss: 68856.1472 - Avg Loss: 161.2556\n",
            "Epoch [29/50] - Batch loss: 153.7056 - Epoch Loss: 69009.8528 - Avg Loss: 161.2380\n",
            "Epoch [29/50] - Batch loss: 167.5547 - Epoch Loss: 69177.4076 - Avg Loss: 161.2527\n",
            "Epoch [29/50] - Batch loss: 152.9474 - Epoch Loss: 69330.3550 - Avg Loss: 161.2334\n",
            "Epoch [29/50] - Batch loss: 159.3844 - Epoch Loss: 69489.7394 - Avg Loss: 161.2291\n",
            "Epoch [29/50] - Batch loss: 163.1774 - Epoch Loss: 69652.9168 - Avg Loss: 161.2336\n",
            "Epoch [29/50] - Batch loss: 162.9419 - Epoch Loss: 69815.8587 - Avg Loss: 161.2375\n",
            "Epoch [29/50] - Batch loss: 155.9919 - Epoch Loss: 69971.8506 - Avg Loss: 161.2255\n",
            "Epoch [29/50] - Batch loss: 167.1776 - Epoch Loss: 70139.0282 - Avg Loss: 161.2391\n",
            "Epoch [29/50] - Batch loss: 156.1682 - Epoch Loss: 70295.1965 - Avg Loss: 161.2275\n",
            "Epoch [29/50] - Batch loss: 158.1856 - Epoch Loss: 70453.3821 - Avg Loss: 161.2206\n",
            "Epoch [29/50] - Batch loss: 165.9628 - Epoch Loss: 70619.3449 - Avg Loss: 161.2314\n",
            "Epoch [29/50] - Batch loss: 160.3989 - Epoch Loss: 70779.7437 - Avg Loss: 161.2295\n",
            "Epoch [29/50] - Batch loss: 162.6829 - Epoch Loss: 70942.4267 - Avg Loss: 161.2328\n",
            "Epoch [29/50] - Batch loss: 152.1572 - Epoch Loss: 71094.5839 - Avg Loss: 161.2122\n",
            "Epoch [29/50] - Batch loss: 167.5186 - Epoch Loss: 71262.1025 - Avg Loss: 161.2265\n",
            "Epoch [29/50] - Batch loss: 163.0753 - Epoch Loss: 71425.1778 - Avg Loss: 161.2306\n",
            "Epoch [29/50] - Batch loss: 158.3157 - Epoch Loss: 71583.4935 - Avg Loss: 161.2241\n",
            "Epoch [29/50] - Batch loss: 156.9354 - Epoch Loss: 71740.4289 - Avg Loss: 161.2144\n",
            "Epoch [29/50] - Batch loss: 168.7016 - Epoch Loss: 71909.1305 - Avg Loss: 161.2312\n",
            "Epoch [29/50] - Batch loss: 168.4062 - Epoch Loss: 72077.5366 - Avg Loss: 161.2473\n",
            "Epoch [29/50] - Batch loss: 162.7970 - Epoch Loss: 72240.3336 - Avg Loss: 161.2507\n",
            "Epoch [29/50] - Batch loss: 151.9803 - Epoch Loss: 72392.3139 - Avg Loss: 161.2301\n",
            "Epoch [29/50] - Batch loss: 154.4876 - Epoch Loss: 72546.8015 - Avg Loss: 161.2151\n",
            "Epoch [29/50] - Batch loss: 164.1997 - Epoch Loss: 72711.0012 - Avg Loss: 161.2217\n",
            "Epoch [29/50] - Batch loss: 169.4660 - Epoch Loss: 72880.4672 - Avg Loss: 161.2400\n",
            "Epoch [29/50] - Batch loss: 152.2382 - Epoch Loss: 73032.7054 - Avg Loss: 161.2201\n",
            "Epoch [29/50] - Batch loss: 162.6014 - Epoch Loss: 73195.3068 - Avg Loss: 161.2231\n",
            "Epoch [29/50] - Batch loss: 162.2235 - Epoch Loss: 73357.5303 - Avg Loss: 161.2253\n",
            "Epoch [29/50] - Batch loss: 152.7474 - Epoch Loss: 73510.2777 - Avg Loss: 161.2067\n",
            "Epoch [29/50] - Batch loss: 159.4292 - Epoch Loss: 73669.7069 - Avg Loss: 161.2029\n",
            "Epoch [29/50] - Batch loss: 152.9611 - Epoch Loss: 73822.6680 - Avg Loss: 161.1849\n",
            "Epoch [29/50] - Batch loss: 157.9433 - Epoch Loss: 73980.6113 - Avg Loss: 161.1778\n",
            "Epoch [29/50] - Batch loss: 160.7503 - Epoch Loss: 74141.3616 - Avg Loss: 161.1769\n",
            "Epoch [29/50] - Batch loss: 156.8600 - Epoch Loss: 74298.2216 - Avg Loss: 161.1675\n",
            "Epoch [29/50] - Batch loss: 164.8324 - Epoch Loss: 74463.0540 - Avg Loss: 161.1754\n",
            "Epoch [29/50] - Batch loss: 161.4223 - Epoch Loss: 74624.4763 - Avg Loss: 161.1760\n",
            "Epoch [29/50] - Batch loss: 169.3894 - Epoch Loss: 74793.8656 - Avg Loss: 161.1937\n",
            "Epoch [29/50] - Batch loss: 164.6733 - Epoch Loss: 74958.5389 - Avg Loss: 161.2012\n",
            "Epoch [29/50] - Batch loss: 154.4066 - Epoch Loss: 75112.9455 - Avg Loss: 161.1866\n",
            "Epoch [29/50] - Batch loss: 163.7521 - Epoch Loss: 75276.6976 - Avg Loss: 161.1921\n",
            "Epoch [29/50] - Batch loss: 163.5841 - Epoch Loss: 75440.2817 - Avg Loss: 161.1972\n",
            "Epoch [29/50] - Batch loss: 159.1100 - Epoch Loss: 75599.3917 - Avg Loss: 161.1927\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 30/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ac3e1695a7246af89d87b2d5a0e3110"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [30/50] - Batch loss: 159.7107 - Epoch Loss: 159.7107 - Avg Loss: 159.7107\n",
            "Epoch [30/50] - Batch loss: 159.7851 - Epoch Loss: 319.4958 - Avg Loss: 159.7479\n",
            "Epoch [30/50] - Batch loss: 159.1692 - Epoch Loss: 478.6650 - Avg Loss: 159.5550\n",
            "Epoch [30/50] - Batch loss: 158.6611 - Epoch Loss: 637.3261 - Avg Loss: 159.3315\n",
            "Epoch [30/50] - Batch loss: 154.1625 - Epoch Loss: 791.4886 - Avg Loss: 158.2977\n",
            "Epoch [30/50] - Batch loss: 157.2333 - Epoch Loss: 948.7219 - Avg Loss: 158.1203\n",
            "Epoch [30/50] - Batch loss: 153.8458 - Epoch Loss: 1102.5677 - Avg Loss: 157.5097\n",
            "Epoch [30/50] - Batch loss: 152.5888 - Epoch Loss: 1255.1564 - Avg Loss: 156.8946\n",
            "Epoch [30/50] - Batch loss: 163.4273 - Epoch Loss: 1418.5838 - Avg Loss: 157.6204\n",
            "Epoch [30/50] - Batch loss: 171.7600 - Epoch Loss: 1590.3438 - Avg Loss: 159.0344\n",
            "Epoch [30/50] - Batch loss: 159.1994 - Epoch Loss: 1749.5432 - Avg Loss: 159.0494\n",
            "Epoch [30/50] - Batch loss: 156.4951 - Epoch Loss: 1906.0383 - Avg Loss: 158.8365\n",
            "Epoch [30/50] - Batch loss: 158.0807 - Epoch Loss: 2064.1190 - Avg Loss: 158.7784\n",
            "Epoch [30/50] - Batch loss: 159.8466 - Epoch Loss: 2223.9656 - Avg Loss: 158.8547\n",
            "Epoch [30/50] - Batch loss: 158.9834 - Epoch Loss: 2382.9490 - Avg Loss: 158.8633\n",
            "Epoch [30/50] - Batch loss: 155.9824 - Epoch Loss: 2538.9314 - Avg Loss: 158.6832\n",
            "Epoch [30/50] - Batch loss: 163.0605 - Epoch Loss: 2701.9919 - Avg Loss: 158.9407\n",
            "Epoch [30/50] - Batch loss: 156.9066 - Epoch Loss: 2858.8985 - Avg Loss: 158.8277\n",
            "Epoch [30/50] - Batch loss: 147.6613 - Epoch Loss: 3006.5598 - Avg Loss: 158.2400\n",
            "Epoch [30/50] - Batch loss: 157.0932 - Epoch Loss: 3163.6529 - Avg Loss: 158.1826\n",
            "Epoch [30/50] - Batch loss: 148.5705 - Epoch Loss: 3312.2234 - Avg Loss: 157.7249\n",
            "Epoch [30/50] - Batch loss: 158.0090 - Epoch Loss: 3470.2324 - Avg Loss: 157.7378\n",
            "Epoch [30/50] - Batch loss: 165.6077 - Epoch Loss: 3635.8401 - Avg Loss: 158.0800\n",
            "Epoch [30/50] - Batch loss: 160.5507 - Epoch Loss: 3796.3909 - Avg Loss: 158.1830\n",
            "Epoch [30/50] - Batch loss: 161.5264 - Epoch Loss: 3957.9173 - Avg Loss: 158.3167\n",
            "Epoch [30/50] - Batch loss: 159.7826 - Epoch Loss: 4117.6998 - Avg Loss: 158.3731\n",
            "Epoch [30/50] - Batch loss: 160.8396 - Epoch Loss: 4278.5394 - Avg Loss: 158.4644\n",
            "Epoch [30/50] - Batch loss: 152.2821 - Epoch Loss: 4430.8215 - Avg Loss: 158.2436\n",
            "Epoch [30/50] - Batch loss: 162.1342 - Epoch Loss: 4592.9558 - Avg Loss: 158.3778\n",
            "Epoch [30/50] - Batch loss: 160.1151 - Epoch Loss: 4753.0708 - Avg Loss: 158.4357\n",
            "Epoch [30/50] - Batch loss: 161.0412 - Epoch Loss: 4914.1121 - Avg Loss: 158.5197\n",
            "Epoch [30/50] - Batch loss: 152.2299 - Epoch Loss: 5066.3419 - Avg Loss: 158.3232\n",
            "Epoch [30/50] - Batch loss: 162.6737 - Epoch Loss: 5229.0157 - Avg Loss: 158.4550\n",
            "Epoch [30/50] - Batch loss: 155.0496 - Epoch Loss: 5384.0652 - Avg Loss: 158.3549\n",
            "Epoch [30/50] - Batch loss: 157.9594 - Epoch Loss: 5542.0246 - Avg Loss: 158.3436\n",
            "Epoch [30/50] - Batch loss: 156.5919 - Epoch Loss: 5698.6165 - Avg Loss: 158.2949\n",
            "Epoch [30/50] - Batch loss: 155.6804 - Epoch Loss: 5854.2969 - Avg Loss: 158.2242\n",
            "Epoch [30/50] - Batch loss: 160.5870 - Epoch Loss: 6014.8839 - Avg Loss: 158.2864\n",
            "Epoch [30/50] - Batch loss: 157.3290 - Epoch Loss: 6172.2129 - Avg Loss: 158.2619\n",
            "Epoch [30/50] - Batch loss: 159.4191 - Epoch Loss: 6331.6319 - Avg Loss: 158.2908\n",
            "Epoch [30/50] - Batch loss: 154.8615 - Epoch Loss: 6486.4935 - Avg Loss: 158.2072\n",
            "Epoch [30/50] - Batch loss: 170.2182 - Epoch Loss: 6656.7117 - Avg Loss: 158.4931\n",
            "Epoch [30/50] - Batch loss: 151.9334 - Epoch Loss: 6808.6451 - Avg Loss: 158.3406\n",
            "Epoch [30/50] - Batch loss: 153.8837 - Epoch Loss: 6962.5288 - Avg Loss: 158.2393\n",
            "Epoch [30/50] - Batch loss: 166.7109 - Epoch Loss: 7129.2397 - Avg Loss: 158.4275\n",
            "Epoch [30/50] - Batch loss: 161.4436 - Epoch Loss: 7290.6834 - Avg Loss: 158.4931\n",
            "Epoch [30/50] - Batch loss: 159.7692 - Epoch Loss: 7450.4526 - Avg Loss: 158.5203\n",
            "Epoch [30/50] - Batch loss: 157.5343 - Epoch Loss: 7607.9869 - Avg Loss: 158.4997\n",
            "Epoch [30/50] - Batch loss: 163.3018 - Epoch Loss: 7771.2887 - Avg Loss: 158.5977\n",
            "Epoch [30/50] - Batch loss: 154.1632 - Epoch Loss: 7925.4518 - Avg Loss: 158.5090\n",
            "Epoch [30/50] - Batch loss: 162.8410 - Epoch Loss: 8088.2929 - Avg Loss: 158.5940\n",
            "Epoch [30/50] - Batch loss: 162.7745 - Epoch Loss: 8251.0674 - Avg Loss: 158.6744\n",
            "Epoch [30/50] - Batch loss: 161.8135 - Epoch Loss: 8412.8809 - Avg Loss: 158.7336\n",
            "Epoch [30/50] - Batch loss: 157.6006 - Epoch Loss: 8570.4815 - Avg Loss: 158.7126\n",
            "Epoch [30/50] - Batch loss: 166.5254 - Epoch Loss: 8737.0069 - Avg Loss: 158.8547\n",
            "Epoch [30/50] - Batch loss: 162.6595 - Epoch Loss: 8899.6664 - Avg Loss: 158.9226\n",
            "Epoch [30/50] - Batch loss: 164.4654 - Epoch Loss: 9064.1318 - Avg Loss: 159.0199\n",
            "Epoch [30/50] - Batch loss: 165.3231 - Epoch Loss: 9229.4550 - Avg Loss: 159.1285\n",
            "Epoch [30/50] - Batch loss: 159.2346 - Epoch Loss: 9388.6896 - Avg Loss: 159.1303\n",
            "Epoch [30/50] - Batch loss: 164.0926 - Epoch Loss: 9552.7822 - Avg Loss: 159.2130\n",
            "Epoch [30/50] - Batch loss: 157.0821 - Epoch Loss: 9709.8642 - Avg Loss: 159.1781\n",
            "Epoch [30/50] - Batch loss: 163.5683 - Epoch Loss: 9873.4325 - Avg Loss: 159.2489\n",
            "Epoch [30/50] - Batch loss: 160.3824 - Epoch Loss: 10033.8149 - Avg Loss: 159.2669\n",
            "Epoch [30/50] - Batch loss: 160.9128 - Epoch Loss: 10194.7276 - Avg Loss: 159.2926\n",
            "Epoch [30/50] - Batch loss: 156.2399 - Epoch Loss: 10350.9675 - Avg Loss: 159.2457\n",
            "Epoch [30/50] - Batch loss: 160.6448 - Epoch Loss: 10511.6123 - Avg Loss: 159.2669\n",
            "Epoch [30/50] - Batch loss: 157.5954 - Epoch Loss: 10669.2076 - Avg Loss: 159.2419\n",
            "Epoch [30/50] - Batch loss: 167.3297 - Epoch Loss: 10836.5373 - Avg Loss: 159.3608\n",
            "Epoch [30/50] - Batch loss: 159.0594 - Epoch Loss: 10995.5967 - Avg Loss: 159.3565\n",
            "Epoch [30/50] - Batch loss: 165.2739 - Epoch Loss: 11160.8707 - Avg Loss: 159.4410\n",
            "Epoch [30/50] - Batch loss: 159.2834 - Epoch Loss: 11320.1540 - Avg Loss: 159.4388\n",
            "Epoch [30/50] - Batch loss: 160.0017 - Epoch Loss: 11480.1557 - Avg Loss: 159.4466\n",
            "Epoch [30/50] - Batch loss: 157.7769 - Epoch Loss: 11637.9327 - Avg Loss: 159.4237\n",
            "Epoch [30/50] - Batch loss: 171.2318 - Epoch Loss: 11809.1644 - Avg Loss: 159.5833\n",
            "Epoch [30/50] - Batch loss: 163.5642 - Epoch Loss: 11972.7286 - Avg Loss: 159.6364\n",
            "Epoch [30/50] - Batch loss: 161.1833 - Epoch Loss: 12133.9119 - Avg Loss: 159.6567\n",
            "Epoch [30/50] - Batch loss: 160.2217 - Epoch Loss: 12294.1336 - Avg Loss: 159.6641\n",
            "Epoch [30/50] - Batch loss: 159.2782 - Epoch Loss: 12453.4118 - Avg Loss: 159.6591\n",
            "Epoch [30/50] - Batch loss: 159.4237 - Epoch Loss: 12612.8355 - Avg Loss: 159.6561\n",
            "Epoch [30/50] - Batch loss: 170.6894 - Epoch Loss: 12783.5250 - Avg Loss: 159.7941\n",
            "Epoch [30/50] - Batch loss: 172.6365 - Epoch Loss: 12956.1615 - Avg Loss: 159.9526\n",
            "Epoch [30/50] - Batch loss: 167.0390 - Epoch Loss: 13123.2004 - Avg Loss: 160.0390\n",
            "Epoch [30/50] - Batch loss: 158.1119 - Epoch Loss: 13281.3123 - Avg Loss: 160.0158\n",
            "Epoch [30/50] - Batch loss: 163.8501 - Epoch Loss: 13445.1624 - Avg Loss: 160.0615\n",
            "Epoch [30/50] - Batch loss: 155.5296 - Epoch Loss: 13600.6920 - Avg Loss: 160.0081\n",
            "Epoch [30/50] - Batch loss: 164.4490 - Epoch Loss: 13765.1410 - Avg Loss: 160.0598\n",
            "Epoch [30/50] - Batch loss: 150.4412 - Epoch Loss: 13915.5821 - Avg Loss: 159.9492\n",
            "Epoch [30/50] - Batch loss: 155.7698 - Epoch Loss: 14071.3519 - Avg Loss: 159.9017\n",
            "Epoch [30/50] - Batch loss: 166.5366 - Epoch Loss: 14237.8885 - Avg Loss: 159.9763\n",
            "Epoch [30/50] - Batch loss: 163.4057 - Epoch Loss: 14401.2942 - Avg Loss: 160.0144\n",
            "Epoch [30/50] - Batch loss: 159.7640 - Epoch Loss: 14561.0582 - Avg Loss: 160.0116\n",
            "Epoch [30/50] - Batch loss: 159.8699 - Epoch Loss: 14720.9281 - Avg Loss: 160.0101\n",
            "Epoch [30/50] - Batch loss: 153.2958 - Epoch Loss: 14874.2239 - Avg Loss: 159.9379\n",
            "Epoch [30/50] - Batch loss: 156.4576 - Epoch Loss: 15030.6815 - Avg Loss: 159.9009\n",
            "Epoch [30/50] - Batch loss: 156.7313 - Epoch Loss: 15187.4129 - Avg Loss: 159.8675\n",
            "Epoch [30/50] - Batch loss: 168.6354 - Epoch Loss: 15356.0482 - Avg Loss: 159.9588\n",
            "Epoch [30/50] - Batch loss: 164.0553 - Epoch Loss: 15520.1035 - Avg Loss: 160.0011\n",
            "Epoch [30/50] - Batch loss: 158.0657 - Epoch Loss: 15678.1693 - Avg Loss: 159.9813\n",
            "Epoch [30/50] - Batch loss: 158.1297 - Epoch Loss: 15836.2990 - Avg Loss: 159.9626\n",
            "Epoch [30/50] - Batch loss: 163.4468 - Epoch Loss: 15999.7458 - Avg Loss: 159.9975\n",
            "Epoch [30/50] - Batch loss: 160.9261 - Epoch Loss: 16160.6719 - Avg Loss: 160.0067\n",
            "Epoch [30/50] - Batch loss: 166.1219 - Epoch Loss: 16326.7938 - Avg Loss: 160.0666\n",
            "Epoch [30/50] - Batch loss: 170.3593 - Epoch Loss: 16497.1531 - Avg Loss: 160.1665\n",
            "Epoch [30/50] - Batch loss: 164.3259 - Epoch Loss: 16661.4790 - Avg Loss: 160.2065\n",
            "Epoch [30/50] - Batch loss: 165.2485 - Epoch Loss: 16826.7275 - Avg Loss: 160.2545\n",
            "Epoch [30/50] - Batch loss: 162.2256 - Epoch Loss: 16988.9530 - Avg Loss: 160.2731\n",
            "Epoch [30/50] - Batch loss: 148.4205 - Epoch Loss: 17137.3736 - Avg Loss: 160.1624\n",
            "Epoch [30/50] - Batch loss: 161.8131 - Epoch Loss: 17299.1866 - Avg Loss: 160.1777\n",
            "Epoch [30/50] - Batch loss: 166.0078 - Epoch Loss: 17465.1945 - Avg Loss: 160.2311\n",
            "Epoch [30/50] - Batch loss: 163.3432 - Epoch Loss: 17628.5377 - Avg Loss: 160.2594\n",
            "Epoch [30/50] - Batch loss: 157.6777 - Epoch Loss: 17786.2154 - Avg Loss: 160.2362\n",
            "Epoch [30/50] - Batch loss: 162.6533 - Epoch Loss: 17948.8687 - Avg Loss: 160.2578\n",
            "Epoch [30/50] - Batch loss: 168.4829 - Epoch Loss: 18117.3516 - Avg Loss: 160.3305\n",
            "Epoch [30/50] - Batch loss: 161.0899 - Epoch Loss: 18278.4415 - Avg Loss: 160.3372\n",
            "Epoch [30/50] - Batch loss: 158.7932 - Epoch Loss: 18437.2347 - Avg Loss: 160.3238\n",
            "Epoch [30/50] - Batch loss: 155.9147 - Epoch Loss: 18593.1494 - Avg Loss: 160.2858\n",
            "Epoch [30/50] - Batch loss: 160.8812 - Epoch Loss: 18754.0306 - Avg Loss: 160.2909\n",
            "Epoch [30/50] - Batch loss: 157.4897 - Epoch Loss: 18911.5204 - Avg Loss: 160.2671\n",
            "Epoch [30/50] - Batch loss: 162.3634 - Epoch Loss: 19073.8837 - Avg Loss: 160.2847\n",
            "Epoch [30/50] - Batch loss: 164.9140 - Epoch Loss: 19238.7977 - Avg Loss: 160.3233\n",
            "Epoch [30/50] - Batch loss: 167.1617 - Epoch Loss: 19405.9594 - Avg Loss: 160.3798\n",
            "Epoch [30/50] - Batch loss: 160.0839 - Epoch Loss: 19566.0433 - Avg Loss: 160.3774\n",
            "Epoch [30/50] - Batch loss: 159.4525 - Epoch Loss: 19725.4958 - Avg Loss: 160.3699\n",
            "Epoch [30/50] - Batch loss: 157.4898 - Epoch Loss: 19882.9855 - Avg Loss: 160.3467\n",
            "Epoch [30/50] - Batch loss: 157.3563 - Epoch Loss: 20040.3418 - Avg Loss: 160.3227\n",
            "Epoch [30/50] - Batch loss: 162.8424 - Epoch Loss: 20203.1842 - Avg Loss: 160.3427\n",
            "Epoch [30/50] - Batch loss: 159.0046 - Epoch Loss: 20362.1889 - Avg Loss: 160.3322\n",
            "Epoch [30/50] - Batch loss: 157.3522 - Epoch Loss: 20519.5410 - Avg Loss: 160.3089\n",
            "Epoch [30/50] - Batch loss: 156.7719 - Epoch Loss: 20676.3130 - Avg Loss: 160.2815\n",
            "Epoch [30/50] - Batch loss: 161.7724 - Epoch Loss: 20838.0854 - Avg Loss: 160.2930\n",
            "Epoch [30/50] - Batch loss: 163.6289 - Epoch Loss: 21001.7143 - Avg Loss: 160.3184\n",
            "Epoch [30/50] - Batch loss: 161.5348 - Epoch Loss: 21163.2491 - Avg Loss: 160.3276\n",
            "Epoch [30/50] - Batch loss: 163.2273 - Epoch Loss: 21326.4764 - Avg Loss: 160.3494\n",
            "Epoch [30/50] - Batch loss: 167.4560 - Epoch Loss: 21493.9323 - Avg Loss: 160.4025\n",
            "Epoch [30/50] - Batch loss: 162.3302 - Epoch Loss: 21656.2625 - Avg Loss: 160.4168\n",
            "Epoch [30/50] - Batch loss: 170.6977 - Epoch Loss: 21826.9603 - Avg Loss: 160.4924\n",
            "Epoch [30/50] - Batch loss: 161.2101 - Epoch Loss: 21988.1703 - Avg Loss: 160.4976\n",
            "Epoch [30/50] - Batch loss: 163.1035 - Epoch Loss: 22151.2738 - Avg Loss: 160.5165\n",
            "Epoch [30/50] - Batch loss: 159.7509 - Epoch Loss: 22311.0247 - Avg Loss: 160.5110\n",
            "Epoch [30/50] - Batch loss: 160.9628 - Epoch Loss: 22471.9875 - Avg Loss: 160.5142\n",
            "Epoch [30/50] - Batch loss: 159.6975 - Epoch Loss: 22631.6849 - Avg Loss: 160.5084\n",
            "Epoch [30/50] - Batch loss: 167.0562 - Epoch Loss: 22798.7411 - Avg Loss: 160.5545\n",
            "Epoch [30/50] - Batch loss: 150.2271 - Epoch Loss: 22948.9682 - Avg Loss: 160.4823\n",
            "Epoch [30/50] - Batch loss: 161.2068 - Epoch Loss: 23110.1750 - Avg Loss: 160.4873\n",
            "Epoch [30/50] - Batch loss: 156.0508 - Epoch Loss: 23266.2257 - Avg Loss: 160.4567\n",
            "Epoch [30/50] - Batch loss: 151.6694 - Epoch Loss: 23417.8952 - Avg Loss: 160.3965\n",
            "Epoch [30/50] - Batch loss: 158.1532 - Epoch Loss: 23576.0484 - Avg Loss: 160.3813\n",
            "Epoch [30/50] - Batch loss: 155.7254 - Epoch Loss: 23731.7739 - Avg Loss: 160.3498\n",
            "Epoch [30/50] - Batch loss: 159.8893 - Epoch Loss: 23891.6632 - Avg Loss: 160.3467\n",
            "Epoch [30/50] - Batch loss: 157.8733 - Epoch Loss: 24049.5365 - Avg Loss: 160.3302\n",
            "Epoch [30/50] - Batch loss: 156.3027 - Epoch Loss: 24205.8392 - Avg Loss: 160.3036\n",
            "Epoch [30/50] - Batch loss: 164.5533 - Epoch Loss: 24370.3925 - Avg Loss: 160.3315\n",
            "Epoch [30/50] - Batch loss: 164.0547 - Epoch Loss: 24534.4471 - Avg Loss: 160.3559\n",
            "Epoch [30/50] - Batch loss: 157.6146 - Epoch Loss: 24692.0617 - Avg Loss: 160.3381\n",
            "Epoch [30/50] - Batch loss: 163.8064 - Epoch Loss: 24855.8681 - Avg Loss: 160.3604\n",
            "Epoch [30/50] - Batch loss: 161.6782 - Epoch Loss: 25017.5463 - Avg Loss: 160.3689\n",
            "Epoch [30/50] - Batch loss: 164.4418 - Epoch Loss: 25181.9881 - Avg Loss: 160.3948\n",
            "Epoch [30/50] - Batch loss: 151.6206 - Epoch Loss: 25333.6087 - Avg Loss: 160.3393\n",
            "Epoch [30/50] - Batch loss: 165.0571 - Epoch Loss: 25498.6658 - Avg Loss: 160.3690\n",
            "Epoch [30/50] - Batch loss: 152.2965 - Epoch Loss: 25650.9622 - Avg Loss: 160.3185\n",
            "Epoch [30/50] - Batch loss: 156.3381 - Epoch Loss: 25807.3003 - Avg Loss: 160.2938\n",
            "Epoch [30/50] - Batch loss: 153.4288 - Epoch Loss: 25960.7292 - Avg Loss: 160.2514\n",
            "Epoch [30/50] - Batch loss: 154.5192 - Epoch Loss: 26115.2484 - Avg Loss: 160.2162\n",
            "Epoch [30/50] - Batch loss: 158.5582 - Epoch Loss: 26273.8065 - Avg Loss: 160.2061\n",
            "Epoch [30/50] - Batch loss: 155.7006 - Epoch Loss: 26429.5071 - Avg Loss: 160.1788\n",
            "Epoch [30/50] - Batch loss: 157.9839 - Epoch Loss: 26587.4910 - Avg Loss: 160.1656\n",
            "Epoch [30/50] - Batch loss: 162.5745 - Epoch Loss: 26750.0655 - Avg Loss: 160.1800\n",
            "Epoch [30/50] - Batch loss: 153.6717 - Epoch Loss: 26903.7372 - Avg Loss: 160.1413\n",
            "Epoch [30/50] - Batch loss: 158.4840 - Epoch Loss: 27062.2212 - Avg Loss: 160.1315\n",
            "Epoch [30/50] - Batch loss: 158.1977 - Epoch Loss: 27220.4189 - Avg Loss: 160.1201\n",
            "Epoch [30/50] - Batch loss: 158.8467 - Epoch Loss: 27379.2656 - Avg Loss: 160.1127\n",
            "Epoch [30/50] - Batch loss: 159.7757 - Epoch Loss: 27539.0413 - Avg Loss: 160.1107\n",
            "Epoch [30/50] - Batch loss: 162.6070 - Epoch Loss: 27701.6483 - Avg Loss: 160.1251\n",
            "Epoch [30/50] - Batch loss: 148.4158 - Epoch Loss: 27850.0641 - Avg Loss: 160.0578\n",
            "Epoch [30/50] - Batch loss: 163.2654 - Epoch Loss: 28013.3295 - Avg Loss: 160.0762\n",
            "Epoch [30/50] - Batch loss: 154.0816 - Epoch Loss: 28167.4111 - Avg Loss: 160.0421\n",
            "Epoch [30/50] - Batch loss: 153.2810 - Epoch Loss: 28320.6921 - Avg Loss: 160.0039\n",
            "Epoch [30/50] - Batch loss: 160.6786 - Epoch Loss: 28481.3707 - Avg Loss: 160.0077\n",
            "Epoch [30/50] - Batch loss: 160.8634 - Epoch Loss: 28642.2341 - Avg Loss: 160.0125\n",
            "Epoch [30/50] - Batch loss: 156.7765 - Epoch Loss: 28799.0106 - Avg Loss: 159.9945\n",
            "Epoch [30/50] - Batch loss: 162.2731 - Epoch Loss: 28961.2837 - Avg Loss: 160.0071\n",
            "Epoch [30/50] - Batch loss: 162.6993 - Epoch Loss: 29123.9830 - Avg Loss: 160.0219\n",
            "Epoch [30/50] - Batch loss: 169.0645 - Epoch Loss: 29293.0475 - Avg Loss: 160.0713\n",
            "Epoch [30/50] - Batch loss: 161.4908 - Epoch Loss: 29454.5383 - Avg Loss: 160.0790\n",
            "Epoch [30/50] - Batch loss: 156.6352 - Epoch Loss: 29611.1735 - Avg Loss: 160.0604\n",
            "Epoch [30/50] - Batch loss: 165.2067 - Epoch Loss: 29776.3802 - Avg Loss: 160.0881\n",
            "Epoch [30/50] - Batch loss: 155.4605 - Epoch Loss: 29931.8407 - Avg Loss: 160.0633\n",
            "Epoch [30/50] - Batch loss: 148.0758 - Epoch Loss: 30079.9165 - Avg Loss: 159.9996\n",
            "Epoch [30/50] - Batch loss: 153.6921 - Epoch Loss: 30233.6086 - Avg Loss: 159.9662\n",
            "Epoch [30/50] - Batch loss: 156.3597 - Epoch Loss: 30389.9684 - Avg Loss: 159.9472\n",
            "Epoch [30/50] - Batch loss: 154.3858 - Epoch Loss: 30544.3542 - Avg Loss: 159.9181\n",
            "Epoch [30/50] - Batch loss: 153.6575 - Epoch Loss: 30698.0117 - Avg Loss: 159.8855\n",
            "Epoch [30/50] - Batch loss: 158.9915 - Epoch Loss: 30857.0033 - Avg Loss: 159.8808\n",
            "Epoch [30/50] - Batch loss: 152.8113 - Epoch Loss: 31009.8146 - Avg Loss: 159.8444\n",
            "Epoch [30/50] - Batch loss: 160.0211 - Epoch Loss: 31169.8357 - Avg Loss: 159.8453\n",
            "Epoch [30/50] - Batch loss: 160.0570 - Epoch Loss: 31329.8927 - Avg Loss: 159.8464\n",
            "Epoch [30/50] - Batch loss: 161.3015 - Epoch Loss: 31491.1942 - Avg Loss: 159.8538\n",
            "Epoch [30/50] - Batch loss: 164.1889 - Epoch Loss: 31655.3831 - Avg Loss: 159.8757\n",
            "Epoch [30/50] - Batch loss: 158.6260 - Epoch Loss: 31814.0091 - Avg Loss: 159.8694\n",
            "Epoch [30/50] - Batch loss: 163.4068 - Epoch Loss: 31977.4159 - Avg Loss: 159.8871\n",
            "Epoch [30/50] - Batch loss: 159.8877 - Epoch Loss: 32137.3037 - Avg Loss: 159.8871\n",
            "Epoch [30/50] - Batch loss: 164.4107 - Epoch Loss: 32301.7144 - Avg Loss: 159.9095\n",
            "Epoch [30/50] - Batch loss: 164.7310 - Epoch Loss: 32466.4454 - Avg Loss: 159.9332\n",
            "Epoch [30/50] - Batch loss: 154.8270 - Epoch Loss: 32621.2724 - Avg Loss: 159.9082\n",
            "Epoch [30/50] - Batch loss: 156.9412 - Epoch Loss: 32778.2137 - Avg Loss: 159.8937\n",
            "Epoch [30/50] - Batch loss: 168.8675 - Epoch Loss: 32947.0812 - Avg Loss: 159.9373\n",
            "Epoch [30/50] - Batch loss: 159.9382 - Epoch Loss: 33107.0194 - Avg Loss: 159.9373\n",
            "Epoch [30/50] - Batch loss: 156.3006 - Epoch Loss: 33263.3200 - Avg Loss: 159.9198\n",
            "Epoch [30/50] - Batch loss: 152.6347 - Epoch Loss: 33415.9547 - Avg Loss: 159.8850\n",
            "Epoch [30/50] - Batch loss: 154.7923 - Epoch Loss: 33570.7471 - Avg Loss: 159.8607\n",
            "Epoch [30/50] - Batch loss: 157.2001 - Epoch Loss: 33727.9472 - Avg Loss: 159.8481\n",
            "Epoch [30/50] - Batch loss: 153.3183 - Epoch Loss: 33881.2655 - Avg Loss: 159.8173\n",
            "Epoch [30/50] - Batch loss: 160.5346 - Epoch Loss: 34041.8000 - Avg Loss: 159.8207\n",
            "Epoch [30/50] - Batch loss: 154.0243 - Epoch Loss: 34195.8243 - Avg Loss: 159.7936\n",
            "Epoch [30/50] - Batch loss: 157.7784 - Epoch Loss: 34353.6027 - Avg Loss: 159.7842\n",
            "Epoch [30/50] - Batch loss: 161.4294 - Epoch Loss: 34515.0322 - Avg Loss: 159.7918\n",
            "Epoch [30/50] - Batch loss: 157.9066 - Epoch Loss: 34672.9387 - Avg Loss: 159.7831\n",
            "Epoch [30/50] - Batch loss: 155.3056 - Epoch Loss: 34828.2443 - Avg Loss: 159.7626\n",
            "Epoch [30/50] - Batch loss: 156.7589 - Epoch Loss: 34985.0033 - Avg Loss: 159.7489\n",
            "Epoch [30/50] - Batch loss: 158.3490 - Epoch Loss: 35143.3523 - Avg Loss: 159.7425\n",
            "Epoch [30/50] - Batch loss: 151.0893 - Epoch Loss: 35294.4416 - Avg Loss: 159.7034\n",
            "Epoch [30/50] - Batch loss: 154.8892 - Epoch Loss: 35449.3308 - Avg Loss: 159.6817\n",
            "Epoch [30/50] - Batch loss: 155.9354 - Epoch Loss: 35605.2662 - Avg Loss: 159.6649\n",
            "Epoch [30/50] - Batch loss: 156.3375 - Epoch Loss: 35761.6037 - Avg Loss: 159.6500\n",
            "Epoch [30/50] - Batch loss: 157.0014 - Epoch Loss: 35918.6051 - Avg Loss: 159.6382\n",
            "Epoch [30/50] - Batch loss: 158.0427 - Epoch Loss: 36076.6478 - Avg Loss: 159.6312\n",
            "Epoch [30/50] - Batch loss: 154.2364 - Epoch Loss: 36230.8842 - Avg Loss: 159.6074\n",
            "Epoch [30/50] - Batch loss: 157.2547 - Epoch Loss: 36388.1388 - Avg Loss: 159.5971\n",
            "Epoch [30/50] - Batch loss: 159.6360 - Epoch Loss: 36547.7748 - Avg Loss: 159.5973\n",
            "Epoch [30/50] - Batch loss: 159.1382 - Epoch Loss: 36706.9130 - Avg Loss: 159.5953\n",
            "Epoch [30/50] - Batch loss: 158.3869 - Epoch Loss: 36865.2999 - Avg Loss: 159.5900\n",
            "Epoch [30/50] - Batch loss: 159.0446 - Epoch Loss: 37024.3445 - Avg Loss: 159.5877\n",
            "Epoch [30/50] - Batch loss: 161.6864 - Epoch Loss: 37186.0310 - Avg Loss: 159.5967\n",
            "Epoch [30/50] - Batch loss: 162.1538 - Epoch Loss: 37348.1848 - Avg Loss: 159.6076\n",
            "Epoch [30/50] - Batch loss: 157.9597 - Epoch Loss: 37506.1445 - Avg Loss: 159.6006\n",
            "Epoch [30/50] - Batch loss: 155.8565 - Epoch Loss: 37662.0010 - Avg Loss: 159.5848\n",
            "Epoch [30/50] - Batch loss: 153.9354 - Epoch Loss: 37815.9364 - Avg Loss: 159.5609\n",
            "Epoch [30/50] - Batch loss: 150.9981 - Epoch Loss: 37966.9344 - Avg Loss: 159.5249\n",
            "Epoch [30/50] - Batch loss: 158.8370 - Epoch Loss: 38125.7714 - Avg Loss: 159.5221\n",
            "Epoch [30/50] - Batch loss: 164.1359 - Epoch Loss: 38289.9073 - Avg Loss: 159.5413\n",
            "Epoch [30/50] - Batch loss: 155.0380 - Epoch Loss: 38444.9454 - Avg Loss: 159.5226\n",
            "Epoch [30/50] - Batch loss: 161.1017 - Epoch Loss: 38606.0471 - Avg Loss: 159.5291\n",
            "Epoch [30/50] - Batch loss: 156.0838 - Epoch Loss: 38762.1309 - Avg Loss: 159.5149\n",
            "Epoch [30/50] - Batch loss: 151.9425 - Epoch Loss: 38914.0734 - Avg Loss: 159.4839\n",
            "Epoch [30/50] - Batch loss: 154.4649 - Epoch Loss: 39068.5383 - Avg Loss: 159.4634\n",
            "Epoch [30/50] - Batch loss: 156.1843 - Epoch Loss: 39224.7226 - Avg Loss: 159.4501\n",
            "Epoch [30/50] - Batch loss: 150.7509 - Epoch Loss: 39375.4735 - Avg Loss: 159.4149\n",
            "Epoch [30/50] - Batch loss: 168.2339 - Epoch Loss: 39543.7074 - Avg Loss: 159.4504\n",
            "Epoch [30/50] - Batch loss: 163.9117 - Epoch Loss: 39707.6190 - Avg Loss: 159.4683\n",
            "Epoch [30/50] - Batch loss: 158.3584 - Epoch Loss: 39865.9774 - Avg Loss: 159.4639\n",
            "Epoch [30/50] - Batch loss: 145.4891 - Epoch Loss: 40011.4666 - Avg Loss: 159.4082\n",
            "Epoch [30/50] - Batch loss: 160.9207 - Epoch Loss: 40172.3873 - Avg Loss: 159.4142\n",
            "Epoch [30/50] - Batch loss: 162.1802 - Epoch Loss: 40334.5675 - Avg Loss: 159.4252\n",
            "Epoch [30/50] - Batch loss: 165.1211 - Epoch Loss: 40499.6886 - Avg Loss: 159.4476\n",
            "Epoch [30/50] - Batch loss: 157.1540 - Epoch Loss: 40656.8425 - Avg Loss: 159.4386\n",
            "Epoch [30/50] - Batch loss: 165.7338 - Epoch Loss: 40822.5763 - Avg Loss: 159.4632\n",
            "Epoch [30/50] - Batch loss: 162.8134 - Epoch Loss: 40985.3897 - Avg Loss: 159.4762\n",
            "Epoch [30/50] - Batch loss: 156.5523 - Epoch Loss: 41141.9420 - Avg Loss: 159.4649\n",
            "Epoch [30/50] - Batch loss: 159.7703 - Epoch Loss: 41301.7123 - Avg Loss: 159.4661\n",
            "Epoch [30/50] - Batch loss: 158.6769 - Epoch Loss: 41460.3892 - Avg Loss: 159.4630\n",
            "Epoch [30/50] - Batch loss: 152.3852 - Epoch Loss: 41612.7743 - Avg Loss: 159.4359\n",
            "Epoch [30/50] - Batch loss: 147.2702 - Epoch Loss: 41760.0445 - Avg Loss: 159.3895\n",
            "Epoch [30/50] - Batch loss: 157.1047 - Epoch Loss: 41917.1492 - Avg Loss: 159.3808\n",
            "Epoch [30/50] - Batch loss: 158.5393 - Epoch Loss: 42075.6885 - Avg Loss: 159.3776\n",
            "Epoch [30/50] - Batch loss: 158.8636 - Epoch Loss: 42234.5521 - Avg Loss: 159.3757\n",
            "Epoch [30/50] - Batch loss: 159.2989 - Epoch Loss: 42393.8510 - Avg Loss: 159.3754\n",
            "Epoch [30/50] - Batch loss: 165.0901 - Epoch Loss: 42558.9411 - Avg Loss: 159.3968\n",
            "Epoch [30/50] - Batch loss: 155.0415 - Epoch Loss: 42713.9826 - Avg Loss: 159.3805\n",
            "Epoch [30/50] - Batch loss: 153.6588 - Epoch Loss: 42867.6414 - Avg Loss: 159.3593\n",
            "Epoch [30/50] - Batch loss: 156.5783 - Epoch Loss: 43024.2197 - Avg Loss: 159.3490\n",
            "Epoch [30/50] - Batch loss: 154.4393 - Epoch Loss: 43178.6590 - Avg Loss: 159.3308\n",
            "Epoch [30/50] - Batch loss: 161.1329 - Epoch Loss: 43339.7919 - Avg Loss: 159.3375\n",
            "Epoch [30/50] - Batch loss: 154.9348 - Epoch Loss: 43494.7267 - Avg Loss: 159.3213\n",
            "Epoch [30/50] - Batch loss: 158.0807 - Epoch Loss: 43652.8074 - Avg Loss: 159.3168\n",
            "Epoch [30/50] - Batch loss: 162.5273 - Epoch Loss: 43815.3347 - Avg Loss: 159.3285\n",
            "Epoch [30/50] - Batch loss: 160.8826 - Epoch Loss: 43976.2174 - Avg Loss: 159.3341\n",
            "Epoch [30/50] - Batch loss: 159.7780 - Epoch Loss: 44135.9954 - Avg Loss: 159.3357\n",
            "Epoch [30/50] - Batch loss: 151.0200 - Epoch Loss: 44287.0153 - Avg Loss: 159.3058\n",
            "Epoch [30/50] - Batch loss: 151.8023 - Epoch Loss: 44438.8176 - Avg Loss: 159.2789\n",
            "Epoch [30/50] - Batch loss: 159.6373 - Epoch Loss: 44598.4548 - Avg Loss: 159.2802\n",
            "Epoch [30/50] - Batch loss: 159.3182 - Epoch Loss: 44757.7731 - Avg Loss: 159.2803\n",
            "Epoch [30/50] - Batch loss: 153.7919 - Epoch Loss: 44911.5650 - Avg Loss: 159.2609\n",
            "Epoch [30/50] - Batch loss: 157.6722 - Epoch Loss: 45069.2372 - Avg Loss: 159.2553\n",
            "Epoch [30/50] - Batch loss: 157.7876 - Epoch Loss: 45227.0248 - Avg Loss: 159.2501\n",
            "Epoch [30/50] - Batch loss: 155.5221 - Epoch Loss: 45382.5469 - Avg Loss: 159.2370\n",
            "Epoch [30/50] - Batch loss: 163.0847 - Epoch Loss: 45545.6315 - Avg Loss: 159.2505\n",
            "Epoch [30/50] - Batch loss: 159.2018 - Epoch Loss: 45704.8334 - Avg Loss: 159.2503\n",
            "Epoch [30/50] - Batch loss: 164.9281 - Epoch Loss: 45869.7615 - Avg Loss: 159.2700\n",
            "Epoch [30/50] - Batch loss: 156.0956 - Epoch Loss: 46025.8570 - Avg Loss: 159.2590\n",
            "Epoch [30/50] - Batch loss: 163.0456 - Epoch Loss: 46188.9026 - Avg Loss: 159.2721\n",
            "Epoch [30/50] - Batch loss: 153.7392 - Epoch Loss: 46342.6418 - Avg Loss: 159.2531\n",
            "Epoch [30/50] - Batch loss: 156.9518 - Epoch Loss: 46499.5936 - Avg Loss: 159.2452\n",
            "Epoch [30/50] - Batch loss: 155.9534 - Epoch Loss: 46655.5470 - Avg Loss: 159.2339\n",
            "Epoch [30/50] - Batch loss: 161.9445 - Epoch Loss: 46817.4915 - Avg Loss: 159.2432\n",
            "Epoch [30/50] - Batch loss: 164.1557 - Epoch Loss: 46981.6473 - Avg Loss: 159.2598\n",
            "Epoch [30/50] - Batch loss: 164.2620 - Epoch Loss: 47145.9093 - Avg Loss: 159.2767\n",
            "Epoch [30/50] - Batch loss: 163.8189 - Epoch Loss: 47309.7281 - Avg Loss: 159.2920\n",
            "Epoch [30/50] - Batch loss: 155.2292 - Epoch Loss: 47464.9573 - Avg Loss: 159.2784\n",
            "Epoch [30/50] - Batch loss: 153.4736 - Epoch Loss: 47618.4309 - Avg Loss: 159.2590\n",
            "Epoch [30/50] - Batch loss: 160.1991 - Epoch Loss: 47778.6300 - Avg Loss: 159.2621\n",
            "Epoch [30/50] - Batch loss: 168.6026 - Epoch Loss: 47947.2326 - Avg Loss: 159.2931\n",
            "Epoch [30/50] - Batch loss: 160.5810 - Epoch Loss: 48107.8136 - Avg Loss: 159.2974\n",
            "Epoch [30/50] - Batch loss: 155.3677 - Epoch Loss: 48263.1813 - Avg Loss: 159.2844\n",
            "Epoch [30/50] - Batch loss: 164.5573 - Epoch Loss: 48427.7385 - Avg Loss: 159.3018\n",
            "Epoch [30/50] - Batch loss: 156.2385 - Epoch Loss: 48583.9770 - Avg Loss: 159.2917\n",
            "Epoch [30/50] - Batch loss: 164.8504 - Epoch Loss: 48748.8275 - Avg Loss: 159.3099\n",
            "Epoch [30/50] - Batch loss: 155.9786 - Epoch Loss: 48904.8060 - Avg Loss: 159.2990\n",
            "Epoch [30/50] - Batch loss: 160.4117 - Epoch Loss: 49065.2178 - Avg Loss: 159.3027\n",
            "Epoch [30/50] - Batch loss: 150.7225 - Epoch Loss: 49215.9403 - Avg Loss: 159.2749\n",
            "Epoch [30/50] - Batch loss: 158.2357 - Epoch Loss: 49374.1759 - Avg Loss: 159.2715\n",
            "Epoch [30/50] - Batch loss: 168.1814 - Epoch Loss: 49542.3574 - Avg Loss: 159.3002\n",
            "Epoch [30/50] - Batch loss: 162.1026 - Epoch Loss: 49704.4600 - Avg Loss: 159.3092\n",
            "Epoch [30/50] - Batch loss: 158.1005 - Epoch Loss: 49862.5605 - Avg Loss: 159.3053\n",
            "Epoch [30/50] - Batch loss: 156.1790 - Epoch Loss: 50018.7395 - Avg Loss: 159.2953\n",
            "Epoch [30/50] - Batch loss: 166.3184 - Epoch Loss: 50185.0579 - Avg Loss: 159.3176\n",
            "Epoch [30/50] - Batch loss: 160.2387 - Epoch Loss: 50345.2966 - Avg Loss: 159.3206\n",
            "Epoch [30/50] - Batch loss: 157.0650 - Epoch Loss: 50502.3616 - Avg Loss: 159.3134\n",
            "Epoch [30/50] - Batch loss: 156.4796 - Epoch Loss: 50658.8413 - Avg Loss: 159.3045\n",
            "Epoch [30/50] - Batch loss: 167.3860 - Epoch Loss: 50826.2273 - Avg Loss: 159.3299\n",
            "Epoch [30/50] - Batch loss: 160.5314 - Epoch Loss: 50986.7587 - Avg Loss: 159.3336\n",
            "Epoch [30/50] - Batch loss: 156.8736 - Epoch Loss: 51143.6323 - Avg Loss: 159.3260\n",
            "Epoch [30/50] - Batch loss: 162.2963 - Epoch Loss: 51305.9286 - Avg Loss: 159.3352\n",
            "Epoch [30/50] - Batch loss: 158.3279 - Epoch Loss: 51464.2564 - Avg Loss: 159.3321\n",
            "Epoch [30/50] - Batch loss: 154.0776 - Epoch Loss: 51618.3340 - Avg Loss: 159.3158\n",
            "Epoch [30/50] - Batch loss: 152.5213 - Epoch Loss: 51770.8554 - Avg Loss: 159.2949\n",
            "Epoch [30/50] - Batch loss: 168.7742 - Epoch Loss: 51939.6295 - Avg Loss: 159.3240\n",
            "Epoch [30/50] - Batch loss: 163.5247 - Epoch Loss: 52103.1543 - Avg Loss: 159.3369\n",
            "Epoch [30/50] - Batch loss: 153.3792 - Epoch Loss: 52256.5334 - Avg Loss: 159.3187\n",
            "Epoch [30/50] - Batch loss: 161.5828 - Epoch Loss: 52418.1162 - Avg Loss: 159.3256\n",
            "Epoch [30/50] - Batch loss: 165.7038 - Epoch Loss: 52583.8200 - Avg Loss: 159.3449\n",
            "Epoch [30/50] - Batch loss: 162.8390 - Epoch Loss: 52746.6590 - Avg Loss: 159.3555\n",
            "Epoch [30/50] - Batch loss: 157.3670 - Epoch Loss: 52904.0260 - Avg Loss: 159.3495\n",
            "Epoch [30/50] - Batch loss: 156.8081 - Epoch Loss: 53060.8341 - Avg Loss: 159.3418\n",
            "Epoch [30/50] - Batch loss: 155.3255 - Epoch Loss: 53216.1596 - Avg Loss: 159.3298\n",
            "Epoch [30/50] - Batch loss: 164.0653 - Epoch Loss: 53380.2250 - Avg Loss: 159.3440\n",
            "Epoch [30/50] - Batch loss: 160.2262 - Epoch Loss: 53540.4511 - Avg Loss: 159.3466\n",
            "Epoch [30/50] - Batch loss: 157.1084 - Epoch Loss: 53697.5596 - Avg Loss: 159.3399\n",
            "Epoch [30/50] - Batch loss: 161.4364 - Epoch Loss: 53858.9960 - Avg Loss: 159.3461\n",
            "Epoch [30/50] - Batch loss: 156.5591 - Epoch Loss: 54015.5551 - Avg Loss: 159.3379\n",
            "Epoch [30/50] - Batch loss: 149.4310 - Epoch Loss: 54164.9861 - Avg Loss: 159.3088\n",
            "Epoch [30/50] - Batch loss: 159.7491 - Epoch Loss: 54324.7353 - Avg Loss: 159.3101\n",
            "Epoch [30/50] - Batch loss: 155.2491 - Epoch Loss: 54479.9844 - Avg Loss: 159.2982\n",
            "Epoch [30/50] - Batch loss: 162.8961 - Epoch Loss: 54642.8805 - Avg Loss: 159.3087\n",
            "Epoch [30/50] - Batch loss: 166.0054 - Epoch Loss: 54808.8859 - Avg Loss: 159.3282\n",
            "Epoch [30/50] - Batch loss: 164.4453 - Epoch Loss: 54973.3312 - Avg Loss: 159.3430\n",
            "Epoch [30/50] - Batch loss: 154.1901 - Epoch Loss: 55127.5213 - Avg Loss: 159.3281\n",
            "Epoch [30/50] - Batch loss: 156.4666 - Epoch Loss: 55283.9879 - Avg Loss: 159.3198\n",
            "Epoch [30/50] - Batch loss: 165.0560 - Epoch Loss: 55449.0439 - Avg Loss: 159.3363\n",
            "Epoch [30/50] - Batch loss: 155.7494 - Epoch Loss: 55604.7934 - Avg Loss: 159.3261\n",
            "Epoch [30/50] - Batch loss: 160.7366 - Epoch Loss: 55765.5300 - Avg Loss: 159.3301\n",
            "Epoch [30/50] - Batch loss: 166.9692 - Epoch Loss: 55932.4992 - Avg Loss: 159.3518\n",
            "Epoch [30/50] - Batch loss: 155.4987 - Epoch Loss: 56087.9979 - Avg Loss: 159.3409\n",
            "Epoch [30/50] - Batch loss: 160.1812 - Epoch Loss: 56248.1790 - Avg Loss: 159.3433\n",
            "Epoch [30/50] - Batch loss: 161.8302 - Epoch Loss: 56410.0093 - Avg Loss: 159.3503\n",
            "Epoch [30/50] - Batch loss: 159.1161 - Epoch Loss: 56569.1254 - Avg Loss: 159.3496\n",
            "Epoch [30/50] - Batch loss: 161.8535 - Epoch Loss: 56730.9789 - Avg Loss: 159.3567\n",
            "Epoch [30/50] - Batch loss: 157.4142 - Epoch Loss: 56888.3931 - Avg Loss: 159.3512\n",
            "Epoch [30/50] - Batch loss: 151.0790 - Epoch Loss: 57039.4721 - Avg Loss: 159.3281\n",
            "Epoch [30/50] - Batch loss: 159.8152 - Epoch Loss: 57199.2874 - Avg Loss: 159.3295\n",
            "Epoch [30/50] - Batch loss: 158.1568 - Epoch Loss: 57357.4442 - Avg Loss: 159.3262\n",
            "Epoch [30/50] - Batch loss: 147.2054 - Epoch Loss: 57504.6495 - Avg Loss: 159.2927\n",
            "Epoch [30/50] - Batch loss: 163.7640 - Epoch Loss: 57668.4135 - Avg Loss: 159.3050\n",
            "Epoch [30/50] - Batch loss: 163.5538 - Epoch Loss: 57831.9673 - Avg Loss: 159.3167\n",
            "Epoch [30/50] - Batch loss: 159.0097 - Epoch Loss: 57990.9770 - Avg Loss: 159.3159\n",
            "Epoch [30/50] - Batch loss: 165.6081 - Epoch Loss: 58156.5851 - Avg Loss: 159.3331\n",
            "Epoch [30/50] - Batch loss: 159.5905 - Epoch Loss: 58316.1756 - Avg Loss: 159.3338\n",
            "Epoch [30/50] - Batch loss: 167.0382 - Epoch Loss: 58483.2138 - Avg Loss: 159.3548\n",
            "Epoch [30/50] - Batch loss: 160.1312 - Epoch Loss: 58643.3450 - Avg Loss: 159.3569\n",
            "Epoch [30/50] - Batch loss: 152.0201 - Epoch Loss: 58795.3651 - Avg Loss: 159.3370\n",
            "Epoch [30/50] - Batch loss: 154.1558 - Epoch Loss: 58949.5209 - Avg Loss: 159.3230\n",
            "Epoch [30/50] - Batch loss: 160.0102 - Epoch Loss: 59109.5311 - Avg Loss: 159.3249\n",
            "Epoch [30/50] - Batch loss: 161.4420 - Epoch Loss: 59270.9731 - Avg Loss: 159.3306\n",
            "Epoch [30/50] - Batch loss: 156.9877 - Epoch Loss: 59427.9608 - Avg Loss: 159.3243\n",
            "Epoch [30/50] - Batch loss: 165.4974 - Epoch Loss: 59593.4582 - Avg Loss: 159.3408\n",
            "Epoch [30/50] - Batch loss: 153.6968 - Epoch Loss: 59747.1550 - Avg Loss: 159.3257\n",
            "Epoch [30/50] - Batch loss: 164.5719 - Epoch Loss: 59911.7269 - Avg Loss: 159.3397\n",
            "Epoch [30/50] - Batch loss: 153.5631 - Epoch Loss: 60065.2900 - Avg Loss: 159.3244\n",
            "Epoch [30/50] - Batch loss: 158.3436 - Epoch Loss: 60223.6335 - Avg Loss: 159.3218\n",
            "Epoch [30/50] - Batch loss: 164.7574 - Epoch Loss: 60388.3909 - Avg Loss: 159.3361\n",
            "Epoch [30/50] - Batch loss: 155.3451 - Epoch Loss: 60543.7360 - Avg Loss: 159.3256\n",
            "Epoch [30/50] - Batch loss: 157.5154 - Epoch Loss: 60701.2514 - Avg Loss: 159.3209\n",
            "Epoch [30/50] - Batch loss: 151.4673 - Epoch Loss: 60852.7187 - Avg Loss: 159.3003\n",
            "Epoch [30/50] - Batch loss: 153.7332 - Epoch Loss: 61006.4518 - Avg Loss: 159.2858\n",
            "Epoch [30/50] - Batch loss: 159.7562 - Epoch Loss: 61166.2081 - Avg Loss: 159.2870\n",
            "Epoch [30/50] - Batch loss: 161.5307 - Epoch Loss: 61327.7388 - Avg Loss: 159.2928\n",
            "Epoch [30/50] - Batch loss: 154.1282 - Epoch Loss: 61481.8670 - Avg Loss: 159.2794\n",
            "Epoch [30/50] - Batch loss: 159.8234 - Epoch Loss: 61641.6904 - Avg Loss: 159.2809\n",
            "Epoch [30/50] - Batch loss: 167.5148 - Epoch Loss: 61809.2052 - Avg Loss: 159.3021\n",
            "Epoch [30/50] - Batch loss: 156.2447 - Epoch Loss: 61965.4499 - Avg Loss: 159.2942\n",
            "Epoch [30/50] - Batch loss: 164.3384 - Epoch Loss: 62129.7883 - Avg Loss: 159.3071\n",
            "Epoch [30/50] - Batch loss: 165.8698 - Epoch Loss: 62295.6580 - Avg Loss: 159.3239\n",
            "Epoch [30/50] - Batch loss: 154.7675 - Epoch Loss: 62450.4256 - Avg Loss: 159.3123\n",
            "Epoch [30/50] - Batch loss: 166.6570 - Epoch Loss: 62617.0826 - Avg Loss: 159.3310\n",
            "Epoch [30/50] - Batch loss: 159.4813 - Epoch Loss: 62776.5638 - Avg Loss: 159.3314\n",
            "Epoch [30/50] - Batch loss: 155.3353 - Epoch Loss: 62931.8992 - Avg Loss: 159.3213\n",
            "Epoch [30/50] - Batch loss: 159.1588 - Epoch Loss: 63091.0580 - Avg Loss: 159.3209\n",
            "Epoch [30/50] - Batch loss: 154.1924 - Epoch Loss: 63245.2504 - Avg Loss: 159.3079\n",
            "Epoch [30/50] - Batch loss: 161.3905 - Epoch Loss: 63406.6409 - Avg Loss: 159.3132\n",
            "Epoch [30/50] - Batch loss: 149.9699 - Epoch Loss: 63556.6108 - Avg Loss: 159.2898\n",
            "Epoch [30/50] - Batch loss: 157.2558 - Epoch Loss: 63713.8666 - Avg Loss: 159.2847\n",
            "Epoch [30/50] - Batch loss: 157.7104 - Epoch Loss: 63871.5770 - Avg Loss: 159.2807\n",
            "Epoch [30/50] - Batch loss: 155.1603 - Epoch Loss: 64026.7373 - Avg Loss: 159.2705\n",
            "Epoch [30/50] - Batch loss: 160.1333 - Epoch Loss: 64186.8706 - Avg Loss: 159.2726\n",
            "Epoch [30/50] - Batch loss: 159.1801 - Epoch Loss: 64346.0507 - Avg Loss: 159.2724\n",
            "Epoch [30/50] - Batch loss: 158.7368 - Epoch Loss: 64504.7875 - Avg Loss: 159.2711\n",
            "Epoch [30/50] - Batch loss: 158.6576 - Epoch Loss: 64663.4451 - Avg Loss: 159.2696\n",
            "Epoch [30/50] - Batch loss: 166.4377 - Epoch Loss: 64829.8828 - Avg Loss: 159.2872\n",
            "Epoch [30/50] - Batch loss: 159.3010 - Epoch Loss: 64989.1838 - Avg Loss: 159.2872\n",
            "Epoch [30/50] - Batch loss: 156.6058 - Epoch Loss: 65145.7896 - Avg Loss: 159.2807\n",
            "Epoch [30/50] - Batch loss: 149.7147 - Epoch Loss: 65295.5043 - Avg Loss: 159.2573\n",
            "Epoch [30/50] - Batch loss: 159.6851 - Epoch Loss: 65455.1894 - Avg Loss: 159.2584\n",
            "Epoch [30/50] - Batch loss: 162.4389 - Epoch Loss: 65617.6283 - Avg Loss: 159.2661\n",
            "Epoch [30/50] - Batch loss: 154.6803 - Epoch Loss: 65772.3086 - Avg Loss: 159.2550\n",
            "Epoch [30/50] - Batch loss: 162.7412 - Epoch Loss: 65935.0498 - Avg Loss: 159.2634\n",
            "Epoch [30/50] - Batch loss: 164.0150 - Epoch Loss: 66099.0647 - Avg Loss: 159.2749\n",
            "Epoch [30/50] - Batch loss: 156.0567 - Epoch Loss: 66255.1215 - Avg Loss: 159.2671\n",
            "Epoch [30/50] - Batch loss: 161.1240 - Epoch Loss: 66416.2455 - Avg Loss: 159.2716\n",
            "Epoch [30/50] - Batch loss: 155.3226 - Epoch Loss: 66571.5681 - Avg Loss: 159.2621\n",
            "Epoch [30/50] - Batch loss: 164.1049 - Epoch Loss: 66735.6730 - Avg Loss: 159.2737\n",
            "Epoch [30/50] - Batch loss: 166.9487 - Epoch Loss: 66902.6218 - Avg Loss: 159.2920\n",
            "Epoch [30/50] - Batch loss: 157.6869 - Epoch Loss: 67060.3087 - Avg Loss: 159.2881\n",
            "Epoch [30/50] - Batch loss: 157.1875 - Epoch Loss: 67217.4961 - Avg Loss: 159.2832\n",
            "Epoch [30/50] - Batch loss: 157.5679 - Epoch Loss: 67375.0640 - Avg Loss: 159.2791\n",
            "Epoch [30/50] - Batch loss: 157.2631 - Epoch Loss: 67532.3271 - Avg Loss: 159.2744\n",
            "Epoch [30/50] - Batch loss: 166.1347 - Epoch Loss: 67698.4618 - Avg Loss: 159.2905\n",
            "Epoch [30/50] - Batch loss: 151.3984 - Epoch Loss: 67849.8602 - Avg Loss: 159.2720\n",
            "Epoch [30/50] - Batch loss: 158.2970 - Epoch Loss: 68008.1572 - Avg Loss: 159.2697\n",
            "Epoch [30/50] - Batch loss: 168.1293 - Epoch Loss: 68176.2865 - Avg Loss: 159.2904\n",
            "Epoch [30/50] - Batch loss: 158.1174 - Epoch Loss: 68334.4039 - Avg Loss: 159.2877\n",
            "Epoch [30/50] - Batch loss: 162.8513 - Epoch Loss: 68497.2553 - Avg Loss: 159.2959\n",
            "Epoch [30/50] - Batch loss: 160.9642 - Epoch Loss: 68658.2195 - Avg Loss: 159.2998\n",
            "Epoch [30/50] - Batch loss: 161.8598 - Epoch Loss: 68820.0792 - Avg Loss: 159.3057\n",
            "Epoch [30/50] - Batch loss: 150.0864 - Epoch Loss: 68970.1656 - Avg Loss: 159.2844\n",
            "Epoch [30/50] - Batch loss: 159.3892 - Epoch Loss: 69129.5548 - Avg Loss: 159.2847\n",
            "Epoch [30/50] - Batch loss: 150.9117 - Epoch Loss: 69280.4665 - Avg Loss: 159.2654\n",
            "Epoch [30/50] - Batch loss: 161.5083 - Epoch Loss: 69441.9748 - Avg Loss: 159.2706\n",
            "Epoch [30/50] - Batch loss: 152.9687 - Epoch Loss: 69594.9435 - Avg Loss: 159.2562\n",
            "Epoch [30/50] - Batch loss: 157.7576 - Epoch Loss: 69752.7011 - Avg Loss: 159.2527\n",
            "Epoch [30/50] - Batch loss: 154.6562 - Epoch Loss: 69907.3573 - Avg Loss: 159.2423\n",
            "Epoch [30/50] - Batch loss: 156.9463 - Epoch Loss: 70064.3036 - Avg Loss: 159.2371\n",
            "Epoch [30/50] - Batch loss: 159.1925 - Epoch Loss: 70223.4961 - Avg Loss: 159.2370\n",
            "Epoch [30/50] - Batch loss: 161.8907 - Epoch Loss: 70385.3868 - Avg Loss: 159.2430\n",
            "Epoch [30/50] - Batch loss: 160.3844 - Epoch Loss: 70545.7711 - Avg Loss: 159.2455\n",
            "Epoch [30/50] - Batch loss: 154.6210 - Epoch Loss: 70700.3922 - Avg Loss: 159.2351\n",
            "Epoch [30/50] - Batch loss: 155.3080 - Epoch Loss: 70855.7002 - Avg Loss: 159.2263\n",
            "Epoch [30/50] - Batch loss: 165.9339 - Epoch Loss: 71021.6341 - Avg Loss: 159.2413\n",
            "Epoch [30/50] - Batch loss: 156.4833 - Epoch Loss: 71178.1174 - Avg Loss: 159.2352\n",
            "Epoch [30/50] - Batch loss: 156.1336 - Epoch Loss: 71334.2511 - Avg Loss: 159.2282\n",
            "Epoch [30/50] - Batch loss: 148.7788 - Epoch Loss: 71483.0298 - Avg Loss: 159.2050\n",
            "Epoch [30/50] - Batch loss: 155.8820 - Epoch Loss: 71638.9118 - Avg Loss: 159.1976\n",
            "Epoch [30/50] - Batch loss: 165.8740 - Epoch Loss: 71804.7858 - Avg Loss: 159.2124\n",
            "Epoch [30/50] - Batch loss: 148.7127 - Epoch Loss: 71953.4986 - Avg Loss: 159.1892\n",
            "Epoch [30/50] - Batch loss: 160.6986 - Epoch Loss: 72114.1971 - Avg Loss: 159.1925\n",
            "Epoch [30/50] - Batch loss: 152.4395 - Epoch Loss: 72266.6366 - Avg Loss: 159.1776\n",
            "Epoch [30/50] - Batch loss: 158.9184 - Epoch Loss: 72425.5549 - Avg Loss: 159.1770\n",
            "Epoch [30/50] - Batch loss: 152.3564 - Epoch Loss: 72577.9114 - Avg Loss: 159.1621\n",
            "Epoch [30/50] - Batch loss: 163.4257 - Epoch Loss: 72741.3371 - Avg Loss: 159.1714\n",
            "Epoch [30/50] - Batch loss: 160.1640 - Epoch Loss: 72901.5010 - Avg Loss: 159.1736\n",
            "Epoch [30/50] - Batch loss: 165.7727 - Epoch Loss: 73067.2737 - Avg Loss: 159.1880\n",
            "Epoch [30/50] - Batch loss: 166.6195 - Epoch Loss: 73233.8932 - Avg Loss: 159.2041\n",
            "Epoch [30/50] - Batch loss: 157.1612 - Epoch Loss: 73391.0545 - Avg Loss: 159.1997\n",
            "Epoch [30/50] - Batch loss: 154.5637 - Epoch Loss: 73545.6182 - Avg Loss: 159.1896\n",
            "Epoch [30/50] - Batch loss: 153.7384 - Epoch Loss: 73699.3566 - Avg Loss: 159.1779\n",
            "Epoch [30/50] - Batch loss: 165.6159 - Epoch Loss: 73864.9724 - Avg Loss: 159.1918\n",
            "Epoch [30/50] - Batch loss: 163.7729 - Epoch Loss: 74028.7453 - Avg Loss: 159.2016\n",
            "Epoch [30/50] - Batch loss: 155.3025 - Epoch Loss: 74184.0479 - Avg Loss: 159.1932\n",
            "Epoch [30/50] - Batch loss: 153.6481 - Epoch Loss: 74337.6960 - Avg Loss: 159.1814\n",
            "Epoch [30/50] - Batch loss: 151.9417 - Epoch Loss: 74489.6377 - Avg Loss: 159.1659\n",
            "Epoch [30/50] - Batch loss: 159.9256 - Epoch Loss: 74649.5633 - Avg Loss: 159.1675\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 31/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99c2e3598cc44090a6aa8475e65cd936"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [31/50] - Batch loss: 157.2709 - Epoch Loss: 157.2709 - Avg Loss: 157.2709\n",
            "Epoch [31/50] - Batch loss: 162.5387 - Epoch Loss: 319.8095 - Avg Loss: 159.9048\n",
            "Epoch [31/50] - Batch loss: 160.8581 - Epoch Loss: 480.6676 - Avg Loss: 160.2225\n",
            "Epoch [31/50] - Batch loss: 151.4232 - Epoch Loss: 632.0909 - Avg Loss: 158.0227\n",
            "Epoch [31/50] - Batch loss: 160.6152 - Epoch Loss: 792.7061 - Avg Loss: 158.5412\n",
            "Epoch [31/50] - Batch loss: 160.8865 - Epoch Loss: 953.5926 - Avg Loss: 158.9321\n",
            "Epoch [31/50] - Batch loss: 153.6983 - Epoch Loss: 1107.2908 - Avg Loss: 158.1844\n",
            "Epoch [31/50] - Batch loss: 162.1186 - Epoch Loss: 1269.4095 - Avg Loss: 158.6762\n",
            "Epoch [31/50] - Batch loss: 157.4338 - Epoch Loss: 1426.8432 - Avg Loss: 158.5381\n",
            "Epoch [31/50] - Batch loss: 156.7228 - Epoch Loss: 1583.5661 - Avg Loss: 158.3566\n",
            "Epoch [31/50] - Batch loss: 157.3792 - Epoch Loss: 1740.9453 - Avg Loss: 158.2678\n",
            "Epoch [31/50] - Batch loss: 164.9222 - Epoch Loss: 1905.8675 - Avg Loss: 158.8223\n",
            "Epoch [31/50] - Batch loss: 160.3211 - Epoch Loss: 2066.1886 - Avg Loss: 158.9376\n",
            "Epoch [31/50] - Batch loss: 159.1430 - Epoch Loss: 2225.3316 - Avg Loss: 158.9523\n",
            "Epoch [31/50] - Batch loss: 159.3722 - Epoch Loss: 2384.7039 - Avg Loss: 158.9803\n",
            "Epoch [31/50] - Batch loss: 156.4290 - Epoch Loss: 2541.1329 - Avg Loss: 158.8208\n",
            "Epoch [31/50] - Batch loss: 156.8921 - Epoch Loss: 2698.0250 - Avg Loss: 158.7074\n",
            "Epoch [31/50] - Batch loss: 159.9001 - Epoch Loss: 2857.9251 - Avg Loss: 158.7736\n",
            "Epoch [31/50] - Batch loss: 160.9351 - Epoch Loss: 3018.8602 - Avg Loss: 158.8874\n",
            "Epoch [31/50] - Batch loss: 155.1352 - Epoch Loss: 3173.9954 - Avg Loss: 158.6998\n",
            "Epoch [31/50] - Batch loss: 156.9798 - Epoch Loss: 3330.9752 - Avg Loss: 158.6179\n",
            "Epoch [31/50] - Batch loss: 157.9931 - Epoch Loss: 3488.9682 - Avg Loss: 158.5895\n",
            "Epoch [31/50] - Batch loss: 165.9167 - Epoch Loss: 3654.8850 - Avg Loss: 158.9080\n",
            "Epoch [31/50] - Batch loss: 150.3455 - Epoch Loss: 3805.2305 - Avg Loss: 158.5513\n",
            "Epoch [31/50] - Batch loss: 155.0145 - Epoch Loss: 3960.2450 - Avg Loss: 158.4098\n",
            "Epoch [31/50] - Batch loss: 154.7825 - Epoch Loss: 4115.0276 - Avg Loss: 158.2703\n",
            "Epoch [31/50] - Batch loss: 158.3231 - Epoch Loss: 4273.3507 - Avg Loss: 158.2722\n",
            "Epoch [31/50] - Batch loss: 157.7183 - Epoch Loss: 4431.0690 - Avg Loss: 158.2525\n",
            "Epoch [31/50] - Batch loss: 162.4001 - Epoch Loss: 4593.4691 - Avg Loss: 158.3955\n",
            "Epoch [31/50] - Batch loss: 152.6926 - Epoch Loss: 4746.1617 - Avg Loss: 158.2054\n",
            "Epoch [31/50] - Batch loss: 158.9991 - Epoch Loss: 4905.1608 - Avg Loss: 158.2310\n",
            "Epoch [31/50] - Batch loss: 161.5079 - Epoch Loss: 5066.6687 - Avg Loss: 158.3334\n",
            "Epoch [31/50] - Batch loss: 151.8963 - Epoch Loss: 5218.5650 - Avg Loss: 158.1383\n",
            "Epoch [31/50] - Batch loss: 163.0509 - Epoch Loss: 5381.6159 - Avg Loss: 158.2828\n",
            "Epoch [31/50] - Batch loss: 159.4216 - Epoch Loss: 5541.0375 - Avg Loss: 158.3154\n",
            "Epoch [31/50] - Batch loss: 166.0037 - Epoch Loss: 5707.0412 - Avg Loss: 158.5289\n",
            "Epoch [31/50] - Batch loss: 164.8711 - Epoch Loss: 5871.9123 - Avg Loss: 158.7003\n",
            "Epoch [31/50] - Batch loss: 153.7909 - Epoch Loss: 6025.7032 - Avg Loss: 158.5711\n",
            "Epoch [31/50] - Batch loss: 163.7448 - Epoch Loss: 6189.4480 - Avg Loss: 158.7038\n",
            "Epoch [31/50] - Batch loss: 157.8277 - Epoch Loss: 6347.2756 - Avg Loss: 158.6819\n",
            "Epoch [31/50] - Batch loss: 154.4151 - Epoch Loss: 6501.6907 - Avg Loss: 158.5778\n",
            "Epoch [31/50] - Batch loss: 160.1944 - Epoch Loss: 6661.8850 - Avg Loss: 158.6163\n",
            "Epoch [31/50] - Batch loss: 156.3091 - Epoch Loss: 6818.1941 - Avg Loss: 158.5627\n",
            "Epoch [31/50] - Batch loss: 161.1978 - Epoch Loss: 6979.3919 - Avg Loss: 158.6225\n",
            "Epoch [31/50] - Batch loss: 157.5159 - Epoch Loss: 7136.9078 - Avg Loss: 158.5980\n",
            "Epoch [31/50] - Batch loss: 163.8637 - Epoch Loss: 7300.7715 - Avg Loss: 158.7124\n",
            "Epoch [31/50] - Batch loss: 155.0146 - Epoch Loss: 7455.7861 - Avg Loss: 158.6337\n",
            "Epoch [31/50] - Batch loss: 164.0681 - Epoch Loss: 7619.8542 - Avg Loss: 158.7470\n",
            "Epoch [31/50] - Batch loss: 155.7354 - Epoch Loss: 7775.5896 - Avg Loss: 158.6855\n",
            "Epoch [31/50] - Batch loss: 162.2212 - Epoch Loss: 7937.8108 - Avg Loss: 158.7562\n",
            "Epoch [31/50] - Batch loss: 156.8691 - Epoch Loss: 8094.6798 - Avg Loss: 158.7192\n",
            "Epoch [31/50] - Batch loss: 162.7334 - Epoch Loss: 8257.4132 - Avg Loss: 158.7964\n",
            "Epoch [31/50] - Batch loss: 154.6872 - Epoch Loss: 8412.1004 - Avg Loss: 158.7189\n",
            "Epoch [31/50] - Batch loss: 153.9134 - Epoch Loss: 8566.0138 - Avg Loss: 158.6299\n",
            "Epoch [31/50] - Batch loss: 151.5400 - Epoch Loss: 8717.5539 - Avg Loss: 158.5010\n",
            "Epoch [31/50] - Batch loss: 157.9232 - Epoch Loss: 8875.4771 - Avg Loss: 158.4907\n",
            "Epoch [31/50] - Batch loss: 160.4235 - Epoch Loss: 9035.9006 - Avg Loss: 158.5246\n",
            "Epoch [31/50] - Batch loss: 156.1495 - Epoch Loss: 9192.0501 - Avg Loss: 158.4836\n",
            "Epoch [31/50] - Batch loss: 154.7369 - Epoch Loss: 9346.7870 - Avg Loss: 158.4201\n",
            "Epoch [31/50] - Batch loss: 151.3342 - Epoch Loss: 9498.1212 - Avg Loss: 158.3020\n",
            "Epoch [31/50] - Batch loss: 160.5447 - Epoch Loss: 9658.6659 - Avg Loss: 158.3388\n",
            "Epoch [31/50] - Batch loss: 165.8968 - Epoch Loss: 9824.5627 - Avg Loss: 158.4607\n",
            "Epoch [31/50] - Batch loss: 161.9913 - Epoch Loss: 9986.5541 - Avg Loss: 158.5167\n",
            "Epoch [31/50] - Batch loss: 158.9760 - Epoch Loss: 10145.5301 - Avg Loss: 158.5239\n",
            "Epoch [31/50] - Batch loss: 150.8038 - Epoch Loss: 10296.3339 - Avg Loss: 158.4051\n",
            "Epoch [31/50] - Batch loss: 159.1789 - Epoch Loss: 10455.5127 - Avg Loss: 158.4169\n",
            "Epoch [31/50] - Batch loss: 157.2893 - Epoch Loss: 10612.8020 - Avg Loss: 158.4000\n",
            "Epoch [31/50] - Batch loss: 155.6753 - Epoch Loss: 10768.4773 - Avg Loss: 158.3600\n",
            "Epoch [31/50] - Batch loss: 168.9843 - Epoch Loss: 10937.4616 - Avg Loss: 158.5139\n",
            "Epoch [31/50] - Batch loss: 151.6093 - Epoch Loss: 11089.0709 - Avg Loss: 158.4153\n",
            "Epoch [31/50] - Batch loss: 152.5588 - Epoch Loss: 11241.6297 - Avg Loss: 158.3328\n",
            "Epoch [31/50] - Batch loss: 155.1287 - Epoch Loss: 11396.7584 - Avg Loss: 158.2883\n",
            "Epoch [31/50] - Batch loss: 163.6030 - Epoch Loss: 11560.3614 - Avg Loss: 158.3611\n",
            "Epoch [31/50] - Batch loss: 157.1999 - Epoch Loss: 11717.5613 - Avg Loss: 158.3454\n",
            "Epoch [31/50] - Batch loss: 159.1000 - Epoch Loss: 11876.6613 - Avg Loss: 158.3555\n",
            "Epoch [31/50] - Batch loss: 158.5257 - Epoch Loss: 12035.1869 - Avg Loss: 158.3577\n",
            "Epoch [31/50] - Batch loss: 155.3279 - Epoch Loss: 12190.5148 - Avg Loss: 158.3184\n",
            "Epoch [31/50] - Batch loss: 156.7812 - Epoch Loss: 12347.2960 - Avg Loss: 158.2987\n",
            "Epoch [31/50] - Batch loss: 169.8678 - Epoch Loss: 12517.1638 - Avg Loss: 158.4451\n",
            "Epoch [31/50] - Batch loss: 163.5176 - Epoch Loss: 12680.6814 - Avg Loss: 158.5085\n",
            "Epoch [31/50] - Batch loss: 155.4648 - Epoch Loss: 12836.1462 - Avg Loss: 158.4709\n",
            "Epoch [31/50] - Batch loss: 163.1620 - Epoch Loss: 12999.3082 - Avg Loss: 158.5281\n",
            "Epoch [31/50] - Batch loss: 156.9186 - Epoch Loss: 13156.2268 - Avg Loss: 158.5088\n",
            "Epoch [31/50] - Batch loss: 160.6361 - Epoch Loss: 13316.8629 - Avg Loss: 158.5341\n",
            "Epoch [31/50] - Batch loss: 166.1241 - Epoch Loss: 13482.9870 - Avg Loss: 158.6234\n",
            "Epoch [31/50] - Batch loss: 158.7436 - Epoch Loss: 13641.7306 - Avg Loss: 158.6248\n",
            "Epoch [31/50] - Batch loss: 157.5228 - Epoch Loss: 13799.2534 - Avg Loss: 158.6121\n",
            "Epoch [31/50] - Batch loss: 154.9532 - Epoch Loss: 13954.2066 - Avg Loss: 158.5705\n",
            "Epoch [31/50] - Batch loss: 156.4618 - Epoch Loss: 14110.6684 - Avg Loss: 158.5468\n",
            "Epoch [31/50] - Batch loss: 157.0505 - Epoch Loss: 14267.7188 - Avg Loss: 158.5302\n",
            "Epoch [31/50] - Batch loss: 163.0562 - Epoch Loss: 14430.7750 - Avg Loss: 158.5799\n",
            "Epoch [31/50] - Batch loss: 161.3462 - Epoch Loss: 14592.1212 - Avg Loss: 158.6100\n",
            "Epoch [31/50] - Batch loss: 155.2341 - Epoch Loss: 14747.3554 - Avg Loss: 158.5737\n",
            "Epoch [31/50] - Batch loss: 156.0090 - Epoch Loss: 14903.3644 - Avg Loss: 158.5464\n",
            "Epoch [31/50] - Batch loss: 156.3753 - Epoch Loss: 15059.7397 - Avg Loss: 158.5236\n",
            "Epoch [31/50] - Batch loss: 159.7891 - Epoch Loss: 15219.5288 - Avg Loss: 158.5368\n",
            "Epoch [31/50] - Batch loss: 157.8512 - Epoch Loss: 15377.3800 - Avg Loss: 158.5297\n",
            "Epoch [31/50] - Batch loss: 164.4943 - Epoch Loss: 15541.8743 - Avg Loss: 158.5906\n",
            "Epoch [31/50] - Batch loss: 164.8367 - Epoch Loss: 15706.7110 - Avg Loss: 158.6536\n",
            "Epoch [31/50] - Batch loss: 159.7786 - Epoch Loss: 15866.4895 - Avg Loss: 158.6649\n",
            "Epoch [31/50] - Batch loss: 158.4519 - Epoch Loss: 16024.9415 - Avg Loss: 158.6628\n",
            "Epoch [31/50] - Batch loss: 162.0875 - Epoch Loss: 16187.0290 - Avg Loss: 158.6964\n",
            "Epoch [31/50] - Batch loss: 157.3394 - Epoch Loss: 16344.3684 - Avg Loss: 158.6832\n",
            "Epoch [31/50] - Batch loss: 157.0810 - Epoch Loss: 16501.4493 - Avg Loss: 158.6678\n",
            "Epoch [31/50] - Batch loss: 159.4198 - Epoch Loss: 16660.8691 - Avg Loss: 158.6749\n",
            "Epoch [31/50] - Batch loss: 164.0371 - Epoch Loss: 16824.9062 - Avg Loss: 158.7255\n",
            "Epoch [31/50] - Batch loss: 159.5760 - Epoch Loss: 16984.4822 - Avg Loss: 158.7335\n",
            "Epoch [31/50] - Batch loss: 154.4141 - Epoch Loss: 17138.8963 - Avg Loss: 158.6935\n",
            "Epoch [31/50] - Batch loss: 159.5704 - Epoch Loss: 17298.4667 - Avg Loss: 158.7015\n",
            "Epoch [31/50] - Batch loss: 158.4066 - Epoch Loss: 17456.8733 - Avg Loss: 158.6988\n",
            "Epoch [31/50] - Batch loss: 161.4026 - Epoch Loss: 17618.2759 - Avg Loss: 158.7232\n",
            "Epoch [31/50] - Batch loss: 165.3844 - Epoch Loss: 17783.6603 - Avg Loss: 158.7827\n",
            "Epoch [31/50] - Batch loss: 160.3540 - Epoch Loss: 17944.0143 - Avg Loss: 158.7966\n",
            "Epoch [31/50] - Batch loss: 154.0648 - Epoch Loss: 18098.0791 - Avg Loss: 158.7551\n",
            "Epoch [31/50] - Batch loss: 156.7560 - Epoch Loss: 18254.8351 - Avg Loss: 158.7377\n",
            "Epoch [31/50] - Batch loss: 155.6337 - Epoch Loss: 18410.4688 - Avg Loss: 158.7109\n",
            "Epoch [31/50] - Batch loss: 154.1352 - Epoch Loss: 18564.6040 - Avg Loss: 158.6718\n",
            "Epoch [31/50] - Batch loss: 163.5720 - Epoch Loss: 18728.1760 - Avg Loss: 158.7134\n",
            "Epoch [31/50] - Batch loss: 150.0579 - Epoch Loss: 18878.2339 - Avg Loss: 158.6406\n",
            "Epoch [31/50] - Batch loss: 168.5933 - Epoch Loss: 19046.8272 - Avg Loss: 158.7236\n",
            "Epoch [31/50] - Batch loss: 153.9526 - Epoch Loss: 19200.7798 - Avg Loss: 158.6841\n",
            "Epoch [31/50] - Batch loss: 162.8902 - Epoch Loss: 19363.6700 - Avg Loss: 158.7186\n",
            "Epoch [31/50] - Batch loss: 159.6464 - Epoch Loss: 19523.3165 - Avg Loss: 158.7262\n",
            "Epoch [31/50] - Batch loss: 170.0676 - Epoch Loss: 19693.3840 - Avg Loss: 158.8176\n",
            "Epoch [31/50] - Batch loss: 155.3443 - Epoch Loss: 19848.7283 - Avg Loss: 158.7898\n",
            "Epoch [31/50] - Batch loss: 161.9714 - Epoch Loss: 20010.6997 - Avg Loss: 158.8151\n",
            "Epoch [31/50] - Batch loss: 161.4389 - Epoch Loss: 20172.1386 - Avg Loss: 158.8357\n",
            "Epoch [31/50] - Batch loss: 165.7008 - Epoch Loss: 20337.8394 - Avg Loss: 158.8894\n",
            "Epoch [31/50] - Batch loss: 154.9490 - Epoch Loss: 20492.7884 - Avg Loss: 158.8588\n",
            "Epoch [31/50] - Batch loss: 159.5732 - Epoch Loss: 20652.3615 - Avg Loss: 158.8643\n",
            "Epoch [31/50] - Batch loss: 158.5951 - Epoch Loss: 20810.9566 - Avg Loss: 158.8623\n",
            "Epoch [31/50] - Batch loss: 163.4483 - Epoch Loss: 20974.4049 - Avg Loss: 158.8970\n",
            "Epoch [31/50] - Batch loss: 163.0855 - Epoch Loss: 21137.4904 - Avg Loss: 158.9285\n",
            "Epoch [31/50] - Batch loss: 158.0365 - Epoch Loss: 21295.5269 - Avg Loss: 158.9218\n",
            "Epoch [31/50] - Batch loss: 156.9947 - Epoch Loss: 21452.5216 - Avg Loss: 158.9076\n",
            "Epoch [31/50] - Batch loss: 156.8951 - Epoch Loss: 21609.4167 - Avg Loss: 158.8928\n",
            "Epoch [31/50] - Batch loss: 153.8628 - Epoch Loss: 21763.2795 - Avg Loss: 158.8561\n",
            "Epoch [31/50] - Batch loss: 163.2429 - Epoch Loss: 21926.5224 - Avg Loss: 158.8878\n",
            "Epoch [31/50] - Batch loss: 159.9050 - Epoch Loss: 22086.4274 - Avg Loss: 158.8952\n",
            "Epoch [31/50] - Batch loss: 167.7609 - Epoch Loss: 22254.1883 - Avg Loss: 158.9585\n",
            "Epoch [31/50] - Batch loss: 155.6217 - Epoch Loss: 22409.8100 - Avg Loss: 158.9348\n",
            "Epoch [31/50] - Batch loss: 165.6529 - Epoch Loss: 22575.4629 - Avg Loss: 158.9821\n",
            "Epoch [31/50] - Batch loss: 164.9276 - Epoch Loss: 22740.3905 - Avg Loss: 159.0237\n",
            "Epoch [31/50] - Batch loss: 163.0085 - Epoch Loss: 22903.3990 - Avg Loss: 159.0514\n",
            "Epoch [31/50] - Batch loss: 162.7466 - Epoch Loss: 23066.1456 - Avg Loss: 159.0769\n",
            "Epoch [31/50] - Batch loss: 160.1756 - Epoch Loss: 23226.3212 - Avg Loss: 159.0844\n",
            "Epoch [31/50] - Batch loss: 154.2596 - Epoch Loss: 23380.5808 - Avg Loss: 159.0516\n",
            "Epoch [31/50] - Batch loss: 154.4134 - Epoch Loss: 23534.9941 - Avg Loss: 159.0202\n",
            "Epoch [31/50] - Batch loss: 154.7799 - Epoch Loss: 23689.7741 - Avg Loss: 158.9918\n",
            "Epoch [31/50] - Batch loss: 157.5725 - Epoch Loss: 23847.3466 - Avg Loss: 158.9823\n",
            "Epoch [31/50] - Batch loss: 158.3248 - Epoch Loss: 24005.6713 - Avg Loss: 158.9780\n",
            "Epoch [31/50] - Batch loss: 156.6518 - Epoch Loss: 24162.3231 - Avg Loss: 158.9627\n",
            "Epoch [31/50] - Batch loss: 163.7728 - Epoch Loss: 24326.0959 - Avg Loss: 158.9941\n",
            "Epoch [31/50] - Batch loss: 157.1169 - Epoch Loss: 24483.2128 - Avg Loss: 158.9819\n",
            "Epoch [31/50] - Batch loss: 161.3298 - Epoch Loss: 24644.5426 - Avg Loss: 158.9970\n",
            "Epoch [31/50] - Batch loss: 160.7311 - Epoch Loss: 24805.2737 - Avg Loss: 159.0082\n",
            "Epoch [31/50] - Batch loss: 158.7861 - Epoch Loss: 24964.0598 - Avg Loss: 159.0068\n",
            "Epoch [31/50] - Batch loss: 158.0525 - Epoch Loss: 25122.1123 - Avg Loss: 159.0007\n",
            "Epoch [31/50] - Batch loss: 154.9098 - Epoch Loss: 25277.0221 - Avg Loss: 158.9750\n",
            "Epoch [31/50] - Batch loss: 157.2306 - Epoch Loss: 25434.2527 - Avg Loss: 158.9641\n",
            "Epoch [31/50] - Batch loss: 157.2189 - Epoch Loss: 25591.4716 - Avg Loss: 158.9532\n",
            "Epoch [31/50] - Batch loss: 151.8270 - Epoch Loss: 25743.2986 - Avg Loss: 158.9093\n",
            "Epoch [31/50] - Batch loss: 165.7180 - Epoch Loss: 25909.0166 - Avg Loss: 158.9510\n",
            "Epoch [31/50] - Batch loss: 156.7198 - Epoch Loss: 26065.7365 - Avg Loss: 158.9374\n",
            "Epoch [31/50] - Batch loss: 159.8626 - Epoch Loss: 26225.5991 - Avg Loss: 158.9430\n",
            "Epoch [31/50] - Batch loss: 162.1429 - Epoch Loss: 26387.7420 - Avg Loss: 158.9623\n",
            "Epoch [31/50] - Batch loss: 159.5919 - Epoch Loss: 26547.3339 - Avg Loss: 158.9661\n",
            "Epoch [31/50] - Batch loss: 160.7930 - Epoch Loss: 26708.1270 - Avg Loss: 158.9769\n",
            "Epoch [31/50] - Batch loss: 158.3991 - Epoch Loss: 26866.5261 - Avg Loss: 158.9735\n",
            "Epoch [31/50] - Batch loss: 154.4402 - Epoch Loss: 27020.9663 - Avg Loss: 158.9469\n",
            "Epoch [31/50] - Batch loss: 160.5825 - Epoch Loss: 27181.5488 - Avg Loss: 158.9564\n",
            "Epoch [31/50] - Batch loss: 158.1521 - Epoch Loss: 27339.7010 - Avg Loss: 158.9517\n",
            "Epoch [31/50] - Batch loss: 159.5988 - Epoch Loss: 27499.2997 - Avg Loss: 158.9555\n",
            "Epoch [31/50] - Batch loss: 161.9289 - Epoch Loss: 27661.2287 - Avg Loss: 158.9726\n",
            "Epoch [31/50] - Batch loss: 161.5549 - Epoch Loss: 27822.7836 - Avg Loss: 158.9873\n",
            "Epoch [31/50] - Batch loss: 158.1370 - Epoch Loss: 27980.9206 - Avg Loss: 158.9825\n",
            "Epoch [31/50] - Batch loss: 157.7434 - Epoch Loss: 28138.6640 - Avg Loss: 158.9755\n",
            "Epoch [31/50] - Batch loss: 156.0827 - Epoch Loss: 28294.7468 - Avg Loss: 158.9593\n",
            "Epoch [31/50] - Batch loss: 157.9422 - Epoch Loss: 28452.6890 - Avg Loss: 158.9536\n",
            "Epoch [31/50] - Batch loss: 150.9323 - Epoch Loss: 28603.6213 - Avg Loss: 158.9090\n",
            "Epoch [31/50] - Batch loss: 154.6217 - Epoch Loss: 28758.2430 - Avg Loss: 158.8853\n",
            "Epoch [31/50] - Batch loss: 165.4818 - Epoch Loss: 28923.7248 - Avg Loss: 158.9216\n",
            "Epoch [31/50] - Batch loss: 166.4240 - Epoch Loss: 29090.1488 - Avg Loss: 158.9626\n",
            "Epoch [31/50] - Batch loss: 159.6609 - Epoch Loss: 29249.8098 - Avg Loss: 158.9664\n",
            "Epoch [31/50] - Batch loss: 169.2144 - Epoch Loss: 29419.0241 - Avg Loss: 159.0218\n",
            "Epoch [31/50] - Batch loss: 158.7242 - Epoch Loss: 29577.7483 - Avg Loss: 159.0202\n",
            "Epoch [31/50] - Batch loss: 155.7744 - Epoch Loss: 29733.5227 - Avg Loss: 159.0028\n",
            "Epoch [31/50] - Batch loss: 165.7813 - Epoch Loss: 29899.3040 - Avg Loss: 159.0389\n",
            "Epoch [31/50] - Batch loss: 161.3065 - Epoch Loss: 30060.6105 - Avg Loss: 159.0508\n",
            "Epoch [31/50] - Batch loss: 158.5168 - Epoch Loss: 30219.1273 - Avg Loss: 159.0480\n",
            "Epoch [31/50] - Batch loss: 162.0458 - Epoch Loss: 30381.1731 - Avg Loss: 159.0637\n",
            "Epoch [31/50] - Batch loss: 176.1137 - Epoch Loss: 30557.2868 - Avg Loss: 159.1525\n",
            "Epoch [31/50] - Batch loss: 170.0206 - Epoch Loss: 30727.3074 - Avg Loss: 159.2088\n",
            "Epoch [31/50] - Batch loss: 163.2091 - Epoch Loss: 30890.5165 - Avg Loss: 159.2295\n",
            "Epoch [31/50] - Batch loss: 156.7549 - Epoch Loss: 31047.2714 - Avg Loss: 159.2168\n",
            "Epoch [31/50] - Batch loss: 167.8447 - Epoch Loss: 31215.1161 - Avg Loss: 159.2608\n",
            "Epoch [31/50] - Batch loss: 166.4212 - Epoch Loss: 31381.5373 - Avg Loss: 159.2971\n",
            "Epoch [31/50] - Batch loss: 168.8253 - Epoch Loss: 31550.3626 - Avg Loss: 159.3453\n",
            "Epoch [31/50] - Batch loss: 161.6874 - Epoch Loss: 31712.0500 - Avg Loss: 159.3570\n",
            "Epoch [31/50] - Batch loss: 157.3113 - Epoch Loss: 31869.3612 - Avg Loss: 159.3468\n",
            "Epoch [31/50] - Batch loss: 161.7952 - Epoch Loss: 32031.1565 - Avg Loss: 159.3590\n",
            "Epoch [31/50] - Batch loss: 161.8201 - Epoch Loss: 32192.9766 - Avg Loss: 159.3712\n",
            "Epoch [31/50] - Batch loss: 165.2072 - Epoch Loss: 32358.1837 - Avg Loss: 159.3999\n",
            "Epoch [31/50] - Batch loss: 165.5369 - Epoch Loss: 32523.7207 - Avg Loss: 159.4300\n",
            "Epoch [31/50] - Batch loss: 157.3346 - Epoch Loss: 32681.0552 - Avg Loss: 159.4198\n",
            "Epoch [31/50] - Batch loss: 159.1701 - Epoch Loss: 32840.2254 - Avg Loss: 159.4186\n",
            "Epoch [31/50] - Batch loss: 164.6837 - Epoch Loss: 33004.9091 - Avg Loss: 159.4440\n",
            "Epoch [31/50] - Batch loss: 162.8139 - Epoch Loss: 33167.7229 - Avg Loss: 159.4602\n",
            "Epoch [31/50] - Batch loss: 158.2597 - Epoch Loss: 33325.9827 - Avg Loss: 159.4545\n",
            "Epoch [31/50] - Batch loss: 164.7941 - Epoch Loss: 33490.7768 - Avg Loss: 159.4799\n",
            "Epoch [31/50] - Batch loss: 167.3145 - Epoch Loss: 33658.0913 - Avg Loss: 159.5170\n",
            "Epoch [31/50] - Batch loss: 161.8684 - Epoch Loss: 33819.9597 - Avg Loss: 159.5281\n",
            "Epoch [31/50] - Batch loss: 157.4283 - Epoch Loss: 33977.3881 - Avg Loss: 159.5183\n",
            "Epoch [31/50] - Batch loss: 157.4441 - Epoch Loss: 34134.8322 - Avg Loss: 159.5086\n",
            "Epoch [31/50] - Batch loss: 156.1115 - Epoch Loss: 34290.9437 - Avg Loss: 159.4928\n",
            "Epoch [31/50] - Batch loss: 166.5426 - Epoch Loss: 34457.4863 - Avg Loss: 159.5254\n",
            "Epoch [31/50] - Batch loss: 161.3329 - Epoch Loss: 34618.8193 - Avg Loss: 159.5337\n",
            "Epoch [31/50] - Batch loss: 162.6040 - Epoch Loss: 34781.4233 - Avg Loss: 159.5478\n",
            "Epoch [31/50] - Batch loss: 164.3602 - Epoch Loss: 34945.7835 - Avg Loss: 159.5698\n",
            "Epoch [31/50] - Batch loss: 163.8320 - Epoch Loss: 35109.6154 - Avg Loss: 159.5892\n",
            "Epoch [31/50] - Batch loss: 165.7445 - Epoch Loss: 35275.3600 - Avg Loss: 159.6170\n",
            "Epoch [31/50] - Batch loss: 153.5988 - Epoch Loss: 35428.9588 - Avg Loss: 159.5899\n",
            "Epoch [31/50] - Batch loss: 154.6926 - Epoch Loss: 35583.6514 - Avg Loss: 159.5679\n",
            "Epoch [31/50] - Batch loss: 162.4204 - Epoch Loss: 35746.0717 - Avg Loss: 159.5807\n",
            "Epoch [31/50] - Batch loss: 148.0834 - Epoch Loss: 35894.1551 - Avg Loss: 159.5296\n",
            "Epoch [31/50] - Batch loss: 163.6651 - Epoch Loss: 36057.8202 - Avg Loss: 159.5479\n",
            "Epoch [31/50] - Batch loss: 158.5576 - Epoch Loss: 36216.3778 - Avg Loss: 159.5435\n",
            "Epoch [31/50] - Batch loss: 158.2581 - Epoch Loss: 36374.6359 - Avg Loss: 159.5379\n",
            "Epoch [31/50] - Batch loss: 162.2262 - Epoch Loss: 36536.8622 - Avg Loss: 159.5496\n",
            "Epoch [31/50] - Batch loss: 159.7873 - Epoch Loss: 36696.6494 - Avg Loss: 159.5506\n",
            "Epoch [31/50] - Batch loss: 160.1452 - Epoch Loss: 36856.7947 - Avg Loss: 159.5532\n",
            "Epoch [31/50] - Batch loss: 162.9147 - Epoch Loss: 37019.7094 - Avg Loss: 159.5677\n",
            "Epoch [31/50] - Batch loss: 163.9155 - Epoch Loss: 37183.6249 - Avg Loss: 159.5864\n",
            "Epoch [31/50] - Batch loss: 155.5176 - Epoch Loss: 37339.1425 - Avg Loss: 159.5690\n",
            "Epoch [31/50] - Batch loss: 162.7819 - Epoch Loss: 37501.9244 - Avg Loss: 159.5827\n",
            "Epoch [31/50] - Batch loss: 157.0455 - Epoch Loss: 37658.9698 - Avg Loss: 159.5719\n",
            "Epoch [31/50] - Batch loss: 162.8579 - Epoch Loss: 37821.8277 - Avg Loss: 159.5858\n",
            "Epoch [31/50] - Batch loss: 158.9888 - Epoch Loss: 37980.8165 - Avg Loss: 159.5833\n",
            "Epoch [31/50] - Batch loss: 161.4768 - Epoch Loss: 38142.2933 - Avg Loss: 159.5912\n",
            "Epoch [31/50] - Batch loss: 158.9289 - Epoch Loss: 38301.2221 - Avg Loss: 159.5884\n",
            "Epoch [31/50] - Batch loss: 157.2911 - Epoch Loss: 38458.5132 - Avg Loss: 159.5789\n",
            "Epoch [31/50] - Batch loss: 161.0967 - Epoch Loss: 38619.6099 - Avg Loss: 159.5852\n",
            "Epoch [31/50] - Batch loss: 161.1615 - Epoch Loss: 38780.7714 - Avg Loss: 159.5917\n",
            "Epoch [31/50] - Batch loss: 155.2043 - Epoch Loss: 38935.9757 - Avg Loss: 159.5737\n",
            "Epoch [31/50] - Batch loss: 168.1961 - Epoch Loss: 39104.1718 - Avg Loss: 159.6089\n",
            "Epoch [31/50] - Batch loss: 156.2600 - Epoch Loss: 39260.4318 - Avg Loss: 159.5953\n",
            "Epoch [31/50] - Batch loss: 161.0163 - Epoch Loss: 39421.4480 - Avg Loss: 159.6010\n",
            "Epoch [31/50] - Batch loss: 155.1493 - Epoch Loss: 39576.5973 - Avg Loss: 159.5831\n",
            "Epoch [31/50] - Batch loss: 163.5870 - Epoch Loss: 39740.1843 - Avg Loss: 159.5991\n",
            "Epoch [31/50] - Batch loss: 154.1166 - Epoch Loss: 39894.3009 - Avg Loss: 159.5772\n",
            "Epoch [31/50] - Batch loss: 153.9989 - Epoch Loss: 40048.2999 - Avg Loss: 159.5550\n",
            "Epoch [31/50] - Batch loss: 159.0148 - Epoch Loss: 40207.3146 - Avg Loss: 159.5528\n",
            "Epoch [31/50] - Batch loss: 164.1440 - Epoch Loss: 40371.4586 - Avg Loss: 159.5710\n",
            "Epoch [31/50] - Batch loss: 158.4337 - Epoch Loss: 40529.8924 - Avg Loss: 159.5665\n",
            "Epoch [31/50] - Batch loss: 159.6623 - Epoch Loss: 40689.5547 - Avg Loss: 159.5669\n",
            "Epoch [31/50] - Batch loss: 162.4867 - Epoch Loss: 40852.0414 - Avg Loss: 159.5783\n",
            "Epoch [31/50] - Batch loss: 167.1401 - Epoch Loss: 41019.1815 - Avg Loss: 159.6077\n",
            "Epoch [31/50] - Batch loss: 154.6496 - Epoch Loss: 41173.8311 - Avg Loss: 159.5885\n",
            "Epoch [31/50] - Batch loss: 163.0602 - Epoch Loss: 41336.8914 - Avg Loss: 159.6019\n",
            "Epoch [31/50] - Batch loss: 158.8438 - Epoch Loss: 41495.7352 - Avg Loss: 159.5990\n",
            "Epoch [31/50] - Batch loss: 161.4733 - Epoch Loss: 41657.2085 - Avg Loss: 159.6062\n",
            "Epoch [31/50] - Batch loss: 162.6726 - Epoch Loss: 41819.8811 - Avg Loss: 159.6179\n",
            "Epoch [31/50] - Batch loss: 154.7805 - Epoch Loss: 41974.6616 - Avg Loss: 159.5995\n",
            "Epoch [31/50] - Batch loss: 169.0562 - Epoch Loss: 42143.7178 - Avg Loss: 159.6353\n",
            "Epoch [31/50] - Batch loss: 157.9608 - Epoch Loss: 42301.6787 - Avg Loss: 159.6290\n",
            "Epoch [31/50] - Batch loss: 168.9441 - Epoch Loss: 42470.6228 - Avg Loss: 159.6640\n",
            "Epoch [31/50] - Batch loss: 164.0918 - Epoch Loss: 42634.7146 - Avg Loss: 159.6806\n",
            "Epoch [31/50] - Batch loss: 163.3568 - Epoch Loss: 42798.0715 - Avg Loss: 159.6943\n",
            "Epoch [31/50] - Batch loss: 162.0941 - Epoch Loss: 42960.1656 - Avg Loss: 159.7032\n",
            "Epoch [31/50] - Batch loss: 158.7379 - Epoch Loss: 43118.9035 - Avg Loss: 159.6996\n",
            "Epoch [31/50] - Batch loss: 159.4023 - Epoch Loss: 43278.3058 - Avg Loss: 159.6985\n",
            "Epoch [31/50] - Batch loss: 158.6254 - Epoch Loss: 43436.9312 - Avg Loss: 159.6946\n",
            "Epoch [31/50] - Batch loss: 157.7924 - Epoch Loss: 43594.7236 - Avg Loss: 159.6876\n",
            "Epoch [31/50] - Batch loss: 158.6013 - Epoch Loss: 43753.3249 - Avg Loss: 159.6837\n",
            "Epoch [31/50] - Batch loss: 162.6411 - Epoch Loss: 43915.9660 - Avg Loss: 159.6944\n",
            "Epoch [31/50] - Batch loss: 163.8482 - Epoch Loss: 44079.8142 - Avg Loss: 159.7095\n",
            "Epoch [31/50] - Batch loss: 158.8457 - Epoch Loss: 44238.6599 - Avg Loss: 159.7064\n",
            "Epoch [31/50] - Batch loss: 154.5581 - Epoch Loss: 44393.2181 - Avg Loss: 159.6878\n",
            "Epoch [31/50] - Batch loss: 155.5139 - Epoch Loss: 44548.7320 - Avg Loss: 159.6729\n",
            "Epoch [31/50] - Batch loss: 156.3969 - Epoch Loss: 44705.1289 - Avg Loss: 159.6612\n",
            "Epoch [31/50] - Batch loss: 164.7605 - Epoch Loss: 44869.8895 - Avg Loss: 159.6793\n",
            "Epoch [31/50] - Batch loss: 168.9725 - Epoch Loss: 45038.8620 - Avg Loss: 159.7123\n",
            "Epoch [31/50] - Batch loss: 162.7718 - Epoch Loss: 45201.6338 - Avg Loss: 159.7231\n",
            "Epoch [31/50] - Batch loss: 153.9830 - Epoch Loss: 45355.6168 - Avg Loss: 159.7029\n",
            "Epoch [31/50] - Batch loss: 160.2524 - Epoch Loss: 45515.8692 - Avg Loss: 159.7048\n",
            "Epoch [31/50] - Batch loss: 161.0463 - Epoch Loss: 45676.9155 - Avg Loss: 159.7095\n",
            "Epoch [31/50] - Batch loss: 161.1160 - Epoch Loss: 45838.0314 - Avg Loss: 159.7144\n",
            "Epoch [31/50] - Batch loss: 155.1203 - Epoch Loss: 45993.1517 - Avg Loss: 159.6984\n",
            "Epoch [31/50] - Batch loss: 156.1595 - Epoch Loss: 46149.3112 - Avg Loss: 159.6862\n",
            "Epoch [31/50] - Batch loss: 162.6416 - Epoch Loss: 46311.9529 - Avg Loss: 159.6964\n",
            "Epoch [31/50] - Batch loss: 157.9425 - Epoch Loss: 46469.8953 - Avg Loss: 159.6904\n",
            "Epoch [31/50] - Batch loss: 155.7068 - Epoch Loss: 46625.6021 - Avg Loss: 159.6767\n",
            "Epoch [31/50] - Batch loss: 157.9544 - Epoch Loss: 46783.5565 - Avg Loss: 159.6708\n",
            "Epoch [31/50] - Batch loss: 165.6796 - Epoch Loss: 46949.2361 - Avg Loss: 159.6913\n",
            "Epoch [31/50] - Batch loss: 162.2980 - Epoch Loss: 47111.5340 - Avg Loss: 159.7001\n",
            "Epoch [31/50] - Batch loss: 160.0547 - Epoch Loss: 47271.5888 - Avg Loss: 159.7013\n",
            "Epoch [31/50] - Batch loss: 156.4872 - Epoch Loss: 47428.0760 - Avg Loss: 159.6905\n",
            "Epoch [31/50] - Batch loss: 159.7861 - Epoch Loss: 47587.8620 - Avg Loss: 159.6908\n",
            "Epoch [31/50] - Batch loss: 158.0497 - Epoch Loss: 47745.9117 - Avg Loss: 159.6853\n",
            "Epoch [31/50] - Batch loss: 154.9831 - Epoch Loss: 47900.8948 - Avg Loss: 159.6696\n",
            "Epoch [31/50] - Batch loss: 158.3552 - Epoch Loss: 48059.2500 - Avg Loss: 159.6653\n",
            "Epoch [31/50] - Batch loss: 156.4889 - Epoch Loss: 48215.7388 - Avg Loss: 159.6548\n",
            "Epoch [31/50] - Batch loss: 158.8454 - Epoch Loss: 48374.5842 - Avg Loss: 159.6521\n",
            "Epoch [31/50] - Batch loss: 164.8275 - Epoch Loss: 48539.4117 - Avg Loss: 159.6691\n",
            "Epoch [31/50] - Batch loss: 161.4808 - Epoch Loss: 48700.8925 - Avg Loss: 159.6751\n",
            "Epoch [31/50] - Batch loss: 169.8600 - Epoch Loss: 48870.7526 - Avg Loss: 159.7083\n",
            "Epoch [31/50] - Batch loss: 164.7765 - Epoch Loss: 49035.5291 - Avg Loss: 159.7249\n",
            "Epoch [31/50] - Batch loss: 160.7904 - Epoch Loss: 49196.3195 - Avg Loss: 159.7283\n",
            "Epoch [31/50] - Batch loss: 158.8639 - Epoch Loss: 49355.1834 - Avg Loss: 159.7255\n",
            "Epoch [31/50] - Batch loss: 162.5301 - Epoch Loss: 49517.7135 - Avg Loss: 159.7346\n",
            "Epoch [31/50] - Batch loss: 162.1937 - Epoch Loss: 49679.9072 - Avg Loss: 159.7425\n",
            "Epoch [31/50] - Batch loss: 147.4082 - Epoch Loss: 49827.3154 - Avg Loss: 159.7029\n",
            "Epoch [31/50] - Batch loss: 156.2668 - Epoch Loss: 49983.5822 - Avg Loss: 159.6920\n",
            "Epoch [31/50] - Batch loss: 164.6796 - Epoch Loss: 50148.2618 - Avg Loss: 159.7078\n",
            "Epoch [31/50] - Batch loss: 159.6878 - Epoch Loss: 50307.9496 - Avg Loss: 159.7078\n",
            "Epoch [31/50] - Batch loss: 160.7991 - Epoch Loss: 50468.7487 - Avg Loss: 159.7112\n",
            "Epoch [31/50] - Batch loss: 161.0760 - Epoch Loss: 50629.8247 - Avg Loss: 159.7155\n",
            "Epoch [31/50] - Batch loss: 161.2756 - Epoch Loss: 50791.1003 - Avg Loss: 159.7204\n",
            "Epoch [31/50] - Batch loss: 166.1027 - Epoch Loss: 50957.2030 - Avg Loss: 159.7404\n",
            "Epoch [31/50] - Batch loss: 158.6933 - Epoch Loss: 51115.8963 - Avg Loss: 159.7372\n",
            "Epoch [31/50] - Batch loss: 151.2545 - Epoch Loss: 51267.1508 - Avg Loss: 159.7108\n",
            "Epoch [31/50] - Batch loss: 164.7932 - Epoch Loss: 51431.9439 - Avg Loss: 159.7265\n",
            "Epoch [31/50] - Batch loss: 155.9909 - Epoch Loss: 51587.9348 - Avg Loss: 159.7150\n",
            "Epoch [31/50] - Batch loss: 158.7596 - Epoch Loss: 51746.6944 - Avg Loss: 159.7120\n",
            "Epoch [31/50] - Batch loss: 156.3336 - Epoch Loss: 51903.0279 - Avg Loss: 159.7016\n",
            "Epoch [31/50] - Batch loss: 154.7327 - Epoch Loss: 52057.7606 - Avg Loss: 159.6864\n",
            "Epoch [31/50] - Batch loss: 158.5633 - Epoch Loss: 52216.3239 - Avg Loss: 159.6829\n",
            "Epoch [31/50] - Batch loss: 164.3842 - Epoch Loss: 52380.7081 - Avg Loss: 159.6973\n",
            "Epoch [31/50] - Batch loss: 168.7346 - Epoch Loss: 52549.4427 - Avg Loss: 159.7247\n",
            "Epoch [31/50] - Batch loss: 162.9660 - Epoch Loss: 52712.4087 - Avg Loss: 159.7346\n",
            "Epoch [31/50] - Batch loss: 161.0454 - Epoch Loss: 52873.4542 - Avg Loss: 159.7385\n",
            "Epoch [31/50] - Batch loss: 157.1650 - Epoch Loss: 53030.6192 - Avg Loss: 159.7308\n",
            "Epoch [31/50] - Batch loss: 165.2924 - Epoch Loss: 53195.9116 - Avg Loss: 159.7475\n",
            "Epoch [31/50] - Batch loss: 159.8109 - Epoch Loss: 53355.7225 - Avg Loss: 159.7477\n",
            "Epoch [31/50] - Batch loss: 159.4983 - Epoch Loss: 53515.2207 - Avg Loss: 159.7469\n",
            "Epoch [31/50] - Batch loss: 159.8380 - Epoch Loss: 53675.0588 - Avg Loss: 159.7472\n",
            "Epoch [31/50] - Batch loss: 150.4071 - Epoch Loss: 53825.4658 - Avg Loss: 159.7195\n",
            "Epoch [31/50] - Batch loss: 162.7491 - Epoch Loss: 53988.2150 - Avg Loss: 159.7284\n",
            "Epoch [31/50] - Batch loss: 151.4968 - Epoch Loss: 54139.7118 - Avg Loss: 159.7042\n",
            "Epoch [31/50] - Batch loss: 160.1695 - Epoch Loss: 54299.8813 - Avg Loss: 159.7055\n",
            "Epoch [31/50] - Batch loss: 158.3345 - Epoch Loss: 54458.2158 - Avg Loss: 159.7015\n",
            "Epoch [31/50] - Batch loss: 154.5242 - Epoch Loss: 54612.7400 - Avg Loss: 159.6864\n",
            "Epoch [31/50] - Batch loss: 159.4135 - Epoch Loss: 54772.1535 - Avg Loss: 159.6856\n",
            "Epoch [31/50] - Batch loss: 159.6668 - Epoch Loss: 54931.8204 - Avg Loss: 159.6855\n",
            "Epoch [31/50] - Batch loss: 166.6191 - Epoch Loss: 55098.4395 - Avg Loss: 159.7056\n",
            "Epoch [31/50] - Batch loss: 155.3843 - Epoch Loss: 55253.8238 - Avg Loss: 159.6931\n",
            "Epoch [31/50] - Batch loss: 158.7853 - Epoch Loss: 55412.6092 - Avg Loss: 159.6905\n",
            "Epoch [31/50] - Batch loss: 158.1080 - Epoch Loss: 55570.7171 - Avg Loss: 159.6860\n",
            "Epoch [31/50] - Batch loss: 161.3741 - Epoch Loss: 55732.0912 - Avg Loss: 159.6908\n",
            "Epoch [31/50] - Batch loss: 162.2799 - Epoch Loss: 55894.3711 - Avg Loss: 159.6982\n",
            "Epoch [31/50] - Batch loss: 159.2697 - Epoch Loss: 56053.6408 - Avg Loss: 159.6970\n",
            "Epoch [31/50] - Batch loss: 166.2529 - Epoch Loss: 56219.8937 - Avg Loss: 159.7156\n",
            "Epoch [31/50] - Batch loss: 165.9881 - Epoch Loss: 56385.8818 - Avg Loss: 159.7334\n",
            "Epoch [31/50] - Batch loss: 160.6380 - Epoch Loss: 56546.5198 - Avg Loss: 159.7359\n",
            "Epoch [31/50] - Batch loss: 164.5613 - Epoch Loss: 56711.0811 - Avg Loss: 159.7495\n",
            "Epoch [31/50] - Batch loss: 159.5895 - Epoch Loss: 56870.6705 - Avg Loss: 159.7491\n",
            "Epoch [31/50] - Batch loss: 154.2114 - Epoch Loss: 57024.8819 - Avg Loss: 159.7336\n",
            "Epoch [31/50] - Batch loss: 159.6555 - Epoch Loss: 57184.5374 - Avg Loss: 159.7333\n",
            "Epoch [31/50] - Batch loss: 161.9049 - Epoch Loss: 57346.4423 - Avg Loss: 159.7394\n",
            "Epoch [31/50] - Batch loss: 158.6076 - Epoch Loss: 57505.0500 - Avg Loss: 159.7362\n",
            "Epoch [31/50] - Batch loss: 158.8665 - Epoch Loss: 57663.9165 - Avg Loss: 159.7338\n",
            "Epoch [31/50] - Batch loss: 162.6826 - Epoch Loss: 57826.5991 - Avg Loss: 159.7420\n",
            "Epoch [31/50] - Batch loss: 168.4712 - Epoch Loss: 57995.0703 - Avg Loss: 159.7660\n",
            "Epoch [31/50] - Batch loss: 160.8892 - Epoch Loss: 58155.9595 - Avg Loss: 159.7691\n",
            "Epoch [31/50] - Batch loss: 156.8136 - Epoch Loss: 58312.7730 - Avg Loss: 159.7610\n",
            "Epoch [31/50] - Batch loss: 155.0274 - Epoch Loss: 58467.8004 - Avg Loss: 159.7481\n",
            "Epoch [31/50] - Batch loss: 154.8978 - Epoch Loss: 58622.6983 - Avg Loss: 159.7349\n",
            "Epoch [31/50] - Batch loss: 157.0937 - Epoch Loss: 58779.7920 - Avg Loss: 159.7277\n",
            "Epoch [31/50] - Batch loss: 161.9775 - Epoch Loss: 58941.7695 - Avg Loss: 159.7338\n",
            "Epoch [31/50] - Batch loss: 155.5296 - Epoch Loss: 59097.2990 - Avg Loss: 159.7224\n",
            "Epoch [31/50] - Batch loss: 162.8770 - Epoch Loss: 59260.1760 - Avg Loss: 159.7309\n",
            "Epoch [31/50] - Batch loss: 157.1392 - Epoch Loss: 59417.3152 - Avg Loss: 159.7240\n",
            "Epoch [31/50] - Batch loss: 160.1077 - Epoch Loss: 59577.4230 - Avg Loss: 159.7250\n",
            "Epoch [31/50] - Batch loss: 162.7104 - Epoch Loss: 59740.1334 - Avg Loss: 159.7330\n",
            "Epoch [31/50] - Batch loss: 159.1770 - Epoch Loss: 59899.3104 - Avg Loss: 159.7315\n",
            "Epoch [31/50] - Batch loss: 162.8362 - Epoch Loss: 60062.1466 - Avg Loss: 159.7398\n",
            "Epoch [31/50] - Batch loss: 156.6434 - Epoch Loss: 60218.7901 - Avg Loss: 159.7315\n",
            "Epoch [31/50] - Batch loss: 151.8197 - Epoch Loss: 60370.6097 - Avg Loss: 159.7106\n",
            "Epoch [31/50] - Batch loss: 160.5082 - Epoch Loss: 60531.1179 - Avg Loss: 159.7127\n",
            "Epoch [31/50] - Batch loss: 156.2786 - Epoch Loss: 60687.3965 - Avg Loss: 159.7037\n",
            "Epoch [31/50] - Batch loss: 152.6655 - Epoch Loss: 60840.0620 - Avg Loss: 159.6852\n",
            "Epoch [31/50] - Batch loss: 168.2985 - Epoch Loss: 61008.3606 - Avg Loss: 159.7078\n",
            "Epoch [31/50] - Batch loss: 151.4008 - Epoch Loss: 61159.7614 - Avg Loss: 159.6861\n",
            "Epoch [31/50] - Batch loss: 163.2650 - Epoch Loss: 61323.0264 - Avg Loss: 159.6954\n",
            "Epoch [31/50] - Batch loss: 170.9277 - Epoch Loss: 61493.9541 - Avg Loss: 159.7246\n",
            "Epoch [31/50] - Batch loss: 170.1971 - Epoch Loss: 61664.1512 - Avg Loss: 159.7517\n",
            "Epoch [31/50] - Batch loss: 153.9736 - Epoch Loss: 61818.1247 - Avg Loss: 159.7368\n",
            "Epoch [31/50] - Batch loss: 157.8844 - Epoch Loss: 61976.0092 - Avg Loss: 159.7320\n",
            "Epoch [31/50] - Batch loss: 156.4636 - Epoch Loss: 62132.4728 - Avg Loss: 159.7236\n",
            "Epoch [31/50] - Batch loss: 159.1919 - Epoch Loss: 62291.6646 - Avg Loss: 159.7222\n",
            "Epoch [31/50] - Batch loss: 158.2750 - Epoch Loss: 62449.9396 - Avg Loss: 159.7185\n",
            "Epoch [31/50] - Batch loss: 161.7603 - Epoch Loss: 62611.7000 - Avg Loss: 159.7237\n",
            "Epoch [31/50] - Batch loss: 165.3742 - Epoch Loss: 62777.0742 - Avg Loss: 159.7381\n",
            "Epoch [31/50] - Batch loss: 156.8862 - Epoch Loss: 62933.9603 - Avg Loss: 159.7309\n",
            "Epoch [31/50] - Batch loss: 167.0955 - Epoch Loss: 63101.0558 - Avg Loss: 159.7495\n",
            "Epoch [31/50] - Batch loss: 167.4268 - Epoch Loss: 63268.4826 - Avg Loss: 159.7689\n",
            "Epoch [31/50] - Batch loss: 160.0991 - Epoch Loss: 63428.5817 - Avg Loss: 159.7697\n",
            "Epoch [31/50] - Batch loss: 163.7829 - Epoch Loss: 63592.3646 - Avg Loss: 159.7798\n",
            "Epoch [31/50] - Batch loss: 155.1826 - Epoch Loss: 63747.5472 - Avg Loss: 159.7683\n",
            "Epoch [31/50] - Batch loss: 150.3786 - Epoch Loss: 63897.9258 - Avg Loss: 159.7448\n",
            "Epoch [31/50] - Batch loss: 155.6720 - Epoch Loss: 64053.5978 - Avg Loss: 159.7347\n",
            "Epoch [31/50] - Batch loss: 154.0489 - Epoch Loss: 64207.6468 - Avg Loss: 159.7205\n",
            "Epoch [31/50] - Batch loss: 157.5480 - Epoch Loss: 64365.1948 - Avg Loss: 159.7151\n",
            "Epoch [31/50] - Batch loss: 157.2166 - Epoch Loss: 64522.4114 - Avg Loss: 159.7089\n",
            "Epoch [31/50] - Batch loss: 157.9899 - Epoch Loss: 64680.4013 - Avg Loss: 159.7047\n",
            "Epoch [31/50] - Batch loss: 161.6856 - Epoch Loss: 64842.0869 - Avg Loss: 159.7096\n",
            "Epoch [31/50] - Batch loss: 168.2272 - Epoch Loss: 65010.3141 - Avg Loss: 159.7305\n",
            "Epoch [31/50] - Batch loss: 159.1164 - Epoch Loss: 65169.4305 - Avg Loss: 159.7290\n",
            "Epoch [31/50] - Batch loss: 155.9513 - Epoch Loss: 65325.3818 - Avg Loss: 159.7198\n",
            "Epoch [31/50] - Batch loss: 152.3868 - Epoch Loss: 65477.7685 - Avg Loss: 159.7019\n",
            "Epoch [31/50] - Batch loss: 158.6861 - Epoch Loss: 65636.4546 - Avg Loss: 159.6994\n",
            "Epoch [31/50] - Batch loss: 171.0288 - Epoch Loss: 65807.4834 - Avg Loss: 159.7269\n",
            "Epoch [31/50] - Batch loss: 164.2252 - Epoch Loss: 65971.7086 - Avg Loss: 159.7378\n",
            "Epoch [31/50] - Batch loss: 151.9753 - Epoch Loss: 66123.6839 - Avg Loss: 159.7190\n",
            "Epoch [31/50] - Batch loss: 164.4561 - Epoch Loss: 66288.1400 - Avg Loss: 159.7305\n",
            "Epoch [31/50] - Batch loss: 159.2050 - Epoch Loss: 66447.3451 - Avg Loss: 159.7292\n",
            "Epoch [31/50] - Batch loss: 155.4620 - Epoch Loss: 66602.8070 - Avg Loss: 159.7190\n",
            "Epoch [31/50] - Batch loss: 158.6716 - Epoch Loss: 66761.4786 - Avg Loss: 159.7165\n",
            "Epoch [31/50] - Batch loss: 168.8779 - Epoch Loss: 66930.3565 - Avg Loss: 159.7383\n",
            "Epoch [31/50] - Batch loss: 166.6634 - Epoch Loss: 67097.0199 - Avg Loss: 159.7548\n",
            "Epoch [31/50] - Batch loss: 170.9654 - Epoch Loss: 67267.9853 - Avg Loss: 159.7814\n",
            "Epoch [31/50] - Batch loss: 159.5667 - Epoch Loss: 67427.5520 - Avg Loss: 159.7809\n",
            "Epoch [31/50] - Batch loss: 165.8720 - Epoch Loss: 67593.4240 - Avg Loss: 159.7953\n",
            "Epoch [31/50] - Batch loss: 158.9212 - Epoch Loss: 67752.3452 - Avg Loss: 159.7933\n",
            "Epoch [31/50] - Batch loss: 158.6058 - Epoch Loss: 67910.9510 - Avg Loss: 159.7905\n",
            "Epoch [31/50] - Batch loss: 167.7225 - Epoch Loss: 68078.6735 - Avg Loss: 159.8091\n",
            "Epoch [31/50] - Batch loss: 160.3043 - Epoch Loss: 68238.9778 - Avg Loss: 159.8103\n",
            "Epoch [31/50] - Batch loss: 161.6606 - Epoch Loss: 68400.6385 - Avg Loss: 159.8146\n",
            "Epoch [31/50] - Batch loss: 158.8671 - Epoch Loss: 68559.5055 - Avg Loss: 159.8124\n",
            "Epoch [31/50] - Batch loss: 162.9291 - Epoch Loss: 68722.4346 - Avg Loss: 159.8196\n",
            "Epoch [31/50] - Batch loss: 163.3715 - Epoch Loss: 68885.8062 - Avg Loss: 159.8279\n",
            "Epoch [31/50] - Batch loss: 159.2357 - Epoch Loss: 69045.0419 - Avg Loss: 159.8265\n",
            "Epoch [31/50] - Batch loss: 157.3818 - Epoch Loss: 69202.4237 - Avg Loss: 159.8208\n",
            "Epoch [31/50] - Batch loss: 161.1435 - Epoch Loss: 69363.5672 - Avg Loss: 159.8239\n",
            "Epoch [31/50] - Batch loss: 156.8965 - Epoch Loss: 69520.4637 - Avg Loss: 159.8172\n",
            "Epoch [31/50] - Batch loss: 156.4903 - Epoch Loss: 69676.9540 - Avg Loss: 159.8095\n",
            "Epoch [31/50] - Batch loss: 157.0497 - Epoch Loss: 69834.0037 - Avg Loss: 159.8032\n",
            "Epoch [31/50] - Batch loss: 151.9023 - Epoch Loss: 69985.9060 - Avg Loss: 159.7852\n",
            "Epoch [31/50] - Batch loss: 156.7158 - Epoch Loss: 70142.6218 - Avg Loss: 159.7782\n",
            "Epoch [31/50] - Batch loss: 154.2457 - Epoch Loss: 70296.8676 - Avg Loss: 159.7656\n",
            "Epoch [31/50] - Batch loss: 155.5955 - Epoch Loss: 70452.4631 - Avg Loss: 159.7562\n",
            "Epoch [31/50] - Batch loss: 151.4458 - Epoch Loss: 70603.9089 - Avg Loss: 159.7374\n",
            "Epoch [31/50] - Batch loss: 157.3057 - Epoch Loss: 70761.2146 - Avg Loss: 159.7319\n",
            "Epoch [31/50] - Batch loss: 158.0367 - Epoch Loss: 70919.2513 - Avg Loss: 159.7280\n",
            "Epoch [31/50] - Batch loss: 154.8426 - Epoch Loss: 71074.0940 - Avg Loss: 159.7171\n",
            "Epoch [31/50] - Batch loss: 149.6398 - Epoch Loss: 71223.7338 - Avg Loss: 159.6945\n",
            "Epoch [31/50] - Batch loss: 162.4210 - Epoch Loss: 71386.1547 - Avg Loss: 159.7006\n",
            "Epoch [31/50] - Batch loss: 161.1612 - Epoch Loss: 71547.3160 - Avg Loss: 159.7038\n",
            "Epoch [31/50] - Batch loss: 160.9450 - Epoch Loss: 71708.2610 - Avg Loss: 159.7066\n",
            "Epoch [31/50] - Batch loss: 160.0885 - Epoch Loss: 71868.3495 - Avg Loss: 159.7074\n",
            "Epoch [31/50] - Batch loss: 156.6796 - Epoch Loss: 72025.0291 - Avg Loss: 159.7007\n",
            "Epoch [31/50] - Batch loss: 161.0620 - Epoch Loss: 72186.0911 - Avg Loss: 159.7037\n",
            "Epoch [31/50] - Batch loss: 159.9591 - Epoch Loss: 72346.0501 - Avg Loss: 159.7043\n",
            "Epoch [31/50] - Batch loss: 161.5828 - Epoch Loss: 72507.6329 - Avg Loss: 159.7084\n",
            "Epoch [31/50] - Batch loss: 162.5653 - Epoch Loss: 72670.1983 - Avg Loss: 159.7147\n",
            "Epoch [31/50] - Batch loss: 157.8630 - Epoch Loss: 72828.0613 - Avg Loss: 159.7107\n",
            "Epoch [31/50] - Batch loss: 152.3348 - Epoch Loss: 72980.3961 - Avg Loss: 159.6945\n",
            "Epoch [31/50] - Batch loss: 159.4168 - Epoch Loss: 73139.8128 - Avg Loss: 159.6939\n",
            "Epoch [31/50] - Batch loss: 154.9813 - Epoch Loss: 73294.7942 - Avg Loss: 159.6836\n",
            "Epoch [31/50] - Batch loss: 151.6172 - Epoch Loss: 73446.4113 - Avg Loss: 159.6661\n",
            "Epoch [31/50] - Batch loss: 165.4599 - Epoch Loss: 73611.8712 - Avg Loss: 159.6787\n",
            "Epoch [31/50] - Batch loss: 158.4820 - Epoch Loss: 73770.3532 - Avg Loss: 159.6761\n",
            "Epoch [31/50] - Batch loss: 161.5025 - Epoch Loss: 73931.8557 - Avg Loss: 159.6800\n",
            "Epoch [31/50] - Batch loss: 156.0247 - Epoch Loss: 74087.8804 - Avg Loss: 159.6722\n",
            "Epoch [31/50] - Batch loss: 157.9868 - Epoch Loss: 74245.8672 - Avg Loss: 159.6685\n",
            "Epoch [31/50] - Batch loss: 153.3775 - Epoch Loss: 74399.2447 - Avg Loss: 159.6550\n",
            "Epoch [31/50] - Batch loss: 163.2357 - Epoch Loss: 74562.4805 - Avg Loss: 159.6627\n",
            "Epoch [31/50] - Batch loss: 157.6109 - Epoch Loss: 74720.0913 - Avg Loss: 159.6583\n",
            "Epoch [31/50] - Batch loss: 154.1011 - Epoch Loss: 74874.1925 - Avg Loss: 159.6465\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 32/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b51cd3bd62914bb3a05b8fb9530c126e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [32/50] - Batch loss: 160.4258 - Epoch Loss: 160.4258 - Avg Loss: 160.4258\n",
            "Epoch [32/50] - Batch loss: 156.4015 - Epoch Loss: 316.8274 - Avg Loss: 158.4137\n",
            "Epoch [32/50] - Batch loss: 157.4657 - Epoch Loss: 474.2931 - Avg Loss: 158.0977\n",
            "Epoch [32/50] - Batch loss: 161.9712 - Epoch Loss: 636.2643 - Avg Loss: 159.0661\n",
            "Epoch [32/50] - Batch loss: 154.2354 - Epoch Loss: 790.4998 - Avg Loss: 158.1000\n",
            "Epoch [32/50] - Batch loss: 164.5316 - Epoch Loss: 955.0314 - Avg Loss: 159.1719\n",
            "Epoch [32/50] - Batch loss: 160.2584 - Epoch Loss: 1115.2898 - Avg Loss: 159.3271\n",
            "Epoch [32/50] - Batch loss: 154.2855 - Epoch Loss: 1269.5753 - Avg Loss: 158.6969\n",
            "Epoch [32/50] - Batch loss: 159.5748 - Epoch Loss: 1429.1501 - Avg Loss: 158.7945\n",
            "Epoch [32/50] - Batch loss: 165.3548 - Epoch Loss: 1594.5049 - Avg Loss: 159.4505\n",
            "Epoch [32/50] - Batch loss: 160.0990 - Epoch Loss: 1754.6039 - Avg Loss: 159.5094\n",
            "Epoch [32/50] - Batch loss: 156.2355 - Epoch Loss: 1910.8394 - Avg Loss: 159.2366\n",
            "Epoch [32/50] - Batch loss: 155.4455 - Epoch Loss: 2066.2849 - Avg Loss: 158.9450\n",
            "Epoch [32/50] - Batch loss: 154.3768 - Epoch Loss: 2220.6616 - Avg Loss: 158.6187\n",
            "Epoch [32/50] - Batch loss: 163.3576 - Epoch Loss: 2384.0192 - Avg Loss: 158.9346\n",
            "Epoch [32/50] - Batch loss: 158.6182 - Epoch Loss: 2542.6374 - Avg Loss: 158.9148\n",
            "Epoch [32/50] - Batch loss: 158.5950 - Epoch Loss: 2701.2324 - Avg Loss: 158.8960\n",
            "Epoch [32/50] - Batch loss: 171.0997 - Epoch Loss: 2872.3321 - Avg Loss: 159.5740\n",
            "Epoch [32/50] - Batch loss: 151.7809 - Epoch Loss: 3024.1130 - Avg Loss: 159.1638\n",
            "Epoch [32/50] - Batch loss: 160.2734 - Epoch Loss: 3184.3864 - Avg Loss: 159.2193\n",
            "Epoch [32/50] - Batch loss: 158.8451 - Epoch Loss: 3343.2314 - Avg Loss: 159.2015\n",
            "Epoch [32/50] - Batch loss: 162.0863 - Epoch Loss: 3505.3177 - Avg Loss: 159.3326\n",
            "Epoch [32/50] - Batch loss: 156.8681 - Epoch Loss: 3662.1858 - Avg Loss: 159.2255\n",
            "Epoch [32/50] - Batch loss: 160.6500 - Epoch Loss: 3822.8358 - Avg Loss: 159.2848\n",
            "Epoch [32/50] - Batch loss: 165.3224 - Epoch Loss: 3988.1582 - Avg Loss: 159.5263\n",
            "Epoch [32/50] - Batch loss: 162.8470 - Epoch Loss: 4151.0052 - Avg Loss: 159.6540\n",
            "Epoch [32/50] - Batch loss: 163.4850 - Epoch Loss: 4314.4901 - Avg Loss: 159.7959\n",
            "Epoch [32/50] - Batch loss: 159.3957 - Epoch Loss: 4473.8858 - Avg Loss: 159.7816\n",
            "Epoch [32/50] - Batch loss: 159.4010 - Epoch Loss: 4633.2868 - Avg Loss: 159.7685\n",
            "Epoch [32/50] - Batch loss: 159.6909 - Epoch Loss: 4792.9776 - Avg Loss: 159.7659\n",
            "Epoch [32/50] - Batch loss: 163.3991 - Epoch Loss: 4956.3768 - Avg Loss: 159.8831\n",
            "Epoch [32/50] - Batch loss: 157.5887 - Epoch Loss: 5113.9655 - Avg Loss: 159.8114\n",
            "Epoch [32/50] - Batch loss: 157.1237 - Epoch Loss: 5271.0892 - Avg Loss: 159.7300\n",
            "Epoch [32/50] - Batch loss: 164.3081 - Epoch Loss: 5435.3973 - Avg Loss: 159.8646\n",
            "Epoch [32/50] - Batch loss: 158.9146 - Epoch Loss: 5594.3119 - Avg Loss: 159.8375\n",
            "Epoch [32/50] - Batch loss: 165.3769 - Epoch Loss: 5759.6888 - Avg Loss: 159.9914\n",
            "Epoch [32/50] - Batch loss: 156.3085 - Epoch Loss: 5915.9974 - Avg Loss: 159.8918\n",
            "Epoch [32/50] - Batch loss: 152.2415 - Epoch Loss: 6068.2389 - Avg Loss: 159.6905\n",
            "Epoch [32/50] - Batch loss: 156.7174 - Epoch Loss: 6224.9563 - Avg Loss: 159.6143\n",
            "Epoch [32/50] - Batch loss: 156.7540 - Epoch Loss: 6381.7103 - Avg Loss: 159.5428\n",
            "Epoch [32/50] - Batch loss: 160.0141 - Epoch Loss: 6541.7244 - Avg Loss: 159.5543\n",
            "Epoch [32/50] - Batch loss: 162.0843 - Epoch Loss: 6703.8087 - Avg Loss: 159.6145\n",
            "Epoch [32/50] - Batch loss: 160.8122 - Epoch Loss: 6864.6209 - Avg Loss: 159.6423\n",
            "Epoch [32/50] - Batch loss: 164.1006 - Epoch Loss: 7028.7215 - Avg Loss: 159.7437\n",
            "Epoch [32/50] - Batch loss: 162.8528 - Epoch Loss: 7191.5743 - Avg Loss: 159.8128\n",
            "Epoch [32/50] - Batch loss: 157.6901 - Epoch Loss: 7349.2645 - Avg Loss: 159.7666\n",
            "Epoch [32/50] - Batch loss: 152.8150 - Epoch Loss: 7502.0795 - Avg Loss: 159.6187\n",
            "Epoch [32/50] - Batch loss: 169.2470 - Epoch Loss: 7671.3265 - Avg Loss: 159.8193\n",
            "Epoch [32/50] - Batch loss: 163.7694 - Epoch Loss: 7835.0959 - Avg Loss: 159.8999\n",
            "Epoch [32/50] - Batch loss: 158.5984 - Epoch Loss: 7993.6943 - Avg Loss: 159.8739\n",
            "Epoch [32/50] - Batch loss: 158.2510 - Epoch Loss: 8151.9453 - Avg Loss: 159.8421\n",
            "Epoch [32/50] - Batch loss: 151.9075 - Epoch Loss: 8303.8528 - Avg Loss: 159.6895\n",
            "Epoch [32/50] - Batch loss: 155.9735 - Epoch Loss: 8459.8263 - Avg Loss: 159.6194\n",
            "Epoch [32/50] - Batch loss: 156.4318 - Epoch Loss: 8616.2581 - Avg Loss: 159.5603\n",
            "Epoch [32/50] - Batch loss: 159.1581 - Epoch Loss: 8775.4163 - Avg Loss: 159.5530\n",
            "Epoch [32/50] - Batch loss: 160.8754 - Epoch Loss: 8936.2917 - Avg Loss: 159.5766\n",
            "Epoch [32/50] - Batch loss: 161.7485 - Epoch Loss: 9098.0402 - Avg Loss: 159.6147\n",
            "Epoch [32/50] - Batch loss: 156.0919 - Epoch Loss: 9254.1321 - Avg Loss: 159.5540\n",
            "Epoch [32/50] - Batch loss: 162.8964 - Epoch Loss: 9417.0285 - Avg Loss: 159.6107\n",
            "Epoch [32/50] - Batch loss: 157.4092 - Epoch Loss: 9574.4378 - Avg Loss: 159.5740\n",
            "Epoch [32/50] - Batch loss: 150.7795 - Epoch Loss: 9725.2172 - Avg Loss: 159.4298\n",
            "Epoch [32/50] - Batch loss: 157.6472 - Epoch Loss: 9882.8644 - Avg Loss: 159.4010\n",
            "Epoch [32/50] - Batch loss: 165.2938 - Epoch Loss: 10048.1582 - Avg Loss: 159.4946\n",
            "Epoch [32/50] - Batch loss: 168.2627 - Epoch Loss: 10216.4209 - Avg Loss: 159.6316\n",
            "Epoch [32/50] - Batch loss: 159.9711 - Epoch Loss: 10376.3920 - Avg Loss: 159.6368\n",
            "Epoch [32/50] - Batch loss: 152.9060 - Epoch Loss: 10529.2980 - Avg Loss: 159.5348\n",
            "Epoch [32/50] - Batch loss: 152.2165 - Epoch Loss: 10681.5145 - Avg Loss: 159.4256\n",
            "Epoch [32/50] - Batch loss: 151.3704 - Epoch Loss: 10832.8849 - Avg Loss: 159.3071\n",
            "Epoch [32/50] - Batch loss: 160.3103 - Epoch Loss: 10993.1952 - Avg Loss: 159.3217\n",
            "Epoch [32/50] - Batch loss: 162.4798 - Epoch Loss: 11155.6750 - Avg Loss: 159.3668\n",
            "Epoch [32/50] - Batch loss: 160.4453 - Epoch Loss: 11316.1203 - Avg Loss: 159.3820\n",
            "Epoch [32/50] - Batch loss: 157.6411 - Epoch Loss: 11473.7614 - Avg Loss: 159.3578\n",
            "Epoch [32/50] - Batch loss: 159.1193 - Epoch Loss: 11632.8807 - Avg Loss: 159.3545\n",
            "Epoch [32/50] - Batch loss: 159.1073 - Epoch Loss: 11791.9880 - Avg Loss: 159.3512\n",
            "Epoch [32/50] - Batch loss: 157.1250 - Epoch Loss: 11949.1130 - Avg Loss: 159.3215\n",
            "Epoch [32/50] - Batch loss: 163.5262 - Epoch Loss: 12112.6392 - Avg Loss: 159.3768\n",
            "Epoch [32/50] - Batch loss: 158.9108 - Epoch Loss: 12271.5500 - Avg Loss: 159.3708\n",
            "Epoch [32/50] - Batch loss: 157.8369 - Epoch Loss: 12429.3869 - Avg Loss: 159.3511\n",
            "Epoch [32/50] - Batch loss: 154.6528 - Epoch Loss: 12584.0397 - Avg Loss: 159.2916\n",
            "Epoch [32/50] - Batch loss: 166.1504 - Epoch Loss: 12750.1901 - Avg Loss: 159.3774\n",
            "Epoch [32/50] - Batch loss: 162.0415 - Epoch Loss: 12912.2316 - Avg Loss: 159.4103\n",
            "Epoch [32/50] - Batch loss: 158.3008 - Epoch Loss: 13070.5324 - Avg Loss: 159.3967\n",
            "Epoch [32/50] - Batch loss: 157.2494 - Epoch Loss: 13227.7818 - Avg Loss: 159.3709\n",
            "Epoch [32/50] - Batch loss: 151.5211 - Epoch Loss: 13379.3028 - Avg Loss: 159.2774\n",
            "Epoch [32/50] - Batch loss: 156.3752 - Epoch Loss: 13535.6781 - Avg Loss: 159.2433\n",
            "Epoch [32/50] - Batch loss: 162.5563 - Epoch Loss: 13698.2344 - Avg Loss: 159.2818\n",
            "Epoch [32/50] - Batch loss: 165.5821 - Epoch Loss: 13863.8164 - Avg Loss: 159.3542\n",
            "Epoch [32/50] - Batch loss: 164.6420 - Epoch Loss: 14028.4584 - Avg Loss: 159.4143\n",
            "Epoch [32/50] - Batch loss: 158.7043 - Epoch Loss: 14187.1627 - Avg Loss: 159.4063\n",
            "Epoch [32/50] - Batch loss: 164.2579 - Epoch Loss: 14351.4207 - Avg Loss: 159.4602\n",
            "Epoch [32/50] - Batch loss: 155.2037 - Epoch Loss: 14506.6244 - Avg Loss: 159.4135\n",
            "Epoch [32/50] - Batch loss: 161.8582 - Epoch Loss: 14668.4826 - Avg Loss: 159.4400\n",
            "Epoch [32/50] - Batch loss: 166.1839 - Epoch Loss: 14834.6665 - Avg Loss: 159.5125\n",
            "Epoch [32/50] - Batch loss: 166.2060 - Epoch Loss: 15000.8725 - Avg Loss: 159.5837\n",
            "Epoch [32/50] - Batch loss: 169.3865 - Epoch Loss: 15170.2590 - Avg Loss: 159.6869\n",
            "Epoch [32/50] - Batch loss: 154.0436 - Epoch Loss: 15324.3026 - Avg Loss: 159.6282\n",
            "Epoch [32/50] - Batch loss: 171.0415 - Epoch Loss: 15495.3441 - Avg Loss: 159.7458\n",
            "Epoch [32/50] - Batch loss: 160.7744 - Epoch Loss: 15656.1184 - Avg Loss: 159.7563\n",
            "Epoch [32/50] - Batch loss: 156.6756 - Epoch Loss: 15812.7940 - Avg Loss: 159.7252\n",
            "Epoch [32/50] - Batch loss: 161.5537 - Epoch Loss: 15974.3477 - Avg Loss: 159.7435\n",
            "Epoch [32/50] - Batch loss: 161.3865 - Epoch Loss: 16135.7342 - Avg Loss: 159.7597\n",
            "Epoch [32/50] - Batch loss: 161.4797 - Epoch Loss: 16297.2139 - Avg Loss: 159.7766\n",
            "Epoch [32/50] - Batch loss: 154.9688 - Epoch Loss: 16452.1827 - Avg Loss: 159.7299\n",
            "Epoch [32/50] - Batch loss: 163.7658 - Epoch Loss: 16615.9485 - Avg Loss: 159.7687\n",
            "Epoch [32/50] - Batch loss: 165.4942 - Epoch Loss: 16781.4427 - Avg Loss: 159.8233\n",
            "Epoch [32/50] - Batch loss: 160.1748 - Epoch Loss: 16941.6175 - Avg Loss: 159.8266\n",
            "Epoch [32/50] - Batch loss: 162.9186 - Epoch Loss: 17104.5361 - Avg Loss: 159.8555\n",
            "Epoch [32/50] - Batch loss: 157.8778 - Epoch Loss: 17262.4139 - Avg Loss: 159.8372\n",
            "Epoch [32/50] - Batch loss: 154.4397 - Epoch Loss: 17416.8536 - Avg Loss: 159.7876\n",
            "Epoch [32/50] - Batch loss: 155.4285 - Epoch Loss: 17572.2820 - Avg Loss: 159.7480\n",
            "Epoch [32/50] - Batch loss: 147.3992 - Epoch Loss: 17719.6813 - Avg Loss: 159.6368\n",
            "Epoch [32/50] - Batch loss: 163.3700 - Epoch Loss: 17883.0513 - Avg Loss: 159.6701\n",
            "Epoch [32/50] - Batch loss: 160.4159 - Epoch Loss: 18043.4672 - Avg Loss: 159.6767\n",
            "Epoch [32/50] - Batch loss: 155.9198 - Epoch Loss: 18199.3869 - Avg Loss: 159.6437\n",
            "Epoch [32/50] - Batch loss: 161.4942 - Epoch Loss: 18360.8812 - Avg Loss: 159.6598\n",
            "Epoch [32/50] - Batch loss: 162.2271 - Epoch Loss: 18523.1083 - Avg Loss: 159.6820\n",
            "Epoch [32/50] - Batch loss: 158.3990 - Epoch Loss: 18681.5073 - Avg Loss: 159.6710\n",
            "Epoch [32/50] - Batch loss: 163.3147 - Epoch Loss: 18844.8220 - Avg Loss: 159.7019\n",
            "Epoch [32/50] - Batch loss: 151.3764 - Epoch Loss: 18996.1985 - Avg Loss: 159.6319\n",
            "Epoch [32/50] - Batch loss: 160.9156 - Epoch Loss: 19157.1140 - Avg Loss: 159.6426\n",
            "Epoch [32/50] - Batch loss: 154.9259 - Epoch Loss: 19312.0400 - Avg Loss: 159.6036\n",
            "Epoch [32/50] - Batch loss: 159.5614 - Epoch Loss: 19471.6013 - Avg Loss: 159.6033\n",
            "Epoch [32/50] - Batch loss: 163.5235 - Epoch Loss: 19635.1248 - Avg Loss: 159.6352\n",
            "Epoch [32/50] - Batch loss: 162.9288 - Epoch Loss: 19798.0536 - Avg Loss: 159.6617\n",
            "Epoch [32/50] - Batch loss: 160.8987 - Epoch Loss: 19958.9523 - Avg Loss: 159.6716\n",
            "Epoch [32/50] - Batch loss: 168.1468 - Epoch Loss: 20127.0991 - Avg Loss: 159.7389\n",
            "Epoch [32/50] - Batch loss: 161.4793 - Epoch Loss: 20288.5784 - Avg Loss: 159.7526\n",
            "Epoch [32/50] - Batch loss: 155.9678 - Epoch Loss: 20444.5461 - Avg Loss: 159.7230\n",
            "Epoch [32/50] - Batch loss: 170.0392 - Epoch Loss: 20614.5854 - Avg Loss: 159.8030\n",
            "Epoch [32/50] - Batch loss: 157.5873 - Epoch Loss: 20772.1727 - Avg Loss: 159.7859\n",
            "Epoch [32/50] - Batch loss: 161.7492 - Epoch Loss: 20933.9219 - Avg Loss: 159.8009\n",
            "Epoch [32/50] - Batch loss: 161.3932 - Epoch Loss: 21095.3150 - Avg Loss: 159.8130\n",
            "Epoch [32/50] - Batch loss: 163.5543 - Epoch Loss: 21258.8693 - Avg Loss: 159.8411\n",
            "Epoch [32/50] - Batch loss: 165.4227 - Epoch Loss: 21424.2921 - Avg Loss: 159.8828\n",
            "Epoch [32/50] - Batch loss: 158.5523 - Epoch Loss: 21582.8443 - Avg Loss: 159.8729\n",
            "Epoch [32/50] - Batch loss: 158.7873 - Epoch Loss: 21741.6316 - Avg Loss: 159.8649\n",
            "Epoch [32/50] - Batch loss: 157.2582 - Epoch Loss: 21898.8898 - Avg Loss: 159.8459\n",
            "Epoch [32/50] - Batch loss: 165.2470 - Epoch Loss: 22064.1368 - Avg Loss: 159.8850\n",
            "Epoch [32/50] - Batch loss: 157.3844 - Epoch Loss: 22221.5212 - Avg Loss: 159.8671\n",
            "Epoch [32/50] - Batch loss: 159.0708 - Epoch Loss: 22380.5920 - Avg Loss: 159.8614\n",
            "Epoch [32/50] - Batch loss: 157.4748 - Epoch Loss: 22538.0668 - Avg Loss: 159.8444\n",
            "Epoch [32/50] - Batch loss: 158.3403 - Epoch Loss: 22696.4071 - Avg Loss: 159.8339\n",
            "Epoch [32/50] - Batch loss: 159.0748 - Epoch Loss: 22855.4819 - Avg Loss: 159.8285\n",
            "Epoch [32/50] - Batch loss: 161.3290 - Epoch Loss: 23016.8109 - Avg Loss: 159.8390\n",
            "Epoch [32/50] - Batch loss: 153.7300 - Epoch Loss: 23170.5409 - Avg Loss: 159.7968\n",
            "Epoch [32/50] - Batch loss: 167.0538 - Epoch Loss: 23337.5947 - Avg Loss: 159.8465\n",
            "Epoch [32/50] - Batch loss: 156.7299 - Epoch Loss: 23494.3246 - Avg Loss: 159.8253\n",
            "Epoch [32/50] - Batch loss: 151.1504 - Epoch Loss: 23645.4751 - Avg Loss: 159.7667\n",
            "Epoch [32/50] - Batch loss: 158.8981 - Epoch Loss: 23804.3732 - Avg Loss: 159.7609\n",
            "Epoch [32/50] - Batch loss: 168.4835 - Epoch Loss: 23972.8567 - Avg Loss: 159.8190\n",
            "Epoch [32/50] - Batch loss: 164.1853 - Epoch Loss: 24137.0420 - Avg Loss: 159.8480\n",
            "Epoch [32/50] - Batch loss: 164.7952 - Epoch Loss: 24301.8372 - Avg Loss: 159.8805\n",
            "Epoch [32/50] - Batch loss: 167.1009 - Epoch Loss: 24468.9381 - Avg Loss: 159.9277\n",
            "Epoch [32/50] - Batch loss: 157.1042 - Epoch Loss: 24626.0424 - Avg Loss: 159.9094\n",
            "Epoch [32/50] - Batch loss: 159.3871 - Epoch Loss: 24785.4294 - Avg Loss: 159.9060\n",
            "Epoch [32/50] - Batch loss: 166.7639 - Epoch Loss: 24952.1933 - Avg Loss: 159.9500\n",
            "Epoch [32/50] - Batch loss: 166.4975 - Epoch Loss: 25118.6908 - Avg Loss: 159.9917\n",
            "Epoch [32/50] - Batch loss: 156.7770 - Epoch Loss: 25275.4678 - Avg Loss: 159.9713\n",
            "Epoch [32/50] - Batch loss: 157.0488 - Epoch Loss: 25432.5167 - Avg Loss: 159.9529\n",
            "Epoch [32/50] - Batch loss: 163.2045 - Epoch Loss: 25595.7211 - Avg Loss: 159.9733\n",
            "Epoch [32/50] - Batch loss: 158.4552 - Epoch Loss: 25754.1764 - Avg Loss: 159.9638\n",
            "Epoch [32/50] - Batch loss: 156.4474 - Epoch Loss: 25910.6237 - Avg Loss: 159.9421\n",
            "Epoch [32/50] - Batch loss: 158.2614 - Epoch Loss: 26068.8851 - Avg Loss: 159.9318\n",
            "Epoch [32/50] - Batch loss: 160.9893 - Epoch Loss: 26229.8744 - Avg Loss: 159.9383\n",
            "Epoch [32/50] - Batch loss: 159.8857 - Epoch Loss: 26389.7601 - Avg Loss: 159.9379\n",
            "Epoch [32/50] - Batch loss: 175.4933 - Epoch Loss: 26565.2534 - Avg Loss: 160.0316\n",
            "Epoch [32/50] - Batch loss: 165.2369 - Epoch Loss: 26730.4903 - Avg Loss: 160.0628\n",
            "Epoch [32/50] - Batch loss: 154.1660 - Epoch Loss: 26884.6563 - Avg Loss: 160.0277\n",
            "Epoch [32/50] - Batch loss: 162.4871 - Epoch Loss: 27047.1435 - Avg Loss: 160.0423\n",
            "Epoch [32/50] - Batch loss: 163.4117 - Epoch Loss: 27210.5552 - Avg Loss: 160.0621\n",
            "Epoch [32/50] - Batch loss: 163.4655 - Epoch Loss: 27374.0207 - Avg Loss: 160.0820\n",
            "Epoch [32/50] - Batch loss: 167.3645 - Epoch Loss: 27541.3851 - Avg Loss: 160.1243\n",
            "Epoch [32/50] - Batch loss: 158.4460 - Epoch Loss: 27699.8311 - Avg Loss: 160.1146\n",
            "Epoch [32/50] - Batch loss: 157.0534 - Epoch Loss: 27856.8845 - Avg Loss: 160.0970\n",
            "Epoch [32/50] - Batch loss: 171.0099 - Epoch Loss: 28027.8945 - Avg Loss: 160.1594\n",
            "Epoch [32/50] - Batch loss: 160.9912 - Epoch Loss: 28188.8857 - Avg Loss: 160.1641\n",
            "Epoch [32/50] - Batch loss: 158.8884 - Epoch Loss: 28347.7741 - Avg Loss: 160.1569\n",
            "Epoch [32/50] - Batch loss: 166.8713 - Epoch Loss: 28514.6454 - Avg Loss: 160.1946\n",
            "Epoch [32/50] - Batch loss: 163.1935 - Epoch Loss: 28677.8389 - Avg Loss: 160.2114\n",
            "Epoch [32/50] - Batch loss: 159.6670 - Epoch Loss: 28837.5059 - Avg Loss: 160.2084\n",
            "Epoch [32/50] - Batch loss: 154.4348 - Epoch Loss: 28991.9408 - Avg Loss: 160.1765\n",
            "Epoch [32/50] - Batch loss: 162.7650 - Epoch Loss: 29154.7058 - Avg Loss: 160.1907\n",
            "Epoch [32/50] - Batch loss: 162.5310 - Epoch Loss: 29317.2367 - Avg Loss: 160.2035\n",
            "Epoch [32/50] - Batch loss: 159.5620 - Epoch Loss: 29476.7988 - Avg Loss: 160.2000\n",
            "Epoch [32/50] - Batch loss: 161.6156 - Epoch Loss: 29638.4144 - Avg Loss: 160.2076\n",
            "Epoch [32/50] - Batch loss: 172.7843 - Epoch Loss: 29811.1986 - Avg Loss: 160.2753\n",
            "Epoch [32/50] - Batch loss: 161.9724 - Epoch Loss: 29973.1710 - Avg Loss: 160.2843\n",
            "Epoch [32/50] - Batch loss: 161.2376 - Epoch Loss: 30134.4086 - Avg Loss: 160.2894\n",
            "Epoch [32/50] - Batch loss: 161.9590 - Epoch Loss: 30296.3676 - Avg Loss: 160.2982\n",
            "Epoch [32/50] - Batch loss: 166.3721 - Epoch Loss: 30462.7397 - Avg Loss: 160.3302\n",
            "Epoch [32/50] - Batch loss: 165.4368 - Epoch Loss: 30628.1765 - Avg Loss: 160.3569\n",
            "Epoch [32/50] - Batch loss: 161.3542 - Epoch Loss: 30789.5306 - Avg Loss: 160.3621\n",
            "Epoch [32/50] - Batch loss: 155.3937 - Epoch Loss: 30944.9243 - Avg Loss: 160.3364\n",
            "Epoch [32/50] - Batch loss: 157.6843 - Epoch Loss: 31102.6086 - Avg Loss: 160.3227\n",
            "Epoch [32/50] - Batch loss: 171.9917 - Epoch Loss: 31274.6002 - Avg Loss: 160.3826\n",
            "Epoch [32/50] - Batch loss: 164.2328 - Epoch Loss: 31438.8330 - Avg Loss: 160.4022\n",
            "Epoch [32/50] - Batch loss: 166.3070 - Epoch Loss: 31605.1400 - Avg Loss: 160.4322\n",
            "Epoch [32/50] - Batch loss: 155.1026 - Epoch Loss: 31760.2426 - Avg Loss: 160.4053\n",
            "Epoch [32/50] - Batch loss: 160.6158 - Epoch Loss: 31920.8584 - Avg Loss: 160.4063\n",
            "Epoch [32/50] - Batch loss: 161.1194 - Epoch Loss: 32081.9777 - Avg Loss: 160.4099\n",
            "Epoch [32/50] - Batch loss: 159.8879 - Epoch Loss: 32241.8657 - Avg Loss: 160.4073\n",
            "Epoch [32/50] - Batch loss: 167.3184 - Epoch Loss: 32409.1840 - Avg Loss: 160.4415\n",
            "Epoch [32/50] - Batch loss: 167.2123 - Epoch Loss: 32576.3964 - Avg Loss: 160.4749\n",
            "Epoch [32/50] - Batch loss: 171.2732 - Epoch Loss: 32747.6696 - Avg Loss: 160.5278\n",
            "Epoch [32/50] - Batch loss: 167.8385 - Epoch Loss: 32915.5081 - Avg Loss: 160.5635\n",
            "Epoch [32/50] - Batch loss: 173.0950 - Epoch Loss: 33088.6031 - Avg Loss: 160.6243\n",
            "Epoch [32/50] - Batch loss: 170.6246 - Epoch Loss: 33259.2276 - Avg Loss: 160.6726\n",
            "Epoch [32/50] - Batch loss: 162.2531 - Epoch Loss: 33421.4807 - Avg Loss: 160.6802\n",
            "Epoch [32/50] - Batch loss: 160.3577 - Epoch Loss: 33581.8385 - Avg Loss: 160.6787\n",
            "Epoch [32/50] - Batch loss: 164.5507 - Epoch Loss: 33746.3891 - Avg Loss: 160.6971\n",
            "Epoch [32/50] - Batch loss: 165.9116 - Epoch Loss: 33912.3008 - Avg Loss: 160.7218\n",
            "Epoch [32/50] - Batch loss: 164.9550 - Epoch Loss: 34077.2557 - Avg Loss: 160.7418\n",
            "Epoch [32/50] - Batch loss: 156.8446 - Epoch Loss: 34234.1003 - Avg Loss: 160.7235\n",
            "Epoch [32/50] - Batch loss: 163.7529 - Epoch Loss: 34397.8532 - Avg Loss: 160.7376\n",
            "Epoch [32/50] - Batch loss: 166.7378 - Epoch Loss: 34564.5910 - Avg Loss: 160.7655\n",
            "Epoch [32/50] - Batch loss: 158.2604 - Epoch Loss: 34722.8514 - Avg Loss: 160.7539\n",
            "Epoch [32/50] - Batch loss: 167.1272 - Epoch Loss: 34889.9786 - Avg Loss: 160.7833\n",
            "Epoch [32/50] - Batch loss: 165.5846 - Epoch Loss: 35055.5632 - Avg Loss: 160.8053\n",
            "Epoch [32/50] - Batch loss: 164.3428 - Epoch Loss: 35219.9060 - Avg Loss: 160.8215\n",
            "Epoch [32/50] - Batch loss: 165.0729 - Epoch Loss: 35384.9789 - Avg Loss: 160.8408\n",
            "Epoch [32/50] - Batch loss: 167.1835 - Epoch Loss: 35552.1624 - Avg Loss: 160.8695\n",
            "Epoch [32/50] - Batch loss: 163.3686 - Epoch Loss: 35715.5310 - Avg Loss: 160.8808\n",
            "Epoch [32/50] - Batch loss: 158.9452 - Epoch Loss: 35874.4762 - Avg Loss: 160.8721\n",
            "Epoch [32/50] - Batch loss: 149.9805 - Epoch Loss: 36024.4567 - Avg Loss: 160.8235\n",
            "Epoch [32/50] - Batch loss: 164.4939 - Epoch Loss: 36188.9505 - Avg Loss: 160.8398\n",
            "Epoch [32/50] - Batch loss: 165.4631 - Epoch Loss: 36354.4137 - Avg Loss: 160.8602\n",
            "Epoch [32/50] - Batch loss: 169.3801 - Epoch Loss: 36523.7938 - Avg Loss: 160.8978\n",
            "Epoch [32/50] - Batch loss: 161.2925 - Epoch Loss: 36685.0863 - Avg Loss: 160.8995\n",
            "Epoch [32/50] - Batch loss: 164.6399 - Epoch Loss: 36849.7262 - Avg Loss: 160.9158\n",
            "Epoch [32/50] - Batch loss: 163.8581 - Epoch Loss: 37013.5843 - Avg Loss: 160.9286\n",
            "Epoch [32/50] - Batch loss: 168.3212 - Epoch Loss: 37181.9055 - Avg Loss: 160.9606\n",
            "Epoch [32/50] - Batch loss: 157.9710 - Epoch Loss: 37339.8765 - Avg Loss: 160.9477\n",
            "Epoch [32/50] - Batch loss: 160.1677 - Epoch Loss: 37500.0443 - Avg Loss: 160.9444\n",
            "Epoch [32/50] - Batch loss: 155.7067 - Epoch Loss: 37655.7509 - Avg Loss: 160.9220\n",
            "Epoch [32/50] - Batch loss: 162.6289 - Epoch Loss: 37818.3799 - Avg Loss: 160.9293\n",
            "Epoch [32/50] - Batch loss: 169.0258 - Epoch Loss: 37987.4057 - Avg Loss: 160.9636\n",
            "Epoch [32/50] - Batch loss: 160.3326 - Epoch Loss: 38147.7383 - Avg Loss: 160.9609\n",
            "Epoch [32/50] - Batch loss: 167.0070 - Epoch Loss: 38314.7453 - Avg Loss: 160.9863\n",
            "Epoch [32/50] - Batch loss: 165.6560 - Epoch Loss: 38480.4012 - Avg Loss: 161.0059\n",
            "Epoch [32/50] - Batch loss: 152.6873 - Epoch Loss: 38633.0885 - Avg Loss: 160.9712\n",
            "Epoch [32/50] - Batch loss: 164.7538 - Epoch Loss: 38797.8423 - Avg Loss: 160.9869\n",
            "Epoch [32/50] - Batch loss: 171.2873 - Epoch Loss: 38969.1296 - Avg Loss: 161.0295\n",
            "Epoch [32/50] - Batch loss: 163.8589 - Epoch Loss: 39132.9885 - Avg Loss: 161.0411\n",
            "Epoch [32/50] - Batch loss: 165.7931 - Epoch Loss: 39298.7816 - Avg Loss: 161.0606\n",
            "Epoch [32/50] - Batch loss: 166.5205 - Epoch Loss: 39465.3021 - Avg Loss: 161.0829\n",
            "Epoch [32/50] - Batch loss: 164.9465 - Epoch Loss: 39630.2486 - Avg Loss: 161.0986\n",
            "Epoch [32/50] - Batch loss: 162.8014 - Epoch Loss: 39793.0500 - Avg Loss: 161.1055\n",
            "Epoch [32/50] - Batch loss: 159.4410 - Epoch Loss: 39952.4910 - Avg Loss: 161.0988\n",
            "Epoch [32/50] - Batch loss: 160.5092 - Epoch Loss: 40113.0001 - Avg Loss: 161.0964\n",
            "Epoch [32/50] - Batch loss: 155.1087 - Epoch Loss: 40268.1088 - Avg Loss: 161.0724\n",
            "Epoch [32/50] - Batch loss: 161.8008 - Epoch Loss: 40429.9096 - Avg Loss: 161.0753\n",
            "Epoch [32/50] - Batch loss: 160.2891 - Epoch Loss: 40590.1987 - Avg Loss: 161.0722\n",
            "Epoch [32/50] - Batch loss: 161.4743 - Epoch Loss: 40751.6730 - Avg Loss: 161.0738\n",
            "Epoch [32/50] - Batch loss: 160.4542 - Epoch Loss: 40912.1272 - Avg Loss: 161.0714\n",
            "Epoch [32/50] - Batch loss: 157.2051 - Epoch Loss: 41069.3323 - Avg Loss: 161.0562\n",
            "Epoch [32/50] - Batch loss: 163.1898 - Epoch Loss: 41232.5220 - Avg Loss: 161.0645\n",
            "Epoch [32/50] - Batch loss: 164.0752 - Epoch Loss: 41396.5973 - Avg Loss: 161.0763\n",
            "Epoch [32/50] - Batch loss: 161.1685 - Epoch Loss: 41557.7658 - Avg Loss: 161.0766\n",
            "Epoch [32/50] - Batch loss: 163.1622 - Epoch Loss: 41720.9280 - Avg Loss: 161.0847\n",
            "Epoch [32/50] - Batch loss: 156.9058 - Epoch Loss: 41877.8338 - Avg Loss: 161.0686\n",
            "Epoch [32/50] - Batch loss: 159.6949 - Epoch Loss: 42037.5287 - Avg Loss: 161.0633\n",
            "Epoch [32/50] - Batch loss: 162.5977 - Epoch Loss: 42200.1263 - Avg Loss: 161.0692\n",
            "Epoch [32/50] - Batch loss: 160.1157 - Epoch Loss: 42360.2420 - Avg Loss: 161.0656\n",
            "Epoch [32/50] - Batch loss: 166.5393 - Epoch Loss: 42526.7813 - Avg Loss: 161.0863\n",
            "Epoch [32/50] - Batch loss: 166.6921 - Epoch Loss: 42693.4734 - Avg Loss: 161.1074\n",
            "Epoch [32/50] - Batch loss: 164.8356 - Epoch Loss: 42858.3091 - Avg Loss: 161.1215\n",
            "Epoch [32/50] - Batch loss: 163.8917 - Epoch Loss: 43022.2008 - Avg Loss: 161.1318\n",
            "Epoch [32/50] - Batch loss: 160.0482 - Epoch Loss: 43182.2490 - Avg Loss: 161.1278\n",
            "Epoch [32/50] - Batch loss: 167.1647 - Epoch Loss: 43349.4137 - Avg Loss: 161.1502\n",
            "Epoch [32/50] - Batch loss: 162.1953 - Epoch Loss: 43511.6090 - Avg Loss: 161.1541\n",
            "Epoch [32/50] - Batch loss: 160.0066 - Epoch Loss: 43671.6156 - Avg Loss: 161.1499\n",
            "Epoch [32/50] - Batch loss: 159.9904 - Epoch Loss: 43831.6060 - Avg Loss: 161.1456\n",
            "Epoch [32/50] - Batch loss: 166.5288 - Epoch Loss: 43998.1349 - Avg Loss: 161.1653\n",
            "Epoch [32/50] - Batch loss: 158.2039 - Epoch Loss: 44156.3387 - Avg Loss: 161.1545\n",
            "Epoch [32/50] - Batch loss: 163.0966 - Epoch Loss: 44319.4353 - Avg Loss: 161.1616\n",
            "Epoch [32/50] - Batch loss: 154.8664 - Epoch Loss: 44474.3017 - Avg Loss: 161.1388\n",
            "Epoch [32/50] - Batch loss: 167.8466 - Epoch Loss: 44642.1483 - Avg Loss: 161.1630\n",
            "Epoch [32/50] - Batch loss: 158.9738 - Epoch Loss: 44801.1221 - Avg Loss: 161.1551\n",
            "Epoch [32/50] - Batch loss: 156.7582 - Epoch Loss: 44957.8802 - Avg Loss: 161.1394\n",
            "Epoch [32/50] - Batch loss: 166.7516 - Epoch Loss: 45124.6318 - Avg Loss: 161.1594\n",
            "Epoch [32/50] - Batch loss: 160.3302 - Epoch Loss: 45284.9620 - Avg Loss: 161.1564\n",
            "Epoch [32/50] - Batch loss: 159.0510 - Epoch Loss: 45444.0130 - Avg Loss: 161.1490\n",
            "Epoch [32/50] - Batch loss: 161.2205 - Epoch Loss: 45605.2336 - Avg Loss: 161.1492\n",
            "Epoch [32/50] - Batch loss: 167.5614 - Epoch Loss: 45772.7950 - Avg Loss: 161.1718\n",
            "Epoch [32/50] - Batch loss: 163.5791 - Epoch Loss: 45936.3740 - Avg Loss: 161.1803\n",
            "Epoch [32/50] - Batch loss: 161.3849 - Epoch Loss: 46097.7589 - Avg Loss: 161.1810\n",
            "Epoch [32/50] - Batch loss: 166.2114 - Epoch Loss: 46263.9704 - Avg Loss: 161.1985\n",
            "Epoch [32/50] - Batch loss: 166.2293 - Epoch Loss: 46430.1996 - Avg Loss: 161.2160\n",
            "Epoch [32/50] - Batch loss: 156.0662 - Epoch Loss: 46586.2659 - Avg Loss: 161.1982\n",
            "Epoch [32/50] - Batch loss: 163.1237 - Epoch Loss: 46749.3896 - Avg Loss: 161.2048\n",
            "Epoch [32/50] - Batch loss: 162.9185 - Epoch Loss: 46912.3081 - Avg Loss: 161.2107\n",
            "Epoch [32/50] - Batch loss: 163.8466 - Epoch Loss: 47076.1548 - Avg Loss: 161.2197\n",
            "Epoch [32/50] - Batch loss: 159.4939 - Epoch Loss: 47235.6486 - Avg Loss: 161.2138\n",
            "Epoch [32/50] - Batch loss: 166.4109 - Epoch Loss: 47402.0595 - Avg Loss: 161.2315\n",
            "Epoch [32/50] - Batch loss: 160.6252 - Epoch Loss: 47562.6847 - Avg Loss: 161.2294\n",
            "Epoch [32/50] - Batch loss: 161.9405 - Epoch Loss: 47724.6252 - Avg Loss: 161.2318\n",
            "Epoch [32/50] - Batch loss: 160.6584 - Epoch Loss: 47885.2836 - Avg Loss: 161.2299\n",
            "Epoch [32/50] - Batch loss: 161.4881 - Epoch Loss: 48046.7716 - Avg Loss: 161.2308\n",
            "Epoch [32/50] - Batch loss: 156.2896 - Epoch Loss: 48203.0612 - Avg Loss: 161.2143\n",
            "Epoch [32/50] - Batch loss: 161.3075 - Epoch Loss: 48364.3687 - Avg Loss: 161.2146\n",
            "Epoch [32/50] - Batch loss: 167.2894 - Epoch Loss: 48531.6581 - Avg Loss: 161.2347\n",
            "Epoch [32/50] - Batch loss: 161.9720 - Epoch Loss: 48693.6301 - Avg Loss: 161.2372\n",
            "Epoch [32/50] - Batch loss: 165.4649 - Epoch Loss: 48859.0950 - Avg Loss: 161.2511\n",
            "Epoch [32/50] - Batch loss: 162.9149 - Epoch Loss: 49022.0099 - Avg Loss: 161.2566\n",
            "Epoch [32/50] - Batch loss: 159.5352 - Epoch Loss: 49181.5451 - Avg Loss: 161.2510\n",
            "Epoch [32/50] - Batch loss: 153.8828 - Epoch Loss: 49335.4279 - Avg Loss: 161.2269\n",
            "Epoch [32/50] - Batch loss: 160.7376 - Epoch Loss: 49496.1655 - Avg Loss: 161.2253\n",
            "Epoch [32/50] - Batch loss: 151.7299 - Epoch Loss: 49647.8954 - Avg Loss: 161.1945\n",
            "Epoch [32/50] - Batch loss: 159.2303 - Epoch Loss: 49807.1257 - Avg Loss: 161.1881\n",
            "Epoch [32/50] - Batch loss: 163.6183 - Epoch Loss: 49970.7441 - Avg Loss: 161.1959\n",
            "Epoch [32/50] - Batch loss: 167.1023 - Epoch Loss: 50137.8464 - Avg Loss: 161.2149\n",
            "Epoch [32/50] - Batch loss: 159.8293 - Epoch Loss: 50297.6757 - Avg Loss: 161.2105\n",
            "Epoch [32/50] - Batch loss: 160.3720 - Epoch Loss: 50458.0477 - Avg Loss: 161.2078\n",
            "Epoch [32/50] - Batch loss: 159.6899 - Epoch Loss: 50617.7376 - Avg Loss: 161.2030\n",
            "Epoch [32/50] - Batch loss: 158.9208 - Epoch Loss: 50776.6584 - Avg Loss: 161.1957\n",
            "Epoch [32/50] - Batch loss: 154.7723 - Epoch Loss: 50931.4307 - Avg Loss: 161.1754\n",
            "Epoch [32/50] - Batch loss: 156.2664 - Epoch Loss: 51087.6971 - Avg Loss: 161.1599\n",
            "Epoch [32/50] - Batch loss: 157.4824 - Epoch Loss: 51245.1795 - Avg Loss: 161.1484\n",
            "Epoch [32/50] - Batch loss: 164.6804 - Epoch Loss: 51409.8599 - Avg Loss: 161.1594\n",
            "Epoch [32/50] - Batch loss: 154.4209 - Epoch Loss: 51564.2808 - Avg Loss: 161.1384\n",
            "Epoch [32/50] - Batch loss: 163.2798 - Epoch Loss: 51727.5606 - Avg Loss: 161.1450\n",
            "Epoch [32/50] - Batch loss: 156.4173 - Epoch Loss: 51883.9779 - Avg Loss: 161.1304\n",
            "Epoch [32/50] - Batch loss: 157.1197 - Epoch Loss: 52041.0976 - Avg Loss: 161.1179\n",
            "Epoch [32/50] - Batch loss: 164.6183 - Epoch Loss: 52205.7159 - Avg Loss: 161.1288\n",
            "Epoch [32/50] - Batch loss: 155.5012 - Epoch Loss: 52361.2172 - Avg Loss: 161.1114\n",
            "Epoch [32/50] - Batch loss: 162.1481 - Epoch Loss: 52523.3653 - Avg Loss: 161.1146\n",
            "Epoch [32/50] - Batch loss: 163.4998 - Epoch Loss: 52686.8651 - Avg Loss: 161.1219\n",
            "Epoch [32/50] - Batch loss: 154.4594 - Epoch Loss: 52841.3245 - Avg Loss: 161.1016\n",
            "Epoch [32/50] - Batch loss: 152.5683 - Epoch Loss: 52993.8928 - Avg Loss: 161.0757\n",
            "Epoch [32/50] - Batch loss: 150.9610 - Epoch Loss: 53144.8538 - Avg Loss: 161.0450\n",
            "Epoch [32/50] - Batch loss: 151.4261 - Epoch Loss: 53296.2799 - Avg Loss: 161.0160\n",
            "Epoch [32/50] - Batch loss: 156.8500 - Epoch Loss: 53453.1298 - Avg Loss: 161.0034\n",
            "Epoch [32/50] - Batch loss: 158.6212 - Epoch Loss: 53611.7511 - Avg Loss: 160.9962\n",
            "Epoch [32/50] - Batch loss: 157.7243 - Epoch Loss: 53769.4753 - Avg Loss: 160.9865\n",
            "Epoch [32/50] - Batch loss: 167.0486 - Epoch Loss: 53936.5239 - Avg Loss: 161.0045\n",
            "Epoch [32/50] - Batch loss: 164.1355 - Epoch Loss: 54100.6594 - Avg Loss: 161.0139\n",
            "Epoch [32/50] - Batch loss: 159.2504 - Epoch Loss: 54259.9098 - Avg Loss: 161.0086\n",
            "Epoch [32/50] - Batch loss: 160.6936 - Epoch Loss: 54420.6034 - Avg Loss: 161.0077\n",
            "Epoch [32/50] - Batch loss: 156.1934 - Epoch Loss: 54576.7968 - Avg Loss: 160.9935\n",
            "Epoch [32/50] - Batch loss: 153.0643 - Epoch Loss: 54729.8611 - Avg Loss: 160.9702\n",
            "Epoch [32/50] - Batch loss: 155.7551 - Epoch Loss: 54885.6162 - Avg Loss: 160.9549\n",
            "Epoch [32/50] - Batch loss: 160.7383 - Epoch Loss: 55046.3545 - Avg Loss: 160.9543\n",
            "Epoch [32/50] - Batch loss: 164.5749 - Epoch Loss: 55210.9294 - Avg Loss: 160.9648\n",
            "Epoch [32/50] - Batch loss: 161.1828 - Epoch Loss: 55372.1122 - Avg Loss: 160.9654\n",
            "Epoch [32/50] - Batch loss: 163.7656 - Epoch Loss: 55535.8777 - Avg Loss: 160.9736\n",
            "Epoch [32/50] - Batch loss: 158.7937 - Epoch Loss: 55694.6715 - Avg Loss: 160.9673\n",
            "Epoch [32/50] - Batch loss: 154.6084 - Epoch Loss: 55849.2799 - Avg Loss: 160.9489\n",
            "Epoch [32/50] - Batch loss: 156.9659 - Epoch Loss: 56006.2457 - Avg Loss: 160.9375\n",
            "Epoch [32/50] - Batch loss: 156.9678 - Epoch Loss: 56163.2136 - Avg Loss: 160.9261\n",
            "Epoch [32/50] - Batch loss: 157.7989 - Epoch Loss: 56321.0125 - Avg Loss: 160.9172\n",
            "Epoch [32/50] - Batch loss: 155.1365 - Epoch Loss: 56476.1490 - Avg Loss: 160.9007\n",
            "Epoch [32/50] - Batch loss: 154.7403 - Epoch Loss: 56630.8893 - Avg Loss: 160.8832\n",
            "Epoch [32/50] - Batch loss: 155.2797 - Epoch Loss: 56786.1690 - Avg Loss: 160.8673\n",
            "Epoch [32/50] - Batch loss: 168.5784 - Epoch Loss: 56954.7473 - Avg Loss: 160.8891\n",
            "Epoch [32/50] - Batch loss: 157.1180 - Epoch Loss: 57111.8653 - Avg Loss: 160.8785\n",
            "Epoch [32/50] - Batch loss: 155.9549 - Epoch Loss: 57267.8203 - Avg Loss: 160.8647\n",
            "Epoch [32/50] - Batch loss: 158.8151 - Epoch Loss: 57426.6353 - Avg Loss: 160.8589\n",
            "Epoch [32/50] - Batch loss: 159.2677 - Epoch Loss: 57585.9031 - Avg Loss: 160.8545\n",
            "Epoch [32/50] - Batch loss: 163.9848 - Epoch Loss: 57749.8878 - Avg Loss: 160.8632\n",
            "Epoch [32/50] - Batch loss: 155.7883 - Epoch Loss: 57905.6761 - Avg Loss: 160.8491\n",
            "Epoch [32/50] - Batch loss: 163.1017 - Epoch Loss: 58068.7779 - Avg Loss: 160.8553\n",
            "Epoch [32/50] - Batch loss: 161.2049 - Epoch Loss: 58229.9828 - Avg Loss: 160.8563\n",
            "Epoch [32/50] - Batch loss: 153.5038 - Epoch Loss: 58383.4866 - Avg Loss: 160.8361\n",
            "Epoch [32/50] - Batch loss: 164.8747 - Epoch Loss: 58548.3613 - Avg Loss: 160.8471\n",
            "Epoch [32/50] - Batch loss: 161.8486 - Epoch Loss: 58710.2099 - Avg Loss: 160.8499\n",
            "Epoch [32/50] - Batch loss: 161.3193 - Epoch Loss: 58871.5292 - Avg Loss: 160.8512\n",
            "Epoch [32/50] - Batch loss: 162.7229 - Epoch Loss: 59034.2522 - Avg Loss: 160.8563\n",
            "Epoch [32/50] - Batch loss: 162.0728 - Epoch Loss: 59196.3250 - Avg Loss: 160.8596\n",
            "Epoch [32/50] - Batch loss: 164.2814 - Epoch Loss: 59360.6064 - Avg Loss: 160.8689\n",
            "Epoch [32/50] - Batch loss: 160.7717 - Epoch Loss: 59521.3781 - Avg Loss: 160.8686\n",
            "Epoch [32/50] - Batch loss: 157.6409 - Epoch Loss: 59679.0189 - Avg Loss: 160.8599\n",
            "Epoch [32/50] - Batch loss: 168.8646 - Epoch Loss: 59847.8835 - Avg Loss: 160.8814\n",
            "Epoch [32/50] - Batch loss: 162.1785 - Epoch Loss: 60010.0620 - Avg Loss: 160.8849\n",
            "Epoch [32/50] - Batch loss: 168.6852 - Epoch Loss: 60178.7471 - Avg Loss: 160.9057\n",
            "Epoch [32/50] - Batch loss: 164.7540 - Epoch Loss: 60343.5011 - Avg Loss: 160.9160\n",
            "Epoch [32/50] - Batch loss: 164.7020 - Epoch Loss: 60508.2032 - Avg Loss: 160.9261\n",
            "Epoch [32/50] - Batch loss: 164.0815 - Epoch Loss: 60672.2847 - Avg Loss: 160.9344\n",
            "Epoch [32/50] - Batch loss: 160.3310 - Epoch Loss: 60832.6157 - Avg Loss: 160.9328\n",
            "Epoch [32/50] - Batch loss: 161.7215 - Epoch Loss: 60994.3372 - Avg Loss: 160.9349\n",
            "Epoch [32/50] - Batch loss: 159.7630 - Epoch Loss: 61154.1001 - Avg Loss: 160.9318\n",
            "Epoch [32/50] - Batch loss: 160.2243 - Epoch Loss: 61314.3244 - Avg Loss: 160.9300\n",
            "Epoch [32/50] - Batch loss: 163.1447 - Epoch Loss: 61477.4692 - Avg Loss: 160.9358\n",
            "Epoch [32/50] - Batch loss: 157.1323 - Epoch Loss: 61634.6015 - Avg Loss: 160.9259\n",
            "Epoch [32/50] - Batch loss: 165.8226 - Epoch Loss: 61800.4241 - Avg Loss: 160.9386\n",
            "Epoch [32/50] - Batch loss: 153.9798 - Epoch Loss: 61954.4040 - Avg Loss: 160.9205\n",
            "Epoch [32/50] - Batch loss: 164.4968 - Epoch Loss: 62118.9008 - Avg Loss: 160.9298\n",
            "Epoch [32/50] - Batch loss: 161.6938 - Epoch Loss: 62280.5945 - Avg Loss: 160.9318\n",
            "Epoch [32/50] - Batch loss: 163.3776 - Epoch Loss: 62443.9722 - Avg Loss: 160.9381\n",
            "Epoch [32/50] - Batch loss: 164.0802 - Epoch Loss: 62608.0524 - Avg Loss: 160.9462\n",
            "Epoch [32/50] - Batch loss: 164.7943 - Epoch Loss: 62772.8466 - Avg Loss: 160.9560\n",
            "Epoch [32/50] - Batch loss: 156.6415 - Epoch Loss: 62929.4881 - Avg Loss: 160.9450\n",
            "Epoch [32/50] - Batch loss: 164.7158 - Epoch Loss: 63094.2039 - Avg Loss: 160.9546\n",
            "Epoch [32/50] - Batch loss: 155.7115 - Epoch Loss: 63249.9154 - Avg Loss: 160.9413\n",
            "Epoch [32/50] - Batch loss: 164.7497 - Epoch Loss: 63414.6652 - Avg Loss: 160.9509\n",
            "Epoch [32/50] - Batch loss: 162.5088 - Epoch Loss: 63577.1740 - Avg Loss: 160.9549\n",
            "Epoch [32/50] - Batch loss: 153.7892 - Epoch Loss: 63730.9632 - Avg Loss: 160.9368\n",
            "Epoch [32/50] - Batch loss: 163.4492 - Epoch Loss: 63894.4124 - Avg Loss: 160.9431\n",
            "Epoch [32/50] - Batch loss: 164.3158 - Epoch Loss: 64058.7282 - Avg Loss: 160.9516\n",
            "Epoch [32/50] - Batch loss: 156.5955 - Epoch Loss: 64215.3237 - Avg Loss: 160.9407\n",
            "Epoch [32/50] - Batch loss: 159.5402 - Epoch Loss: 64374.8639 - Avg Loss: 160.9372\n",
            "Epoch [32/50] - Batch loss: 163.1189 - Epoch Loss: 64537.9828 - Avg Loss: 160.9426\n",
            "Epoch [32/50] - Batch loss: 167.3562 - Epoch Loss: 64705.3390 - Avg Loss: 160.9586\n",
            "Epoch [32/50] - Batch loss: 167.9813 - Epoch Loss: 64873.3203 - Avg Loss: 160.9760\n",
            "Epoch [32/50] - Batch loss: 166.7837 - Epoch Loss: 65040.1040 - Avg Loss: 160.9904\n",
            "Epoch [32/50] - Batch loss: 166.4816 - Epoch Loss: 65206.5856 - Avg Loss: 161.0039\n",
            "Epoch [32/50] - Batch loss: 166.1187 - Epoch Loss: 65372.7043 - Avg Loss: 161.0165\n",
            "Epoch [32/50] - Batch loss: 164.8111 - Epoch Loss: 65537.5154 - Avg Loss: 161.0258\n",
            "Epoch [32/50] - Batch loss: 157.9362 - Epoch Loss: 65695.4516 - Avg Loss: 161.0183\n",
            "Epoch [32/50] - Batch loss: 166.2549 - Epoch Loss: 65861.7065 - Avg Loss: 161.0311\n",
            "Epoch [32/50] - Batch loss: 161.0894 - Epoch Loss: 66022.7959 - Avg Loss: 161.0312\n",
            "Epoch [32/50] - Batch loss: 161.9777 - Epoch Loss: 66184.7736 - Avg Loss: 161.0335\n",
            "Epoch [32/50] - Batch loss: 163.2956 - Epoch Loss: 66348.0692 - Avg Loss: 161.0390\n",
            "Epoch [32/50] - Batch loss: 162.9525 - Epoch Loss: 66511.0217 - Avg Loss: 161.0436\n",
            "Epoch [32/50] - Batch loss: 167.4471 - Epoch Loss: 66678.4687 - Avg Loss: 161.0591\n",
            "Epoch [32/50] - Batch loss: 156.3774 - Epoch Loss: 66834.8461 - Avg Loss: 161.0478\n",
            "Epoch [32/50] - Batch loss: 165.9684 - Epoch Loss: 67000.8145 - Avg Loss: 161.0597\n",
            "Epoch [32/50] - Batch loss: 163.6792 - Epoch Loss: 67164.4938 - Avg Loss: 161.0659\n",
            "Epoch [32/50] - Batch loss: 168.2637 - Epoch Loss: 67332.7575 - Avg Loss: 161.0832\n",
            "Epoch [32/50] - Batch loss: 151.9990 - Epoch Loss: 67484.7565 - Avg Loss: 161.0615\n",
            "Epoch [32/50] - Batch loss: 155.8129 - Epoch Loss: 67640.5694 - Avg Loss: 161.0490\n",
            "Epoch [32/50] - Batch loss: 159.3846 - Epoch Loss: 67799.9540 - Avg Loss: 161.0450\n",
            "Epoch [32/50] - Batch loss: 158.4551 - Epoch Loss: 67958.4091 - Avg Loss: 161.0389\n",
            "Epoch [32/50] - Batch loss: 170.2792 - Epoch Loss: 68128.6884 - Avg Loss: 161.0607\n",
            "Epoch [32/50] - Batch loss: 163.3446 - Epoch Loss: 68292.0330 - Avg Loss: 161.0661\n",
            "Epoch [32/50] - Batch loss: 160.1479 - Epoch Loss: 68452.1809 - Avg Loss: 161.0640\n",
            "Epoch [32/50] - Batch loss: 159.7672 - Epoch Loss: 68611.9481 - Avg Loss: 161.0609\n",
            "Epoch [32/50] - Batch loss: 164.0538 - Epoch Loss: 68776.0019 - Avg Loss: 161.0679\n",
            "Epoch [32/50] - Batch loss: 163.4619 - Epoch Loss: 68939.4638 - Avg Loss: 161.0735\n",
            "Epoch [32/50] - Batch loss: 159.0998 - Epoch Loss: 69098.5635 - Avg Loss: 161.0689\n",
            "Epoch [32/50] - Batch loss: 157.4431 - Epoch Loss: 69256.0066 - Avg Loss: 161.0605\n",
            "Epoch [32/50] - Batch loss: 167.2162 - Epoch Loss: 69423.2229 - Avg Loss: 161.0748\n",
            "Epoch [32/50] - Batch loss: 160.5836 - Epoch Loss: 69583.8065 - Avg Loss: 161.0736\n",
            "Epoch [32/50] - Batch loss: 156.3261 - Epoch Loss: 69740.1326 - Avg Loss: 161.0627\n",
            "Epoch [32/50] - Batch loss: 168.2655 - Epoch Loss: 69908.3981 - Avg Loss: 161.0793\n",
            "Epoch [32/50] - Batch loss: 155.4438 - Epoch Loss: 70063.8419 - Avg Loss: 161.0663\n",
            "Epoch [32/50] - Batch loss: 165.6299 - Epoch Loss: 70229.4718 - Avg Loss: 161.0768\n",
            "Epoch [32/50] - Batch loss: 166.2641 - Epoch Loss: 70395.7358 - Avg Loss: 161.0886\n",
            "Epoch [32/50] - Batch loss: 156.4506 - Epoch Loss: 70552.1865 - Avg Loss: 161.0781\n",
            "Epoch [32/50] - Batch loss: 161.8990 - Epoch Loss: 70714.0855 - Avg Loss: 161.0799\n",
            "Epoch [32/50] - Batch loss: 158.6060 - Epoch Loss: 70872.6915 - Avg Loss: 161.0743\n",
            "Epoch [32/50] - Batch loss: 163.3231 - Epoch Loss: 71036.0146 - Avg Loss: 161.0794\n",
            "Epoch [32/50] - Batch loss: 160.3440 - Epoch Loss: 71196.3586 - Avg Loss: 161.0777\n",
            "Epoch [32/50] - Batch loss: 160.4870 - Epoch Loss: 71356.8456 - Avg Loss: 161.0764\n",
            "Epoch [32/50] - Batch loss: 160.4033 - Epoch Loss: 71517.2489 - Avg Loss: 161.0749\n",
            "Epoch [32/50] - Batch loss: 165.8427 - Epoch Loss: 71683.0916 - Avg Loss: 161.0856\n",
            "Epoch [32/50] - Batch loss: 161.1585 - Epoch Loss: 71844.2501 - Avg Loss: 161.0858\n",
            "Epoch [32/50] - Batch loss: 152.6666 - Epoch Loss: 71996.9167 - Avg Loss: 161.0669\n",
            "Epoch [32/50] - Batch loss: 155.9639 - Epoch Loss: 72152.8805 - Avg Loss: 161.0555\n",
            "Epoch [32/50] - Batch loss: 168.2734 - Epoch Loss: 72321.1540 - Avg Loss: 161.0716\n",
            "Epoch [32/50] - Batch loss: 162.8770 - Epoch Loss: 72484.0310 - Avg Loss: 161.0756\n",
            "Epoch [32/50] - Batch loss: 160.5995 - Epoch Loss: 72644.6305 - Avg Loss: 161.0746\n",
            "Epoch [32/50] - Batch loss: 159.5445 - Epoch Loss: 72804.1750 - Avg Loss: 161.0712\n",
            "Epoch [32/50] - Batch loss: 157.0103 - Epoch Loss: 72961.1854 - Avg Loss: 161.0622\n",
            "Epoch [32/50] - Batch loss: 160.8278 - Epoch Loss: 73122.0132 - Avg Loss: 161.0617\n",
            "Epoch [32/50] - Batch loss: 164.1165 - Epoch Loss: 73286.1297 - Avg Loss: 161.0684\n",
            "Epoch [32/50] - Batch loss: 154.8623 - Epoch Loss: 73440.9919 - Avg Loss: 161.0548\n",
            "Epoch [32/50] - Batch loss: 159.0617 - Epoch Loss: 73600.0537 - Avg Loss: 161.0504\n",
            "Epoch [32/50] - Batch loss: 160.9485 - Epoch Loss: 73761.0021 - Avg Loss: 161.0502\n",
            "Epoch [32/50] - Batch loss: 159.6106 - Epoch Loss: 73920.6127 - Avg Loss: 161.0471\n",
            "Epoch [32/50] - Batch loss: 160.7260 - Epoch Loss: 74081.3387 - Avg Loss: 161.0464\n",
            "Epoch [32/50] - Batch loss: 158.9999 - Epoch Loss: 74240.3386 - Avg Loss: 161.0419\n",
            "Epoch [32/50] - Batch loss: 156.5757 - Epoch Loss: 74396.9143 - Avg Loss: 161.0323\n",
            "Epoch [32/50] - Batch loss: 162.7428 - Epoch Loss: 74559.6572 - Avg Loss: 161.0360\n",
            "Epoch [32/50] - Batch loss: 155.7882 - Epoch Loss: 74715.4453 - Avg Loss: 161.0247\n",
            "Epoch [32/50] - Batch loss: 167.2835 - Epoch Loss: 74882.7289 - Avg Loss: 161.0381\n",
            "Epoch [32/50] - Batch loss: 171.7060 - Epoch Loss: 75054.4348 - Avg Loss: 161.0610\n",
            "Epoch [32/50] - Batch loss: 164.9616 - Epoch Loss: 75219.3964 - Avg Loss: 161.0694\n",
            "Epoch [32/50] - Batch loss: 157.6354 - Epoch Loss: 75377.0318 - Avg Loss: 161.0620\n",
            "Epoch [32/50] - Batch loss: 160.3944 - Epoch Loss: 75537.4261 - Avg Loss: 161.0606\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 33/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "abecedb8556f415db0892ed17e4130ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [33/50] - Batch loss: 162.4883 - Epoch Loss: 162.4883 - Avg Loss: 162.4883\n",
            "Epoch [33/50] - Batch loss: 166.4006 - Epoch Loss: 328.8889 - Avg Loss: 164.4445\n",
            "Epoch [33/50] - Batch loss: 154.1693 - Epoch Loss: 483.0583 - Avg Loss: 161.0194\n",
            "Epoch [33/50] - Batch loss: 167.9504 - Epoch Loss: 651.0086 - Avg Loss: 162.7522\n",
            "Epoch [33/50] - Batch loss: 166.6723 - Epoch Loss: 817.6809 - Avg Loss: 163.5362\n",
            "Epoch [33/50] - Batch loss: 159.1398 - Epoch Loss: 976.8208 - Avg Loss: 162.8035\n",
            "Epoch [33/50] - Batch loss: 164.9501 - Epoch Loss: 1141.7709 - Avg Loss: 163.1101\n",
            "Epoch [33/50] - Batch loss: 162.6002 - Epoch Loss: 1304.3711 - Avg Loss: 163.0464\n",
            "Epoch [33/50] - Batch loss: 162.1961 - Epoch Loss: 1466.5672 - Avg Loss: 162.9519\n",
            "Epoch [33/50] - Batch loss: 163.4912 - Epoch Loss: 1630.0583 - Avg Loss: 163.0058\n",
            "Epoch [33/50] - Batch loss: 160.2973 - Epoch Loss: 1790.3556 - Avg Loss: 162.7596\n",
            "Epoch [33/50] - Batch loss: 162.6126 - Epoch Loss: 1952.9682 - Avg Loss: 162.7474\n",
            "Epoch [33/50] - Batch loss: 156.5985 - Epoch Loss: 2109.5668 - Avg Loss: 162.2744\n",
            "Epoch [33/50] - Batch loss: 159.6040 - Epoch Loss: 2269.1707 - Avg Loss: 162.0836\n",
            "Epoch [33/50] - Batch loss: 164.5608 - Epoch Loss: 2433.7315 - Avg Loss: 162.2488\n",
            "Epoch [33/50] - Batch loss: 160.7162 - Epoch Loss: 2594.4477 - Avg Loss: 162.1530\n",
            "Epoch [33/50] - Batch loss: 153.9007 - Epoch Loss: 2748.3484 - Avg Loss: 161.6676\n",
            "Epoch [33/50] - Batch loss: 155.9369 - Epoch Loss: 2904.2852 - Avg Loss: 161.3492\n",
            "Epoch [33/50] - Batch loss: 162.4312 - Epoch Loss: 3066.7164 - Avg Loss: 161.4061\n",
            "Epoch [33/50] - Batch loss: 162.3926 - Epoch Loss: 3229.1091 - Avg Loss: 161.4555\n",
            "Epoch [33/50] - Batch loss: 159.6959 - Epoch Loss: 3388.8049 - Avg Loss: 161.3717\n",
            "Epoch [33/50] - Batch loss: 155.3010 - Epoch Loss: 3544.1059 - Avg Loss: 161.0957\n",
            "Epoch [33/50] - Batch loss: 158.4204 - Epoch Loss: 3702.5263 - Avg Loss: 160.9794\n",
            "Epoch [33/50] - Batch loss: 161.8345 - Epoch Loss: 3864.3608 - Avg Loss: 161.0150\n",
            "Epoch [33/50] - Batch loss: 156.6022 - Epoch Loss: 4020.9630 - Avg Loss: 160.8385\n",
            "Epoch [33/50] - Batch loss: 160.3571 - Epoch Loss: 4181.3201 - Avg Loss: 160.8200\n",
            "Epoch [33/50] - Batch loss: 161.6116 - Epoch Loss: 4342.9317 - Avg Loss: 160.8493\n",
            "Epoch [33/50] - Batch loss: 158.8407 - Epoch Loss: 4501.7725 - Avg Loss: 160.7776\n",
            "Epoch [33/50] - Batch loss: 156.9784 - Epoch Loss: 4658.7509 - Avg Loss: 160.6466\n",
            "Epoch [33/50] - Batch loss: 163.1041 - Epoch Loss: 4821.8550 - Avg Loss: 160.7285\n",
            "Epoch [33/50] - Batch loss: 157.6443 - Epoch Loss: 4979.4993 - Avg Loss: 160.6290\n",
            "Epoch [33/50] - Batch loss: 158.9443 - Epoch Loss: 5138.4436 - Avg Loss: 160.5764\n",
            "Epoch [33/50] - Batch loss: 163.0407 - Epoch Loss: 5301.4843 - Avg Loss: 160.6510\n",
            "Epoch [33/50] - Batch loss: 160.9777 - Epoch Loss: 5462.4620 - Avg Loss: 160.6606\n",
            "Epoch [33/50] - Batch loss: 164.6567 - Epoch Loss: 5627.1187 - Avg Loss: 160.7748\n",
            "Epoch [33/50] - Batch loss: 155.5933 - Epoch Loss: 5782.7120 - Avg Loss: 160.6309\n",
            "Epoch [33/50] - Batch loss: 159.2385 - Epoch Loss: 5941.9505 - Avg Loss: 160.5933\n",
            "Epoch [33/50] - Batch loss: 164.5464 - Epoch Loss: 6106.4969 - Avg Loss: 160.6973\n",
            "Epoch [33/50] - Batch loss: 157.5837 - Epoch Loss: 6264.0806 - Avg Loss: 160.6175\n",
            "Epoch [33/50] - Batch loss: 154.3883 - Epoch Loss: 6418.4689 - Avg Loss: 160.4617\n",
            "Epoch [33/50] - Batch loss: 161.6450 - Epoch Loss: 6580.1140 - Avg Loss: 160.4906\n",
            "Epoch [33/50] - Batch loss: 153.2286 - Epoch Loss: 6733.3426 - Avg Loss: 160.3177\n",
            "Epoch [33/50] - Batch loss: 163.5845 - Epoch Loss: 6896.9270 - Avg Loss: 160.3937\n",
            "Epoch [33/50] - Batch loss: 159.3414 - Epoch Loss: 7056.2684 - Avg Loss: 160.3697\n",
            "Epoch [33/50] - Batch loss: 155.6733 - Epoch Loss: 7211.9417 - Avg Loss: 160.2654\n",
            "Epoch [33/50] - Batch loss: 165.1217 - Epoch Loss: 7377.0634 - Avg Loss: 160.3709\n",
            "Epoch [33/50] - Batch loss: 160.7991 - Epoch Loss: 7537.8625 - Avg Loss: 160.3801\n",
            "Epoch [33/50] - Batch loss: 160.2316 - Epoch Loss: 7698.0941 - Avg Loss: 160.3770\n",
            "Epoch [33/50] - Batch loss: 153.9441 - Epoch Loss: 7852.0382 - Avg Loss: 160.2457\n",
            "Epoch [33/50] - Batch loss: 161.7498 - Epoch Loss: 8013.7880 - Avg Loss: 160.2758\n",
            "Epoch [33/50] - Batch loss: 155.5347 - Epoch Loss: 8169.3228 - Avg Loss: 160.1828\n",
            "Epoch [33/50] - Batch loss: 153.9192 - Epoch Loss: 8323.2419 - Avg Loss: 160.0623\n",
            "Epoch [33/50] - Batch loss: 155.9945 - Epoch Loss: 8479.2364 - Avg Loss: 159.9856\n",
            "Epoch [33/50] - Batch loss: 165.8760 - Epoch Loss: 8645.1124 - Avg Loss: 160.0947\n",
            "Epoch [33/50] - Batch loss: 165.4445 - Epoch Loss: 8810.5569 - Avg Loss: 160.1919\n",
            "Epoch [33/50] - Batch loss: 151.1278 - Epoch Loss: 8961.6848 - Avg Loss: 160.0301\n",
            "Epoch [33/50] - Batch loss: 154.3750 - Epoch Loss: 9116.0597 - Avg Loss: 159.9309\n",
            "Epoch [33/50] - Batch loss: 153.0285 - Epoch Loss: 9269.0882 - Avg Loss: 159.8119\n",
            "Epoch [33/50] - Batch loss: 164.5327 - Epoch Loss: 9433.6208 - Avg Loss: 159.8919\n",
            "Epoch [33/50] - Batch loss: 157.4970 - Epoch Loss: 9591.1178 - Avg Loss: 159.8520\n",
            "Epoch [33/50] - Batch loss: 151.7711 - Epoch Loss: 9742.8889 - Avg Loss: 159.7195\n",
            "Epoch [33/50] - Batch loss: 167.6352 - Epoch Loss: 9910.5240 - Avg Loss: 159.8472\n",
            "Epoch [33/50] - Batch loss: 157.8574 - Epoch Loss: 10068.3814 - Avg Loss: 159.8156\n",
            "Epoch [33/50] - Batch loss: 157.6126 - Epoch Loss: 10225.9940 - Avg Loss: 159.7812\n",
            "Epoch [33/50] - Batch loss: 162.9364 - Epoch Loss: 10388.9304 - Avg Loss: 159.8297\n",
            "Epoch [33/50] - Batch loss: 164.2805 - Epoch Loss: 10553.2109 - Avg Loss: 159.8971\n",
            "Epoch [33/50] - Batch loss: 156.6600 - Epoch Loss: 10709.8709 - Avg Loss: 159.8488\n",
            "Epoch [33/50] - Batch loss: 162.0506 - Epoch Loss: 10871.9215 - Avg Loss: 159.8812\n",
            "Epoch [33/50] - Batch loss: 160.5366 - Epoch Loss: 11032.4581 - Avg Loss: 159.8907\n",
            "Epoch [33/50] - Batch loss: 166.7294 - Epoch Loss: 11199.1875 - Avg Loss: 159.9884\n",
            "Epoch [33/50] - Batch loss: 160.5762 - Epoch Loss: 11359.7637 - Avg Loss: 159.9967\n",
            "Epoch [33/50] - Batch loss: 165.7003 - Epoch Loss: 11525.4639 - Avg Loss: 160.0759\n",
            "Epoch [33/50] - Batch loss: 161.3236 - Epoch Loss: 11686.7875 - Avg Loss: 160.0930\n",
            "Epoch [33/50] - Batch loss: 161.8802 - Epoch Loss: 11848.6677 - Avg Loss: 160.1171\n",
            "Epoch [33/50] - Batch loss: 158.0489 - Epoch Loss: 12006.7166 - Avg Loss: 160.0896\n",
            "Epoch [33/50] - Batch loss: 160.0783 - Epoch Loss: 12166.7949 - Avg Loss: 160.0894\n",
            "Epoch [33/50] - Batch loss: 162.9515 - Epoch Loss: 12329.7464 - Avg Loss: 160.1266\n",
            "Epoch [33/50] - Batch loss: 157.3055 - Epoch Loss: 12487.0518 - Avg Loss: 160.0904\n",
            "Epoch [33/50] - Batch loss: 150.9172 - Epoch Loss: 12637.9690 - Avg Loss: 159.9743\n",
            "Epoch [33/50] - Batch loss: 156.2062 - Epoch Loss: 12794.1752 - Avg Loss: 159.9272\n",
            "Epoch [33/50] - Batch loss: 166.6003 - Epoch Loss: 12960.7756 - Avg Loss: 160.0096\n",
            "Epoch [33/50] - Batch loss: 155.1436 - Epoch Loss: 13115.9192 - Avg Loss: 159.9502\n",
            "Epoch [33/50] - Batch loss: 151.8026 - Epoch Loss: 13267.7218 - Avg Loss: 159.8521\n",
            "Epoch [33/50] - Batch loss: 151.0136 - Epoch Loss: 13418.7354 - Avg Loss: 159.7468\n",
            "Epoch [33/50] - Batch loss: 158.9639 - Epoch Loss: 13577.6992 - Avg Loss: 159.7376\n",
            "Epoch [33/50] - Batch loss: 155.2414 - Epoch Loss: 13732.9407 - Avg Loss: 159.6854\n",
            "Epoch [33/50] - Batch loss: 157.8970 - Epoch Loss: 13890.8377 - Avg Loss: 159.6648\n",
            "Epoch [33/50] - Batch loss: 164.4112 - Epoch Loss: 14055.2489 - Avg Loss: 159.7187\n",
            "Epoch [33/50] - Batch loss: 159.8429 - Epoch Loss: 14215.0918 - Avg Loss: 159.7201\n",
            "Epoch [33/50] - Batch loss: 164.7153 - Epoch Loss: 14379.8071 - Avg Loss: 159.7756\n",
            "Epoch [33/50] - Batch loss: 158.4569 - Epoch Loss: 14538.2641 - Avg Loss: 159.7611\n",
            "Epoch [33/50] - Batch loss: 155.7425 - Epoch Loss: 14694.0066 - Avg Loss: 159.7175\n",
            "Epoch [33/50] - Batch loss: 165.3567 - Epoch Loss: 14859.3633 - Avg Loss: 159.7781\n",
            "Epoch [33/50] - Batch loss: 155.2523 - Epoch Loss: 15014.6156 - Avg Loss: 159.7300\n",
            "Epoch [33/50] - Batch loss: 157.7956 - Epoch Loss: 15172.4113 - Avg Loss: 159.7096\n",
            "Epoch [33/50] - Batch loss: 160.7995 - Epoch Loss: 15333.2108 - Avg Loss: 159.7209\n",
            "Epoch [33/50] - Batch loss: 163.1661 - Epoch Loss: 15496.3769 - Avg Loss: 159.7565\n",
            "Epoch [33/50] - Batch loss: 166.2112 - Epoch Loss: 15662.5881 - Avg Loss: 159.8223\n",
            "Epoch [33/50] - Batch loss: 162.1491 - Epoch Loss: 15824.7372 - Avg Loss: 159.8458\n",
            "Epoch [33/50] - Batch loss: 160.5311 - Epoch Loss: 15985.2683 - Avg Loss: 159.8527\n",
            "Epoch [33/50] - Batch loss: 158.7252 - Epoch Loss: 16143.9935 - Avg Loss: 159.8415\n",
            "Epoch [33/50] - Batch loss: 158.1932 - Epoch Loss: 16302.1867 - Avg Loss: 159.8254\n",
            "Epoch [33/50] - Batch loss: 161.3839 - Epoch Loss: 16463.5706 - Avg Loss: 159.8405\n",
            "Epoch [33/50] - Batch loss: 160.0401 - Epoch Loss: 16623.6107 - Avg Loss: 159.8424\n",
            "Epoch [33/50] - Batch loss: 164.3446 - Epoch Loss: 16787.9553 - Avg Loss: 159.8853\n",
            "Epoch [33/50] - Batch loss: 160.7410 - Epoch Loss: 16948.6963 - Avg Loss: 159.8934\n",
            "Epoch [33/50] - Batch loss: 160.0219 - Epoch Loss: 17108.7182 - Avg Loss: 159.8946\n",
            "Epoch [33/50] - Batch loss: 166.5300 - Epoch Loss: 17275.2481 - Avg Loss: 159.9560\n",
            "Epoch [33/50] - Batch loss: 155.9017 - Epoch Loss: 17431.1498 - Avg Loss: 159.9188\n",
            "Epoch [33/50] - Batch loss: 156.8522 - Epoch Loss: 17588.0020 - Avg Loss: 159.8909\n",
            "Epoch [33/50] - Batch loss: 156.0656 - Epoch Loss: 17744.0676 - Avg Loss: 159.8565\n",
            "Epoch [33/50] - Batch loss: 151.7484 - Epoch Loss: 17895.8160 - Avg Loss: 159.7841\n",
            "Epoch [33/50] - Batch loss: 161.5556 - Epoch Loss: 18057.3716 - Avg Loss: 159.7997\n",
            "Epoch [33/50] - Batch loss: 160.5948 - Epoch Loss: 18217.9665 - Avg Loss: 159.8067\n",
            "Epoch [33/50] - Batch loss: 153.1763 - Epoch Loss: 18371.1428 - Avg Loss: 159.7491\n",
            "Epoch [33/50] - Batch loss: 159.2610 - Epoch Loss: 18530.4038 - Avg Loss: 159.7449\n",
            "Epoch [33/50] - Batch loss: 154.5450 - Epoch Loss: 18684.9488 - Avg Loss: 159.7004\n",
            "Epoch [33/50] - Batch loss: 163.7414 - Epoch Loss: 18848.6902 - Avg Loss: 159.7347\n",
            "Epoch [33/50] - Batch loss: 166.0303 - Epoch Loss: 19014.7205 - Avg Loss: 159.7876\n",
            "Epoch [33/50] - Batch loss: 155.8150 - Epoch Loss: 19170.5355 - Avg Loss: 159.7545\n",
            "Epoch [33/50] - Batch loss: 157.0252 - Epoch Loss: 19327.5607 - Avg Loss: 159.7319\n",
            "Epoch [33/50] - Batch loss: 152.0922 - Epoch Loss: 19479.6529 - Avg Loss: 159.6693\n",
            "Epoch [33/50] - Batch loss: 157.0498 - Epoch Loss: 19636.7026 - Avg Loss: 159.6480\n",
            "Epoch [33/50] - Batch loss: 158.8002 - Epoch Loss: 19795.5029 - Avg Loss: 159.6412\n",
            "Epoch [33/50] - Batch loss: 160.1917 - Epoch Loss: 19955.6946 - Avg Loss: 159.6456\n",
            "Epoch [33/50] - Batch loss: 156.1457 - Epoch Loss: 20111.8403 - Avg Loss: 159.6178\n",
            "Epoch [33/50] - Batch loss: 159.6350 - Epoch Loss: 20271.4753 - Avg Loss: 159.6179\n",
            "Epoch [33/50] - Batch loss: 157.4404 - Epoch Loss: 20428.9157 - Avg Loss: 159.6009\n",
            "Epoch [33/50] - Batch loss: 155.4932 - Epoch Loss: 20584.4089 - Avg Loss: 159.5691\n",
            "Epoch [33/50] - Batch loss: 153.3466 - Epoch Loss: 20737.7556 - Avg Loss: 159.5212\n",
            "Epoch [33/50] - Batch loss: 152.5652 - Epoch Loss: 20890.3208 - Avg Loss: 159.4681\n",
            "Epoch [33/50] - Batch loss: 153.5372 - Epoch Loss: 21043.8580 - Avg Loss: 159.4232\n",
            "Epoch [33/50] - Batch loss: 160.4124 - Epoch Loss: 21204.2705 - Avg Loss: 159.4306\n",
            "Epoch [33/50] - Batch loss: 165.1354 - Epoch Loss: 21369.4058 - Avg Loss: 159.4732\n",
            "Epoch [33/50] - Batch loss: 155.2204 - Epoch Loss: 21524.6262 - Avg Loss: 159.4417\n",
            "Epoch [33/50] - Batch loss: 151.6684 - Epoch Loss: 21676.2946 - Avg Loss: 159.3845\n",
            "Epoch [33/50] - Batch loss: 154.2561 - Epoch Loss: 21830.5507 - Avg Loss: 159.3471\n",
            "Epoch [33/50] - Batch loss: 158.0329 - Epoch Loss: 21988.5836 - Avg Loss: 159.3376\n",
            "Epoch [33/50] - Batch loss: 168.4906 - Epoch Loss: 22157.0742 - Avg Loss: 159.4034\n",
            "Epoch [33/50] - Batch loss: 153.1210 - Epoch Loss: 22310.1952 - Avg Loss: 159.3585\n",
            "Epoch [33/50] - Batch loss: 154.3759 - Epoch Loss: 22464.5712 - Avg Loss: 159.3232\n",
            "Epoch [33/50] - Batch loss: 156.0718 - Epoch Loss: 22620.6430 - Avg Loss: 159.3003\n",
            "Epoch [33/50] - Batch loss: 159.3473 - Epoch Loss: 22779.9902 - Avg Loss: 159.3006\n",
            "Epoch [33/50] - Batch loss: 155.8135 - Epoch Loss: 22935.8038 - Avg Loss: 159.2764\n",
            "Epoch [33/50] - Batch loss: 153.9731 - Epoch Loss: 23089.7769 - Avg Loss: 159.2398\n",
            "Epoch [33/50] - Batch loss: 163.3931 - Epoch Loss: 23253.1700 - Avg Loss: 159.2683\n",
            "Epoch [33/50] - Batch loss: 154.9827 - Epoch Loss: 23408.1527 - Avg Loss: 159.2391\n",
            "Epoch [33/50] - Batch loss: 153.9055 - Epoch Loss: 23562.0582 - Avg Loss: 159.2031\n",
            "Epoch [33/50] - Batch loss: 155.4913 - Epoch Loss: 23717.5495 - Avg Loss: 159.1782\n",
            "Epoch [33/50] - Batch loss: 152.9572 - Epoch Loss: 23870.5067 - Avg Loss: 159.1367\n",
            "Epoch [33/50] - Batch loss: 164.5768 - Epoch Loss: 24035.0834 - Avg Loss: 159.1727\n",
            "Epoch [33/50] - Batch loss: 150.2271 - Epoch Loss: 24185.3105 - Avg Loss: 159.1139\n",
            "Epoch [33/50] - Batch loss: 163.4135 - Epoch Loss: 24348.7240 - Avg Loss: 159.1420\n",
            "Epoch [33/50] - Batch loss: 157.3753 - Epoch Loss: 24506.0993 - Avg Loss: 159.1305\n",
            "Epoch [33/50] - Batch loss: 163.9488 - Epoch Loss: 24670.0481 - Avg Loss: 159.1616\n",
            "Epoch [33/50] - Batch loss: 152.5598 - Epoch Loss: 24822.6079 - Avg Loss: 159.1193\n",
            "Epoch [33/50] - Batch loss: 150.1068 - Epoch Loss: 24972.7147 - Avg Loss: 159.0619\n",
            "Epoch [33/50] - Batch loss: 166.2518 - Epoch Loss: 25138.9665 - Avg Loss: 159.1074\n",
            "Epoch [33/50] - Batch loss: 157.7697 - Epoch Loss: 25296.7362 - Avg Loss: 159.0990\n",
            "Epoch [33/50] - Batch loss: 153.1771 - Epoch Loss: 25449.9133 - Avg Loss: 159.0620\n",
            "Epoch [33/50] - Batch loss: 156.9224 - Epoch Loss: 25606.8357 - Avg Loss: 159.0487\n",
            "Epoch [33/50] - Batch loss: 155.5518 - Epoch Loss: 25762.3876 - Avg Loss: 159.0271\n",
            "Epoch [33/50] - Batch loss: 164.9078 - Epoch Loss: 25927.2954 - Avg Loss: 159.0632\n",
            "Epoch [33/50] - Batch loss: 152.7201 - Epoch Loss: 26080.0155 - Avg Loss: 159.0245\n",
            "Epoch [33/50] - Batch loss: 158.6502 - Epoch Loss: 26238.6657 - Avg Loss: 159.0222\n",
            "Epoch [33/50] - Batch loss: 163.8595 - Epoch Loss: 26402.5252 - Avg Loss: 159.0514\n",
            "Epoch [33/50] - Batch loss: 158.7308 - Epoch Loss: 26561.2560 - Avg Loss: 159.0494\n",
            "Epoch [33/50] - Batch loss: 157.5579 - Epoch Loss: 26718.8139 - Avg Loss: 159.0406\n",
            "Epoch [33/50] - Batch loss: 158.5753 - Epoch Loss: 26877.3892 - Avg Loss: 159.0378\n",
            "Epoch [33/50] - Batch loss: 154.0834 - Epoch Loss: 27031.4726 - Avg Loss: 159.0087\n",
            "Epoch [33/50] - Batch loss: 160.6771 - Epoch Loss: 27192.1497 - Avg Loss: 159.0184\n",
            "Epoch [33/50] - Batch loss: 165.5673 - Epoch Loss: 27357.7171 - Avg Loss: 159.0565\n",
            "Epoch [33/50] - Batch loss: 160.1588 - Epoch Loss: 27517.8759 - Avg Loss: 159.0629\n",
            "Epoch [33/50] - Batch loss: 156.6233 - Epoch Loss: 27674.4992 - Avg Loss: 159.0488\n",
            "Epoch [33/50] - Batch loss: 158.5919 - Epoch Loss: 27833.0911 - Avg Loss: 159.0462\n",
            "Epoch [33/50] - Batch loss: 163.1794 - Epoch Loss: 27996.2705 - Avg Loss: 159.0697\n",
            "Epoch [33/50] - Batch loss: 166.5853 - Epoch Loss: 28162.8557 - Avg Loss: 159.1122\n",
            "Epoch [33/50] - Batch loss: 164.6273 - Epoch Loss: 28327.4831 - Avg Loss: 159.1432\n",
            "Epoch [33/50] - Batch loss: 157.4094 - Epoch Loss: 28484.8925 - Avg Loss: 159.1335\n",
            "Epoch [33/50] - Batch loss: 150.5127 - Epoch Loss: 28635.4052 - Avg Loss: 159.0856\n",
            "Epoch [33/50] - Batch loss: 159.9593 - Epoch Loss: 28795.3645 - Avg Loss: 159.0904\n",
            "Epoch [33/50] - Batch loss: 158.0519 - Epoch Loss: 28953.4164 - Avg Loss: 159.0847\n",
            "Epoch [33/50] - Batch loss: 153.0359 - Epoch Loss: 29106.4523 - Avg Loss: 159.0517\n",
            "Epoch [33/50] - Batch loss: 160.8870 - Epoch Loss: 29267.3393 - Avg Loss: 159.0616\n",
            "Epoch [33/50] - Batch loss: 155.5860 - Epoch Loss: 29422.9254 - Avg Loss: 159.0428\n",
            "Epoch [33/50] - Batch loss: 153.7239 - Epoch Loss: 29576.6492 - Avg Loss: 159.0142\n",
            "Epoch [33/50] - Batch loss: 164.5002 - Epoch Loss: 29741.1494 - Avg Loss: 159.0436\n",
            "Epoch [33/50] - Batch loss: 163.3215 - Epoch Loss: 29904.4710 - Avg Loss: 159.0663\n",
            "Epoch [33/50] - Batch loss: 156.3268 - Epoch Loss: 30060.7977 - Avg Loss: 159.0518\n",
            "Epoch [33/50] - Batch loss: 159.1880 - Epoch Loss: 30219.9857 - Avg Loss: 159.0526\n",
            "Epoch [33/50] - Batch loss: 152.9290 - Epoch Loss: 30372.9147 - Avg Loss: 159.0205\n",
            "Epoch [33/50] - Batch loss: 154.8178 - Epoch Loss: 30527.7325 - Avg Loss: 158.9986\n",
            "Epoch [33/50] - Batch loss: 162.3977 - Epoch Loss: 30690.1302 - Avg Loss: 159.0162\n",
            "Epoch [33/50] - Batch loss: 159.3345 - Epoch Loss: 30849.4647 - Avg Loss: 159.0179\n",
            "Epoch [33/50] - Batch loss: 161.9168 - Epoch Loss: 31011.3815 - Avg Loss: 159.0327\n",
            "Epoch [33/50] - Batch loss: 157.5467 - Epoch Loss: 31168.9283 - Avg Loss: 159.0251\n",
            "Epoch [33/50] - Batch loss: 152.3124 - Epoch Loss: 31321.2407 - Avg Loss: 158.9911\n",
            "Epoch [33/50] - Batch loss: 155.5429 - Epoch Loss: 31476.7836 - Avg Loss: 158.9737\n",
            "Epoch [33/50] - Batch loss: 160.4924 - Epoch Loss: 31637.2759 - Avg Loss: 158.9813\n",
            "Epoch [33/50] - Batch loss: 154.1869 - Epoch Loss: 31791.4628 - Avg Loss: 158.9573\n",
            "Epoch [33/50] - Batch loss: 162.7185 - Epoch Loss: 31954.1814 - Avg Loss: 158.9760\n",
            "Epoch [33/50] - Batch loss: 163.6959 - Epoch Loss: 32117.8773 - Avg Loss: 158.9994\n",
            "Epoch [33/50] - Batch loss: 157.3665 - Epoch Loss: 32275.2438 - Avg Loss: 158.9913\n",
            "Epoch [33/50] - Batch loss: 157.2544 - Epoch Loss: 32432.4982 - Avg Loss: 158.9828\n",
            "Epoch [33/50] - Batch loss: 153.6525 - Epoch Loss: 32586.1507 - Avg Loss: 158.9568\n",
            "Epoch [33/50] - Batch loss: 163.0613 - Epoch Loss: 32749.2120 - Avg Loss: 158.9768\n",
            "Epoch [33/50] - Batch loss: 157.2996 - Epoch Loss: 32906.5115 - Avg Loss: 158.9687\n",
            "Epoch [33/50] - Batch loss: 156.6244 - Epoch Loss: 33063.1359 - Avg Loss: 158.9574\n",
            "Epoch [33/50] - Batch loss: 158.9923 - Epoch Loss: 33222.1282 - Avg Loss: 158.9576\n",
            "Epoch [33/50] - Batch loss: 159.8729 - Epoch Loss: 33382.0011 - Avg Loss: 158.9619\n",
            "Epoch [33/50] - Batch loss: 160.3062 - Epoch Loss: 33542.3072 - Avg Loss: 158.9683\n",
            "Epoch [33/50] - Batch loss: 166.1331 - Epoch Loss: 33708.4404 - Avg Loss: 159.0021\n",
            "Epoch [33/50] - Batch loss: 156.5880 - Epoch Loss: 33865.0283 - Avg Loss: 158.9907\n",
            "Epoch [33/50] - Batch loss: 165.8772 - Epoch Loss: 34030.9055 - Avg Loss: 159.0229\n",
            "Epoch [33/50] - Batch loss: 157.1840 - Epoch Loss: 34188.0895 - Avg Loss: 159.0144\n",
            "Epoch [33/50] - Batch loss: 159.8964 - Epoch Loss: 34347.9859 - Avg Loss: 159.0185\n",
            "Epoch [33/50] - Batch loss: 158.9654 - Epoch Loss: 34506.9513 - Avg Loss: 159.0182\n",
            "Epoch [33/50] - Batch loss: 157.6685 - Epoch Loss: 34664.6199 - Avg Loss: 159.0120\n",
            "Epoch [33/50] - Batch loss: 158.2778 - Epoch Loss: 34822.8977 - Avg Loss: 159.0087\n",
            "Epoch [33/50] - Batch loss: 153.8721 - Epoch Loss: 34976.7698 - Avg Loss: 158.9853\n",
            "Epoch [33/50] - Batch loss: 164.2891 - Epoch Loss: 35141.0589 - Avg Loss: 159.0093\n",
            "Epoch [33/50] - Batch loss: 155.0466 - Epoch Loss: 35296.1055 - Avg Loss: 158.9915\n",
            "Epoch [33/50] - Batch loss: 159.2105 - Epoch Loss: 35455.3160 - Avg Loss: 158.9924\n",
            "Epoch [33/50] - Batch loss: 158.5715 - Epoch Loss: 35613.8874 - Avg Loss: 158.9906\n",
            "Epoch [33/50] - Batch loss: 156.2719 - Epoch Loss: 35770.1594 - Avg Loss: 158.9785\n",
            "Epoch [33/50] - Batch loss: 168.7177 - Epoch Loss: 35938.8770 - Avg Loss: 159.0216\n",
            "Epoch [33/50] - Batch loss: 156.1281 - Epoch Loss: 36095.0051 - Avg Loss: 159.0088\n",
            "Epoch [33/50] - Batch loss: 155.8589 - Epoch Loss: 36250.8640 - Avg Loss: 158.9950\n",
            "Epoch [33/50] - Batch loss: 155.5452 - Epoch Loss: 36406.4092 - Avg Loss: 158.9800\n",
            "Epoch [33/50] - Batch loss: 155.5558 - Epoch Loss: 36561.9650 - Avg Loss: 158.9651\n",
            "Epoch [33/50] - Batch loss: 162.6549 - Epoch Loss: 36724.6199 - Avg Loss: 158.9810\n",
            "Epoch [33/50] - Batch loss: 157.3549 - Epoch Loss: 36881.9747 - Avg Loss: 158.9740\n",
            "Epoch [33/50] - Batch loss: 161.7710 - Epoch Loss: 37043.7458 - Avg Loss: 158.9860\n",
            "Epoch [33/50] - Batch loss: 166.1952 - Epoch Loss: 37209.9409 - Avg Loss: 159.0168\n",
            "Epoch [33/50] - Batch loss: 155.9540 - Epoch Loss: 37365.8949 - Avg Loss: 159.0038\n",
            "Epoch [33/50] - Batch loss: 157.7138 - Epoch Loss: 37523.6087 - Avg Loss: 158.9983\n",
            "Epoch [33/50] - Batch loss: 149.7962 - Epoch Loss: 37673.4049 - Avg Loss: 158.9595\n",
            "Epoch [33/50] - Batch loss: 161.8228 - Epoch Loss: 37835.2278 - Avg Loss: 158.9715\n",
            "Epoch [33/50] - Batch loss: 152.8568 - Epoch Loss: 37988.0846 - Avg Loss: 158.9460\n",
            "Epoch [33/50] - Batch loss: 159.6378 - Epoch Loss: 38147.7224 - Avg Loss: 158.9488\n",
            "Epoch [33/50] - Batch loss: 158.9112 - Epoch Loss: 38306.6336 - Avg Loss: 158.9487\n",
            "Epoch [33/50] - Batch loss: 155.2859 - Epoch Loss: 38461.9195 - Avg Loss: 158.9336\n",
            "Epoch [33/50] - Batch loss: 160.0092 - Epoch Loss: 38621.9287 - Avg Loss: 158.9380\n",
            "Epoch [33/50] - Batch loss: 154.7198 - Epoch Loss: 38776.6485 - Avg Loss: 158.9207\n",
            "Epoch [33/50] - Batch loss: 159.9493 - Epoch Loss: 38936.5978 - Avg Loss: 158.9249\n",
            "Epoch [33/50] - Batch loss: 157.8646 - Epoch Loss: 39094.4624 - Avg Loss: 158.9206\n",
            "Epoch [33/50] - Batch loss: 162.5518 - Epoch Loss: 39257.0142 - Avg Loss: 158.9353\n",
            "Epoch [33/50] - Batch loss: 163.1552 - Epoch Loss: 39420.1694 - Avg Loss: 158.9523\n",
            "Epoch [33/50] - Batch loss: 157.1774 - Epoch Loss: 39577.3468 - Avg Loss: 158.9452\n",
            "Epoch [33/50] - Batch loss: 159.8284 - Epoch Loss: 39737.1752 - Avg Loss: 158.9487\n",
            "Epoch [33/50] - Batch loss: 154.6314 - Epoch Loss: 39891.8066 - Avg Loss: 158.9315\n",
            "Epoch [33/50] - Batch loss: 153.2955 - Epoch Loss: 40045.1021 - Avg Loss: 158.9091\n",
            "Epoch [33/50] - Batch loss: 156.0825 - Epoch Loss: 40201.1846 - Avg Loss: 158.8980\n",
            "Epoch [33/50] - Batch loss: 161.6229 - Epoch Loss: 40362.8075 - Avg Loss: 158.9087\n",
            "Epoch [33/50] - Batch loss: 156.6796 - Epoch Loss: 40519.4870 - Avg Loss: 158.8999\n",
            "Epoch [33/50] - Batch loss: 167.6218 - Epoch Loss: 40687.1088 - Avg Loss: 158.9340\n",
            "Epoch [33/50] - Batch loss: 150.9546 - Epoch Loss: 40838.0634 - Avg Loss: 158.9030\n",
            "Epoch [33/50] - Batch loss: 165.8011 - Epoch Loss: 41003.8645 - Avg Loss: 158.9297\n",
            "Epoch [33/50] - Batch loss: 163.5777 - Epoch Loss: 41167.4422 - Avg Loss: 158.9477\n",
            "Epoch [33/50] - Batch loss: 158.2602 - Epoch Loss: 41325.7023 - Avg Loss: 158.9450\n",
            "Epoch [33/50] - Batch loss: 152.7705 - Epoch Loss: 41478.4728 - Avg Loss: 158.9214\n",
            "Epoch [33/50] - Batch loss: 159.6254 - Epoch Loss: 41638.0981 - Avg Loss: 158.9240\n",
            "Epoch [33/50] - Batch loss: 159.3970 - Epoch Loss: 41797.4952 - Avg Loss: 158.9258\n",
            "Epoch [33/50] - Batch loss: 167.8972 - Epoch Loss: 41965.3923 - Avg Loss: 158.9598\n",
            "Epoch [33/50] - Batch loss: 156.5111 - Epoch Loss: 42121.9035 - Avg Loss: 158.9506\n",
            "Epoch [33/50] - Batch loss: 155.3129 - Epoch Loss: 42277.2164 - Avg Loss: 158.9369\n",
            "Epoch [33/50] - Batch loss: 158.8138 - Epoch Loss: 42436.0302 - Avg Loss: 158.9364\n",
            "Epoch [33/50] - Batch loss: 154.8624 - Epoch Loss: 42590.8926 - Avg Loss: 158.9212\n",
            "Epoch [33/50] - Batch loss: 152.5744 - Epoch Loss: 42743.4671 - Avg Loss: 158.8976\n",
            "Epoch [33/50] - Batch loss: 161.4620 - Epoch Loss: 42904.9291 - Avg Loss: 158.9071\n",
            "Epoch [33/50] - Batch loss: 167.3064 - Epoch Loss: 43072.2355 - Avg Loss: 158.9381\n",
            "Epoch [33/50] - Batch loss: 162.8318 - Epoch Loss: 43235.0673 - Avg Loss: 158.9525\n",
            "Epoch [33/50] - Batch loss: 168.6924 - Epoch Loss: 43403.7597 - Avg Loss: 158.9881\n",
            "Epoch [33/50] - Batch loss: 162.9724 - Epoch Loss: 43566.7320 - Avg Loss: 159.0027\n",
            "Epoch [33/50] - Batch loss: 162.4543 - Epoch Loss: 43729.1864 - Avg Loss: 159.0152\n",
            "Epoch [33/50] - Batch loss: 159.0690 - Epoch Loss: 43888.2553 - Avg Loss: 159.0154\n",
            "Epoch [33/50] - Batch loss: 162.7391 - Epoch Loss: 44050.9944 - Avg Loss: 159.0289\n",
            "Epoch [33/50] - Batch loss: 166.0180 - Epoch Loss: 44217.0124 - Avg Loss: 159.0540\n",
            "Epoch [33/50] - Batch loss: 160.7741 - Epoch Loss: 44377.7865 - Avg Loss: 159.0602\n",
            "Epoch [33/50] - Batch loss: 163.2597 - Epoch Loss: 44541.0462 - Avg Loss: 159.0752\n",
            "Epoch [33/50] - Batch loss: 166.3667 - Epoch Loss: 44707.4129 - Avg Loss: 159.1011\n",
            "Epoch [33/50] - Batch loss: 162.3165 - Epoch Loss: 44869.7294 - Avg Loss: 159.1125\n",
            "Epoch [33/50] - Batch loss: 167.3349 - Epoch Loss: 45037.0643 - Avg Loss: 159.1416\n",
            "Epoch [33/50] - Batch loss: 158.1426 - Epoch Loss: 45195.2069 - Avg Loss: 159.1381\n",
            "Epoch [33/50] - Batch loss: 165.3218 - Epoch Loss: 45360.5287 - Avg Loss: 159.1597\n",
            "Epoch [33/50] - Batch loss: 156.0570 - Epoch Loss: 45516.5857 - Avg Loss: 159.1489\n",
            "Epoch [33/50] - Batch loss: 165.3861 - Epoch Loss: 45681.9718 - Avg Loss: 159.1706\n",
            "Epoch [33/50] - Batch loss: 166.6157 - Epoch Loss: 45848.5876 - Avg Loss: 159.1965\n",
            "Epoch [33/50] - Batch loss: 166.8480 - Epoch Loss: 46015.4356 - Avg Loss: 159.2230\n",
            "Epoch [33/50] - Batch loss: 166.4486 - Epoch Loss: 46181.8841 - Avg Loss: 159.2479\n",
            "Epoch [33/50] - Batch loss: 159.5868 - Epoch Loss: 46341.4709 - Avg Loss: 159.2490\n",
            "Epoch [33/50] - Batch loss: 161.8790 - Epoch Loss: 46503.3500 - Avg Loss: 159.2580\n",
            "Epoch [33/50] - Batch loss: 158.7965 - Epoch Loss: 46662.1465 - Avg Loss: 159.2565\n",
            "Epoch [33/50] - Batch loss: 159.6194 - Epoch Loss: 46821.7659 - Avg Loss: 159.2577\n",
            "Epoch [33/50] - Batch loss: 167.8080 - Epoch Loss: 46989.5739 - Avg Loss: 159.2867\n",
            "Epoch [33/50] - Batch loss: 162.2468 - Epoch Loss: 47151.8207 - Avg Loss: 159.2967\n",
            "Epoch [33/50] - Batch loss: 167.1509 - Epoch Loss: 47318.9717 - Avg Loss: 159.3231\n",
            "Epoch [33/50] - Batch loss: 159.1498 - Epoch Loss: 47478.1215 - Avg Loss: 159.3226\n",
            "Epoch [33/50] - Batch loss: 162.6088 - Epoch Loss: 47640.7303 - Avg Loss: 159.3335\n",
            "Epoch [33/50] - Batch loss: 158.5631 - Epoch Loss: 47799.2934 - Avg Loss: 159.3310\n",
            "Epoch [33/50] - Batch loss: 164.3879 - Epoch Loss: 47963.6813 - Avg Loss: 159.3478\n",
            "Epoch [33/50] - Batch loss: 167.0385 - Epoch Loss: 48130.7198 - Avg Loss: 159.3732\n",
            "Epoch [33/50] - Batch loss: 161.4328 - Epoch Loss: 48292.1525 - Avg Loss: 159.3800\n",
            "Epoch [33/50] - Batch loss: 156.8682 - Epoch Loss: 48449.0207 - Avg Loss: 159.3718\n",
            "Epoch [33/50] - Batch loss: 168.0317 - Epoch Loss: 48617.0524 - Avg Loss: 159.4002\n",
            "Epoch [33/50] - Batch loss: 162.2823 - Epoch Loss: 48779.3348 - Avg Loss: 159.4096\n",
            "Epoch [33/50] - Batch loss: 157.3259 - Epoch Loss: 48936.6607 - Avg Loss: 159.4028\n",
            "Epoch [33/50] - Batch loss: 162.6639 - Epoch Loss: 49099.3246 - Avg Loss: 159.4134\n",
            "Epoch [33/50] - Batch loss: 154.6013 - Epoch Loss: 49253.9259 - Avg Loss: 159.3978\n",
            "Epoch [33/50] - Batch loss: 168.5197 - Epoch Loss: 49422.4456 - Avg Loss: 159.4272\n",
            "Epoch [33/50] - Batch loss: 170.8967 - Epoch Loss: 49593.3423 - Avg Loss: 159.4641\n",
            "Epoch [33/50] - Batch loss: 161.7002 - Epoch Loss: 49755.0426 - Avg Loss: 159.4713\n",
            "Epoch [33/50] - Batch loss: 158.3947 - Epoch Loss: 49913.4373 - Avg Loss: 159.4679\n",
            "Epoch [33/50] - Batch loss: 160.8187 - Epoch Loss: 50074.2560 - Avg Loss: 159.4722\n",
            "Epoch [33/50] - Batch loss: 170.2436 - Epoch Loss: 50244.4996 - Avg Loss: 159.5063\n",
            "Epoch [33/50] - Batch loss: 164.4126 - Epoch Loss: 50408.9122 - Avg Loss: 159.5219\n",
            "Epoch [33/50] - Batch loss: 160.1918 - Epoch Loss: 50569.1040 - Avg Loss: 159.5240\n",
            "Epoch [33/50] - Batch loss: 156.0828 - Epoch Loss: 50725.1868 - Avg Loss: 159.5132\n",
            "Epoch [33/50] - Batch loss: 164.3361 - Epoch Loss: 50889.5229 - Avg Loss: 159.5283\n",
            "Epoch [33/50] - Batch loss: 163.3647 - Epoch Loss: 51052.8876 - Avg Loss: 159.5403\n",
            "Epoch [33/50] - Batch loss: 168.6157 - Epoch Loss: 51221.5032 - Avg Loss: 159.5685\n",
            "Epoch [33/50] - Batch loss: 167.3444 - Epoch Loss: 51388.8477 - Avg Loss: 159.5927\n",
            "Epoch [33/50] - Batch loss: 172.1038 - Epoch Loss: 51560.9515 - Avg Loss: 159.6314\n",
            "Epoch [33/50] - Batch loss: 162.3040 - Epoch Loss: 51723.2554 - Avg Loss: 159.6397\n",
            "Epoch [33/50] - Batch loss: 169.1068 - Epoch Loss: 51892.3622 - Avg Loss: 159.6688\n",
            "Epoch [33/50] - Batch loss: 162.8093 - Epoch Loss: 52055.1715 - Avg Loss: 159.6784\n",
            "Epoch [33/50] - Batch loss: 165.6575 - Epoch Loss: 52220.8291 - Avg Loss: 159.6967\n",
            "Epoch [33/50] - Batch loss: 162.1969 - Epoch Loss: 52383.0260 - Avg Loss: 159.7043\n",
            "Epoch [33/50] - Batch loss: 171.6977 - Epoch Loss: 52554.7237 - Avg Loss: 159.7408\n",
            "Epoch [33/50] - Batch loss: 173.2760 - Epoch Loss: 52727.9997 - Avg Loss: 159.7818\n",
            "Epoch [33/50] - Batch loss: 161.9397 - Epoch Loss: 52889.9394 - Avg Loss: 159.7883\n",
            "Epoch [33/50] - Batch loss: 158.7447 - Epoch Loss: 53048.6841 - Avg Loss: 159.7852\n",
            "Epoch [33/50] - Batch loss: 163.1425 - Epoch Loss: 53211.8266 - Avg Loss: 159.7953\n",
            "Epoch [33/50] - Batch loss: 162.4574 - Epoch Loss: 53374.2839 - Avg Loss: 159.8032\n",
            "Epoch [33/50] - Batch loss: 155.3624 - Epoch Loss: 53529.6464 - Avg Loss: 159.7900\n",
            "Epoch [33/50] - Batch loss: 164.9173 - Epoch Loss: 53694.5636 - Avg Loss: 159.8052\n",
            "Epoch [33/50] - Batch loss: 160.3010 - Epoch Loss: 53854.8646 - Avg Loss: 159.8067\n",
            "Epoch [33/50] - Batch loss: 163.1994 - Epoch Loss: 54018.0641 - Avg Loss: 159.8168\n",
            "Epoch [33/50] - Batch loss: 153.8913 - Epoch Loss: 54171.9554 - Avg Loss: 159.7993\n",
            "Epoch [33/50] - Batch loss: 159.9020 - Epoch Loss: 54331.8573 - Avg Loss: 159.7996\n",
            "Epoch [33/50] - Batch loss: 172.1251 - Epoch Loss: 54503.9824 - Avg Loss: 159.8357\n",
            "Epoch [33/50] - Batch loss: 162.3238 - Epoch Loss: 54666.3062 - Avg Loss: 159.8430\n",
            "Epoch [33/50] - Batch loss: 161.3730 - Epoch Loss: 54827.6792 - Avg Loss: 159.8475\n",
            "Epoch [33/50] - Batch loss: 154.8145 - Epoch Loss: 54982.4937 - Avg Loss: 159.8328\n",
            "Epoch [33/50] - Batch loss: 162.8719 - Epoch Loss: 55145.3656 - Avg Loss: 159.8416\n",
            "Epoch [33/50] - Batch loss: 166.6845 - Epoch Loss: 55312.0501 - Avg Loss: 159.8614\n",
            "Epoch [33/50] - Batch loss: 163.0474 - Epoch Loss: 55475.0975 - Avg Loss: 159.8706\n",
            "Epoch [33/50] - Batch loss: 163.4108 - Epoch Loss: 55638.5083 - Avg Loss: 159.8808\n",
            "Epoch [33/50] - Batch loss: 156.6371 - Epoch Loss: 55795.1454 - Avg Loss: 159.8715\n",
            "Epoch [33/50] - Batch loss: 156.5586 - Epoch Loss: 55951.7040 - Avg Loss: 159.8620\n",
            "Epoch [33/50] - Batch loss: 156.3163 - Epoch Loss: 56108.0203 - Avg Loss: 159.8519\n",
            "Epoch [33/50] - Batch loss: 154.5289 - Epoch Loss: 56262.5493 - Avg Loss: 159.8368\n",
            "Epoch [33/50] - Batch loss: 163.5195 - Epoch Loss: 56426.0688 - Avg Loss: 159.8472\n",
            "Epoch [33/50] - Batch loss: 159.2577 - Epoch Loss: 56585.3265 - Avg Loss: 159.8456\n",
            "Epoch [33/50] - Batch loss: 165.5964 - Epoch Loss: 56750.9229 - Avg Loss: 159.8618\n",
            "Epoch [33/50] - Batch loss: 162.5972 - Epoch Loss: 56913.5200 - Avg Loss: 159.8694\n",
            "Epoch [33/50] - Batch loss: 167.6962 - Epoch Loss: 57081.2162 - Avg Loss: 159.8914\n",
            "Epoch [33/50] - Batch loss: 164.4232 - Epoch Loss: 57245.6394 - Avg Loss: 159.9040\n",
            "Epoch [33/50] - Batch loss: 158.9238 - Epoch Loss: 57404.5632 - Avg Loss: 159.9013\n",
            "Epoch [33/50] - Batch loss: 171.2196 - Epoch Loss: 57575.7828 - Avg Loss: 159.9327\n",
            "Epoch [33/50] - Batch loss: 158.4025 - Epoch Loss: 57734.1853 - Avg Loss: 159.9285\n",
            "Epoch [33/50] - Batch loss: 166.6428 - Epoch Loss: 57900.8281 - Avg Loss: 159.9470\n",
            "Epoch [33/50] - Batch loss: 155.4172 - Epoch Loss: 58056.2453 - Avg Loss: 159.9346\n",
            "Epoch [33/50] - Batch loss: 157.1840 - Epoch Loss: 58213.4293 - Avg Loss: 159.9270\n",
            "Epoch [33/50] - Batch loss: 163.6609 - Epoch Loss: 58377.0901 - Avg Loss: 159.9372\n",
            "Epoch [33/50] - Batch loss: 167.9575 - Epoch Loss: 58545.0477 - Avg Loss: 159.9591\n",
            "Epoch [33/50] - Batch loss: 159.3320 - Epoch Loss: 58704.3797 - Avg Loss: 159.9574\n",
            "Epoch [33/50] - Batch loss: 167.6512 - Epoch Loss: 58872.0309 - Avg Loss: 159.9783\n",
            "Epoch [33/50] - Batch loss: 160.7865 - Epoch Loss: 59032.8174 - Avg Loss: 159.9805\n",
            "Epoch [33/50] - Batch loss: 162.1076 - Epoch Loss: 59194.9250 - Avg Loss: 159.9863\n",
            "Epoch [33/50] - Batch loss: 161.7307 - Epoch Loss: 59356.6558 - Avg Loss: 159.9910\n",
            "Epoch [33/50] - Batch loss: 162.6416 - Epoch Loss: 59519.2974 - Avg Loss: 159.9981\n",
            "Epoch [33/50] - Batch loss: 160.9075 - Epoch Loss: 59680.2049 - Avg Loss: 160.0005\n",
            "Epoch [33/50] - Batch loss: 159.6832 - Epoch Loss: 59839.8881 - Avg Loss: 159.9997\n",
            "Epoch [33/50] - Batch loss: 166.0252 - Epoch Loss: 60005.9133 - Avg Loss: 160.0158\n",
            "Epoch [33/50] - Batch loss: 157.1398 - Epoch Loss: 60163.0531 - Avg Loss: 160.0081\n",
            "Epoch [33/50] - Batch loss: 167.0799 - Epoch Loss: 60330.1330 - Avg Loss: 160.0269\n",
            "Epoch [33/50] - Batch loss: 162.0592 - Epoch Loss: 60492.1923 - Avg Loss: 160.0323\n",
            "Epoch [33/50] - Batch loss: 162.0048 - Epoch Loss: 60654.1971 - Avg Loss: 160.0375\n",
            "Epoch [33/50] - Batch loss: 165.1249 - Epoch Loss: 60819.3220 - Avg Loss: 160.0508\n",
            "Epoch [33/50] - Batch loss: 157.7000 - Epoch Loss: 60977.0220 - Avg Loss: 160.0447\n",
            "Epoch [33/50] - Batch loss: 172.0751 - Epoch Loss: 61149.0971 - Avg Loss: 160.0762\n",
            "Epoch [33/50] - Batch loss: 163.1881 - Epoch Loss: 61312.2852 - Avg Loss: 160.0843\n",
            "Epoch [33/50] - Batch loss: 168.1474 - Epoch Loss: 61480.4326 - Avg Loss: 160.1053\n",
            "Epoch [33/50] - Batch loss: 159.1429 - Epoch Loss: 61639.5755 - Avg Loss: 160.1028\n",
            "Epoch [33/50] - Batch loss: 155.8646 - Epoch Loss: 61795.4401 - Avg Loss: 160.0918\n",
            "Epoch [33/50] - Batch loss: 157.0747 - Epoch Loss: 61952.5148 - Avg Loss: 160.0840\n",
            "Epoch [33/50] - Batch loss: 161.5933 - Epoch Loss: 62114.1081 - Avg Loss: 160.0879\n",
            "Epoch [33/50] - Batch loss: 160.8027 - Epoch Loss: 62274.9108 - Avg Loss: 160.0897\n",
            "Epoch [33/50] - Batch loss: 162.5107 - Epoch Loss: 62437.4215 - Avg Loss: 160.0960\n",
            "Epoch [33/50] - Batch loss: 155.4154 - Epoch Loss: 62592.8369 - Avg Loss: 160.0840\n",
            "Epoch [33/50] - Batch loss: 148.6655 - Epoch Loss: 62741.5024 - Avg Loss: 160.0549\n",
            "Epoch [33/50] - Batch loss: 154.6664 - Epoch Loss: 62896.1688 - Avg Loss: 160.0411\n",
            "Epoch [33/50] - Batch loss: 155.5036 - Epoch Loss: 63051.6724 - Avg Loss: 160.0296\n",
            "Epoch [33/50] - Batch loss: 152.5191 - Epoch Loss: 63204.1915 - Avg Loss: 160.0106\n",
            "Epoch [33/50] - Batch loss: 162.8233 - Epoch Loss: 63367.0148 - Avg Loss: 160.0177\n",
            "Epoch [33/50] - Batch loss: 157.0158 - Epoch Loss: 63524.0306 - Avg Loss: 160.0102\n",
            "Epoch [33/50] - Batch loss: 154.7933 - Epoch Loss: 63678.8239 - Avg Loss: 159.9970\n",
            "Epoch [33/50] - Batch loss: 156.7941 - Epoch Loss: 63835.6179 - Avg Loss: 159.9890\n",
            "Epoch [33/50] - Batch loss: 156.1944 - Epoch Loss: 63991.8123 - Avg Loss: 159.9795\n",
            "Epoch [33/50] - Batch loss: 167.2104 - Epoch Loss: 64159.0227 - Avg Loss: 159.9976\n",
            "Epoch [33/50] - Batch loss: 158.7761 - Epoch Loss: 64317.7988 - Avg Loss: 159.9945\n",
            "Epoch [33/50] - Batch loss: 165.1024 - Epoch Loss: 64482.9012 - Avg Loss: 160.0072\n",
            "Epoch [33/50] - Batch loss: 157.0514 - Epoch Loss: 64639.9526 - Avg Loss: 159.9999\n",
            "Epoch [33/50] - Batch loss: 158.4970 - Epoch Loss: 64798.4496 - Avg Loss: 159.9962\n",
            "Epoch [33/50] - Batch loss: 160.9354 - Epoch Loss: 64959.3850 - Avg Loss: 159.9985\n",
            "Epoch [33/50] - Batch loss: 154.8745 - Epoch Loss: 65114.2594 - Avg Loss: 159.9859\n",
            "Epoch [33/50] - Batch loss: 158.0227 - Epoch Loss: 65272.2821 - Avg Loss: 159.9811\n",
            "Epoch [33/50] - Batch loss: 162.9518 - Epoch Loss: 65435.2339 - Avg Loss: 159.9883\n",
            "Epoch [33/50] - Batch loss: 151.9294 - Epoch Loss: 65587.1633 - Avg Loss: 159.9687\n",
            "Epoch [33/50] - Batch loss: 168.0039 - Epoch Loss: 65755.1672 - Avg Loss: 159.9882\n",
            "Epoch [33/50] - Batch loss: 162.2737 - Epoch Loss: 65917.4409 - Avg Loss: 159.9938\n",
            "Epoch [33/50] - Batch loss: 162.8360 - Epoch Loss: 66080.2769 - Avg Loss: 160.0007\n",
            "Epoch [33/50] - Batch loss: 155.9999 - Epoch Loss: 66236.2769 - Avg Loss: 159.9910\n",
            "Epoch [33/50] - Batch loss: 155.4305 - Epoch Loss: 66391.7074 - Avg Loss: 159.9800\n",
            "Epoch [33/50] - Batch loss: 158.2533 - Epoch Loss: 66549.9607 - Avg Loss: 159.9759\n",
            "Epoch [33/50] - Batch loss: 158.1284 - Epoch Loss: 66708.0891 - Avg Loss: 159.9714\n",
            "Epoch [33/50] - Batch loss: 164.4225 - Epoch Loss: 66872.5117 - Avg Loss: 159.9821\n",
            "Epoch [33/50] - Batch loss: 159.1423 - Epoch Loss: 67031.6540 - Avg Loss: 159.9801\n",
            "Epoch [33/50] - Batch loss: 164.3113 - Epoch Loss: 67195.9653 - Avg Loss: 159.9904\n",
            "Epoch [33/50] - Batch loss: 153.7681 - Epoch Loss: 67349.7333 - Avg Loss: 159.9756\n",
            "Epoch [33/50] - Batch loss: 158.9259 - Epoch Loss: 67508.6592 - Avg Loss: 159.9731\n",
            "Epoch [33/50] - Batch loss: 161.2027 - Epoch Loss: 67669.8620 - Avg Loss: 159.9760\n",
            "Epoch [33/50] - Batch loss: 153.7217 - Epoch Loss: 67823.5837 - Avg Loss: 159.9613\n",
            "Epoch [33/50] - Batch loss: 159.9894 - Epoch Loss: 67983.5731 - Avg Loss: 159.9613\n",
            "Epoch [33/50] - Batch loss: 164.8911 - Epoch Loss: 68148.4642 - Avg Loss: 159.9729\n",
            "Epoch [33/50] - Batch loss: 159.4912 - Epoch Loss: 68307.9555 - Avg Loss: 159.9718\n",
            "Epoch [33/50] - Batch loss: 151.5693 - Epoch Loss: 68459.5248 - Avg Loss: 159.9522\n",
            "Epoch [33/50] - Batch loss: 153.7148 - Epoch Loss: 68613.2396 - Avg Loss: 159.9376\n",
            "Epoch [33/50] - Batch loss: 153.3685 - Epoch Loss: 68766.6081 - Avg Loss: 159.9223\n",
            "Epoch [33/50] - Batch loss: 162.7912 - Epoch Loss: 68929.3993 - Avg Loss: 159.9290\n",
            "Epoch [33/50] - Batch loss: 155.5005 - Epoch Loss: 69084.8998 - Avg Loss: 159.9187\n",
            "Epoch [33/50] - Batch loss: 170.1767 - Epoch Loss: 69255.0765 - Avg Loss: 159.9424\n",
            "Epoch [33/50] - Batch loss: 158.2724 - Epoch Loss: 69413.3489 - Avg Loss: 159.9386\n",
            "Epoch [33/50] - Batch loss: 157.3508 - Epoch Loss: 69570.6997 - Avg Loss: 159.9326\n",
            "Epoch [33/50] - Batch loss: 163.4026 - Epoch Loss: 69734.1023 - Avg Loss: 159.9406\n",
            "Epoch [33/50] - Batch loss: 164.2310 - Epoch Loss: 69898.3334 - Avg Loss: 159.9504\n",
            "Epoch [33/50] - Batch loss: 163.1904 - Epoch Loss: 70061.5237 - Avg Loss: 159.9578\n",
            "Epoch [33/50] - Batch loss: 162.9473 - Epoch Loss: 70224.4710 - Avg Loss: 159.9646\n",
            "Epoch [33/50] - Batch loss: 162.1679 - Epoch Loss: 70386.6389 - Avg Loss: 159.9696\n",
            "Epoch [33/50] - Batch loss: 158.4750 - Epoch Loss: 70545.1139 - Avg Loss: 159.9662\n",
            "Epoch [33/50] - Batch loss: 172.0313 - Epoch Loss: 70717.1451 - Avg Loss: 159.9935\n",
            "Epoch [33/50] - Batch loss: 160.6239 - Epoch Loss: 70877.7690 - Avg Loss: 159.9950\n",
            "Epoch [33/50] - Batch loss: 162.3731 - Epoch Loss: 71040.1421 - Avg Loss: 160.0003\n",
            "Epoch [33/50] - Batch loss: 157.8044 - Epoch Loss: 71197.9465 - Avg Loss: 159.9954\n",
            "Epoch [33/50] - Batch loss: 161.3179 - Epoch Loss: 71359.2644 - Avg Loss: 159.9984\n",
            "Epoch [33/50] - Batch loss: 164.4930 - Epoch Loss: 71523.7574 - Avg Loss: 160.0084\n",
            "Epoch [33/50] - Batch loss: 163.3702 - Epoch Loss: 71687.1276 - Avg Loss: 160.0159\n",
            "Epoch [33/50] - Batch loss: 160.2994 - Epoch Loss: 71847.4269 - Avg Loss: 160.0165\n",
            "Epoch [33/50] - Batch loss: 157.2059 - Epoch Loss: 72004.6328 - Avg Loss: 160.0103\n",
            "Epoch [33/50] - Batch loss: 160.9624 - Epoch Loss: 72165.5952 - Avg Loss: 160.0124\n",
            "Epoch [33/50] - Batch loss: 166.3048 - Epoch Loss: 72331.9000 - Avg Loss: 160.0263\n",
            "Epoch [33/50] - Batch loss: 155.3049 - Epoch Loss: 72487.2050 - Avg Loss: 160.0159\n",
            "Epoch [33/50] - Batch loss: 163.7097 - Epoch Loss: 72650.9147 - Avg Loss: 160.0240\n",
            "Epoch [33/50] - Batch loss: 163.2054 - Epoch Loss: 72814.1201 - Avg Loss: 160.0310\n",
            "Epoch [33/50] - Batch loss: 157.7348 - Epoch Loss: 72971.8549 - Avg Loss: 160.0260\n",
            "Epoch [33/50] - Batch loss: 158.4617 - Epoch Loss: 73130.3166 - Avg Loss: 160.0226\n",
            "Epoch [33/50] - Batch loss: 160.7875 - Epoch Loss: 73291.1041 - Avg Loss: 160.0242\n",
            "Epoch [33/50] - Batch loss: 159.9546 - Epoch Loss: 73451.0587 - Avg Loss: 160.0241\n",
            "Epoch [33/50] - Batch loss: 154.3003 - Epoch Loss: 73605.3590 - Avg Loss: 160.0117\n",
            "Epoch [33/50] - Batch loss: 156.8621 - Epoch Loss: 73762.2211 - Avg Loss: 160.0048\n",
            "Epoch [33/50] - Batch loss: 167.1281 - Epoch Loss: 73929.3492 - Avg Loss: 160.0202\n",
            "Epoch [33/50] - Batch loss: 155.5243 - Epoch Loss: 74084.8735 - Avg Loss: 160.0105\n",
            "Epoch [33/50] - Batch loss: 161.2962 - Epoch Loss: 74246.1697 - Avg Loss: 160.0133\n",
            "Epoch [33/50] - Batch loss: 156.4041 - Epoch Loss: 74402.5738 - Avg Loss: 160.0055\n",
            "Epoch [33/50] - Batch loss: 164.8200 - Epoch Loss: 74567.3938 - Avg Loss: 160.0159\n",
            "Epoch [33/50] - Batch loss: 154.0156 - Epoch Loss: 74721.4094 - Avg Loss: 160.0030\n",
            "Epoch [33/50] - Batch loss: 166.2735 - Epoch Loss: 74887.6829 - Avg Loss: 160.0164\n",
            "Epoch [33/50] - Batch loss: 161.9538 - Epoch Loss: 75049.6367 - Avg Loss: 160.0205\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 34/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2bd13063f724e098061d6a52299a54d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [34/50] - Batch loss: 161.0829 - Epoch Loss: 161.0829 - Avg Loss: 161.0829\n",
            "Epoch [34/50] - Batch loss: 155.4896 - Epoch Loss: 316.5725 - Avg Loss: 158.2863\n",
            "Epoch [34/50] - Batch loss: 155.5869 - Epoch Loss: 472.1594 - Avg Loss: 157.3865\n",
            "Epoch [34/50] - Batch loss: 161.9171 - Epoch Loss: 634.0764 - Avg Loss: 158.5191\n",
            "Epoch [34/50] - Batch loss: 159.9194 - Epoch Loss: 793.9959 - Avg Loss: 158.7992\n",
            "Epoch [34/50] - Batch loss: 156.4875 - Epoch Loss: 950.4833 - Avg Loss: 158.4139\n",
            "Epoch [34/50] - Batch loss: 163.7715 - Epoch Loss: 1114.2549 - Avg Loss: 159.1793\n",
            "Epoch [34/50] - Batch loss: 160.7921 - Epoch Loss: 1275.0469 - Avg Loss: 159.3809\n",
            "Epoch [34/50] - Batch loss: 167.9854 - Epoch Loss: 1443.0323 - Avg Loss: 160.3369\n",
            "Epoch [34/50] - Batch loss: 167.6510 - Epoch Loss: 1610.6833 - Avg Loss: 161.0683\n",
            "Epoch [34/50] - Batch loss: 156.8409 - Epoch Loss: 1767.5242 - Avg Loss: 160.6840\n",
            "Epoch [34/50] - Batch loss: 165.2550 - Epoch Loss: 1932.7792 - Avg Loss: 161.0649\n",
            "Epoch [34/50] - Batch loss: 162.5919 - Epoch Loss: 2095.3711 - Avg Loss: 161.1824\n",
            "Epoch [34/50] - Batch loss: 164.2514 - Epoch Loss: 2259.6225 - Avg Loss: 161.4016\n",
            "Epoch [34/50] - Batch loss: 164.1753 - Epoch Loss: 2423.7978 - Avg Loss: 161.5865\n",
            "Epoch [34/50] - Batch loss: 169.1402 - Epoch Loss: 2592.9380 - Avg Loss: 162.0586\n",
            "Epoch [34/50] - Batch loss: 152.5842 - Epoch Loss: 2745.5222 - Avg Loss: 161.5013\n",
            "Epoch [34/50] - Batch loss: 167.1550 - Epoch Loss: 2912.6772 - Avg Loss: 161.8154\n",
            "Epoch [34/50] - Batch loss: 162.4137 - Epoch Loss: 3075.0909 - Avg Loss: 161.8469\n",
            "Epoch [34/50] - Batch loss: 160.2858 - Epoch Loss: 3235.3767 - Avg Loss: 161.7688\n",
            "Epoch [34/50] - Batch loss: 160.7961 - Epoch Loss: 3396.1728 - Avg Loss: 161.7225\n",
            "Epoch [34/50] - Batch loss: 156.4868 - Epoch Loss: 3552.6596 - Avg Loss: 161.4845\n",
            "Epoch [34/50] - Batch loss: 158.8068 - Epoch Loss: 3711.4664 - Avg Loss: 161.3681\n",
            "Epoch [34/50] - Batch loss: 169.9177 - Epoch Loss: 3881.3842 - Avg Loss: 161.7243\n",
            "Epoch [34/50] - Batch loss: 166.8474 - Epoch Loss: 4048.2315 - Avg Loss: 161.9293\n",
            "Epoch [34/50] - Batch loss: 157.1687 - Epoch Loss: 4205.4003 - Avg Loss: 161.7462\n",
            "Epoch [34/50] - Batch loss: 160.9993 - Epoch Loss: 4366.3996 - Avg Loss: 161.7185\n",
            "Epoch [34/50] - Batch loss: 159.8501 - Epoch Loss: 4526.2497 - Avg Loss: 161.6518\n",
            "Epoch [34/50] - Batch loss: 159.8472 - Epoch Loss: 4686.0969 - Avg Loss: 161.5895\n",
            "Epoch [34/50] - Batch loss: 157.7083 - Epoch Loss: 4843.8052 - Avg Loss: 161.4602\n",
            "Epoch [34/50] - Batch loss: 163.1670 - Epoch Loss: 5006.9722 - Avg Loss: 161.5152\n",
            "Epoch [34/50] - Batch loss: 152.0650 - Epoch Loss: 5159.0372 - Avg Loss: 161.2199\n",
            "Epoch [34/50] - Batch loss: 156.2372 - Epoch Loss: 5315.2744 - Avg Loss: 161.0689\n",
            "Epoch [34/50] - Batch loss: 158.1740 - Epoch Loss: 5473.4483 - Avg Loss: 160.9838\n",
            "Epoch [34/50] - Batch loss: 156.5905 - Epoch Loss: 5630.0388 - Avg Loss: 160.8583\n",
            "Epoch [34/50] - Batch loss: 162.8872 - Epoch Loss: 5792.9261 - Avg Loss: 160.9146\n",
            "Epoch [34/50] - Batch loss: 166.4843 - Epoch Loss: 5959.4104 - Avg Loss: 161.0651\n",
            "Epoch [34/50] - Batch loss: 153.8716 - Epoch Loss: 6113.2820 - Avg Loss: 160.8758\n",
            "Epoch [34/50] - Batch loss: 162.5818 - Epoch Loss: 6275.8638 - Avg Loss: 160.9196\n",
            "Epoch [34/50] - Batch loss: 159.9768 - Epoch Loss: 6435.8406 - Avg Loss: 160.8960\n",
            "Epoch [34/50] - Batch loss: 168.0857 - Epoch Loss: 6603.9263 - Avg Loss: 161.0714\n",
            "Epoch [34/50] - Batch loss: 163.1148 - Epoch Loss: 6767.0411 - Avg Loss: 161.1200\n",
            "Epoch [34/50] - Batch loss: 160.3452 - Epoch Loss: 6927.3864 - Avg Loss: 161.1020\n",
            "Epoch [34/50] - Batch loss: 154.4635 - Epoch Loss: 7081.8498 - Avg Loss: 160.9511\n",
            "Epoch [34/50] - Batch loss: 164.9964 - Epoch Loss: 7246.8463 - Avg Loss: 161.0410\n",
            "Epoch [34/50] - Batch loss: 159.9627 - Epoch Loss: 7406.8090 - Avg Loss: 161.0176\n",
            "Epoch [34/50] - Batch loss: 161.9776 - Epoch Loss: 7568.7866 - Avg Loss: 161.0380\n",
            "Epoch [34/50] - Batch loss: 156.3152 - Epoch Loss: 7725.1017 - Avg Loss: 160.9396\n",
            "Epoch [34/50] - Batch loss: 158.8387 - Epoch Loss: 7883.9404 - Avg Loss: 160.8967\n",
            "Epoch [34/50] - Batch loss: 155.6345 - Epoch Loss: 8039.5749 - Avg Loss: 160.7915\n",
            "Epoch [34/50] - Batch loss: 159.9560 - Epoch Loss: 8199.5309 - Avg Loss: 160.7751\n",
            "Epoch [34/50] - Batch loss: 162.5428 - Epoch Loss: 8362.0736 - Avg Loss: 160.8091\n",
            "Epoch [34/50] - Batch loss: 156.4697 - Epoch Loss: 8518.5433 - Avg Loss: 160.7272\n",
            "Epoch [34/50] - Batch loss: 163.4673 - Epoch Loss: 8682.0107 - Avg Loss: 160.7780\n",
            "Epoch [34/50] - Batch loss: 156.7809 - Epoch Loss: 8838.7915 - Avg Loss: 160.7053\n",
            "Epoch [34/50] - Batch loss: 154.2383 - Epoch Loss: 8993.0299 - Avg Loss: 160.5898\n",
            "Epoch [34/50] - Batch loss: 160.2585 - Epoch Loss: 9153.2884 - Avg Loss: 160.5840\n",
            "Epoch [34/50] - Batch loss: 158.8336 - Epoch Loss: 9312.1220 - Avg Loss: 160.5538\n",
            "Epoch [34/50] - Batch loss: 158.0881 - Epoch Loss: 9470.2101 - Avg Loss: 160.5120\n",
            "Epoch [34/50] - Batch loss: 163.2556 - Epoch Loss: 9633.4657 - Avg Loss: 160.5578\n",
            "Epoch [34/50] - Batch loss: 161.0497 - Epoch Loss: 9794.5154 - Avg Loss: 160.5658\n",
            "Epoch [34/50] - Batch loss: 163.0289 - Epoch Loss: 9957.5443 - Avg Loss: 160.6056\n",
            "Epoch [34/50] - Batch loss: 164.9070 - Epoch Loss: 10122.4512 - Avg Loss: 160.6738\n",
            "Epoch [34/50] - Batch loss: 159.8460 - Epoch Loss: 10282.2972 - Avg Loss: 160.6609\n",
            "Epoch [34/50] - Batch loss: 162.0856 - Epoch Loss: 10444.3828 - Avg Loss: 160.6828\n",
            "Epoch [34/50] - Batch loss: 160.8747 - Epoch Loss: 10605.2575 - Avg Loss: 160.6857\n",
            "Epoch [34/50] - Batch loss: 153.4314 - Epoch Loss: 10758.6890 - Avg Loss: 160.5774\n",
            "Epoch [34/50] - Batch loss: 160.6530 - Epoch Loss: 10919.3419 - Avg Loss: 160.5786\n",
            "Epoch [34/50] - Batch loss: 153.6230 - Epoch Loss: 11072.9649 - Avg Loss: 160.4778\n",
            "Epoch [34/50] - Batch loss: 166.5712 - Epoch Loss: 11239.5361 - Avg Loss: 160.5648\n",
            "Epoch [34/50] - Batch loss: 168.2259 - Epoch Loss: 11407.7620 - Avg Loss: 160.6727\n",
            "Epoch [34/50] - Batch loss: 159.9163 - Epoch Loss: 11567.6783 - Avg Loss: 160.6622\n",
            "Epoch [34/50] - Batch loss: 160.6427 - Epoch Loss: 11728.3210 - Avg Loss: 160.6619\n",
            "Epoch [34/50] - Batch loss: 159.3053 - Epoch Loss: 11887.6263 - Avg Loss: 160.6436\n",
            "Epoch [34/50] - Batch loss: 155.4132 - Epoch Loss: 12043.0395 - Avg Loss: 160.5739\n",
            "Epoch [34/50] - Batch loss: 162.6925 - Epoch Loss: 12205.7320 - Avg Loss: 160.6017\n",
            "Epoch [34/50] - Batch loss: 149.9355 - Epoch Loss: 12355.6674 - Avg Loss: 160.4632\n",
            "Epoch [34/50] - Batch loss: 151.5648 - Epoch Loss: 12507.2322 - Avg Loss: 160.3491\n",
            "Epoch [34/50] - Batch loss: 162.4971 - Epoch Loss: 12669.7293 - Avg Loss: 160.3763\n",
            "Epoch [34/50] - Batch loss: 168.0492 - Epoch Loss: 12837.7784 - Avg Loss: 160.4722\n",
            "Epoch [34/50] - Batch loss: 165.1398 - Epoch Loss: 13002.9182 - Avg Loss: 160.5299\n",
            "Epoch [34/50] - Batch loss: 161.2274 - Epoch Loss: 13164.1456 - Avg Loss: 160.5384\n",
            "Epoch [34/50] - Batch loss: 158.1103 - Epoch Loss: 13322.2559 - Avg Loss: 160.5091\n",
            "Epoch [34/50] - Batch loss: 161.9102 - Epoch Loss: 13484.1661 - Avg Loss: 160.5258\n",
            "Epoch [34/50] - Batch loss: 157.7429 - Epoch Loss: 13641.9090 - Avg Loss: 160.4930\n",
            "Epoch [34/50] - Batch loss: 156.1853 - Epoch Loss: 13798.0942 - Avg Loss: 160.4430\n",
            "Epoch [34/50] - Batch loss: 157.4695 - Epoch Loss: 13955.5637 - Avg Loss: 160.4088\n",
            "Epoch [34/50] - Batch loss: 162.5984 - Epoch Loss: 14118.1621 - Avg Loss: 160.4337\n",
            "Epoch [34/50] - Batch loss: 159.3813 - Epoch Loss: 14277.5434 - Avg Loss: 160.4218\n",
            "Epoch [34/50] - Batch loss: 157.1398 - Epoch Loss: 14434.6832 - Avg Loss: 160.3854\n",
            "Epoch [34/50] - Batch loss: 160.9984 - Epoch Loss: 14595.6816 - Avg Loss: 160.3921\n",
            "Epoch [34/50] - Batch loss: 163.8818 - Epoch Loss: 14759.5635 - Avg Loss: 160.4300\n",
            "Epoch [34/50] - Batch loss: 164.3471 - Epoch Loss: 14923.9105 - Avg Loss: 160.4722\n",
            "Epoch [34/50] - Batch loss: 161.6393 - Epoch Loss: 15085.5498 - Avg Loss: 160.4846\n",
            "Epoch [34/50] - Batch loss: 163.4704 - Epoch Loss: 15249.0202 - Avg Loss: 160.5160\n",
            "Epoch [34/50] - Batch loss: 157.5650 - Epoch Loss: 15406.5852 - Avg Loss: 160.4853\n",
            "Epoch [34/50] - Batch loss: 159.5254 - Epoch Loss: 15566.1106 - Avg Loss: 160.4754\n",
            "Epoch [34/50] - Batch loss: 155.4126 - Epoch Loss: 15721.5231 - Avg Loss: 160.4237\n",
            "Epoch [34/50] - Batch loss: 159.7464 - Epoch Loss: 15881.2695 - Avg Loss: 160.4169\n",
            "Epoch [34/50] - Batch loss: 168.7145 - Epoch Loss: 16049.9840 - Avg Loss: 160.4998\n",
            "Epoch [34/50] - Batch loss: 162.1630 - Epoch Loss: 16212.1470 - Avg Loss: 160.5163\n",
            "Epoch [34/50] - Batch loss: 163.0339 - Epoch Loss: 16375.1809 - Avg Loss: 160.5410\n",
            "Epoch [34/50] - Batch loss: 156.3281 - Epoch Loss: 16531.5090 - Avg Loss: 160.5001\n",
            "Epoch [34/50] - Batch loss: 160.0295 - Epoch Loss: 16691.5385 - Avg Loss: 160.4956\n",
            "Epoch [34/50] - Batch loss: 165.8515 - Epoch Loss: 16857.3901 - Avg Loss: 160.5466\n",
            "Epoch [34/50] - Batch loss: 166.3265 - Epoch Loss: 17023.7166 - Avg Loss: 160.6011\n",
            "Epoch [34/50] - Batch loss: 159.9220 - Epoch Loss: 17183.6386 - Avg Loss: 160.5948\n",
            "Epoch [34/50] - Batch loss: 166.4143 - Epoch Loss: 17350.0529 - Avg Loss: 160.6486\n",
            "Epoch [34/50] - Batch loss: 157.5092 - Epoch Loss: 17507.5621 - Avg Loss: 160.6198\n",
            "Epoch [34/50] - Batch loss: 161.6644 - Epoch Loss: 17669.2265 - Avg Loss: 160.6293\n",
            "Epoch [34/50] - Batch loss: 163.9274 - Epoch Loss: 17833.1539 - Avg Loss: 160.6590\n",
            "Epoch [34/50] - Batch loss: 163.6405 - Epoch Loss: 17996.7944 - Avg Loss: 160.6857\n",
            "Epoch [34/50] - Batch loss: 159.2235 - Epoch Loss: 18156.0179 - Avg Loss: 160.6727\n",
            "Epoch [34/50] - Batch loss: 148.3787 - Epoch Loss: 18304.3967 - Avg Loss: 160.5649\n",
            "Epoch [34/50] - Batch loss: 159.2721 - Epoch Loss: 18463.6687 - Avg Loss: 160.5536\n",
            "Epoch [34/50] - Batch loss: 156.0737 - Epoch Loss: 18619.7424 - Avg Loss: 160.5150\n",
            "Epoch [34/50] - Batch loss: 159.8957 - Epoch Loss: 18779.6381 - Avg Loss: 160.5097\n",
            "Epoch [34/50] - Batch loss: 164.0690 - Epoch Loss: 18943.7071 - Avg Loss: 160.5399\n",
            "Epoch [34/50] - Batch loss: 158.4358 - Epoch Loss: 19102.1429 - Avg Loss: 160.5222\n",
            "Epoch [34/50] - Batch loss: 165.0083 - Epoch Loss: 19267.1512 - Avg Loss: 160.5596\n",
            "Epoch [34/50] - Batch loss: 164.2311 - Epoch Loss: 19431.3823 - Avg Loss: 160.5899\n",
            "Epoch [34/50] - Batch loss: 151.6603 - Epoch Loss: 19583.0426 - Avg Loss: 160.5167\n",
            "Epoch [34/50] - Batch loss: 164.5640 - Epoch Loss: 19747.6066 - Avg Loss: 160.5496\n",
            "Epoch [34/50] - Batch loss: 157.9614 - Epoch Loss: 19905.5680 - Avg Loss: 160.5288\n",
            "Epoch [34/50] - Batch loss: 163.0143 - Epoch Loss: 20068.5823 - Avg Loss: 160.5487\n",
            "Epoch [34/50] - Batch loss: 154.1200 - Epoch Loss: 20222.7023 - Avg Loss: 160.4976\n",
            "Epoch [34/50] - Batch loss: 157.7231 - Epoch Loss: 20380.4254 - Avg Loss: 160.4758\n",
            "Epoch [34/50] - Batch loss: 152.6264 - Epoch Loss: 20533.0519 - Avg Loss: 160.4145\n",
            "Epoch [34/50] - Batch loss: 163.0164 - Epoch Loss: 20696.0683 - Avg Loss: 160.4346\n",
            "Epoch [34/50] - Batch loss: 164.2467 - Epoch Loss: 20860.3150 - Avg Loss: 160.4640\n",
            "Epoch [34/50] - Batch loss: 164.3583 - Epoch Loss: 21024.6734 - Avg Loss: 160.4937\n",
            "Epoch [34/50] - Batch loss: 154.9916 - Epoch Loss: 21179.6650 - Avg Loss: 160.4520\n",
            "Epoch [34/50] - Batch loss: 151.4648 - Epoch Loss: 21331.1297 - Avg Loss: 160.3844\n",
            "Epoch [34/50] - Batch loss: 159.9818 - Epoch Loss: 21491.1115 - Avg Loss: 160.3814\n",
            "Epoch [34/50] - Batch loss: 166.9562 - Epoch Loss: 21658.0677 - Avg Loss: 160.4301\n",
            "Epoch [34/50] - Batch loss: 151.6049 - Epoch Loss: 21809.6726 - Avg Loss: 160.3652\n",
            "Epoch [34/50] - Batch loss: 166.3609 - Epoch Loss: 21976.0334 - Avg Loss: 160.4090\n",
            "Epoch [34/50] - Batch loss: 160.5433 - Epoch Loss: 22136.5767 - Avg Loss: 160.4100\n",
            "Epoch [34/50] - Batch loss: 155.0690 - Epoch Loss: 22291.6457 - Avg Loss: 160.3716\n",
            "Epoch [34/50] - Batch loss: 162.0334 - Epoch Loss: 22453.6791 - Avg Loss: 160.3834\n",
            "Epoch [34/50] - Batch loss: 163.8372 - Epoch Loss: 22617.5163 - Avg Loss: 160.4079\n",
            "Epoch [34/50] - Batch loss: 161.1540 - Epoch Loss: 22778.6703 - Avg Loss: 160.4132\n",
            "Epoch [34/50] - Batch loss: 161.0822 - Epoch Loss: 22939.7526 - Avg Loss: 160.4179\n",
            "Epoch [34/50] - Batch loss: 154.5124 - Epoch Loss: 23094.2650 - Avg Loss: 160.3768\n",
            "Epoch [34/50] - Batch loss: 159.5239 - Epoch Loss: 23253.7888 - Avg Loss: 160.3710\n",
            "Epoch [34/50] - Batch loss: 159.5055 - Epoch Loss: 23413.2944 - Avg Loss: 160.3650\n",
            "Epoch [34/50] - Batch loss: 160.3876 - Epoch Loss: 23573.6820 - Avg Loss: 160.3652\n",
            "Epoch [34/50] - Batch loss: 161.9358 - Epoch Loss: 23735.6178 - Avg Loss: 160.3758\n",
            "Epoch [34/50] - Batch loss: 158.3536 - Epoch Loss: 23893.9715 - Avg Loss: 160.3622\n",
            "Epoch [34/50] - Batch loss: 161.5779 - Epoch Loss: 24055.5493 - Avg Loss: 160.3703\n",
            "Epoch [34/50] - Batch loss: 158.6747 - Epoch Loss: 24214.2240 - Avg Loss: 160.3591\n",
            "Epoch [34/50] - Batch loss: 152.9071 - Epoch Loss: 24367.1311 - Avg Loss: 160.3101\n",
            "Epoch [34/50] - Batch loss: 153.6039 - Epoch Loss: 24520.7350 - Avg Loss: 160.2662\n",
            "Epoch [34/50] - Batch loss: 157.7749 - Epoch Loss: 24678.5099 - Avg Loss: 160.2501\n",
            "Epoch [34/50] - Batch loss: 168.4997 - Epoch Loss: 24847.0096 - Avg Loss: 160.3033\n",
            "Epoch [34/50] - Batch loss: 160.3381 - Epoch Loss: 25007.3477 - Avg Loss: 160.3035\n",
            "Epoch [34/50] - Batch loss: 151.5791 - Epoch Loss: 25158.9268 - Avg Loss: 160.2479\n",
            "Epoch [34/50] - Batch loss: 159.8381 - Epoch Loss: 25318.7649 - Avg Loss: 160.2453\n",
            "Epoch [34/50] - Batch loss: 160.0198 - Epoch Loss: 25478.7847 - Avg Loss: 160.2439\n",
            "Epoch [34/50] - Batch loss: 162.9454 - Epoch Loss: 25641.7301 - Avg Loss: 160.2608\n",
            "Epoch [34/50] - Batch loss: 159.7409 - Epoch Loss: 25801.4710 - Avg Loss: 160.2576\n",
            "Epoch [34/50] - Batch loss: 155.0831 - Epoch Loss: 25956.5541 - Avg Loss: 160.2256\n",
            "Epoch [34/50] - Batch loss: 161.1512 - Epoch Loss: 26117.7054 - Avg Loss: 160.2313\n",
            "Epoch [34/50] - Batch loss: 159.7975 - Epoch Loss: 26277.5028 - Avg Loss: 160.2287\n",
            "Epoch [34/50] - Batch loss: 160.1945 - Epoch Loss: 26437.6974 - Avg Loss: 160.2285\n",
            "Epoch [34/50] - Batch loss: 152.0656 - Epoch Loss: 26589.7629 - Avg Loss: 160.1793\n",
            "Epoch [34/50] - Batch loss: 152.8729 - Epoch Loss: 26742.6358 - Avg Loss: 160.1355\n",
            "Epoch [34/50] - Batch loss: 159.6005 - Epoch Loss: 26902.2363 - Avg Loss: 160.1324\n",
            "Epoch [34/50] - Batch loss: 159.1512 - Epoch Loss: 27061.3875 - Avg Loss: 160.1266\n",
            "Epoch [34/50] - Batch loss: 166.5015 - Epoch Loss: 27227.8890 - Avg Loss: 160.1641\n",
            "Epoch [34/50] - Batch loss: 160.8734 - Epoch Loss: 27388.7624 - Avg Loss: 160.1682\n",
            "Epoch [34/50] - Batch loss: 160.1163 - Epoch Loss: 27548.8787 - Avg Loss: 160.1679\n",
            "Epoch [34/50] - Batch loss: 159.1521 - Epoch Loss: 27708.0308 - Avg Loss: 160.1620\n",
            "Epoch [34/50] - Batch loss: 159.7869 - Epoch Loss: 27867.8177 - Avg Loss: 160.1599\n",
            "Epoch [34/50] - Batch loss: 156.4166 - Epoch Loss: 28024.2343 - Avg Loss: 160.1385\n",
            "Epoch [34/50] - Batch loss: 156.5420 - Epoch Loss: 28180.7764 - Avg Loss: 160.1180\n",
            "Epoch [34/50] - Batch loss: 161.0530 - Epoch Loss: 28341.8293 - Avg Loss: 160.1233\n",
            "Epoch [34/50] - Batch loss: 157.5549 - Epoch Loss: 28499.3842 - Avg Loss: 160.1089\n",
            "Epoch [34/50] - Batch loss: 161.8428 - Epoch Loss: 28661.2271 - Avg Loss: 160.1186\n",
            "Epoch [34/50] - Batch loss: 159.2392 - Epoch Loss: 28820.4662 - Avg Loss: 160.1137\n",
            "Epoch [34/50] - Batch loss: 153.2688 - Epoch Loss: 28973.7350 - Avg Loss: 160.0759\n",
            "Epoch [34/50] - Batch loss: 156.6578 - Epoch Loss: 29130.3928 - Avg Loss: 160.0571\n",
            "Epoch [34/50] - Batch loss: 154.6943 - Epoch Loss: 29285.0870 - Avg Loss: 160.0278\n",
            "Epoch [34/50] - Batch loss: 153.6818 - Epoch Loss: 29438.7689 - Avg Loss: 159.9933\n",
            "Epoch [34/50] - Batch loss: 159.3535 - Epoch Loss: 29598.1223 - Avg Loss: 159.9899\n",
            "Epoch [34/50] - Batch loss: 162.0623 - Epoch Loss: 29760.1846 - Avg Loss: 160.0010\n",
            "Epoch [34/50] - Batch loss: 158.2534 - Epoch Loss: 29918.4380 - Avg Loss: 159.9916\n",
            "Epoch [34/50] - Batch loss: 162.4038 - Epoch Loss: 30080.8418 - Avg Loss: 160.0045\n",
            "Epoch [34/50] - Batch loss: 166.1686 - Epoch Loss: 30247.0104 - Avg Loss: 160.0371\n",
            "Epoch [34/50] - Batch loss: 168.5449 - Epoch Loss: 30415.5553 - Avg Loss: 160.0819\n",
            "Epoch [34/50] - Batch loss: 157.2549 - Epoch Loss: 30572.8102 - Avg Loss: 160.0671\n",
            "Epoch [34/50] - Batch loss: 153.1933 - Epoch Loss: 30726.0034 - Avg Loss: 160.0313\n",
            "Epoch [34/50] - Batch loss: 159.1463 - Epoch Loss: 30885.1498 - Avg Loss: 160.0267\n",
            "Epoch [34/50] - Batch loss: 159.9853 - Epoch Loss: 31045.1350 - Avg Loss: 160.0265\n",
            "Epoch [34/50] - Batch loss: 160.0599 - Epoch Loss: 31205.1950 - Avg Loss: 160.0266\n",
            "Epoch [34/50] - Batch loss: 154.8229 - Epoch Loss: 31360.0179 - Avg Loss: 160.0001\n",
            "Epoch [34/50] - Batch loss: 160.5102 - Epoch Loss: 31520.5281 - Avg Loss: 160.0027\n",
            "Epoch [34/50] - Batch loss: 160.7724 - Epoch Loss: 31681.3005 - Avg Loss: 160.0066\n",
            "Epoch [34/50] - Batch loss: 160.2000 - Epoch Loss: 31841.5006 - Avg Loss: 160.0075\n",
            "Epoch [34/50] - Batch loss: 164.4062 - Epoch Loss: 32005.9067 - Avg Loss: 160.0295\n",
            "Epoch [34/50] - Batch loss: 158.6450 - Epoch Loss: 32164.5517 - Avg Loss: 160.0226\n",
            "Epoch [34/50] - Batch loss: 157.3024 - Epoch Loss: 32321.8541 - Avg Loss: 160.0092\n",
            "Epoch [34/50] - Batch loss: 162.6908 - Epoch Loss: 32484.5449 - Avg Loss: 160.0224\n",
            "Epoch [34/50] - Batch loss: 159.3133 - Epoch Loss: 32643.8582 - Avg Loss: 160.0189\n",
            "Epoch [34/50] - Batch loss: 165.5502 - Epoch Loss: 32809.4084 - Avg Loss: 160.0459\n",
            "Epoch [34/50] - Batch loss: 157.2322 - Epoch Loss: 32966.6405 - Avg Loss: 160.0322\n",
            "Epoch [34/50] - Batch loss: 158.1188 - Epoch Loss: 33124.7594 - Avg Loss: 160.0230\n",
            "Epoch [34/50] - Batch loss: 161.5524 - Epoch Loss: 33286.3118 - Avg Loss: 160.0303\n",
            "Epoch [34/50] - Batch loss: 156.8820 - Epoch Loss: 33443.1937 - Avg Loss: 160.0153\n",
            "Epoch [34/50] - Batch loss: 160.6135 - Epoch Loss: 33603.8072 - Avg Loss: 160.0181\n",
            "Epoch [34/50] - Batch loss: 155.1253 - Epoch Loss: 33758.9325 - Avg Loss: 159.9949\n",
            "Epoch [34/50] - Batch loss: 151.6364 - Epoch Loss: 33910.5689 - Avg Loss: 159.9555\n",
            "Epoch [34/50] - Batch loss: 162.2672 - Epoch Loss: 34072.8361 - Avg Loss: 159.9664\n",
            "Epoch [34/50] - Batch loss: 169.6080 - Epoch Loss: 34242.4441 - Avg Loss: 160.0114\n",
            "Epoch [34/50] - Batch loss: 167.8121 - Epoch Loss: 34410.2561 - Avg Loss: 160.0477\n",
            "Epoch [34/50] - Batch loss: 158.6346 - Epoch Loss: 34568.8907 - Avg Loss: 160.0412\n",
            "Epoch [34/50] - Batch loss: 164.4473 - Epoch Loss: 34733.3380 - Avg Loss: 160.0615\n",
            "Epoch [34/50] - Batch loss: 166.2485 - Epoch Loss: 34899.5865 - Avg Loss: 160.0898\n",
            "Epoch [34/50] - Batch loss: 162.8359 - Epoch Loss: 35062.4223 - Avg Loss: 160.1024\n",
            "Epoch [34/50] - Batch loss: 161.9325 - Epoch Loss: 35224.3548 - Avg Loss: 160.1107\n",
            "Epoch [34/50] - Batch loss: 151.4273 - Epoch Loss: 35375.7822 - Avg Loss: 160.0714\n",
            "Epoch [34/50] - Batch loss: 161.1489 - Epoch Loss: 35536.9311 - Avg Loss: 160.0763\n",
            "Epoch [34/50] - Batch loss: 159.3617 - Epoch Loss: 35696.2928 - Avg Loss: 160.0731\n",
            "Epoch [34/50] - Batch loss: 165.2109 - Epoch Loss: 35861.5036 - Avg Loss: 160.0960\n",
            "Epoch [34/50] - Batch loss: 160.1524 - Epoch Loss: 36021.6560 - Avg Loss: 160.0962\n",
            "Epoch [34/50] - Batch loss: 163.1905 - Epoch Loss: 36184.8465 - Avg Loss: 160.1099\n",
            "Epoch [34/50] - Batch loss: 162.9240 - Epoch Loss: 36347.7705 - Avg Loss: 160.1223\n",
            "Epoch [34/50] - Batch loss: 154.4650 - Epoch Loss: 36502.2354 - Avg Loss: 160.0975\n",
            "Epoch [34/50] - Batch loss: 153.3179 - Epoch Loss: 36655.5533 - Avg Loss: 160.0679\n",
            "Epoch [34/50] - Batch loss: 156.4208 - Epoch Loss: 36811.9741 - Avg Loss: 160.0521\n",
            "Epoch [34/50] - Batch loss: 165.8229 - Epoch Loss: 36977.7970 - Avg Loss: 160.0770\n",
            "Epoch [34/50] - Batch loss: 157.1778 - Epoch Loss: 37134.9749 - Avg Loss: 160.0645\n",
            "Epoch [34/50] - Batch loss: 162.8669 - Epoch Loss: 37297.8418 - Avg Loss: 160.0766\n",
            "Epoch [34/50] - Batch loss: 159.1087 - Epoch Loss: 37456.9504 - Avg Loss: 160.0724\n",
            "Epoch [34/50] - Batch loss: 158.3774 - Epoch Loss: 37615.3278 - Avg Loss: 160.0652\n",
            "Epoch [34/50] - Batch loss: 166.9321 - Epoch Loss: 37782.2599 - Avg Loss: 160.0943\n",
            "Epoch [34/50] - Batch loss: 156.6382 - Epoch Loss: 37938.8981 - Avg Loss: 160.0797\n",
            "Epoch [34/50] - Batch loss: 158.7289 - Epoch Loss: 38097.6270 - Avg Loss: 160.0741\n",
            "Epoch [34/50] - Batch loss: 156.5548 - Epoch Loss: 38254.1818 - Avg Loss: 160.0593\n",
            "Epoch [34/50] - Batch loss: 158.9222 - Epoch Loss: 38413.1040 - Avg Loss: 160.0546\n",
            "Epoch [34/50] - Batch loss: 162.2479 - Epoch Loss: 38575.3519 - Avg Loss: 160.0637\n",
            "Epoch [34/50] - Batch loss: 168.3376 - Epoch Loss: 38743.6895 - Avg Loss: 160.0979\n",
            "Epoch [34/50] - Batch loss: 155.9100 - Epoch Loss: 38899.5995 - Avg Loss: 160.0807\n",
            "Epoch [34/50] - Batch loss: 158.2834 - Epoch Loss: 39057.8828 - Avg Loss: 160.0733\n",
            "Epoch [34/50] - Batch loss: 167.3080 - Epoch Loss: 39225.1908 - Avg Loss: 160.1028\n",
            "Epoch [34/50] - Batch loss: 150.6648 - Epoch Loss: 39375.8557 - Avg Loss: 160.0645\n",
            "Epoch [34/50] - Batch loss: 165.6133 - Epoch Loss: 39541.4689 - Avg Loss: 160.0869\n",
            "Epoch [34/50] - Batch loss: 157.9627 - Epoch Loss: 39699.4316 - Avg Loss: 160.0784\n",
            "Epoch [34/50] - Batch loss: 155.0556 - Epoch Loss: 39854.4872 - Avg Loss: 160.0582\n",
            "Epoch [34/50] - Batch loss: 156.7567 - Epoch Loss: 40011.2440 - Avg Loss: 160.0450\n",
            "Epoch [34/50] - Batch loss: 163.7783 - Epoch Loss: 40175.0223 - Avg Loss: 160.0598\n",
            "Epoch [34/50] - Batch loss: 161.7781 - Epoch Loss: 40336.8004 - Avg Loss: 160.0667\n",
            "Epoch [34/50] - Batch loss: 157.8582 - Epoch Loss: 40494.6586 - Avg Loss: 160.0579\n",
            "Epoch [34/50] - Batch loss: 167.9798 - Epoch Loss: 40662.6384 - Avg Loss: 160.0891\n",
            "Epoch [34/50] - Batch loss: 160.6530 - Epoch Loss: 40823.2915 - Avg Loss: 160.0913\n",
            "Epoch [34/50] - Batch loss: 165.0234 - Epoch Loss: 40988.3148 - Avg Loss: 160.1106\n",
            "Epoch [34/50] - Batch loss: 158.4969 - Epoch Loss: 41146.8117 - Avg Loss: 160.1043\n",
            "Epoch [34/50] - Batch loss: 160.2814 - Epoch Loss: 41307.0932 - Avg Loss: 160.1050\n",
            "Epoch [34/50] - Batch loss: 158.0139 - Epoch Loss: 41465.1071 - Avg Loss: 160.0969\n",
            "Epoch [34/50] - Batch loss: 167.2428 - Epoch Loss: 41632.3499 - Avg Loss: 160.1244\n",
            "Epoch [34/50] - Batch loss: 168.0997 - Epoch Loss: 41800.4496 - Avg Loss: 160.1550\n",
            "Epoch [34/50] - Batch loss: 162.5829 - Epoch Loss: 41963.0325 - Avg Loss: 160.1642\n",
            "Epoch [34/50] - Batch loss: 160.1210 - Epoch Loss: 42123.1535 - Avg Loss: 160.1641\n",
            "Epoch [34/50] - Batch loss: 159.0965 - Epoch Loss: 42282.2501 - Avg Loss: 160.1600\n",
            "Epoch [34/50] - Batch loss: 152.8309 - Epoch Loss: 42435.0810 - Avg Loss: 160.1324\n",
            "Epoch [34/50] - Batch loss: 163.3149 - Epoch Loss: 42598.3959 - Avg Loss: 160.1443\n",
            "Epoch [34/50] - Batch loss: 151.5776 - Epoch Loss: 42749.9735 - Avg Loss: 160.1123\n",
            "Epoch [34/50] - Batch loss: 154.9803 - Epoch Loss: 42904.9537 - Avg Loss: 160.0931\n",
            "Epoch [34/50] - Batch loss: 165.5899 - Epoch Loss: 43070.5436 - Avg Loss: 160.1135\n",
            "Epoch [34/50] - Batch loss: 160.2026 - Epoch Loss: 43230.7462 - Avg Loss: 160.1139\n",
            "Epoch [34/50] - Batch loss: 162.5452 - Epoch Loss: 43393.2914 - Avg Loss: 160.1228\n",
            "Epoch [34/50] - Batch loss: 161.1227 - Epoch Loss: 43554.4142 - Avg Loss: 160.1265\n",
            "Epoch [34/50] - Batch loss: 158.4917 - Epoch Loss: 43712.9059 - Avg Loss: 160.1205\n",
            "Epoch [34/50] - Batch loss: 146.9820 - Epoch Loss: 43859.8879 - Avg Loss: 160.0726\n",
            "Epoch [34/50] - Batch loss: 167.9809 - Epoch Loss: 44027.8688 - Avg Loss: 160.1013\n",
            "Epoch [34/50] - Batch loss: 151.4077 - Epoch Loss: 44179.2766 - Avg Loss: 160.0698\n",
            "Epoch [34/50] - Batch loss: 167.2152 - Epoch Loss: 44346.4917 - Avg Loss: 160.0956\n",
            "Epoch [34/50] - Batch loss: 160.9772 - Epoch Loss: 44507.4689 - Avg Loss: 160.0988\n",
            "Epoch [34/50] - Batch loss: 161.1305 - Epoch Loss: 44668.5994 - Avg Loss: 160.1025\n",
            "Epoch [34/50] - Batch loss: 153.5966 - Epoch Loss: 44822.1960 - Avg Loss: 160.0793\n",
            "Epoch [34/50] - Batch loss: 163.6446 - Epoch Loss: 44985.8406 - Avg Loss: 160.0920\n",
            "Epoch [34/50] - Batch loss: 165.6078 - Epoch Loss: 45151.4484 - Avg Loss: 160.1115\n",
            "Epoch [34/50] - Batch loss: 169.0008 - Epoch Loss: 45320.4493 - Avg Loss: 160.1429\n",
            "Epoch [34/50] - Batch loss: 161.5895 - Epoch Loss: 45482.0388 - Avg Loss: 160.1480\n",
            "Epoch [34/50] - Batch loss: 161.5339 - Epoch Loss: 45643.5726 - Avg Loss: 160.1529\n",
            "Epoch [34/50] - Batch loss: 158.4209 - Epoch Loss: 45801.9935 - Avg Loss: 160.1468\n",
            "Epoch [34/50] - Batch loss: 159.5597 - Epoch Loss: 45961.5532 - Avg Loss: 160.1448\n",
            "Epoch [34/50] - Batch loss: 164.7070 - Epoch Loss: 46126.2602 - Avg Loss: 160.1606\n",
            "Epoch [34/50] - Batch loss: 152.5273 - Epoch Loss: 46278.7875 - Avg Loss: 160.1342\n",
            "Epoch [34/50] - Batch loss: 158.3268 - Epoch Loss: 46437.1144 - Avg Loss: 160.1280\n",
            "Epoch [34/50] - Batch loss: 156.8766 - Epoch Loss: 46593.9910 - Avg Loss: 160.1168\n",
            "Epoch [34/50] - Batch loss: 158.4008 - Epoch Loss: 46752.3918 - Avg Loss: 160.1109\n",
            "Epoch [34/50] - Batch loss: 161.5123 - Epoch Loss: 46913.9041 - Avg Loss: 160.1157\n",
            "Epoch [34/50] - Batch loss: 158.8922 - Epoch Loss: 47072.7963 - Avg Loss: 160.1116\n",
            "Epoch [34/50] - Batch loss: 158.7688 - Epoch Loss: 47231.5651 - Avg Loss: 160.1070\n",
            "Epoch [34/50] - Batch loss: 160.0593 - Epoch Loss: 47391.6244 - Avg Loss: 160.1068\n",
            "Epoch [34/50] - Batch loss: 156.4993 - Epoch Loss: 47548.1237 - Avg Loss: 160.0947\n",
            "Epoch [34/50] - Batch loss: 161.4696 - Epoch Loss: 47709.5933 - Avg Loss: 160.0993\n",
            "Epoch [34/50] - Batch loss: 153.5825 - Epoch Loss: 47863.1758 - Avg Loss: 160.0775\n",
            "Epoch [34/50] - Batch loss: 159.5918 - Epoch Loss: 48022.7676 - Avg Loss: 160.0759\n",
            "Epoch [34/50] - Batch loss: 161.8931 - Epoch Loss: 48184.6607 - Avg Loss: 160.0819\n",
            "Epoch [34/50] - Batch loss: 168.3328 - Epoch Loss: 48352.9935 - Avg Loss: 160.1092\n",
            "Epoch [34/50] - Batch loss: 166.2764 - Epoch Loss: 48519.2699 - Avg Loss: 160.1296\n",
            "Epoch [34/50] - Batch loss: 166.3907 - Epoch Loss: 48685.6606 - Avg Loss: 160.1502\n",
            "Epoch [34/50] - Batch loss: 152.3271 - Epoch Loss: 48837.9876 - Avg Loss: 160.1245\n",
            "Epoch [34/50] - Batch loss: 161.3663 - Epoch Loss: 48999.3540 - Avg Loss: 160.1286\n",
            "Epoch [34/50] - Batch loss: 165.5503 - Epoch Loss: 49164.9043 - Avg Loss: 160.1463\n",
            "Epoch [34/50] - Batch loss: 154.6654 - Epoch Loss: 49319.5697 - Avg Loss: 160.1285\n",
            "Epoch [34/50] - Batch loss: 161.7404 - Epoch Loss: 49481.3101 - Avg Loss: 160.1337\n",
            "Epoch [34/50] - Batch loss: 161.9704 - Epoch Loss: 49643.2805 - Avg Loss: 160.1396\n",
            "Epoch [34/50] - Batch loss: 152.8176 - Epoch Loss: 49796.0981 - Avg Loss: 160.1161\n",
            "Epoch [34/50] - Batch loss: 157.8025 - Epoch Loss: 49953.9006 - Avg Loss: 160.1087\n",
            "Epoch [34/50] - Batch loss: 154.6558 - Epoch Loss: 50108.5564 - Avg Loss: 160.0912\n",
            "Epoch [34/50] - Batch loss: 161.4528 - Epoch Loss: 50270.0091 - Avg Loss: 160.0956\n",
            "Epoch [34/50] - Batch loss: 159.5101 - Epoch Loss: 50429.5193 - Avg Loss: 160.0937\n",
            "Epoch [34/50] - Batch loss: 152.2202 - Epoch Loss: 50581.7394 - Avg Loss: 160.0688\n",
            "Epoch [34/50] - Batch loss: 159.4632 - Epoch Loss: 50741.2026 - Avg Loss: 160.0669\n",
            "Epoch [34/50] - Batch loss: 153.4232 - Epoch Loss: 50894.6258 - Avg Loss: 160.0460\n",
            "Epoch [34/50] - Batch loss: 157.5298 - Epoch Loss: 51052.1555 - Avg Loss: 160.0381\n",
            "Epoch [34/50] - Batch loss: 156.1921 - Epoch Loss: 51208.3477 - Avg Loss: 160.0261\n",
            "Epoch [34/50] - Batch loss: 151.7439 - Epoch Loss: 51360.0915 - Avg Loss: 160.0003\n",
            "Epoch [34/50] - Batch loss: 154.6700 - Epoch Loss: 51514.7615 - Avg Loss: 159.9837\n",
            "Epoch [34/50] - Batch loss: 165.6104 - Epoch Loss: 51680.3719 - Avg Loss: 160.0012\n",
            "Epoch [34/50] - Batch loss: 158.3061 - Epoch Loss: 51838.6780 - Avg Loss: 159.9959\n",
            "Epoch [34/50] - Batch loss: 158.0598 - Epoch Loss: 51996.7377 - Avg Loss: 159.9900\n",
            "Epoch [34/50] - Batch loss: 159.6070 - Epoch Loss: 52156.3447 - Avg Loss: 159.9888\n",
            "Epoch [34/50] - Batch loss: 160.9582 - Epoch Loss: 52317.3029 - Avg Loss: 159.9918\n",
            "Epoch [34/50] - Batch loss: 160.8284 - Epoch Loss: 52478.1313 - Avg Loss: 159.9943\n",
            "Epoch [34/50] - Batch loss: 158.6533 - Epoch Loss: 52636.7846 - Avg Loss: 159.9902\n",
            "Epoch [34/50] - Batch loss: 163.2487 - Epoch Loss: 52800.0333 - Avg Loss: 160.0001\n",
            "Epoch [34/50] - Batch loss: 149.3495 - Epoch Loss: 52949.3828 - Avg Loss: 159.9679\n",
            "Epoch [34/50] - Batch loss: 163.0773 - Epoch Loss: 53112.4601 - Avg Loss: 159.9773\n",
            "Epoch [34/50] - Batch loss: 158.4588 - Epoch Loss: 53270.9189 - Avg Loss: 159.9727\n",
            "Epoch [34/50] - Batch loss: 149.4027 - Epoch Loss: 53420.3216 - Avg Loss: 159.9411\n",
            "Epoch [34/50] - Batch loss: 153.5448 - Epoch Loss: 53573.8663 - Avg Loss: 159.9220\n",
            "Epoch [34/50] - Batch loss: 154.0185 - Epoch Loss: 53727.8849 - Avg Loss: 159.9044\n",
            "Epoch [34/50] - Batch loss: 162.3820 - Epoch Loss: 53890.2669 - Avg Loss: 159.9118\n",
            "Epoch [34/50] - Batch loss: 153.5421 - Epoch Loss: 54043.8090 - Avg Loss: 159.8929\n",
            "Epoch [34/50] - Batch loss: 161.5481 - Epoch Loss: 54205.3570 - Avg Loss: 159.8978\n",
            "Epoch [34/50] - Batch loss: 147.7732 - Epoch Loss: 54353.1302 - Avg Loss: 159.8621\n",
            "Epoch [34/50] - Batch loss: 156.5249 - Epoch Loss: 54509.6551 - Avg Loss: 159.8524\n",
            "Epoch [34/50] - Batch loss: 157.3381 - Epoch Loss: 54666.9932 - Avg Loss: 159.8450\n",
            "Epoch [34/50] - Batch loss: 164.6341 - Epoch Loss: 54831.6273 - Avg Loss: 159.8590\n",
            "Epoch [34/50] - Batch loss: 156.6242 - Epoch Loss: 54988.2515 - Avg Loss: 159.8496\n",
            "Epoch [34/50] - Batch loss: 158.9282 - Epoch Loss: 55147.1797 - Avg Loss: 159.8469\n",
            "Epoch [34/50] - Batch loss: 165.1897 - Epoch Loss: 55312.3695 - Avg Loss: 159.8623\n",
            "Epoch [34/50] - Batch loss: 155.8198 - Epoch Loss: 55468.1893 - Avg Loss: 159.8507\n",
            "Epoch [34/50] - Batch loss: 166.7598 - Epoch Loss: 55634.9491 - Avg Loss: 159.8705\n",
            "Epoch [34/50] - Batch loss: 169.3878 - Epoch Loss: 55804.3369 - Avg Loss: 159.8978\n",
            "Epoch [34/50] - Batch loss: 168.9992 - Epoch Loss: 55973.3361 - Avg Loss: 159.9238\n",
            "Epoch [34/50] - Batch loss: 153.4220 - Epoch Loss: 56126.7581 - Avg Loss: 159.9053\n",
            "Epoch [34/50] - Batch loss: 158.5490 - Epoch Loss: 56285.3071 - Avg Loss: 159.9014\n",
            "Epoch [34/50] - Batch loss: 166.2749 - Epoch Loss: 56451.5819 - Avg Loss: 159.9195\n",
            "Epoch [34/50] - Batch loss: 157.9545 - Epoch Loss: 56609.5365 - Avg Loss: 159.9139\n",
            "Epoch [34/50] - Batch loss: 156.7667 - Epoch Loss: 56766.3032 - Avg Loss: 159.9051\n",
            "Epoch [34/50] - Batch loss: 166.9957 - Epoch Loss: 56933.2989 - Avg Loss: 159.9250\n",
            "Epoch [34/50] - Batch loss: 151.8352 - Epoch Loss: 57085.1342 - Avg Loss: 159.9023\n",
            "Epoch [34/50] - Batch loss: 158.4791 - Epoch Loss: 57243.6133 - Avg Loss: 159.8984\n",
            "Epoch [34/50] - Batch loss: 157.5325 - Epoch Loss: 57401.1458 - Avg Loss: 159.8918\n",
            "Epoch [34/50] - Batch loss: 155.6881 - Epoch Loss: 57556.8339 - Avg Loss: 159.8801\n",
            "Epoch [34/50] - Batch loss: 163.5299 - Epoch Loss: 57720.3638 - Avg Loss: 159.8902\n",
            "Epoch [34/50] - Batch loss: 162.2144 - Epoch Loss: 57882.5782 - Avg Loss: 159.8966\n",
            "Epoch [34/50] - Batch loss: 153.2973 - Epoch Loss: 58035.8755 - Avg Loss: 159.8784\n",
            "Epoch [34/50] - Batch loss: 158.5935 - Epoch Loss: 58194.4690 - Avg Loss: 159.8749\n",
            "Epoch [34/50] - Batch loss: 167.2702 - Epoch Loss: 58361.7391 - Avg Loss: 159.8952\n",
            "Epoch [34/50] - Batch loss: 159.0092 - Epoch Loss: 58520.7483 - Avg Loss: 159.8928\n",
            "Epoch [34/50] - Batch loss: 169.8987 - Epoch Loss: 58690.6470 - Avg Loss: 159.9200\n",
            "Epoch [34/50] - Batch loss: 159.6765 - Epoch Loss: 58850.3236 - Avg Loss: 159.9194\n",
            "Epoch [34/50] - Batch loss: 162.7034 - Epoch Loss: 59013.0269 - Avg Loss: 159.9269\n",
            "Epoch [34/50] - Batch loss: 165.9701 - Epoch Loss: 59178.9970 - Avg Loss: 159.9432\n",
            "Epoch [34/50] - Batch loss: 166.7019 - Epoch Loss: 59345.6989 - Avg Loss: 159.9615\n",
            "Epoch [34/50] - Batch loss: 158.6331 - Epoch Loss: 59504.3320 - Avg Loss: 159.9579\n",
            "Epoch [34/50] - Batch loss: 167.2381 - Epoch Loss: 59671.5701 - Avg Loss: 159.9774\n",
            "Epoch [34/50] - Batch loss: 153.0951 - Epoch Loss: 59824.6652 - Avg Loss: 159.9590\n",
            "Epoch [34/50] - Batch loss: 163.4516 - Epoch Loss: 59988.1168 - Avg Loss: 159.9683\n",
            "Epoch [34/50] - Batch loss: 158.6780 - Epoch Loss: 60146.7948 - Avg Loss: 159.9649\n",
            "Epoch [34/50] - Batch loss: 156.0909 - Epoch Loss: 60302.8857 - Avg Loss: 159.9546\n",
            "Epoch [34/50] - Batch loss: 156.5193 - Epoch Loss: 60459.4051 - Avg Loss: 159.9455\n",
            "Epoch [34/50] - Batch loss: 153.9819 - Epoch Loss: 60613.3870 - Avg Loss: 159.9298\n",
            "Epoch [34/50] - Batch loss: 156.9069 - Epoch Loss: 60770.2939 - Avg Loss: 159.9218\n",
            "Epoch [34/50] - Batch loss: 158.6055 - Epoch Loss: 60928.8994 - Avg Loss: 159.9184\n",
            "Epoch [34/50] - Batch loss: 161.2292 - Epoch Loss: 61090.1286 - Avg Loss: 159.9218\n",
            "Epoch [34/50] - Batch loss: 167.6259 - Epoch Loss: 61257.7545 - Avg Loss: 159.9419\n",
            "Epoch [34/50] - Batch loss: 154.7208 - Epoch Loss: 61412.4753 - Avg Loss: 159.9283\n",
            "Epoch [34/50] - Batch loss: 156.0353 - Epoch Loss: 61568.5106 - Avg Loss: 159.9182\n",
            "Epoch [34/50] - Batch loss: 160.6747 - Epoch Loss: 61729.1853 - Avg Loss: 159.9202\n",
            "Epoch [34/50] - Batch loss: 164.0441 - Epoch Loss: 61893.2294 - Avg Loss: 159.9308\n",
            "Epoch [34/50] - Batch loss: 157.1225 - Epoch Loss: 62050.3519 - Avg Loss: 159.9236\n",
            "Epoch [34/50] - Batch loss: 161.1621 - Epoch Loss: 62211.5140 - Avg Loss: 159.9268\n",
            "Epoch [34/50] - Batch loss: 152.6194 - Epoch Loss: 62364.1334 - Avg Loss: 159.9080\n",
            "Epoch [34/50] - Batch loss: 159.6509 - Epoch Loss: 62523.7843 - Avg Loss: 159.9074\n",
            "Epoch [34/50] - Batch loss: 154.5604 - Epoch Loss: 62678.3447 - Avg Loss: 159.8937\n",
            "Epoch [34/50] - Batch loss: 161.3721 - Epoch Loss: 62839.7168 - Avg Loss: 159.8975\n",
            "Epoch [34/50] - Batch loss: 160.0059 - Epoch Loss: 62999.7227 - Avg Loss: 159.8978\n",
            "Epoch [34/50] - Batch loss: 162.5839 - Epoch Loss: 63162.3066 - Avg Loss: 159.9046\n",
            "Epoch [34/50] - Batch loss: 152.6709 - Epoch Loss: 63314.9775 - Avg Loss: 159.8863\n",
            "Epoch [34/50] - Batch loss: 160.4633 - Epoch Loss: 63475.4408 - Avg Loss: 159.8878\n",
            "Epoch [34/50] - Batch loss: 155.9747 - Epoch Loss: 63631.4156 - Avg Loss: 159.8779\n",
            "Epoch [34/50] - Batch loss: 159.4602 - Epoch Loss: 63790.8758 - Avg Loss: 159.8769\n",
            "Epoch [34/50] - Batch loss: 151.2772 - Epoch Loss: 63942.1530 - Avg Loss: 159.8554\n",
            "Epoch [34/50] - Batch loss: 158.9362 - Epoch Loss: 64101.0892 - Avg Loss: 159.8531\n",
            "Epoch [34/50] - Batch loss: 159.9232 - Epoch Loss: 64261.0124 - Avg Loss: 159.8533\n",
            "Epoch [34/50] - Batch loss: 156.1498 - Epoch Loss: 64417.1622 - Avg Loss: 159.8441\n",
            "Epoch [34/50] - Batch loss: 157.7727 - Epoch Loss: 64574.9349 - Avg Loss: 159.8389\n",
            "Epoch [34/50] - Batch loss: 151.9298 - Epoch Loss: 64726.8647 - Avg Loss: 159.8194\n",
            "Epoch [34/50] - Batch loss: 162.3249 - Epoch Loss: 64889.1896 - Avg Loss: 159.8256\n",
            "Epoch [34/50] - Batch loss: 159.6106 - Epoch Loss: 65048.8002 - Avg Loss: 159.8251\n",
            "Epoch [34/50] - Batch loss: 154.4265 - Epoch Loss: 65203.2267 - Avg Loss: 159.8118\n",
            "Epoch [34/50] - Batch loss: 170.8547 - Epoch Loss: 65374.0814 - Avg Loss: 159.8388\n",
            "Epoch [34/50] - Batch loss: 161.2624 - Epoch Loss: 65535.3438 - Avg Loss: 159.8423\n",
            "Epoch [34/50] - Batch loss: 152.5916 - Epoch Loss: 65687.9354 - Avg Loss: 159.8247\n",
            "Epoch [34/50] - Batch loss: 156.3544 - Epoch Loss: 65844.2897 - Avg Loss: 159.8162\n",
            "Epoch [34/50] - Batch loss: 167.4145 - Epoch Loss: 66011.7042 - Avg Loss: 159.8346\n",
            "Epoch [34/50] - Batch loss: 163.9314 - Epoch Loss: 66175.6356 - Avg Loss: 159.8445\n",
            "Epoch [34/50] - Batch loss: 154.2692 - Epoch Loss: 66329.9047 - Avg Loss: 159.8311\n",
            "Epoch [34/50] - Batch loss: 156.8877 - Epoch Loss: 66486.7924 - Avg Loss: 159.8240\n",
            "Epoch [34/50] - Batch loss: 162.6736 - Epoch Loss: 66649.4660 - Avg Loss: 159.8309\n",
            "Epoch [34/50] - Batch loss: 159.8672 - Epoch Loss: 66809.3333 - Avg Loss: 159.8309\n",
            "Epoch [34/50] - Batch loss: 160.0410 - Epoch Loss: 66969.3743 - Avg Loss: 159.8314\n",
            "Epoch [34/50] - Batch loss: 162.5445 - Epoch Loss: 67131.9188 - Avg Loss: 159.8379\n",
            "Epoch [34/50] - Batch loss: 163.9733 - Epoch Loss: 67295.8921 - Avg Loss: 159.8477\n",
            "Epoch [34/50] - Batch loss: 166.8734 - Epoch Loss: 67462.7655 - Avg Loss: 159.8644\n",
            "Epoch [34/50] - Batch loss: 157.1148 - Epoch Loss: 67619.8803 - Avg Loss: 159.8579\n",
            "Epoch [34/50] - Batch loss: 156.0745 - Epoch Loss: 67775.9549 - Avg Loss: 159.8490\n",
            "Epoch [34/50] - Batch loss: 151.1104 - Epoch Loss: 67927.0652 - Avg Loss: 159.8284\n",
            "Epoch [34/50] - Batch loss: 155.6816 - Epoch Loss: 68082.7469 - Avg Loss: 159.8187\n",
            "Epoch [34/50] - Batch loss: 162.0584 - Epoch Loss: 68244.8053 - Avg Loss: 159.8239\n",
            "Epoch [34/50] - Batch loss: 158.6042 - Epoch Loss: 68403.4095 - Avg Loss: 159.8211\n",
            "Epoch [34/50] - Batch loss: 157.5632 - Epoch Loss: 68560.9728 - Avg Loss: 159.8158\n",
            "Epoch [34/50] - Batch loss: 163.8532 - Epoch Loss: 68724.8259 - Avg Loss: 159.8252\n",
            "Epoch [34/50] - Batch loss: 156.7878 - Epoch Loss: 68881.6138 - Avg Loss: 159.8181\n",
            "Epoch [34/50] - Batch loss: 158.0782 - Epoch Loss: 69039.6920 - Avg Loss: 159.8141\n",
            "Epoch [34/50] - Batch loss: 156.0983 - Epoch Loss: 69195.7903 - Avg Loss: 159.8055\n",
            "Epoch [34/50] - Batch loss: 164.4651 - Epoch Loss: 69360.2554 - Avg Loss: 159.8163\n",
            "Epoch [34/50] - Batch loss: 158.7905 - Epoch Loss: 69519.0459 - Avg Loss: 159.8139\n",
            "Epoch [34/50] - Batch loss: 159.1828 - Epoch Loss: 69678.2286 - Avg Loss: 159.8125\n",
            "Epoch [34/50] - Batch loss: 157.8799 - Epoch Loss: 69836.1086 - Avg Loss: 159.8080\n",
            "Epoch [34/50] - Batch loss: 168.7134 - Epoch Loss: 70004.8220 - Avg Loss: 159.8284\n",
            "Epoch [34/50] - Batch loss: 159.4826 - Epoch Loss: 70164.3046 - Avg Loss: 159.8276\n",
            "Epoch [34/50] - Batch loss: 163.5343 - Epoch Loss: 70327.8389 - Avg Loss: 159.8360\n",
            "Epoch [34/50] - Batch loss: 156.7982 - Epoch Loss: 70484.6371 - Avg Loss: 159.8291\n",
            "Epoch [34/50] - Batch loss: 156.9787 - Epoch Loss: 70641.6157 - Avg Loss: 159.8227\n",
            "Epoch [34/50] - Batch loss: 157.1370 - Epoch Loss: 70798.7527 - Avg Loss: 159.8166\n",
            "Epoch [34/50] - Batch loss: 168.3080 - Epoch Loss: 70967.0607 - Avg Loss: 159.8357\n",
            "Epoch [34/50] - Batch loss: 161.5657 - Epoch Loss: 71128.6263 - Avg Loss: 159.8396\n",
            "Epoch [34/50] - Batch loss: 160.9016 - Epoch Loss: 71289.5280 - Avg Loss: 159.8420\n",
            "Epoch [34/50] - Batch loss: 157.3870 - Epoch Loss: 71446.9150 - Avg Loss: 159.8365\n",
            "Epoch [34/50] - Batch loss: 156.4698 - Epoch Loss: 71603.3848 - Avg Loss: 159.8290\n",
            "Epoch [34/50] - Batch loss: 161.3903 - Epoch Loss: 71764.7751 - Avg Loss: 159.8325\n",
            "Epoch [34/50] - Batch loss: 171.3605 - Epoch Loss: 71936.1356 - Avg Loss: 159.8581\n",
            "Epoch [34/50] - Batch loss: 151.5325 - Epoch Loss: 72087.6681 - Avg Loss: 159.8396\n",
            "Epoch [34/50] - Batch loss: 160.1065 - Epoch Loss: 72247.7746 - Avg Loss: 159.8402\n",
            "Epoch [34/50] - Batch loss: 161.3303 - Epoch Loss: 72409.1049 - Avg Loss: 159.8435\n",
            "Epoch [34/50] - Batch loss: 163.5931 - Epoch Loss: 72572.6980 - Avg Loss: 159.8518\n",
            "Epoch [34/50] - Batch loss: 156.5325 - Epoch Loss: 72729.2305 - Avg Loss: 159.8445\n",
            "Epoch [34/50] - Batch loss: 153.2486 - Epoch Loss: 72882.4790 - Avg Loss: 159.8300\n",
            "Epoch [34/50] - Batch loss: 160.9796 - Epoch Loss: 73043.4586 - Avg Loss: 159.8325\n",
            "Epoch [34/50] - Batch loss: 158.3003 - Epoch Loss: 73201.7589 - Avg Loss: 159.8292\n",
            "Epoch [34/50] - Batch loss: 162.8123 - Epoch Loss: 73364.5712 - Avg Loss: 159.8357\n",
            "Epoch [34/50] - Batch loss: 166.5850 - Epoch Loss: 73531.1563 - Avg Loss: 159.8503\n",
            "Epoch [34/50] - Batch loss: 162.4285 - Epoch Loss: 73693.5847 - Avg Loss: 159.8559\n",
            "Epoch [34/50] - Batch loss: 166.5345 - Epoch Loss: 73860.1193 - Avg Loss: 159.8704\n",
            "Epoch [34/50] - Batch loss: 161.5735 - Epoch Loss: 74021.6928 - Avg Loss: 159.8741\n",
            "Epoch [34/50] - Batch loss: 158.3822 - Epoch Loss: 74180.0749 - Avg Loss: 159.8709\n",
            "Epoch [34/50] - Batch loss: 155.2654 - Epoch Loss: 74335.3403 - Avg Loss: 159.8609\n",
            "Epoch [34/50] - Batch loss: 157.0862 - Epoch Loss: 74492.4265 - Avg Loss: 159.8550\n",
            "Epoch [34/50] - Batch loss: 155.1711 - Epoch Loss: 74647.5975 - Avg Loss: 159.8450\n",
            "Epoch [34/50] - Batch loss: 159.7795 - Epoch Loss: 74807.3770 - Avg Loss: 159.8448\n",
            "Epoch [34/50] - Batch loss: 155.8370 - Epoch Loss: 74963.2140 - Avg Loss: 159.8363\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 35/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "559c1f9435c542098c57ae5e6fb80f72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [35/50] - Batch loss: 163.4927 - Epoch Loss: 163.4927 - Avg Loss: 163.4927\n",
            "Epoch [35/50] - Batch loss: 159.8219 - Epoch Loss: 323.3146 - Avg Loss: 161.6573\n",
            "Epoch [35/50] - Batch loss: 173.4366 - Epoch Loss: 496.7512 - Avg Loss: 165.5837\n",
            "Epoch [35/50] - Batch loss: 161.6554 - Epoch Loss: 658.4066 - Avg Loss: 164.6016\n",
            "Epoch [35/50] - Batch loss: 159.3130 - Epoch Loss: 817.7196 - Avg Loss: 163.5439\n",
            "Epoch [35/50] - Batch loss: 153.6222 - Epoch Loss: 971.3417 - Avg Loss: 161.8903\n",
            "Epoch [35/50] - Batch loss: 160.0662 - Epoch Loss: 1131.4080 - Avg Loss: 161.6297\n",
            "Epoch [35/50] - Batch loss: 156.2156 - Epoch Loss: 1287.6236 - Avg Loss: 160.9529\n",
            "Epoch [35/50] - Batch loss: 164.3556 - Epoch Loss: 1451.9792 - Avg Loss: 161.3310\n",
            "Epoch [35/50] - Batch loss: 159.2354 - Epoch Loss: 1611.2146 - Avg Loss: 161.1215\n",
            "Epoch [35/50] - Batch loss: 160.0085 - Epoch Loss: 1771.2231 - Avg Loss: 161.0203\n",
            "Epoch [35/50] - Batch loss: 158.2703 - Epoch Loss: 1929.4934 - Avg Loss: 160.7911\n",
            "Epoch [35/50] - Batch loss: 155.6427 - Epoch Loss: 2085.1360 - Avg Loss: 160.3951\n",
            "Epoch [35/50] - Batch loss: 160.8020 - Epoch Loss: 2245.9380 - Avg Loss: 160.4241\n",
            "Epoch [35/50] - Batch loss: 160.7796 - Epoch Loss: 2406.7176 - Avg Loss: 160.4478\n",
            "Epoch [35/50] - Batch loss: 158.8669 - Epoch Loss: 2565.5845 - Avg Loss: 160.3490\n",
            "Epoch [35/50] - Batch loss: 160.7947 - Epoch Loss: 2726.3792 - Avg Loss: 160.3752\n",
            "Epoch [35/50] - Batch loss: 171.6589 - Epoch Loss: 2898.0381 - Avg Loss: 161.0021\n",
            "Epoch [35/50] - Batch loss: 162.8182 - Epoch Loss: 3060.8563 - Avg Loss: 161.0977\n",
            "Epoch [35/50] - Batch loss: 164.0911 - Epoch Loss: 3224.9474 - Avg Loss: 161.2474\n",
            "Epoch [35/50] - Batch loss: 155.7602 - Epoch Loss: 3380.7077 - Avg Loss: 160.9861\n",
            "Epoch [35/50] - Batch loss: 151.7706 - Epoch Loss: 3532.4782 - Avg Loss: 160.5672\n",
            "Epoch [35/50] - Batch loss: 168.4837 - Epoch Loss: 3700.9619 - Avg Loss: 160.9114\n",
            "Epoch [35/50] - Batch loss: 160.2985 - Epoch Loss: 3861.2604 - Avg Loss: 160.8859\n",
            "Epoch [35/50] - Batch loss: 155.9679 - Epoch Loss: 4017.2283 - Avg Loss: 160.6891\n",
            "Epoch [35/50] - Batch loss: 160.8757 - Epoch Loss: 4178.1040 - Avg Loss: 160.6963\n",
            "Epoch [35/50] - Batch loss: 153.8269 - Epoch Loss: 4331.9310 - Avg Loss: 160.4419\n",
            "Epoch [35/50] - Batch loss: 156.8512 - Epoch Loss: 4488.7821 - Avg Loss: 160.3136\n",
            "Epoch [35/50] - Batch loss: 162.8185 - Epoch Loss: 4651.6007 - Avg Loss: 160.4000\n",
            "Epoch [35/50] - Batch loss: 167.2123 - Epoch Loss: 4818.8129 - Avg Loss: 160.6271\n",
            "Epoch [35/50] - Batch loss: 161.0961 - Epoch Loss: 4979.9090 - Avg Loss: 160.6422\n",
            "Epoch [35/50] - Batch loss: 162.7210 - Epoch Loss: 5142.6300 - Avg Loss: 160.7072\n",
            "Epoch [35/50] - Batch loss: 153.9939 - Epoch Loss: 5296.6239 - Avg Loss: 160.5038\n",
            "Epoch [35/50] - Batch loss: 150.9092 - Epoch Loss: 5447.5331 - Avg Loss: 160.2216\n",
            "Epoch [35/50] - Batch loss: 153.4100 - Epoch Loss: 5600.9431 - Avg Loss: 160.0269\n",
            "Epoch [35/50] - Batch loss: 151.9016 - Epoch Loss: 5752.8447 - Avg Loss: 159.8012\n",
            "Epoch [35/50] - Batch loss: 162.7272 - Epoch Loss: 5915.5719 - Avg Loss: 159.8803\n",
            "Epoch [35/50] - Batch loss: 160.0515 - Epoch Loss: 6075.6233 - Avg Loss: 159.8848\n",
            "Epoch [35/50] - Batch loss: 164.4143 - Epoch Loss: 6240.0376 - Avg Loss: 160.0010\n",
            "Epoch [35/50] - Batch loss: 160.0637 - Epoch Loss: 6400.1013 - Avg Loss: 160.0025\n",
            "Epoch [35/50] - Batch loss: 160.7415 - Epoch Loss: 6560.8427 - Avg Loss: 160.0206\n",
            "Epoch [35/50] - Batch loss: 153.5413 - Epoch Loss: 6714.3840 - Avg Loss: 159.8663\n",
            "Epoch [35/50] - Batch loss: 158.3330 - Epoch Loss: 6872.7169 - Avg Loss: 159.8306\n",
            "Epoch [35/50] - Batch loss: 161.6875 - Epoch Loss: 7034.4044 - Avg Loss: 159.8728\n",
            "Epoch [35/50] - Batch loss: 159.4240 - Epoch Loss: 7193.8284 - Avg Loss: 159.8629\n",
            "Epoch [35/50] - Batch loss: 156.7315 - Epoch Loss: 7350.5599 - Avg Loss: 159.7948\n",
            "Epoch [35/50] - Batch loss: 161.6107 - Epoch Loss: 7512.1706 - Avg Loss: 159.8334\n",
            "Epoch [35/50] - Batch loss: 149.4107 - Epoch Loss: 7661.5813 - Avg Loss: 159.6163\n",
            "Epoch [35/50] - Batch loss: 155.9582 - Epoch Loss: 7817.5395 - Avg Loss: 159.5416\n",
            "Epoch [35/50] - Batch loss: 154.2614 - Epoch Loss: 7971.8009 - Avg Loss: 159.4360\n",
            "Epoch [35/50] - Batch loss: 161.9777 - Epoch Loss: 8133.7786 - Avg Loss: 159.4859\n",
            "Epoch [35/50] - Batch loss: 163.0948 - Epoch Loss: 8296.8733 - Avg Loss: 159.5553\n",
            "Epoch [35/50] - Batch loss: 154.6983 - Epoch Loss: 8451.5716 - Avg Loss: 159.4636\n",
            "Epoch [35/50] - Batch loss: 161.5539 - Epoch Loss: 8613.1255 - Avg Loss: 159.5023\n",
            "Epoch [35/50] - Batch loss: 158.1897 - Epoch Loss: 8771.3151 - Avg Loss: 159.4785\n",
            "Epoch [35/50] - Batch loss: 167.1779 - Epoch Loss: 8938.4930 - Avg Loss: 159.6159\n",
            "Epoch [35/50] - Batch loss: 161.1493 - Epoch Loss: 9099.6422 - Avg Loss: 159.6428\n",
            "Epoch [35/50] - Batch loss: 157.0998 - Epoch Loss: 9256.7421 - Avg Loss: 159.5990\n",
            "Epoch [35/50] - Batch loss: 162.5917 - Epoch Loss: 9419.3337 - Avg Loss: 159.6497\n",
            "Epoch [35/50] - Batch loss: 155.3629 - Epoch Loss: 9574.6966 - Avg Loss: 159.5783\n",
            "Epoch [35/50] - Batch loss: 159.9679 - Epoch Loss: 9734.6646 - Avg Loss: 159.5847\n",
            "Epoch [35/50] - Batch loss: 165.8119 - Epoch Loss: 9900.4764 - Avg Loss: 159.6851\n",
            "Epoch [35/50] - Batch loss: 156.5553 - Epoch Loss: 10057.0317 - Avg Loss: 159.6354\n",
            "Epoch [35/50] - Batch loss: 158.8738 - Epoch Loss: 10215.9056 - Avg Loss: 159.6235\n",
            "Epoch [35/50] - Batch loss: 152.0147 - Epoch Loss: 10367.9203 - Avg Loss: 159.5065\n",
            "Epoch [35/50] - Batch loss: 163.7407 - Epoch Loss: 10531.6610 - Avg Loss: 159.5706\n",
            "Epoch [35/50] - Batch loss: 157.6745 - Epoch Loss: 10689.3356 - Avg Loss: 159.5423\n",
            "Epoch [35/50] - Batch loss: 163.1751 - Epoch Loss: 10852.5107 - Avg Loss: 159.5957\n",
            "Epoch [35/50] - Batch loss: 156.5887 - Epoch Loss: 11009.0994 - Avg Loss: 159.5522\n",
            "Epoch [35/50] - Batch loss: 162.0445 - Epoch Loss: 11171.1439 - Avg Loss: 159.5878\n",
            "Epoch [35/50] - Batch loss: 163.6391 - Epoch Loss: 11334.7829 - Avg Loss: 159.6448\n",
            "Epoch [35/50] - Batch loss: 163.3920 - Epoch Loss: 11498.1749 - Avg Loss: 159.6969\n",
            "Epoch [35/50] - Batch loss: 160.6256 - Epoch Loss: 11658.8005 - Avg Loss: 159.7096\n",
            "Epoch [35/50] - Batch loss: 155.8864 - Epoch Loss: 11814.6869 - Avg Loss: 159.6579\n",
            "Epoch [35/50] - Batch loss: 158.8501 - Epoch Loss: 11973.5370 - Avg Loss: 159.6472\n",
            "Epoch [35/50] - Batch loss: 157.6860 - Epoch Loss: 12131.2230 - Avg Loss: 159.6214\n",
            "Epoch [35/50] - Batch loss: 163.8083 - Epoch Loss: 12295.0313 - Avg Loss: 159.6757\n",
            "Epoch [35/50] - Batch loss: 161.5331 - Epoch Loss: 12456.5644 - Avg Loss: 159.6995\n",
            "Epoch [35/50] - Batch loss: 161.5269 - Epoch Loss: 12618.0913 - Avg Loss: 159.7227\n",
            "Epoch [35/50] - Batch loss: 162.9301 - Epoch Loss: 12781.0214 - Avg Loss: 159.7628\n",
            "Epoch [35/50] - Batch loss: 155.9934 - Epoch Loss: 12937.0149 - Avg Loss: 159.7162\n",
            "Epoch [35/50] - Batch loss: 149.2963 - Epoch Loss: 13086.3112 - Avg Loss: 159.5892\n",
            "Epoch [35/50] - Batch loss: 162.8557 - Epoch Loss: 13249.1669 - Avg Loss: 159.6285\n",
            "Epoch [35/50] - Batch loss: 156.7806 - Epoch Loss: 13405.9475 - Avg Loss: 159.5946\n",
            "Epoch [35/50] - Batch loss: 160.4168 - Epoch Loss: 13566.3643 - Avg Loss: 159.6043\n",
            "Epoch [35/50] - Batch loss: 153.4784 - Epoch Loss: 13719.8427 - Avg Loss: 159.5331\n",
            "Epoch [35/50] - Batch loss: 155.5770 - Epoch Loss: 13875.4197 - Avg Loss: 159.4876\n",
            "Epoch [35/50] - Batch loss: 150.9975 - Epoch Loss: 14026.4173 - Avg Loss: 159.3911\n",
            "Epoch [35/50] - Batch loss: 155.2423 - Epoch Loss: 14181.6596 - Avg Loss: 159.3445\n",
            "Epoch [35/50] - Batch loss: 161.3522 - Epoch Loss: 14343.0118 - Avg Loss: 159.3668\n",
            "Epoch [35/50] - Batch loss: 148.0991 - Epoch Loss: 14491.1109 - Avg Loss: 159.2430\n",
            "Epoch [35/50] - Batch loss: 160.8616 - Epoch Loss: 14651.9725 - Avg Loss: 159.2606\n",
            "Epoch [35/50] - Batch loss: 162.6660 - Epoch Loss: 14814.6385 - Avg Loss: 159.2972\n",
            "Epoch [35/50] - Batch loss: 159.0471 - Epoch Loss: 14973.6855 - Avg Loss: 159.2945\n",
            "Epoch [35/50] - Batch loss: 153.4836 - Epoch Loss: 15127.1691 - Avg Loss: 159.2334\n",
            "Epoch [35/50] - Batch loss: 152.8362 - Epoch Loss: 15280.0053 - Avg Loss: 159.1667\n",
            "Epoch [35/50] - Batch loss: 157.4821 - Epoch Loss: 15437.4874 - Avg Loss: 159.1494\n",
            "Epoch [35/50] - Batch loss: 156.7518 - Epoch Loss: 15594.2392 - Avg Loss: 159.1249\n",
            "Epoch [35/50] - Batch loss: 155.1036 - Epoch Loss: 15749.3428 - Avg Loss: 159.0843\n",
            "Epoch [35/50] - Batch loss: 164.3654 - Epoch Loss: 15913.7082 - Avg Loss: 159.1371\n",
            "Epoch [35/50] - Batch loss: 167.1348 - Epoch Loss: 16080.8429 - Avg Loss: 159.2163\n",
            "Epoch [35/50] - Batch loss: 161.0059 - Epoch Loss: 16241.8488 - Avg Loss: 159.2338\n",
            "Epoch [35/50] - Batch loss: 171.4217 - Epoch Loss: 16413.2706 - Avg Loss: 159.3521\n",
            "Epoch [35/50] - Batch loss: 157.4522 - Epoch Loss: 16570.7228 - Avg Loss: 159.3339\n",
            "Epoch [35/50] - Batch loss: 162.0482 - Epoch Loss: 16732.7710 - Avg Loss: 159.3597\n",
            "Epoch [35/50] - Batch loss: 162.4046 - Epoch Loss: 16895.1757 - Avg Loss: 159.3884\n",
            "Epoch [35/50] - Batch loss: 172.1410 - Epoch Loss: 17067.3167 - Avg Loss: 159.5076\n",
            "Epoch [35/50] - Batch loss: 157.3944 - Epoch Loss: 17224.7111 - Avg Loss: 159.4881\n",
            "Epoch [35/50] - Batch loss: 169.9074 - Epoch Loss: 17394.6185 - Avg Loss: 159.5837\n",
            "Epoch [35/50] - Batch loss: 167.6688 - Epoch Loss: 17562.2873 - Avg Loss: 159.6572\n",
            "Epoch [35/50] - Batch loss: 157.5240 - Epoch Loss: 17719.8113 - Avg Loss: 159.6379\n",
            "Epoch [35/50] - Batch loss: 162.1815 - Epoch Loss: 17881.9927 - Avg Loss: 159.6606\n",
            "Epoch [35/50] - Batch loss: 164.3672 - Epoch Loss: 18046.3599 - Avg Loss: 159.7023\n",
            "Epoch [35/50] - Batch loss: 154.0783 - Epoch Loss: 18200.4382 - Avg Loss: 159.6530\n",
            "Epoch [35/50] - Batch loss: 160.8362 - Epoch Loss: 18361.2744 - Avg Loss: 159.6633\n",
            "Epoch [35/50] - Batch loss: 160.5191 - Epoch Loss: 18521.7935 - Avg Loss: 159.6706\n",
            "Epoch [35/50] - Batch loss: 157.4805 - Epoch Loss: 18679.2740 - Avg Loss: 159.6519\n",
            "Epoch [35/50] - Batch loss: 156.7773 - Epoch Loss: 18836.0513 - Avg Loss: 159.6276\n",
            "Epoch [35/50] - Batch loss: 158.4818 - Epoch Loss: 18994.5331 - Avg Loss: 159.6179\n",
            "Epoch [35/50] - Batch loss: 156.4815 - Epoch Loss: 19151.0146 - Avg Loss: 159.5918\n",
            "Epoch [35/50] - Batch loss: 167.7240 - Epoch Loss: 19318.7385 - Avg Loss: 159.6590\n",
            "Epoch [35/50] - Batch loss: 159.5909 - Epoch Loss: 19478.3295 - Avg Loss: 159.6584\n",
            "Epoch [35/50] - Batch loss: 161.2079 - Epoch Loss: 19639.5374 - Avg Loss: 159.6710\n",
            "Epoch [35/50] - Batch loss: 157.1988 - Epoch Loss: 19796.7361 - Avg Loss: 159.6511\n",
            "Epoch [35/50] - Batch loss: 158.2729 - Epoch Loss: 19955.0090 - Avg Loss: 159.6401\n",
            "Epoch [35/50] - Batch loss: 162.5751 - Epoch Loss: 20117.5842 - Avg Loss: 159.6634\n",
            "Epoch [35/50] - Batch loss: 157.1924 - Epoch Loss: 20274.7766 - Avg Loss: 159.6439\n",
            "Epoch [35/50] - Batch loss: 160.5478 - Epoch Loss: 20435.3244 - Avg Loss: 159.6510\n",
            "Epoch [35/50] - Batch loss: 161.4958 - Epoch Loss: 20596.8202 - Avg Loss: 159.6653\n",
            "Epoch [35/50] - Batch loss: 158.5566 - Epoch Loss: 20755.3768 - Avg Loss: 159.6567\n",
            "Epoch [35/50] - Batch loss: 159.3018 - Epoch Loss: 20914.6787 - Avg Loss: 159.6540\n",
            "Epoch [35/50] - Batch loss: 158.3634 - Epoch Loss: 21073.0421 - Avg Loss: 159.6443\n",
            "Epoch [35/50] - Batch loss: 161.5886 - Epoch Loss: 21234.6306 - Avg Loss: 159.6589\n",
            "Epoch [35/50] - Batch loss: 161.8748 - Epoch Loss: 21396.5054 - Avg Loss: 159.6754\n",
            "Epoch [35/50] - Batch loss: 153.7366 - Epoch Loss: 21550.2421 - Avg Loss: 159.6314\n",
            "Epoch [35/50] - Batch loss: 158.5527 - Epoch Loss: 21708.7948 - Avg Loss: 159.6235\n",
            "Epoch [35/50] - Batch loss: 160.9505 - Epoch Loss: 21869.7453 - Avg Loss: 159.6332\n",
            "Epoch [35/50] - Batch loss: 163.0185 - Epoch Loss: 22032.7637 - Avg Loss: 159.6577\n",
            "Epoch [35/50] - Batch loss: 158.7439 - Epoch Loss: 22191.5076 - Avg Loss: 159.6511\n",
            "Epoch [35/50] - Batch loss: 164.1369 - Epoch Loss: 22355.6445 - Avg Loss: 159.6832\n",
            "Epoch [35/50] - Batch loss: 159.6700 - Epoch Loss: 22515.3145 - Avg Loss: 159.6831\n",
            "Epoch [35/50] - Batch loss: 166.3440 - Epoch Loss: 22681.6586 - Avg Loss: 159.7300\n",
            "Epoch [35/50] - Batch loss: 160.6073 - Epoch Loss: 22842.2658 - Avg Loss: 159.7361\n",
            "Epoch [35/50] - Batch loss: 171.2523 - Epoch Loss: 23013.5181 - Avg Loss: 159.8161\n",
            "Epoch [35/50] - Batch loss: 163.4650 - Epoch Loss: 23176.9830 - Avg Loss: 159.8413\n",
            "Epoch [35/50] - Batch loss: 157.3907 - Epoch Loss: 23334.3738 - Avg Loss: 159.8245\n",
            "Epoch [35/50] - Batch loss: 166.2472 - Epoch Loss: 23500.6210 - Avg Loss: 159.8682\n",
            "Epoch [35/50] - Batch loss: 169.8680 - Epoch Loss: 23670.4890 - Avg Loss: 159.9357\n",
            "Epoch [35/50] - Batch loss: 163.9974 - Epoch Loss: 23834.4864 - Avg Loss: 159.9630\n",
            "Epoch [35/50] - Batch loss: 165.7320 - Epoch Loss: 24000.2184 - Avg Loss: 160.0015\n",
            "Epoch [35/50] - Batch loss: 164.5976 - Epoch Loss: 24164.8159 - Avg Loss: 160.0319\n",
            "Epoch [35/50] - Batch loss: 157.0829 - Epoch Loss: 24321.8988 - Avg Loss: 160.0125\n",
            "Epoch [35/50] - Batch loss: 153.2301 - Epoch Loss: 24475.1289 - Avg Loss: 159.9682\n",
            "Epoch [35/50] - Batch loss: 159.5266 - Epoch Loss: 24634.6555 - Avg Loss: 159.9653\n",
            "Epoch [35/50] - Batch loss: 158.4427 - Epoch Loss: 24793.0982 - Avg Loss: 159.9555\n",
            "Epoch [35/50] - Batch loss: 159.9007 - Epoch Loss: 24952.9989 - Avg Loss: 159.9551\n",
            "Epoch [35/50] - Batch loss: 156.9669 - Epoch Loss: 25109.9657 - Avg Loss: 159.9361\n",
            "Epoch [35/50] - Batch loss: 157.4834 - Epoch Loss: 25267.4492 - Avg Loss: 159.9206\n",
            "Epoch [35/50] - Batch loss: 158.2220 - Epoch Loss: 25425.6712 - Avg Loss: 159.9099\n",
            "Epoch [35/50] - Batch loss: 152.9262 - Epoch Loss: 25578.5974 - Avg Loss: 159.8662\n",
            "Epoch [35/50] - Batch loss: 157.5722 - Epoch Loss: 25736.1696 - Avg Loss: 159.8520\n",
            "Epoch [35/50] - Batch loss: 158.6534 - Epoch Loss: 25894.8230 - Avg Loss: 159.8446\n",
            "Epoch [35/50] - Batch loss: 162.1095 - Epoch Loss: 26056.9325 - Avg Loss: 159.8585\n",
            "Epoch [35/50] - Batch loss: 161.4719 - Epoch Loss: 26218.4043 - Avg Loss: 159.8683\n",
            "Epoch [35/50] - Batch loss: 160.0108 - Epoch Loss: 26378.4152 - Avg Loss: 159.8692\n",
            "Epoch [35/50] - Batch loss: 154.9992 - Epoch Loss: 26533.4144 - Avg Loss: 159.8398\n",
            "Epoch [35/50] - Batch loss: 152.1007 - Epoch Loss: 26685.5150 - Avg Loss: 159.7935\n",
            "Epoch [35/50] - Batch loss: 157.9778 - Epoch Loss: 26843.4928 - Avg Loss: 159.7827\n",
            "Epoch [35/50] - Batch loss: 156.0187 - Epoch Loss: 26999.5115 - Avg Loss: 159.7604\n",
            "Epoch [35/50] - Batch loss: 152.1671 - Epoch Loss: 27151.6785 - Avg Loss: 159.7158\n",
            "Epoch [35/50] - Batch loss: 155.7196 - Epoch Loss: 27307.3981 - Avg Loss: 159.6924\n",
            "Epoch [35/50] - Batch loss: 162.2703 - Epoch Loss: 27469.6684 - Avg Loss: 159.7074\n",
            "Epoch [35/50] - Batch loss: 162.3155 - Epoch Loss: 27631.9839 - Avg Loss: 159.7225\n",
            "Epoch [35/50] - Batch loss: 157.9554 - Epoch Loss: 27789.9393 - Avg Loss: 159.7123\n",
            "Epoch [35/50] - Batch loss: 161.9601 - Epoch Loss: 27951.8994 - Avg Loss: 159.7251\n",
            "Epoch [35/50] - Batch loss: 158.6072 - Epoch Loss: 28110.5066 - Avg Loss: 159.7188\n",
            "Epoch [35/50] - Batch loss: 167.4380 - Epoch Loss: 28277.9445 - Avg Loss: 159.7624\n",
            "Epoch [35/50] - Batch loss: 156.9720 - Epoch Loss: 28434.9166 - Avg Loss: 159.7467\n",
            "Epoch [35/50] - Batch loss: 160.9314 - Epoch Loss: 28595.8480 - Avg Loss: 159.7533\n",
            "Epoch [35/50] - Batch loss: 161.0090 - Epoch Loss: 28756.8570 - Avg Loss: 159.7603\n",
            "Epoch [35/50] - Batch loss: 159.7324 - Epoch Loss: 28916.5894 - Avg Loss: 159.7602\n",
            "Epoch [35/50] - Batch loss: 159.4441 - Epoch Loss: 29076.0335 - Avg Loss: 159.7584\n",
            "Epoch [35/50] - Batch loss: 155.5185 - Epoch Loss: 29231.5520 - Avg Loss: 159.7353\n",
            "Epoch [35/50] - Batch loss: 165.6873 - Epoch Loss: 29397.2393 - Avg Loss: 159.7676\n",
            "Epoch [35/50] - Batch loss: 154.8421 - Epoch Loss: 29552.0814 - Avg Loss: 159.7410\n",
            "Epoch [35/50] - Batch loss: 156.7307 - Epoch Loss: 29708.8122 - Avg Loss: 159.7248\n",
            "Epoch [35/50] - Batch loss: 162.0722 - Epoch Loss: 29870.8843 - Avg Loss: 159.7373\n",
            "Epoch [35/50] - Batch loss: 154.7228 - Epoch Loss: 30025.6071 - Avg Loss: 159.7107\n",
            "Epoch [35/50] - Batch loss: 161.2442 - Epoch Loss: 30186.8513 - Avg Loss: 159.7188\n",
            "Epoch [35/50] - Batch loss: 153.8066 - Epoch Loss: 30340.6580 - Avg Loss: 159.6877\n",
            "Epoch [35/50] - Batch loss: 169.6126 - Epoch Loss: 30510.2705 - Avg Loss: 159.7396\n",
            "Epoch [35/50] - Batch loss: 161.8833 - Epoch Loss: 30672.1538 - Avg Loss: 159.7508\n",
            "Epoch [35/50] - Batch loss: 152.8589 - Epoch Loss: 30825.0127 - Avg Loss: 159.7151\n",
            "Epoch [35/50] - Batch loss: 158.8640 - Epoch Loss: 30983.8767 - Avg Loss: 159.7107\n",
            "Epoch [35/50] - Batch loss: 163.1730 - Epoch Loss: 31147.0497 - Avg Loss: 159.7285\n",
            "Epoch [35/50] - Batch loss: 155.3810 - Epoch Loss: 31302.4307 - Avg Loss: 159.7063\n",
            "Epoch [35/50] - Batch loss: 156.9033 - Epoch Loss: 31459.3340 - Avg Loss: 159.6921\n",
            "Epoch [35/50] - Batch loss: 160.3271 - Epoch Loss: 31619.6611 - Avg Loss: 159.6953\n",
            "Epoch [35/50] - Batch loss: 165.6587 - Epoch Loss: 31785.3198 - Avg Loss: 159.7252\n",
            "Epoch [35/50] - Batch loss: 164.6010 - Epoch Loss: 31949.9209 - Avg Loss: 159.7496\n",
            "Epoch [35/50] - Batch loss: 163.7051 - Epoch Loss: 32113.6260 - Avg Loss: 159.7693\n",
            "Epoch [35/50] - Batch loss: 162.2786 - Epoch Loss: 32275.9046 - Avg Loss: 159.7817\n",
            "Epoch [35/50] - Batch loss: 158.4421 - Epoch Loss: 32434.3466 - Avg Loss: 159.7751\n",
            "Epoch [35/50] - Batch loss: 165.4618 - Epoch Loss: 32599.8085 - Avg Loss: 159.8030\n",
            "Epoch [35/50] - Batch loss: 157.0482 - Epoch Loss: 32756.8567 - Avg Loss: 159.7895\n",
            "Epoch [35/50] - Batch loss: 165.0619 - Epoch Loss: 32921.9187 - Avg Loss: 159.8151\n",
            "Epoch [35/50] - Batch loss: 163.5067 - Epoch Loss: 33085.4254 - Avg Loss: 159.8330\n",
            "Epoch [35/50] - Batch loss: 162.2004 - Epoch Loss: 33247.6258 - Avg Loss: 159.8444\n",
            "Epoch [35/50] - Batch loss: 163.0281 - Epoch Loss: 33410.6539 - Avg Loss: 159.8596\n",
            "Epoch [35/50] - Batch loss: 157.8259 - Epoch Loss: 33568.4798 - Avg Loss: 159.8499\n",
            "Epoch [35/50] - Batch loss: 152.1359 - Epoch Loss: 33720.6158 - Avg Loss: 159.8133\n",
            "Epoch [35/50] - Batch loss: 161.0340 - Epoch Loss: 33881.6498 - Avg Loss: 159.8191\n",
            "Epoch [35/50] - Batch loss: 155.2453 - Epoch Loss: 34036.8951 - Avg Loss: 159.7976\n",
            "Epoch [35/50] - Batch loss: 157.9310 - Epoch Loss: 34194.8260 - Avg Loss: 159.7889\n",
            "Epoch [35/50] - Batch loss: 160.1592 - Epoch Loss: 34354.9852 - Avg Loss: 159.7906\n",
            "Epoch [35/50] - Batch loss: 168.5917 - Epoch Loss: 34523.5770 - Avg Loss: 159.8314\n",
            "Epoch [35/50] - Batch loss: 161.6445 - Epoch Loss: 34685.2215 - Avg Loss: 159.8397\n",
            "Epoch [35/50] - Batch loss: 156.3493 - Epoch Loss: 34841.5708 - Avg Loss: 159.8237\n",
            "Epoch [35/50] - Batch loss: 159.4496 - Epoch Loss: 35001.0204 - Avg Loss: 159.8220\n",
            "Epoch [35/50] - Batch loss: 158.2303 - Epoch Loss: 35159.2508 - Avg Loss: 159.8148\n",
            "Epoch [35/50] - Batch loss: 160.6338 - Epoch Loss: 35319.8846 - Avg Loss: 159.8185\n",
            "Epoch [35/50] - Batch loss: 152.4771 - Epoch Loss: 35472.3617 - Avg Loss: 159.7854\n",
            "Epoch [35/50] - Batch loss: 163.7481 - Epoch Loss: 35636.1098 - Avg Loss: 159.8032\n",
            "Epoch [35/50] - Batch loss: 161.2338 - Epoch Loss: 35797.3436 - Avg Loss: 159.8096\n",
            "Epoch [35/50] - Batch loss: 163.1132 - Epoch Loss: 35960.4568 - Avg Loss: 159.8243\n",
            "Epoch [35/50] - Batch loss: 159.8316 - Epoch Loss: 36120.2884 - Avg Loss: 159.8243\n",
            "Epoch [35/50] - Batch loss: 162.8555 - Epoch Loss: 36283.1439 - Avg Loss: 159.8376\n",
            "Epoch [35/50] - Batch loss: 169.3484 - Epoch Loss: 36452.4923 - Avg Loss: 159.8794\n",
            "Epoch [35/50] - Batch loss: 150.9984 - Epoch Loss: 36603.4907 - Avg Loss: 159.8406\n",
            "Epoch [35/50] - Batch loss: 162.2745 - Epoch Loss: 36765.7652 - Avg Loss: 159.8512\n",
            "Epoch [35/50] - Batch loss: 165.7111 - Epoch Loss: 36931.4763 - Avg Loss: 159.8765\n",
            "Epoch [35/50] - Batch loss: 158.5867 - Epoch Loss: 37090.0630 - Avg Loss: 159.8710\n",
            "Epoch [35/50] - Batch loss: 164.6888 - Epoch Loss: 37254.7518 - Avg Loss: 159.8916\n",
            "Epoch [35/50] - Batch loss: 165.1158 - Epoch Loss: 37419.8676 - Avg Loss: 159.9140\n",
            "Epoch [35/50] - Batch loss: 162.3194 - Epoch Loss: 37582.1870 - Avg Loss: 159.9242\n",
            "Epoch [35/50] - Batch loss: 155.0404 - Epoch Loss: 37737.2274 - Avg Loss: 159.9035\n",
            "Epoch [35/50] - Batch loss: 154.2813 - Epoch Loss: 37891.5087 - Avg Loss: 159.8798\n",
            "Epoch [35/50] - Batch loss: 156.7351 - Epoch Loss: 38048.2438 - Avg Loss: 159.8666\n",
            "Epoch [35/50] - Batch loss: 161.5482 - Epoch Loss: 38209.7921 - Avg Loss: 159.8736\n",
            "Epoch [35/50] - Batch loss: 157.6598 - Epoch Loss: 38367.4518 - Avg Loss: 159.8644\n",
            "Epoch [35/50] - Batch loss: 165.1596 - Epoch Loss: 38532.6115 - Avg Loss: 159.8864\n",
            "Epoch [35/50] - Batch loss: 159.7218 - Epoch Loss: 38692.3333 - Avg Loss: 159.8857\n",
            "Epoch [35/50] - Batch loss: 156.6915 - Epoch Loss: 38849.0247 - Avg Loss: 159.8725\n",
            "Epoch [35/50] - Batch loss: 150.5099 - Epoch Loss: 38999.5347 - Avg Loss: 159.8342\n",
            "Epoch [35/50] - Batch loss: 168.9885 - Epoch Loss: 39168.5231 - Avg Loss: 159.8715\n",
            "Epoch [35/50] - Batch loss: 158.7396 - Epoch Loss: 39327.2628 - Avg Loss: 159.8669\n",
            "Epoch [35/50] - Batch loss: 162.0272 - Epoch Loss: 39489.2900 - Avg Loss: 159.8757\n",
            "Epoch [35/50] - Batch loss: 154.4387 - Epoch Loss: 39643.7287 - Avg Loss: 159.8537\n",
            "Epoch [35/50] - Batch loss: 160.8498 - Epoch Loss: 39804.5786 - Avg Loss: 159.8577\n",
            "Epoch [35/50] - Batch loss: 156.8465 - Epoch Loss: 39961.4251 - Avg Loss: 159.8457\n",
            "Epoch [35/50] - Batch loss: 165.1740 - Epoch Loss: 40126.5990 - Avg Loss: 159.8669\n",
            "Epoch [35/50] - Batch loss: 163.8429 - Epoch Loss: 40290.4420 - Avg Loss: 159.8827\n",
            "Epoch [35/50] - Batch loss: 164.7672 - Epoch Loss: 40455.2092 - Avg Loss: 159.9020\n",
            "Epoch [35/50] - Batch loss: 152.1267 - Epoch Loss: 40607.3359 - Avg Loss: 159.8714\n",
            "Epoch [35/50] - Batch loss: 153.9548 - Epoch Loss: 40761.2907 - Avg Loss: 159.8482\n",
            "Epoch [35/50] - Batch loss: 160.6077 - Epoch Loss: 40921.8984 - Avg Loss: 159.8512\n",
            "Epoch [35/50] - Batch loss: 161.2358 - Epoch Loss: 41083.1342 - Avg Loss: 159.8566\n",
            "Epoch [35/50] - Batch loss: 168.6726 - Epoch Loss: 41251.8068 - Avg Loss: 159.8907\n",
            "Epoch [35/50] - Batch loss: 160.3627 - Epoch Loss: 41412.1695 - Avg Loss: 159.8925\n",
            "Epoch [35/50] - Batch loss: 166.3815 - Epoch Loss: 41578.5511 - Avg Loss: 159.9175\n",
            "Epoch [35/50] - Batch loss: 163.8993 - Epoch Loss: 41742.4503 - Avg Loss: 159.9328\n",
            "Epoch [35/50] - Batch loss: 163.6609 - Epoch Loss: 41906.1112 - Avg Loss: 159.9470\n",
            "Epoch [35/50] - Batch loss: 161.5674 - Epoch Loss: 42067.6786 - Avg Loss: 159.9532\n",
            "Epoch [35/50] - Batch loss: 152.3793 - Epoch Loss: 42220.0580 - Avg Loss: 159.9245\n",
            "Epoch [35/50] - Batch loss: 160.5357 - Epoch Loss: 42380.5937 - Avg Loss: 159.9268\n",
            "Epoch [35/50] - Batch loss: 154.5688 - Epoch Loss: 42535.1624 - Avg Loss: 159.9066\n",
            "Epoch [35/50] - Batch loss: 168.1164 - Epoch Loss: 42703.2788 - Avg Loss: 159.9374\n",
            "Epoch [35/50] - Batch loss: 158.4389 - Epoch Loss: 42861.7178 - Avg Loss: 159.9318\n",
            "Epoch [35/50] - Batch loss: 160.8978 - Epoch Loss: 43022.6156 - Avg Loss: 159.9354\n",
            "Epoch [35/50] - Batch loss: 166.5724 - Epoch Loss: 43189.1880 - Avg Loss: 159.9600\n",
            "Epoch [35/50] - Batch loss: 159.8206 - Epoch Loss: 43349.0086 - Avg Loss: 159.9594\n",
            "Epoch [35/50] - Batch loss: 167.1362 - Epoch Loss: 43516.1449 - Avg Loss: 159.9858\n",
            "Epoch [35/50] - Batch loss: 158.5688 - Epoch Loss: 43674.7137 - Avg Loss: 159.9806\n",
            "Epoch [35/50] - Batch loss: 163.1378 - Epoch Loss: 43837.8514 - Avg Loss: 159.9922\n",
            "Epoch [35/50] - Batch loss: 159.8505 - Epoch Loss: 43997.7020 - Avg Loss: 159.9916\n",
            "Epoch [35/50] - Batch loss: 149.7043 - Epoch Loss: 44147.4063 - Avg Loss: 159.9544\n",
            "Epoch [35/50] - Batch loss: 156.8910 - Epoch Loss: 44304.2973 - Avg Loss: 159.9433\n",
            "Epoch [35/50] - Batch loss: 161.1263 - Epoch Loss: 44465.4236 - Avg Loss: 159.9476\n",
            "Epoch [35/50] - Batch loss: 161.8615 - Epoch Loss: 44627.2851 - Avg Loss: 159.9544\n",
            "Epoch [35/50] - Batch loss: 158.0840 - Epoch Loss: 44785.3691 - Avg Loss: 159.9477\n",
            "Epoch [35/50] - Batch loss: 157.1398 - Epoch Loss: 44942.5090 - Avg Loss: 159.9378\n",
            "Epoch [35/50] - Batch loss: 159.2112 - Epoch Loss: 45101.7202 - Avg Loss: 159.9352\n",
            "Epoch [35/50] - Batch loss: 152.1633 - Epoch Loss: 45253.8835 - Avg Loss: 159.9077\n",
            "Epoch [35/50] - Batch loss: 169.4633 - Epoch Loss: 45423.3468 - Avg Loss: 159.9414\n",
            "Epoch [35/50] - Batch loss: 163.6693 - Epoch Loss: 45587.0161 - Avg Loss: 159.9544\n",
            "Epoch [35/50] - Batch loss: 160.9377 - Epoch Loss: 45747.9538 - Avg Loss: 159.9579\n",
            "Epoch [35/50] - Batch loss: 154.0999 - Epoch Loss: 45902.0537 - Avg Loss: 159.9375\n",
            "Epoch [35/50] - Batch loss: 158.8616 - Epoch Loss: 46060.9153 - Avg Loss: 159.9337\n",
            "Epoch [35/50] - Batch loss: 153.8009 - Epoch Loss: 46214.7161 - Avg Loss: 159.9125\n",
            "Epoch [35/50] - Batch loss: 160.7732 - Epoch Loss: 46375.4893 - Avg Loss: 159.9155\n",
            "Epoch [35/50] - Batch loss: 160.0130 - Epoch Loss: 46535.5023 - Avg Loss: 159.9158\n",
            "Epoch [35/50] - Batch loss: 159.3449 - Epoch Loss: 46694.8472 - Avg Loss: 159.9139\n",
            "Epoch [35/50] - Batch loss: 165.3539 - Epoch Loss: 46860.2012 - Avg Loss: 159.9324\n",
            "Epoch [35/50] - Batch loss: 156.4403 - Epoch Loss: 47016.6415 - Avg Loss: 159.9205\n",
            "Epoch [35/50] - Batch loss: 163.2850 - Epoch Loss: 47179.9265 - Avg Loss: 159.9320\n",
            "Epoch [35/50] - Batch loss: 156.1590 - Epoch Loss: 47336.0855 - Avg Loss: 159.9192\n",
            "Epoch [35/50] - Batch loss: 161.5662 - Epoch Loss: 47497.6516 - Avg Loss: 159.9248\n",
            "Epoch [35/50] - Batch loss: 158.9052 - Epoch Loss: 47656.5568 - Avg Loss: 159.9213\n",
            "Epoch [35/50] - Batch loss: 159.9918 - Epoch Loss: 47816.5486 - Avg Loss: 159.9216\n",
            "Epoch [35/50] - Batch loss: 156.0615 - Epoch Loss: 47972.6101 - Avg Loss: 159.9087\n",
            "Epoch [35/50] - Batch loss: 155.1649 - Epoch Loss: 48127.7750 - Avg Loss: 159.8929\n",
            "Epoch [35/50] - Batch loss: 164.9149 - Epoch Loss: 48292.6899 - Avg Loss: 159.9096\n",
            "Epoch [35/50] - Batch loss: 157.6231 - Epoch Loss: 48450.3130 - Avg Loss: 159.9020\n",
            "Epoch [35/50] - Batch loss: 155.3837 - Epoch Loss: 48605.6967 - Avg Loss: 159.8872\n",
            "Epoch [35/50] - Batch loss: 159.6658 - Epoch Loss: 48765.3625 - Avg Loss: 159.8864\n",
            "Epoch [35/50] - Batch loss: 158.8750 - Epoch Loss: 48924.2375 - Avg Loss: 159.8831\n",
            "Epoch [35/50] - Batch loss: 153.3633 - Epoch Loss: 49077.6007 - Avg Loss: 159.8619\n",
            "Epoch [35/50] - Batch loss: 165.1553 - Epoch Loss: 49242.7560 - Avg Loss: 159.8791\n",
            "Epoch [35/50] - Batch loss: 163.3431 - Epoch Loss: 49406.0991 - Avg Loss: 159.8903\n",
            "Epoch [35/50] - Batch loss: 153.9246 - Epoch Loss: 49560.0237 - Avg Loss: 159.8710\n",
            "Epoch [35/50] - Batch loss: 154.7680 - Epoch Loss: 49714.7916 - Avg Loss: 159.8546\n",
            "Epoch [35/50] - Batch loss: 160.6250 - Epoch Loss: 49875.4166 - Avg Loss: 159.8571\n",
            "Epoch [35/50] - Batch loss: 158.8425 - Epoch Loss: 50034.2591 - Avg Loss: 159.8539\n",
            "Epoch [35/50] - Batch loss: 153.9605 - Epoch Loss: 50188.2196 - Avg Loss: 159.8351\n",
            "Epoch [35/50] - Batch loss: 158.3153 - Epoch Loss: 50346.5348 - Avg Loss: 159.8303\n",
            "Epoch [35/50] - Batch loss: 159.3597 - Epoch Loss: 50505.8945 - Avg Loss: 159.8288\n",
            "Epoch [35/50] - Batch loss: 155.4922 - Epoch Loss: 50661.3867 - Avg Loss: 159.8151\n",
            "Epoch [35/50] - Batch loss: 155.2089 - Epoch Loss: 50816.5956 - Avg Loss: 159.8006\n",
            "Epoch [35/50] - Batch loss: 162.1717 - Epoch Loss: 50978.7674 - Avg Loss: 159.8080\n",
            "Epoch [35/50] - Batch loss: 149.9527 - Epoch Loss: 51128.7201 - Avg Loss: 159.7773\n",
            "Epoch [35/50] - Batch loss: 157.1782 - Epoch Loss: 51285.8984 - Avg Loss: 159.7692\n",
            "Epoch [35/50] - Batch loss: 154.0656 - Epoch Loss: 51439.9640 - Avg Loss: 159.7514\n",
            "Epoch [35/50] - Batch loss: 161.2957 - Epoch Loss: 51601.2597 - Avg Loss: 159.7562\n",
            "Epoch [35/50] - Batch loss: 160.3647 - Epoch Loss: 51761.6244 - Avg Loss: 159.7581\n",
            "Epoch [35/50] - Batch loss: 162.1812 - Epoch Loss: 51923.8056 - Avg Loss: 159.7656\n",
            "Epoch [35/50] - Batch loss: 165.0616 - Epoch Loss: 52088.8672 - Avg Loss: 159.7818\n",
            "Epoch [35/50] - Batch loss: 167.7873 - Epoch Loss: 52256.6544 - Avg Loss: 159.8063\n",
            "Epoch [35/50] - Batch loss: 156.1617 - Epoch Loss: 52412.8161 - Avg Loss: 159.7952\n",
            "Epoch [35/50] - Batch loss: 159.3176 - Epoch Loss: 52572.1338 - Avg Loss: 159.7937\n",
            "Epoch [35/50] - Batch loss: 155.4984 - Epoch Loss: 52727.6322 - Avg Loss: 159.7807\n",
            "Epoch [35/50] - Batch loss: 158.0603 - Epoch Loss: 52885.6925 - Avg Loss: 159.7755\n",
            "Epoch [35/50] - Batch loss: 166.4169 - Epoch Loss: 53052.1094 - Avg Loss: 159.7955\n",
            "Epoch [35/50] - Batch loss: 166.2066 - Epoch Loss: 53218.3160 - Avg Loss: 159.8148\n",
            "Epoch [35/50] - Batch loss: 153.9727 - Epoch Loss: 53372.2887 - Avg Loss: 159.7973\n",
            "Epoch [35/50] - Batch loss: 155.3147 - Epoch Loss: 53527.6034 - Avg Loss: 159.7839\n",
            "Epoch [35/50] - Batch loss: 157.0957 - Epoch Loss: 53684.6991 - Avg Loss: 159.7759\n",
            "Epoch [35/50] - Batch loss: 158.9089 - Epoch Loss: 53843.6080 - Avg Loss: 159.7733\n",
            "Epoch [35/50] - Batch loss: 159.7675 - Epoch Loss: 54003.3755 - Avg Loss: 159.7733\n",
            "Epoch [35/50] - Batch loss: 155.2102 - Epoch Loss: 54158.5857 - Avg Loss: 159.7598\n",
            "Epoch [35/50] - Batch loss: 154.8703 - Epoch Loss: 54313.4561 - Avg Loss: 159.7455\n",
            "Epoch [35/50] - Batch loss: 154.5008 - Epoch Loss: 54467.9568 - Avg Loss: 159.7301\n",
            "Epoch [35/50] - Batch loss: 156.9317 - Epoch Loss: 54624.8885 - Avg Loss: 159.7219\n",
            "Epoch [35/50] - Batch loss: 169.3526 - Epoch Loss: 54794.2412 - Avg Loss: 159.7500\n",
            "Epoch [35/50] - Batch loss: 162.8530 - Epoch Loss: 54957.0942 - Avg Loss: 159.7590\n",
            "Epoch [35/50] - Batch loss: 147.6656 - Epoch Loss: 55104.7597 - Avg Loss: 159.7239\n",
            "Epoch [35/50] - Batch loss: 165.6982 - Epoch Loss: 55270.4579 - Avg Loss: 159.7412\n",
            "Epoch [35/50] - Batch loss: 157.6507 - Epoch Loss: 55428.1086 - Avg Loss: 159.7352\n",
            "Epoch [35/50] - Batch loss: 153.5519 - Epoch Loss: 55581.6605 - Avg Loss: 159.7174\n",
            "Epoch [35/50] - Batch loss: 162.7425 - Epoch Loss: 55744.4030 - Avg Loss: 159.7261\n",
            "Epoch [35/50] - Batch loss: 161.6601 - Epoch Loss: 55906.0631 - Avg Loss: 159.7316\n",
            "Epoch [35/50] - Batch loss: 155.3578 - Epoch Loss: 56061.4210 - Avg Loss: 159.7191\n",
            "Epoch [35/50] - Batch loss: 159.3723 - Epoch Loss: 56220.7933 - Avg Loss: 159.7182\n",
            "Epoch [35/50] - Batch loss: 150.2684 - Epoch Loss: 56371.0617 - Avg Loss: 159.6914\n",
            "Epoch [35/50] - Batch loss: 162.7870 - Epoch Loss: 56533.8487 - Avg Loss: 159.7001\n",
            "Epoch [35/50] - Batch loss: 165.4483 - Epoch Loss: 56699.2970 - Avg Loss: 159.7163\n",
            "Epoch [35/50] - Batch loss: 155.7831 - Epoch Loss: 56855.0800 - Avg Loss: 159.7053\n",
            "Epoch [35/50] - Batch loss: 159.5799 - Epoch Loss: 57014.6599 - Avg Loss: 159.7049\n",
            "Epoch [35/50] - Batch loss: 158.3978 - Epoch Loss: 57173.0577 - Avg Loss: 159.7013\n",
            "Epoch [35/50] - Batch loss: 162.3697 - Epoch Loss: 57335.4273 - Avg Loss: 159.7087\n",
            "Epoch [35/50] - Batch loss: 157.3086 - Epoch Loss: 57492.7360 - Avg Loss: 159.7020\n",
            "Epoch [35/50] - Batch loss: 154.0045 - Epoch Loss: 57646.7405 - Avg Loss: 159.6863\n",
            "Epoch [35/50] - Batch loss: 154.5797 - Epoch Loss: 57801.3202 - Avg Loss: 159.6722\n",
            "Epoch [35/50] - Batch loss: 157.6744 - Epoch Loss: 57958.9946 - Avg Loss: 159.6667\n",
            "Epoch [35/50] - Batch loss: 162.4147 - Epoch Loss: 58121.4094 - Avg Loss: 159.6742\n",
            "Epoch [35/50] - Batch loss: 157.7453 - Epoch Loss: 58279.1547 - Avg Loss: 159.6689\n",
            "Epoch [35/50] - Batch loss: 149.2330 - Epoch Loss: 58428.3877 - Avg Loss: 159.6404\n",
            "Epoch [35/50] - Batch loss: 160.3795 - Epoch Loss: 58588.7672 - Avg Loss: 159.6424\n",
            "Epoch [35/50] - Batch loss: 159.5456 - Epoch Loss: 58748.3128 - Avg Loss: 159.6422\n",
            "Epoch [35/50] - Batch loss: 156.8464 - Epoch Loss: 58905.1592 - Avg Loss: 159.6346\n",
            "Epoch [35/50] - Batch loss: 158.5110 - Epoch Loss: 59063.6702 - Avg Loss: 159.6315\n",
            "Epoch [35/50] - Batch loss: 158.2583 - Epoch Loss: 59221.9285 - Avg Loss: 159.6278\n",
            "Epoch [35/50] - Batch loss: 165.1057 - Epoch Loss: 59387.0341 - Avg Loss: 159.6426\n",
            "Epoch [35/50] - Batch loss: 163.9021 - Epoch Loss: 59550.9362 - Avg Loss: 159.6540\n",
            "Epoch [35/50] - Batch loss: 162.6074 - Epoch Loss: 59713.5436 - Avg Loss: 159.6619\n",
            "Epoch [35/50] - Batch loss: 162.8788 - Epoch Loss: 59876.4224 - Avg Loss: 159.6705\n",
            "Epoch [35/50] - Batch loss: 160.8728 - Epoch Loss: 60037.2953 - Avg Loss: 159.6737\n",
            "Epoch [35/50] - Batch loss: 163.8204 - Epoch Loss: 60201.1156 - Avg Loss: 159.6847\n",
            "Epoch [35/50] - Batch loss: 162.7319 - Epoch Loss: 60363.8475 - Avg Loss: 159.6927\n",
            "Epoch [35/50] - Batch loss: 156.3299 - Epoch Loss: 60520.1774 - Avg Loss: 159.6838\n",
            "Epoch [35/50] - Batch loss: 157.0229 - Epoch Loss: 60677.2003 - Avg Loss: 159.6768\n",
            "Epoch [35/50] - Batch loss: 156.5306 - Epoch Loss: 60833.7309 - Avg Loss: 159.6686\n",
            "Epoch [35/50] - Batch loss: 147.3195 - Epoch Loss: 60981.0504 - Avg Loss: 159.6363\n",
            "Epoch [35/50] - Batch loss: 162.0353 - Epoch Loss: 61143.0858 - Avg Loss: 159.6425\n",
            "Epoch [35/50] - Batch loss: 167.4457 - Epoch Loss: 61310.5315 - Avg Loss: 159.6628\n",
            "Epoch [35/50] - Batch loss: 161.3405 - Epoch Loss: 61471.8720 - Avg Loss: 159.6672\n",
            "Epoch [35/50] - Batch loss: 152.7700 - Epoch Loss: 61624.6420 - Avg Loss: 159.6493\n",
            "Epoch [35/50] - Batch loss: 163.3698 - Epoch Loss: 61788.0117 - Avg Loss: 159.6589\n",
            "Epoch [35/50] - Batch loss: 157.6404 - Epoch Loss: 61945.6521 - Avg Loss: 159.6537\n",
            "Epoch [35/50] - Batch loss: 161.2830 - Epoch Loss: 62106.9351 - Avg Loss: 159.6579\n",
            "Epoch [35/50] - Batch loss: 165.7760 - Epoch Loss: 62272.7111 - Avg Loss: 159.6736\n",
            "Epoch [35/50] - Batch loss: 163.4909 - Epoch Loss: 62436.2020 - Avg Loss: 159.6834\n",
            "Epoch [35/50] - Batch loss: 156.5842 - Epoch Loss: 62592.7862 - Avg Loss: 159.6755\n",
            "Epoch [35/50] - Batch loss: 159.8627 - Epoch Loss: 62752.6489 - Avg Loss: 159.6760\n",
            "Epoch [35/50] - Batch loss: 165.1010 - Epoch Loss: 62917.7500 - Avg Loss: 159.6897\n",
            "Epoch [35/50] - Batch loss: 153.8998 - Epoch Loss: 63071.6498 - Avg Loss: 159.6751\n",
            "Epoch [35/50] - Batch loss: 155.3992 - Epoch Loss: 63227.0490 - Avg Loss: 159.6643\n",
            "Epoch [35/50] - Batch loss: 151.8758 - Epoch Loss: 63378.9247 - Avg Loss: 159.6446\n",
            "Epoch [35/50] - Batch loss: 159.3618 - Epoch Loss: 63538.2866 - Avg Loss: 159.6439\n",
            "Epoch [35/50] - Batch loss: 166.5927 - Epoch Loss: 63704.8792 - Avg Loss: 159.6614\n",
            "Epoch [35/50] - Batch loss: 154.7188 - Epoch Loss: 63859.5981 - Avg Loss: 159.6490\n",
            "Epoch [35/50] - Batch loss: 163.4586 - Epoch Loss: 64023.0567 - Avg Loss: 159.6585\n",
            "Epoch [35/50] - Batch loss: 156.2007 - Epoch Loss: 64179.2574 - Avg Loss: 159.6499\n",
            "Epoch [35/50] - Batch loss: 156.7805 - Epoch Loss: 64336.0379 - Avg Loss: 159.6428\n",
            "Epoch [35/50] - Batch loss: 158.5609 - Epoch Loss: 64494.5988 - Avg Loss: 159.6401\n",
            "Epoch [35/50] - Batch loss: 152.9893 - Epoch Loss: 64647.5881 - Avg Loss: 159.6237\n",
            "Epoch [35/50] - Batch loss: 164.0345 - Epoch Loss: 64811.6226 - Avg Loss: 159.6345\n",
            "Epoch [35/50] - Batch loss: 160.5104 - Epoch Loss: 64972.1330 - Avg Loss: 159.6367\n",
            "Epoch [35/50] - Batch loss: 150.3248 - Epoch Loss: 65122.4579 - Avg Loss: 159.6139\n",
            "Epoch [35/50] - Batch loss: 165.3023 - Epoch Loss: 65287.7602 - Avg Loss: 159.6278\n",
            "Epoch [35/50] - Batch loss: 165.0296 - Epoch Loss: 65452.7898 - Avg Loss: 159.6410\n",
            "Epoch [35/50] - Batch loss: 158.5882 - Epoch Loss: 65611.3779 - Avg Loss: 159.6384\n",
            "Epoch [35/50] - Batch loss: 160.7892 - Epoch Loss: 65772.1672 - Avg Loss: 159.6412\n",
            "Epoch [35/50] - Batch loss: 161.5039 - Epoch Loss: 65933.6711 - Avg Loss: 159.6457\n",
            "Epoch [35/50] - Batch loss: 159.9244 - Epoch Loss: 66093.5954 - Avg Loss: 159.6464\n",
            "Epoch [35/50] - Batch loss: 158.6985 - Epoch Loss: 66252.2939 - Avg Loss: 159.6441\n",
            "Epoch [35/50] - Batch loss: 156.8217 - Epoch Loss: 66409.1156 - Avg Loss: 159.6373\n",
            "Epoch [35/50] - Batch loss: 148.5813 - Epoch Loss: 66557.6969 - Avg Loss: 159.6108\n",
            "Epoch [35/50] - Batch loss: 155.7959 - Epoch Loss: 66713.4928 - Avg Loss: 159.6017\n",
            "Epoch [35/50] - Batch loss: 150.4470 - Epoch Loss: 66863.9398 - Avg Loss: 159.5798\n",
            "Epoch [35/50] - Batch loss: 153.2826 - Epoch Loss: 67017.2224 - Avg Loss: 159.5648\n",
            "Epoch [35/50] - Batch loss: 153.4763 - Epoch Loss: 67170.6987 - Avg Loss: 159.5504\n",
            "Epoch [35/50] - Batch loss: 155.0427 - Epoch Loss: 67325.7414 - Avg Loss: 159.5397\n",
            "Epoch [35/50] - Batch loss: 154.5491 - Epoch Loss: 67480.2905 - Avg Loss: 159.5279\n",
            "Epoch [35/50] - Batch loss: 157.7359 - Epoch Loss: 67638.0264 - Avg Loss: 159.5236\n",
            "Epoch [35/50] - Batch loss: 153.8574 - Epoch Loss: 67791.8837 - Avg Loss: 159.5103\n",
            "Epoch [35/50] - Batch loss: 162.9786 - Epoch Loss: 67954.8624 - Avg Loss: 159.5185\n",
            "Epoch [35/50] - Batch loss: 164.8473 - Epoch Loss: 68119.7097 - Avg Loss: 159.5309\n",
            "Epoch [35/50] - Batch loss: 162.9555 - Epoch Loss: 68282.6652 - Avg Loss: 159.5389\n",
            "Epoch [35/50] - Batch loss: 155.8231 - Epoch Loss: 68438.4883 - Avg Loss: 159.5303\n",
            "Epoch [35/50] - Batch loss: 160.4142 - Epoch Loss: 68598.9025 - Avg Loss: 159.5323\n",
            "Epoch [35/50] - Batch loss: 156.3036 - Epoch Loss: 68755.2060 - Avg Loss: 159.5248\n",
            "Epoch [35/50] - Batch loss: 163.4225 - Epoch Loss: 68918.6286 - Avg Loss: 159.5339\n",
            "Epoch [35/50] - Batch loss: 159.8582 - Epoch Loss: 69078.4867 - Avg Loss: 159.5346\n",
            "Epoch [35/50] - Batch loss: 155.2253 - Epoch Loss: 69233.7120 - Avg Loss: 159.5247\n",
            "Epoch [35/50] - Batch loss: 157.3378 - Epoch Loss: 69391.0498 - Avg Loss: 159.5197\n",
            "Epoch [35/50] - Batch loss: 156.9359 - Epoch Loss: 69547.9857 - Avg Loss: 159.5137\n",
            "Epoch [35/50] - Batch loss: 158.5547 - Epoch Loss: 69706.5404 - Avg Loss: 159.5115\n",
            "Epoch [35/50] - Batch loss: 167.8640 - Epoch Loss: 69874.4044 - Avg Loss: 159.5306\n",
            "Epoch [35/50] - Batch loss: 159.7361 - Epoch Loss: 70034.1405 - Avg Loss: 159.5311\n",
            "Epoch [35/50] - Batch loss: 160.5043 - Epoch Loss: 70194.6449 - Avg Loss: 159.5333\n",
            "Epoch [35/50] - Batch loss: 168.9367 - Epoch Loss: 70363.5815 - Avg Loss: 159.5546\n",
            "Epoch [35/50] - Batch loss: 161.6290 - Epoch Loss: 70525.2106 - Avg Loss: 159.5593\n",
            "Epoch [35/50] - Batch loss: 161.1369 - Epoch Loss: 70686.3475 - Avg Loss: 159.5629\n",
            "Epoch [35/50] - Batch loss: 164.6006 - Epoch Loss: 70850.9481 - Avg Loss: 159.5742\n",
            "Epoch [35/50] - Batch loss: 164.5253 - Epoch Loss: 71015.4734 - Avg Loss: 159.5853\n",
            "Epoch [35/50] - Batch loss: 158.0537 - Epoch Loss: 71173.5271 - Avg Loss: 159.5819\n",
            "Epoch [35/50] - Batch loss: 157.9745 - Epoch Loss: 71331.5016 - Avg Loss: 159.5783\n",
            "Epoch [35/50] - Batch loss: 157.3267 - Epoch Loss: 71488.8283 - Avg Loss: 159.5733\n",
            "Epoch [35/50] - Batch loss: 152.0357 - Epoch Loss: 71640.8640 - Avg Loss: 159.5565\n",
            "Epoch [35/50] - Batch loss: 166.1929 - Epoch Loss: 71807.0569 - Avg Loss: 159.5712\n",
            "Epoch [35/50] - Batch loss: 160.8598 - Epoch Loss: 71967.9167 - Avg Loss: 159.5741\n",
            "Epoch [35/50] - Batch loss: 152.9397 - Epoch Loss: 72120.8564 - Avg Loss: 159.5594\n",
            "Epoch [35/50] - Batch loss: 155.6298 - Epoch Loss: 72276.4863 - Avg Loss: 159.5507\n",
            "Epoch [35/50] - Batch loss: 155.8244 - Epoch Loss: 72432.3107 - Avg Loss: 159.5425\n",
            "Epoch [35/50] - Batch loss: 157.6824 - Epoch Loss: 72589.9931 - Avg Loss: 159.5384\n",
            "Epoch [35/50] - Batch loss: 159.0428 - Epoch Loss: 72749.0359 - Avg Loss: 159.5374\n",
            "Epoch [35/50] - Batch loss: 163.6512 - Epoch Loss: 72912.6871 - Avg Loss: 159.5464\n",
            "Epoch [35/50] - Batch loss: 154.2134 - Epoch Loss: 73066.9004 - Avg Loss: 159.5347\n",
            "Epoch [35/50] - Batch loss: 155.9128 - Epoch Loss: 73222.8132 - Avg Loss: 159.5268\n",
            "Epoch [35/50] - Batch loss: 157.5110 - Epoch Loss: 73380.3242 - Avg Loss: 159.5224\n",
            "Epoch [35/50] - Batch loss: 156.0492 - Epoch Loss: 73536.3734 - Avg Loss: 159.5149\n",
            "Epoch [35/50] - Batch loss: 161.6677 - Epoch Loss: 73698.0411 - Avg Loss: 159.5196\n",
            "Epoch [35/50] - Batch loss: 161.3976 - Epoch Loss: 73859.4387 - Avg Loss: 159.5236\n",
            "Epoch [35/50] - Batch loss: 159.7296 - Epoch Loss: 74019.1683 - Avg Loss: 159.5241\n",
            "Epoch [35/50] - Batch loss: 159.1212 - Epoch Loss: 74178.2895 - Avg Loss: 159.5232\n",
            "Epoch [35/50] - Batch loss: 161.2556 - Epoch Loss: 74339.5451 - Avg Loss: 159.5269\n",
            "Epoch [35/50] - Batch loss: 156.5173 - Epoch Loss: 74496.0624 - Avg Loss: 159.5205\n",
            "Epoch [35/50] - Batch loss: 166.6606 - Epoch Loss: 74662.7230 - Avg Loss: 159.5357\n",
            "Epoch [35/50] - Batch loss: 161.7337 - Epoch Loss: 74824.4568 - Avg Loss: 159.5404\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 36/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d45f9a8ee9e1428d814c6928a977f0dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [36/50] - Batch loss: 157.6881 - Epoch Loss: 157.6881 - Avg Loss: 157.6881\n",
            "Epoch [36/50] - Batch loss: 155.6778 - Epoch Loss: 313.3659 - Avg Loss: 156.6829\n",
            "Epoch [36/50] - Batch loss: 159.4238 - Epoch Loss: 472.7897 - Avg Loss: 157.5966\n",
            "Epoch [36/50] - Batch loss: 156.9696 - Epoch Loss: 629.7592 - Avg Loss: 157.4398\n",
            "Epoch [36/50] - Batch loss: 165.0941 - Epoch Loss: 794.8533 - Avg Loss: 158.9707\n",
            "Epoch [36/50] - Batch loss: 158.3849 - Epoch Loss: 953.2382 - Avg Loss: 158.8730\n",
            "Epoch [36/50] - Batch loss: 160.4037 - Epoch Loss: 1113.6419 - Avg Loss: 159.0917\n",
            "Epoch [36/50] - Batch loss: 164.5645 - Epoch Loss: 1278.2064 - Avg Loss: 159.7758\n",
            "Epoch [36/50] - Batch loss: 161.5455 - Epoch Loss: 1439.7519 - Avg Loss: 159.9724\n",
            "Epoch [36/50] - Batch loss: 164.1857 - Epoch Loss: 1603.9376 - Avg Loss: 160.3938\n",
            "Epoch [36/50] - Batch loss: 162.3612 - Epoch Loss: 1766.2988 - Avg Loss: 160.5726\n",
            "Epoch [36/50] - Batch loss: 158.4975 - Epoch Loss: 1924.7963 - Avg Loss: 160.3997\n",
            "Epoch [36/50] - Batch loss: 160.2572 - Epoch Loss: 2085.0536 - Avg Loss: 160.3887\n",
            "Epoch [36/50] - Batch loss: 159.2064 - Epoch Loss: 2244.2599 - Avg Loss: 160.3043\n",
            "Epoch [36/50] - Batch loss: 158.8001 - Epoch Loss: 2403.0600 - Avg Loss: 160.2040\n",
            "Epoch [36/50] - Batch loss: 153.1117 - Epoch Loss: 2556.1718 - Avg Loss: 159.7607\n",
            "Epoch [36/50] - Batch loss: 164.5964 - Epoch Loss: 2720.7682 - Avg Loss: 160.0452\n",
            "Epoch [36/50] - Batch loss: 158.7340 - Epoch Loss: 2879.5022 - Avg Loss: 159.9723\n",
            "Epoch [36/50] - Batch loss: 152.8033 - Epoch Loss: 3032.3055 - Avg Loss: 159.5950\n",
            "Epoch [36/50] - Batch loss: 150.9395 - Epoch Loss: 3183.2449 - Avg Loss: 159.1622\n",
            "Epoch [36/50] - Batch loss: 162.3108 - Epoch Loss: 3345.5557 - Avg Loss: 159.3122\n",
            "Epoch [36/50] - Batch loss: 163.5538 - Epoch Loss: 3509.1095 - Avg Loss: 159.5050\n",
            "Epoch [36/50] - Batch loss: 157.8328 - Epoch Loss: 3666.9423 - Avg Loss: 159.4323\n",
            "Epoch [36/50] - Batch loss: 157.6462 - Epoch Loss: 3824.5885 - Avg Loss: 159.3579\n",
            "Epoch [36/50] - Batch loss: 158.0052 - Epoch Loss: 3982.5936 - Avg Loss: 159.3037\n",
            "Epoch [36/50] - Batch loss: 159.8269 - Epoch Loss: 4142.4205 - Avg Loss: 159.3239\n",
            "Epoch [36/50] - Batch loss: 151.9547 - Epoch Loss: 4294.3752 - Avg Loss: 159.0509\n",
            "Epoch [36/50] - Batch loss: 160.7565 - Epoch Loss: 4455.1317 - Avg Loss: 159.1118\n",
            "Epoch [36/50] - Batch loss: 158.4295 - Epoch Loss: 4613.5612 - Avg Loss: 159.0883\n",
            "Epoch [36/50] - Batch loss: 162.2589 - Epoch Loss: 4775.8201 - Avg Loss: 159.1940\n",
            "Epoch [36/50] - Batch loss: 155.8977 - Epoch Loss: 4931.7177 - Avg Loss: 159.0877\n",
            "Epoch [36/50] - Batch loss: 150.7539 - Epoch Loss: 5082.4716 - Avg Loss: 158.8272\n",
            "Epoch [36/50] - Batch loss: 160.1929 - Epoch Loss: 5242.6645 - Avg Loss: 158.8686\n",
            "Epoch [36/50] - Batch loss: 149.3230 - Epoch Loss: 5391.9875 - Avg Loss: 158.5879\n",
            "Epoch [36/50] - Batch loss: 161.8162 - Epoch Loss: 5553.8036 - Avg Loss: 158.6801\n",
            "Epoch [36/50] - Batch loss: 165.5263 - Epoch Loss: 5719.3299 - Avg Loss: 158.8703\n",
            "Epoch [36/50] - Batch loss: 155.5689 - Epoch Loss: 5874.8988 - Avg Loss: 158.7810\n",
            "Epoch [36/50] - Batch loss: 157.9048 - Epoch Loss: 6032.8036 - Avg Loss: 158.7580\n",
            "Epoch [36/50] - Batch loss: 159.0164 - Epoch Loss: 6191.8201 - Avg Loss: 158.7646\n",
            "Epoch [36/50] - Batch loss: 166.0769 - Epoch Loss: 6357.8969 - Avg Loss: 158.9474\n",
            "Epoch [36/50] - Batch loss: 156.3900 - Epoch Loss: 6514.2870 - Avg Loss: 158.8850\n",
            "Epoch [36/50] - Batch loss: 155.2509 - Epoch Loss: 6669.5379 - Avg Loss: 158.7985\n",
            "Epoch [36/50] - Batch loss: 154.1758 - Epoch Loss: 6823.7136 - Avg Loss: 158.6910\n",
            "Epoch [36/50] - Batch loss: 155.4230 - Epoch Loss: 6979.1366 - Avg Loss: 158.6167\n",
            "Epoch [36/50] - Batch loss: 160.6216 - Epoch Loss: 7139.7582 - Avg Loss: 158.6613\n",
            "Epoch [36/50] - Batch loss: 157.1907 - Epoch Loss: 7296.9489 - Avg Loss: 158.6293\n",
            "Epoch [36/50] - Batch loss: 161.3010 - Epoch Loss: 7458.2499 - Avg Loss: 158.6862\n",
            "Epoch [36/50] - Batch loss: 157.5155 - Epoch Loss: 7615.7654 - Avg Loss: 158.6618\n",
            "Epoch [36/50] - Batch loss: 161.9709 - Epoch Loss: 7777.7364 - Avg Loss: 158.7293\n",
            "Epoch [36/50] - Batch loss: 161.3222 - Epoch Loss: 7939.0586 - Avg Loss: 158.7812\n",
            "Epoch [36/50] - Batch loss: 160.0604 - Epoch Loss: 8099.1190 - Avg Loss: 158.8063\n",
            "Epoch [36/50] - Batch loss: 163.1942 - Epoch Loss: 8262.3132 - Avg Loss: 158.8906\n",
            "Epoch [36/50] - Batch loss: 153.0176 - Epoch Loss: 8415.3308 - Avg Loss: 158.7798\n",
            "Epoch [36/50] - Batch loss: 156.9920 - Epoch Loss: 8572.3229 - Avg Loss: 158.7467\n",
            "Epoch [36/50] - Batch loss: 155.4220 - Epoch Loss: 8727.7448 - Avg Loss: 158.6863\n",
            "Epoch [36/50] - Batch loss: 148.8116 - Epoch Loss: 8876.5565 - Avg Loss: 158.5099\n",
            "Epoch [36/50] - Batch loss: 161.5449 - Epoch Loss: 9038.1013 - Avg Loss: 158.5632\n",
            "Epoch [36/50] - Batch loss: 159.6749 - Epoch Loss: 9197.7762 - Avg Loss: 158.5823\n",
            "Epoch [36/50] - Batch loss: 158.3322 - Epoch Loss: 9356.1084 - Avg Loss: 158.5781\n",
            "Epoch [36/50] - Batch loss: 158.7341 - Epoch Loss: 9514.8424 - Avg Loss: 158.5807\n",
            "Epoch [36/50] - Batch loss: 153.0473 - Epoch Loss: 9667.8897 - Avg Loss: 158.4900\n",
            "Epoch [36/50] - Batch loss: 164.5355 - Epoch Loss: 9832.4252 - Avg Loss: 158.5875\n",
            "Epoch [36/50] - Batch loss: 158.0354 - Epoch Loss: 9990.4606 - Avg Loss: 158.5787\n",
            "Epoch [36/50] - Batch loss: 156.0315 - Epoch Loss: 10146.4921 - Avg Loss: 158.5389\n",
            "Epoch [36/50] - Batch loss: 164.2282 - Epoch Loss: 10310.7203 - Avg Loss: 158.6265\n",
            "Epoch [36/50] - Batch loss: 158.3495 - Epoch Loss: 10469.0698 - Avg Loss: 158.6223\n",
            "Epoch [36/50] - Batch loss: 162.8250 - Epoch Loss: 10631.8948 - Avg Loss: 158.6850\n",
            "Epoch [36/50] - Batch loss: 164.3430 - Epoch Loss: 10796.2378 - Avg Loss: 158.7682\n",
            "Epoch [36/50] - Batch loss: 156.5332 - Epoch Loss: 10952.7710 - Avg Loss: 158.7358\n",
            "Epoch [36/50] - Batch loss: 155.3766 - Epoch Loss: 11108.1476 - Avg Loss: 158.6878\n",
            "Epoch [36/50] - Batch loss: 160.8715 - Epoch Loss: 11269.0191 - Avg Loss: 158.7186\n",
            "Epoch [36/50] - Batch loss: 157.5995 - Epoch Loss: 11426.6186 - Avg Loss: 158.7030\n",
            "Epoch [36/50] - Batch loss: 154.9985 - Epoch Loss: 11581.6171 - Avg Loss: 158.6523\n",
            "Epoch [36/50] - Batch loss: 169.1685 - Epoch Loss: 11750.7856 - Avg Loss: 158.7944\n",
            "Epoch [36/50] - Batch loss: 159.9172 - Epoch Loss: 11910.7027 - Avg Loss: 158.8094\n",
            "Epoch [36/50] - Batch loss: 158.6158 - Epoch Loss: 12069.3186 - Avg Loss: 158.8068\n",
            "Epoch [36/50] - Batch loss: 154.4054 - Epoch Loss: 12223.7239 - Avg Loss: 158.7497\n",
            "Epoch [36/50] - Batch loss: 158.7894 - Epoch Loss: 12382.5133 - Avg Loss: 158.7502\n",
            "Epoch [36/50] - Batch loss: 160.4162 - Epoch Loss: 12542.9295 - Avg Loss: 158.7713\n",
            "Epoch [36/50] - Batch loss: 160.9270 - Epoch Loss: 12703.8564 - Avg Loss: 158.7982\n",
            "Epoch [36/50] - Batch loss: 153.3587 - Epoch Loss: 12857.2152 - Avg Loss: 158.7311\n",
            "Epoch [36/50] - Batch loss: 157.8042 - Epoch Loss: 13015.0194 - Avg Loss: 158.7197\n",
            "Epoch [36/50] - Batch loss: 163.2102 - Epoch Loss: 13178.2296 - Avg Loss: 158.7739\n",
            "Epoch [36/50] - Batch loss: 159.3650 - Epoch Loss: 13337.5946 - Avg Loss: 158.7809\n",
            "Epoch [36/50] - Batch loss: 163.5093 - Epoch Loss: 13501.1040 - Avg Loss: 158.8365\n",
            "Epoch [36/50] - Batch loss: 155.7782 - Epoch Loss: 13656.8822 - Avg Loss: 158.8010\n",
            "Epoch [36/50] - Batch loss: 158.7120 - Epoch Loss: 13815.5942 - Avg Loss: 158.7999\n",
            "Epoch [36/50] - Batch loss: 159.4337 - Epoch Loss: 13975.0280 - Avg Loss: 158.8071\n",
            "Epoch [36/50] - Batch loss: 157.6635 - Epoch Loss: 14132.6914 - Avg Loss: 158.7943\n",
            "Epoch [36/50] - Batch loss: 158.7093 - Epoch Loss: 14291.4007 - Avg Loss: 158.7933\n",
            "Epoch [36/50] - Batch loss: 158.8758 - Epoch Loss: 14450.2765 - Avg Loss: 158.7942\n",
            "Epoch [36/50] - Batch loss: 158.6888 - Epoch Loss: 14608.9653 - Avg Loss: 158.7931\n",
            "Epoch [36/50] - Batch loss: 160.2846 - Epoch Loss: 14769.2498 - Avg Loss: 158.8091\n",
            "Epoch [36/50] - Batch loss: 158.6971 - Epoch Loss: 14927.9470 - Avg Loss: 158.8079\n",
            "Epoch [36/50] - Batch loss: 163.2064 - Epoch Loss: 15091.1534 - Avg Loss: 158.8542\n",
            "Epoch [36/50] - Batch loss: 158.5975 - Epoch Loss: 15249.7509 - Avg Loss: 158.8516\n",
            "Epoch [36/50] - Batch loss: 149.6891 - Epoch Loss: 15399.4400 - Avg Loss: 158.7571\n",
            "Epoch [36/50] - Batch loss: 157.5674 - Epoch Loss: 15557.0075 - Avg Loss: 158.7450\n",
            "Epoch [36/50] - Batch loss: 154.9369 - Epoch Loss: 15711.9444 - Avg Loss: 158.7065\n",
            "Epoch [36/50] - Batch loss: 162.2526 - Epoch Loss: 15874.1970 - Avg Loss: 158.7420\n",
            "Epoch [36/50] - Batch loss: 159.0499 - Epoch Loss: 16033.2469 - Avg Loss: 158.7450\n",
            "Epoch [36/50] - Batch loss: 159.9529 - Epoch Loss: 16193.1998 - Avg Loss: 158.7569\n",
            "Epoch [36/50] - Batch loss: 155.8985 - Epoch Loss: 16349.0983 - Avg Loss: 158.7291\n",
            "Epoch [36/50] - Batch loss: 158.5321 - Epoch Loss: 16507.6304 - Avg Loss: 158.7272\n",
            "Epoch [36/50] - Batch loss: 166.6826 - Epoch Loss: 16674.3130 - Avg Loss: 158.8030\n",
            "Epoch [36/50] - Batch loss: 168.4910 - Epoch Loss: 16842.8040 - Avg Loss: 158.8944\n",
            "Epoch [36/50] - Batch loss: 158.6980 - Epoch Loss: 17001.5020 - Avg Loss: 158.8925\n",
            "Epoch [36/50] - Batch loss: 160.3992 - Epoch Loss: 17161.9012 - Avg Loss: 158.9065\n",
            "Epoch [36/50] - Batch loss: 161.6985 - Epoch Loss: 17323.5997 - Avg Loss: 158.9321\n",
            "Epoch [36/50] - Batch loss: 158.1465 - Epoch Loss: 17481.7462 - Avg Loss: 158.9250\n",
            "Epoch [36/50] - Batch loss: 156.4787 - Epoch Loss: 17638.2249 - Avg Loss: 158.9029\n",
            "Epoch [36/50] - Batch loss: 164.8743 - Epoch Loss: 17803.0992 - Avg Loss: 158.9562\n",
            "Epoch [36/50] - Batch loss: 159.5214 - Epoch Loss: 17962.6205 - Avg Loss: 158.9612\n",
            "Epoch [36/50] - Batch loss: 166.4371 - Epoch Loss: 18129.0576 - Avg Loss: 159.0268\n",
            "Epoch [36/50] - Batch loss: 162.7022 - Epoch Loss: 18291.7598 - Avg Loss: 159.0588\n",
            "Epoch [36/50] - Batch loss: 161.9190 - Epoch Loss: 18453.6788 - Avg Loss: 159.0834\n",
            "Epoch [36/50] - Batch loss: 152.4999 - Epoch Loss: 18606.1786 - Avg Loss: 159.0272\n",
            "Epoch [36/50] - Batch loss: 147.1252 - Epoch Loss: 18753.3039 - Avg Loss: 158.9263\n",
            "Epoch [36/50] - Batch loss: 155.5375 - Epoch Loss: 18908.8414 - Avg Loss: 158.8978\n",
            "Epoch [36/50] - Batch loss: 157.1449 - Epoch Loss: 19065.9863 - Avg Loss: 158.8832\n",
            "Epoch [36/50] - Batch loss: 153.8038 - Epoch Loss: 19219.7901 - Avg Loss: 158.8412\n",
            "Epoch [36/50] - Batch loss: 163.9703 - Epoch Loss: 19383.7604 - Avg Loss: 158.8833\n",
            "Epoch [36/50] - Batch loss: 154.6563 - Epoch Loss: 19538.4167 - Avg Loss: 158.8489\n",
            "Epoch [36/50] - Batch loss: 159.7637 - Epoch Loss: 19698.1803 - Avg Loss: 158.8563\n",
            "Epoch [36/50] - Batch loss: 158.2851 - Epoch Loss: 19856.4654 - Avg Loss: 158.8517\n",
            "Epoch [36/50] - Batch loss: 159.9936 - Epoch Loss: 20016.4591 - Avg Loss: 158.8608\n",
            "Epoch [36/50] - Batch loss: 159.6006 - Epoch Loss: 20176.0596 - Avg Loss: 158.8666\n",
            "Epoch [36/50] - Batch loss: 149.1366 - Epoch Loss: 20325.1962 - Avg Loss: 158.7906\n",
            "Epoch [36/50] - Batch loss: 168.8596 - Epoch Loss: 20494.0558 - Avg Loss: 158.8686\n",
            "Epoch [36/50] - Batch loss: 165.6632 - Epoch Loss: 20659.7189 - Avg Loss: 158.9209\n",
            "Epoch [36/50] - Batch loss: 161.2796 - Epoch Loss: 20820.9986 - Avg Loss: 158.9389\n",
            "Epoch [36/50] - Batch loss: 157.6352 - Epoch Loss: 20978.6338 - Avg Loss: 158.9290\n",
            "Epoch [36/50] - Batch loss: 159.9955 - Epoch Loss: 21138.6293 - Avg Loss: 158.9371\n",
            "Epoch [36/50] - Batch loss: 159.6220 - Epoch Loss: 21298.2513 - Avg Loss: 158.9422\n",
            "Epoch [36/50] - Batch loss: 157.8028 - Epoch Loss: 21456.0541 - Avg Loss: 158.9337\n",
            "Epoch [36/50] - Batch loss: 156.9570 - Epoch Loss: 21613.0111 - Avg Loss: 158.9192\n",
            "Epoch [36/50] - Batch loss: 159.9435 - Epoch Loss: 21772.9546 - Avg Loss: 158.9267\n",
            "Epoch [36/50] - Batch loss: 161.3960 - Epoch Loss: 21934.3507 - Avg Loss: 158.9446\n",
            "Epoch [36/50] - Batch loss: 164.4255 - Epoch Loss: 22098.7762 - Avg Loss: 158.9840\n",
            "Epoch [36/50] - Batch loss: 162.4450 - Epoch Loss: 22261.2212 - Avg Loss: 159.0087\n",
            "Epoch [36/50] - Batch loss: 158.1921 - Epoch Loss: 22419.4133 - Avg Loss: 159.0029\n",
            "Epoch [36/50] - Batch loss: 166.3184 - Epoch Loss: 22585.7317 - Avg Loss: 159.0544\n",
            "Epoch [36/50] - Batch loss: 159.5694 - Epoch Loss: 22745.3012 - Avg Loss: 159.0581\n",
            "Epoch [36/50] - Batch loss: 164.7376 - Epoch Loss: 22910.0388 - Avg Loss: 159.0975\n",
            "Epoch [36/50] - Batch loss: 169.3160 - Epoch Loss: 23079.3548 - Avg Loss: 159.1680\n",
            "Epoch [36/50] - Batch loss: 161.0820 - Epoch Loss: 23240.4368 - Avg Loss: 159.1811\n",
            "Epoch [36/50] - Batch loss: 168.1067 - Epoch Loss: 23408.5435 - Avg Loss: 159.2418\n",
            "Epoch [36/50] - Batch loss: 155.5321 - Epoch Loss: 23564.0756 - Avg Loss: 159.2167\n",
            "Epoch [36/50] - Batch loss: 158.1364 - Epoch Loss: 23722.2119 - Avg Loss: 159.2095\n",
            "Epoch [36/50] - Batch loss: 158.6724 - Epoch Loss: 23880.8844 - Avg Loss: 159.2059\n",
            "Epoch [36/50] - Batch loss: 151.4873 - Epoch Loss: 24032.3716 - Avg Loss: 159.1548\n",
            "Epoch [36/50] - Batch loss: 165.8484 - Epoch Loss: 24198.2200 - Avg Loss: 159.1988\n",
            "Epoch [36/50] - Batch loss: 154.5058 - Epoch Loss: 24352.7258 - Avg Loss: 159.1681\n",
            "Epoch [36/50] - Batch loss: 163.1889 - Epoch Loss: 24515.9147 - Avg Loss: 159.1943\n",
            "Epoch [36/50] - Batch loss: 168.6621 - Epoch Loss: 24684.5768 - Avg Loss: 159.2553\n",
            "Epoch [36/50] - Batch loss: 158.4876 - Epoch Loss: 24843.0643 - Avg Loss: 159.2504\n",
            "Epoch [36/50] - Batch loss: 156.2118 - Epoch Loss: 24999.2761 - Avg Loss: 159.2311\n",
            "Epoch [36/50] - Batch loss: 160.5538 - Epoch Loss: 25159.8300 - Avg Loss: 159.2394\n",
            "Epoch [36/50] - Batch loss: 160.9335 - Epoch Loss: 25320.7634 - Avg Loss: 159.2501\n",
            "Epoch [36/50] - Batch loss: 156.6269 - Epoch Loss: 25477.3903 - Avg Loss: 159.2337\n",
            "Epoch [36/50] - Batch loss: 159.0170 - Epoch Loss: 25636.4073 - Avg Loss: 159.2323\n",
            "Epoch [36/50] - Batch loss: 164.9846 - Epoch Loss: 25801.3919 - Avg Loss: 159.2679\n",
            "Epoch [36/50] - Batch loss: 153.6105 - Epoch Loss: 25955.0024 - Avg Loss: 159.2331\n",
            "Epoch [36/50] - Batch loss: 159.7808 - Epoch Loss: 26114.7832 - Avg Loss: 159.2365\n",
            "Epoch [36/50] - Batch loss: 159.4132 - Epoch Loss: 26274.1964 - Avg Loss: 159.2376\n",
            "Epoch [36/50] - Batch loss: 159.6699 - Epoch Loss: 26433.8662 - Avg Loss: 159.2402\n",
            "Epoch [36/50] - Batch loss: 160.1815 - Epoch Loss: 26594.0477 - Avg Loss: 159.2458\n",
            "Epoch [36/50] - Batch loss: 157.8080 - Epoch Loss: 26751.8558 - Avg Loss: 159.2372\n",
            "Epoch [36/50] - Batch loss: 161.4966 - Epoch Loss: 26913.3523 - Avg Loss: 159.2506\n",
            "Epoch [36/50] - Batch loss: 167.5233 - Epoch Loss: 27080.8757 - Avg Loss: 159.2993\n",
            "Epoch [36/50] - Batch loss: 155.5035 - Epoch Loss: 27236.3792 - Avg Loss: 159.2771\n",
            "Epoch [36/50] - Batch loss: 161.2384 - Epoch Loss: 27397.6176 - Avg Loss: 159.2885\n",
            "Epoch [36/50] - Batch loss: 159.0365 - Epoch Loss: 27556.6541 - Avg Loss: 159.2870\n",
            "Epoch [36/50] - Batch loss: 162.3097 - Epoch Loss: 27718.9638 - Avg Loss: 159.3044\n",
            "Epoch [36/50] - Batch loss: 152.5159 - Epoch Loss: 27871.4798 - Avg Loss: 159.2656\n",
            "Epoch [36/50] - Batch loss: 167.5099 - Epoch Loss: 28038.9897 - Avg Loss: 159.3124\n",
            "Epoch [36/50] - Batch loss: 161.7797 - Epoch Loss: 28200.7694 - Avg Loss: 159.3264\n",
            "Epoch [36/50] - Batch loss: 157.5379 - Epoch Loss: 28358.3073 - Avg Loss: 159.3163\n",
            "Epoch [36/50] - Batch loss: 159.1842 - Epoch Loss: 28517.4915 - Avg Loss: 159.3156\n",
            "Epoch [36/50] - Batch loss: 156.7040 - Epoch Loss: 28674.1955 - Avg Loss: 159.3011\n",
            "Epoch [36/50] - Batch loss: 166.0292 - Epoch Loss: 28840.2247 - Avg Loss: 159.3383\n",
            "Epoch [36/50] - Batch loss: 166.4671 - Epoch Loss: 29006.6918 - Avg Loss: 159.3774\n",
            "Epoch [36/50] - Batch loss: 162.6383 - Epoch Loss: 29169.3301 - Avg Loss: 159.3952\n",
            "Epoch [36/50] - Batch loss: 162.8142 - Epoch Loss: 29332.1443 - Avg Loss: 159.4138\n",
            "Epoch [36/50] - Batch loss: 159.9529 - Epoch Loss: 29492.0972 - Avg Loss: 159.4167\n",
            "Epoch [36/50] - Batch loss: 156.3484 - Epoch Loss: 29648.4456 - Avg Loss: 159.4002\n",
            "Epoch [36/50] - Batch loss: 160.5809 - Epoch Loss: 29809.0265 - Avg Loss: 159.4066\n",
            "Epoch [36/50] - Batch loss: 165.4718 - Epoch Loss: 29974.4983 - Avg Loss: 159.4388\n",
            "Epoch [36/50] - Batch loss: 162.4323 - Epoch Loss: 30136.9306 - Avg Loss: 159.4547\n",
            "Epoch [36/50] - Batch loss: 153.7010 - Epoch Loss: 30290.6315 - Avg Loss: 159.4244\n",
            "Epoch [36/50] - Batch loss: 156.2051 - Epoch Loss: 30446.8366 - Avg Loss: 159.4075\n",
            "Epoch [36/50] - Batch loss: 155.1163 - Epoch Loss: 30601.9530 - Avg Loss: 159.3852\n",
            "Epoch [36/50] - Batch loss: 162.1314 - Epoch Loss: 30764.0843 - Avg Loss: 159.3994\n",
            "Epoch [36/50] - Batch loss: 158.3391 - Epoch Loss: 30922.4234 - Avg Loss: 159.3939\n",
            "Epoch [36/50] - Batch loss: 165.3108 - Epoch Loss: 31087.7343 - Avg Loss: 159.4243\n",
            "Epoch [36/50] - Batch loss: 159.0726 - Epoch Loss: 31246.8069 - Avg Loss: 159.4225\n",
            "Epoch [36/50] - Batch loss: 162.8967 - Epoch Loss: 31409.7036 - Avg Loss: 159.4401\n",
            "Epoch [36/50] - Batch loss: 163.7350 - Epoch Loss: 31573.4385 - Avg Loss: 159.4618\n",
            "Epoch [36/50] - Batch loss: 159.6344 - Epoch Loss: 31733.0730 - Avg Loss: 159.4627\n",
            "Epoch [36/50] - Batch loss: 158.6510 - Epoch Loss: 31891.7239 - Avg Loss: 159.4586\n",
            "Epoch [36/50] - Batch loss: 158.6415 - Epoch Loss: 32050.3654 - Avg Loss: 159.4546\n",
            "Epoch [36/50] - Batch loss: 163.1971 - Epoch Loss: 32213.5626 - Avg Loss: 159.4731\n",
            "Epoch [36/50] - Batch loss: 150.8634 - Epoch Loss: 32364.4260 - Avg Loss: 159.4307\n",
            "Epoch [36/50] - Batch loss: 156.0704 - Epoch Loss: 32520.4964 - Avg Loss: 159.4142\n",
            "Epoch [36/50] - Batch loss: 164.5209 - Epoch Loss: 32685.0173 - Avg Loss: 159.4391\n",
            "Epoch [36/50] - Batch loss: 156.3969 - Epoch Loss: 32841.4141 - Avg Loss: 159.4243\n",
            "Epoch [36/50] - Batch loss: 160.4421 - Epoch Loss: 33001.8562 - Avg Loss: 159.4293\n",
            "Epoch [36/50] - Batch loss: 152.3762 - Epoch Loss: 33154.2324 - Avg Loss: 159.3953\n",
            "Epoch [36/50] - Batch loss: 160.0636 - Epoch Loss: 33314.2960 - Avg Loss: 159.3985\n",
            "Epoch [36/50] - Batch loss: 165.8949 - Epoch Loss: 33480.1908 - Avg Loss: 159.4295\n",
            "Epoch [36/50] - Batch loss: 157.8579 - Epoch Loss: 33638.0487 - Avg Loss: 159.4220\n",
            "Epoch [36/50] - Batch loss: 156.8362 - Epoch Loss: 33794.8849 - Avg Loss: 159.4098\n",
            "Epoch [36/50] - Batch loss: 167.1721 - Epoch Loss: 33962.0570 - Avg Loss: 159.4463\n",
            "Epoch [36/50] - Batch loss: 158.1742 - Epoch Loss: 34120.2312 - Avg Loss: 159.4403\n",
            "Epoch [36/50] - Batch loss: 163.7352 - Epoch Loss: 34283.9665 - Avg Loss: 159.4603\n",
            "Epoch [36/50] - Batch loss: 172.7099 - Epoch Loss: 34456.6764 - Avg Loss: 159.5216\n",
            "Epoch [36/50] - Batch loss: 160.5148 - Epoch Loss: 34617.1911 - Avg Loss: 159.5262\n",
            "Epoch [36/50] - Batch loss: 165.4098 - Epoch Loss: 34782.6010 - Avg Loss: 159.5532\n",
            "Epoch [36/50] - Batch loss: 153.0778 - Epoch Loss: 34935.6787 - Avg Loss: 159.5236\n",
            "Epoch [36/50] - Batch loss: 163.1178 - Epoch Loss: 35098.7965 - Avg Loss: 159.5400\n",
            "Epoch [36/50] - Batch loss: 167.9280 - Epoch Loss: 35266.7246 - Avg Loss: 159.5779\n",
            "Epoch [36/50] - Batch loss: 156.6503 - Epoch Loss: 35423.3748 - Avg Loss: 159.5648\n",
            "Epoch [36/50] - Batch loss: 155.6649 - Epoch Loss: 35579.0397 - Avg Loss: 159.5473\n",
            "Epoch [36/50] - Batch loss: 158.8064 - Epoch Loss: 35737.8462 - Avg Loss: 159.5440\n",
            "Epoch [36/50] - Batch loss: 151.2241 - Epoch Loss: 35889.0703 - Avg Loss: 159.5070\n",
            "Epoch [36/50] - Batch loss: 166.3427 - Epoch Loss: 36055.4130 - Avg Loss: 159.5372\n",
            "Epoch [36/50] - Batch loss: 159.1883 - Epoch Loss: 36214.6013 - Avg Loss: 159.5357\n",
            "Epoch [36/50] - Batch loss: 160.8751 - Epoch Loss: 36375.4764 - Avg Loss: 159.5416\n",
            "Epoch [36/50] - Batch loss: 159.1559 - Epoch Loss: 36534.6323 - Avg Loss: 159.5399\n",
            "Epoch [36/50] - Batch loss: 157.3317 - Epoch Loss: 36691.9640 - Avg Loss: 159.5303\n",
            "Epoch [36/50] - Batch loss: 159.2955 - Epoch Loss: 36851.2595 - Avg Loss: 159.5293\n",
            "Epoch [36/50] - Batch loss: 166.4104 - Epoch Loss: 37017.6699 - Avg Loss: 159.5589\n",
            "Epoch [36/50] - Batch loss: 154.0932 - Epoch Loss: 37171.7631 - Avg Loss: 159.5355\n",
            "Epoch [36/50] - Batch loss: 168.5343 - Epoch Loss: 37340.2974 - Avg Loss: 159.5739\n",
            "Epoch [36/50] - Batch loss: 155.5015 - Epoch Loss: 37495.7988 - Avg Loss: 159.5566\n",
            "Epoch [36/50] - Batch loss: 156.4193 - Epoch Loss: 37652.2181 - Avg Loss: 159.5433\n",
            "Epoch [36/50] - Batch loss: 158.9391 - Epoch Loss: 37811.1573 - Avg Loss: 159.5407\n",
            "Epoch [36/50] - Batch loss: 173.0673 - Epoch Loss: 37984.2245 - Avg Loss: 159.5976\n",
            "Epoch [36/50] - Batch loss: 164.2525 - Epoch Loss: 38148.4770 - Avg Loss: 159.6171\n",
            "Epoch [36/50] - Batch loss: 152.9100 - Epoch Loss: 38301.3871 - Avg Loss: 159.5891\n",
            "Epoch [36/50] - Batch loss: 161.1706 - Epoch Loss: 38462.5577 - Avg Loss: 159.5957\n",
            "Epoch [36/50] - Batch loss: 168.9759 - Epoch Loss: 38631.5336 - Avg Loss: 159.6344\n",
            "Epoch [36/50] - Batch loss: 155.4854 - Epoch Loss: 38787.0190 - Avg Loss: 159.6174\n",
            "Epoch [36/50] - Batch loss: 156.9869 - Epoch Loss: 38944.0059 - Avg Loss: 159.6066\n",
            "Epoch [36/50] - Batch loss: 158.8001 - Epoch Loss: 39102.8060 - Avg Loss: 159.6033\n",
            "Epoch [36/50] - Batch loss: 158.1263 - Epoch Loss: 39260.9323 - Avg Loss: 159.5973\n",
            "Epoch [36/50] - Batch loss: 160.9360 - Epoch Loss: 39421.8684 - Avg Loss: 159.6027\n",
            "Epoch [36/50] - Batch loss: 163.7067 - Epoch Loss: 39585.5751 - Avg Loss: 159.6193\n",
            "Epoch [36/50] - Batch loss: 158.1923 - Epoch Loss: 39743.7673 - Avg Loss: 159.6135\n",
            "Epoch [36/50] - Batch loss: 156.5552 - Epoch Loss: 39900.3226 - Avg Loss: 159.6013\n",
            "Epoch [36/50] - Batch loss: 156.2497 - Epoch Loss: 40056.5722 - Avg Loss: 159.5879\n",
            "Epoch [36/50] - Batch loss: 159.6349 - Epoch Loss: 40216.2072 - Avg Loss: 159.5881\n",
            "Epoch [36/50] - Batch loss: 164.5565 - Epoch Loss: 40380.7637 - Avg Loss: 159.6078\n",
            "Epoch [36/50] - Batch loss: 161.6796 - Epoch Loss: 40542.4433 - Avg Loss: 159.6159\n",
            "Epoch [36/50] - Batch loss: 156.1077 - Epoch Loss: 40698.5510 - Avg Loss: 159.6022\n",
            "Epoch [36/50] - Batch loss: 155.0032 - Epoch Loss: 40853.5542 - Avg Loss: 159.5842\n",
            "Epoch [36/50] - Batch loss: 163.6070 - Epoch Loss: 41017.1612 - Avg Loss: 159.5998\n",
            "Epoch [36/50] - Batch loss: 160.9074 - Epoch Loss: 41178.0686 - Avg Loss: 159.6049\n",
            "Epoch [36/50] - Batch loss: 153.9870 - Epoch Loss: 41332.0556 - Avg Loss: 159.5832\n",
            "Epoch [36/50] - Batch loss: 160.7136 - Epoch Loss: 41492.7691 - Avg Loss: 159.5876\n",
            "Epoch [36/50] - Batch loss: 161.1843 - Epoch Loss: 41653.9535 - Avg Loss: 159.5937\n",
            "Epoch [36/50] - Batch loss: 171.3436 - Epoch Loss: 41825.2970 - Avg Loss: 159.6385\n",
            "Epoch [36/50] - Batch loss: 166.3136 - Epoch Loss: 41991.6106 - Avg Loss: 159.6639\n",
            "Epoch [36/50] - Batch loss: 157.7482 - Epoch Loss: 42149.3589 - Avg Loss: 159.6567\n",
            "Epoch [36/50] - Batch loss: 168.4611 - Epoch Loss: 42317.8199 - Avg Loss: 159.6899\n",
            "Epoch [36/50] - Batch loss: 161.5895 - Epoch Loss: 42479.4094 - Avg Loss: 159.6970\n",
            "Epoch [36/50] - Batch loss: 159.0099 - Epoch Loss: 42638.4194 - Avg Loss: 159.6945\n",
            "Epoch [36/50] - Batch loss: 159.3822 - Epoch Loss: 42797.8016 - Avg Loss: 159.6933\n",
            "Epoch [36/50] - Batch loss: 161.7764 - Epoch Loss: 42959.5780 - Avg Loss: 159.7010\n",
            "Epoch [36/50] - Batch loss: 168.1961 - Epoch Loss: 43127.7741 - Avg Loss: 159.7325\n",
            "Epoch [36/50] - Batch loss: 159.7589 - Epoch Loss: 43287.5330 - Avg Loss: 159.7326\n",
            "Epoch [36/50] - Batch loss: 160.5461 - Epoch Loss: 43448.0791 - Avg Loss: 159.7356\n",
            "Epoch [36/50] - Batch loss: 158.8430 - Epoch Loss: 43606.9220 - Avg Loss: 159.7323\n",
            "Epoch [36/50] - Batch loss: 167.2440 - Epoch Loss: 43774.1660 - Avg Loss: 159.7597\n",
            "Epoch [36/50] - Batch loss: 163.1772 - Epoch Loss: 43937.3432 - Avg Loss: 159.7722\n",
            "Epoch [36/50] - Batch loss: 160.3580 - Epoch Loss: 44097.7012 - Avg Loss: 159.7743\n",
            "Epoch [36/50] - Batch loss: 162.3333 - Epoch Loss: 44260.0345 - Avg Loss: 159.7835\n",
            "Epoch [36/50] - Batch loss: 162.8957 - Epoch Loss: 44422.9302 - Avg Loss: 159.7947\n",
            "Epoch [36/50] - Batch loss: 165.7967 - Epoch Loss: 44588.7269 - Avg Loss: 159.8162\n",
            "Epoch [36/50] - Batch loss: 164.5323 - Epoch Loss: 44753.2591 - Avg Loss: 159.8331\n",
            "Epoch [36/50] - Batch loss: 153.6773 - Epoch Loss: 44906.9365 - Avg Loss: 159.8112\n",
            "Epoch [36/50] - Batch loss: 161.6448 - Epoch Loss: 45068.5813 - Avg Loss: 159.8177\n",
            "Epoch [36/50] - Batch loss: 155.9439 - Epoch Loss: 45224.5252 - Avg Loss: 159.8040\n",
            "Epoch [36/50] - Batch loss: 150.9329 - Epoch Loss: 45375.4581 - Avg Loss: 159.7727\n",
            "Epoch [36/50] - Batch loss: 161.2583 - Epoch Loss: 45536.7163 - Avg Loss: 159.7780\n",
            "Epoch [36/50] - Batch loss: 155.1147 - Epoch Loss: 45691.8310 - Avg Loss: 159.7616\n",
            "Epoch [36/50] - Batch loss: 154.2400 - Epoch Loss: 45846.0710 - Avg Loss: 159.7424\n",
            "Epoch [36/50] - Batch loss: 170.4859 - Epoch Loss: 46016.5569 - Avg Loss: 159.7797\n",
            "Epoch [36/50] - Batch loss: 162.7885 - Epoch Loss: 46179.3453 - Avg Loss: 159.7901\n",
            "Epoch [36/50] - Batch loss: 156.7830 - Epoch Loss: 46336.1283 - Avg Loss: 159.7798\n",
            "Epoch [36/50] - Batch loss: 163.3649 - Epoch Loss: 46499.4931 - Avg Loss: 159.7921\n",
            "Epoch [36/50] - Batch loss: 167.2991 - Epoch Loss: 46666.7923 - Avg Loss: 159.8178\n",
            "Epoch [36/50] - Batch loss: 164.7726 - Epoch Loss: 46831.5649 - Avg Loss: 159.8347\n",
            "Epoch [36/50] - Batch loss: 164.6191 - Epoch Loss: 46996.1840 - Avg Loss: 159.8510\n",
            "Epoch [36/50] - Batch loss: 149.5334 - Epoch Loss: 47145.7174 - Avg Loss: 159.8160\n",
            "Epoch [36/50] - Batch loss: 156.9302 - Epoch Loss: 47302.6476 - Avg Loss: 159.8062\n",
            "Epoch [36/50] - Batch loss: 159.5019 - Epoch Loss: 47462.1494 - Avg Loss: 159.8052\n",
            "Epoch [36/50] - Batch loss: 159.8501 - Epoch Loss: 47621.9996 - Avg Loss: 159.8054\n",
            "Epoch [36/50] - Batch loss: 156.0600 - Epoch Loss: 47778.0596 - Avg Loss: 159.7928\n",
            "Epoch [36/50] - Batch loss: 155.4879 - Epoch Loss: 47933.5475 - Avg Loss: 159.7785\n",
            "Epoch [36/50] - Batch loss: 166.2651 - Epoch Loss: 48099.8126 - Avg Loss: 159.8000\n",
            "Epoch [36/50] - Batch loss: 161.1551 - Epoch Loss: 48260.9677 - Avg Loss: 159.8045\n",
            "Epoch [36/50] - Batch loss: 160.7195 - Epoch Loss: 48421.6872 - Avg Loss: 159.8075\n",
            "Epoch [36/50] - Batch loss: 161.9657 - Epoch Loss: 48583.6529 - Avg Loss: 159.8146\n",
            "Epoch [36/50] - Batch loss: 157.4447 - Epoch Loss: 48741.0976 - Avg Loss: 159.8069\n",
            "Epoch [36/50] - Batch loss: 155.4948 - Epoch Loss: 48896.5924 - Avg Loss: 159.7928\n",
            "Epoch [36/50] - Batch loss: 161.5901 - Epoch Loss: 49058.1825 - Avg Loss: 159.7986\n",
            "Epoch [36/50] - Batch loss: 155.0955 - Epoch Loss: 49213.2780 - Avg Loss: 159.7834\n",
            "Epoch [36/50] - Batch loss: 162.8250 - Epoch Loss: 49376.1030 - Avg Loss: 159.7932\n",
            "Epoch [36/50] - Batch loss: 154.3599 - Epoch Loss: 49530.4629 - Avg Loss: 159.7757\n",
            "Epoch [36/50] - Batch loss: 167.0233 - Epoch Loss: 49697.4862 - Avg Loss: 159.7990\n",
            "Epoch [36/50] - Batch loss: 164.7237 - Epoch Loss: 49862.2099 - Avg Loss: 159.8148\n",
            "Epoch [36/50] - Batch loss: 165.1588 - Epoch Loss: 50027.3687 - Avg Loss: 159.8318\n",
            "Epoch [36/50] - Batch loss: 163.5136 - Epoch Loss: 50190.8824 - Avg Loss: 159.8436\n",
            "Epoch [36/50] - Batch loss: 156.9376 - Epoch Loss: 50347.8200 - Avg Loss: 159.8343\n",
            "Epoch [36/50] - Batch loss: 160.4682 - Epoch Loss: 50508.2881 - Avg Loss: 159.8364\n",
            "Epoch [36/50] - Batch loss: 153.2406 - Epoch Loss: 50661.5287 - Avg Loss: 159.8155\n",
            "Epoch [36/50] - Batch loss: 157.2227 - Epoch Loss: 50818.7515 - Avg Loss: 159.8074\n",
            "Epoch [36/50] - Batch loss: 156.3015 - Epoch Loss: 50975.0529 - Avg Loss: 159.7964\n",
            "Epoch [36/50] - Batch loss: 162.6329 - Epoch Loss: 51137.6859 - Avg Loss: 159.8053\n",
            "Epoch [36/50] - Batch loss: 159.9227 - Epoch Loss: 51297.6086 - Avg Loss: 159.8056\n",
            "Epoch [36/50] - Batch loss: 151.7057 - Epoch Loss: 51449.3144 - Avg Loss: 159.7805\n",
            "Epoch [36/50] - Batch loss: 160.6892 - Epoch Loss: 51610.0036 - Avg Loss: 159.7833\n",
            "Epoch [36/50] - Batch loss: 158.9458 - Epoch Loss: 51768.9494 - Avg Loss: 159.7807\n",
            "Epoch [36/50] - Batch loss: 164.8127 - Epoch Loss: 51933.7620 - Avg Loss: 159.7962\n",
            "Epoch [36/50] - Batch loss: 156.6978 - Epoch Loss: 52090.4598 - Avg Loss: 159.7867\n",
            "Epoch [36/50] - Batch loss: 159.1907 - Epoch Loss: 52249.6505 - Avg Loss: 159.7849\n",
            "Epoch [36/50] - Batch loss: 157.0216 - Epoch Loss: 52406.6721 - Avg Loss: 159.7764\n",
            "Epoch [36/50] - Batch loss: 161.7627 - Epoch Loss: 52568.4348 - Avg Loss: 159.7825\n",
            "Epoch [36/50] - Batch loss: 159.3419 - Epoch Loss: 52727.7766 - Avg Loss: 159.7811\n",
            "Epoch [36/50] - Batch loss: 167.3261 - Epoch Loss: 52895.1027 - Avg Loss: 159.8039\n",
            "Epoch [36/50] - Batch loss: 158.7522 - Epoch Loss: 53053.8548 - Avg Loss: 159.8008\n",
            "Epoch [36/50] - Batch loss: 153.9892 - Epoch Loss: 53207.8440 - Avg Loss: 159.7833\n",
            "Epoch [36/50] - Batch loss: 160.5597 - Epoch Loss: 53368.4037 - Avg Loss: 159.7856\n",
            "Epoch [36/50] - Batch loss: 163.0457 - Epoch Loss: 53531.4494 - Avg Loss: 159.7954\n",
            "Epoch [36/50] - Batch loss: 160.0521 - Epoch Loss: 53691.5015 - Avg Loss: 159.7961\n",
            "Epoch [36/50] - Batch loss: 160.1176 - Epoch Loss: 53851.6191 - Avg Loss: 159.7971\n",
            "Epoch [36/50] - Batch loss: 158.0329 - Epoch Loss: 54009.6520 - Avg Loss: 159.7919\n",
            "Epoch [36/50] - Batch loss: 164.0911 - Epoch Loss: 54173.7431 - Avg Loss: 159.8046\n",
            "Epoch [36/50] - Batch loss: 165.7982 - Epoch Loss: 54339.5413 - Avg Loss: 159.8222\n",
            "Epoch [36/50] - Batch loss: 160.8277 - Epoch Loss: 54500.3690 - Avg Loss: 159.8251\n",
            "Epoch [36/50] - Batch loss: 157.1942 - Epoch Loss: 54657.5632 - Avg Loss: 159.8174\n",
            "Epoch [36/50] - Batch loss: 161.3578 - Epoch Loss: 54818.9210 - Avg Loss: 159.8219\n",
            "Epoch [36/50] - Batch loss: 154.4986 - Epoch Loss: 54973.4196 - Avg Loss: 159.8065\n",
            "Epoch [36/50] - Batch loss: 149.1289 - Epoch Loss: 55122.5485 - Avg Loss: 159.7755\n",
            "Epoch [36/50] - Batch loss: 160.2327 - Epoch Loss: 55282.7811 - Avg Loss: 159.7768\n",
            "Epoch [36/50] - Batch loss: 153.4601 - Epoch Loss: 55436.2413 - Avg Loss: 159.7586\n",
            "Epoch [36/50] - Batch loss: 156.6018 - Epoch Loss: 55592.8430 - Avg Loss: 159.7495\n",
            "Epoch [36/50] - Batch loss: 155.3909 - Epoch Loss: 55748.2340 - Avg Loss: 159.7371\n",
            "Epoch [36/50] - Batch loss: 161.7243 - Epoch Loss: 55909.9583 - Avg Loss: 159.7427\n",
            "Epoch [36/50] - Batch loss: 162.4312 - Epoch Loss: 56072.3895 - Avg Loss: 159.7504\n",
            "Epoch [36/50] - Batch loss: 153.4570 - Epoch Loss: 56225.8466 - Avg Loss: 159.7325\n",
            "Epoch [36/50] - Batch loss: 161.3123 - Epoch Loss: 56387.1589 - Avg Loss: 159.7370\n",
            "Epoch [36/50] - Batch loss: 159.6755 - Epoch Loss: 56546.8344 - Avg Loss: 159.7368\n",
            "Epoch [36/50] - Batch loss: 168.9052 - Epoch Loss: 56715.7396 - Avg Loss: 159.7626\n",
            "Epoch [36/50] - Batch loss: 160.2848 - Epoch Loss: 56876.0244 - Avg Loss: 159.7641\n",
            "Epoch [36/50] - Batch loss: 163.2130 - Epoch Loss: 57039.2374 - Avg Loss: 159.7738\n",
            "Epoch [36/50] - Batch loss: 152.5175 - Epoch Loss: 57191.7549 - Avg Loss: 159.7535\n",
            "Epoch [36/50] - Batch loss: 147.1840 - Epoch Loss: 57338.9390 - Avg Loss: 159.7185\n",
            "Epoch [36/50] - Batch loss: 160.5632 - Epoch Loss: 57499.5022 - Avg Loss: 159.7208\n",
            "Epoch [36/50] - Batch loss: 161.4098 - Epoch Loss: 57660.9120 - Avg Loss: 159.7255\n",
            "Epoch [36/50] - Batch loss: 160.1273 - Epoch Loss: 57821.0393 - Avg Loss: 159.7266\n",
            "Epoch [36/50] - Batch loss: 158.1574 - Epoch Loss: 57979.1968 - Avg Loss: 159.7223\n",
            "Epoch [36/50] - Batch loss: 164.8715 - Epoch Loss: 58144.0683 - Avg Loss: 159.7365\n",
            "Epoch [36/50] - Batch loss: 152.4216 - Epoch Loss: 58296.4899 - Avg Loss: 159.7164\n",
            "Epoch [36/50] - Batch loss: 156.0441 - Epoch Loss: 58452.5340 - Avg Loss: 159.7064\n",
            "Epoch [36/50] - Batch loss: 150.0185 - Epoch Loss: 58602.5525 - Avg Loss: 159.6800\n",
            "Epoch [36/50] - Batch loss: 155.1025 - Epoch Loss: 58757.6550 - Avg Loss: 159.6675\n",
            "Epoch [36/50] - Batch loss: 155.4084 - Epoch Loss: 58913.0634 - Avg Loss: 159.6560\n",
            "Epoch [36/50] - Batch loss: 155.4373 - Epoch Loss: 59068.5007 - Avg Loss: 159.6446\n",
            "Epoch [36/50] - Batch loss: 155.2683 - Epoch Loss: 59223.7690 - Avg Loss: 159.6328\n",
            "Epoch [36/50] - Batch loss: 159.9876 - Epoch Loss: 59383.7566 - Avg Loss: 159.6338\n",
            "Epoch [36/50] - Batch loss: 157.6573 - Epoch Loss: 59541.4139 - Avg Loss: 159.6285\n",
            "Epoch [36/50] - Batch loss: 161.8154 - Epoch Loss: 59703.2292 - Avg Loss: 159.6343\n",
            "Epoch [36/50] - Batch loss: 155.3431 - Epoch Loss: 59858.5723 - Avg Loss: 159.6229\n",
            "Epoch [36/50] - Batch loss: 149.7654 - Epoch Loss: 60008.3378 - Avg Loss: 159.5966\n",
            "Epoch [36/50] - Batch loss: 159.7961 - Epoch Loss: 60168.1339 - Avg Loss: 159.5972\n",
            "Epoch [36/50] - Batch loss: 157.2003 - Epoch Loss: 60325.3342 - Avg Loss: 159.5908\n",
            "Epoch [36/50] - Batch loss: 151.7903 - Epoch Loss: 60477.1245 - Avg Loss: 159.5702\n",
            "Epoch [36/50] - Batch loss: 154.1102 - Epoch Loss: 60631.2346 - Avg Loss: 159.5559\n",
            "Epoch [36/50] - Batch loss: 152.2788 - Epoch Loss: 60783.5135 - Avg Loss: 159.5368\n",
            "Epoch [36/50] - Batch loss: 156.8497 - Epoch Loss: 60940.3632 - Avg Loss: 159.5297\n",
            "Epoch [36/50] - Batch loss: 152.0975 - Epoch Loss: 61092.4607 - Avg Loss: 159.5103\n",
            "Epoch [36/50] - Batch loss: 158.2215 - Epoch Loss: 61250.6822 - Avg Loss: 159.5070\n",
            "Epoch [36/50] - Batch loss: 160.0605 - Epoch Loss: 61410.7427 - Avg Loss: 159.5084\n",
            "Epoch [36/50] - Batch loss: 158.1811 - Epoch Loss: 61568.9238 - Avg Loss: 159.5050\n",
            "Epoch [36/50] - Batch loss: 156.2225 - Epoch Loss: 61725.1463 - Avg Loss: 159.4965\n",
            "Epoch [36/50] - Batch loss: 160.4124 - Epoch Loss: 61885.5587 - Avg Loss: 159.4989\n",
            "Epoch [36/50] - Batch loss: 161.3340 - Epoch Loss: 62046.8926 - Avg Loss: 159.5036\n",
            "Epoch [36/50] - Batch loss: 160.5374 - Epoch Loss: 62207.4300 - Avg Loss: 159.5062\n",
            "Epoch [36/50] - Batch loss: 158.1929 - Epoch Loss: 62365.6229 - Avg Loss: 159.5029\n",
            "Epoch [36/50] - Batch loss: 157.7788 - Epoch Loss: 62523.4016 - Avg Loss: 159.4985\n",
            "Epoch [36/50] - Batch loss: 157.6859 - Epoch Loss: 62681.0875 - Avg Loss: 159.4939\n",
            "Epoch [36/50] - Batch loss: 152.1182 - Epoch Loss: 62833.2057 - Avg Loss: 159.4751\n",
            "Epoch [36/50] - Batch loss: 154.7534 - Epoch Loss: 62987.9591 - Avg Loss: 159.4632\n",
            "Epoch [36/50] - Batch loss: 156.5186 - Epoch Loss: 63144.4777 - Avg Loss: 159.4558\n",
            "Epoch [36/50] - Batch loss: 162.4036 - Epoch Loss: 63306.8813 - Avg Loss: 159.4632\n",
            "Epoch [36/50] - Batch loss: 155.5669 - Epoch Loss: 63462.4482 - Avg Loss: 159.4534\n",
            "Epoch [36/50] - Batch loss: 163.3277 - Epoch Loss: 63625.7759 - Avg Loss: 159.4631\n",
            "Epoch [36/50] - Batch loss: 165.5836 - Epoch Loss: 63791.3596 - Avg Loss: 159.4784\n",
            "Epoch [36/50] - Batch loss: 153.3134 - Epoch Loss: 63944.6729 - Avg Loss: 159.4630\n",
            "Epoch [36/50] - Batch loss: 159.9382 - Epoch Loss: 64104.6112 - Avg Loss: 159.4642\n",
            "Epoch [36/50] - Batch loss: 157.4244 - Epoch Loss: 64262.0356 - Avg Loss: 159.4591\n",
            "Epoch [36/50] - Batch loss: 160.1545 - Epoch Loss: 64422.1900 - Avg Loss: 159.4609\n",
            "Epoch [36/50] - Batch loss: 153.8967 - Epoch Loss: 64576.0868 - Avg Loss: 159.4471\n",
            "Epoch [36/50] - Batch loss: 153.1361 - Epoch Loss: 64729.2229 - Avg Loss: 159.4316\n",
            "Epoch [36/50] - Batch loss: 156.8446 - Epoch Loss: 64886.0675 - Avg Loss: 159.4252\n",
            "Epoch [36/50] - Batch loss: 159.0326 - Epoch Loss: 65045.1001 - Avg Loss: 159.4243\n",
            "Epoch [36/50] - Batch loss: 164.1851 - Epoch Loss: 65209.2852 - Avg Loss: 159.4359\n",
            "Epoch [36/50] - Batch loss: 149.0076 - Epoch Loss: 65358.2927 - Avg Loss: 159.4105\n",
            "Epoch [36/50] - Batch loss: 154.5884 - Epoch Loss: 65512.8811 - Avg Loss: 159.3987\n",
            "Epoch [36/50] - Batch loss: 155.1014 - Epoch Loss: 65667.9826 - Avg Loss: 159.3883\n",
            "Epoch [36/50] - Batch loss: 165.7218 - Epoch Loss: 65833.7044 - Avg Loss: 159.4036\n",
            "Epoch [36/50] - Batch loss: 161.8875 - Epoch Loss: 65995.5919 - Avg Loss: 159.4096\n",
            "Epoch [36/50] - Batch loss: 155.9396 - Epoch Loss: 66151.5315 - Avg Loss: 159.4013\n",
            "Epoch [36/50] - Batch loss: 154.0350 - Epoch Loss: 66305.5665 - Avg Loss: 159.3884\n",
            "Epoch [36/50] - Batch loss: 153.8196 - Epoch Loss: 66459.3861 - Avg Loss: 159.3750\n",
            "Epoch [36/50] - Batch loss: 149.1609 - Epoch Loss: 66608.5470 - Avg Loss: 159.3506\n",
            "Epoch [36/50] - Batch loss: 161.0892 - Epoch Loss: 66769.6362 - Avg Loss: 159.3547\n",
            "Epoch [36/50] - Batch loss: 159.8119 - Epoch Loss: 66929.4481 - Avg Loss: 159.3558\n",
            "Epoch [36/50] - Batch loss: 164.8105 - Epoch Loss: 67094.2586 - Avg Loss: 159.3688\n",
            "Epoch [36/50] - Batch loss: 156.5446 - Epoch Loss: 67250.8032 - Avg Loss: 159.3621\n",
            "Epoch [36/50] - Batch loss: 151.4950 - Epoch Loss: 67402.2982 - Avg Loss: 159.3435\n",
            "Epoch [36/50] - Batch loss: 163.4761 - Epoch Loss: 67565.7743 - Avg Loss: 159.3532\n",
            "Epoch [36/50] - Batch loss: 154.7889 - Epoch Loss: 67720.5632 - Avg Loss: 159.3425\n",
            "Epoch [36/50] - Batch loss: 163.8368 - Epoch Loss: 67884.4000 - Avg Loss: 159.3531\n",
            "Epoch [36/50] - Batch loss: 158.2941 - Epoch Loss: 68042.6941 - Avg Loss: 159.3506\n",
            "Epoch [36/50] - Batch loss: 156.3589 - Epoch Loss: 68199.0530 - Avg Loss: 159.3436\n",
            "Epoch [36/50] - Batch loss: 150.9620 - Epoch Loss: 68350.0150 - Avg Loss: 159.3240\n",
            "Epoch [36/50] - Batch loss: 147.9722 - Epoch Loss: 68497.9872 - Avg Loss: 159.2976\n",
            "Epoch [36/50] - Batch loss: 153.3173 - Epoch Loss: 68651.3045 - Avg Loss: 159.2838\n",
            "Epoch [36/50] - Batch loss: 145.2093 - Epoch Loss: 68796.5137 - Avg Loss: 159.2512\n",
            "Epoch [36/50] - Batch loss: 151.6041 - Epoch Loss: 68948.1178 - Avg Loss: 159.2335\n",
            "Epoch [36/50] - Batch loss: 156.2700 - Epoch Loss: 69104.3878 - Avg Loss: 159.2267\n",
            "Epoch [36/50] - Batch loss: 155.6504 - Epoch Loss: 69260.0382 - Avg Loss: 159.2185\n",
            "Epoch [36/50] - Batch loss: 163.8695 - Epoch Loss: 69423.9076 - Avg Loss: 159.2291\n",
            "Epoch [36/50] - Batch loss: 157.8026 - Epoch Loss: 69581.7102 - Avg Loss: 159.2259\n",
            "Epoch [36/50] - Batch loss: 157.5001 - Epoch Loss: 69739.2103 - Avg Loss: 159.2219\n",
            "Epoch [36/50] - Batch loss: 162.5922 - Epoch Loss: 69901.8025 - Avg Loss: 159.2296\n",
            "Epoch [36/50] - Batch loss: 165.1269 - Epoch Loss: 70066.9295 - Avg Loss: 159.2430\n",
            "Epoch [36/50] - Batch loss: 166.4690 - Epoch Loss: 70233.3985 - Avg Loss: 159.2594\n",
            "Epoch [36/50] - Batch loss: 154.3058 - Epoch Loss: 70387.7043 - Avg Loss: 159.2482\n",
            "Epoch [36/50] - Batch loss: 154.0445 - Epoch Loss: 70541.7488 - Avg Loss: 159.2365\n",
            "Epoch [36/50] - Batch loss: 154.5353 - Epoch Loss: 70696.2841 - Avg Loss: 159.2259\n",
            "Epoch [36/50] - Batch loss: 156.4577 - Epoch Loss: 70852.7419 - Avg Loss: 159.2196\n",
            "Epoch [36/50] - Batch loss: 149.6212 - Epoch Loss: 71002.3630 - Avg Loss: 159.1981\n",
            "Epoch [36/50] - Batch loss: 153.5824 - Epoch Loss: 71155.9454 - Avg Loss: 159.1856\n",
            "Epoch [36/50] - Batch loss: 144.7682 - Epoch Loss: 71300.7136 - Avg Loss: 159.1534\n",
            "Epoch [36/50] - Batch loss: 155.6342 - Epoch Loss: 71456.3478 - Avg Loss: 159.1455\n",
            "Epoch [36/50] - Batch loss: 153.7351 - Epoch Loss: 71610.0828 - Avg Loss: 159.1335\n",
            "Epoch [36/50] - Batch loss: 155.9854 - Epoch Loss: 71766.0682 - Avg Loss: 159.1265\n",
            "Epoch [36/50] - Batch loss: 155.9632 - Epoch Loss: 71922.0314 - Avg Loss: 159.1195\n",
            "Epoch [36/50] - Batch loss: 157.4268 - Epoch Loss: 72079.4582 - Avg Loss: 159.1158\n",
            "Epoch [36/50] - Batch loss: 157.3741 - Epoch Loss: 72236.8324 - Avg Loss: 159.1120\n",
            "Epoch [36/50] - Batch loss: 152.5493 - Epoch Loss: 72389.3817 - Avg Loss: 159.0975\n",
            "Epoch [36/50] - Batch loss: 160.8716 - Epoch Loss: 72550.2533 - Avg Loss: 159.1014\n",
            "Epoch [36/50] - Batch loss: 165.7580 - Epoch Loss: 72716.0113 - Avg Loss: 159.1160\n",
            "Epoch [36/50] - Batch loss: 158.0966 - Epoch Loss: 72874.1080 - Avg Loss: 159.1138\n",
            "Epoch [36/50] - Batch loss: 146.2069 - Epoch Loss: 73020.3149 - Avg Loss: 159.0857\n",
            "Epoch [36/50] - Batch loss: 157.3742 - Epoch Loss: 73177.6891 - Avg Loss: 159.0819\n",
            "Epoch [36/50] - Batch loss: 158.3615 - Epoch Loss: 73336.0505 - Avg Loss: 159.0804\n",
            "Epoch [36/50] - Batch loss: 158.0444 - Epoch Loss: 73494.0949 - Avg Loss: 159.0781\n",
            "Epoch [36/50] - Batch loss: 156.0714 - Epoch Loss: 73650.1663 - Avg Loss: 159.0716\n",
            "Epoch [36/50] - Batch loss: 146.7358 - Epoch Loss: 73796.9021 - Avg Loss: 159.0450\n",
            "Epoch [36/50] - Batch loss: 163.0161 - Epoch Loss: 73959.9181 - Avg Loss: 159.0536\n",
            "Epoch [36/50] - Batch loss: 156.7578 - Epoch Loss: 74116.6759 - Avg Loss: 159.0487\n",
            "Epoch [36/50] - Batch loss: 161.7602 - Epoch Loss: 74278.4360 - Avg Loss: 159.0545\n",
            "Epoch [36/50] - Batch loss: 164.2225 - Epoch Loss: 74442.6585 - Avg Loss: 159.0655\n",
            "Epoch [36/50] - Batch loss: 165.9162 - Epoch Loss: 74608.5747 - Avg Loss: 159.0801\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 37/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "615dfa53fde64eff945eb1493c75bd1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [37/50] - Batch loss: 154.9072 - Epoch Loss: 154.9072 - Avg Loss: 154.9072\n",
            "Epoch [37/50] - Batch loss: 160.0745 - Epoch Loss: 314.9817 - Avg Loss: 157.4908\n",
            "Epoch [37/50] - Batch loss: 155.1561 - Epoch Loss: 470.1378 - Avg Loss: 156.7126\n",
            "Epoch [37/50] - Batch loss: 162.8775 - Epoch Loss: 633.0153 - Avg Loss: 158.2538\n",
            "Epoch [37/50] - Batch loss: 160.0939 - Epoch Loss: 793.1092 - Avg Loss: 158.6218\n",
            "Epoch [37/50] - Batch loss: 153.6243 - Epoch Loss: 946.7334 - Avg Loss: 157.7889\n",
            "Epoch [37/50] - Batch loss: 148.6150 - Epoch Loss: 1095.3484 - Avg Loss: 156.4783\n",
            "Epoch [37/50] - Batch loss: 160.3342 - Epoch Loss: 1255.6826 - Avg Loss: 156.9603\n",
            "Epoch [37/50] - Batch loss: 162.9249 - Epoch Loss: 1418.6076 - Avg Loss: 157.6231\n",
            "Epoch [37/50] - Batch loss: 155.2572 - Epoch Loss: 1573.8648 - Avg Loss: 157.3865\n",
            "Epoch [37/50] - Batch loss: 167.4005 - Epoch Loss: 1741.2653 - Avg Loss: 158.2968\n",
            "Epoch [37/50] - Batch loss: 158.1870 - Epoch Loss: 1899.4523 - Avg Loss: 158.2877\n",
            "Epoch [37/50] - Batch loss: 155.3973 - Epoch Loss: 2054.8495 - Avg Loss: 158.0653\n",
            "Epoch [37/50] - Batch loss: 159.1760 - Epoch Loss: 2214.0256 - Avg Loss: 158.1447\n",
            "Epoch [37/50] - Batch loss: 149.3087 - Epoch Loss: 2363.3343 - Avg Loss: 157.5556\n",
            "Epoch [37/50] - Batch loss: 158.9205 - Epoch Loss: 2522.2549 - Avg Loss: 157.6409\n",
            "Epoch [37/50] - Batch loss: 156.4469 - Epoch Loss: 2678.7017 - Avg Loss: 157.5707\n",
            "Epoch [37/50] - Batch loss: 162.1296 - Epoch Loss: 2840.8314 - Avg Loss: 157.8240\n",
            "Epoch [37/50] - Batch loss: 155.9570 - Epoch Loss: 2996.7883 - Avg Loss: 157.7257\n",
            "Epoch [37/50] - Batch loss: 155.8540 - Epoch Loss: 3152.6423 - Avg Loss: 157.6321\n",
            "Epoch [37/50] - Batch loss: 164.5371 - Epoch Loss: 3317.1794 - Avg Loss: 157.9609\n",
            "Epoch [37/50] - Batch loss: 158.2569 - Epoch Loss: 3475.4363 - Avg Loss: 157.9744\n",
            "Epoch [37/50] - Batch loss: 161.3008 - Epoch Loss: 3636.7372 - Avg Loss: 158.1190\n",
            "Epoch [37/50] - Batch loss: 161.0033 - Epoch Loss: 3797.7404 - Avg Loss: 158.2392\n",
            "Epoch [37/50] - Batch loss: 162.1238 - Epoch Loss: 3959.8642 - Avg Loss: 158.3946\n",
            "Epoch [37/50] - Batch loss: 160.5048 - Epoch Loss: 4120.3690 - Avg Loss: 158.4757\n",
            "Epoch [37/50] - Batch loss: 156.0848 - Epoch Loss: 4276.4538 - Avg Loss: 158.3872\n",
            "Epoch [37/50] - Batch loss: 154.7798 - Epoch Loss: 4431.2336 - Avg Loss: 158.2583\n",
            "Epoch [37/50] - Batch loss: 162.2111 - Epoch Loss: 4593.4447 - Avg Loss: 158.3946\n",
            "Epoch [37/50] - Batch loss: 154.8968 - Epoch Loss: 4748.3414 - Avg Loss: 158.2780\n",
            "Epoch [37/50] - Batch loss: 155.1960 - Epoch Loss: 4903.5375 - Avg Loss: 158.1786\n",
            "Epoch [37/50] - Batch loss: 160.9376 - Epoch Loss: 5064.4751 - Avg Loss: 158.2648\n",
            "Epoch [37/50] - Batch loss: 157.2219 - Epoch Loss: 5221.6970 - Avg Loss: 158.2332\n",
            "Epoch [37/50] - Batch loss: 152.5289 - Epoch Loss: 5374.2259 - Avg Loss: 158.0655\n",
            "Epoch [37/50] - Batch loss: 166.6400 - Epoch Loss: 5540.8659 - Avg Loss: 158.3105\n",
            "Epoch [37/50] - Batch loss: 150.6146 - Epoch Loss: 5691.4805 - Avg Loss: 158.0967\n",
            "Epoch [37/50] - Batch loss: 154.0987 - Epoch Loss: 5845.5792 - Avg Loss: 157.9886\n",
            "Epoch [37/50] - Batch loss: 158.4907 - Epoch Loss: 6004.0699 - Avg Loss: 158.0018\n",
            "Epoch [37/50] - Batch loss: 156.9689 - Epoch Loss: 6161.0388 - Avg Loss: 157.9754\n",
            "Epoch [37/50] - Batch loss: 160.1324 - Epoch Loss: 6321.1713 - Avg Loss: 158.0293\n",
            "Epoch [37/50] - Batch loss: 154.4241 - Epoch Loss: 6475.5954 - Avg Loss: 157.9414\n",
            "Epoch [37/50] - Batch loss: 157.5588 - Epoch Loss: 6633.1542 - Avg Loss: 157.9322\n",
            "Epoch [37/50] - Batch loss: 160.8466 - Epoch Loss: 6794.0007 - Avg Loss: 158.0000\n",
            "Epoch [37/50] - Batch loss: 155.7689 - Epoch Loss: 6949.7697 - Avg Loss: 157.9493\n",
            "Epoch [37/50] - Batch loss: 151.2610 - Epoch Loss: 7101.0307 - Avg Loss: 157.8007\n",
            "Epoch [37/50] - Batch loss: 158.3084 - Epoch Loss: 7259.3391 - Avg Loss: 157.8117\n",
            "Epoch [37/50] - Batch loss: 164.2960 - Epoch Loss: 7423.6351 - Avg Loss: 157.9497\n",
            "Epoch [37/50] - Batch loss: 172.6960 - Epoch Loss: 7596.3311 - Avg Loss: 158.2569\n",
            "Epoch [37/50] - Batch loss: 162.7403 - Epoch Loss: 7759.0714 - Avg Loss: 158.3484\n",
            "Epoch [37/50] - Batch loss: 146.8285 - Epoch Loss: 7905.8999 - Avg Loss: 158.1180\n",
            "Epoch [37/50] - Batch loss: 166.4739 - Epoch Loss: 8072.3738 - Avg Loss: 158.2818\n",
            "Epoch [37/50] - Batch loss: 153.8461 - Epoch Loss: 8226.2199 - Avg Loss: 158.1965\n",
            "Epoch [37/50] - Batch loss: 161.6809 - Epoch Loss: 8387.9008 - Avg Loss: 158.2623\n",
            "Epoch [37/50] - Batch loss: 157.6082 - Epoch Loss: 8545.5090 - Avg Loss: 158.2502\n",
            "Epoch [37/50] - Batch loss: 158.1593 - Epoch Loss: 8703.6682 - Avg Loss: 158.2485\n",
            "Epoch [37/50] - Batch loss: 157.3684 - Epoch Loss: 8861.0366 - Avg Loss: 158.2328\n",
            "Epoch [37/50] - Batch loss: 160.6450 - Epoch Loss: 9021.6816 - Avg Loss: 158.2751\n",
            "Epoch [37/50] - Batch loss: 154.9038 - Epoch Loss: 9176.5854 - Avg Loss: 158.2170\n",
            "Epoch [37/50] - Batch loss: 160.6168 - Epoch Loss: 9337.2021 - Avg Loss: 158.2577\n",
            "Epoch [37/50] - Batch loss: 166.7786 - Epoch Loss: 9503.9807 - Avg Loss: 158.3997\n",
            "Epoch [37/50] - Batch loss: 158.6947 - Epoch Loss: 9662.6755 - Avg Loss: 158.4045\n",
            "Epoch [37/50] - Batch loss: 153.6804 - Epoch Loss: 9816.3559 - Avg Loss: 158.3283\n",
            "Epoch [37/50] - Batch loss: 156.0985 - Epoch Loss: 9972.4544 - Avg Loss: 158.2929\n",
            "Epoch [37/50] - Batch loss: 168.6164 - Epoch Loss: 10141.0707 - Avg Loss: 158.4542\n",
            "Epoch [37/50] - Batch loss: 157.9356 - Epoch Loss: 10299.0063 - Avg Loss: 158.4463\n",
            "Epoch [37/50] - Batch loss: 155.3254 - Epoch Loss: 10454.3317 - Avg Loss: 158.3990\n",
            "Epoch [37/50] - Batch loss: 156.6204 - Epoch Loss: 10610.9520 - Avg Loss: 158.3724\n",
            "Epoch [37/50] - Batch loss: 160.6956 - Epoch Loss: 10771.6477 - Avg Loss: 158.4066\n",
            "Epoch [37/50] - Batch loss: 154.6992 - Epoch Loss: 10926.3469 - Avg Loss: 158.3529\n",
            "Epoch [37/50] - Batch loss: 158.6010 - Epoch Loss: 11084.9480 - Avg Loss: 158.3564\n",
            "Epoch [37/50] - Batch loss: 155.7707 - Epoch Loss: 11240.7187 - Avg Loss: 158.3200\n",
            "Epoch [37/50] - Batch loss: 154.3697 - Epoch Loss: 11395.0884 - Avg Loss: 158.2651\n",
            "Epoch [37/50] - Batch loss: 163.8234 - Epoch Loss: 11558.9118 - Avg Loss: 158.3413\n",
            "Epoch [37/50] - Batch loss: 156.6179 - Epoch Loss: 11715.5298 - Avg Loss: 158.3180\n",
            "Epoch [37/50] - Batch loss: 157.0027 - Epoch Loss: 11872.5325 - Avg Loss: 158.3004\n",
            "Epoch [37/50] - Batch loss: 160.3560 - Epoch Loss: 12032.8884 - Avg Loss: 158.3275\n",
            "Epoch [37/50] - Batch loss: 164.2791 - Epoch Loss: 12197.1675 - Avg Loss: 158.4048\n",
            "Epoch [37/50] - Batch loss: 166.3251 - Epoch Loss: 12363.4927 - Avg Loss: 158.5063\n",
            "Epoch [37/50] - Batch loss: 153.7680 - Epoch Loss: 12517.2607 - Avg Loss: 158.4463\n",
            "Epoch [37/50] - Batch loss: 154.5267 - Epoch Loss: 12671.7874 - Avg Loss: 158.3973\n",
            "Epoch [37/50] - Batch loss: 151.3043 - Epoch Loss: 12823.0917 - Avg Loss: 158.3098\n",
            "Epoch [37/50] - Batch loss: 162.0017 - Epoch Loss: 12985.0935 - Avg Loss: 158.3548\n",
            "Epoch [37/50] - Batch loss: 162.4258 - Epoch Loss: 13147.5193 - Avg Loss: 158.4038\n",
            "Epoch [37/50] - Batch loss: 155.7139 - Epoch Loss: 13303.2332 - Avg Loss: 158.3718\n",
            "Epoch [37/50] - Batch loss: 154.0551 - Epoch Loss: 13457.2883 - Avg Loss: 158.3210\n",
            "Epoch [37/50] - Batch loss: 165.5864 - Epoch Loss: 13622.8747 - Avg Loss: 158.4055\n",
            "Epoch [37/50] - Batch loss: 162.3016 - Epoch Loss: 13785.1763 - Avg Loss: 158.4503\n",
            "Epoch [37/50] - Batch loss: 150.9840 - Epoch Loss: 13936.1602 - Avg Loss: 158.3655\n",
            "Epoch [37/50] - Batch loss: 163.8319 - Epoch Loss: 14099.9921 - Avg Loss: 158.4269\n",
            "Epoch [37/50] - Batch loss: 161.3035 - Epoch Loss: 14261.2956 - Avg Loss: 158.4588\n",
            "Epoch [37/50] - Batch loss: 155.7277 - Epoch Loss: 14417.0233 - Avg Loss: 158.4288\n",
            "Epoch [37/50] - Batch loss: 152.2649 - Epoch Loss: 14569.2882 - Avg Loss: 158.3618\n",
            "Epoch [37/50] - Batch loss: 155.6726 - Epoch Loss: 14724.9608 - Avg Loss: 158.3329\n",
            "Epoch [37/50] - Batch loss: 156.8251 - Epoch Loss: 14881.7859 - Avg Loss: 158.3169\n",
            "Epoch [37/50] - Batch loss: 163.0118 - Epoch Loss: 15044.7977 - Avg Loss: 158.3663\n",
            "Epoch [37/50] - Batch loss: 164.6557 - Epoch Loss: 15209.4534 - Avg Loss: 158.4318\n",
            "Epoch [37/50] - Batch loss: 166.0680 - Epoch Loss: 15375.5214 - Avg Loss: 158.5105\n",
            "Epoch [37/50] - Batch loss: 156.6059 - Epoch Loss: 15532.1273 - Avg Loss: 158.4911\n",
            "Epoch [37/50] - Batch loss: 155.5608 - Epoch Loss: 15687.6881 - Avg Loss: 158.4615\n",
            "Epoch [37/50] - Batch loss: 161.4479 - Epoch Loss: 15849.1360 - Avg Loss: 158.4914\n",
            "Epoch [37/50] - Batch loss: 158.6686 - Epoch Loss: 16007.8046 - Avg Loss: 158.4931\n",
            "Epoch [37/50] - Batch loss: 163.0426 - Epoch Loss: 16170.8472 - Avg Loss: 158.5377\n",
            "Epoch [37/50] - Batch loss: 156.3665 - Epoch Loss: 16327.2137 - Avg Loss: 158.5166\n",
            "Epoch [37/50] - Batch loss: 160.0615 - Epoch Loss: 16487.2752 - Avg Loss: 158.5315\n",
            "Epoch [37/50] - Batch loss: 152.5146 - Epoch Loss: 16639.7897 - Avg Loss: 158.4742\n",
            "Epoch [37/50] - Batch loss: 158.9188 - Epoch Loss: 16798.7086 - Avg Loss: 158.4784\n",
            "Epoch [37/50] - Batch loss: 163.7243 - Epoch Loss: 16962.4329 - Avg Loss: 158.5274\n",
            "Epoch [37/50] - Batch loss: 160.2614 - Epoch Loss: 17122.6944 - Avg Loss: 158.5435\n",
            "Epoch [37/50] - Batch loss: 158.6926 - Epoch Loss: 17281.3870 - Avg Loss: 158.5448\n",
            "Epoch [37/50] - Batch loss: 153.9747 - Epoch Loss: 17435.3617 - Avg Loss: 158.5033\n",
            "Epoch [37/50] - Batch loss: 162.4666 - Epoch Loss: 17597.8282 - Avg Loss: 158.5390\n",
            "Epoch [37/50] - Batch loss: 168.8209 - Epoch Loss: 17766.6492 - Avg Loss: 158.6308\n",
            "Epoch [37/50] - Batch loss: 160.0261 - Epoch Loss: 17926.6752 - Avg Loss: 158.6431\n",
            "Epoch [37/50] - Batch loss: 158.8449 - Epoch Loss: 18085.5201 - Avg Loss: 158.6449\n",
            "Epoch [37/50] - Batch loss: 155.4293 - Epoch Loss: 18240.9494 - Avg Loss: 158.6170\n",
            "Epoch [37/50] - Batch loss: 154.3355 - Epoch Loss: 18395.2849 - Avg Loss: 158.5800\n",
            "Epoch [37/50] - Batch loss: 153.3049 - Epoch Loss: 18548.5898 - Avg Loss: 158.5350\n",
            "Epoch [37/50] - Batch loss: 153.3205 - Epoch Loss: 18701.9103 - Avg Loss: 158.4908\n",
            "Epoch [37/50] - Batch loss: 155.6897 - Epoch Loss: 18857.5999 - Avg Loss: 158.4672\n",
            "Epoch [37/50] - Batch loss: 158.6487 - Epoch Loss: 19016.2486 - Avg Loss: 158.4687\n",
            "Epoch [37/50] - Batch loss: 164.0648 - Epoch Loss: 19180.3134 - Avg Loss: 158.5150\n",
            "Epoch [37/50] - Batch loss: 161.3820 - Epoch Loss: 19341.6954 - Avg Loss: 158.5385\n",
            "Epoch [37/50] - Batch loss: 160.3744 - Epoch Loss: 19502.0697 - Avg Loss: 158.5534\n",
            "Epoch [37/50] - Batch loss: 150.6065 - Epoch Loss: 19652.6762 - Avg Loss: 158.4893\n",
            "Epoch [37/50] - Batch loss: 167.2547 - Epoch Loss: 19819.9310 - Avg Loss: 158.5594\n",
            "Epoch [37/50] - Batch loss: 158.4181 - Epoch Loss: 19978.3490 - Avg Loss: 158.5583\n",
            "Epoch [37/50] - Batch loss: 156.2017 - Epoch Loss: 20134.5507 - Avg Loss: 158.5398\n",
            "Epoch [37/50] - Batch loss: 153.1777 - Epoch Loss: 20287.7284 - Avg Loss: 158.4979\n",
            "Epoch [37/50] - Batch loss: 153.8210 - Epoch Loss: 20441.5494 - Avg Loss: 158.4616\n",
            "Epoch [37/50] - Batch loss: 155.3750 - Epoch Loss: 20596.9244 - Avg Loss: 158.4379\n",
            "Epoch [37/50] - Batch loss: 154.2746 - Epoch Loss: 20751.1990 - Avg Loss: 158.4061\n",
            "Epoch [37/50] - Batch loss: 157.3268 - Epoch Loss: 20908.5258 - Avg Loss: 158.3979\n",
            "Epoch [37/50] - Batch loss: 159.6498 - Epoch Loss: 21068.1756 - Avg Loss: 158.4073\n",
            "Epoch [37/50] - Batch loss: 152.4450 - Epoch Loss: 21220.6206 - Avg Loss: 158.3628\n",
            "Epoch [37/50] - Batch loss: 157.8434 - Epoch Loss: 21378.4640 - Avg Loss: 158.3590\n",
            "Epoch [37/50] - Batch loss: 165.3741 - Epoch Loss: 21543.8381 - Avg Loss: 158.4106\n",
            "Epoch [37/50] - Batch loss: 157.1229 - Epoch Loss: 21700.9609 - Avg Loss: 158.4012\n",
            "Epoch [37/50] - Batch loss: 162.9659 - Epoch Loss: 21863.9268 - Avg Loss: 158.4343\n",
            "Epoch [37/50] - Batch loss: 157.0070 - Epoch Loss: 22020.9338 - Avg Loss: 158.4240\n",
            "Epoch [37/50] - Batch loss: 148.7560 - Epoch Loss: 22169.6898 - Avg Loss: 158.3549\n",
            "Epoch [37/50] - Batch loss: 149.2711 - Epoch Loss: 22318.9609 - Avg Loss: 158.2905\n",
            "Epoch [37/50] - Batch loss: 160.8514 - Epoch Loss: 22479.8123 - Avg Loss: 158.3085\n",
            "Epoch [37/50] - Batch loss: 164.7410 - Epoch Loss: 22644.5532 - Avg Loss: 158.3535\n",
            "Epoch [37/50] - Batch loss: 169.9268 - Epoch Loss: 22814.4800 - Avg Loss: 158.4339\n",
            "Epoch [37/50] - Batch loss: 151.8313 - Epoch Loss: 22966.3113 - Avg Loss: 158.3884\n",
            "Epoch [37/50] - Batch loss: 161.2646 - Epoch Loss: 23127.5759 - Avg Loss: 158.4081\n",
            "Epoch [37/50] - Batch loss: 159.9794 - Epoch Loss: 23287.5552 - Avg Loss: 158.4187\n",
            "Epoch [37/50] - Batch loss: 164.7328 - Epoch Loss: 23452.2880 - Avg Loss: 158.4614\n",
            "Epoch [37/50] - Batch loss: 159.9284 - Epoch Loss: 23612.2164 - Avg Loss: 158.4713\n",
            "Epoch [37/50] - Batch loss: 159.7833 - Epoch Loss: 23771.9997 - Avg Loss: 158.4800\n",
            "Epoch [37/50] - Batch loss: 160.3137 - Epoch Loss: 23932.3135 - Avg Loss: 158.4921\n",
            "Epoch [37/50] - Batch loss: 161.7409 - Epoch Loss: 24094.0544 - Avg Loss: 158.5135\n",
            "Epoch [37/50] - Batch loss: 163.0731 - Epoch Loss: 24257.1275 - Avg Loss: 158.5433\n",
            "Epoch [37/50] - Batch loss: 154.5964 - Epoch Loss: 24411.7239 - Avg Loss: 158.5177\n",
            "Epoch [37/50] - Batch loss: 158.8244 - Epoch Loss: 24570.5483 - Avg Loss: 158.5197\n",
            "Epoch [37/50] - Batch loss: 151.7104 - Epoch Loss: 24722.2587 - Avg Loss: 158.4760\n",
            "Epoch [37/50] - Batch loss: 162.9829 - Epoch Loss: 24885.2416 - Avg Loss: 158.5047\n",
            "Epoch [37/50] - Batch loss: 159.2146 - Epoch Loss: 25044.4562 - Avg Loss: 158.5092\n",
            "Epoch [37/50] - Batch loss: 161.3850 - Epoch Loss: 25205.8412 - Avg Loss: 158.5273\n",
            "Epoch [37/50] - Batch loss: 156.6265 - Epoch Loss: 25362.4677 - Avg Loss: 158.5154\n",
            "Epoch [37/50] - Batch loss: 156.9812 - Epoch Loss: 25519.4490 - Avg Loss: 158.5059\n",
            "Epoch [37/50] - Batch loss: 154.7025 - Epoch Loss: 25674.1515 - Avg Loss: 158.4824\n",
            "Epoch [37/50] - Batch loss: 152.3767 - Epoch Loss: 25826.5282 - Avg Loss: 158.4450\n",
            "Epoch [37/50] - Batch loss: 155.0047 - Epoch Loss: 25981.5328 - Avg Loss: 158.4240\n",
            "Epoch [37/50] - Batch loss: 156.7374 - Epoch Loss: 26138.2702 - Avg Loss: 158.4138\n",
            "Epoch [37/50] - Batch loss: 149.5947 - Epoch Loss: 26287.8649 - Avg Loss: 158.3606\n",
            "Epoch [37/50] - Batch loss: 150.9683 - Epoch Loss: 26438.8332 - Avg Loss: 158.3164\n",
            "Epoch [37/50] - Batch loss: 149.2861 - Epoch Loss: 26588.1193 - Avg Loss: 158.2626\n",
            "Epoch [37/50] - Batch loss: 164.0115 - Epoch Loss: 26752.1308 - Avg Loss: 158.2966\n",
            "Epoch [37/50] - Batch loss: 162.9190 - Epoch Loss: 26915.0497 - Avg Loss: 158.3238\n",
            "Epoch [37/50] - Batch loss: 152.2005 - Epoch Loss: 27067.2503 - Avg Loss: 158.2880\n",
            "Epoch [37/50] - Batch loss: 154.5694 - Epoch Loss: 27221.8197 - Avg Loss: 158.2664\n",
            "Epoch [37/50] - Batch loss: 152.0820 - Epoch Loss: 27373.9018 - Avg Loss: 158.2306\n",
            "Epoch [37/50] - Batch loss: 164.4243 - Epoch Loss: 27538.3260 - Avg Loss: 158.2662\n",
            "Epoch [37/50] - Batch loss: 158.2281 - Epoch Loss: 27696.5542 - Avg Loss: 158.2660\n",
            "Epoch [37/50] - Batch loss: 157.0196 - Epoch Loss: 27853.5738 - Avg Loss: 158.2589\n",
            "Epoch [37/50] - Batch loss: 158.6426 - Epoch Loss: 28012.2164 - Avg Loss: 158.2611\n",
            "Epoch [37/50] - Batch loss: 159.1876 - Epoch Loss: 28171.4039 - Avg Loss: 158.2663\n",
            "Epoch [37/50] - Batch loss: 154.2323 - Epoch Loss: 28325.6362 - Avg Loss: 158.2438\n",
            "Epoch [37/50] - Batch loss: 156.1372 - Epoch Loss: 28481.7734 - Avg Loss: 158.2321\n",
            "Epoch [37/50] - Batch loss: 159.1978 - Epoch Loss: 28640.9712 - Avg Loss: 158.2374\n",
            "Epoch [37/50] - Batch loss: 166.1425 - Epoch Loss: 28807.1137 - Avg Loss: 158.2808\n",
            "Epoch [37/50] - Batch loss: 166.8926 - Epoch Loss: 28974.0063 - Avg Loss: 158.3279\n",
            "Epoch [37/50] - Batch loss: 161.7957 - Epoch Loss: 29135.8021 - Avg Loss: 158.3468\n",
            "Epoch [37/50] - Batch loss: 161.1046 - Epoch Loss: 29296.9066 - Avg Loss: 158.3617\n",
            "Epoch [37/50] - Batch loss: 155.8249 - Epoch Loss: 29452.7315 - Avg Loss: 158.3480\n",
            "Epoch [37/50] - Batch loss: 158.0584 - Epoch Loss: 29610.7899 - Avg Loss: 158.3465\n",
            "Epoch [37/50] - Batch loss: 153.2469 - Epoch Loss: 29764.0368 - Avg Loss: 158.3193\n",
            "Epoch [37/50] - Batch loss: 159.0829 - Epoch Loss: 29923.1197 - Avg Loss: 158.3234\n",
            "Epoch [37/50] - Batch loss: 159.7130 - Epoch Loss: 30082.8327 - Avg Loss: 158.3307\n",
            "Epoch [37/50] - Batch loss: 159.7089 - Epoch Loss: 30242.5416 - Avg Loss: 158.3379\n",
            "Epoch [37/50] - Batch loss: 156.6833 - Epoch Loss: 30399.2250 - Avg Loss: 158.3293\n",
            "Epoch [37/50] - Batch loss: 143.3335 - Epoch Loss: 30542.5585 - Avg Loss: 158.2516\n",
            "Epoch [37/50] - Batch loss: 156.3106 - Epoch Loss: 30698.8690 - Avg Loss: 158.2416\n",
            "Epoch [37/50] - Batch loss: 161.1220 - Epoch Loss: 30859.9911 - Avg Loss: 158.2564\n",
            "Epoch [37/50] - Batch loss: 156.2878 - Epoch Loss: 31016.2788 - Avg Loss: 158.2463\n",
            "Epoch [37/50] - Batch loss: 156.0422 - Epoch Loss: 31172.3211 - Avg Loss: 158.2351\n",
            "Epoch [37/50] - Batch loss: 152.5700 - Epoch Loss: 31324.8911 - Avg Loss: 158.2065\n",
            "Epoch [37/50] - Batch loss: 157.9266 - Epoch Loss: 31482.8177 - Avg Loss: 158.2051\n",
            "Epoch [37/50] - Batch loss: 149.3440 - Epoch Loss: 31632.1617 - Avg Loss: 158.1608\n",
            "Epoch [37/50] - Batch loss: 153.9074 - Epoch Loss: 31786.0691 - Avg Loss: 158.1396\n",
            "Epoch [37/50] - Batch loss: 154.4485 - Epoch Loss: 31940.5177 - Avg Loss: 158.1214\n",
            "Epoch [37/50] - Batch loss: 162.0822 - Epoch Loss: 32102.5999 - Avg Loss: 158.1409\n",
            "Epoch [37/50] - Batch loss: 157.9369 - Epoch Loss: 32260.5368 - Avg Loss: 158.1399\n",
            "Epoch [37/50] - Batch loss: 153.6358 - Epoch Loss: 32414.1726 - Avg Loss: 158.1179\n",
            "Epoch [37/50] - Batch loss: 159.2277 - Epoch Loss: 32573.4003 - Avg Loss: 158.1233\n",
            "Epoch [37/50] - Batch loss: 156.8896 - Epoch Loss: 32730.2899 - Avg Loss: 158.1173\n",
            "Epoch [37/50] - Batch loss: 152.2030 - Epoch Loss: 32882.4929 - Avg Loss: 158.0889\n",
            "Epoch [37/50] - Batch loss: 167.7785 - Epoch Loss: 33050.2714 - Avg Loss: 158.1353\n",
            "Epoch [37/50] - Batch loss: 154.4653 - Epoch Loss: 33204.7368 - Avg Loss: 158.1178\n",
            "Epoch [37/50] - Batch loss: 153.7040 - Epoch Loss: 33358.4408 - Avg Loss: 158.0969\n",
            "Epoch [37/50] - Batch loss: 152.7784 - Epoch Loss: 33511.2192 - Avg Loss: 158.0718\n",
            "Epoch [37/50] - Batch loss: 150.1192 - Epoch Loss: 33661.3384 - Avg Loss: 158.0345\n",
            "Epoch [37/50] - Batch loss: 155.8163 - Epoch Loss: 33817.1548 - Avg Loss: 158.0241\n",
            "Epoch [37/50] - Batch loss: 157.9264 - Epoch Loss: 33975.0811 - Avg Loss: 158.0236\n",
            "Epoch [37/50] - Batch loss: 152.5783 - Epoch Loss: 34127.6594 - Avg Loss: 157.9984\n",
            "Epoch [37/50] - Batch loss: 162.2242 - Epoch Loss: 34289.8836 - Avg Loss: 158.0179\n",
            "Epoch [37/50] - Batch loss: 151.7762 - Epoch Loss: 34441.6598 - Avg Loss: 157.9893\n",
            "Epoch [37/50] - Batch loss: 160.2953 - Epoch Loss: 34601.9551 - Avg Loss: 157.9998\n",
            "Epoch [37/50] - Batch loss: 156.2853 - Epoch Loss: 34758.2403 - Avg Loss: 157.9920\n",
            "Epoch [37/50] - Batch loss: 152.2770 - Epoch Loss: 34910.5173 - Avg Loss: 157.9661\n",
            "Epoch [37/50] - Batch loss: 157.7817 - Epoch Loss: 35068.2990 - Avg Loss: 157.9653\n",
            "Epoch [37/50] - Batch loss: 152.4370 - Epoch Loss: 35220.7360 - Avg Loss: 157.9405\n",
            "Epoch [37/50] - Batch loss: 157.5297 - Epoch Loss: 35378.2658 - Avg Loss: 157.9387\n",
            "Epoch [37/50] - Batch loss: 150.0825 - Epoch Loss: 35528.3483 - Avg Loss: 157.9038\n",
            "Epoch [37/50] - Batch loss: 159.9610 - Epoch Loss: 35688.3093 - Avg Loss: 157.9129\n",
            "Epoch [37/50] - Batch loss: 161.6544 - Epoch Loss: 35849.9637 - Avg Loss: 157.9294\n",
            "Epoch [37/50] - Batch loss: 157.7075 - Epoch Loss: 36007.6712 - Avg Loss: 157.9284\n",
            "Epoch [37/50] - Batch loss: 157.3803 - Epoch Loss: 36165.0515 - Avg Loss: 157.9260\n",
            "Epoch [37/50] - Batch loss: 157.0993 - Epoch Loss: 36322.1508 - Avg Loss: 157.9224\n",
            "Epoch [37/50] - Batch loss: 165.4370 - Epoch Loss: 36487.5879 - Avg Loss: 157.9549\n",
            "Epoch [37/50] - Batch loss: 158.4162 - Epoch Loss: 36646.0040 - Avg Loss: 157.9569\n",
            "Epoch [37/50] - Batch loss: 151.4862 - Epoch Loss: 36797.4903 - Avg Loss: 157.9291\n",
            "Epoch [37/50] - Batch loss: 152.9124 - Epoch Loss: 36950.4027 - Avg Loss: 157.9077\n",
            "Epoch [37/50] - Batch loss: 163.2288 - Epoch Loss: 37113.6315 - Avg Loss: 157.9303\n",
            "Epoch [37/50] - Batch loss: 158.8547 - Epoch Loss: 37272.4862 - Avg Loss: 157.9343\n",
            "Epoch [37/50] - Batch loss: 159.2217 - Epoch Loss: 37431.7079 - Avg Loss: 157.9397\n",
            "Epoch [37/50] - Batch loss: 159.5939 - Epoch Loss: 37591.3019 - Avg Loss: 157.9466\n",
            "Epoch [37/50] - Batch loss: 157.1020 - Epoch Loss: 37748.4039 - Avg Loss: 157.9431\n",
            "Epoch [37/50] - Batch loss: 163.2101 - Epoch Loss: 37911.6140 - Avg Loss: 157.9651\n",
            "Epoch [37/50] - Batch loss: 164.0755 - Epoch Loss: 38075.6895 - Avg Loss: 157.9904\n",
            "Epoch [37/50] - Batch loss: 156.2568 - Epoch Loss: 38231.9463 - Avg Loss: 157.9832\n",
            "Epoch [37/50] - Batch loss: 159.4502 - Epoch Loss: 38391.3965 - Avg Loss: 157.9893\n",
            "Epoch [37/50] - Batch loss: 147.2350 - Epoch Loss: 38538.6315 - Avg Loss: 157.9452\n",
            "Epoch [37/50] - Batch loss: 156.8947 - Epoch Loss: 38695.5262 - Avg Loss: 157.9409\n",
            "Epoch [37/50] - Batch loss: 158.2391 - Epoch Loss: 38853.7653 - Avg Loss: 157.9421\n",
            "Epoch [37/50] - Batch loss: 157.7880 - Epoch Loss: 39011.5533 - Avg Loss: 157.9415\n",
            "Epoch [37/50] - Batch loss: 150.4456 - Epoch Loss: 39161.9989 - Avg Loss: 157.9113\n",
            "Epoch [37/50] - Batch loss: 152.1884 - Epoch Loss: 39314.1873 - Avg Loss: 157.8883\n",
            "Epoch [37/50] - Batch loss: 160.6373 - Epoch Loss: 39474.8247 - Avg Loss: 157.8993\n",
            "Epoch [37/50] - Batch loss: 160.3478 - Epoch Loss: 39635.1725 - Avg Loss: 157.9091\n",
            "Epoch [37/50] - Batch loss: 152.2771 - Epoch Loss: 39787.4495 - Avg Loss: 157.8867\n",
            "Epoch [37/50] - Batch loss: 156.5748 - Epoch Loss: 39944.0244 - Avg Loss: 157.8815\n",
            "Epoch [37/50] - Batch loss: 156.7773 - Epoch Loss: 40100.8017 - Avg Loss: 157.8772\n",
            "Epoch [37/50] - Batch loss: 164.1809 - Epoch Loss: 40264.9825 - Avg Loss: 157.9019\n",
            "Epoch [37/50] - Batch loss: 157.7699 - Epoch Loss: 40422.7524 - Avg Loss: 157.9014\n",
            "Epoch [37/50] - Batch loss: 160.1935 - Epoch Loss: 40582.9459 - Avg Loss: 157.9103\n",
            "Epoch [37/50] - Batch loss: 162.1574 - Epoch Loss: 40745.1033 - Avg Loss: 157.9268\n",
            "Epoch [37/50] - Batch loss: 156.0540 - Epoch Loss: 40901.1573 - Avg Loss: 157.9195\n",
            "Epoch [37/50] - Batch loss: 159.8933 - Epoch Loss: 41061.0506 - Avg Loss: 157.9271\n",
            "Epoch [37/50] - Batch loss: 157.6608 - Epoch Loss: 41218.7114 - Avg Loss: 157.9261\n",
            "Epoch [37/50] - Batch loss: 165.3533 - Epoch Loss: 41384.0648 - Avg Loss: 157.9544\n",
            "Epoch [37/50] - Batch loss: 164.7439 - Epoch Loss: 41548.8087 - Avg Loss: 157.9803\n",
            "Epoch [37/50] - Batch loss: 148.7957 - Epoch Loss: 41697.6043 - Avg Loss: 157.9455\n",
            "Epoch [37/50] - Batch loss: 165.9775 - Epoch Loss: 41863.5818 - Avg Loss: 157.9758\n",
            "Epoch [37/50] - Batch loss: 151.0616 - Epoch Loss: 42014.6434 - Avg Loss: 157.9498\n",
            "Epoch [37/50] - Batch loss: 156.3195 - Epoch Loss: 42170.9629 - Avg Loss: 157.9437\n",
            "Epoch [37/50] - Batch loss: 146.6218 - Epoch Loss: 42317.5847 - Avg Loss: 157.9014\n",
            "Epoch [37/50] - Batch loss: 157.9476 - Epoch Loss: 42475.5323 - Avg Loss: 157.9016\n",
            "Epoch [37/50] - Batch loss: 161.2562 - Epoch Loss: 42636.7885 - Avg Loss: 157.9140\n",
            "Epoch [37/50] - Batch loss: 162.9240 - Epoch Loss: 42799.7125 - Avg Loss: 157.9325\n",
            "Epoch [37/50] - Batch loss: 156.9056 - Epoch Loss: 42956.6181 - Avg Loss: 157.9287\n",
            "Epoch [37/50] - Batch loss: 155.8591 - Epoch Loss: 43112.4772 - Avg Loss: 157.9212\n",
            "Epoch [37/50] - Batch loss: 159.5994 - Epoch Loss: 43272.0766 - Avg Loss: 157.9273\n",
            "Epoch [37/50] - Batch loss: 162.2292 - Epoch Loss: 43434.3058 - Avg Loss: 157.9429\n",
            "Epoch [37/50] - Batch loss: 159.2611 - Epoch Loss: 43593.5669 - Avg Loss: 157.9477\n",
            "Epoch [37/50] - Batch loss: 150.0318 - Epoch Loss: 43743.5988 - Avg Loss: 157.9191\n",
            "Epoch [37/50] - Batch loss: 162.0838 - Epoch Loss: 43905.6826 - Avg Loss: 157.9341\n",
            "Epoch [37/50] - Batch loss: 157.6813 - Epoch Loss: 44063.3639 - Avg Loss: 157.9332\n",
            "Epoch [37/50] - Batch loss: 156.6580 - Epoch Loss: 44220.0219 - Avg Loss: 157.9286\n",
            "Epoch [37/50] - Batch loss: 156.2183 - Epoch Loss: 44376.2402 - Avg Loss: 157.9226\n",
            "Epoch [37/50] - Batch loss: 155.7532 - Epoch Loss: 44531.9933 - Avg Loss: 157.9149\n",
            "Epoch [37/50] - Batch loss: 161.7724 - Epoch Loss: 44693.7658 - Avg Loss: 157.9285\n",
            "Epoch [37/50] - Batch loss: 155.1512 - Epoch Loss: 44848.9169 - Avg Loss: 157.9187\n",
            "Epoch [37/50] - Batch loss: 154.1093 - Epoch Loss: 45003.0263 - Avg Loss: 157.9054\n",
            "Epoch [37/50] - Batch loss: 154.3774 - Epoch Loss: 45157.4037 - Avg Loss: 157.8930\n",
            "Epoch [37/50] - Batch loss: 157.4329 - Epoch Loss: 45314.8367 - Avg Loss: 157.8914\n",
            "Epoch [37/50] - Batch loss: 150.4656 - Epoch Loss: 45465.3023 - Avg Loss: 157.8656\n",
            "Epoch [37/50] - Batch loss: 156.8613 - Epoch Loss: 45622.1636 - Avg Loss: 157.8622\n",
            "Epoch [37/50] - Batch loss: 163.1480 - Epoch Loss: 45785.3116 - Avg Loss: 157.8804\n",
            "Epoch [37/50] - Batch loss: 151.5499 - Epoch Loss: 45936.8616 - Avg Loss: 157.8586\n",
            "Epoch [37/50] - Batch loss: 160.4925 - Epoch Loss: 46097.3541 - Avg Loss: 157.8677\n",
            "Epoch [37/50] - Batch loss: 161.7771 - Epoch Loss: 46259.1312 - Avg Loss: 157.8810\n",
            "Epoch [37/50] - Batch loss: 156.4704 - Epoch Loss: 46415.6016 - Avg Loss: 157.8762\n",
            "Epoch [37/50] - Batch loss: 158.8759 - Epoch Loss: 46574.4774 - Avg Loss: 157.8796\n",
            "Epoch [37/50] - Batch loss: 156.6850 - Epoch Loss: 46731.1625 - Avg Loss: 157.8755\n",
            "Epoch [37/50] - Batch loss: 156.9840 - Epoch Loss: 46888.1465 - Avg Loss: 157.8725\n",
            "Epoch [37/50] - Batch loss: 149.4713 - Epoch Loss: 47037.6178 - Avg Loss: 157.8444\n",
            "Epoch [37/50] - Batch loss: 162.8103 - Epoch Loss: 47200.4281 - Avg Loss: 157.8610\n",
            "Epoch [37/50] - Batch loss: 151.4525 - Epoch Loss: 47351.8807 - Avg Loss: 157.8396\n",
            "Epoch [37/50] - Batch loss: 154.4665 - Epoch Loss: 47506.3471 - Avg Loss: 157.8284\n",
            "Epoch [37/50] - Batch loss: 158.1355 - Epoch Loss: 47664.4827 - Avg Loss: 157.8294\n",
            "Epoch [37/50] - Batch loss: 162.4994 - Epoch Loss: 47826.9821 - Avg Loss: 157.8448\n",
            "Epoch [37/50] - Batch loss: 161.6991 - Epoch Loss: 47988.6812 - Avg Loss: 157.8575\n",
            "Epoch [37/50] - Batch loss: 162.7794 - Epoch Loss: 48151.4605 - Avg Loss: 157.8736\n",
            "Epoch [37/50] - Batch loss: 158.0094 - Epoch Loss: 48309.4700 - Avg Loss: 157.8741\n",
            "Epoch [37/50] - Batch loss: 165.8920 - Epoch Loss: 48475.3620 - Avg Loss: 157.9002\n",
            "Epoch [37/50] - Batch loss: 152.9516 - Epoch Loss: 48628.3136 - Avg Loss: 157.8841\n",
            "Epoch [37/50] - Batch loss: 161.8123 - Epoch Loss: 48790.1259 - Avg Loss: 157.8968\n",
            "Epoch [37/50] - Batch loss: 156.1086 - Epoch Loss: 48946.2344 - Avg Loss: 157.8911\n",
            "Epoch [37/50] - Batch loss: 153.3369 - Epoch Loss: 49099.5714 - Avg Loss: 157.8764\n",
            "Epoch [37/50] - Batch loss: 157.7383 - Epoch Loss: 49257.3097 - Avg Loss: 157.8760\n",
            "Epoch [37/50] - Batch loss: 160.2742 - Epoch Loss: 49417.5839 - Avg Loss: 157.8837\n",
            "Epoch [37/50] - Batch loss: 158.2164 - Epoch Loss: 49575.8004 - Avg Loss: 157.8847\n",
            "Epoch [37/50] - Batch loss: 153.8620 - Epoch Loss: 49729.6624 - Avg Loss: 157.8719\n",
            "Epoch [37/50] - Batch loss: 153.4886 - Epoch Loss: 49883.1510 - Avg Loss: 157.8581\n",
            "Epoch [37/50] - Batch loss: 160.2323 - Epoch Loss: 50043.3833 - Avg Loss: 157.8656\n",
            "Epoch [37/50] - Batch loss: 159.7095 - Epoch Loss: 50203.0929 - Avg Loss: 157.8714\n",
            "Epoch [37/50] - Batch loss: 162.9502 - Epoch Loss: 50366.0431 - Avg Loss: 157.8873\n",
            "Epoch [37/50] - Batch loss: 151.5603 - Epoch Loss: 50517.6034 - Avg Loss: 157.8675\n",
            "Epoch [37/50] - Batch loss: 169.8497 - Epoch Loss: 50687.4531 - Avg Loss: 157.9048\n",
            "Epoch [37/50] - Batch loss: 160.9488 - Epoch Loss: 50848.4020 - Avg Loss: 157.9143\n",
            "Epoch [37/50] - Batch loss: 154.8729 - Epoch Loss: 51003.2749 - Avg Loss: 157.9049\n",
            "Epoch [37/50] - Batch loss: 164.5651 - Epoch Loss: 51167.8399 - Avg Loss: 157.9254\n",
            "Epoch [37/50] - Batch loss: 160.5669 - Epoch Loss: 51328.4068 - Avg Loss: 157.9336\n",
            "Epoch [37/50] - Batch loss: 161.2656 - Epoch Loss: 51489.6724 - Avg Loss: 157.9438\n",
            "Epoch [37/50] - Batch loss: 157.1325 - Epoch Loss: 51646.8049 - Avg Loss: 157.9413\n",
            "Epoch [37/50] - Batch loss: 164.8613 - Epoch Loss: 51811.6662 - Avg Loss: 157.9624\n",
            "Epoch [37/50] - Batch loss: 150.1637 - Epoch Loss: 51961.8299 - Avg Loss: 157.9387\n",
            "Epoch [37/50] - Batch loss: 155.7927 - Epoch Loss: 52117.6226 - Avg Loss: 157.9322\n",
            "Epoch [37/50] - Batch loss: 163.9521 - Epoch Loss: 52281.5747 - Avg Loss: 157.9504\n",
            "Epoch [37/50] - Batch loss: 158.3617 - Epoch Loss: 52439.9364 - Avg Loss: 157.9516\n",
            "Epoch [37/50] - Batch loss: 163.3078 - Epoch Loss: 52603.2442 - Avg Loss: 157.9677\n",
            "Epoch [37/50] - Batch loss: 161.0099 - Epoch Loss: 52764.2541 - Avg Loss: 157.9768\n",
            "Epoch [37/50] - Batch loss: 156.4727 - Epoch Loss: 52920.7268 - Avg Loss: 157.9723\n",
            "Epoch [37/50] - Batch loss: 159.7710 - Epoch Loss: 53080.4977 - Avg Loss: 157.9777\n",
            "Epoch [37/50] - Batch loss: 162.8387 - Epoch Loss: 53243.3365 - Avg Loss: 157.9921\n",
            "Epoch [37/50] - Batch loss: 157.3474 - Epoch Loss: 53400.6838 - Avg Loss: 157.9902\n",
            "Epoch [37/50] - Batch loss: 149.5432 - Epoch Loss: 53550.2271 - Avg Loss: 157.9653\n",
            "Epoch [37/50] - Batch loss: 150.8586 - Epoch Loss: 53701.0856 - Avg Loss: 157.9444\n",
            "Epoch [37/50] - Batch loss: 161.0513 - Epoch Loss: 53862.1370 - Avg Loss: 157.9535\n",
            "Epoch [37/50] - Batch loss: 153.8296 - Epoch Loss: 54015.9666 - Avg Loss: 157.9414\n",
            "Epoch [37/50] - Batch loss: 160.6314 - Epoch Loss: 54176.5980 - Avg Loss: 157.9493\n",
            "Epoch [37/50] - Batch loss: 158.4709 - Epoch Loss: 54335.0689 - Avg Loss: 157.9508\n",
            "Epoch [37/50] - Batch loss: 157.6618 - Epoch Loss: 54492.7308 - Avg Loss: 157.9499\n",
            "Epoch [37/50] - Batch loss: 157.7710 - Epoch Loss: 54650.5017 - Avg Loss: 157.9494\n",
            "Epoch [37/50] - Batch loss: 153.6701 - Epoch Loss: 54804.1718 - Avg Loss: 157.9371\n",
            "Epoch [37/50] - Batch loss: 153.1458 - Epoch Loss: 54957.3176 - Avg Loss: 157.9233\n",
            "Epoch [37/50] - Batch loss: 150.2438 - Epoch Loss: 55107.5614 - Avg Loss: 157.9013\n",
            "Epoch [37/50] - Batch loss: 150.7157 - Epoch Loss: 55258.2771 - Avg Loss: 157.8808\n",
            "Epoch [37/50] - Batch loss: 157.7266 - Epoch Loss: 55416.0036 - Avg Loss: 157.8804\n",
            "Epoch [37/50] - Batch loss: 147.9531 - Epoch Loss: 55563.9567 - Avg Loss: 157.8521\n",
            "Epoch [37/50] - Batch loss: 156.0668 - Epoch Loss: 55720.0235 - Avg Loss: 157.8471\n",
            "Epoch [37/50] - Batch loss: 159.9859 - Epoch Loss: 55880.0095 - Avg Loss: 157.8531\n",
            "Epoch [37/50] - Batch loss: 155.7090 - Epoch Loss: 56035.7184 - Avg Loss: 157.8471\n",
            "Epoch [37/50] - Batch loss: 154.3384 - Epoch Loss: 56190.0568 - Avg Loss: 157.8372\n",
            "Epoch [37/50] - Batch loss: 156.6435 - Epoch Loss: 56346.7003 - Avg Loss: 157.8339\n",
            "Epoch [37/50] - Batch loss: 155.8671 - Epoch Loss: 56502.5674 - Avg Loss: 157.8284\n",
            "Epoch [37/50] - Batch loss: 159.4702 - Epoch Loss: 56662.0377 - Avg Loss: 157.8330\n",
            "Epoch [37/50] - Batch loss: 161.6604 - Epoch Loss: 56823.6981 - Avg Loss: 157.8436\n",
            "Epoch [37/50] - Batch loss: 160.6692 - Epoch Loss: 56984.3673 - Avg Loss: 157.8514\n",
            "Epoch [37/50] - Batch loss: 158.5486 - Epoch Loss: 57142.9159 - Avg Loss: 157.8534\n",
            "Epoch [37/50] - Batch loss: 152.4643 - Epoch Loss: 57295.3802 - Avg Loss: 157.8385\n",
            "Epoch [37/50] - Batch loss: 157.3968 - Epoch Loss: 57452.7770 - Avg Loss: 157.8373\n",
            "Epoch [37/50] - Batch loss: 152.9369 - Epoch Loss: 57605.7139 - Avg Loss: 157.8239\n",
            "Epoch [37/50] - Batch loss: 155.5194 - Epoch Loss: 57761.2334 - Avg Loss: 157.8176\n",
            "Epoch [37/50] - Batch loss: 154.1280 - Epoch Loss: 57915.3614 - Avg Loss: 157.8075\n",
            "Epoch [37/50] - Batch loss: 155.9127 - Epoch Loss: 58071.2741 - Avg Loss: 157.8024\n",
            "Epoch [37/50] - Batch loss: 159.8610 - Epoch Loss: 58231.1351 - Avg Loss: 157.8080\n",
            "Epoch [37/50] - Batch loss: 160.4328 - Epoch Loss: 58391.5679 - Avg Loss: 157.8150\n",
            "Epoch [37/50] - Batch loss: 157.0594 - Epoch Loss: 58548.6272 - Avg Loss: 157.8130\n",
            "Epoch [37/50] - Batch loss: 158.8271 - Epoch Loss: 58707.4543 - Avg Loss: 157.8157\n",
            "Epoch [37/50] - Batch loss: 151.4794 - Epoch Loss: 58858.9337 - Avg Loss: 157.7987\n",
            "Epoch [37/50] - Batch loss: 158.3587 - Epoch Loss: 59017.2924 - Avg Loss: 157.8002\n",
            "Epoch [37/50] - Batch loss: 160.8167 - Epoch Loss: 59178.1092 - Avg Loss: 157.8083\n",
            "Epoch [37/50] - Batch loss: 164.0737 - Epoch Loss: 59342.1828 - Avg Loss: 157.8250\n",
            "Epoch [37/50] - Batch loss: 147.1754 - Epoch Loss: 59489.3582 - Avg Loss: 157.7967\n",
            "Epoch [37/50] - Batch loss: 161.4526 - Epoch Loss: 59650.8108 - Avg Loss: 157.8064\n",
            "Epoch [37/50] - Batch loss: 157.7060 - Epoch Loss: 59808.5168 - Avg Loss: 157.8061\n",
            "Epoch [37/50] - Batch loss: 154.9248 - Epoch Loss: 59963.4417 - Avg Loss: 157.7985\n",
            "Epoch [37/50] - Batch loss: 162.4112 - Epoch Loss: 60125.8528 - Avg Loss: 157.8106\n",
            "Epoch [37/50] - Batch loss: 158.0117 - Epoch Loss: 60283.8645 - Avg Loss: 157.8112\n",
            "Epoch [37/50] - Batch loss: 153.6161 - Epoch Loss: 60437.4806 - Avg Loss: 157.8002\n",
            "Epoch [37/50] - Batch loss: 159.6546 - Epoch Loss: 60597.1352 - Avg Loss: 157.8050\n",
            "Epoch [37/50] - Batch loss: 157.7095 - Epoch Loss: 60754.8447 - Avg Loss: 157.8048\n",
            "Epoch [37/50] - Batch loss: 157.5227 - Epoch Loss: 60912.3674 - Avg Loss: 157.8041\n",
            "Epoch [37/50] - Batch loss: 162.8906 - Epoch Loss: 61075.2580 - Avg Loss: 157.8172\n",
            "Epoch [37/50] - Batch loss: 157.0945 - Epoch Loss: 61232.3525 - Avg Loss: 157.8153\n",
            "Epoch [37/50] - Batch loss: 157.0234 - Epoch Loss: 61389.3759 - Avg Loss: 157.8133\n",
            "Epoch [37/50] - Batch loss: 157.4187 - Epoch Loss: 61546.7946 - Avg Loss: 157.8123\n",
            "Epoch [37/50] - Batch loss: 159.6140 - Epoch Loss: 61706.4086 - Avg Loss: 157.8169\n",
            "Epoch [37/50] - Batch loss: 165.0536 - Epoch Loss: 61871.4621 - Avg Loss: 157.8354\n",
            "Epoch [37/50] - Batch loss: 161.8042 - Epoch Loss: 62033.2663 - Avg Loss: 157.8455\n",
            "Epoch [37/50] - Batch loss: 159.6770 - Epoch Loss: 62192.9434 - Avg Loss: 157.8501\n",
            "Epoch [37/50] - Batch loss: 159.2189 - Epoch Loss: 62352.1623 - Avg Loss: 157.8536\n",
            "Epoch [37/50] - Batch loss: 159.3537 - Epoch Loss: 62511.5160 - Avg Loss: 157.8574\n",
            "Epoch [37/50] - Batch loss: 156.0905 - Epoch Loss: 62667.6065 - Avg Loss: 157.8529\n",
            "Epoch [37/50] - Batch loss: 150.5764 - Epoch Loss: 62818.1829 - Avg Loss: 157.8346\n",
            "Epoch [37/50] - Batch loss: 159.7772 - Epoch Loss: 62977.9601 - Avg Loss: 157.8395\n",
            "Epoch [37/50] - Batch loss: 153.3591 - Epoch Loss: 63131.3193 - Avg Loss: 157.8283\n",
            "Epoch [37/50] - Batch loss: 161.9422 - Epoch Loss: 63293.2615 - Avg Loss: 157.8386\n",
            "Epoch [37/50] - Batch loss: 149.4240 - Epoch Loss: 63442.6855 - Avg Loss: 157.8176\n",
            "Epoch [37/50] - Batch loss: 150.4556 - Epoch Loss: 63593.1411 - Avg Loss: 157.7994\n",
            "Epoch [37/50] - Batch loss: 167.0091 - Epoch Loss: 63760.1502 - Avg Loss: 157.8222\n",
            "Epoch [37/50] - Batch loss: 154.9591 - Epoch Loss: 63915.1093 - Avg Loss: 157.8151\n",
            "Epoch [37/50] - Batch loss: 152.2929 - Epoch Loss: 64067.4022 - Avg Loss: 157.8015\n",
            "Epoch [37/50] - Batch loss: 163.4388 - Epoch Loss: 64230.8410 - Avg Loss: 157.8153\n",
            "Epoch [37/50] - Batch loss: 158.3963 - Epoch Loss: 64389.2373 - Avg Loss: 157.8168\n",
            "Epoch [37/50] - Batch loss: 160.0007 - Epoch Loss: 64549.2380 - Avg Loss: 157.8221\n",
            "Epoch [37/50] - Batch loss: 151.8798 - Epoch Loss: 64701.1178 - Avg Loss: 157.8076\n",
            "Epoch [37/50] - Batch loss: 162.2666 - Epoch Loss: 64863.3844 - Avg Loss: 157.8185\n",
            "Epoch [37/50] - Batch loss: 161.9993 - Epoch Loss: 65025.3837 - Avg Loss: 157.8286\n",
            "Epoch [37/50] - Batch loss: 156.8693 - Epoch Loss: 65182.2531 - Avg Loss: 157.8263\n",
            "Epoch [37/50] - Batch loss: 161.1176 - Epoch Loss: 65343.3707 - Avg Loss: 157.8342\n",
            "Epoch [37/50] - Batch loss: 155.8170 - Epoch Loss: 65499.1877 - Avg Loss: 157.8294\n",
            "Epoch [37/50] - Batch loss: 166.1979 - Epoch Loss: 65665.3856 - Avg Loss: 157.8495\n",
            "Epoch [37/50] - Batch loss: 160.9673 - Epoch Loss: 65826.3529 - Avg Loss: 157.8570\n",
            "Epoch [37/50] - Batch loss: 164.8680 - Epoch Loss: 65991.2209 - Avg Loss: 157.8737\n",
            "Epoch [37/50] - Batch loss: 156.2822 - Epoch Loss: 66147.5031 - Avg Loss: 157.8699\n",
            "Epoch [37/50] - Batch loss: 155.0250 - Epoch Loss: 66302.5280 - Avg Loss: 157.8632\n",
            "Epoch [37/50] - Batch loss: 151.7152 - Epoch Loss: 66454.2433 - Avg Loss: 157.8486\n",
            "Epoch [37/50] - Batch loss: 160.5836 - Epoch Loss: 66614.8269 - Avg Loss: 157.8550\n",
            "Epoch [37/50] - Batch loss: 160.6738 - Epoch Loss: 66775.5006 - Avg Loss: 157.8617\n",
            "Epoch [37/50] - Batch loss: 158.8462 - Epoch Loss: 66934.3469 - Avg Loss: 157.8640\n",
            "Epoch [37/50] - Batch loss: 163.3397 - Epoch Loss: 67097.6866 - Avg Loss: 157.8769\n",
            "Epoch [37/50] - Batch loss: 155.8464 - Epoch Loss: 67253.5330 - Avg Loss: 157.8721\n",
            "Epoch [37/50] - Batch loss: 154.4844 - Epoch Loss: 67408.0175 - Avg Loss: 157.8642\n",
            "Epoch [37/50] - Batch loss: 165.4146 - Epoch Loss: 67573.4321 - Avg Loss: 157.8819\n",
            "Epoch [37/50] - Batch loss: 159.0154 - Epoch Loss: 67732.4475 - Avg Loss: 157.8845\n",
            "Epoch [37/50] - Batch loss: 151.9731 - Epoch Loss: 67884.4206 - Avg Loss: 157.8707\n",
            "Epoch [37/50] - Batch loss: 153.5916 - Epoch Loss: 68038.0122 - Avg Loss: 157.8608\n",
            "Epoch [37/50] - Batch loss: 162.2764 - Epoch Loss: 68200.2885 - Avg Loss: 157.8710\n",
            "Epoch [37/50] - Batch loss: 158.3298 - Epoch Loss: 68358.6184 - Avg Loss: 157.8721\n",
            "Epoch [37/50] - Batch loss: 162.6574 - Epoch Loss: 68521.2757 - Avg Loss: 157.8831\n",
            "Epoch [37/50] - Batch loss: 149.1466 - Epoch Loss: 68670.4223 - Avg Loss: 157.8630\n",
            "Epoch [37/50] - Batch loss: 160.1817 - Epoch Loss: 68830.6041 - Avg Loss: 157.8684\n",
            "Epoch [37/50] - Batch loss: 164.4150 - Epoch Loss: 68995.0191 - Avg Loss: 157.8833\n",
            "Epoch [37/50] - Batch loss: 158.4188 - Epoch Loss: 69153.4379 - Avg Loss: 157.8846\n",
            "Epoch [37/50] - Batch loss: 157.1861 - Epoch Loss: 69310.6239 - Avg Loss: 157.8830\n",
            "Epoch [37/50] - Batch loss: 152.3515 - Epoch Loss: 69462.9754 - Avg Loss: 157.8704\n",
            "Epoch [37/50] - Batch loss: 165.9496 - Epoch Loss: 69628.9250 - Avg Loss: 157.8887\n",
            "Epoch [37/50] - Batch loss: 160.1786 - Epoch Loss: 69789.1037 - Avg Loss: 157.8939\n",
            "Epoch [37/50] - Batch loss: 155.7552 - Epoch Loss: 69944.8589 - Avg Loss: 157.8891\n",
            "Epoch [37/50] - Batch loss: 155.7048 - Epoch Loss: 70100.5637 - Avg Loss: 157.8842\n",
            "Epoch [37/50] - Batch loss: 158.5986 - Epoch Loss: 70259.1623 - Avg Loss: 157.8858\n",
            "Epoch [37/50] - Batch loss: 162.1093 - Epoch Loss: 70421.2715 - Avg Loss: 157.8952\n",
            "Epoch [37/50] - Batch loss: 164.2176 - Epoch Loss: 70585.4892 - Avg Loss: 157.9094\n",
            "Epoch [37/50] - Batch loss: 158.6982 - Epoch Loss: 70744.1874 - Avg Loss: 157.9111\n",
            "Epoch [37/50] - Batch loss: 162.7145 - Epoch Loss: 70906.9019 - Avg Loss: 157.9218\n",
            "Epoch [37/50] - Batch loss: 157.4426 - Epoch Loss: 71064.3445 - Avg Loss: 157.9208\n",
            "Epoch [37/50] - Batch loss: 162.1189 - Epoch Loss: 71226.4634 - Avg Loss: 157.9301\n",
            "Epoch [37/50] - Batch loss: 152.6202 - Epoch Loss: 71379.0836 - Avg Loss: 157.9183\n",
            "Epoch [37/50] - Batch loss: 158.8745 - Epoch Loss: 71537.9580 - Avg Loss: 157.9204\n",
            "Epoch [37/50] - Batch loss: 165.7724 - Epoch Loss: 71703.7304 - Avg Loss: 157.9377\n",
            "Epoch [37/50] - Batch loss: 157.6585 - Epoch Loss: 71861.3889 - Avg Loss: 157.9371\n",
            "Epoch [37/50] - Batch loss: 158.5770 - Epoch Loss: 72019.9659 - Avg Loss: 157.9385\n",
            "Epoch [37/50] - Batch loss: 162.9660 - Epoch Loss: 72182.9319 - Avg Loss: 157.9495\n",
            "Epoch [37/50] - Batch loss: 156.3594 - Epoch Loss: 72339.2913 - Avg Loss: 157.9461\n",
            "Epoch [37/50] - Batch loss: 154.8292 - Epoch Loss: 72494.1205 - Avg Loss: 157.9393\n",
            "Epoch [37/50] - Batch loss: 153.4548 - Epoch Loss: 72647.5753 - Avg Loss: 157.9295\n",
            "Epoch [37/50] - Batch loss: 154.1159 - Epoch Loss: 72801.6912 - Avg Loss: 157.9212\n",
            "Epoch [37/50] - Batch loss: 158.9312 - Epoch Loss: 72960.6223 - Avg Loss: 157.9234\n",
            "Epoch [37/50] - Batch loss: 160.5677 - Epoch Loss: 73121.1901 - Avg Loss: 157.9291\n",
            "Epoch [37/50] - Batch loss: 157.3006 - Epoch Loss: 73278.4907 - Avg Loss: 157.9278\n",
            "Epoch [37/50] - Batch loss: 159.7020 - Epoch Loss: 73438.1926 - Avg Loss: 157.9316\n",
            "Epoch [37/50] - Batch loss: 161.2932 - Epoch Loss: 73599.4858 - Avg Loss: 157.9388\n",
            "Epoch [37/50] - Batch loss: 160.1431 - Epoch Loss: 73759.6289 - Avg Loss: 157.9435\n",
            "Epoch [37/50] - Batch loss: 159.6681 - Epoch Loss: 73919.2970 - Avg Loss: 157.9472\n",
            "Epoch [37/50] - Batch loss: 163.9728 - Epoch Loss: 74083.2698 - Avg Loss: 157.9601\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 38/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90b7b8b99da4445c9a3daabf76ac525d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [38/50] - Batch loss: 151.3329 - Epoch Loss: 151.3329 - Avg Loss: 151.3329\n",
            "Epoch [38/50] - Batch loss: 157.5186 - Epoch Loss: 308.8515 - Avg Loss: 154.4258\n",
            "Epoch [38/50] - Batch loss: 163.3153 - Epoch Loss: 472.1668 - Avg Loss: 157.3889\n",
            "Epoch [38/50] - Batch loss: 162.7450 - Epoch Loss: 634.9119 - Avg Loss: 158.7280\n",
            "Epoch [38/50] - Batch loss: 152.2671 - Epoch Loss: 787.1790 - Avg Loss: 157.4358\n",
            "Epoch [38/50] - Batch loss: 159.2003 - Epoch Loss: 946.3793 - Avg Loss: 157.7299\n",
            "Epoch [38/50] - Batch loss: 157.0377 - Epoch Loss: 1103.4170 - Avg Loss: 157.6310\n",
            "Epoch [38/50] - Batch loss: 160.5088 - Epoch Loss: 1263.9258 - Avg Loss: 157.9907\n",
            "Epoch [38/50] - Batch loss: 167.5224 - Epoch Loss: 1431.4482 - Avg Loss: 159.0498\n",
            "Epoch [38/50] - Batch loss: 157.0043 - Epoch Loss: 1588.4525 - Avg Loss: 158.8452\n",
            "Epoch [38/50] - Batch loss: 157.0292 - Epoch Loss: 1745.4817 - Avg Loss: 158.6802\n",
            "Epoch [38/50] - Batch loss: 153.3259 - Epoch Loss: 1898.8075 - Avg Loss: 158.2340\n",
            "Epoch [38/50] - Batch loss: 152.6330 - Epoch Loss: 2051.4405 - Avg Loss: 157.8031\n",
            "Epoch [38/50] - Batch loss: 160.6008 - Epoch Loss: 2212.0413 - Avg Loss: 158.0030\n",
            "Epoch [38/50] - Batch loss: 164.2053 - Epoch Loss: 2376.2466 - Avg Loss: 158.4164\n",
            "Epoch [38/50] - Batch loss: 154.9055 - Epoch Loss: 2531.1521 - Avg Loss: 158.1970\n",
            "Epoch [38/50] - Batch loss: 159.3730 - Epoch Loss: 2690.5251 - Avg Loss: 158.2662\n",
            "Epoch [38/50] - Batch loss: 161.2708 - Epoch Loss: 2851.7958 - Avg Loss: 158.4331\n",
            "Epoch [38/50] - Batch loss: 162.1849 - Epoch Loss: 3013.9808 - Avg Loss: 158.6306\n",
            "Epoch [38/50] - Batch loss: 152.8932 - Epoch Loss: 3166.8740 - Avg Loss: 158.3437\n",
            "Epoch [38/50] - Batch loss: 164.0298 - Epoch Loss: 3330.9038 - Avg Loss: 158.6145\n",
            "Epoch [38/50] - Batch loss: 153.6197 - Epoch Loss: 3484.5235 - Avg Loss: 158.3874\n",
            "Epoch [38/50] - Batch loss: 161.9088 - Epoch Loss: 3646.4324 - Avg Loss: 158.5405\n",
            "Epoch [38/50] - Batch loss: 154.4499 - Epoch Loss: 3800.8822 - Avg Loss: 158.3701\n",
            "Epoch [38/50] - Batch loss: 154.1833 - Epoch Loss: 3955.0656 - Avg Loss: 158.2026\n",
            "Epoch [38/50] - Batch loss: 154.9377 - Epoch Loss: 4110.0033 - Avg Loss: 158.0771\n",
            "Epoch [38/50] - Batch loss: 159.6477 - Epoch Loss: 4269.6510 - Avg Loss: 158.1352\n",
            "Epoch [38/50] - Batch loss: 162.5659 - Epoch Loss: 4432.2169 - Avg Loss: 158.2935\n",
            "Epoch [38/50] - Batch loss: 155.5937 - Epoch Loss: 4587.8106 - Avg Loss: 158.2004\n",
            "Epoch [38/50] - Batch loss: 156.6789 - Epoch Loss: 4744.4895 - Avg Loss: 158.1497\n",
            "Epoch [38/50] - Batch loss: 153.7347 - Epoch Loss: 4898.2242 - Avg Loss: 158.0072\n",
            "Epoch [38/50] - Batch loss: 159.1142 - Epoch Loss: 5057.3385 - Avg Loss: 158.0418\n",
            "Epoch [38/50] - Batch loss: 159.1094 - Epoch Loss: 5216.4479 - Avg Loss: 158.0742\n",
            "Epoch [38/50] - Batch loss: 168.8269 - Epoch Loss: 5385.2748 - Avg Loss: 158.3904\n",
            "Epoch [38/50] - Batch loss: 159.4002 - Epoch Loss: 5544.6750 - Avg Loss: 158.4193\n",
            "Epoch [38/50] - Batch loss: 161.1799 - Epoch Loss: 5705.8548 - Avg Loss: 158.4960\n",
            "Epoch [38/50] - Batch loss: 164.2830 - Epoch Loss: 5870.1378 - Avg Loss: 158.6524\n",
            "Epoch [38/50] - Batch loss: 156.3914 - Epoch Loss: 6026.5293 - Avg Loss: 158.5929\n",
            "Epoch [38/50] - Batch loss: 162.8936 - Epoch Loss: 6189.4229 - Avg Loss: 158.7032\n",
            "Epoch [38/50] - Batch loss: 155.0294 - Epoch Loss: 6344.4523 - Avg Loss: 158.6113\n",
            "Epoch [38/50] - Batch loss: 156.7776 - Epoch Loss: 6501.2299 - Avg Loss: 158.5666\n",
            "Epoch [38/50] - Batch loss: 159.3947 - Epoch Loss: 6660.6246 - Avg Loss: 158.5863\n",
            "Epoch [38/50] - Batch loss: 157.8581 - Epoch Loss: 6818.4827 - Avg Loss: 158.5694\n",
            "Epoch [38/50] - Batch loss: 148.7223 - Epoch Loss: 6967.2050 - Avg Loss: 158.3456\n",
            "Epoch [38/50] - Batch loss: 165.3145 - Epoch Loss: 7132.5195 - Avg Loss: 158.5004\n",
            "Epoch [38/50] - Batch loss: 160.5047 - Epoch Loss: 7293.0242 - Avg Loss: 158.5440\n",
            "Epoch [38/50] - Batch loss: 156.9697 - Epoch Loss: 7449.9938 - Avg Loss: 158.5105\n",
            "Epoch [38/50] - Batch loss: 149.3706 - Epoch Loss: 7599.3644 - Avg Loss: 158.3201\n",
            "Epoch [38/50] - Batch loss: 155.9366 - Epoch Loss: 7755.3010 - Avg Loss: 158.2714\n",
            "Epoch [38/50] - Batch loss: 152.0597 - Epoch Loss: 7907.3606 - Avg Loss: 158.1472\n",
            "Epoch [38/50] - Batch loss: 168.4870 - Epoch Loss: 8075.8477 - Avg Loss: 158.3500\n",
            "Epoch [38/50] - Batch loss: 163.2933 - Epoch Loss: 8239.1409 - Avg Loss: 158.4450\n",
            "Epoch [38/50] - Batch loss: 158.3912 - Epoch Loss: 8397.5322 - Avg Loss: 158.4440\n",
            "Epoch [38/50] - Batch loss: 153.0340 - Epoch Loss: 8550.5661 - Avg Loss: 158.3438\n",
            "Epoch [38/50] - Batch loss: 154.1760 - Epoch Loss: 8704.7421 - Avg Loss: 158.2680\n",
            "Epoch [38/50] - Batch loss: 162.6624 - Epoch Loss: 8867.4045 - Avg Loss: 158.3465\n",
            "Epoch [38/50] - Batch loss: 157.7614 - Epoch Loss: 9025.1659 - Avg Loss: 158.3362\n",
            "Epoch [38/50] - Batch loss: 155.0434 - Epoch Loss: 9180.2093 - Avg Loss: 158.2795\n",
            "Epoch [38/50] - Batch loss: 156.5454 - Epoch Loss: 9336.7547 - Avg Loss: 158.2501\n",
            "Epoch [38/50] - Batch loss: 153.5460 - Epoch Loss: 9490.3008 - Avg Loss: 158.1717\n",
            "Epoch [38/50] - Batch loss: 158.3986 - Epoch Loss: 9648.6993 - Avg Loss: 158.1754\n",
            "Epoch [38/50] - Batch loss: 153.6762 - Epoch Loss: 9802.3756 - Avg Loss: 158.1028\n",
            "Epoch [38/50] - Batch loss: 161.9148 - Epoch Loss: 9964.2904 - Avg Loss: 158.1633\n",
            "Epoch [38/50] - Batch loss: 152.6924 - Epoch Loss: 10116.9828 - Avg Loss: 158.0779\n",
            "Epoch [38/50] - Batch loss: 151.8673 - Epoch Loss: 10268.8501 - Avg Loss: 157.9823\n",
            "Epoch [38/50] - Batch loss: 156.3103 - Epoch Loss: 10425.1604 - Avg Loss: 157.9570\n",
            "Epoch [38/50] - Batch loss: 160.7995 - Epoch Loss: 10585.9599 - Avg Loss: 157.9994\n",
            "Epoch [38/50] - Batch loss: 156.8583 - Epoch Loss: 10742.8182 - Avg Loss: 157.9826\n",
            "Epoch [38/50] - Batch loss: 155.5632 - Epoch Loss: 10898.3814 - Avg Loss: 157.9476\n",
            "Epoch [38/50] - Batch loss: 154.8778 - Epoch Loss: 11053.2592 - Avg Loss: 157.9037\n",
            "Epoch [38/50] - Batch loss: 152.2209 - Epoch Loss: 11205.4801 - Avg Loss: 157.8237\n",
            "Epoch [38/50] - Batch loss: 162.3673 - Epoch Loss: 11367.8474 - Avg Loss: 157.8868\n",
            "Epoch [38/50] - Batch loss: 162.3890 - Epoch Loss: 11530.2364 - Avg Loss: 157.9484\n",
            "Epoch [38/50] - Batch loss: 150.1307 - Epoch Loss: 11680.3671 - Avg Loss: 157.8428\n",
            "Epoch [38/50] - Batch loss: 152.8853 - Epoch Loss: 11833.2523 - Avg Loss: 157.7767\n",
            "Epoch [38/50] - Batch loss: 152.2589 - Epoch Loss: 11985.5112 - Avg Loss: 157.7041\n",
            "Epoch [38/50] - Batch loss: 158.4332 - Epoch Loss: 12143.9444 - Avg Loss: 157.7136\n",
            "Epoch [38/50] - Batch loss: 161.1494 - Epoch Loss: 12305.0938 - Avg Loss: 157.7576\n",
            "Epoch [38/50] - Batch loss: 155.9139 - Epoch Loss: 12461.0077 - Avg Loss: 157.7343\n",
            "Epoch [38/50] - Batch loss: 154.0832 - Epoch Loss: 12615.0909 - Avg Loss: 157.6886\n",
            "Epoch [38/50] - Batch loss: 160.9360 - Epoch Loss: 12776.0269 - Avg Loss: 157.7287\n",
            "Epoch [38/50] - Batch loss: 163.8927 - Epoch Loss: 12939.9195 - Avg Loss: 157.8039\n",
            "Epoch [38/50] - Batch loss: 160.3636 - Epoch Loss: 13100.2832 - Avg Loss: 157.8347\n",
            "Epoch [38/50] - Batch loss: 156.6621 - Epoch Loss: 13256.9453 - Avg Loss: 157.8208\n",
            "Epoch [38/50] - Batch loss: 161.8762 - Epoch Loss: 13418.8215 - Avg Loss: 157.8685\n",
            "Epoch [38/50] - Batch loss: 146.4444 - Epoch Loss: 13565.2659 - Avg Loss: 157.7356\n",
            "Epoch [38/50] - Batch loss: 164.6745 - Epoch Loss: 13729.9404 - Avg Loss: 157.8154\n",
            "Epoch [38/50] - Batch loss: 156.9374 - Epoch Loss: 13886.8778 - Avg Loss: 157.8054\n",
            "Epoch [38/50] - Batch loss: 154.3832 - Epoch Loss: 14041.2610 - Avg Loss: 157.7670\n",
            "Epoch [38/50] - Batch loss: 159.6765 - Epoch Loss: 14200.9375 - Avg Loss: 157.7882\n",
            "Epoch [38/50] - Batch loss: 156.3132 - Epoch Loss: 14357.2508 - Avg Loss: 157.7720\n",
            "Epoch [38/50] - Batch loss: 154.8221 - Epoch Loss: 14512.0728 - Avg Loss: 157.7399\n",
            "Epoch [38/50] - Batch loss: 156.3980 - Epoch Loss: 14668.4708 - Avg Loss: 157.7255\n",
            "Epoch [38/50] - Batch loss: 166.8379 - Epoch Loss: 14835.3087 - Avg Loss: 157.8224\n",
            "Epoch [38/50] - Batch loss: 154.1809 - Epoch Loss: 14989.4896 - Avg Loss: 157.7841\n",
            "Epoch [38/50] - Batch loss: 150.6831 - Epoch Loss: 15140.1727 - Avg Loss: 157.7101\n",
            "Epoch [38/50] - Batch loss: 158.5829 - Epoch Loss: 15298.7556 - Avg Loss: 157.7191\n",
            "Epoch [38/50] - Batch loss: 152.0268 - Epoch Loss: 15450.7824 - Avg Loss: 157.6610\n",
            "Epoch [38/50] - Batch loss: 154.1008 - Epoch Loss: 15604.8832 - Avg Loss: 157.6251\n",
            "Epoch [38/50] - Batch loss: 162.4039 - Epoch Loss: 15767.2871 - Avg Loss: 157.6729\n",
            "Epoch [38/50] - Batch loss: 166.4685 - Epoch Loss: 15933.7557 - Avg Loss: 157.7600\n",
            "Epoch [38/50] - Batch loss: 156.4190 - Epoch Loss: 16090.1747 - Avg Loss: 157.7468\n",
            "Epoch [38/50] - Batch loss: 158.2237 - Epoch Loss: 16248.3984 - Avg Loss: 157.7514\n",
            "Epoch [38/50] - Batch loss: 157.1809 - Epoch Loss: 16405.5793 - Avg Loss: 157.7460\n",
            "Epoch [38/50] - Batch loss: 158.6985 - Epoch Loss: 16564.2778 - Avg Loss: 157.7550\n",
            "Epoch [38/50] - Batch loss: 163.8596 - Epoch Loss: 16728.1374 - Avg Loss: 157.8126\n",
            "Epoch [38/50] - Batch loss: 145.1776 - Epoch Loss: 16873.3150 - Avg Loss: 157.6945\n",
            "Epoch [38/50] - Batch loss: 162.4049 - Epoch Loss: 17035.7199 - Avg Loss: 157.7381\n",
            "Epoch [38/50] - Batch loss: 160.6001 - Epoch Loss: 17196.3200 - Avg Loss: 157.7644\n",
            "Epoch [38/50] - Batch loss: 163.3657 - Epoch Loss: 17359.6857 - Avg Loss: 157.8153\n",
            "Epoch [38/50] - Batch loss: 155.1279 - Epoch Loss: 17514.8136 - Avg Loss: 157.7911\n",
            "Epoch [38/50] - Batch loss: 151.6242 - Epoch Loss: 17666.4377 - Avg Loss: 157.7361\n",
            "Epoch [38/50] - Batch loss: 152.2789 - Epoch Loss: 17818.7167 - Avg Loss: 157.6878\n",
            "Epoch [38/50] - Batch loss: 153.1161 - Epoch Loss: 17971.8328 - Avg Loss: 157.6477\n",
            "Epoch [38/50] - Batch loss: 150.5740 - Epoch Loss: 18122.4068 - Avg Loss: 157.5861\n",
            "Epoch [38/50] - Batch loss: 156.6876 - Epoch Loss: 18279.0944 - Avg Loss: 157.5784\n",
            "Epoch [38/50] - Batch loss: 162.8473 - Epoch Loss: 18441.9417 - Avg Loss: 157.6234\n",
            "Epoch [38/50] - Batch loss: 163.4994 - Epoch Loss: 18605.4410 - Avg Loss: 157.6732\n",
            "Epoch [38/50] - Batch loss: 159.8051 - Epoch Loss: 18765.2462 - Avg Loss: 157.6911\n",
            "Epoch [38/50] - Batch loss: 152.1242 - Epoch Loss: 18917.3703 - Avg Loss: 157.6448\n",
            "Epoch [38/50] - Batch loss: 151.0777 - Epoch Loss: 19068.4480 - Avg Loss: 157.5905\n",
            "Epoch [38/50] - Batch loss: 154.6873 - Epoch Loss: 19223.1354 - Avg Loss: 157.5667\n",
            "Epoch [38/50] - Batch loss: 154.7466 - Epoch Loss: 19377.8820 - Avg Loss: 157.5438\n",
            "Epoch [38/50] - Batch loss: 162.4061 - Epoch Loss: 19540.2881 - Avg Loss: 157.5830\n",
            "Epoch [38/50] - Batch loss: 167.4778 - Epoch Loss: 19707.7659 - Avg Loss: 157.6621\n",
            "Epoch [38/50] - Batch loss: 155.3665 - Epoch Loss: 19863.1324 - Avg Loss: 157.6439\n",
            "Epoch [38/50] - Batch loss: 151.2585 - Epoch Loss: 20014.3909 - Avg Loss: 157.5936\n",
            "Epoch [38/50] - Batch loss: 153.0189 - Epoch Loss: 20167.4098 - Avg Loss: 157.5579\n",
            "Epoch [38/50] - Batch loss: 154.0569 - Epoch Loss: 20321.4667 - Avg Loss: 157.5307\n",
            "Epoch [38/50] - Batch loss: 151.7850 - Epoch Loss: 20473.2517 - Avg Loss: 157.4866\n",
            "Epoch [38/50] - Batch loss: 160.1858 - Epoch Loss: 20633.4375 - Avg Loss: 157.5072\n",
            "Epoch [38/50] - Batch loss: 160.0745 - Epoch Loss: 20793.5120 - Avg Loss: 157.5266\n",
            "Epoch [38/50] - Batch loss: 158.1728 - Epoch Loss: 20951.6848 - Avg Loss: 157.5315\n",
            "Epoch [38/50] - Batch loss: 154.5935 - Epoch Loss: 21106.2783 - Avg Loss: 157.5095\n",
            "Epoch [38/50] - Batch loss: 161.3944 - Epoch Loss: 21267.6728 - Avg Loss: 157.5383\n",
            "Epoch [38/50] - Batch loss: 152.7534 - Epoch Loss: 21420.4262 - Avg Loss: 157.5031\n",
            "Epoch [38/50] - Batch loss: 145.4459 - Epoch Loss: 21565.8721 - Avg Loss: 157.4151\n",
            "Epoch [38/50] - Batch loss: 164.2737 - Epoch Loss: 21730.1458 - Avg Loss: 157.4648\n",
            "Epoch [38/50] - Batch loss: 158.8425 - Epoch Loss: 21888.9883 - Avg Loss: 157.4747\n",
            "Epoch [38/50] - Batch loss: 150.1602 - Epoch Loss: 22039.1485 - Avg Loss: 157.4225\n",
            "Epoch [38/50] - Batch loss: 161.3193 - Epoch Loss: 22200.4678 - Avg Loss: 157.4501\n",
            "Epoch [38/50] - Batch loss: 165.9766 - Epoch Loss: 22366.4445 - Avg Loss: 157.5102\n",
            "Epoch [38/50] - Batch loss: 159.0890 - Epoch Loss: 22525.5334 - Avg Loss: 157.5212\n",
            "Epoch [38/50] - Batch loss: 154.7808 - Epoch Loss: 22680.3142 - Avg Loss: 157.5022\n",
            "Epoch [38/50] - Batch loss: 160.9017 - Epoch Loss: 22841.2159 - Avg Loss: 157.5256\n",
            "Epoch [38/50] - Batch loss: 157.6223 - Epoch Loss: 22998.8382 - Avg Loss: 157.5263\n",
            "Epoch [38/50] - Batch loss: 165.3049 - Epoch Loss: 23164.1431 - Avg Loss: 157.5792\n",
            "Epoch [38/50] - Batch loss: 154.9020 - Epoch Loss: 23319.0451 - Avg Loss: 157.5611\n",
            "Epoch [38/50] - Batch loss: 160.4714 - Epoch Loss: 23479.5165 - Avg Loss: 157.5806\n",
            "Epoch [38/50] - Batch loss: 152.9992 - Epoch Loss: 23632.5157 - Avg Loss: 157.5501\n",
            "Epoch [38/50] - Batch loss: 161.3467 - Epoch Loss: 23793.8624 - Avg Loss: 157.5752\n",
            "Epoch [38/50] - Batch loss: 156.0077 - Epoch Loss: 23949.8701 - Avg Loss: 157.5649\n",
            "Epoch [38/50] - Batch loss: 141.0526 - Epoch Loss: 24090.9227 - Avg Loss: 157.4570\n",
            "Epoch [38/50] - Batch loss: 161.8898 - Epoch Loss: 24252.8125 - Avg Loss: 157.4858\n",
            "Epoch [38/50] - Batch loss: 159.9843 - Epoch Loss: 24412.7967 - Avg Loss: 157.5019\n",
            "Epoch [38/50] - Batch loss: 151.3576 - Epoch Loss: 24564.1543 - Avg Loss: 157.4625\n",
            "Epoch [38/50] - Batch loss: 157.8612 - Epoch Loss: 24722.0155 - Avg Loss: 157.4651\n",
            "Epoch [38/50] - Batch loss: 163.0399 - Epoch Loss: 24885.0554 - Avg Loss: 157.5004\n",
            "Epoch [38/50] - Batch loss: 156.4323 - Epoch Loss: 25041.4878 - Avg Loss: 157.4936\n",
            "Epoch [38/50] - Batch loss: 160.3375 - Epoch Loss: 25201.8253 - Avg Loss: 157.5114\n",
            "Epoch [38/50] - Batch loss: 155.9922 - Epoch Loss: 25357.8175 - Avg Loss: 157.5020\n",
            "Epoch [38/50] - Batch loss: 155.6866 - Epoch Loss: 25513.5041 - Avg Loss: 157.4908\n",
            "Epoch [38/50] - Batch loss: 154.4360 - Epoch Loss: 25667.9401 - Avg Loss: 157.4720\n",
            "Epoch [38/50] - Batch loss: 162.4784 - Epoch Loss: 25830.4185 - Avg Loss: 157.5026\n",
            "Epoch [38/50] - Batch loss: 157.4997 - Epoch Loss: 25987.9182 - Avg Loss: 157.5025\n",
            "Epoch [38/50] - Batch loss: 160.7477 - Epoch Loss: 26148.6659 - Avg Loss: 157.5221\n",
            "Epoch [38/50] - Batch loss: 164.6400 - Epoch Loss: 26313.3059 - Avg Loss: 157.5647\n",
            "Epoch [38/50] - Batch loss: 164.2442 - Epoch Loss: 26477.5501 - Avg Loss: 157.6045\n",
            "Epoch [38/50] - Batch loss: 153.0282 - Epoch Loss: 26630.5783 - Avg Loss: 157.5774\n",
            "Epoch [38/50] - Batch loss: 158.5009 - Epoch Loss: 26789.0792 - Avg Loss: 157.5828\n",
            "Epoch [38/50] - Batch loss: 159.8756 - Epoch Loss: 26948.9548 - Avg Loss: 157.5962\n",
            "Epoch [38/50] - Batch loss: 156.7781 - Epoch Loss: 27105.7329 - Avg Loss: 157.5915\n",
            "Epoch [38/50] - Batch loss: 157.0601 - Epoch Loss: 27262.7930 - Avg Loss: 157.5884\n",
            "Epoch [38/50] - Batch loss: 155.5526 - Epoch Loss: 27418.3456 - Avg Loss: 157.5767\n",
            "Epoch [38/50] - Batch loss: 162.3190 - Epoch Loss: 27580.6646 - Avg Loss: 157.6038\n",
            "Epoch [38/50] - Batch loss: 164.8525 - Epoch Loss: 27745.5171 - Avg Loss: 157.6450\n",
            "Epoch [38/50] - Batch loss: 163.0050 - Epoch Loss: 27908.5221 - Avg Loss: 157.6753\n",
            "Epoch [38/50] - Batch loss: 158.9223 - Epoch Loss: 28067.4444 - Avg Loss: 157.6823\n",
            "Epoch [38/50] - Batch loss: 156.7841 - Epoch Loss: 28224.2285 - Avg Loss: 157.6773\n",
            "Epoch [38/50] - Batch loss: 162.2552 - Epoch Loss: 28386.4838 - Avg Loss: 157.7027\n",
            "Epoch [38/50] - Batch loss: 161.6986 - Epoch Loss: 28548.1823 - Avg Loss: 157.7248\n",
            "Epoch [38/50] - Batch loss: 161.1752 - Epoch Loss: 28709.3575 - Avg Loss: 157.7437\n",
            "Epoch [38/50] - Batch loss: 154.5212 - Epoch Loss: 28863.8787 - Avg Loss: 157.7261\n",
            "Epoch [38/50] - Batch loss: 155.9704 - Epoch Loss: 29019.8491 - Avg Loss: 157.7166\n",
            "Epoch [38/50] - Batch loss: 155.5269 - Epoch Loss: 29175.3760 - Avg Loss: 157.7047\n",
            "Epoch [38/50] - Batch loss: 160.2128 - Epoch Loss: 29335.5888 - Avg Loss: 157.7182\n",
            "Epoch [38/50] - Batch loss: 162.2050 - Epoch Loss: 29497.7938 - Avg Loss: 157.7422\n",
            "Epoch [38/50] - Batch loss: 154.1232 - Epoch Loss: 29651.9169 - Avg Loss: 157.7230\n",
            "Epoch [38/50] - Batch loss: 161.6508 - Epoch Loss: 29813.5677 - Avg Loss: 157.7437\n",
            "Epoch [38/50] - Batch loss: 159.5935 - Epoch Loss: 29973.1612 - Avg Loss: 157.7535\n",
            "Epoch [38/50] - Batch loss: 160.9481 - Epoch Loss: 30134.1093 - Avg Loss: 157.7702\n",
            "Epoch [38/50] - Batch loss: 160.6049 - Epoch Loss: 30294.7142 - Avg Loss: 157.7850\n",
            "Epoch [38/50] - Batch loss: 160.6565 - Epoch Loss: 30455.3708 - Avg Loss: 157.7998\n",
            "Epoch [38/50] - Batch loss: 155.3010 - Epoch Loss: 30610.6717 - Avg Loss: 157.7870\n",
            "Epoch [38/50] - Batch loss: 148.7245 - Epoch Loss: 30759.3962 - Avg Loss: 157.7405\n",
            "Epoch [38/50] - Batch loss: 161.3958 - Epoch Loss: 30920.7920 - Avg Loss: 157.7591\n",
            "Epoch [38/50] - Batch loss: 155.2728 - Epoch Loss: 31076.0648 - Avg Loss: 157.7465\n",
            "Epoch [38/50] - Batch loss: 153.8025 - Epoch Loss: 31229.8673 - Avg Loss: 157.7266\n",
            "Epoch [38/50] - Batch loss: 154.5603 - Epoch Loss: 31384.4276 - Avg Loss: 157.7107\n",
            "Epoch [38/50] - Batch loss: 153.8879 - Epoch Loss: 31538.3155 - Avg Loss: 157.6916\n",
            "Epoch [38/50] - Batch loss: 156.8762 - Epoch Loss: 31695.1917 - Avg Loss: 157.6875\n",
            "Epoch [38/50] - Batch loss: 164.0276 - Epoch Loss: 31859.2193 - Avg Loss: 157.7189\n",
            "Epoch [38/50] - Batch loss: 163.5915 - Epoch Loss: 32022.8108 - Avg Loss: 157.7478\n",
            "Epoch [38/50] - Batch loss: 160.7124 - Epoch Loss: 32183.5232 - Avg Loss: 157.7624\n",
            "Epoch [38/50] - Batch loss: 161.8015 - Epoch Loss: 32345.3246 - Avg Loss: 157.7821\n",
            "Epoch [38/50] - Batch loss: 156.5365 - Epoch Loss: 32501.8611 - Avg Loss: 157.7760\n",
            "Epoch [38/50] - Batch loss: 162.9783 - Epoch Loss: 32664.8394 - Avg Loss: 157.8012\n",
            "Epoch [38/50] - Batch loss: 162.8936 - Epoch Loss: 32827.7331 - Avg Loss: 157.8256\n",
            "Epoch [38/50] - Batch loss: 156.0279 - Epoch Loss: 32983.7610 - Avg Loss: 157.8170\n",
            "Epoch [38/50] - Batch loss: 162.0036 - Epoch Loss: 33145.7646 - Avg Loss: 157.8370\n",
            "Epoch [38/50] - Batch loss: 167.2105 - Epoch Loss: 33312.9751 - Avg Loss: 157.8814\n",
            "Epoch [38/50] - Batch loss: 163.1130 - Epoch Loss: 33476.0881 - Avg Loss: 157.9061\n",
            "Epoch [38/50] - Batch loss: 160.3219 - Epoch Loss: 33636.4100 - Avg Loss: 157.9174\n",
            "Epoch [38/50] - Batch loss: 160.7791 - Epoch Loss: 33797.1891 - Avg Loss: 157.9308\n",
            "Epoch [38/50] - Batch loss: 163.3575 - Epoch Loss: 33960.5465 - Avg Loss: 157.9560\n",
            "Epoch [38/50] - Batch loss: 157.9943 - Epoch Loss: 34118.5408 - Avg Loss: 157.9562\n",
            "Epoch [38/50] - Batch loss: 156.4694 - Epoch Loss: 34275.0102 - Avg Loss: 157.9494\n",
            "Epoch [38/50] - Batch loss: 154.1146 - Epoch Loss: 34429.1248 - Avg Loss: 157.9318\n",
            "Epoch [38/50] - Batch loss: 164.6747 - Epoch Loss: 34593.7996 - Avg Loss: 157.9626\n",
            "Epoch [38/50] - Batch loss: 159.3814 - Epoch Loss: 34753.1810 - Avg Loss: 157.9690\n",
            "Epoch [38/50] - Batch loss: 157.7458 - Epoch Loss: 34910.9268 - Avg Loss: 157.9680\n",
            "Epoch [38/50] - Batch loss: 160.1271 - Epoch Loss: 35071.0538 - Avg Loss: 157.9777\n",
            "Epoch [38/50] - Batch loss: 164.2525 - Epoch Loss: 35235.3064 - Avg Loss: 158.0059\n",
            "Epoch [38/50] - Batch loss: 156.7275 - Epoch Loss: 35392.0339 - Avg Loss: 158.0002\n",
            "Epoch [38/50] - Batch loss: 164.2178 - Epoch Loss: 35556.2516 - Avg Loss: 158.0278\n",
            "Epoch [38/50] - Batch loss: 169.8485 - Epoch Loss: 35726.1002 - Avg Loss: 158.0801\n",
            "Epoch [38/50] - Batch loss: 156.3842 - Epoch Loss: 35882.4844 - Avg Loss: 158.0726\n",
            "Epoch [38/50] - Batch loss: 160.6335 - Epoch Loss: 36043.1179 - Avg Loss: 158.0839\n",
            "Epoch [38/50] - Batch loss: 150.7514 - Epoch Loss: 36193.8693 - Avg Loss: 158.0518\n",
            "Epoch [38/50] - Batch loss: 162.0137 - Epoch Loss: 36355.8830 - Avg Loss: 158.0691\n",
            "Epoch [38/50] - Batch loss: 155.8337 - Epoch Loss: 36511.7168 - Avg Loss: 158.0594\n",
            "Epoch [38/50] - Batch loss: 164.3829 - Epoch Loss: 36676.0997 - Avg Loss: 158.0866\n",
            "Epoch [38/50] - Batch loss: 159.1297 - Epoch Loss: 36835.2294 - Avg Loss: 158.0911\n",
            "Epoch [38/50] - Batch loss: 162.4074 - Epoch Loss: 36997.6368 - Avg Loss: 158.1096\n",
            "Epoch [38/50] - Batch loss: 166.5639 - Epoch Loss: 37164.2007 - Avg Loss: 158.1455\n",
            "Epoch [38/50] - Batch loss: 157.9901 - Epoch Loss: 37322.1908 - Avg Loss: 158.1449\n",
            "Epoch [38/50] - Batch loss: 158.4733 - Epoch Loss: 37480.6641 - Avg Loss: 158.1463\n",
            "Epoch [38/50] - Batch loss: 156.0748 - Epoch Loss: 37636.7389 - Avg Loss: 158.1376\n",
            "Epoch [38/50] - Batch loss: 163.0009 - Epoch Loss: 37799.7399 - Avg Loss: 158.1579\n",
            "Epoch [38/50] - Batch loss: 155.0841 - Epoch Loss: 37954.8239 - Avg Loss: 158.1451\n",
            "Epoch [38/50] - Batch loss: 167.1393 - Epoch Loss: 38121.9632 - Avg Loss: 158.1824\n",
            "Epoch [38/50] - Batch loss: 159.0575 - Epoch Loss: 38281.0208 - Avg Loss: 158.1860\n",
            "Epoch [38/50] - Batch loss: 159.5105 - Epoch Loss: 38440.5312 - Avg Loss: 158.1915\n",
            "Epoch [38/50] - Batch loss: 165.6693 - Epoch Loss: 38606.2005 - Avg Loss: 158.2221\n",
            "Epoch [38/50] - Batch loss: 155.8425 - Epoch Loss: 38762.0430 - Avg Loss: 158.2124\n",
            "Epoch [38/50] - Batch loss: 153.5147 - Epoch Loss: 38915.5577 - Avg Loss: 158.1933\n",
            "Epoch [38/50] - Batch loss: 157.7534 - Epoch Loss: 39073.3111 - Avg Loss: 158.1915\n",
            "Epoch [38/50] - Batch loss: 152.4521 - Epoch Loss: 39225.7632 - Avg Loss: 158.1684\n",
            "Epoch [38/50] - Batch loss: 162.9294 - Epoch Loss: 39388.6926 - Avg Loss: 158.1875\n",
            "Epoch [38/50] - Batch loss: 154.7770 - Epoch Loss: 39543.4697 - Avg Loss: 158.1739\n",
            "Epoch [38/50] - Batch loss: 159.9773 - Epoch Loss: 39703.4470 - Avg Loss: 158.1811\n",
            "Epoch [38/50] - Batch loss: 152.2754 - Epoch Loss: 39855.7224 - Avg Loss: 158.1576\n",
            "Epoch [38/50] - Batch loss: 155.6652 - Epoch Loss: 40011.3876 - Avg Loss: 158.1478\n",
            "Epoch [38/50] - Batch loss: 159.5677 - Epoch Loss: 40170.9553 - Avg Loss: 158.1534\n",
            "Epoch [38/50] - Batch loss: 156.2299 - Epoch Loss: 40327.1852 - Avg Loss: 158.1458\n",
            "Epoch [38/50] - Batch loss: 159.0968 - Epoch Loss: 40486.2820 - Avg Loss: 158.1495\n",
            "Epoch [38/50] - Batch loss: 162.8735 - Epoch Loss: 40649.1555 - Avg Loss: 158.1679\n",
            "Epoch [38/50] - Batch loss: 161.0770 - Epoch Loss: 40810.2325 - Avg Loss: 158.1792\n",
            "Epoch [38/50] - Batch loss: 154.3745 - Epoch Loss: 40964.6070 - Avg Loss: 158.1645\n",
            "Epoch [38/50] - Batch loss: 158.7815 - Epoch Loss: 41123.3885 - Avg Loss: 158.1669\n",
            "Epoch [38/50] - Batch loss: 154.9635 - Epoch Loss: 41278.3520 - Avg Loss: 158.1546\n",
            "Epoch [38/50] - Batch loss: 165.6457 - Epoch Loss: 41443.9977 - Avg Loss: 158.1832\n",
            "Epoch [38/50] - Batch loss: 156.2997 - Epoch Loss: 41600.2974 - Avg Loss: 158.1760\n",
            "Epoch [38/50] - Batch loss: 162.3610 - Epoch Loss: 41762.6585 - Avg Loss: 158.1919\n",
            "Epoch [38/50] - Batch loss: 165.6864 - Epoch Loss: 41928.3449 - Avg Loss: 158.2202\n",
            "Epoch [38/50] - Batch loss: 160.8947 - Epoch Loss: 42089.2396 - Avg Loss: 158.2302\n",
            "Epoch [38/50] - Batch loss: 154.0282 - Epoch Loss: 42243.2678 - Avg Loss: 158.2145\n",
            "Epoch [38/50] - Batch loss: 157.0518 - Epoch Loss: 42400.3196 - Avg Loss: 158.2101\n",
            "Epoch [38/50] - Batch loss: 164.8162 - Epoch Loss: 42565.1358 - Avg Loss: 158.2347\n",
            "Epoch [38/50] - Batch loss: 160.0890 - Epoch Loss: 42725.2248 - Avg Loss: 158.2416\n",
            "Epoch [38/50] - Batch loss: 167.7439 - Epoch Loss: 42892.9687 - Avg Loss: 158.2766\n",
            "Epoch [38/50] - Batch loss: 161.4828 - Epoch Loss: 43054.4516 - Avg Loss: 158.2884\n",
            "Epoch [38/50] - Batch loss: 156.4750 - Epoch Loss: 43210.9266 - Avg Loss: 158.2818\n",
            "Epoch [38/50] - Batch loss: 163.7612 - Epoch Loss: 43374.6878 - Avg Loss: 158.3018\n",
            "Epoch [38/50] - Batch loss: 164.8564 - Epoch Loss: 43539.5442 - Avg Loss: 158.3256\n",
            "Epoch [38/50] - Batch loss: 156.1771 - Epoch Loss: 43695.7213 - Avg Loss: 158.3178\n",
            "Epoch [38/50] - Batch loss: 156.2608 - Epoch Loss: 43851.9821 - Avg Loss: 158.3104\n",
            "Epoch [38/50] - Batch loss: 154.0141 - Epoch Loss: 44005.9962 - Avg Loss: 158.2950\n",
            "Epoch [38/50] - Batch loss: 159.2937 - Epoch Loss: 44165.2899 - Avg Loss: 158.2985\n",
            "Epoch [38/50] - Batch loss: 159.1830 - Epoch Loss: 44324.4729 - Avg Loss: 158.3017\n",
            "Epoch [38/50] - Batch loss: 155.6127 - Epoch Loss: 44480.0856 - Avg Loss: 158.2921\n",
            "Epoch [38/50] - Batch loss: 162.5553 - Epoch Loss: 44642.6409 - Avg Loss: 158.3072\n",
            "Epoch [38/50] - Batch loss: 153.5672 - Epoch Loss: 44796.2081 - Avg Loss: 158.2905\n",
            "Epoch [38/50] - Batch loss: 164.3889 - Epoch Loss: 44960.5970 - Avg Loss: 158.3120\n",
            "Epoch [38/50] - Batch loss: 159.7459 - Epoch Loss: 45120.3429 - Avg Loss: 158.3170\n",
            "Epoch [38/50] - Batch loss: 152.3972 - Epoch Loss: 45272.7402 - Avg Loss: 158.2963\n",
            "Epoch [38/50] - Batch loss: 153.9971 - Epoch Loss: 45426.7373 - Avg Loss: 158.2813\n",
            "Epoch [38/50] - Batch loss: 162.4184 - Epoch Loss: 45589.1556 - Avg Loss: 158.2957\n",
            "Epoch [38/50] - Batch loss: 162.3268 - Epoch Loss: 45751.4824 - Avg Loss: 158.3096\n",
            "Epoch [38/50] - Batch loss: 166.9616 - Epoch Loss: 45918.4440 - Avg Loss: 158.3395\n",
            "Epoch [38/50] - Batch loss: 156.2080 - Epoch Loss: 46074.6520 - Avg Loss: 158.3321\n",
            "Epoch [38/50] - Batch loss: 168.5569 - Epoch Loss: 46243.2089 - Avg Loss: 158.3672\n",
            "Epoch [38/50] - Batch loss: 159.2061 - Epoch Loss: 46402.4150 - Avg Loss: 158.3700\n",
            "Epoch [38/50] - Batch loss: 154.6862 - Epoch Loss: 46557.1012 - Avg Loss: 158.3575\n",
            "Epoch [38/50] - Batch loss: 165.9115 - Epoch Loss: 46723.0127 - Avg Loss: 158.3831\n",
            "Epoch [38/50] - Batch loss: 161.1697 - Epoch Loss: 46884.1824 - Avg Loss: 158.3925\n",
            "Epoch [38/50] - Batch loss: 157.1191 - Epoch Loss: 47041.3015 - Avg Loss: 158.3882\n",
            "Epoch [38/50] - Batch loss: 168.6448 - Epoch Loss: 47209.9463 - Avg Loss: 158.4226\n",
            "Epoch [38/50] - Batch loss: 164.0024 - Epoch Loss: 47373.9487 - Avg Loss: 158.4413\n",
            "Epoch [38/50] - Batch loss: 152.0238 - Epoch Loss: 47525.9725 - Avg Loss: 158.4199\n",
            "Epoch [38/50] - Batch loss: 155.4301 - Epoch Loss: 47681.4026 - Avg Loss: 158.4100\n",
            "Epoch [38/50] - Batch loss: 158.1381 - Epoch Loss: 47839.5407 - Avg Loss: 158.4091\n",
            "Epoch [38/50] - Batch loss: 157.8710 - Epoch Loss: 47997.4117 - Avg Loss: 158.4073\n",
            "Epoch [38/50] - Batch loss: 158.0332 - Epoch Loss: 48155.4449 - Avg Loss: 158.4061\n",
            "Epoch [38/50] - Batch loss: 153.7917 - Epoch Loss: 48309.2366 - Avg Loss: 158.3909\n",
            "Epoch [38/50] - Batch loss: 155.6240 - Epoch Loss: 48464.8606 - Avg Loss: 158.3819\n",
            "Epoch [38/50] - Batch loss: 163.7815 - Epoch Loss: 48628.6421 - Avg Loss: 158.3995\n",
            "Epoch [38/50] - Batch loss: 162.6711 - Epoch Loss: 48791.3132 - Avg Loss: 158.4134\n",
            "Epoch [38/50] - Batch loss: 160.1458 - Epoch Loss: 48951.4590 - Avg Loss: 158.4190\n",
            "Epoch [38/50] - Batch loss: 159.4728 - Epoch Loss: 49110.9318 - Avg Loss: 158.4224\n",
            "Epoch [38/50] - Batch loss: 165.4183 - Epoch Loss: 49276.3501 - Avg Loss: 158.4449\n",
            "Epoch [38/50] - Batch loss: 162.2936 - Epoch Loss: 49438.6438 - Avg Loss: 158.4572\n",
            "Epoch [38/50] - Batch loss: 158.7915 - Epoch Loss: 49597.4353 - Avg Loss: 158.4583\n",
            "Epoch [38/50] - Batch loss: 163.0179 - Epoch Loss: 49760.4532 - Avg Loss: 158.4728\n",
            "Epoch [38/50] - Batch loss: 163.1415 - Epoch Loss: 49923.5947 - Avg Loss: 158.4876\n",
            "Epoch [38/50] - Batch loss: 165.9222 - Epoch Loss: 50089.5169 - Avg Loss: 158.5111\n",
            "Epoch [38/50] - Batch loss: 164.6972 - Epoch Loss: 50254.2141 - Avg Loss: 158.5306\n",
            "Epoch [38/50] - Batch loss: 152.8816 - Epoch Loss: 50407.0957 - Avg Loss: 158.5129\n",
            "Epoch [38/50] - Batch loss: 159.8334 - Epoch Loss: 50566.9291 - Avg Loss: 158.5170\n",
            "Epoch [38/50] - Batch loss: 161.7541 - Epoch Loss: 50728.6831 - Avg Loss: 158.5271\n",
            "Epoch [38/50] - Batch loss: 157.4956 - Epoch Loss: 50886.1788 - Avg Loss: 158.5239\n",
            "Epoch [38/50] - Batch loss: 166.7402 - Epoch Loss: 51052.9190 - Avg Loss: 158.5494\n",
            "Epoch [38/50] - Batch loss: 163.9111 - Epoch Loss: 51216.8300 - Avg Loss: 158.5660\n",
            "Epoch [38/50] - Batch loss: 164.1916 - Epoch Loss: 51381.0216 - Avg Loss: 158.5834\n",
            "Epoch [38/50] - Batch loss: 163.6013 - Epoch Loss: 51544.6229 - Avg Loss: 158.5988\n",
            "Epoch [38/50] - Batch loss: 159.3818 - Epoch Loss: 51704.0046 - Avg Loss: 158.6012\n",
            "Epoch [38/50] - Batch loss: 165.7911 - Epoch Loss: 51869.7958 - Avg Loss: 158.6232\n",
            "Epoch [38/50] - Batch loss: 152.9997 - Epoch Loss: 52022.7955 - Avg Loss: 158.6061\n",
            "Epoch [38/50] - Batch loss: 163.0860 - Epoch Loss: 52185.8815 - Avg Loss: 158.6197\n",
            "Epoch [38/50] - Batch loss: 152.5678 - Epoch Loss: 52338.4492 - Avg Loss: 158.6014\n",
            "Epoch [38/50] - Batch loss: 159.4301 - Epoch Loss: 52497.8794 - Avg Loss: 158.6039\n",
            "Epoch [38/50] - Batch loss: 160.6551 - Epoch Loss: 52658.5345 - Avg Loss: 158.6100\n",
            "Epoch [38/50] - Batch loss: 169.1707 - Epoch Loss: 52827.7052 - Avg Loss: 158.6418\n",
            "Epoch [38/50] - Batch loss: 155.2896 - Epoch Loss: 52982.9948 - Avg Loss: 158.6317\n",
            "Epoch [38/50] - Batch loss: 167.5282 - Epoch Loss: 53150.5230 - Avg Loss: 158.6583\n",
            "Epoch [38/50] - Batch loss: 157.9443 - Epoch Loss: 53308.4673 - Avg Loss: 158.6562\n",
            "Epoch [38/50] - Batch loss: 160.2988 - Epoch Loss: 53468.7661 - Avg Loss: 158.6610\n",
            "Epoch [38/50] - Batch loss: 156.1129 - Epoch Loss: 53624.8790 - Avg Loss: 158.6535\n",
            "Epoch [38/50] - Batch loss: 157.1621 - Epoch Loss: 53782.0411 - Avg Loss: 158.6491\n",
            "Epoch [38/50] - Batch loss: 155.9413 - Epoch Loss: 53937.9823 - Avg Loss: 158.6411\n",
            "Epoch [38/50] - Batch loss: 165.1255 - Epoch Loss: 54103.1078 - Avg Loss: 158.6601\n",
            "Epoch [38/50] - Batch loss: 155.6896 - Epoch Loss: 54258.7974 - Avg Loss: 158.6515\n",
            "Epoch [38/50] - Batch loss: 160.6099 - Epoch Loss: 54419.4073 - Avg Loss: 158.6572\n",
            "Epoch [38/50] - Batch loss: 169.2795 - Epoch Loss: 54588.6868 - Avg Loss: 158.6880\n",
            "Epoch [38/50] - Batch loss: 155.8530 - Epoch Loss: 54744.5397 - Avg Loss: 158.6798\n",
            "Epoch [38/50] - Batch loss: 162.4311 - Epoch Loss: 54906.9709 - Avg Loss: 158.6907\n",
            "Epoch [38/50] - Batch loss: 168.8646 - Epoch Loss: 55075.8355 - Avg Loss: 158.7200\n",
            "Epoch [38/50] - Batch loss: 168.8606 - Epoch Loss: 55244.6960 - Avg Loss: 158.7491\n",
            "Epoch [38/50] - Batch loss: 165.1131 - Epoch Loss: 55409.8092 - Avg Loss: 158.7674\n",
            "Epoch [38/50] - Batch loss: 159.8232 - Epoch Loss: 55569.6324 - Avg Loss: 158.7704\n",
            "Epoch [38/50] - Batch loss: 149.2263 - Epoch Loss: 55718.8587 - Avg Loss: 158.7432\n",
            "Epoch [38/50] - Batch loss: 161.8317 - Epoch Loss: 55880.6904 - Avg Loss: 158.7520\n",
            "Epoch [38/50] - Batch loss: 161.0280 - Epoch Loss: 56041.7184 - Avg Loss: 158.7584\n",
            "Epoch [38/50] - Batch loss: 166.7713 - Epoch Loss: 56208.4897 - Avg Loss: 158.7810\n",
            "Epoch [38/50] - Batch loss: 159.6263 - Epoch Loss: 56368.1160 - Avg Loss: 158.7834\n",
            "Epoch [38/50] - Batch loss: 155.2464 - Epoch Loss: 56523.3623 - Avg Loss: 158.7735\n",
            "Epoch [38/50] - Batch loss: 151.7030 - Epoch Loss: 56675.0653 - Avg Loss: 158.7537\n",
            "Epoch [38/50] - Batch loss: 156.0126 - Epoch Loss: 56831.0779 - Avg Loss: 158.7460\n",
            "Epoch [38/50] - Batch loss: 155.8037 - Epoch Loss: 56986.8816 - Avg Loss: 158.7378\n",
            "Epoch [38/50] - Batch loss: 157.4099 - Epoch Loss: 57144.2914 - Avg Loss: 158.7341\n",
            "Epoch [38/50] - Batch loss: 162.6600 - Epoch Loss: 57306.9514 - Avg Loss: 158.7450\n",
            "Epoch [38/50] - Batch loss: 158.6480 - Epoch Loss: 57465.5994 - Avg Loss: 158.7447\n",
            "Epoch [38/50] - Batch loss: 164.8914 - Epoch Loss: 57630.4908 - Avg Loss: 158.7617\n",
            "Epoch [38/50] - Batch loss: 163.5779 - Epoch Loss: 57794.0688 - Avg Loss: 158.7749\n",
            "Epoch [38/50] - Batch loss: 149.8114 - Epoch Loss: 57943.8801 - Avg Loss: 158.7504\n",
            "Epoch [38/50] - Batch loss: 160.8385 - Epoch Loss: 58104.7186 - Avg Loss: 158.7561\n",
            "Epoch [38/50] - Batch loss: 159.6265 - Epoch Loss: 58264.3451 - Avg Loss: 158.7584\n",
            "Epoch [38/50] - Batch loss: 158.6506 - Epoch Loss: 58422.9957 - Avg Loss: 158.7581\n",
            "Epoch [38/50] - Batch loss: 159.8491 - Epoch Loss: 58582.8448 - Avg Loss: 158.7611\n",
            "Epoch [38/50] - Batch loss: 156.7536 - Epoch Loss: 58739.5984 - Avg Loss: 158.7557\n",
            "Epoch [38/50] - Batch loss: 160.3664 - Epoch Loss: 58899.9648 - Avg Loss: 158.7600\n",
            "Epoch [38/50] - Batch loss: 161.5378 - Epoch Loss: 59061.5027 - Avg Loss: 158.7675\n",
            "Epoch [38/50] - Batch loss: 153.2436 - Epoch Loss: 59214.7463 - Avg Loss: 158.7527\n",
            "Epoch [38/50] - Batch loss: 153.7418 - Epoch Loss: 59368.4881 - Avg Loss: 158.7393\n",
            "Epoch [38/50] - Batch loss: 161.1526 - Epoch Loss: 59529.6408 - Avg Loss: 158.7457\n",
            "Epoch [38/50] - Batch loss: 157.8412 - Epoch Loss: 59687.4819 - Avg Loss: 158.7433\n",
            "Epoch [38/50] - Batch loss: 163.5659 - Epoch Loss: 59851.0479 - Avg Loss: 158.7561\n",
            "Epoch [38/50] - Batch loss: 157.4862 - Epoch Loss: 60008.5341 - Avg Loss: 158.7527\n",
            "Epoch [38/50] - Batch loss: 157.5653 - Epoch Loss: 60166.0993 - Avg Loss: 158.7496\n",
            "Epoch [38/50] - Batch loss: 151.6065 - Epoch Loss: 60317.7059 - Avg Loss: 158.7308\n",
            "Epoch [38/50] - Batch loss: 156.3908 - Epoch Loss: 60474.0966 - Avg Loss: 158.7247\n",
            "Epoch [38/50] - Batch loss: 165.1088 - Epoch Loss: 60639.2054 - Avg Loss: 158.7414\n",
            "Epoch [38/50] - Batch loss: 167.3243 - Epoch Loss: 60806.5297 - Avg Loss: 158.7638\n",
            "Epoch [38/50] - Batch loss: 159.4803 - Epoch Loss: 60966.0100 - Avg Loss: 158.7657\n",
            "Epoch [38/50] - Batch loss: 159.0008 - Epoch Loss: 61125.0108 - Avg Loss: 158.7663\n",
            "Epoch [38/50] - Batch loss: 155.2093 - Epoch Loss: 61280.2201 - Avg Loss: 158.7570\n",
            "Epoch [38/50] - Batch loss: 152.0824 - Epoch Loss: 61432.3026 - Avg Loss: 158.7398\n",
            "Epoch [38/50] - Batch loss: 147.3964 - Epoch Loss: 61579.6989 - Avg Loss: 158.7106\n",
            "Epoch [38/50] - Batch loss: 158.4174 - Epoch Loss: 61738.1164 - Avg Loss: 158.7098\n",
            "Epoch [38/50] - Batch loss: 154.9151 - Epoch Loss: 61893.0315 - Avg Loss: 158.7001\n",
            "Epoch [38/50] - Batch loss: 163.3751 - Epoch Loss: 62056.4066 - Avg Loss: 158.7120\n",
            "Epoch [38/50] - Batch loss: 164.7909 - Epoch Loss: 62221.1976 - Avg Loss: 158.7275\n",
            "Epoch [38/50] - Batch loss: 157.3860 - Epoch Loss: 62378.5835 - Avg Loss: 158.7241\n",
            "Epoch [38/50] - Batch loss: 164.2964 - Epoch Loss: 62542.8800 - Avg Loss: 158.7383\n",
            "Epoch [38/50] - Batch loss: 163.2204 - Epoch Loss: 62706.1003 - Avg Loss: 158.7496\n",
            "Epoch [38/50] - Batch loss: 157.5545 - Epoch Loss: 62863.6548 - Avg Loss: 158.7466\n",
            "Epoch [38/50] - Batch loss: 165.2834 - Epoch Loss: 63028.9382 - Avg Loss: 158.7631\n",
            "Epoch [38/50] - Batch loss: 160.0581 - Epoch Loss: 63188.9963 - Avg Loss: 158.7663\n",
            "Epoch [38/50] - Batch loss: 150.8536 - Epoch Loss: 63339.8499 - Avg Loss: 158.7465\n",
            "Epoch [38/50] - Batch loss: 159.7474 - Epoch Loss: 63499.5973 - Avg Loss: 158.7490\n",
            "Epoch [38/50] - Batch loss: 162.5387 - Epoch Loss: 63662.1360 - Avg Loss: 158.7584\n",
            "Epoch [38/50] - Batch loss: 155.6981 - Epoch Loss: 63817.8341 - Avg Loss: 158.7508\n",
            "Epoch [38/50] - Batch loss: 154.0780 - Epoch Loss: 63971.9120 - Avg Loss: 158.7392\n",
            "Epoch [38/50] - Batch loss: 151.8096 - Epoch Loss: 64123.7216 - Avg Loss: 158.7221\n",
            "Epoch [38/50] - Batch loss: 157.3276 - Epoch Loss: 64281.0493 - Avg Loss: 158.7186\n",
            "Epoch [38/50] - Batch loss: 160.4257 - Epoch Loss: 64441.4749 - Avg Loss: 158.7228\n",
            "Epoch [38/50] - Batch loss: 152.7907 - Epoch Loss: 64594.2657 - Avg Loss: 158.7083\n",
            "Epoch [38/50] - Batch loss: 152.4807 - Epoch Loss: 64746.7464 - Avg Loss: 158.6930\n",
            "Epoch [38/50] - Batch loss: 159.2436 - Epoch Loss: 64905.9900 - Avg Loss: 158.6944\n",
            "Epoch [38/50] - Batch loss: 160.1770 - Epoch Loss: 65066.1669 - Avg Loss: 158.6980\n",
            "Epoch [38/50] - Batch loss: 158.2033 - Epoch Loss: 65224.3702 - Avg Loss: 158.6968\n",
            "Epoch [38/50] - Batch loss: 156.2281 - Epoch Loss: 65380.5983 - Avg Loss: 158.6908\n",
            "Epoch [38/50] - Batch loss: 157.1015 - Epoch Loss: 65537.6998 - Avg Loss: 158.6869\n",
            "Epoch [38/50] - Batch loss: 156.0135 - Epoch Loss: 65693.7133 - Avg Loss: 158.6805\n",
            "Epoch [38/50] - Batch loss: 157.1087 - Epoch Loss: 65850.8219 - Avg Loss: 158.6767\n",
            "Epoch [38/50] - Batch loss: 157.0738 - Epoch Loss: 66007.8958 - Avg Loss: 158.6728\n",
            "Epoch [38/50] - Batch loss: 161.1832 - Epoch Loss: 66169.0789 - Avg Loss: 158.6788\n",
            "Epoch [38/50] - Batch loss: 153.0972 - Epoch Loss: 66322.1762 - Avg Loss: 158.6655\n",
            "Epoch [38/50] - Batch loss: 159.5200 - Epoch Loss: 66481.6962 - Avg Loss: 158.6675\n",
            "Epoch [38/50] - Batch loss: 164.2107 - Epoch Loss: 66645.9069 - Avg Loss: 158.6807\n",
            "Epoch [38/50] - Batch loss: 161.5998 - Epoch Loss: 66807.5067 - Avg Loss: 158.6877\n",
            "Epoch [38/50] - Batch loss: 158.1571 - Epoch Loss: 66965.6638 - Avg Loss: 158.6864\n",
            "Epoch [38/50] - Batch loss: 164.5343 - Epoch Loss: 67130.1981 - Avg Loss: 158.7002\n",
            "Epoch [38/50] - Batch loss: 166.5727 - Epoch Loss: 67296.7708 - Avg Loss: 158.7188\n",
            "Epoch [38/50] - Batch loss: 151.8938 - Epoch Loss: 67448.6646 - Avg Loss: 158.7027\n",
            "Epoch [38/50] - Batch loss: 160.8747 - Epoch Loss: 67609.5393 - Avg Loss: 158.7078\n",
            "Epoch [38/50] - Batch loss: 157.0163 - Epoch Loss: 67766.5556 - Avg Loss: 158.7039\n",
            "Epoch [38/50] - Batch loss: 154.5496 - Epoch Loss: 67921.1051 - Avg Loss: 158.6942\n",
            "Epoch [38/50] - Batch loss: 161.5526 - Epoch Loss: 68082.6577 - Avg Loss: 158.7008\n",
            "Epoch [38/50] - Batch loss: 157.2570 - Epoch Loss: 68239.9147 - Avg Loss: 158.6975\n",
            "Epoch [38/50] - Batch loss: 167.5050 - Epoch Loss: 68407.4197 - Avg Loss: 158.7179\n",
            "Epoch [38/50] - Batch loss: 151.0082 - Epoch Loss: 68558.4279 - Avg Loss: 158.7001\n",
            "Epoch [38/50] - Batch loss: 156.8424 - Epoch Loss: 68715.2703 - Avg Loss: 158.6958\n",
            "Epoch [38/50] - Batch loss: 159.8792 - Epoch Loss: 68875.1495 - Avg Loss: 158.6985\n",
            "Epoch [38/50] - Batch loss: 164.8027 - Epoch Loss: 69039.9522 - Avg Loss: 158.7125\n",
            "Epoch [38/50] - Batch loss: 162.6541 - Epoch Loss: 69202.6063 - Avg Loss: 158.7216\n",
            "Epoch [38/50] - Batch loss: 154.8301 - Epoch Loss: 69357.4364 - Avg Loss: 158.7127\n",
            "Epoch [38/50] - Batch loss: 163.6249 - Epoch Loss: 69521.0613 - Avg Loss: 158.7239\n",
            "Epoch [38/50] - Batch loss: 155.7146 - Epoch Loss: 69676.7759 - Avg Loss: 158.7170\n",
            "Epoch [38/50] - Batch loss: 154.5058 - Epoch Loss: 69831.2817 - Avg Loss: 158.7075\n",
            "Epoch [38/50] - Batch loss: 155.2223 - Epoch Loss: 69986.5040 - Avg Loss: 158.6996\n",
            "Epoch [38/50] - Batch loss: 157.5875 - Epoch Loss: 70144.0916 - Avg Loss: 158.6970\n",
            "Epoch [38/50] - Batch loss: 160.8184 - Epoch Loss: 70304.9099 - Avg Loss: 158.7018\n",
            "Epoch [38/50] - Batch loss: 154.8680 - Epoch Loss: 70459.7779 - Avg Loss: 158.6932\n",
            "Epoch [38/50] - Batch loss: 154.0094 - Epoch Loss: 70613.7873 - Avg Loss: 158.6827\n",
            "Epoch [38/50] - Batch loss: 156.6934 - Epoch Loss: 70770.4807 - Avg Loss: 158.6782\n",
            "Epoch [38/50] - Batch loss: 155.9186 - Epoch Loss: 70926.3993 - Avg Loss: 158.6720\n",
            "Epoch [38/50] - Batch loss: 158.8076 - Epoch Loss: 71085.2069 - Avg Loss: 158.6723\n",
            "Epoch [38/50] - Batch loss: 153.4917 - Epoch Loss: 71238.6986 - Avg Loss: 158.6608\n",
            "Epoch [38/50] - Batch loss: 159.4930 - Epoch Loss: 71398.1916 - Avg Loss: 158.6626\n",
            "Epoch [38/50] - Batch loss: 165.3670 - Epoch Loss: 71563.5586 - Avg Loss: 158.6775\n",
            "Epoch [38/50] - Batch loss: 160.0451 - Epoch Loss: 71723.6036 - Avg Loss: 158.6805\n",
            "Epoch [38/50] - Batch loss: 159.7087 - Epoch Loss: 71883.3123 - Avg Loss: 158.6828\n",
            "Epoch [38/50] - Batch loss: 159.9413 - Epoch Loss: 72043.2536 - Avg Loss: 158.6856\n",
            "Epoch [38/50] - Batch loss: 148.0840 - Epoch Loss: 72191.3376 - Avg Loss: 158.6623\n",
            "Epoch [38/50] - Batch loss: 156.9635 - Epoch Loss: 72348.3012 - Avg Loss: 158.6586\n",
            "Epoch [38/50] - Batch loss: 158.3731 - Epoch Loss: 72506.6743 - Avg Loss: 158.6579\n",
            "Epoch [38/50] - Batch loss: 159.0847 - Epoch Loss: 72665.7590 - Avg Loss: 158.6589\n",
            "Epoch [38/50] - Batch loss: 160.5146 - Epoch Loss: 72826.2735 - Avg Loss: 158.6629\n",
            "Epoch [38/50] - Batch loss: 159.3164 - Epoch Loss: 72985.5899 - Avg Loss: 158.6643\n",
            "Epoch [38/50] - Batch loss: 154.0330 - Epoch Loss: 73139.6229 - Avg Loss: 158.6543\n",
            "Epoch [38/50] - Batch loss: 156.3139 - Epoch Loss: 73295.9368 - Avg Loss: 158.6492\n",
            "Epoch [38/50] - Batch loss: 157.9368 - Epoch Loss: 73453.8735 - Avg Loss: 158.6477\n",
            "Epoch [38/50] - Batch loss: 161.0637 - Epoch Loss: 73614.9372 - Avg Loss: 158.6529\n",
            "Epoch [38/50] - Batch loss: 162.7089 - Epoch Loss: 73777.6461 - Avg Loss: 158.6616\n",
            "Epoch [38/50] - Batch loss: 165.6831 - Epoch Loss: 73943.3292 - Avg Loss: 158.6767\n",
            "Epoch [38/50] - Batch loss: 154.7901 - Epoch Loss: 74098.1194 - Avg Loss: 158.6683\n",
            "Epoch [38/50] - Batch loss: 154.7001 - Epoch Loss: 74252.8195 - Avg Loss: 158.6599\n",
            "Epoch [38/50] - Batch loss: 161.7788 - Epoch Loss: 74414.5983 - Avg Loss: 158.6665\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 39/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee3bd314e9ee4d66b0f88080b5869a49"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [39/50] - Batch loss: 164.4752 - Epoch Loss: 164.4752 - Avg Loss: 164.4752\n",
            "Epoch [39/50] - Batch loss: 161.4501 - Epoch Loss: 325.9253 - Avg Loss: 162.9626\n",
            "Epoch [39/50] - Batch loss: 156.1087 - Epoch Loss: 482.0340 - Avg Loss: 160.6780\n",
            "Epoch [39/50] - Batch loss: 153.1001 - Epoch Loss: 635.1340 - Avg Loss: 158.7835\n",
            "Epoch [39/50] - Batch loss: 159.8154 - Epoch Loss: 794.9494 - Avg Loss: 158.9899\n",
            "Epoch [39/50] - Batch loss: 160.9907 - Epoch Loss: 955.9401 - Avg Loss: 159.3233\n",
            "Epoch [39/50] - Batch loss: 152.4981 - Epoch Loss: 1108.4382 - Avg Loss: 158.3483\n",
            "Epoch [39/50] - Batch loss: 150.4277 - Epoch Loss: 1258.8659 - Avg Loss: 157.3582\n",
            "Epoch [39/50] - Batch loss: 160.1209 - Epoch Loss: 1418.9867 - Avg Loss: 157.6652\n",
            "Epoch [39/50] - Batch loss: 158.9710 - Epoch Loss: 1577.9577 - Avg Loss: 157.7958\n",
            "Epoch [39/50] - Batch loss: 162.0796 - Epoch Loss: 1740.0373 - Avg Loss: 158.1852\n",
            "Epoch [39/50] - Batch loss: 160.2668 - Epoch Loss: 1900.3041 - Avg Loss: 158.3587\n",
            "Epoch [39/50] - Batch loss: 159.6096 - Epoch Loss: 2059.9138 - Avg Loss: 158.4549\n",
            "Epoch [39/50] - Batch loss: 163.8654 - Epoch Loss: 2223.7792 - Avg Loss: 158.8414\n",
            "Epoch [39/50] - Batch loss: 163.2104 - Epoch Loss: 2386.9896 - Avg Loss: 159.1326\n",
            "Epoch [39/50] - Batch loss: 154.5911 - Epoch Loss: 2541.5806 - Avg Loss: 158.8488\n",
            "Epoch [39/50] - Batch loss: 163.4656 - Epoch Loss: 2705.0462 - Avg Loss: 159.1204\n",
            "Epoch [39/50] - Batch loss: 159.5257 - Epoch Loss: 2864.5720 - Avg Loss: 159.1429\n",
            "Epoch [39/50] - Batch loss: 157.8462 - Epoch Loss: 3022.4182 - Avg Loss: 159.0746\n",
            "Epoch [39/50] - Batch loss: 156.6036 - Epoch Loss: 3179.0218 - Avg Loss: 158.9511\n",
            "Epoch [39/50] - Batch loss: 165.9048 - Epoch Loss: 3344.9267 - Avg Loss: 159.2822\n",
            "Epoch [39/50] - Batch loss: 155.8306 - Epoch Loss: 3500.7573 - Avg Loss: 159.1253\n",
            "Epoch [39/50] - Batch loss: 158.3765 - Epoch Loss: 3659.1338 - Avg Loss: 159.0928\n",
            "Epoch [39/50] - Batch loss: 167.0339 - Epoch Loss: 3826.1677 - Avg Loss: 159.4237\n",
            "Epoch [39/50] - Batch loss: 157.3292 - Epoch Loss: 3983.4969 - Avg Loss: 159.3399\n",
            "Epoch [39/50] - Batch loss: 157.7936 - Epoch Loss: 4141.2905 - Avg Loss: 159.2804\n",
            "Epoch [39/50] - Batch loss: 158.1140 - Epoch Loss: 4299.4044 - Avg Loss: 159.2372\n",
            "Epoch [39/50] - Batch loss: 160.3333 - Epoch Loss: 4459.7378 - Avg Loss: 159.2763\n",
            "Epoch [39/50] - Batch loss: 155.0802 - Epoch Loss: 4614.8180 - Avg Loss: 159.1317\n",
            "Epoch [39/50] - Batch loss: 161.0019 - Epoch Loss: 4775.8199 - Avg Loss: 159.1940\n",
            "Epoch [39/50] - Batch loss: 165.8444 - Epoch Loss: 4941.6643 - Avg Loss: 159.4085\n",
            "Epoch [39/50] - Batch loss: 155.1128 - Epoch Loss: 5096.7771 - Avg Loss: 159.2743\n",
            "Epoch [39/50] - Batch loss: 157.5737 - Epoch Loss: 5254.3508 - Avg Loss: 159.2228\n",
            "Epoch [39/50] - Batch loss: 158.1648 - Epoch Loss: 5412.5156 - Avg Loss: 159.1916\n",
            "Epoch [39/50] - Batch loss: 156.9378 - Epoch Loss: 5569.4534 - Avg Loss: 159.1272\n",
            "Epoch [39/50] - Batch loss: 153.2442 - Epoch Loss: 5722.6976 - Avg Loss: 158.9638\n",
            "Epoch [39/50] - Batch loss: 160.4320 - Epoch Loss: 5883.1295 - Avg Loss: 159.0035\n",
            "Epoch [39/50] - Batch loss: 163.7066 - Epoch Loss: 6046.8362 - Avg Loss: 159.1273\n",
            "Epoch [39/50] - Batch loss: 164.5527 - Epoch Loss: 6211.3889 - Avg Loss: 159.2664\n",
            "Epoch [39/50] - Batch loss: 160.7153 - Epoch Loss: 6372.1042 - Avg Loss: 159.3026\n",
            "Epoch [39/50] - Batch loss: 166.0074 - Epoch Loss: 6538.1116 - Avg Loss: 159.4661\n",
            "Epoch [39/50] - Batch loss: 166.5131 - Epoch Loss: 6704.6247 - Avg Loss: 159.6339\n",
            "Epoch [39/50] - Batch loss: 155.7697 - Epoch Loss: 6860.3944 - Avg Loss: 159.5441\n",
            "Epoch [39/50] - Batch loss: 162.6724 - Epoch Loss: 7023.0668 - Avg Loss: 159.6152\n",
            "Epoch [39/50] - Batch loss: 153.3491 - Epoch Loss: 7176.4159 - Avg Loss: 159.4759\n",
            "Epoch [39/50] - Batch loss: 162.4684 - Epoch Loss: 7338.8843 - Avg Loss: 159.5410\n",
            "Epoch [39/50] - Batch loss: 165.1337 - Epoch Loss: 7504.0180 - Avg Loss: 159.6600\n",
            "Epoch [39/50] - Batch loss: 153.2277 - Epoch Loss: 7657.2457 - Avg Loss: 159.5260\n",
            "Epoch [39/50] - Batch loss: 165.6244 - Epoch Loss: 7822.8701 - Avg Loss: 159.6504\n",
            "Epoch [39/50] - Batch loss: 156.7563 - Epoch Loss: 7979.6264 - Avg Loss: 159.5925\n",
            "Epoch [39/50] - Batch loss: 166.2214 - Epoch Loss: 8145.8478 - Avg Loss: 159.7225\n",
            "Epoch [39/50] - Batch loss: 157.7518 - Epoch Loss: 8303.5996 - Avg Loss: 159.6846\n",
            "Epoch [39/50] - Batch loss: 172.9140 - Epoch Loss: 8476.5135 - Avg Loss: 159.9342\n",
            "Epoch [39/50] - Batch loss: 163.2946 - Epoch Loss: 8639.8081 - Avg Loss: 159.9964\n",
            "Epoch [39/50] - Batch loss: 164.8868 - Epoch Loss: 8804.6949 - Avg Loss: 160.0854\n",
            "Epoch [39/50] - Batch loss: 163.1181 - Epoch Loss: 8967.8130 - Avg Loss: 160.1395\n",
            "Epoch [39/50] - Batch loss: 155.7657 - Epoch Loss: 9123.5787 - Avg Loss: 160.0628\n",
            "Epoch [39/50] - Batch loss: 153.4602 - Epoch Loss: 9277.0389 - Avg Loss: 159.9489\n",
            "Epoch [39/50] - Batch loss: 157.7159 - Epoch Loss: 9434.7548 - Avg Loss: 159.9111\n",
            "Epoch [39/50] - Batch loss: 164.0946 - Epoch Loss: 9598.8494 - Avg Loss: 159.9808\n",
            "Epoch [39/50] - Batch loss: 153.5709 - Epoch Loss: 9752.4203 - Avg Loss: 159.8757\n",
            "Epoch [39/50] - Batch loss: 149.1090 - Epoch Loss: 9901.5293 - Avg Loss: 159.7021\n",
            "Epoch [39/50] - Batch loss: 161.7128 - Epoch Loss: 10063.2421 - Avg Loss: 159.7340\n",
            "Epoch [39/50] - Batch loss: 156.9715 - Epoch Loss: 10220.2136 - Avg Loss: 159.6908\n",
            "Epoch [39/50] - Batch loss: 144.1252 - Epoch Loss: 10364.3388 - Avg Loss: 159.4514\n",
            "Epoch [39/50] - Batch loss: 160.2763 - Epoch Loss: 10524.6151 - Avg Loss: 159.4639\n",
            "Epoch [39/50] - Batch loss: 150.0360 - Epoch Loss: 10674.6511 - Avg Loss: 159.3232\n",
            "Epoch [39/50] - Batch loss: 153.9978 - Epoch Loss: 10828.6489 - Avg Loss: 159.2448\n",
            "Epoch [39/50] - Batch loss: 157.9031 - Epoch Loss: 10986.5520 - Avg Loss: 159.2254\n",
            "Epoch [39/50] - Batch loss: 154.4777 - Epoch Loss: 11141.0297 - Avg Loss: 159.1576\n",
            "Epoch [39/50] - Batch loss: 156.0318 - Epoch Loss: 11297.0615 - Avg Loss: 159.1135\n",
            "Epoch [39/50] - Batch loss: 157.8050 - Epoch Loss: 11454.8665 - Avg Loss: 159.0954\n",
            "Epoch [39/50] - Batch loss: 163.0960 - Epoch Loss: 11617.9625 - Avg Loss: 159.1502\n",
            "Epoch [39/50] - Batch loss: 158.5281 - Epoch Loss: 11776.4906 - Avg Loss: 159.1418\n",
            "Epoch [39/50] - Batch loss: 154.4619 - Epoch Loss: 11930.9525 - Avg Loss: 159.0794\n",
            "Epoch [39/50] - Batch loss: 159.2999 - Epoch Loss: 12090.2523 - Avg Loss: 159.0823\n",
            "Epoch [39/50] - Batch loss: 153.9407 - Epoch Loss: 12244.1931 - Avg Loss: 159.0155\n",
            "Epoch [39/50] - Batch loss: 156.6110 - Epoch Loss: 12400.8041 - Avg Loss: 158.9847\n",
            "Epoch [39/50] - Batch loss: 159.7016 - Epoch Loss: 12560.5057 - Avg Loss: 158.9937\n",
            "Epoch [39/50] - Batch loss: 158.5197 - Epoch Loss: 12719.0254 - Avg Loss: 158.9878\n",
            "Epoch [39/50] - Batch loss: 160.7306 - Epoch Loss: 12879.7560 - Avg Loss: 159.0093\n",
            "Epoch [39/50] - Batch loss: 153.3852 - Epoch Loss: 13033.1413 - Avg Loss: 158.9407\n",
            "Epoch [39/50] - Batch loss: 157.8337 - Epoch Loss: 13190.9750 - Avg Loss: 158.9274\n",
            "Epoch [39/50] - Batch loss: 154.8010 - Epoch Loss: 13345.7760 - Avg Loss: 158.8783\n",
            "Epoch [39/50] - Batch loss: 158.6726 - Epoch Loss: 13504.4486 - Avg Loss: 158.8759\n",
            "Epoch [39/50] - Batch loss: 155.5844 - Epoch Loss: 13660.0330 - Avg Loss: 158.8376\n",
            "Epoch [39/50] - Batch loss: 151.2055 - Epoch Loss: 13811.2384 - Avg Loss: 158.7499\n",
            "Epoch [39/50] - Batch loss: 157.0621 - Epoch Loss: 13968.3005 - Avg Loss: 158.7307\n",
            "Epoch [39/50] - Batch loss: 161.9629 - Epoch Loss: 14130.2634 - Avg Loss: 158.7670\n",
            "Epoch [39/50] - Batch loss: 151.7396 - Epoch Loss: 14282.0030 - Avg Loss: 158.6889\n",
            "Epoch [39/50] - Batch loss: 148.7588 - Epoch Loss: 14430.7618 - Avg Loss: 158.5798\n",
            "Epoch [39/50] - Batch loss: 156.4763 - Epoch Loss: 14587.2382 - Avg Loss: 158.5569\n",
            "Epoch [39/50] - Batch loss: 157.1871 - Epoch Loss: 14744.4253 - Avg Loss: 158.5422\n",
            "Epoch [39/50] - Batch loss: 155.1194 - Epoch Loss: 14899.5448 - Avg Loss: 158.5058\n",
            "Epoch [39/50] - Batch loss: 160.3295 - Epoch Loss: 15059.8743 - Avg Loss: 158.5250\n",
            "Epoch [39/50] - Batch loss: 160.2717 - Epoch Loss: 15220.1460 - Avg Loss: 158.5432\n",
            "Epoch [39/50] - Batch loss: 161.3286 - Epoch Loss: 15381.4746 - Avg Loss: 158.5719\n",
            "Epoch [39/50] - Batch loss: 158.7232 - Epoch Loss: 15540.1978 - Avg Loss: 158.5734\n",
            "Epoch [39/50] - Batch loss: 163.7757 - Epoch Loss: 15703.9735 - Avg Loss: 158.6260\n",
            "Epoch [39/50] - Batch loss: 164.1010 - Epoch Loss: 15868.0745 - Avg Loss: 158.6807\n",
            "Epoch [39/50] - Batch loss: 155.4482 - Epoch Loss: 16023.5226 - Avg Loss: 158.6487\n",
            "Epoch [39/50] - Batch loss: 163.7695 - Epoch Loss: 16187.2921 - Avg Loss: 158.6989\n",
            "Epoch [39/50] - Batch loss: 151.6695 - Epoch Loss: 16338.9617 - Avg Loss: 158.6307\n",
            "Epoch [39/50] - Batch loss: 157.0047 - Epoch Loss: 16495.9664 - Avg Loss: 158.6151\n",
            "Epoch [39/50] - Batch loss: 156.4257 - Epoch Loss: 16652.3922 - Avg Loss: 158.5942\n",
            "Epoch [39/50] - Batch loss: 157.4929 - Epoch Loss: 16809.8850 - Avg Loss: 158.5838\n",
            "Epoch [39/50] - Batch loss: 158.6173 - Epoch Loss: 16968.5023 - Avg Loss: 158.5841\n",
            "Epoch [39/50] - Batch loss: 157.7282 - Epoch Loss: 17126.2306 - Avg Loss: 158.5762\n",
            "Epoch [39/50] - Batch loss: 156.1977 - Epoch Loss: 17282.4282 - Avg Loss: 158.5544\n",
            "Epoch [39/50] - Batch loss: 149.6013 - Epoch Loss: 17432.0296 - Avg Loss: 158.4730\n",
            "Epoch [39/50] - Batch loss: 152.9469 - Epoch Loss: 17584.9764 - Avg Loss: 158.4232\n",
            "Epoch [39/50] - Batch loss: 162.2100 - Epoch Loss: 17747.1865 - Avg Loss: 158.4570\n",
            "Epoch [39/50] - Batch loss: 162.8086 - Epoch Loss: 17909.9951 - Avg Loss: 158.4955\n",
            "Epoch [39/50] - Batch loss: 157.7654 - Epoch Loss: 18067.7604 - Avg Loss: 158.4891\n",
            "Epoch [39/50] - Batch loss: 156.3076 - Epoch Loss: 18224.0680 - Avg Loss: 158.4702\n",
            "Epoch [39/50] - Batch loss: 162.7280 - Epoch Loss: 18386.7961 - Avg Loss: 158.5069\n",
            "Epoch [39/50] - Batch loss: 162.7305 - Epoch Loss: 18549.5266 - Avg Loss: 158.5430\n",
            "Epoch [39/50] - Batch loss: 158.3135 - Epoch Loss: 18707.8401 - Avg Loss: 158.5410\n",
            "Epoch [39/50] - Batch loss: 152.0257 - Epoch Loss: 18859.8658 - Avg Loss: 158.4863\n",
            "Epoch [39/50] - Batch loss: 159.8124 - Epoch Loss: 19019.6782 - Avg Loss: 158.4973\n",
            "Epoch [39/50] - Batch loss: 155.1129 - Epoch Loss: 19174.7911 - Avg Loss: 158.4693\n",
            "Epoch [39/50] - Batch loss: 165.4110 - Epoch Loss: 19340.2021 - Avg Loss: 158.5262\n",
            "Epoch [39/50] - Batch loss: 159.1757 - Epoch Loss: 19499.3779 - Avg Loss: 158.5315\n",
            "Epoch [39/50] - Batch loss: 154.3810 - Epoch Loss: 19653.7589 - Avg Loss: 158.4981\n",
            "Epoch [39/50] - Batch loss: 158.5462 - Epoch Loss: 19812.3051 - Avg Loss: 158.4984\n",
            "Epoch [39/50] - Batch loss: 160.6570 - Epoch Loss: 19972.9621 - Avg Loss: 158.5156\n",
            "Epoch [39/50] - Batch loss: 160.5034 - Epoch Loss: 20133.4655 - Avg Loss: 158.5312\n",
            "Epoch [39/50] - Batch loss: 163.5777 - Epoch Loss: 20297.0432 - Avg Loss: 158.5706\n",
            "Epoch [39/50] - Batch loss: 156.7857 - Epoch Loss: 20453.8289 - Avg Loss: 158.5568\n",
            "Epoch [39/50] - Batch loss: 158.7821 - Epoch Loss: 20612.6110 - Avg Loss: 158.5585\n",
            "Epoch [39/50] - Batch loss: 158.1273 - Epoch Loss: 20770.7383 - Avg Loss: 158.5553\n",
            "Epoch [39/50] - Batch loss: 153.6472 - Epoch Loss: 20924.3854 - Avg Loss: 158.5181\n",
            "Epoch [39/50] - Batch loss: 160.4511 - Epoch Loss: 21084.8365 - Avg Loss: 158.5326\n",
            "Epoch [39/50] - Batch loss: 158.3849 - Epoch Loss: 21243.2214 - Avg Loss: 158.5315\n",
            "Epoch [39/50] - Batch loss: 164.8100 - Epoch Loss: 21408.0314 - Avg Loss: 158.5780\n",
            "Epoch [39/50] - Batch loss: 160.1989 - Epoch Loss: 21568.2303 - Avg Loss: 158.5899\n",
            "Epoch [39/50] - Batch loss: 163.9241 - Epoch Loss: 21732.1544 - Avg Loss: 158.6289\n",
            "Epoch [39/50] - Batch loss: 158.1034 - Epoch Loss: 21890.2577 - Avg Loss: 158.6251\n",
            "Epoch [39/50] - Batch loss: 156.1404 - Epoch Loss: 22046.3981 - Avg Loss: 158.6072\n",
            "Epoch [39/50] - Batch loss: 156.6758 - Epoch Loss: 22203.0739 - Avg Loss: 158.5934\n",
            "Epoch [39/50] - Batch loss: 156.1824 - Epoch Loss: 22359.2563 - Avg Loss: 158.5763\n",
            "Epoch [39/50] - Batch loss: 157.6833 - Epoch Loss: 22516.9396 - Avg Loss: 158.5700\n",
            "Epoch [39/50] - Batch loss: 158.7817 - Epoch Loss: 22675.7212 - Avg Loss: 158.5715\n",
            "Epoch [39/50] - Batch loss: 161.0707 - Epoch Loss: 22836.7920 - Avg Loss: 158.5888\n",
            "Epoch [39/50] - Batch loss: 164.1562 - Epoch Loss: 23000.9482 - Avg Loss: 158.6272\n",
            "Epoch [39/50] - Batch loss: 152.6181 - Epoch Loss: 23153.5663 - Avg Loss: 158.5861\n",
            "Epoch [39/50] - Batch loss: 156.8135 - Epoch Loss: 23310.3798 - Avg Loss: 158.5740\n",
            "Epoch [39/50] - Batch loss: 156.4394 - Epoch Loss: 23466.8192 - Avg Loss: 158.5596\n",
            "Epoch [39/50] - Batch loss: 158.2725 - Epoch Loss: 23625.0917 - Avg Loss: 158.5577\n",
            "Epoch [39/50] - Batch loss: 154.3973 - Epoch Loss: 23779.4890 - Avg Loss: 158.5299\n",
            "Epoch [39/50] - Batch loss: 161.7119 - Epoch Loss: 23941.2009 - Avg Loss: 158.5510\n",
            "Epoch [39/50] - Batch loss: 158.5099 - Epoch Loss: 24099.7108 - Avg Loss: 158.5507\n",
            "Epoch [39/50] - Batch loss: 159.9909 - Epoch Loss: 24259.7017 - Avg Loss: 158.5601\n",
            "Epoch [39/50] - Batch loss: 157.1845 - Epoch Loss: 24416.8862 - Avg Loss: 158.5512\n",
            "Epoch [39/50] - Batch loss: 157.5845 - Epoch Loss: 24574.4707 - Avg Loss: 158.5450\n",
            "Epoch [39/50] - Batch loss: 151.7345 - Epoch Loss: 24726.2053 - Avg Loss: 158.5013\n",
            "Epoch [39/50] - Batch loss: 166.7116 - Epoch Loss: 24892.9169 - Avg Loss: 158.5536\n",
            "Epoch [39/50] - Batch loss: 162.3832 - Epoch Loss: 25055.3001 - Avg Loss: 158.5778\n",
            "Epoch [39/50] - Batch loss: 158.0669 - Epoch Loss: 25213.3670 - Avg Loss: 158.5746\n",
            "Epoch [39/50] - Batch loss: 152.4456 - Epoch Loss: 25365.8126 - Avg Loss: 158.5363\n",
            "Epoch [39/50] - Batch loss: 151.8867 - Epoch Loss: 25517.6993 - Avg Loss: 158.4950\n",
            "Epoch [39/50] - Batch loss: 161.5450 - Epoch Loss: 25679.2442 - Avg Loss: 158.5139\n",
            "Epoch [39/50] - Batch loss: 160.6371 - Epoch Loss: 25839.8813 - Avg Loss: 158.5269\n",
            "Epoch [39/50] - Batch loss: 164.4458 - Epoch Loss: 26004.3270 - Avg Loss: 158.5630\n",
            "Epoch [39/50] - Batch loss: 158.3786 - Epoch Loss: 26162.7057 - Avg Loss: 158.5619\n",
            "Epoch [39/50] - Batch loss: 156.6529 - Epoch Loss: 26319.3586 - Avg Loss: 158.5504\n",
            "Epoch [39/50] - Batch loss: 161.1996 - Epoch Loss: 26480.5581 - Avg Loss: 158.5662\n",
            "Epoch [39/50] - Batch loss: 159.4557 - Epoch Loss: 26640.0138 - Avg Loss: 158.5715\n",
            "Epoch [39/50] - Batch loss: 162.7238 - Epoch Loss: 26802.7377 - Avg Loss: 158.5961\n",
            "Epoch [39/50] - Batch loss: 157.8193 - Epoch Loss: 26960.5570 - Avg Loss: 158.5915\n",
            "Epoch [39/50] - Batch loss: 159.7092 - Epoch Loss: 27120.2662 - Avg Loss: 158.5980\n",
            "Epoch [39/50] - Batch loss: 157.9247 - Epoch Loss: 27278.1909 - Avg Loss: 158.5941\n",
            "Epoch [39/50] - Batch loss: 155.5003 - Epoch Loss: 27433.6912 - Avg Loss: 158.5762\n",
            "Epoch [39/50] - Batch loss: 161.1829 - Epoch Loss: 27594.8740 - Avg Loss: 158.5912\n",
            "Epoch [39/50] - Batch loss: 167.4510 - Epoch Loss: 27762.3250 - Avg Loss: 158.6419\n",
            "Epoch [39/50] - Batch loss: 159.1948 - Epoch Loss: 27921.5198 - Avg Loss: 158.6450\n",
            "Epoch [39/50] - Batch loss: 156.6877 - Epoch Loss: 28078.2075 - Avg Loss: 158.6339\n",
            "Epoch [39/50] - Batch loss: 161.9333 - Epoch Loss: 28240.1408 - Avg Loss: 158.6525\n",
            "Epoch [39/50] - Batch loss: 160.9888 - Epoch Loss: 28401.1296 - Avg Loss: 158.6655\n",
            "Epoch [39/50] - Batch loss: 155.6442 - Epoch Loss: 28556.7739 - Avg Loss: 158.6487\n",
            "Epoch [39/50] - Batch loss: 159.7220 - Epoch Loss: 28716.4959 - Avg Loss: 158.6547\n",
            "Epoch [39/50] - Batch loss: 158.4299 - Epoch Loss: 28874.9259 - Avg Loss: 158.6534\n",
            "Epoch [39/50] - Batch loss: 158.0016 - Epoch Loss: 29032.9274 - Avg Loss: 158.6499\n",
            "Epoch [39/50] - Batch loss: 154.4187 - Epoch Loss: 29187.3461 - Avg Loss: 158.6269\n",
            "Epoch [39/50] - Batch loss: 164.0824 - Epoch Loss: 29351.4285 - Avg Loss: 158.6564\n",
            "Epoch [39/50] - Batch loss: 159.5892 - Epoch Loss: 29511.0177 - Avg Loss: 158.6614\n",
            "Epoch [39/50] - Batch loss: 169.2683 - Epoch Loss: 29680.2860 - Avg Loss: 158.7181\n",
            "Epoch [39/50] - Batch loss: 155.3825 - Epoch Loss: 29835.6685 - Avg Loss: 158.7004\n",
            "Epoch [39/50] - Batch loss: 157.8707 - Epoch Loss: 29993.5392 - Avg Loss: 158.6960\n",
            "Epoch [39/50] - Batch loss: 159.9130 - Epoch Loss: 30153.4523 - Avg Loss: 158.7024\n",
            "Epoch [39/50] - Batch loss: 163.9560 - Epoch Loss: 30317.4083 - Avg Loss: 158.7299\n",
            "Epoch [39/50] - Batch loss: 156.1216 - Epoch Loss: 30473.5299 - Avg Loss: 158.7163\n",
            "Epoch [39/50] - Batch loss: 152.1494 - Epoch Loss: 30625.6792 - Avg Loss: 158.6823\n",
            "Epoch [39/50] - Batch loss: 161.1828 - Epoch Loss: 30786.8620 - Avg Loss: 158.6952\n",
            "Epoch [39/50] - Batch loss: 153.4319 - Epoch Loss: 30940.2939 - Avg Loss: 158.6682\n",
            "Epoch [39/50] - Batch loss: 152.7726 - Epoch Loss: 31093.0665 - Avg Loss: 158.6381\n",
            "Epoch [39/50] - Batch loss: 154.4732 - Epoch Loss: 31247.5397 - Avg Loss: 158.6170\n",
            "Epoch [39/50] - Batch loss: 155.0620 - Epoch Loss: 31402.6018 - Avg Loss: 158.5990\n",
            "Epoch [39/50] - Batch loss: 163.4423 - Epoch Loss: 31566.0441 - Avg Loss: 158.6233\n",
            "Epoch [39/50] - Batch loss: 155.1250 - Epoch Loss: 31721.1690 - Avg Loss: 158.6058\n",
            "Epoch [39/50] - Batch loss: 159.2016 - Epoch Loss: 31880.3707 - Avg Loss: 158.6088\n",
            "Epoch [39/50] - Batch loss: 165.1587 - Epoch Loss: 32045.5294 - Avg Loss: 158.6412\n",
            "Epoch [39/50] - Batch loss: 161.1207 - Epoch Loss: 32206.6501 - Avg Loss: 158.6534\n",
            "Epoch [39/50] - Batch loss: 162.6939 - Epoch Loss: 32369.3440 - Avg Loss: 158.6733\n",
            "Epoch [39/50] - Batch loss: 158.9491 - Epoch Loss: 32528.2931 - Avg Loss: 158.6746\n",
            "Epoch [39/50] - Batch loss: 154.5214 - Epoch Loss: 32682.8145 - Avg Loss: 158.6544\n",
            "Epoch [39/50] - Batch loss: 162.4923 - Epoch Loss: 32845.3068 - Avg Loss: 158.6730\n",
            "Epoch [39/50] - Batch loss: 157.5896 - Epoch Loss: 33002.8965 - Avg Loss: 158.6678\n",
            "Epoch [39/50] - Batch loss: 157.6325 - Epoch Loss: 33160.5290 - Avg Loss: 158.6628\n",
            "Epoch [39/50] - Batch loss: 157.9866 - Epoch Loss: 33318.5156 - Avg Loss: 158.6596\n",
            "Epoch [39/50] - Batch loss: 170.4355 - Epoch Loss: 33488.9512 - Avg Loss: 158.7154\n",
            "Epoch [39/50] - Batch loss: 158.8272 - Epoch Loss: 33647.7784 - Avg Loss: 158.7159\n",
            "Epoch [39/50] - Batch loss: 160.9630 - Epoch Loss: 33808.7413 - Avg Loss: 158.7265\n",
            "Epoch [39/50] - Batch loss: 155.0391 - Epoch Loss: 33963.7804 - Avg Loss: 158.7093\n",
            "Epoch [39/50] - Batch loss: 162.4279 - Epoch Loss: 34126.2083 - Avg Loss: 158.7266\n",
            "Epoch [39/50] - Batch loss: 155.5558 - Epoch Loss: 34281.7642 - Avg Loss: 158.7119\n",
            "Epoch [39/50] - Batch loss: 156.4655 - Epoch Loss: 34438.2296 - Avg Loss: 158.7015\n",
            "Epoch [39/50] - Batch loss: 169.7641 - Epoch Loss: 34607.9937 - Avg Loss: 158.7523\n",
            "Epoch [39/50] - Batch loss: 151.1505 - Epoch Loss: 34759.1442 - Avg Loss: 158.7176\n",
            "Epoch [39/50] - Batch loss: 165.6742 - Epoch Loss: 34924.8184 - Avg Loss: 158.7492\n",
            "Epoch [39/50] - Batch loss: 158.4426 - Epoch Loss: 35083.2610 - Avg Loss: 158.7478\n",
            "Epoch [39/50] - Batch loss: 162.2953 - Epoch Loss: 35245.5563 - Avg Loss: 158.7638\n",
            "Epoch [39/50] - Batch loss: 157.2274 - Epoch Loss: 35402.7837 - Avg Loss: 158.7569\n",
            "Epoch [39/50] - Batch loss: 160.5535 - Epoch Loss: 35563.3372 - Avg Loss: 158.7649\n",
            "Epoch [39/50] - Batch loss: 157.5910 - Epoch Loss: 35720.9283 - Avg Loss: 158.7597\n",
            "Epoch [39/50] - Batch loss: 158.9834 - Epoch Loss: 35879.9116 - Avg Loss: 158.7607\n",
            "Epoch [39/50] - Batch loss: 156.3315 - Epoch Loss: 36036.2431 - Avg Loss: 158.7500\n",
            "Epoch [39/50] - Batch loss: 169.2162 - Epoch Loss: 36205.4593 - Avg Loss: 158.7959\n",
            "Epoch [39/50] - Batch loss: 158.7791 - Epoch Loss: 36364.2384 - Avg Loss: 158.7958\n",
            "Epoch [39/50] - Batch loss: 158.5145 - Epoch Loss: 36522.7529 - Avg Loss: 158.7946\n",
            "Epoch [39/50] - Batch loss: 166.6761 - Epoch Loss: 36689.4289 - Avg Loss: 158.8287\n",
            "Epoch [39/50] - Batch loss: 155.0694 - Epoch Loss: 36844.4983 - Avg Loss: 158.8125\n",
            "Epoch [39/50] - Batch loss: 163.1149 - Epoch Loss: 37007.6132 - Avg Loss: 158.8310\n",
            "Epoch [39/50] - Batch loss: 155.0844 - Epoch Loss: 37162.6976 - Avg Loss: 158.8149\n",
            "Epoch [39/50] - Batch loss: 159.0095 - Epoch Loss: 37321.7071 - Avg Loss: 158.8158\n",
            "Epoch [39/50] - Batch loss: 156.6096 - Epoch Loss: 37478.3167 - Avg Loss: 158.8064\n",
            "Epoch [39/50] - Batch loss: 163.2296 - Epoch Loss: 37641.5463 - Avg Loss: 158.8251\n",
            "Epoch [39/50] - Batch loss: 157.2294 - Epoch Loss: 37798.7757 - Avg Loss: 158.8184\n",
            "Epoch [39/50] - Batch loss: 157.6866 - Epoch Loss: 37956.4623 - Avg Loss: 158.8136\n",
            "Epoch [39/50] - Batch loss: 162.1219 - Epoch Loss: 38118.5842 - Avg Loss: 158.8274\n",
            "Epoch [39/50] - Batch loss: 158.8469 - Epoch Loss: 38277.4311 - Avg Loss: 158.8275\n",
            "Epoch [39/50] - Batch loss: 161.9779 - Epoch Loss: 38439.4090 - Avg Loss: 158.8405\n",
            "Epoch [39/50] - Batch loss: 159.7063 - Epoch Loss: 38599.1152 - Avg Loss: 158.8441\n",
            "Epoch [39/50] - Batch loss: 161.2003 - Epoch Loss: 38760.3155 - Avg Loss: 158.8538\n",
            "Epoch [39/50] - Batch loss: 156.5269 - Epoch Loss: 38916.8424 - Avg Loss: 158.8443\n",
            "Epoch [39/50] - Batch loss: 160.9667 - Epoch Loss: 39077.8091 - Avg Loss: 158.8529\n",
            "Epoch [39/50] - Batch loss: 162.0783 - Epoch Loss: 39239.8874 - Avg Loss: 158.8659\n",
            "Epoch [39/50] - Batch loss: 160.0032 - Epoch Loss: 39399.8906 - Avg Loss: 158.8705\n",
            "Epoch [39/50] - Batch loss: 166.2726 - Epoch Loss: 39566.1632 - Avg Loss: 158.9003\n",
            "Epoch [39/50] - Batch loss: 171.2743 - Epoch Loss: 39737.4375 - Avg Loss: 158.9497\n",
            "Epoch [39/50] - Batch loss: 155.6371 - Epoch Loss: 39893.0746 - Avg Loss: 158.9366\n",
            "Epoch [39/50] - Batch loss: 162.5979 - Epoch Loss: 40055.6725 - Avg Loss: 158.9511\n",
            "Epoch [39/50] - Batch loss: 159.2288 - Epoch Loss: 40214.9014 - Avg Loss: 158.9522\n",
            "Epoch [39/50] - Batch loss: 163.5967 - Epoch Loss: 40378.4980 - Avg Loss: 158.9705\n",
            "Epoch [39/50] - Batch loss: 158.7031 - Epoch Loss: 40537.2012 - Avg Loss: 158.9694\n",
            "Epoch [39/50] - Batch loss: 160.6824 - Epoch Loss: 40697.8836 - Avg Loss: 158.9761\n",
            "Epoch [39/50] - Batch loss: 160.2875 - Epoch Loss: 40858.1711 - Avg Loss: 158.9812\n",
            "Epoch [39/50] - Batch loss: 164.9387 - Epoch Loss: 41023.1098 - Avg Loss: 159.0043\n",
            "Epoch [39/50] - Batch loss: 153.0976 - Epoch Loss: 41176.2074 - Avg Loss: 158.9815\n",
            "Epoch [39/50] - Batch loss: 160.6844 - Epoch Loss: 41336.8918 - Avg Loss: 158.9880\n",
            "Epoch [39/50] - Batch loss: 160.3775 - Epoch Loss: 41497.2693 - Avg Loss: 158.9934\n",
            "Epoch [39/50] - Batch loss: 160.9986 - Epoch Loss: 41658.2679 - Avg Loss: 159.0010\n",
            "Epoch [39/50] - Batch loss: 150.3502 - Epoch Loss: 41808.6181 - Avg Loss: 158.9681\n",
            "Epoch [39/50] - Batch loss: 164.9179 - Epoch Loss: 41973.5359 - Avg Loss: 158.9907\n",
            "Epoch [39/50] - Batch loss: 155.4320 - Epoch Loss: 42128.9679 - Avg Loss: 158.9772\n",
            "Epoch [39/50] - Batch loss: 152.1606 - Epoch Loss: 42281.1286 - Avg Loss: 158.9516\n",
            "Epoch [39/50] - Batch loss: 162.1755 - Epoch Loss: 42443.3040 - Avg Loss: 158.9637\n",
            "Epoch [39/50] - Batch loss: 154.9276 - Epoch Loss: 42598.2317 - Avg Loss: 158.9486\n",
            "Epoch [39/50] - Batch loss: 162.3216 - Epoch Loss: 42760.5533 - Avg Loss: 158.9612\n",
            "Epoch [39/50] - Batch loss: 159.3000 - Epoch Loss: 42919.8532 - Avg Loss: 158.9624\n",
            "Epoch [39/50] - Batch loss: 156.4921 - Epoch Loss: 43076.3454 - Avg Loss: 158.9533\n",
            "Epoch [39/50] - Batch loss: 160.4790 - Epoch Loss: 43236.8243 - Avg Loss: 158.9589\n",
            "Epoch [39/50] - Batch loss: 159.4554 - Epoch Loss: 43396.2797 - Avg Loss: 158.9607\n",
            "Epoch [39/50] - Batch loss: 149.3857 - Epoch Loss: 43545.6655 - Avg Loss: 158.9258\n",
            "Epoch [39/50] - Batch loss: 157.6349 - Epoch Loss: 43703.3004 - Avg Loss: 158.9211\n",
            "Epoch [39/50] - Batch loss: 156.9858 - Epoch Loss: 43860.2862 - Avg Loss: 158.9141\n",
            "Epoch [39/50] - Batch loss: 155.6577 - Epoch Loss: 44015.9439 - Avg Loss: 158.9023\n",
            "Epoch [39/50] - Batch loss: 165.7328 - Epoch Loss: 44181.6768 - Avg Loss: 158.9269\n",
            "Epoch [39/50] - Batch loss: 156.7052 - Epoch Loss: 44338.3819 - Avg Loss: 158.9189\n",
            "Epoch [39/50] - Batch loss: 161.9626 - Epoch Loss: 44500.3445 - Avg Loss: 158.9298\n",
            "Epoch [39/50] - Batch loss: 155.4763 - Epoch Loss: 44655.8208 - Avg Loss: 158.9175\n",
            "Epoch [39/50] - Batch loss: 160.4267 - Epoch Loss: 44816.2475 - Avg Loss: 158.9229\n",
            "Epoch [39/50] - Batch loss: 156.4465 - Epoch Loss: 44972.6940 - Avg Loss: 158.9141\n",
            "Epoch [39/50] - Batch loss: 152.1392 - Epoch Loss: 45124.8331 - Avg Loss: 158.8903\n",
            "Epoch [39/50] - Batch loss: 151.9296 - Epoch Loss: 45276.7628 - Avg Loss: 158.8658\n",
            "Epoch [39/50] - Batch loss: 150.4976 - Epoch Loss: 45427.2604 - Avg Loss: 158.8366\n",
            "Epoch [39/50] - Batch loss: 163.4029 - Epoch Loss: 45590.6633 - Avg Loss: 158.8525\n",
            "Epoch [39/50] - Batch loss: 159.5980 - Epoch Loss: 45750.2613 - Avg Loss: 158.8551\n",
            "Epoch [39/50] - Batch loss: 161.6699 - Epoch Loss: 45911.9312 - Avg Loss: 158.8648\n",
            "Epoch [39/50] - Batch loss: 160.2001 - Epoch Loss: 46072.1313 - Avg Loss: 158.8694\n",
            "Epoch [39/50] - Batch loss: 163.7855 - Epoch Loss: 46235.9167 - Avg Loss: 158.8863\n",
            "Epoch [39/50] - Batch loss: 164.0793 - Epoch Loss: 46399.9961 - Avg Loss: 158.9041\n",
            "Epoch [39/50] - Batch loss: 156.3316 - Epoch Loss: 46556.3277 - Avg Loss: 158.8953\n",
            "Epoch [39/50] - Batch loss: 153.5070 - Epoch Loss: 46709.8346 - Avg Loss: 158.8770\n",
            "Epoch [39/50] - Batch loss: 155.3976 - Epoch Loss: 46865.2323 - Avg Loss: 158.8652\n",
            "Epoch [39/50] - Batch loss: 159.8289 - Epoch Loss: 47025.0612 - Avg Loss: 158.8684\n",
            "Epoch [39/50] - Batch loss: 161.3851 - Epoch Loss: 47186.4463 - Avg Loss: 158.8769\n",
            "Epoch [39/50] - Batch loss: 165.4918 - Epoch Loss: 47351.9381 - Avg Loss: 158.8991\n",
            "Epoch [39/50] - Batch loss: 162.2187 - Epoch Loss: 47514.1569 - Avg Loss: 158.9102\n",
            "Epoch [39/50] - Batch loss: 161.8476 - Epoch Loss: 47676.0045 - Avg Loss: 158.9200\n",
            "Epoch [39/50] - Batch loss: 161.7482 - Epoch Loss: 47837.7527 - Avg Loss: 158.9294\n",
            "Epoch [39/50] - Batch loss: 156.1588 - Epoch Loss: 47993.9115 - Avg Loss: 158.9202\n",
            "Epoch [39/50] - Batch loss: 160.1661 - Epoch Loss: 48154.0776 - Avg Loss: 158.9243\n",
            "Epoch [39/50] - Batch loss: 152.4477 - Epoch Loss: 48306.5254 - Avg Loss: 158.9030\n",
            "Epoch [39/50] - Batch loss: 152.2002 - Epoch Loss: 48458.7256 - Avg Loss: 158.8811\n",
            "Epoch [39/50] - Batch loss: 161.4395 - Epoch Loss: 48620.1651 - Avg Loss: 158.8894\n",
            "Epoch [39/50] - Batch loss: 153.2034 - Epoch Loss: 48773.3685 - Avg Loss: 158.8709\n",
            "Epoch [39/50] - Batch loss: 153.1067 - Epoch Loss: 48926.4752 - Avg Loss: 158.8522\n",
            "Epoch [39/50] - Batch loss: 157.1677 - Epoch Loss: 49083.6430 - Avg Loss: 158.8467\n",
            "Epoch [39/50] - Batch loss: 160.3085 - Epoch Loss: 49243.9514 - Avg Loss: 158.8515\n",
            "Epoch [39/50] - Batch loss: 160.6482 - Epoch Loss: 49404.5997 - Avg Loss: 158.8572\n",
            "Epoch [39/50] - Batch loss: 162.6368 - Epoch Loss: 49567.2365 - Avg Loss: 158.8693\n",
            "Epoch [39/50] - Batch loss: 157.2588 - Epoch Loss: 49724.4953 - Avg Loss: 158.8642\n",
            "Epoch [39/50] - Batch loss: 156.8896 - Epoch Loss: 49881.3849 - Avg Loss: 158.8579\n",
            "Epoch [39/50] - Batch loss: 163.8902 - Epoch Loss: 50045.2750 - Avg Loss: 158.8739\n",
            "Epoch [39/50] - Batch loss: 159.2801 - Epoch Loss: 50204.5551 - Avg Loss: 158.8752\n",
            "Epoch [39/50] - Batch loss: 161.4677 - Epoch Loss: 50366.0228 - Avg Loss: 158.8834\n",
            "Epoch [39/50] - Batch loss: 163.6880 - Epoch Loss: 50529.7108 - Avg Loss: 158.8985\n",
            "Epoch [39/50] - Batch loss: 158.6955 - Epoch Loss: 50688.4064 - Avg Loss: 158.8978\n",
            "Epoch [39/50] - Batch loss: 157.3177 - Epoch Loss: 50845.7240 - Avg Loss: 158.8929\n",
            "Epoch [39/50] - Batch loss: 157.3543 - Epoch Loss: 51003.0783 - Avg Loss: 158.8881\n",
            "Epoch [39/50] - Batch loss: 161.6017 - Epoch Loss: 51164.6800 - Avg Loss: 158.8965\n",
            "Epoch [39/50] - Batch loss: 156.1872 - Epoch Loss: 51320.8672 - Avg Loss: 158.8881\n",
            "Epoch [39/50] - Batch loss: 161.8373 - Epoch Loss: 51482.7045 - Avg Loss: 158.8972\n",
            "Epoch [39/50] - Batch loss: 158.2096 - Epoch Loss: 51640.9142 - Avg Loss: 158.8951\n",
            "Epoch [39/50] - Batch loss: 156.1102 - Epoch Loss: 51797.0244 - Avg Loss: 158.8866\n",
            "Epoch [39/50] - Batch loss: 165.8384 - Epoch Loss: 51962.8628 - Avg Loss: 158.9078\n",
            "Epoch [39/50] - Batch loss: 151.1996 - Epoch Loss: 52114.0624 - Avg Loss: 158.8843\n",
            "Epoch [39/50] - Batch loss: 157.7392 - Epoch Loss: 52271.8016 - Avg Loss: 158.8809\n",
            "Epoch [39/50] - Batch loss: 158.9535 - Epoch Loss: 52430.7551 - Avg Loss: 158.8811\n",
            "Epoch [39/50] - Batch loss: 153.7178 - Epoch Loss: 52584.4729 - Avg Loss: 158.8655\n",
            "Epoch [39/50] - Batch loss: 152.4530 - Epoch Loss: 52736.9259 - Avg Loss: 158.8462\n",
            "Epoch [39/50] - Batch loss: 154.9544 - Epoch Loss: 52891.8803 - Avg Loss: 158.8345\n",
            "Epoch [39/50] - Batch loss: 158.0998 - Epoch Loss: 53049.9801 - Avg Loss: 158.8323\n",
            "Epoch [39/50] - Batch loss: 152.6656 - Epoch Loss: 53202.6457 - Avg Loss: 158.8139\n",
            "Epoch [39/50] - Batch loss: 157.2977 - Epoch Loss: 53359.9434 - Avg Loss: 158.8094\n",
            "Epoch [39/50] - Batch loss: 156.6776 - Epoch Loss: 53516.6210 - Avg Loss: 158.8030\n",
            "Epoch [39/50] - Batch loss: 155.9740 - Epoch Loss: 53672.5950 - Avg Loss: 158.7947\n",
            "Epoch [39/50] - Batch loss: 164.0227 - Epoch Loss: 53836.6177 - Avg Loss: 158.8101\n",
            "Epoch [39/50] - Batch loss: 165.7034 - Epoch Loss: 54002.3211 - Avg Loss: 158.8304\n",
            "Epoch [39/50] - Batch loss: 156.5539 - Epoch Loss: 54158.8750 - Avg Loss: 158.8237\n",
            "Epoch [39/50] - Batch loss: 154.3159 - Epoch Loss: 54313.1909 - Avg Loss: 158.8105\n",
            "Epoch [39/50] - Batch loss: 163.2332 - Epoch Loss: 54476.4241 - Avg Loss: 158.8234\n",
            "Epoch [39/50] - Batch loss: 153.8369 - Epoch Loss: 54630.2610 - Avg Loss: 158.8089\n",
            "Epoch [39/50] - Batch loss: 167.0749 - Epoch Loss: 54797.3359 - Avg Loss: 158.8329\n",
            "Epoch [39/50] - Batch loss: 160.5080 - Epoch Loss: 54957.8439 - Avg Loss: 158.8377\n",
            "Epoch [39/50] - Batch loss: 152.3971 - Epoch Loss: 55110.2409 - Avg Loss: 158.8191\n",
            "Epoch [39/50] - Batch loss: 163.2483 - Epoch Loss: 55273.4892 - Avg Loss: 158.8319\n",
            "Epoch [39/50] - Batch loss: 157.6879 - Epoch Loss: 55431.1771 - Avg Loss: 158.8286\n",
            "Epoch [39/50] - Batch loss: 153.8555 - Epoch Loss: 55585.0326 - Avg Loss: 158.8144\n",
            "Epoch [39/50] - Batch loss: 160.6992 - Epoch Loss: 55745.7318 - Avg Loss: 158.8197\n",
            "Epoch [39/50] - Batch loss: 148.7044 - Epoch Loss: 55894.4362 - Avg Loss: 158.7910\n",
            "Epoch [39/50] - Batch loss: 158.1373 - Epoch Loss: 56052.5735 - Avg Loss: 158.7892\n",
            "Epoch [39/50] - Batch loss: 161.5043 - Epoch Loss: 56214.0778 - Avg Loss: 158.7968\n",
            "Epoch [39/50] - Batch loss: 160.6597 - Epoch Loss: 56374.7374 - Avg Loss: 158.8021\n",
            "Epoch [39/50] - Batch loss: 160.2314 - Epoch Loss: 56534.9689 - Avg Loss: 158.8061\n",
            "Epoch [39/50] - Batch loss: 159.7609 - Epoch Loss: 56694.7298 - Avg Loss: 158.8088\n",
            "Epoch [39/50] - Batch loss: 163.1615 - Epoch Loss: 56857.8913 - Avg Loss: 158.8209\n",
            "Epoch [39/50] - Batch loss: 161.0415 - Epoch Loss: 57018.9328 - Avg Loss: 158.8271\n",
            "Epoch [39/50] - Batch loss: 153.8968 - Epoch Loss: 57172.8296 - Avg Loss: 158.8134\n",
            "Epoch [39/50] - Batch loss: 155.5918 - Epoch Loss: 57328.4213 - Avg Loss: 158.8045\n",
            "Epoch [39/50] - Batch loss: 164.6132 - Epoch Loss: 57493.0346 - Avg Loss: 158.8205\n",
            "Epoch [39/50] - Batch loss: 160.6011 - Epoch Loss: 57653.6357 - Avg Loss: 158.8254\n",
            "Epoch [39/50] - Batch loss: 159.2299 - Epoch Loss: 57812.8656 - Avg Loss: 158.8266\n",
            "Epoch [39/50] - Batch loss: 157.1903 - Epoch Loss: 57970.0559 - Avg Loss: 158.8221\n",
            "Epoch [39/50] - Batch loss: 161.2180 - Epoch Loss: 58131.2740 - Avg Loss: 158.8286\n",
            "Epoch [39/50] - Batch loss: 157.6580 - Epoch Loss: 58288.9320 - Avg Loss: 158.8254\n",
            "Epoch [39/50] - Batch loss: 164.8786 - Epoch Loss: 58453.8106 - Avg Loss: 158.8419\n",
            "Epoch [39/50] - Batch loss: 161.1784 - Epoch Loss: 58614.9890 - Avg Loss: 158.8482\n",
            "Epoch [39/50] - Batch loss: 158.7125 - Epoch Loss: 58773.7015 - Avg Loss: 158.8478\n",
            "Epoch [39/50] - Batch loss: 160.9636 - Epoch Loss: 58934.6651 - Avg Loss: 158.8535\n",
            "Epoch [39/50] - Batch loss: 151.9158 - Epoch Loss: 59086.5809 - Avg Loss: 158.8349\n",
            "Epoch [39/50] - Batch loss: 158.2639 - Epoch Loss: 59244.8448 - Avg Loss: 158.8334\n",
            "Epoch [39/50] - Batch loss: 151.9964 - Epoch Loss: 59396.8412 - Avg Loss: 158.8151\n",
            "Epoch [39/50] - Batch loss: 161.4756 - Epoch Loss: 59558.3168 - Avg Loss: 158.8222\n",
            "Epoch [39/50] - Batch loss: 158.2784 - Epoch Loss: 59716.5953 - Avg Loss: 158.8207\n",
            "Epoch [39/50] - Batch loss: 159.5618 - Epoch Loss: 59876.1570 - Avg Loss: 158.8227\n",
            "Epoch [39/50] - Batch loss: 165.3510 - Epoch Loss: 60041.5080 - Avg Loss: 158.8400\n",
            "Epoch [39/50] - Batch loss: 166.7027 - Epoch Loss: 60208.2106 - Avg Loss: 158.8607\n",
            "Epoch [39/50] - Batch loss: 156.8815 - Epoch Loss: 60365.0921 - Avg Loss: 158.8555\n",
            "Epoch [39/50] - Batch loss: 165.4072 - Epoch Loss: 60530.4993 - Avg Loss: 158.8727\n",
            "Epoch [39/50] - Batch loss: 160.7835 - Epoch Loss: 60691.2828 - Avg Loss: 158.8777\n",
            "Epoch [39/50] - Batch loss: 160.8085 - Epoch Loss: 60852.0914 - Avg Loss: 158.8827\n",
            "Epoch [39/50] - Batch loss: 162.4824 - Epoch Loss: 61014.5738 - Avg Loss: 158.8921\n",
            "Epoch [39/50] - Batch loss: 164.4765 - Epoch Loss: 61179.0503 - Avg Loss: 158.9066\n",
            "Epoch [39/50] - Batch loss: 162.5648 - Epoch Loss: 61341.6151 - Avg Loss: 158.9161\n",
            "Epoch [39/50] - Batch loss: 156.5839 - Epoch Loss: 61498.1990 - Avg Loss: 158.9101\n",
            "Epoch [39/50] - Batch loss: 159.2137 - Epoch Loss: 61657.4128 - Avg Loss: 158.9109\n",
            "Epoch [39/50] - Batch loss: 157.3926 - Epoch Loss: 61814.8054 - Avg Loss: 158.9070\n",
            "Epoch [39/50] - Batch loss: 164.8207 - Epoch Loss: 61979.6261 - Avg Loss: 158.9221\n",
            "Epoch [39/50] - Batch loss: 158.3378 - Epoch Loss: 62137.9639 - Avg Loss: 158.9206\n",
            "Epoch [39/50] - Batch loss: 155.5470 - Epoch Loss: 62293.5109 - Avg Loss: 158.9120\n",
            "Epoch [39/50] - Batch loss: 158.6704 - Epoch Loss: 62452.1813 - Avg Loss: 158.9114\n",
            "Epoch [39/50] - Batch loss: 161.4957 - Epoch Loss: 62613.6769 - Avg Loss: 158.9180\n",
            "Epoch [39/50] - Batch loss: 152.5443 - Epoch Loss: 62766.2213 - Avg Loss: 158.9018\n",
            "Epoch [39/50] - Batch loss: 153.0018 - Epoch Loss: 62919.2231 - Avg Loss: 158.8869\n",
            "Epoch [39/50] - Batch loss: 154.6234 - Epoch Loss: 63073.8465 - Avg Loss: 158.8762\n",
            "Epoch [39/50] - Batch loss: 163.5977 - Epoch Loss: 63237.4441 - Avg Loss: 158.8881\n",
            "Epoch [39/50] - Batch loss: 160.6642 - Epoch Loss: 63398.1083 - Avg Loss: 158.8925\n",
            "Epoch [39/50] - Batch loss: 157.1260 - Epoch Loss: 63555.2343 - Avg Loss: 158.8881\n",
            "Epoch [39/50] - Batch loss: 160.2369 - Epoch Loss: 63715.4711 - Avg Loss: 158.8914\n",
            "Epoch [39/50] - Batch loss: 164.9742 - Epoch Loss: 63880.4453 - Avg Loss: 158.9066\n",
            "Epoch [39/50] - Batch loss: 164.7876 - Epoch Loss: 64045.2329 - Avg Loss: 158.9212\n",
            "Epoch [39/50] - Batch loss: 161.1534 - Epoch Loss: 64206.3863 - Avg Loss: 158.9267\n",
            "Epoch [39/50] - Batch loss: 154.7421 - Epoch Loss: 64361.1285 - Avg Loss: 158.9164\n",
            "Epoch [39/50] - Batch loss: 163.1300 - Epoch Loss: 64524.2585 - Avg Loss: 158.9267\n",
            "Epoch [39/50] - Batch loss: 151.6114 - Epoch Loss: 64675.8699 - Avg Loss: 158.9088\n",
            "Epoch [39/50] - Batch loss: 162.2320 - Epoch Loss: 64838.1019 - Avg Loss: 158.9169\n",
            "Epoch [39/50] - Batch loss: 160.4495 - Epoch Loss: 64998.5514 - Avg Loss: 158.9207\n",
            "Epoch [39/50] - Batch loss: 158.2073 - Epoch Loss: 65156.7587 - Avg Loss: 158.9189\n",
            "Epoch [39/50] - Batch loss: 157.4957 - Epoch Loss: 65314.2545 - Avg Loss: 158.9155\n",
            "Epoch [39/50] - Batch loss: 156.5486 - Epoch Loss: 65470.8030 - Avg Loss: 158.9097\n",
            "Epoch [39/50] - Batch loss: 157.9873 - Epoch Loss: 65628.7903 - Avg Loss: 158.9075\n",
            "Epoch [39/50] - Batch loss: 161.5279 - Epoch Loss: 65790.3182 - Avg Loss: 158.9138\n",
            "Epoch [39/50] - Batch loss: 150.5043 - Epoch Loss: 65940.8224 - Avg Loss: 158.8935\n",
            "Epoch [39/50] - Batch loss: 152.0792 - Epoch Loss: 66092.9017 - Avg Loss: 158.8772\n",
            "Epoch [39/50] - Batch loss: 158.4607 - Epoch Loss: 66251.3624 - Avg Loss: 158.8762\n",
            "Epoch [39/50] - Batch loss: 163.9936 - Epoch Loss: 66415.3560 - Avg Loss: 158.8884\n",
            "Epoch [39/50] - Batch loss: 160.7613 - Epoch Loss: 66576.1173 - Avg Loss: 158.8929\n",
            "Epoch [39/50] - Batch loss: 155.7337 - Epoch Loss: 66731.8510 - Avg Loss: 158.8854\n",
            "Epoch [39/50] - Batch loss: 164.0588 - Epoch Loss: 66895.9098 - Avg Loss: 158.8976\n",
            "Epoch [39/50] - Batch loss: 158.6309 - Epoch Loss: 67054.5407 - Avg Loss: 158.8970\n",
            "Epoch [39/50] - Batch loss: 157.3520 - Epoch Loss: 67211.8927 - Avg Loss: 158.8934\n",
            "Epoch [39/50] - Batch loss: 159.5811 - Epoch Loss: 67371.4738 - Avg Loss: 158.8950\n",
            "Epoch [39/50] - Batch loss: 153.4357 - Epoch Loss: 67524.9095 - Avg Loss: 158.8821\n",
            "Epoch [39/50] - Batch loss: 153.8028 - Epoch Loss: 67678.7123 - Avg Loss: 158.8702\n",
            "Epoch [39/50] - Batch loss: 157.2410 - Epoch Loss: 67835.9533 - Avg Loss: 158.8664\n",
            "Epoch [39/50] - Batch loss: 157.5979 - Epoch Loss: 67993.5512 - Avg Loss: 158.8634\n",
            "Epoch [39/50] - Batch loss: 156.9459 - Epoch Loss: 68150.4971 - Avg Loss: 158.8590\n",
            "Epoch [39/50] - Batch loss: 162.8747 - Epoch Loss: 68313.3718 - Avg Loss: 158.8683\n",
            "Epoch [39/50] - Batch loss: 155.3111 - Epoch Loss: 68468.6829 - Avg Loss: 158.8601\n",
            "Epoch [39/50] - Batch loss: 155.6732 - Epoch Loss: 68624.3561 - Avg Loss: 158.8527\n",
            "Epoch [39/50] - Batch loss: 157.9937 - Epoch Loss: 68782.3498 - Avg Loss: 158.8507\n",
            "Epoch [39/50] - Batch loss: 160.9340 - Epoch Loss: 68943.2839 - Avg Loss: 158.8555\n",
            "Epoch [39/50] - Batch loss: 158.8020 - Epoch Loss: 69102.0859 - Avg Loss: 158.8554\n",
            "Epoch [39/50] - Batch loss: 162.7029 - Epoch Loss: 69264.7888 - Avg Loss: 158.8642\n",
            "Epoch [39/50] - Batch loss: 157.5357 - Epoch Loss: 69422.3245 - Avg Loss: 158.8612\n",
            "Epoch [39/50] - Batch loss: 157.6214 - Epoch Loss: 69579.9459 - Avg Loss: 158.8583\n",
            "Epoch [39/50] - Batch loss: 160.6418 - Epoch Loss: 69740.5877 - Avg Loss: 158.8624\n",
            "Epoch [39/50] - Batch loss: 158.7005 - Epoch Loss: 69899.2882 - Avg Loss: 158.8620\n",
            "Epoch [39/50] - Batch loss: 164.4208 - Epoch Loss: 70063.7089 - Avg Loss: 158.8746\n",
            "Epoch [39/50] - Batch loss: 156.5908 - Epoch Loss: 70220.2998 - Avg Loss: 158.8695\n",
            "Epoch [39/50] - Batch loss: 158.7854 - Epoch Loss: 70379.0851 - Avg Loss: 158.8693\n",
            "Epoch [39/50] - Batch loss: 161.1822 - Epoch Loss: 70540.2674 - Avg Loss: 158.8745\n",
            "Epoch [39/50] - Batch loss: 162.6470 - Epoch Loss: 70702.9144 - Avg Loss: 158.8830\n",
            "Epoch [39/50] - Batch loss: 159.1854 - Epoch Loss: 70862.0998 - Avg Loss: 158.8836\n",
            "Epoch [39/50] - Batch loss: 161.0750 - Epoch Loss: 71023.1748 - Avg Loss: 158.8885\n",
            "Epoch [39/50] - Batch loss: 160.9613 - Epoch Loss: 71184.1361 - Avg Loss: 158.8932\n",
            "Epoch [39/50] - Batch loss: 158.6911 - Epoch Loss: 71342.8272 - Avg Loss: 158.8927\n",
            "Epoch [39/50] - Batch loss: 155.8330 - Epoch Loss: 71498.6602 - Avg Loss: 158.8859\n",
            "Epoch [39/50] - Batch loss: 172.3442 - Epoch Loss: 71671.0044 - Avg Loss: 158.9158\n",
            "Epoch [39/50] - Batch loss: 153.8737 - Epoch Loss: 71824.8781 - Avg Loss: 158.9046\n",
            "Epoch [39/50] - Batch loss: 165.8595 - Epoch Loss: 71990.7375 - Avg Loss: 158.9200\n",
            "Epoch [39/50] - Batch loss: 153.3688 - Epoch Loss: 72144.1063 - Avg Loss: 158.9077\n",
            "Epoch [39/50] - Batch loss: 161.4295 - Epoch Loss: 72305.5358 - Avg Loss: 158.9133\n",
            "Epoch [39/50] - Batch loss: 166.3284 - Epoch Loss: 72471.8642 - Avg Loss: 158.9295\n",
            "Epoch [39/50] - Batch loss: 158.2685 - Epoch Loss: 72630.1327 - Avg Loss: 158.9281\n",
            "Epoch [39/50] - Batch loss: 156.6333 - Epoch Loss: 72786.7660 - Avg Loss: 158.9231\n",
            "Epoch [39/50] - Batch loss: 160.0373 - Epoch Loss: 72946.8033 - Avg Loss: 158.9255\n",
            "Epoch [39/50] - Batch loss: 158.2401 - Epoch Loss: 73105.0434 - Avg Loss: 158.9240\n",
            "Epoch [39/50] - Batch loss: 165.6446 - Epoch Loss: 73270.6880 - Avg Loss: 158.9386\n",
            "Epoch [39/50] - Batch loss: 159.1586 - Epoch Loss: 73429.8466 - Avg Loss: 158.9391\n",
            "Epoch [39/50] - Batch loss: 162.3927 - Epoch Loss: 73592.2393 - Avg Loss: 158.9465\n",
            "Epoch [39/50] - Batch loss: 162.5855 - Epoch Loss: 73754.8248 - Avg Loss: 158.9544\n",
            "Epoch [39/50] - Batch loss: 157.5598 - Epoch Loss: 73912.3846 - Avg Loss: 158.9514\n",
            "Epoch [39/50] - Batch loss: 156.9878 - Epoch Loss: 74069.3723 - Avg Loss: 158.9472\n",
            "Epoch [39/50] - Batch loss: 152.3996 - Epoch Loss: 74221.7719 - Avg Loss: 158.9331\n",
            "Epoch [39/50] - Batch loss: 156.3787 - Epoch Loss: 74378.1507 - Avg Loss: 158.9277\n",
            "Epoch [39/50] - Batch loss: 150.2962 - Epoch Loss: 74528.4469 - Avg Loss: 158.9093\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 40/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "695fe9aaab0b460d917792809513a6e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [40/50] - Batch loss: 153.2588 - Epoch Loss: 153.2588 - Avg Loss: 153.2588\n",
            "Epoch [40/50] - Batch loss: 155.5101 - Epoch Loss: 308.7689 - Avg Loss: 154.3845\n",
            "Epoch [40/50] - Batch loss: 159.5214 - Epoch Loss: 468.2904 - Avg Loss: 156.0968\n",
            "Epoch [40/50] - Batch loss: 160.2881 - Epoch Loss: 628.5784 - Avg Loss: 157.1446\n",
            "Epoch [40/50] - Batch loss: 161.4018 - Epoch Loss: 789.9803 - Avg Loss: 157.9961\n",
            "Epoch [40/50] - Batch loss: 156.9231 - Epoch Loss: 946.9033 - Avg Loss: 157.8172\n",
            "Epoch [40/50] - Batch loss: 159.1230 - Epoch Loss: 1106.0263 - Avg Loss: 158.0038\n",
            "Epoch [40/50] - Batch loss: 153.7478 - Epoch Loss: 1259.7742 - Avg Loss: 157.4718\n",
            "Epoch [40/50] - Batch loss: 160.1198 - Epoch Loss: 1419.8940 - Avg Loss: 157.7660\n",
            "Epoch [40/50] - Batch loss: 157.9989 - Epoch Loss: 1577.8929 - Avg Loss: 157.7893\n",
            "Epoch [40/50] - Batch loss: 159.1830 - Epoch Loss: 1737.0759 - Avg Loss: 157.9160\n",
            "Epoch [40/50] - Batch loss: 162.8750 - Epoch Loss: 1899.9509 - Avg Loss: 158.3292\n",
            "Epoch [40/50] - Batch loss: 154.7616 - Epoch Loss: 2054.7125 - Avg Loss: 158.0548\n",
            "Epoch [40/50] - Batch loss: 155.0778 - Epoch Loss: 2209.7903 - Avg Loss: 157.8422\n",
            "Epoch [40/50] - Batch loss: 157.4107 - Epoch Loss: 2367.2010 - Avg Loss: 157.8134\n",
            "Epoch [40/50] - Batch loss: 149.0009 - Epoch Loss: 2516.2018 - Avg Loss: 157.2626\n",
            "Epoch [40/50] - Batch loss: 159.8311 - Epoch Loss: 2676.0329 - Avg Loss: 157.4137\n",
            "Epoch [40/50] - Batch loss: 156.8191 - Epoch Loss: 2832.8520 - Avg Loss: 157.3807\n",
            "Epoch [40/50] - Batch loss: 151.1324 - Epoch Loss: 2983.9844 - Avg Loss: 157.0518\n",
            "Epoch [40/50] - Batch loss: 163.6742 - Epoch Loss: 3147.6586 - Avg Loss: 157.3829\n",
            "Epoch [40/50] - Batch loss: 155.3873 - Epoch Loss: 3303.0459 - Avg Loss: 157.2879\n",
            "Epoch [40/50] - Batch loss: 156.7318 - Epoch Loss: 3459.7776 - Avg Loss: 157.2626\n",
            "Epoch [40/50] - Batch loss: 151.6603 - Epoch Loss: 3611.4380 - Avg Loss: 157.0190\n",
            "Epoch [40/50] - Batch loss: 160.6506 - Epoch Loss: 3772.0885 - Avg Loss: 157.1704\n",
            "Epoch [40/50] - Batch loss: 155.8516 - Epoch Loss: 3927.9401 - Avg Loss: 157.1176\n",
            "Epoch [40/50] - Batch loss: 154.2811 - Epoch Loss: 4082.2212 - Avg Loss: 157.0085\n",
            "Epoch [40/50] - Batch loss: 153.9188 - Epoch Loss: 4236.1400 - Avg Loss: 156.8941\n",
            "Epoch [40/50] - Batch loss: 156.8434 - Epoch Loss: 4392.9834 - Avg Loss: 156.8923\n",
            "Epoch [40/50] - Batch loss: 164.3147 - Epoch Loss: 4557.2981 - Avg Loss: 157.1482\n",
            "Epoch [40/50] - Batch loss: 160.7476 - Epoch Loss: 4718.0457 - Avg Loss: 157.2682\n",
            "Epoch [40/50] - Batch loss: 158.2667 - Epoch Loss: 4876.3124 - Avg Loss: 157.3004\n",
            "Epoch [40/50] - Batch loss: 158.2800 - Epoch Loss: 5034.5925 - Avg Loss: 157.3310\n",
            "Epoch [40/50] - Batch loss: 157.8382 - Epoch Loss: 5192.4306 - Avg Loss: 157.3464\n",
            "Epoch [40/50] - Batch loss: 159.6495 - Epoch Loss: 5352.0802 - Avg Loss: 157.4141\n",
            "Epoch [40/50] - Batch loss: 159.7888 - Epoch Loss: 5511.8690 - Avg Loss: 157.4820\n",
            "Epoch [40/50] - Batch loss: 161.1271 - Epoch Loss: 5672.9961 - Avg Loss: 157.5832\n",
            "Epoch [40/50] - Batch loss: 146.6279 - Epoch Loss: 5819.6239 - Avg Loss: 157.2871\n",
            "Epoch [40/50] - Batch loss: 165.1582 - Epoch Loss: 5984.7821 - Avg Loss: 157.4943\n",
            "Epoch [40/50] - Batch loss: 166.2256 - Epoch Loss: 6151.0077 - Avg Loss: 157.7181\n",
            "Epoch [40/50] - Batch loss: 153.1864 - Epoch Loss: 6304.1941 - Avg Loss: 157.6049\n",
            "Epoch [40/50] - Batch loss: 154.9762 - Epoch Loss: 6459.1703 - Avg Loss: 157.5407\n",
            "Epoch [40/50] - Batch loss: 163.4120 - Epoch Loss: 6622.5823 - Avg Loss: 157.6805\n",
            "Epoch [40/50] - Batch loss: 150.4169 - Epoch Loss: 6772.9992 - Avg Loss: 157.5116\n",
            "Epoch [40/50] - Batch loss: 156.8986 - Epoch Loss: 6929.8978 - Avg Loss: 157.4977\n",
            "Epoch [40/50] - Batch loss: 153.1045 - Epoch Loss: 7083.0023 - Avg Loss: 157.4001\n",
            "Epoch [40/50] - Batch loss: 161.0346 - Epoch Loss: 7244.0369 - Avg Loss: 157.4791\n",
            "Epoch [40/50] - Batch loss: 159.5049 - Epoch Loss: 7403.5417 - Avg Loss: 157.5222\n",
            "Epoch [40/50] - Batch loss: 147.4252 - Epoch Loss: 7550.9670 - Avg Loss: 157.3118\n",
            "Epoch [40/50] - Batch loss: 161.6515 - Epoch Loss: 7712.6185 - Avg Loss: 157.4004\n",
            "Epoch [40/50] - Batch loss: 154.7228 - Epoch Loss: 7867.3413 - Avg Loss: 157.3468\n",
            "Epoch [40/50] - Batch loss: 153.2402 - Epoch Loss: 8020.5815 - Avg Loss: 157.2663\n",
            "Epoch [40/50] - Batch loss: 157.7388 - Epoch Loss: 8178.3203 - Avg Loss: 157.2754\n",
            "Epoch [40/50] - Batch loss: 161.1469 - Epoch Loss: 8339.4671 - Avg Loss: 157.3484\n",
            "Epoch [40/50] - Batch loss: 157.7567 - Epoch Loss: 8497.2238 - Avg Loss: 157.3560\n",
            "Epoch [40/50] - Batch loss: 157.3936 - Epoch Loss: 8654.6174 - Avg Loss: 157.3567\n",
            "Epoch [40/50] - Batch loss: 153.2560 - Epoch Loss: 8807.8734 - Avg Loss: 157.2835\n",
            "Epoch [40/50] - Batch loss: 159.9517 - Epoch Loss: 8967.8250 - Avg Loss: 157.3303\n",
            "Epoch [40/50] - Batch loss: 165.2667 - Epoch Loss: 9133.0918 - Avg Loss: 157.4671\n",
            "Epoch [40/50] - Batch loss: 156.8465 - Epoch Loss: 9289.9382 - Avg Loss: 157.4566\n",
            "Epoch [40/50] - Batch loss: 153.4035 - Epoch Loss: 9443.3418 - Avg Loss: 157.3890\n",
            "Epoch [40/50] - Batch loss: 156.3713 - Epoch Loss: 9599.7131 - Avg Loss: 157.3723\n",
            "Epoch [40/50] - Batch loss: 150.5674 - Epoch Loss: 9750.2805 - Avg Loss: 157.2626\n",
            "Epoch [40/50] - Batch loss: 156.8562 - Epoch Loss: 9907.1368 - Avg Loss: 157.2561\n",
            "Epoch [40/50] - Batch loss: 162.0051 - Epoch Loss: 10069.1419 - Avg Loss: 157.3303\n",
            "Epoch [40/50] - Batch loss: 163.8209 - Epoch Loss: 10232.9628 - Avg Loss: 157.4302\n",
            "Epoch [40/50] - Batch loss: 156.2100 - Epoch Loss: 10389.1728 - Avg Loss: 157.4117\n",
            "Epoch [40/50] - Batch loss: 153.8231 - Epoch Loss: 10542.9958 - Avg Loss: 157.3581\n",
            "Epoch [40/50] - Batch loss: 154.3094 - Epoch Loss: 10697.3052 - Avg Loss: 157.3133\n",
            "Epoch [40/50] - Batch loss: 158.4045 - Epoch Loss: 10855.7097 - Avg Loss: 157.3291\n",
            "Epoch [40/50] - Batch loss: 157.5293 - Epoch Loss: 11013.2390 - Avg Loss: 157.3320\n",
            "Epoch [40/50] - Batch loss: 161.7801 - Epoch Loss: 11175.0190 - Avg Loss: 157.3946\n",
            "Epoch [40/50] - Batch loss: 155.8684 - Epoch Loss: 11330.8874 - Avg Loss: 157.3734\n",
            "Epoch [40/50] - Batch loss: 159.9261 - Epoch Loss: 11490.8136 - Avg Loss: 157.4084\n",
            "Epoch [40/50] - Batch loss: 152.0084 - Epoch Loss: 11642.8219 - Avg Loss: 157.3354\n",
            "Epoch [40/50] - Batch loss: 165.2522 - Epoch Loss: 11808.0741 - Avg Loss: 157.4410\n",
            "Epoch [40/50] - Batch loss: 157.2802 - Epoch Loss: 11965.3543 - Avg Loss: 157.4389\n",
            "Epoch [40/50] - Batch loss: 158.6333 - Epoch Loss: 12123.9876 - Avg Loss: 157.4544\n",
            "Epoch [40/50] - Batch loss: 152.4467 - Epoch Loss: 12276.4343 - Avg Loss: 157.3902\n",
            "Epoch [40/50] - Batch loss: 151.2883 - Epoch Loss: 12427.7226 - Avg Loss: 157.3129\n",
            "Epoch [40/50] - Batch loss: 149.6458 - Epoch Loss: 12577.3683 - Avg Loss: 157.2171\n",
            "Epoch [40/50] - Batch loss: 158.0842 - Epoch Loss: 12735.4525 - Avg Loss: 157.2278\n",
            "Epoch [40/50] - Batch loss: 159.8195 - Epoch Loss: 12895.2721 - Avg Loss: 157.2594\n",
            "Epoch [40/50] - Batch loss: 158.8339 - Epoch Loss: 13054.1060 - Avg Loss: 157.2784\n",
            "Epoch [40/50] - Batch loss: 158.3331 - Epoch Loss: 13212.4391 - Avg Loss: 157.2909\n",
            "Epoch [40/50] - Batch loss: 153.7298 - Epoch Loss: 13366.1689 - Avg Loss: 157.2490\n",
            "Epoch [40/50] - Batch loss: 156.7183 - Epoch Loss: 13522.8872 - Avg Loss: 157.2429\n",
            "Epoch [40/50] - Batch loss: 150.3719 - Epoch Loss: 13673.2592 - Avg Loss: 157.1639\n",
            "Epoch [40/50] - Batch loss: 157.8632 - Epoch Loss: 13831.1224 - Avg Loss: 157.1718\n",
            "Epoch [40/50] - Batch loss: 152.1788 - Epoch Loss: 13983.3011 - Avg Loss: 157.1157\n",
            "Epoch [40/50] - Batch loss: 151.9921 - Epoch Loss: 14135.2932 - Avg Loss: 157.0588\n",
            "Epoch [40/50] - Batch loss: 152.5432 - Epoch Loss: 14287.8364 - Avg Loss: 157.0092\n",
            "Epoch [40/50] - Batch loss: 155.4282 - Epoch Loss: 14443.2646 - Avg Loss: 156.9920\n",
            "Epoch [40/50] - Batch loss: 157.8110 - Epoch Loss: 14601.0755 - Avg Loss: 157.0008\n",
            "Epoch [40/50] - Batch loss: 156.6399 - Epoch Loss: 14757.7154 - Avg Loss: 156.9970\n",
            "Epoch [40/50] - Batch loss: 152.7144 - Epoch Loss: 14910.4298 - Avg Loss: 156.9519\n",
            "Epoch [40/50] - Batch loss: 162.9729 - Epoch Loss: 15073.4026 - Avg Loss: 157.0146\n",
            "Epoch [40/50] - Batch loss: 152.1908 - Epoch Loss: 15225.5934 - Avg Loss: 156.9649\n",
            "Epoch [40/50] - Batch loss: 160.7981 - Epoch Loss: 15386.3915 - Avg Loss: 157.0040\n",
            "Epoch [40/50] - Batch loss: 158.0146 - Epoch Loss: 15544.4061 - Avg Loss: 157.0142\n",
            "Epoch [40/50] - Batch loss: 166.1684 - Epoch Loss: 15710.5745 - Avg Loss: 157.1057\n",
            "Epoch [40/50] - Batch loss: 149.0607 - Epoch Loss: 15859.6352 - Avg Loss: 157.0261\n",
            "Epoch [40/50] - Batch loss: 159.7667 - Epoch Loss: 16019.4019 - Avg Loss: 157.0530\n",
            "Epoch [40/50] - Batch loss: 155.3273 - Epoch Loss: 16174.7291 - Avg Loss: 157.0362\n",
            "Epoch [40/50] - Batch loss: 154.8009 - Epoch Loss: 16329.5300 - Avg Loss: 157.0147\n",
            "Epoch [40/50] - Batch loss: 157.5283 - Epoch Loss: 16487.0583 - Avg Loss: 157.0196\n",
            "Epoch [40/50] - Batch loss: 153.8284 - Epoch Loss: 16640.8868 - Avg Loss: 156.9895\n",
            "Epoch [40/50] - Batch loss: 157.7749 - Epoch Loss: 16798.6617 - Avg Loss: 156.9968\n",
            "Epoch [40/50] - Batch loss: 153.7650 - Epoch Loss: 16952.4267 - Avg Loss: 156.9669\n",
            "Epoch [40/50] - Batch loss: 158.2748 - Epoch Loss: 17110.7015 - Avg Loss: 156.9789\n",
            "Epoch [40/50] - Batch loss: 155.5427 - Epoch Loss: 17266.2442 - Avg Loss: 156.9659\n",
            "Epoch [40/50] - Batch loss: 161.0293 - Epoch Loss: 17427.2735 - Avg Loss: 157.0025\n",
            "Epoch [40/50] - Batch loss: 157.7982 - Epoch Loss: 17585.0717 - Avg Loss: 157.0096\n",
            "Epoch [40/50] - Batch loss: 148.6053 - Epoch Loss: 17733.6771 - Avg Loss: 156.9352\n",
            "Epoch [40/50] - Batch loss: 156.5414 - Epoch Loss: 17890.2184 - Avg Loss: 156.9317\n",
            "Epoch [40/50] - Batch loss: 162.0860 - Epoch Loss: 18052.3045 - Avg Loss: 156.9766\n",
            "Epoch [40/50] - Batch loss: 153.9116 - Epoch Loss: 18206.2161 - Avg Loss: 156.9501\n",
            "Epoch [40/50] - Batch loss: 161.1465 - Epoch Loss: 18367.3626 - Avg Loss: 156.9860\n",
            "Epoch [40/50] - Batch loss: 166.0314 - Epoch Loss: 18533.3940 - Avg Loss: 157.0627\n",
            "Epoch [40/50] - Batch loss: 160.4216 - Epoch Loss: 18693.8156 - Avg Loss: 157.0909\n",
            "Epoch [40/50] - Batch loss: 151.9054 - Epoch Loss: 18845.7209 - Avg Loss: 157.0477\n",
            "Epoch [40/50] - Batch loss: 157.3209 - Epoch Loss: 19003.0418 - Avg Loss: 157.0499\n",
            "Epoch [40/50] - Batch loss: 157.5750 - Epoch Loss: 19160.6168 - Avg Loss: 157.0542\n",
            "Epoch [40/50] - Batch loss: 157.8071 - Epoch Loss: 19318.4239 - Avg Loss: 157.0604\n",
            "Epoch [40/50] - Batch loss: 157.9050 - Epoch Loss: 19476.3289 - Avg Loss: 157.0672\n",
            "Epoch [40/50] - Batch loss: 159.4774 - Epoch Loss: 19635.8062 - Avg Loss: 157.0864\n",
            "Epoch [40/50] - Batch loss: 162.1868 - Epoch Loss: 19797.9930 - Avg Loss: 157.1269\n",
            "Epoch [40/50] - Batch loss: 153.5884 - Epoch Loss: 19951.5814 - Avg Loss: 157.0991\n",
            "Epoch [40/50] - Batch loss: 160.8921 - Epoch Loss: 20112.4735 - Avg Loss: 157.1287\n",
            "Epoch [40/50] - Batch loss: 151.7861 - Epoch Loss: 20264.2596 - Avg Loss: 157.0873\n",
            "Epoch [40/50] - Batch loss: 160.6924 - Epoch Loss: 20424.9520 - Avg Loss: 157.1150\n",
            "Epoch [40/50] - Batch loss: 155.5500 - Epoch Loss: 20580.5020 - Avg Loss: 157.1031\n",
            "Epoch [40/50] - Batch loss: 152.7851 - Epoch Loss: 20733.2871 - Avg Loss: 157.0704\n",
            "Epoch [40/50] - Batch loss: 154.7967 - Epoch Loss: 20888.0838 - Avg Loss: 157.0533\n",
            "Epoch [40/50] - Batch loss: 152.7824 - Epoch Loss: 21040.8662 - Avg Loss: 157.0214\n",
            "Epoch [40/50] - Batch loss: 158.2047 - Epoch Loss: 21199.0709 - Avg Loss: 157.0302\n",
            "Epoch [40/50] - Batch loss: 159.4213 - Epoch Loss: 21358.4921 - Avg Loss: 157.0477\n",
            "Epoch [40/50] - Batch loss: 159.7621 - Epoch Loss: 21518.2542 - Avg Loss: 157.0675\n",
            "Epoch [40/50] - Batch loss: 163.4625 - Epoch Loss: 21681.7166 - Avg Loss: 157.1139\n",
            "Epoch [40/50] - Batch loss: 154.8108 - Epoch Loss: 21836.5274 - Avg Loss: 157.0973\n",
            "Epoch [40/50] - Batch loss: 151.2735 - Epoch Loss: 21987.8009 - Avg Loss: 157.0557\n",
            "Epoch [40/50] - Batch loss: 157.1044 - Epoch Loss: 22144.9053 - Avg Loss: 157.0561\n",
            "Epoch [40/50] - Batch loss: 156.6105 - Epoch Loss: 22301.5158 - Avg Loss: 157.0529\n",
            "Epoch [40/50] - Batch loss: 156.1815 - Epoch Loss: 22457.6973 - Avg Loss: 157.0468\n",
            "Epoch [40/50] - Batch loss: 156.1794 - Epoch Loss: 22613.8767 - Avg Loss: 157.0408\n",
            "Epoch [40/50] - Batch loss: 150.9895 - Epoch Loss: 22764.8663 - Avg Loss: 156.9991\n",
            "Epoch [40/50] - Batch loss: 157.5376 - Epoch Loss: 22922.4039 - Avg Loss: 157.0028\n",
            "Epoch [40/50] - Batch loss: 156.7601 - Epoch Loss: 23079.1640 - Avg Loss: 157.0011\n",
            "Epoch [40/50] - Batch loss: 157.0476 - Epoch Loss: 23236.2116 - Avg Loss: 157.0014\n",
            "Epoch [40/50] - Batch loss: 157.0138 - Epoch Loss: 23393.2255 - Avg Loss: 157.0015\n",
            "Epoch [40/50] - Batch loss: 158.5506 - Epoch Loss: 23551.7761 - Avg Loss: 157.0118\n",
            "Epoch [40/50] - Batch loss: 158.7700 - Epoch Loss: 23710.5461 - Avg Loss: 157.0235\n",
            "Epoch [40/50] - Batch loss: 150.9775 - Epoch Loss: 23861.5236 - Avg Loss: 156.9837\n",
            "Epoch [40/50] - Batch loss: 158.1620 - Epoch Loss: 24019.6856 - Avg Loss: 156.9914\n",
            "Epoch [40/50] - Batch loss: 152.8754 - Epoch Loss: 24172.5609 - Avg Loss: 156.9647\n",
            "Epoch [40/50] - Batch loss: 151.1733 - Epoch Loss: 24323.7343 - Avg Loss: 156.9273\n",
            "Epoch [40/50] - Batch loss: 158.9975 - Epoch Loss: 24482.7318 - Avg Loss: 156.9406\n",
            "Epoch [40/50] - Batch loss: 153.8215 - Epoch Loss: 24636.5533 - Avg Loss: 156.9207\n",
            "Epoch [40/50] - Batch loss: 152.3128 - Epoch Loss: 24788.8661 - Avg Loss: 156.8916\n",
            "Epoch [40/50] - Batch loss: 160.8446 - Epoch Loss: 24949.7107 - Avg Loss: 156.9164\n",
            "Epoch [40/50] - Batch loss: 161.9055 - Epoch Loss: 25111.6162 - Avg Loss: 156.9476\n",
            "Epoch [40/50] - Batch loss: 158.1703 - Epoch Loss: 25269.7865 - Avg Loss: 156.9552\n",
            "Epoch [40/50] - Batch loss: 148.0774 - Epoch Loss: 25417.8639 - Avg Loss: 156.9004\n",
            "Epoch [40/50] - Batch loss: 161.3176 - Epoch Loss: 25579.1815 - Avg Loss: 156.9275\n",
            "Epoch [40/50] - Batch loss: 151.4469 - Epoch Loss: 25730.6284 - Avg Loss: 156.8941\n",
            "Epoch [40/50] - Batch loss: 153.5542 - Epoch Loss: 25884.1825 - Avg Loss: 156.8738\n",
            "Epoch [40/50] - Batch loss: 153.3260 - Epoch Loss: 26037.5086 - Avg Loss: 156.8525\n",
            "Epoch [40/50] - Batch loss: 161.6588 - Epoch Loss: 26199.1673 - Avg Loss: 156.8812\n",
            "Epoch [40/50] - Batch loss: 154.2832 - Epoch Loss: 26353.4505 - Avg Loss: 156.8658\n",
            "Epoch [40/50] - Batch loss: 151.8611 - Epoch Loss: 26505.3116 - Avg Loss: 156.8362\n",
            "Epoch [40/50] - Batch loss: 156.0329 - Epoch Loss: 26661.3445 - Avg Loss: 156.8314\n",
            "Epoch [40/50] - Batch loss: 159.0663 - Epoch Loss: 26820.4108 - Avg Loss: 156.8445\n",
            "Epoch [40/50] - Batch loss: 159.0697 - Epoch Loss: 26979.4805 - Avg Loss: 156.8574\n",
            "Epoch [40/50] - Batch loss: 160.2122 - Epoch Loss: 27139.6927 - Avg Loss: 156.8768\n",
            "Epoch [40/50] - Batch loss: 160.1530 - Epoch Loss: 27299.8457 - Avg Loss: 156.8957\n",
            "Epoch [40/50] - Batch loss: 167.1548 - Epoch Loss: 27467.0005 - Avg Loss: 156.9543\n",
            "Epoch [40/50] - Batch loss: 149.1164 - Epoch Loss: 27616.1169 - Avg Loss: 156.9098\n",
            "Epoch [40/50] - Batch loss: 162.4153 - Epoch Loss: 27778.5321 - Avg Loss: 156.9409\n",
            "Epoch [40/50] - Batch loss: 159.1311 - Epoch Loss: 27937.6632 - Avg Loss: 156.9532\n",
            "Epoch [40/50] - Batch loss: 160.6392 - Epoch Loss: 28098.3024 - Avg Loss: 156.9738\n",
            "Epoch [40/50] - Batch loss: 162.8107 - Epoch Loss: 28261.1130 - Avg Loss: 157.0062\n",
            "Epoch [40/50] - Batch loss: 156.0341 - Epoch Loss: 28417.1472 - Avg Loss: 157.0008\n",
            "Epoch [40/50] - Batch loss: 155.4848 - Epoch Loss: 28572.6319 - Avg Loss: 156.9925\n",
            "Epoch [40/50] - Batch loss: 160.1341 - Epoch Loss: 28732.7660 - Avg Loss: 157.0097\n",
            "Epoch [40/50] - Batch loss: 159.6991 - Epoch Loss: 28892.4651 - Avg Loss: 157.0243\n",
            "Epoch [40/50] - Batch loss: 158.4786 - Epoch Loss: 29050.9437 - Avg Loss: 157.0321\n",
            "Epoch [40/50] - Batch loss: 155.0907 - Epoch Loss: 29206.0343 - Avg Loss: 157.0217\n",
            "Epoch [40/50] - Batch loss: 151.8492 - Epoch Loss: 29357.8835 - Avg Loss: 156.9940\n",
            "Epoch [40/50] - Batch loss: 161.6179 - Epoch Loss: 29519.5014 - Avg Loss: 157.0186\n",
            "Epoch [40/50] - Batch loss: 159.2623 - Epoch Loss: 29678.7637 - Avg Loss: 157.0305\n",
            "Epoch [40/50] - Batch loss: 162.3896 - Epoch Loss: 29841.1533 - Avg Loss: 157.0587\n",
            "Epoch [40/50] - Batch loss: 151.1807 - Epoch Loss: 29992.3340 - Avg Loss: 157.0279\n",
            "Epoch [40/50] - Batch loss: 158.0486 - Epoch Loss: 30150.3826 - Avg Loss: 157.0332\n",
            "Epoch [40/50] - Batch loss: 160.8530 - Epoch Loss: 30311.2357 - Avg Loss: 157.0530\n",
            "Epoch [40/50] - Batch loss: 162.6460 - Epoch Loss: 30473.8816 - Avg Loss: 157.0819\n",
            "Epoch [40/50] - Batch loss: 163.4645 - Epoch Loss: 30637.3461 - Avg Loss: 157.1146\n",
            "Epoch [40/50] - Batch loss: 155.8615 - Epoch Loss: 30793.2076 - Avg Loss: 157.1082\n",
            "Epoch [40/50] - Batch loss: 155.5979 - Epoch Loss: 30948.8056 - Avg Loss: 157.1005\n",
            "Epoch [40/50] - Batch loss: 152.0351 - Epoch Loss: 31100.8406 - Avg Loss: 157.0750\n",
            "Epoch [40/50] - Batch loss: 163.2930 - Epoch Loss: 31264.1336 - Avg Loss: 157.1062\n",
            "Epoch [40/50] - Batch loss: 161.6676 - Epoch Loss: 31425.8011 - Avg Loss: 157.1290\n",
            "Epoch [40/50] - Batch loss: 155.7336 - Epoch Loss: 31581.5348 - Avg Loss: 157.1221\n",
            "Epoch [40/50] - Batch loss: 152.7979 - Epoch Loss: 31734.3327 - Avg Loss: 157.1007\n",
            "Epoch [40/50] - Batch loss: 162.3085 - Epoch Loss: 31896.6411 - Avg Loss: 157.1263\n",
            "Epoch [40/50] - Batch loss: 153.3422 - Epoch Loss: 32049.9833 - Avg Loss: 157.1078\n",
            "Epoch [40/50] - Batch loss: 156.1832 - Epoch Loss: 32206.1665 - Avg Loss: 157.1033\n",
            "Epoch [40/50] - Batch loss: 158.4511 - Epoch Loss: 32364.6176 - Avg Loss: 157.1098\n",
            "Epoch [40/50] - Batch loss: 155.5252 - Epoch Loss: 32520.1428 - Avg Loss: 157.1021\n",
            "Epoch [40/50] - Batch loss: 157.6797 - Epoch Loss: 32677.8225 - Avg Loss: 157.1049\n",
            "Epoch [40/50] - Batch loss: 158.3006 - Epoch Loss: 32836.1231 - Avg Loss: 157.1106\n",
            "Epoch [40/50] - Batch loss: 159.4075 - Epoch Loss: 32995.5306 - Avg Loss: 157.1216\n",
            "Epoch [40/50] - Batch loss: 165.8777 - Epoch Loss: 33161.4084 - Avg Loss: 157.1631\n",
            "Epoch [40/50] - Batch loss: 154.8258 - Epoch Loss: 33316.2341 - Avg Loss: 157.1520\n",
            "Epoch [40/50] - Batch loss: 156.2455 - Epoch Loss: 33472.4796 - Avg Loss: 157.1478\n",
            "Epoch [40/50] - Batch loss: 155.6532 - Epoch Loss: 33628.1328 - Avg Loss: 157.1408\n",
            "Epoch [40/50] - Batch loss: 158.0894 - Epoch Loss: 33786.2222 - Avg Loss: 157.1452\n",
            "Epoch [40/50] - Batch loss: 160.6274 - Epoch Loss: 33946.8496 - Avg Loss: 157.1613\n",
            "Epoch [40/50] - Batch loss: 153.5878 - Epoch Loss: 34100.4374 - Avg Loss: 157.1449\n",
            "Epoch [40/50] - Batch loss: 158.0494 - Epoch Loss: 34258.4868 - Avg Loss: 157.1490\n",
            "Epoch [40/50] - Batch loss: 160.7999 - Epoch Loss: 34419.2867 - Avg Loss: 157.1657\n",
            "Epoch [40/50] - Batch loss: 161.4662 - Epoch Loss: 34580.7529 - Avg Loss: 157.1852\n",
            "Epoch [40/50] - Batch loss: 153.8620 - Epoch Loss: 34734.6149 - Avg Loss: 157.1702\n",
            "Epoch [40/50] - Batch loss: 161.9331 - Epoch Loss: 34896.5480 - Avg Loss: 157.1917\n",
            "Epoch [40/50] - Batch loss: 157.2317 - Epoch Loss: 35053.7796 - Avg Loss: 157.1918\n",
            "Epoch [40/50] - Batch loss: 153.6336 - Epoch Loss: 35207.4133 - Avg Loss: 157.1760\n",
            "Epoch [40/50] - Batch loss: 153.5658 - Epoch Loss: 35360.9791 - Avg Loss: 157.1599\n",
            "Epoch [40/50] - Batch loss: 153.7146 - Epoch Loss: 35514.6937 - Avg Loss: 157.1447\n",
            "Epoch [40/50] - Batch loss: 154.0725 - Epoch Loss: 35668.7663 - Avg Loss: 157.1311\n",
            "Epoch [40/50] - Batch loss: 167.0097 - Epoch Loss: 35835.7759 - Avg Loss: 157.1745\n",
            "Epoch [40/50] - Batch loss: 163.7976 - Epoch Loss: 35999.5735 - Avg Loss: 157.2034\n",
            "Epoch [40/50] - Batch loss: 154.7090 - Epoch Loss: 36154.2825 - Avg Loss: 157.1925\n",
            "Epoch [40/50] - Batch loss: 156.2164 - Epoch Loss: 36310.4989 - Avg Loss: 157.1883\n",
            "Epoch [40/50] - Batch loss: 162.0998 - Epoch Loss: 36472.5987 - Avg Loss: 157.2095\n",
            "Epoch [40/50] - Batch loss: 163.2996 - Epoch Loss: 36635.8983 - Avg Loss: 157.2356\n",
            "Epoch [40/50] - Batch loss: 155.4711 - Epoch Loss: 36791.3694 - Avg Loss: 157.2281\n",
            "Epoch [40/50] - Batch loss: 162.3152 - Epoch Loss: 36953.6846 - Avg Loss: 157.2497\n",
            "Epoch [40/50] - Batch loss: 147.5316 - Epoch Loss: 37101.2162 - Avg Loss: 157.2085\n",
            "Epoch [40/50] - Batch loss: 162.8277 - Epoch Loss: 37264.0439 - Avg Loss: 157.2323\n",
            "Epoch [40/50] - Batch loss: 166.2723 - Epoch Loss: 37430.3162 - Avg Loss: 157.2702\n",
            "Epoch [40/50] - Batch loss: 157.6232 - Epoch Loss: 37587.9394 - Avg Loss: 157.2717\n",
            "Epoch [40/50] - Batch loss: 165.4801 - Epoch Loss: 37753.4195 - Avg Loss: 157.3059\n",
            "Epoch [40/50] - Batch loss: 150.1475 - Epoch Loss: 37903.5670 - Avg Loss: 157.2762\n",
            "Epoch [40/50] - Batch loss: 152.4047 - Epoch Loss: 38055.9717 - Avg Loss: 157.2561\n",
            "Epoch [40/50] - Batch loss: 153.9780 - Epoch Loss: 38209.9497 - Avg Loss: 157.2426\n",
            "Epoch [40/50] - Batch loss: 159.8643 - Epoch Loss: 38369.8140 - Avg Loss: 157.2533\n",
            "Epoch [40/50] - Batch loss: 166.5208 - Epoch Loss: 38536.3348 - Avg Loss: 157.2912\n",
            "Epoch [40/50] - Batch loss: 165.7614 - Epoch Loss: 38702.0962 - Avg Loss: 157.3256\n",
            "Epoch [40/50] - Batch loss: 159.7997 - Epoch Loss: 38861.8959 - Avg Loss: 157.3356\n",
            "Epoch [40/50] - Batch loss: 159.2228 - Epoch Loss: 39021.1187 - Avg Loss: 157.3432\n",
            "Epoch [40/50] - Batch loss: 162.8456 - Epoch Loss: 39183.9642 - Avg Loss: 157.3653\n",
            "Epoch [40/50] - Batch loss: 153.4887 - Epoch Loss: 39337.4529 - Avg Loss: 157.3498\n",
            "Epoch [40/50] - Batch loss: 158.5717 - Epoch Loss: 39496.0246 - Avg Loss: 157.3547\n",
            "Epoch [40/50] - Batch loss: 151.9664 - Epoch Loss: 39647.9911 - Avg Loss: 157.3333\n",
            "Epoch [40/50] - Batch loss: 162.9051 - Epoch Loss: 39810.8961 - Avg Loss: 157.3553\n",
            "Epoch [40/50] - Batch loss: 164.9616 - Epoch Loss: 39975.8577 - Avg Loss: 157.3853\n",
            "Epoch [40/50] - Batch loss: 154.6408 - Epoch Loss: 40130.4985 - Avg Loss: 157.3745\n",
            "Epoch [40/50] - Batch loss: 152.1356 - Epoch Loss: 40282.6340 - Avg Loss: 157.3540\n",
            "Epoch [40/50] - Batch loss: 154.5222 - Epoch Loss: 40437.1563 - Avg Loss: 157.3430\n",
            "Epoch [40/50] - Batch loss: 156.9561 - Epoch Loss: 40594.1124 - Avg Loss: 157.3415\n",
            "Epoch [40/50] - Batch loss: 162.8960 - Epoch Loss: 40757.0083 - Avg Loss: 157.3630\n",
            "Epoch [40/50] - Batch loss: 158.9703 - Epoch Loss: 40915.9787 - Avg Loss: 157.3691\n",
            "Epoch [40/50] - Batch loss: 165.5169 - Epoch Loss: 41081.4956 - Avg Loss: 157.4004\n",
            "Epoch [40/50] - Batch loss: 163.3090 - Epoch Loss: 41244.8046 - Avg Loss: 157.4229\n",
            "Epoch [40/50] - Batch loss: 156.8681 - Epoch Loss: 41401.6727 - Avg Loss: 157.4208\n",
            "Epoch [40/50] - Batch loss: 156.6862 - Epoch Loss: 41558.3589 - Avg Loss: 157.4180\n",
            "Epoch [40/50] - Batch loss: 167.0630 - Epoch Loss: 41725.4219 - Avg Loss: 157.4544\n",
            "Epoch [40/50] - Batch loss: 159.8521 - Epoch Loss: 41885.2740 - Avg Loss: 157.4634\n",
            "Epoch [40/50] - Batch loss: 158.8402 - Epoch Loss: 42044.1142 - Avg Loss: 157.4686\n",
            "Epoch [40/50] - Batch loss: 156.9432 - Epoch Loss: 42201.0574 - Avg Loss: 157.4666\n",
            "Epoch [40/50] - Batch loss: 156.7722 - Epoch Loss: 42357.8296 - Avg Loss: 157.4641\n",
            "Epoch [40/50] - Batch loss: 157.7756 - Epoch Loss: 42515.6052 - Avg Loss: 157.4652\n",
            "Epoch [40/50] - Batch loss: 166.8380 - Epoch Loss: 42682.4432 - Avg Loss: 157.4998\n",
            "Epoch [40/50] - Batch loss: 161.5212 - Epoch Loss: 42843.9644 - Avg Loss: 157.5146\n",
            "Epoch [40/50] - Batch loss: 165.5341 - Epoch Loss: 43009.4985 - Avg Loss: 157.5440\n",
            "Epoch [40/50] - Batch loss: 168.7364 - Epoch Loss: 43178.2349 - Avg Loss: 157.5848\n",
            "Epoch [40/50] - Batch loss: 152.5078 - Epoch Loss: 43330.7427 - Avg Loss: 157.5663\n",
            "Epoch [40/50] - Batch loss: 156.8451 - Epoch Loss: 43487.5878 - Avg Loss: 157.5637\n",
            "Epoch [40/50] - Batch loss: 162.6080 - Epoch Loss: 43650.1958 - Avg Loss: 157.5819\n",
            "Epoch [40/50] - Batch loss: 164.3029 - Epoch Loss: 43814.4986 - Avg Loss: 157.6061\n",
            "Epoch [40/50] - Batch loss: 162.1090 - Epoch Loss: 43976.6076 - Avg Loss: 157.6222\n",
            "Epoch [40/50] - Batch loss: 156.2717 - Epoch Loss: 44132.8793 - Avg Loss: 157.6174\n",
            "Epoch [40/50] - Batch loss: 164.0637 - Epoch Loss: 44296.9430 - Avg Loss: 157.6404\n",
            "Epoch [40/50] - Batch loss: 159.3611 - Epoch Loss: 44456.3041 - Avg Loss: 157.6465\n",
            "Epoch [40/50] - Batch loss: 157.2274 - Epoch Loss: 44613.5315 - Avg Loss: 157.6450\n",
            "Epoch [40/50] - Batch loss: 158.2345 - Epoch Loss: 44771.7660 - Avg Loss: 157.6471\n",
            "Epoch [40/50] - Batch loss: 153.1106 - Epoch Loss: 44924.8766 - Avg Loss: 157.6311\n",
            "Epoch [40/50] - Batch loss: 153.3893 - Epoch Loss: 45078.2659 - Avg Loss: 157.6163\n",
            "Epoch [40/50] - Batch loss: 153.1783 - Epoch Loss: 45231.4442 - Avg Loss: 157.6009\n",
            "Epoch [40/50] - Batch loss: 153.0390 - Epoch Loss: 45384.4832 - Avg Loss: 157.5850\n",
            "Epoch [40/50] - Batch loss: 167.9610 - Epoch Loss: 45552.4442 - Avg Loss: 157.6209\n",
            "Epoch [40/50] - Batch loss: 164.9649 - Epoch Loss: 45717.4090 - Avg Loss: 157.6462\n",
            "Epoch [40/50] - Batch loss: 156.1299 - Epoch Loss: 45873.5390 - Avg Loss: 157.6410\n",
            "Epoch [40/50] - Batch loss: 161.4157 - Epoch Loss: 46034.9547 - Avg Loss: 157.6540\n",
            "Epoch [40/50] - Batch loss: 157.7908 - Epoch Loss: 46192.7455 - Avg Loss: 157.6544\n",
            "Epoch [40/50] - Batch loss: 160.0522 - Epoch Loss: 46352.7977 - Avg Loss: 157.6626\n",
            "Epoch [40/50] - Batch loss: 166.4898 - Epoch Loss: 46519.2874 - Avg Loss: 157.6925\n",
            "Epoch [40/50] - Batch loss: 162.9071 - Epoch Loss: 46682.1945 - Avg Loss: 157.7101\n",
            "Epoch [40/50] - Batch loss: 157.9231 - Epoch Loss: 46840.1176 - Avg Loss: 157.7108\n",
            "Epoch [40/50] - Batch loss: 161.7513 - Epoch Loss: 47001.8689 - Avg Loss: 157.7244\n",
            "Epoch [40/50] - Batch loss: 159.9059 - Epoch Loss: 47161.7747 - Avg Loss: 157.7317\n",
            "Epoch [40/50] - Batch loss: 158.7596 - Epoch Loss: 47320.5343 - Avg Loss: 157.7351\n",
            "Epoch [40/50] - Batch loss: 168.4523 - Epoch Loss: 47488.9866 - Avg Loss: 157.7707\n",
            "Epoch [40/50] - Batch loss: 163.4967 - Epoch Loss: 47652.4834 - Avg Loss: 157.7897\n",
            "Epoch [40/50] - Batch loss: 151.9761 - Epoch Loss: 47804.4595 - Avg Loss: 157.7705\n",
            "Epoch [40/50] - Batch loss: 158.9492 - Epoch Loss: 47963.4088 - Avg Loss: 157.7744\n",
            "Epoch [40/50] - Batch loss: 166.6115 - Epoch Loss: 48130.0203 - Avg Loss: 157.8033\n",
            "Epoch [40/50] - Batch loss: 155.1824 - Epoch Loss: 48285.2027 - Avg Loss: 157.7948\n",
            "Epoch [40/50] - Batch loss: 162.1462 - Epoch Loss: 48447.3490 - Avg Loss: 157.8090\n",
            "Epoch [40/50] - Batch loss: 155.3642 - Epoch Loss: 48602.7132 - Avg Loss: 157.8010\n",
            "Epoch [40/50] - Batch loss: 164.0964 - Epoch Loss: 48766.8095 - Avg Loss: 157.8214\n",
            "Epoch [40/50] - Batch loss: 161.9432 - Epoch Loss: 48928.7527 - Avg Loss: 157.8347\n",
            "Epoch [40/50] - Batch loss: 158.0285 - Epoch Loss: 49086.7812 - Avg Loss: 157.8353\n",
            "Epoch [40/50] - Batch loss: 162.0356 - Epoch Loss: 49248.8167 - Avg Loss: 157.8488\n",
            "Epoch [40/50] - Batch loss: 162.4863 - Epoch Loss: 49411.3031 - Avg Loss: 157.8636\n",
            "Epoch [40/50] - Batch loss: 158.5034 - Epoch Loss: 49569.8064 - Avg Loss: 157.8656\n",
            "Epoch [40/50] - Batch loss: 164.5901 - Epoch Loss: 49734.3965 - Avg Loss: 157.8870\n",
            "Epoch [40/50] - Batch loss: 150.7238 - Epoch Loss: 49885.1203 - Avg Loss: 157.8643\n",
            "Epoch [40/50] - Batch loss: 156.9501 - Epoch Loss: 50042.0704 - Avg Loss: 157.8614\n",
            "Epoch [40/50] - Batch loss: 165.2498 - Epoch Loss: 50207.3203 - Avg Loss: 157.8847\n",
            "Epoch [40/50] - Batch loss: 155.3533 - Epoch Loss: 50362.6736 - Avg Loss: 157.8767\n",
            "Epoch [40/50] - Batch loss: 157.7326 - Epoch Loss: 50520.4062 - Avg Loss: 157.8763\n",
            "Epoch [40/50] - Batch loss: 158.4167 - Epoch Loss: 50678.8229 - Avg Loss: 157.8780\n",
            "Epoch [40/50] - Batch loss: 154.4247 - Epoch Loss: 50833.2476 - Avg Loss: 157.8672\n",
            "Epoch [40/50] - Batch loss: 160.7776 - Epoch Loss: 50994.0251 - Avg Loss: 157.8762\n",
            "Epoch [40/50] - Batch loss: 154.5667 - Epoch Loss: 51148.5918 - Avg Loss: 157.8660\n",
            "Epoch [40/50] - Batch loss: 155.8437 - Epoch Loss: 51304.4355 - Avg Loss: 157.8598\n",
            "Epoch [40/50] - Batch loss: 162.4092 - Epoch Loss: 51466.8447 - Avg Loss: 157.8738\n",
            "Epoch [40/50] - Batch loss: 156.8260 - Epoch Loss: 51623.6707 - Avg Loss: 157.8706\n",
            "Epoch [40/50] - Batch loss: 158.6910 - Epoch Loss: 51782.3617 - Avg Loss: 157.8731\n",
            "Epoch [40/50] - Batch loss: 162.3452 - Epoch Loss: 51944.7069 - Avg Loss: 157.8866\n",
            "Epoch [40/50] - Batch loss: 157.7612 - Epoch Loss: 52102.4681 - Avg Loss: 157.8863\n",
            "Epoch [40/50] - Batch loss: 161.2847 - Epoch Loss: 52263.7528 - Avg Loss: 157.8965\n",
            "Epoch [40/50] - Batch loss: 156.3296 - Epoch Loss: 52420.0824 - Avg Loss: 157.8918\n",
            "Epoch [40/50] - Batch loss: 155.3706 - Epoch Loss: 52575.4530 - Avg Loss: 157.8842\n",
            "Epoch [40/50] - Batch loss: 159.0863 - Epoch Loss: 52734.5393 - Avg Loss: 157.8878\n",
            "Epoch [40/50] - Batch loss: 153.6783 - Epoch Loss: 52888.2176 - Avg Loss: 157.8753\n",
            "Epoch [40/50] - Batch loss: 157.0483 - Epoch Loss: 53045.2659 - Avg Loss: 157.8728\n",
            "Epoch [40/50] - Batch loss: 165.2968 - Epoch Loss: 53210.5627 - Avg Loss: 157.8948\n",
            "Epoch [40/50] - Batch loss: 155.8730 - Epoch Loss: 53366.4357 - Avg Loss: 157.8889\n",
            "Epoch [40/50] - Batch loss: 155.7066 - Epoch Loss: 53522.1423 - Avg Loss: 157.8824\n",
            "Epoch [40/50] - Batch loss: 157.4387 - Epoch Loss: 53679.5810 - Avg Loss: 157.8811\n",
            "Epoch [40/50] - Batch loss: 159.3416 - Epoch Loss: 53838.9225 - Avg Loss: 157.8854\n",
            "Epoch [40/50] - Batch loss: 152.7043 - Epoch Loss: 53991.6268 - Avg Loss: 157.8703\n",
            "Epoch [40/50] - Batch loss: 168.5174 - Epoch Loss: 54160.1443 - Avg Loss: 157.9013\n",
            "Epoch [40/50] - Batch loss: 158.5535 - Epoch Loss: 54318.6978 - Avg Loss: 157.9032\n",
            "Epoch [40/50] - Batch loss: 159.1246 - Epoch Loss: 54477.8223 - Avg Loss: 157.9067\n",
            "Epoch [40/50] - Batch loss: 154.3711 - Epoch Loss: 54632.1934 - Avg Loss: 157.8965\n",
            "Epoch [40/50] - Batch loss: 160.1989 - Epoch Loss: 54792.3924 - Avg Loss: 157.9031\n",
            "Epoch [40/50] - Batch loss: 156.9262 - Epoch Loss: 54949.3186 - Avg Loss: 157.9003\n",
            "Epoch [40/50] - Batch loss: 154.2890 - Epoch Loss: 55103.6076 - Avg Loss: 157.8900\n",
            "Epoch [40/50] - Batch loss: 164.2776 - Epoch Loss: 55267.8851 - Avg Loss: 157.9082\n",
            "Epoch [40/50] - Batch loss: 152.7511 - Epoch Loss: 55420.6362 - Avg Loss: 157.8936\n",
            "Epoch [40/50] - Batch loss: 161.6207 - Epoch Loss: 55582.2570 - Avg Loss: 157.9041\n",
            "Epoch [40/50] - Batch loss: 149.3666 - Epoch Loss: 55731.6235 - Avg Loss: 157.8800\n",
            "Epoch [40/50] - Batch loss: 161.8638 - Epoch Loss: 55893.4874 - Avg Loss: 157.8912\n",
            "Epoch [40/50] - Batch loss: 153.8712 - Epoch Loss: 56047.3585 - Avg Loss: 157.8799\n",
            "Epoch [40/50] - Batch loss: 161.4793 - Epoch Loss: 56208.8378 - Avg Loss: 157.8900\n",
            "Epoch [40/50] - Batch loss: 155.1405 - Epoch Loss: 56363.9783 - Avg Loss: 157.8823\n",
            "Epoch [40/50] - Batch loss: 159.9064 - Epoch Loss: 56523.8847 - Avg Loss: 157.8879\n",
            "Epoch [40/50] - Batch loss: 157.9674 - Epoch Loss: 56681.8521 - Avg Loss: 157.8882\n",
            "Epoch [40/50] - Batch loss: 162.4962 - Epoch Loss: 56844.3483 - Avg Loss: 157.9010\n",
            "Epoch [40/50] - Batch loss: 157.1337 - Epoch Loss: 57001.4820 - Avg Loss: 157.8988\n",
            "Epoch [40/50] - Batch loss: 161.2076 - Epoch Loss: 57162.6896 - Avg Loss: 157.9080\n",
            "Epoch [40/50] - Batch loss: 160.5880 - Epoch Loss: 57323.2776 - Avg Loss: 157.9154\n",
            "Epoch [40/50] - Batch loss: 165.7592 - Epoch Loss: 57489.0368 - Avg Loss: 157.9369\n",
            "Epoch [40/50] - Batch loss: 151.7334 - Epoch Loss: 57640.7702 - Avg Loss: 157.9199\n",
            "Epoch [40/50] - Batch loss: 158.2202 - Epoch Loss: 57798.9904 - Avg Loss: 157.9207\n",
            "Epoch [40/50] - Batch loss: 149.6747 - Epoch Loss: 57948.6650 - Avg Loss: 157.8983\n",
            "Epoch [40/50] - Batch loss: 159.8668 - Epoch Loss: 58108.5319 - Avg Loss: 157.9036\n",
            "Epoch [40/50] - Batch loss: 158.9878 - Epoch Loss: 58267.5196 - Avg Loss: 157.9066\n",
            "Epoch [40/50] - Batch loss: 148.9085 - Epoch Loss: 58416.4281 - Avg Loss: 157.8822\n",
            "Epoch [40/50] - Batch loss: 148.3192 - Epoch Loss: 58564.7473 - Avg Loss: 157.8565\n",
            "Epoch [40/50] - Batch loss: 162.3991 - Epoch Loss: 58727.1465 - Avg Loss: 157.8687\n",
            "Epoch [40/50] - Batch loss: 157.2383 - Epoch Loss: 58884.3848 - Avg Loss: 157.8670\n",
            "Epoch [40/50] - Batch loss: 157.2943 - Epoch Loss: 59041.6791 - Avg Loss: 157.8655\n",
            "Epoch [40/50] - Batch loss: 150.5326 - Epoch Loss: 59192.2117 - Avg Loss: 157.8459\n",
            "Epoch [40/50] - Batch loss: 162.6095 - Epoch Loss: 59354.8211 - Avg Loss: 157.8586\n",
            "Epoch [40/50] - Batch loss: 159.5803 - Epoch Loss: 59514.4014 - Avg Loss: 157.8631\n",
            "Epoch [40/50] - Batch loss: 157.2873 - Epoch Loss: 59671.6887 - Avg Loss: 157.8616\n",
            "Epoch [40/50] - Batch loss: 156.3168 - Epoch Loss: 59828.0056 - Avg Loss: 157.8575\n",
            "Epoch [40/50] - Batch loss: 157.6616 - Epoch Loss: 59985.6672 - Avg Loss: 157.8570\n",
            "Epoch [40/50] - Batch loss: 152.9996 - Epoch Loss: 60138.6668 - Avg Loss: 157.8443\n",
            "Epoch [40/50] - Batch loss: 164.4959 - Epoch Loss: 60303.1627 - Avg Loss: 157.8617\n",
            "Epoch [40/50] - Batch loss: 151.0499 - Epoch Loss: 60454.2126 - Avg Loss: 157.8439\n",
            "Epoch [40/50] - Batch loss: 160.4035 - Epoch Loss: 60614.6161 - Avg Loss: 157.8506\n",
            "Epoch [40/50] - Batch loss: 151.6453 - Epoch Loss: 60766.2614 - Avg Loss: 157.8344\n",
            "Epoch [40/50] - Batch loss: 155.2650 - Epoch Loss: 60921.5264 - Avg Loss: 157.8278\n",
            "Epoch [40/50] - Batch loss: 166.0024 - Epoch Loss: 61087.5289 - Avg Loss: 157.8489\n",
            "Epoch [40/50] - Batch loss: 164.0272 - Epoch Loss: 61251.5561 - Avg Loss: 157.8648\n",
            "Epoch [40/50] - Batch loss: 160.3797 - Epoch Loss: 61411.9358 - Avg Loss: 157.8713\n",
            "Epoch [40/50] - Batch loss: 161.5664 - Epoch Loss: 61573.5022 - Avg Loss: 157.8808\n",
            "Epoch [40/50] - Batch loss: 158.1348 - Epoch Loss: 61731.6370 - Avg Loss: 157.8814\n",
            "Epoch [40/50] - Batch loss: 156.0868 - Epoch Loss: 61887.7238 - Avg Loss: 157.8768\n",
            "Epoch [40/50] - Batch loss: 155.0108 - Epoch Loss: 62042.7345 - Avg Loss: 157.8696\n",
            "Epoch [40/50] - Batch loss: 147.8657 - Epoch Loss: 62190.6003 - Avg Loss: 157.8442\n",
            "Epoch [40/50] - Batch loss: 161.6012 - Epoch Loss: 62352.2015 - Avg Loss: 157.8537\n",
            "Epoch [40/50] - Batch loss: 160.6764 - Epoch Loss: 62512.8779 - Avg Loss: 157.8608\n",
            "Epoch [40/50] - Batch loss: 150.7324 - Epoch Loss: 62663.6102 - Avg Loss: 157.8428\n",
            "Epoch [40/50] - Batch loss: 146.2585 - Epoch Loss: 62809.8688 - Avg Loss: 157.8137\n",
            "Epoch [40/50] - Batch loss: 156.6042 - Epoch Loss: 62966.4730 - Avg Loss: 157.8107\n",
            "Epoch [40/50] - Batch loss: 151.2540 - Epoch Loss: 63117.7269 - Avg Loss: 157.7943\n",
            "Epoch [40/50] - Batch loss: 159.1110 - Epoch Loss: 63276.8379 - Avg Loss: 157.7976\n",
            "Epoch [40/50] - Batch loss: 154.4758 - Epoch Loss: 63431.3137 - Avg Loss: 157.7893\n",
            "Epoch [40/50] - Batch loss: 158.4508 - Epoch Loss: 63589.7644 - Avg Loss: 157.7910\n",
            "Epoch [40/50] - Batch loss: 155.3385 - Epoch Loss: 63745.1029 - Avg Loss: 157.7849\n",
            "Epoch [40/50] - Batch loss: 163.2051 - Epoch Loss: 63908.3080 - Avg Loss: 157.7983\n",
            "Epoch [40/50] - Batch loss: 155.3529 - Epoch Loss: 64063.6609 - Avg Loss: 157.7923\n",
            "Epoch [40/50] - Batch loss: 154.6001 - Epoch Loss: 64218.2610 - Avg Loss: 157.7844\n",
            "Epoch [40/50] - Batch loss: 158.9465 - Epoch Loss: 64377.2076 - Avg Loss: 157.7873\n",
            "Epoch [40/50] - Batch loss: 149.4921 - Epoch Loss: 64526.6997 - Avg Loss: 157.7670\n",
            "Epoch [40/50] - Batch loss: 156.2918 - Epoch Loss: 64682.9915 - Avg Loss: 157.7634\n",
            "Epoch [40/50] - Batch loss: 153.6241 - Epoch Loss: 64836.6156 - Avg Loss: 157.7533\n",
            "Epoch [40/50] - Batch loss: 150.0604 - Epoch Loss: 64986.6760 - Avg Loss: 157.7347\n",
            "Epoch [40/50] - Batch loss: 167.3054 - Epoch Loss: 65153.9814 - Avg Loss: 157.7578\n",
            "Epoch [40/50] - Batch loss: 148.6640 - Epoch Loss: 65302.6453 - Avg Loss: 157.7359\n",
            "Epoch [40/50] - Batch loss: 158.8828 - Epoch Loss: 65461.5281 - Avg Loss: 157.7386\n",
            "Epoch [40/50] - Batch loss: 158.5849 - Epoch Loss: 65620.1130 - Avg Loss: 157.7407\n",
            "Epoch [40/50] - Batch loss: 158.8126 - Epoch Loss: 65778.9256 - Avg Loss: 157.7432\n",
            "Epoch [40/50] - Batch loss: 160.8246 - Epoch Loss: 65939.7502 - Avg Loss: 157.7506\n",
            "Epoch [40/50] - Batch loss: 156.2769 - Epoch Loss: 66096.0271 - Avg Loss: 157.7471\n",
            "Epoch [40/50] - Batch loss: 161.8491 - Epoch Loss: 66257.8762 - Avg Loss: 157.7568\n",
            "Epoch [40/50] - Batch loss: 160.7515 - Epoch Loss: 66418.6277 - Avg Loss: 157.7640\n",
            "Epoch [40/50] - Batch loss: 155.0785 - Epoch Loss: 66573.7062 - Avg Loss: 157.7576\n",
            "Epoch [40/50] - Batch loss: 159.6862 - Epoch Loss: 66733.3924 - Avg Loss: 157.7622\n",
            "Epoch [40/50] - Batch loss: 164.2588 - Epoch Loss: 66897.6512 - Avg Loss: 157.7775\n",
            "Epoch [40/50] - Batch loss: 162.6134 - Epoch Loss: 67060.2646 - Avg Loss: 157.7889\n",
            "Epoch [40/50] - Batch loss: 156.0809 - Epoch Loss: 67216.3456 - Avg Loss: 157.7848\n",
            "Epoch [40/50] - Batch loss: 152.8784 - Epoch Loss: 67369.2240 - Avg Loss: 157.7734\n",
            "Epoch [40/50] - Batch loss: 156.5073 - Epoch Loss: 67525.7313 - Avg Loss: 157.7704\n",
            "Epoch [40/50] - Batch loss: 159.9571 - Epoch Loss: 67685.6883 - Avg Loss: 157.7755\n",
            "Epoch [40/50] - Batch loss: 154.0029 - Epoch Loss: 67839.6913 - Avg Loss: 157.7667\n",
            "Epoch [40/50] - Batch loss: 155.6977 - Epoch Loss: 67995.3890 - Avg Loss: 157.7619\n",
            "Epoch [40/50] - Batch loss: 158.5264 - Epoch Loss: 68153.9154 - Avg Loss: 157.7637\n",
            "Epoch [40/50] - Batch loss: 158.9411 - Epoch Loss: 68312.8565 - Avg Loss: 157.7664\n",
            "Epoch [40/50] - Batch loss: 159.4394 - Epoch Loss: 68472.2959 - Avg Loss: 157.7703\n",
            "Epoch [40/50] - Batch loss: 153.4270 - Epoch Loss: 68625.7229 - Avg Loss: 157.7603\n",
            "Epoch [40/50] - Batch loss: 157.8787 - Epoch Loss: 68783.6016 - Avg Loss: 157.7606\n",
            "Epoch [40/50] - Batch loss: 159.2607 - Epoch Loss: 68942.8623 - Avg Loss: 157.7640\n",
            "Epoch [40/50] - Batch loss: 162.5998 - Epoch Loss: 69105.4621 - Avg Loss: 157.7750\n",
            "Epoch [40/50] - Batch loss: 157.3383 - Epoch Loss: 69262.8004 - Avg Loss: 157.7740\n",
            "Epoch [40/50] - Batch loss: 163.6248 - Epoch Loss: 69426.4252 - Avg Loss: 157.7873\n",
            "Epoch [40/50] - Batch loss: 154.4306 - Epoch Loss: 69580.8558 - Avg Loss: 157.7797\n",
            "Epoch [40/50] - Batch loss: 165.0018 - Epoch Loss: 69745.8576 - Avg Loss: 157.7961\n",
            "Epoch [40/50] - Batch loss: 160.2228 - Epoch Loss: 69906.0804 - Avg Loss: 157.8015\n",
            "Epoch [40/50] - Batch loss: 159.3492 - Epoch Loss: 70065.4296 - Avg Loss: 157.8050\n",
            "Epoch [40/50] - Batch loss: 160.3314 - Epoch Loss: 70225.7610 - Avg Loss: 157.8107\n",
            "Epoch [40/50] - Batch loss: 161.0315 - Epoch Loss: 70386.7925 - Avg Loss: 157.8179\n",
            "Epoch [40/50] - Batch loss: 153.5386 - Epoch Loss: 70540.3311 - Avg Loss: 157.8083\n",
            "Epoch [40/50] - Batch loss: 150.9158 - Epoch Loss: 70691.2469 - Avg Loss: 157.7930\n",
            "Epoch [40/50] - Batch loss: 165.5316 - Epoch Loss: 70856.7785 - Avg Loss: 157.8102\n",
            "Epoch [40/50] - Batch loss: 159.2388 - Epoch Loss: 71016.0173 - Avg Loss: 157.8134\n",
            "Epoch [40/50] - Batch loss: 156.1468 - Epoch Loss: 71172.1641 - Avg Loss: 157.8097\n",
            "Epoch [40/50] - Batch loss: 168.3988 - Epoch Loss: 71340.5629 - Avg Loss: 157.8331\n",
            "Epoch [40/50] - Batch loss: 160.6108 - Epoch Loss: 71501.1737 - Avg Loss: 157.8392\n",
            "Epoch [40/50] - Batch loss: 157.1318 - Epoch Loss: 71658.3055 - Avg Loss: 157.8377\n",
            "Epoch [40/50] - Batch loss: 152.4494 - Epoch Loss: 71810.7549 - Avg Loss: 157.8258\n",
            "Epoch [40/50] - Batch loss: 163.9467 - Epoch Loss: 71974.7016 - Avg Loss: 157.8393\n",
            "Epoch [40/50] - Batch loss: 159.3452 - Epoch Loss: 72134.0467 - Avg Loss: 157.8426\n",
            "Epoch [40/50] - Batch loss: 160.7068 - Epoch Loss: 72294.7535 - Avg Loss: 157.8488\n",
            "Epoch [40/50] - Batch loss: 157.3492 - Epoch Loss: 72452.1028 - Avg Loss: 157.8477\n",
            "Epoch [40/50] - Batch loss: 158.8506 - Epoch Loss: 72610.9534 - Avg Loss: 157.8499\n",
            "Epoch [40/50] - Batch loss: 163.7361 - Epoch Loss: 72774.6895 - Avg Loss: 157.8627\n",
            "Epoch [40/50] - Batch loss: 152.5826 - Epoch Loss: 72927.2721 - Avg Loss: 157.8512\n",
            "Epoch [40/50] - Batch loss: 166.1669 - Epoch Loss: 73093.4390 - Avg Loss: 157.8692\n",
            "Epoch [40/50] - Batch loss: 160.6805 - Epoch Loss: 73254.1195 - Avg Loss: 157.8753\n",
            "Epoch [40/50] - Batch loss: 158.8094 - Epoch Loss: 73412.9289 - Avg Loss: 157.8773\n",
            "Epoch [40/50] - Batch loss: 158.0177 - Epoch Loss: 73570.9466 - Avg Loss: 157.8776\n",
            "Epoch [40/50] - Batch loss: 163.3298 - Epoch Loss: 73734.2765 - Avg Loss: 157.8892\n",
            "Epoch [40/50] - Batch loss: 149.4276 - Epoch Loss: 73883.7041 - Avg Loss: 157.8712\n",
            "Epoch [40/50] - Batch loss: 156.8322 - Epoch Loss: 74040.5363 - Avg Loss: 157.8689\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 41/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09b8ba6e2ba64fdc869228a01f3da70d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [41/50] - Batch loss: 155.4074 - Epoch Loss: 155.4074 - Avg Loss: 155.4074\n",
            "Epoch [41/50] - Batch loss: 157.4772 - Epoch Loss: 312.8847 - Avg Loss: 156.4423\n",
            "Epoch [41/50] - Batch loss: 151.5477 - Epoch Loss: 464.4323 - Avg Loss: 154.8108\n",
            "Epoch [41/50] - Batch loss: 159.8669 - Epoch Loss: 624.2992 - Avg Loss: 156.0748\n",
            "Epoch [41/50] - Batch loss: 163.2310 - Epoch Loss: 787.5302 - Avg Loss: 157.5060\n",
            "Epoch [41/50] - Batch loss: 155.3417 - Epoch Loss: 942.8719 - Avg Loss: 157.1453\n",
            "Epoch [41/50] - Batch loss: 164.6272 - Epoch Loss: 1107.4991 - Avg Loss: 158.2142\n",
            "Epoch [41/50] - Batch loss: 154.2696 - Epoch Loss: 1261.7687 - Avg Loss: 157.7211\n",
            "Epoch [41/50] - Batch loss: 165.3298 - Epoch Loss: 1427.0985 - Avg Loss: 158.5665\n",
            "Epoch [41/50] - Batch loss: 157.0233 - Epoch Loss: 1584.1218 - Avg Loss: 158.4122\n",
            "Epoch [41/50] - Batch loss: 165.5284 - Epoch Loss: 1749.6502 - Avg Loss: 159.0591\n",
            "Epoch [41/50] - Batch loss: 160.3052 - Epoch Loss: 1909.9554 - Avg Loss: 159.1629\n",
            "Epoch [41/50] - Batch loss: 154.2255 - Epoch Loss: 2064.1808 - Avg Loss: 158.7831\n",
            "Epoch [41/50] - Batch loss: 165.9734 - Epoch Loss: 2230.1542 - Avg Loss: 159.2967\n",
            "Epoch [41/50] - Batch loss: 157.3547 - Epoch Loss: 2387.5089 - Avg Loss: 159.1673\n",
            "Epoch [41/50] - Batch loss: 157.3323 - Epoch Loss: 2544.8412 - Avg Loss: 159.0526\n",
            "Epoch [41/50] - Batch loss: 161.2119 - Epoch Loss: 2706.0531 - Avg Loss: 159.1796\n",
            "Epoch [41/50] - Batch loss: 155.4712 - Epoch Loss: 2861.5243 - Avg Loss: 158.9736\n",
            "Epoch [41/50] - Batch loss: 153.8073 - Epoch Loss: 3015.3317 - Avg Loss: 158.7017\n",
            "Epoch [41/50] - Batch loss: 156.2412 - Epoch Loss: 3171.5728 - Avg Loss: 158.5786\n",
            "Epoch [41/50] - Batch loss: 159.7059 - Epoch Loss: 3331.2787 - Avg Loss: 158.6323\n",
            "Epoch [41/50] - Batch loss: 161.9628 - Epoch Loss: 3493.2414 - Avg Loss: 158.7837\n",
            "Epoch [41/50] - Batch loss: 162.8458 - Epoch Loss: 3656.0872 - Avg Loss: 158.9603\n",
            "Epoch [41/50] - Batch loss: 159.9585 - Epoch Loss: 3816.0458 - Avg Loss: 159.0019\n",
            "Epoch [41/50] - Batch loss: 160.8192 - Epoch Loss: 3976.8649 - Avg Loss: 159.0746\n",
            "Epoch [41/50] - Batch loss: 161.2983 - Epoch Loss: 4138.1632 - Avg Loss: 159.1601\n",
            "Epoch [41/50] - Batch loss: 157.1118 - Epoch Loss: 4295.2750 - Avg Loss: 159.0843\n",
            "Epoch [41/50] - Batch loss: 156.8206 - Epoch Loss: 4452.0956 - Avg Loss: 159.0034\n",
            "Epoch [41/50] - Batch loss: 160.6601 - Epoch Loss: 4612.7557 - Avg Loss: 159.0605\n",
            "Epoch [41/50] - Batch loss: 166.5804 - Epoch Loss: 4779.3361 - Avg Loss: 159.3112\n",
            "Epoch [41/50] - Batch loss: 157.2606 - Epoch Loss: 4936.5966 - Avg Loss: 159.2451\n",
            "Epoch [41/50] - Batch loss: 169.5622 - Epoch Loss: 5106.1589 - Avg Loss: 159.5675\n",
            "Epoch [41/50] - Batch loss: 164.8139 - Epoch Loss: 5270.9728 - Avg Loss: 159.7264\n",
            "Epoch [41/50] - Batch loss: 160.9363 - Epoch Loss: 5431.9091 - Avg Loss: 159.7620\n",
            "Epoch [41/50] - Batch loss: 154.9812 - Epoch Loss: 5586.8903 - Avg Loss: 159.6254\n",
            "Epoch [41/50] - Batch loss: 163.7272 - Epoch Loss: 5750.6175 - Avg Loss: 159.7394\n",
            "Epoch [41/50] - Batch loss: 167.1463 - Epoch Loss: 5917.7639 - Avg Loss: 159.9396\n",
            "Epoch [41/50] - Batch loss: 162.6514 - Epoch Loss: 6080.4153 - Avg Loss: 160.0109\n",
            "Epoch [41/50] - Batch loss: 165.3274 - Epoch Loss: 6245.7427 - Avg Loss: 160.1472\n",
            "Epoch [41/50] - Batch loss: 162.2774 - Epoch Loss: 6408.0201 - Avg Loss: 160.2005\n",
            "Epoch [41/50] - Batch loss: 158.3997 - Epoch Loss: 6566.4198 - Avg Loss: 160.1566\n",
            "Epoch [41/50] - Batch loss: 171.2318 - Epoch Loss: 6737.6516 - Avg Loss: 160.4203\n",
            "Epoch [41/50] - Batch loss: 160.6154 - Epoch Loss: 6898.2669 - Avg Loss: 160.4248\n",
            "Epoch [41/50] - Batch loss: 172.9245 - Epoch Loss: 7071.1914 - Avg Loss: 160.7089\n",
            "Epoch [41/50] - Batch loss: 162.1672 - Epoch Loss: 7233.3587 - Avg Loss: 160.7413\n",
            "Epoch [41/50] - Batch loss: 168.7010 - Epoch Loss: 7402.0596 - Avg Loss: 160.9143\n",
            "Epoch [41/50] - Batch loss: 167.9302 - Epoch Loss: 7569.9898 - Avg Loss: 161.0636\n",
            "Epoch [41/50] - Batch loss: 157.9255 - Epoch Loss: 7727.9153 - Avg Loss: 160.9982\n",
            "Epoch [41/50] - Batch loss: 154.4517 - Epoch Loss: 7882.3670 - Avg Loss: 160.8646\n",
            "Epoch [41/50] - Batch loss: 166.1696 - Epoch Loss: 8048.5366 - Avg Loss: 160.9707\n",
            "Epoch [41/50] - Batch loss: 161.3897 - Epoch Loss: 8209.9263 - Avg Loss: 160.9789\n",
            "Epoch [41/50] - Batch loss: 158.7752 - Epoch Loss: 8368.7015 - Avg Loss: 160.9366\n",
            "Epoch [41/50] - Batch loss: 169.3242 - Epoch Loss: 8538.0257 - Avg Loss: 161.0948\n",
            "Epoch [41/50] - Batch loss: 171.6628 - Epoch Loss: 8709.6885 - Avg Loss: 161.2905\n",
            "Epoch [41/50] - Batch loss: 163.6445 - Epoch Loss: 8873.3330 - Avg Loss: 161.3333\n",
            "Epoch [41/50] - Batch loss: 158.6154 - Epoch Loss: 9031.9485 - Avg Loss: 161.2848\n",
            "Epoch [41/50] - Batch loss: 158.1404 - Epoch Loss: 9190.0889 - Avg Loss: 161.2296\n",
            "Epoch [41/50] - Batch loss: 172.7183 - Epoch Loss: 9362.8072 - Avg Loss: 161.4277\n",
            "Epoch [41/50] - Batch loss: 163.2992 - Epoch Loss: 9526.1064 - Avg Loss: 161.4594\n",
            "Epoch [41/50] - Batch loss: 163.4220 - Epoch Loss: 9689.5283 - Avg Loss: 161.4921\n",
            "Epoch [41/50] - Batch loss: 157.1197 - Epoch Loss: 9846.6481 - Avg Loss: 161.4205\n",
            "Epoch [41/50] - Batch loss: 159.1871 - Epoch Loss: 10005.8352 - Avg Loss: 161.3844\n",
            "Epoch [41/50] - Batch loss: 168.6192 - Epoch Loss: 10174.4544 - Avg Loss: 161.4993\n",
            "Epoch [41/50] - Batch loss: 162.9065 - Epoch Loss: 10337.3610 - Avg Loss: 161.5213\n",
            "Epoch [41/50] - Batch loss: 163.4938 - Epoch Loss: 10500.8547 - Avg Loss: 161.5516\n",
            "Epoch [41/50] - Batch loss: 166.0508 - Epoch Loss: 10666.9056 - Avg Loss: 161.6198\n",
            "Epoch [41/50] - Batch loss: 152.9891 - Epoch Loss: 10819.8946 - Avg Loss: 161.4910\n",
            "Epoch [41/50] - Batch loss: 164.8814 - Epoch Loss: 10984.7760 - Avg Loss: 161.5408\n",
            "Epoch [41/50] - Batch loss: 161.5949 - Epoch Loss: 11146.3710 - Avg Loss: 161.5416\n",
            "Epoch [41/50] - Batch loss: 164.7957 - Epoch Loss: 11311.1667 - Avg Loss: 161.5881\n",
            "Epoch [41/50] - Batch loss: 166.9620 - Epoch Loss: 11478.1287 - Avg Loss: 161.6638\n",
            "Epoch [41/50] - Batch loss: 171.0636 - Epoch Loss: 11649.1923 - Avg Loss: 161.7943\n",
            "Epoch [41/50] - Batch loss: 162.5138 - Epoch Loss: 11811.7061 - Avg Loss: 161.8042\n",
            "Epoch [41/50] - Batch loss: 164.4855 - Epoch Loss: 11976.1916 - Avg Loss: 161.8404\n",
            "Epoch [41/50] - Batch loss: 168.7005 - Epoch Loss: 12144.8921 - Avg Loss: 161.9319\n",
            "Epoch [41/50] - Batch loss: 167.4502 - Epoch Loss: 12312.3423 - Avg Loss: 162.0045\n",
            "Epoch [41/50] - Batch loss: 161.9352 - Epoch Loss: 12474.2775 - Avg Loss: 162.0036\n",
            "Epoch [41/50] - Batch loss: 157.8755 - Epoch Loss: 12632.1530 - Avg Loss: 161.9507\n",
            "Epoch [41/50] - Batch loss: 170.2790 - Epoch Loss: 12802.4321 - Avg Loss: 162.0561\n",
            "Epoch [41/50] - Batch loss: 160.8794 - Epoch Loss: 12963.3114 - Avg Loss: 162.0414\n",
            "Epoch [41/50] - Batch loss: 170.2112 - Epoch Loss: 13133.5227 - Avg Loss: 162.1423\n",
            "Epoch [41/50] - Batch loss: 160.0603 - Epoch Loss: 13293.5830 - Avg Loss: 162.1169\n",
            "Epoch [41/50] - Batch loss: 158.8001 - Epoch Loss: 13452.3831 - Avg Loss: 162.0769\n",
            "Epoch [41/50] - Batch loss: 163.0839 - Epoch Loss: 13615.4670 - Avg Loss: 162.0889\n",
            "Epoch [41/50] - Batch loss: 156.3451 - Epoch Loss: 13771.8122 - Avg Loss: 162.0213\n",
            "Epoch [41/50] - Batch loss: 152.3683 - Epoch Loss: 13924.1805 - Avg Loss: 161.9091\n",
            "Epoch [41/50] - Batch loss: 170.4011 - Epoch Loss: 14094.5816 - Avg Loss: 162.0067\n",
            "Epoch [41/50] - Batch loss: 165.5188 - Epoch Loss: 14260.1004 - Avg Loss: 162.0466\n",
            "Epoch [41/50] - Batch loss: 166.1818 - Epoch Loss: 14426.2823 - Avg Loss: 162.0931\n",
            "Epoch [41/50] - Batch loss: 155.8348 - Epoch Loss: 14582.1170 - Avg Loss: 162.0235\n",
            "Epoch [41/50] - Batch loss: 158.6419 - Epoch Loss: 14740.7589 - Avg Loss: 161.9864\n",
            "Epoch [41/50] - Batch loss: 163.2885 - Epoch Loss: 14904.0474 - Avg Loss: 162.0005\n",
            "Epoch [41/50] - Batch loss: 161.3566 - Epoch Loss: 15065.4041 - Avg Loss: 161.9936\n",
            "Epoch [41/50] - Batch loss: 159.9525 - Epoch Loss: 15225.3566 - Avg Loss: 161.9719\n",
            "Epoch [41/50] - Batch loss: 166.5592 - Epoch Loss: 15391.9157 - Avg Loss: 162.0202\n",
            "Epoch [41/50] - Batch loss: 148.4313 - Epoch Loss: 15540.3470 - Avg Loss: 161.8786\n",
            "Epoch [41/50] - Batch loss: 160.9839 - Epoch Loss: 15701.3309 - Avg Loss: 161.8694\n",
            "Epoch [41/50] - Batch loss: 158.3723 - Epoch Loss: 15859.7032 - Avg Loss: 161.8337\n",
            "Epoch [41/50] - Batch loss: 153.8717 - Epoch Loss: 16013.5749 - Avg Loss: 161.7533\n",
            "Epoch [41/50] - Batch loss: 165.2552 - Epoch Loss: 16178.8302 - Avg Loss: 161.7883\n",
            "Epoch [41/50] - Batch loss: 152.2062 - Epoch Loss: 16331.0364 - Avg Loss: 161.6934\n",
            "Epoch [41/50] - Batch loss: 157.8588 - Epoch Loss: 16488.8952 - Avg Loss: 161.6558\n",
            "Epoch [41/50] - Batch loss: 156.2984 - Epoch Loss: 16645.1936 - Avg Loss: 161.6038\n",
            "Epoch [41/50] - Batch loss: 155.9858 - Epoch Loss: 16801.1793 - Avg Loss: 161.5498\n",
            "Epoch [41/50] - Batch loss: 166.1473 - Epoch Loss: 16967.3266 - Avg Loss: 161.5936\n",
            "Epoch [41/50] - Batch loss: 165.4788 - Epoch Loss: 17132.8054 - Avg Loss: 161.6302\n",
            "Epoch [41/50] - Batch loss: 172.4922 - Epoch Loss: 17305.2976 - Avg Loss: 161.7318\n",
            "Epoch [41/50] - Batch loss: 156.3382 - Epoch Loss: 17461.6358 - Avg Loss: 161.6818\n",
            "Epoch [41/50] - Batch loss: 154.3433 - Epoch Loss: 17615.9791 - Avg Loss: 161.6145\n",
            "Epoch [41/50] - Batch loss: 156.0407 - Epoch Loss: 17772.0198 - Avg Loss: 161.5638\n",
            "Epoch [41/50] - Batch loss: 160.1039 - Epoch Loss: 17932.1237 - Avg Loss: 161.5507\n",
            "Epoch [41/50] - Batch loss: 163.0426 - Epoch Loss: 18095.1663 - Avg Loss: 161.5640\n",
            "Epoch [41/50] - Batch loss: 160.3510 - Epoch Loss: 18255.5173 - Avg Loss: 161.5533\n",
            "Epoch [41/50] - Batch loss: 158.6432 - Epoch Loss: 18414.1606 - Avg Loss: 161.5277\n",
            "Epoch [41/50] - Batch loss: 149.8644 - Epoch Loss: 18564.0250 - Avg Loss: 161.4263\n",
            "Epoch [41/50] - Batch loss: 168.3033 - Epoch Loss: 18732.3282 - Avg Loss: 161.4856\n",
            "Epoch [41/50] - Batch loss: 162.1289 - Epoch Loss: 18894.4572 - Avg Loss: 161.4911\n",
            "Epoch [41/50] - Batch loss: 167.3787 - Epoch Loss: 19061.8358 - Avg Loss: 161.5410\n",
            "Epoch [41/50] - Batch loss: 159.3426 - Epoch Loss: 19221.1784 - Avg Loss: 161.5225\n",
            "Epoch [41/50] - Batch loss: 160.9272 - Epoch Loss: 19382.1056 - Avg Loss: 161.5175\n",
            "Epoch [41/50] - Batch loss: 155.8341 - Epoch Loss: 19537.9397 - Avg Loss: 161.4706\n",
            "Epoch [41/50] - Batch loss: 160.2846 - Epoch Loss: 19698.2244 - Avg Loss: 161.4609\n",
            "Epoch [41/50] - Batch loss: 165.2597 - Epoch Loss: 19863.4841 - Avg Loss: 161.4917\n",
            "Epoch [41/50] - Batch loss: 164.8148 - Epoch Loss: 20028.2988 - Avg Loss: 161.5185\n",
            "Epoch [41/50] - Batch loss: 162.4525 - Epoch Loss: 20190.7514 - Avg Loss: 161.5260\n",
            "Epoch [41/50] - Batch loss: 162.7422 - Epoch Loss: 20353.4936 - Avg Loss: 161.5357\n",
            "Epoch [41/50] - Batch loss: 160.0537 - Epoch Loss: 20513.5473 - Avg Loss: 161.5240\n",
            "Epoch [41/50] - Batch loss: 161.2966 - Epoch Loss: 20674.8439 - Avg Loss: 161.5222\n",
            "Epoch [41/50] - Batch loss: 159.1349 - Epoch Loss: 20833.9788 - Avg Loss: 161.5037\n",
            "Epoch [41/50] - Batch loss: 151.4965 - Epoch Loss: 20985.4753 - Avg Loss: 161.4267\n",
            "Epoch [41/50] - Batch loss: 158.9594 - Epoch Loss: 21144.4348 - Avg Loss: 161.4079\n",
            "Epoch [41/50] - Batch loss: 164.9242 - Epoch Loss: 21309.3589 - Avg Loss: 161.4345\n",
            "Epoch [41/50] - Batch loss: 167.4060 - Epoch Loss: 21476.7650 - Avg Loss: 161.4794\n",
            "Epoch [41/50] - Batch loss: 163.2872 - Epoch Loss: 21640.0522 - Avg Loss: 161.4929\n",
            "Epoch [41/50] - Batch loss: 159.2893 - Epoch Loss: 21799.3415 - Avg Loss: 161.4766\n",
            "Epoch [41/50] - Batch loss: 159.8444 - Epoch Loss: 21959.1858 - Avg Loss: 161.4646\n",
            "Epoch [41/50] - Batch loss: 166.6502 - Epoch Loss: 22125.8361 - Avg Loss: 161.5025\n",
            "Epoch [41/50] - Batch loss: 158.2725 - Epoch Loss: 22284.1086 - Avg Loss: 161.4790\n",
            "Epoch [41/50] - Batch loss: 160.1368 - Epoch Loss: 22444.2454 - Avg Loss: 161.4694\n",
            "Epoch [41/50] - Batch loss: 159.3554 - Epoch Loss: 22603.6008 - Avg Loss: 161.4543\n",
            "Epoch [41/50] - Batch loss: 157.5981 - Epoch Loss: 22761.1989 - Avg Loss: 161.4269\n",
            "Epoch [41/50] - Batch loss: 161.3161 - Epoch Loss: 22922.5150 - Avg Loss: 161.4262\n",
            "Epoch [41/50] - Batch loss: 162.3262 - Epoch Loss: 23084.8412 - Avg Loss: 161.4325\n",
            "Epoch [41/50] - Batch loss: 171.2627 - Epoch Loss: 23256.1039 - Avg Loss: 161.5007\n",
            "Epoch [41/50] - Batch loss: 157.4061 - Epoch Loss: 23413.5100 - Avg Loss: 161.4725\n",
            "Epoch [41/50] - Batch loss: 173.3952 - Epoch Loss: 23586.9051 - Avg Loss: 161.5541\n",
            "Epoch [41/50] - Batch loss: 163.8907 - Epoch Loss: 23750.7959 - Avg Loss: 161.5700\n",
            "Epoch [41/50] - Batch loss: 161.8927 - Epoch Loss: 23912.6885 - Avg Loss: 161.5722\n",
            "Epoch [41/50] - Batch loss: 162.4071 - Epoch Loss: 24075.0956 - Avg Loss: 161.5778\n",
            "Epoch [41/50] - Batch loss: 162.9877 - Epoch Loss: 24238.0834 - Avg Loss: 161.5872\n",
            "Epoch [41/50] - Batch loss: 159.5513 - Epoch Loss: 24397.6346 - Avg Loss: 161.5737\n",
            "Epoch [41/50] - Batch loss: 161.5454 - Epoch Loss: 24559.1800 - Avg Loss: 161.5736\n",
            "Epoch [41/50] - Batch loss: 167.6159 - Epoch Loss: 24726.7959 - Avg Loss: 161.6130\n",
            "Epoch [41/50] - Batch loss: 151.8556 - Epoch Loss: 24878.6515 - Avg Loss: 161.5497\n",
            "Epoch [41/50] - Batch loss: 158.8362 - Epoch Loss: 25037.4877 - Avg Loss: 161.5322\n",
            "Epoch [41/50] - Batch loss: 162.2637 - Epoch Loss: 25199.7514 - Avg Loss: 161.5369\n",
            "Epoch [41/50] - Batch loss: 159.6016 - Epoch Loss: 25359.3530 - Avg Loss: 161.5245\n",
            "Epoch [41/50] - Batch loss: 158.0962 - Epoch Loss: 25517.4491 - Avg Loss: 161.5028\n",
            "Epoch [41/50] - Batch loss: 169.9081 - Epoch Loss: 25687.3572 - Avg Loss: 161.5557\n",
            "Epoch [41/50] - Batch loss: 166.4065 - Epoch Loss: 25853.7637 - Avg Loss: 161.5860\n",
            "Epoch [41/50] - Batch loss: 157.5164 - Epoch Loss: 26011.2802 - Avg Loss: 161.5607\n",
            "Epoch [41/50] - Batch loss: 159.7762 - Epoch Loss: 26171.0564 - Avg Loss: 161.5497\n",
            "Epoch [41/50] - Batch loss: 166.2076 - Epoch Loss: 26337.2640 - Avg Loss: 161.5783\n",
            "Epoch [41/50] - Batch loss: 158.8461 - Epoch Loss: 26496.1101 - Avg Loss: 161.5616\n",
            "Epoch [41/50] - Batch loss: 163.0674 - Epoch Loss: 26659.1774 - Avg Loss: 161.5708\n",
            "Epoch [41/50] - Batch loss: 161.0721 - Epoch Loss: 26820.2495 - Avg Loss: 161.5678\n",
            "Epoch [41/50] - Batch loss: 162.9081 - Epoch Loss: 26983.1576 - Avg Loss: 161.5758\n",
            "Epoch [41/50] - Batch loss: 164.2247 - Epoch Loss: 27147.3822 - Avg Loss: 161.5916\n",
            "Epoch [41/50] - Batch loss: 168.9635 - Epoch Loss: 27316.3457 - Avg Loss: 161.6352\n",
            "Epoch [41/50] - Batch loss: 163.6930 - Epoch Loss: 27480.0387 - Avg Loss: 161.6473\n",
            "Epoch [41/50] - Batch loss: 157.2014 - Epoch Loss: 27637.2401 - Avg Loss: 161.6213\n",
            "Epoch [41/50] - Batch loss: 158.2695 - Epoch Loss: 27795.5096 - Avg Loss: 161.6018\n",
            "Epoch [41/50] - Batch loss: 163.3552 - Epoch Loss: 27958.8649 - Avg Loss: 161.6119\n",
            "Epoch [41/50] - Batch loss: 160.9759 - Epoch Loss: 28119.8408 - Avg Loss: 161.6083\n",
            "Epoch [41/50] - Batch loss: 152.7941 - Epoch Loss: 28272.6349 - Avg Loss: 161.5579\n",
            "Epoch [41/50] - Batch loss: 157.3962 - Epoch Loss: 28430.0311 - Avg Loss: 161.5343\n",
            "Epoch [41/50] - Batch loss: 167.6582 - Epoch Loss: 28597.6893 - Avg Loss: 161.5689\n",
            "Epoch [41/50] - Batch loss: 168.5139 - Epoch Loss: 28766.2033 - Avg Loss: 161.6079\n",
            "Epoch [41/50] - Batch loss: 168.1251 - Epoch Loss: 28934.3284 - Avg Loss: 161.6443\n",
            "Epoch [41/50] - Batch loss: 157.4413 - Epoch Loss: 29091.7697 - Avg Loss: 161.6209\n",
            "Epoch [41/50] - Batch loss: 153.8907 - Epoch Loss: 29245.6603 - Avg Loss: 161.5782\n",
            "Epoch [41/50] - Batch loss: 167.9348 - Epoch Loss: 29413.5951 - Avg Loss: 161.6132\n",
            "Epoch [41/50] - Batch loss: 156.1474 - Epoch Loss: 29569.7425 - Avg Loss: 161.5833\n",
            "Epoch [41/50] - Batch loss: 162.1004 - Epoch Loss: 29731.8428 - Avg Loss: 161.5861\n",
            "Epoch [41/50] - Batch loss: 163.7447 - Epoch Loss: 29895.5876 - Avg Loss: 161.5978\n",
            "Epoch [41/50] - Batch loss: 158.5589 - Epoch Loss: 30054.1464 - Avg Loss: 161.5814\n",
            "Epoch [41/50] - Batch loss: 158.5596 - Epoch Loss: 30212.7060 - Avg Loss: 161.5653\n",
            "Epoch [41/50] - Batch loss: 165.0365 - Epoch Loss: 30377.7426 - Avg Loss: 161.5837\n",
            "Epoch [41/50] - Batch loss: 162.2637 - Epoch Loss: 30540.0063 - Avg Loss: 161.5873\n",
            "Epoch [41/50] - Batch loss: 164.8551 - Epoch Loss: 30704.8614 - Avg Loss: 161.6045\n",
            "Epoch [41/50] - Batch loss: 155.6239 - Epoch Loss: 30860.4852 - Avg Loss: 161.5732\n",
            "Epoch [41/50] - Batch loss: 173.0096 - Epoch Loss: 31033.4948 - Avg Loss: 161.6328\n",
            "Epoch [41/50] - Batch loss: 158.3108 - Epoch Loss: 31191.8056 - Avg Loss: 161.6156\n",
            "Epoch [41/50] - Batch loss: 165.1027 - Epoch Loss: 31356.9083 - Avg Loss: 161.6335\n",
            "Epoch [41/50] - Batch loss: 152.8571 - Epoch Loss: 31509.7654 - Avg Loss: 161.5885\n",
            "Epoch [41/50] - Batch loss: 152.1745 - Epoch Loss: 31661.9399 - Avg Loss: 161.5405\n",
            "Epoch [41/50] - Batch loss: 167.7139 - Epoch Loss: 31829.6538 - Avg Loss: 161.5718\n",
            "Epoch [41/50] - Batch loss: 159.1727 - Epoch Loss: 31988.8265 - Avg Loss: 161.5597\n",
            "Epoch [41/50] - Batch loss: 168.3464 - Epoch Loss: 32157.1729 - Avg Loss: 161.5938\n",
            "Epoch [41/50] - Batch loss: 164.2949 - Epoch Loss: 32321.4678 - Avg Loss: 161.6073\n",
            "Epoch [41/50] - Batch loss: 172.1191 - Epoch Loss: 32493.5869 - Avg Loss: 161.6596\n",
            "Epoch [41/50] - Batch loss: 151.7031 - Epoch Loss: 32645.2900 - Avg Loss: 161.6103\n",
            "Epoch [41/50] - Batch loss: 159.0207 - Epoch Loss: 32804.3106 - Avg Loss: 161.5976\n",
            "Epoch [41/50] - Batch loss: 156.9648 - Epoch Loss: 32961.2755 - Avg Loss: 161.5749\n",
            "Epoch [41/50] - Batch loss: 159.9415 - Epoch Loss: 33121.2169 - Avg Loss: 161.5669\n",
            "Epoch [41/50] - Batch loss: 164.9055 - Epoch Loss: 33286.1225 - Avg Loss: 161.5831\n",
            "Epoch [41/50] - Batch loss: 162.3213 - Epoch Loss: 33448.4437 - Avg Loss: 161.5867\n",
            "Epoch [41/50] - Batch loss: 168.3294 - Epoch Loss: 33616.7731 - Avg Loss: 161.6191\n",
            "Epoch [41/50] - Batch loss: 162.0581 - Epoch Loss: 33778.8312 - Avg Loss: 161.6212\n",
            "Epoch [41/50] - Batch loss: 160.1753 - Epoch Loss: 33939.0065 - Avg Loss: 161.6143\n",
            "Epoch [41/50] - Batch loss: 165.6714 - Epoch Loss: 34104.6779 - Avg Loss: 161.6335\n",
            "Epoch [41/50] - Batch loss: 161.6738 - Epoch Loss: 34266.3518 - Avg Loss: 161.6337\n",
            "Epoch [41/50] - Batch loss: 165.2204 - Epoch Loss: 34431.5722 - Avg Loss: 161.6506\n",
            "Epoch [41/50] - Batch loss: 164.4064 - Epoch Loss: 34595.9786 - Avg Loss: 161.6635\n",
            "Epoch [41/50] - Batch loss: 155.4884 - Epoch Loss: 34751.4669 - Avg Loss: 161.6347\n",
            "Epoch [41/50] - Batch loss: 159.5229 - Epoch Loss: 34910.9898 - Avg Loss: 161.6250\n",
            "Epoch [41/50] - Batch loss: 162.5061 - Epoch Loss: 35073.4959 - Avg Loss: 161.6290\n",
            "Epoch [41/50] - Batch loss: 153.8428 - Epoch Loss: 35227.3387 - Avg Loss: 161.5933\n",
            "Epoch [41/50] - Batch loss: 174.0164 - Epoch Loss: 35401.3551 - Avg Loss: 161.6500\n",
            "Epoch [41/50] - Batch loss: 158.6399 - Epoch Loss: 35559.9950 - Avg Loss: 161.6363\n",
            "Epoch [41/50] - Batch loss: 163.1988 - Epoch Loss: 35723.1938 - Avg Loss: 161.6434\n",
            "Epoch [41/50] - Batch loss: 168.5064 - Epoch Loss: 35891.7002 - Avg Loss: 161.6743\n",
            "Epoch [41/50] - Batch loss: 165.2361 - Epoch Loss: 36056.9363 - Avg Loss: 161.6903\n",
            "Epoch [41/50] - Batch loss: 166.5208 - Epoch Loss: 36223.4571 - Avg Loss: 161.7119\n",
            "Epoch [41/50] - Batch loss: 174.4441 - Epoch Loss: 36397.9013 - Avg Loss: 161.7685\n",
            "Epoch [41/50] - Batch loss: 163.6190 - Epoch Loss: 36561.5202 - Avg Loss: 161.7766\n",
            "Epoch [41/50] - Batch loss: 162.1174 - Epoch Loss: 36723.6376 - Avg Loss: 161.7781\n",
            "Epoch [41/50] - Batch loss: 157.3087 - Epoch Loss: 36880.9464 - Avg Loss: 161.7585\n",
            "Epoch [41/50] - Batch loss: 168.9087 - Epoch Loss: 37049.8551 - Avg Loss: 161.7898\n",
            "Epoch [41/50] - Batch loss: 160.9410 - Epoch Loss: 37210.7961 - Avg Loss: 161.7861\n",
            "Epoch [41/50] - Batch loss: 165.1215 - Epoch Loss: 37375.9176 - Avg Loss: 161.8005\n",
            "Epoch [41/50] - Batch loss: 155.8109 - Epoch Loss: 37531.7284 - Avg Loss: 161.7747\n",
            "Epoch [41/50] - Batch loss: 163.1134 - Epoch Loss: 37694.8418 - Avg Loss: 161.7804\n",
            "Epoch [41/50] - Batch loss: 169.5269 - Epoch Loss: 37864.3687 - Avg Loss: 161.8135\n",
            "Epoch [41/50] - Batch loss: 165.1256 - Epoch Loss: 38029.4943 - Avg Loss: 161.8276\n",
            "Epoch [41/50] - Batch loss: 166.1301 - Epoch Loss: 38195.6244 - Avg Loss: 161.8459\n",
            "Epoch [41/50] - Batch loss: 157.0372 - Epoch Loss: 38352.6616 - Avg Loss: 161.8256\n",
            "Epoch [41/50] - Batch loss: 160.1218 - Epoch Loss: 38512.7834 - Avg Loss: 161.8184\n",
            "Epoch [41/50] - Batch loss: 163.5491 - Epoch Loss: 38676.3325 - Avg Loss: 161.8257\n",
            "Epoch [41/50] - Batch loss: 165.0791 - Epoch Loss: 38841.4116 - Avg Loss: 161.8392\n",
            "Epoch [41/50] - Batch loss: 156.9418 - Epoch Loss: 38998.3534 - Avg Loss: 161.8189\n",
            "Epoch [41/50] - Batch loss: 167.1655 - Epoch Loss: 39165.5189 - Avg Loss: 161.8410\n",
            "Epoch [41/50] - Batch loss: 164.5828 - Epoch Loss: 39330.1017 - Avg Loss: 161.8523\n",
            "Epoch [41/50] - Batch loss: 157.5086 - Epoch Loss: 39487.6103 - Avg Loss: 161.8345\n",
            "Epoch [41/50] - Batch loss: 168.5142 - Epoch Loss: 39656.1245 - Avg Loss: 161.8617\n",
            "Epoch [41/50] - Batch loss: 165.4563 - Epoch Loss: 39821.5808 - Avg Loss: 161.8763\n",
            "Epoch [41/50] - Batch loss: 169.1360 - Epoch Loss: 39990.7168 - Avg Loss: 161.9057\n",
            "Epoch [41/50] - Batch loss: 165.9007 - Epoch Loss: 40156.6176 - Avg Loss: 161.9218\n",
            "Epoch [41/50] - Batch loss: 155.4681 - Epoch Loss: 40312.0857 - Avg Loss: 161.8959\n",
            "Epoch [41/50] - Batch loss: 168.9903 - Epoch Loss: 40481.0760 - Avg Loss: 161.9243\n",
            "Epoch [41/50] - Batch loss: 176.9934 - Epoch Loss: 40658.0694 - Avg Loss: 161.9843\n",
            "Epoch [41/50] - Batch loss: 161.3993 - Epoch Loss: 40819.4687 - Avg Loss: 161.9820\n",
            "Epoch [41/50] - Batch loss: 171.7626 - Epoch Loss: 40991.2313 - Avg Loss: 162.0207\n",
            "Epoch [41/50] - Batch loss: 154.4925 - Epoch Loss: 41145.7238 - Avg Loss: 161.9910\n",
            "Epoch [41/50] - Batch loss: 169.5812 - Epoch Loss: 41315.3049 - Avg Loss: 162.0208\n",
            "Epoch [41/50] - Batch loss: 162.2330 - Epoch Loss: 41477.5380 - Avg Loss: 162.0216\n",
            "Epoch [41/50] - Batch loss: 165.6107 - Epoch Loss: 41643.1487 - Avg Loss: 162.0356\n",
            "Epoch [41/50] - Batch loss: 166.0980 - Epoch Loss: 41809.2467 - Avg Loss: 162.0513\n",
            "Epoch [41/50] - Batch loss: 159.3167 - Epoch Loss: 41968.5635 - Avg Loss: 162.0408\n",
            "Epoch [41/50] - Batch loss: 160.1212 - Epoch Loss: 42128.6847 - Avg Loss: 162.0334\n",
            "Epoch [41/50] - Batch loss: 159.4532 - Epoch Loss: 42288.1379 - Avg Loss: 162.0235\n",
            "Epoch [41/50] - Batch loss: 164.0930 - Epoch Loss: 42452.2309 - Avg Loss: 162.0314\n",
            "Epoch [41/50] - Batch loss: 169.7998 - Epoch Loss: 42622.0307 - Avg Loss: 162.0610\n",
            "Epoch [41/50] - Batch loss: 159.0286 - Epoch Loss: 42781.0593 - Avg Loss: 162.0495\n",
            "Epoch [41/50] - Batch loss: 162.3998 - Epoch Loss: 42943.4591 - Avg Loss: 162.0508\n",
            "Epoch [41/50] - Batch loss: 163.2677 - Epoch Loss: 43106.7267 - Avg Loss: 162.0554\n",
            "Epoch [41/50] - Batch loss: 159.1236 - Epoch Loss: 43265.8504 - Avg Loss: 162.0444\n",
            "Epoch [41/50] - Batch loss: 162.6870 - Epoch Loss: 43428.5373 - Avg Loss: 162.0468\n",
            "Epoch [41/50] - Batch loss: 156.5258 - Epoch Loss: 43585.0631 - Avg Loss: 162.0263\n",
            "Epoch [41/50] - Batch loss: 163.6720 - Epoch Loss: 43748.7351 - Avg Loss: 162.0324\n",
            "Epoch [41/50] - Batch loss: 153.5781 - Epoch Loss: 43902.3132 - Avg Loss: 162.0012\n",
            "Epoch [41/50] - Batch loss: 166.1515 - Epoch Loss: 44068.4647 - Avg Loss: 162.0164\n",
            "Epoch [41/50] - Batch loss: 161.9577 - Epoch Loss: 44230.4224 - Avg Loss: 162.0162\n",
            "Epoch [41/50] - Batch loss: 161.5220 - Epoch Loss: 44391.9444 - Avg Loss: 162.0144\n",
            "Epoch [41/50] - Batch loss: 169.3813 - Epoch Loss: 44561.3257 - Avg Loss: 162.0412\n",
            "Epoch [41/50] - Batch loss: 156.8931 - Epoch Loss: 44718.2188 - Avg Loss: 162.0225\n",
            "Epoch [41/50] - Batch loss: 162.7533 - Epoch Loss: 44880.9720 - Avg Loss: 162.0252\n",
            "Epoch [41/50] - Batch loss: 166.4783 - Epoch Loss: 45047.4504 - Avg Loss: 162.0412\n",
            "Epoch [41/50] - Batch loss: 160.0184 - Epoch Loss: 45207.4688 - Avg Loss: 162.0339\n",
            "Epoch [41/50] - Batch loss: 171.1977 - Epoch Loss: 45378.6665 - Avg Loss: 162.0667\n",
            "Epoch [41/50] - Batch loss: 160.6287 - Epoch Loss: 45539.2952 - Avg Loss: 162.0615\n",
            "Epoch [41/50] - Batch loss: 164.6656 - Epoch Loss: 45703.9608 - Avg Loss: 162.0708\n",
            "Epoch [41/50] - Batch loss: 162.0896 - Epoch Loss: 45866.0503 - Avg Loss: 162.0708\n",
            "Epoch [41/50] - Batch loss: 159.4769 - Epoch Loss: 46025.5273 - Avg Loss: 162.0617\n",
            "Epoch [41/50] - Batch loss: 167.8564 - Epoch Loss: 46193.3836 - Avg Loss: 162.0820\n",
            "Epoch [41/50] - Batch loss: 157.3351 - Epoch Loss: 46350.7188 - Avg Loss: 162.0655\n",
            "Epoch [41/50] - Batch loss: 152.4660 - Epoch Loss: 46503.1848 - Avg Loss: 162.0320\n",
            "Epoch [41/50] - Batch loss: 163.4845 - Epoch Loss: 46666.6692 - Avg Loss: 162.0370\n",
            "Epoch [41/50] - Batch loss: 164.6203 - Epoch Loss: 46831.2895 - Avg Loss: 162.0460\n",
            "Epoch [41/50] - Batch loss: 161.6451 - Epoch Loss: 46992.9346 - Avg Loss: 162.0446\n",
            "Epoch [41/50] - Batch loss: 163.8130 - Epoch Loss: 47156.7477 - Avg Loss: 162.0507\n",
            "Epoch [41/50] - Batch loss: 159.2161 - Epoch Loss: 47315.9638 - Avg Loss: 162.0410\n",
            "Epoch [41/50] - Batch loss: 168.4309 - Epoch Loss: 47484.3947 - Avg Loss: 162.0628\n",
            "Epoch [41/50] - Batch loss: 158.5322 - Epoch Loss: 47642.9269 - Avg Loss: 162.0508\n",
            "Epoch [41/50] - Batch loss: 173.3463 - Epoch Loss: 47816.2732 - Avg Loss: 162.0891\n",
            "Epoch [41/50] - Batch loss: 156.8297 - Epoch Loss: 47973.1029 - Avg Loss: 162.0713\n",
            "Epoch [41/50] - Batch loss: 164.4563 - Epoch Loss: 48137.5592 - Avg Loss: 162.0793\n",
            "Epoch [41/50] - Batch loss: 155.9308 - Epoch Loss: 48293.4900 - Avg Loss: 162.0587\n",
            "Epoch [41/50] - Batch loss: 158.5915 - Epoch Loss: 48452.0815 - Avg Loss: 162.0471\n",
            "Epoch [41/50] - Batch loss: 167.9179 - Epoch Loss: 48619.9994 - Avg Loss: 162.0667\n",
            "Epoch [41/50] - Batch loss: 160.5369 - Epoch Loss: 48780.5363 - Avg Loss: 162.0616\n",
            "Epoch [41/50] - Batch loss: 159.2711 - Epoch Loss: 48939.8073 - Avg Loss: 162.0523\n",
            "Epoch [41/50] - Batch loss: 174.2936 - Epoch Loss: 49114.1010 - Avg Loss: 162.0927\n",
            "Epoch [41/50] - Batch loss: 162.8594 - Epoch Loss: 49276.9604 - Avg Loss: 162.0953\n",
            "Epoch [41/50] - Batch loss: 157.0714 - Epoch Loss: 49434.0318 - Avg Loss: 162.0788\n",
            "Epoch [41/50] - Batch loss: 162.2648 - Epoch Loss: 49596.2966 - Avg Loss: 162.0794\n",
            "Epoch [41/50] - Batch loss: 155.5540 - Epoch Loss: 49751.8505 - Avg Loss: 162.0581\n",
            "Epoch [41/50] - Batch loss: 164.9651 - Epoch Loss: 49916.8157 - Avg Loss: 162.0676\n",
            "Epoch [41/50] - Batch loss: 163.2720 - Epoch Loss: 50080.0877 - Avg Loss: 162.0715\n",
            "Epoch [41/50] - Batch loss: 166.6588 - Epoch Loss: 50246.7465 - Avg Loss: 162.0863\n",
            "Epoch [41/50] - Batch loss: 162.5003 - Epoch Loss: 50409.2468 - Avg Loss: 162.0876\n",
            "Epoch [41/50] - Batch loss: 170.0399 - Epoch Loss: 50579.2867 - Avg Loss: 162.1131\n",
            "Epoch [41/50] - Batch loss: 170.3989 - Epoch Loss: 50749.6856 - Avg Loss: 162.1396\n",
            "Epoch [41/50] - Batch loss: 159.9471 - Epoch Loss: 50909.6328 - Avg Loss: 162.1326\n",
            "Epoch [41/50] - Batch loss: 165.8566 - Epoch Loss: 51075.4893 - Avg Loss: 162.1444\n",
            "Epoch [41/50] - Batch loss: 167.4420 - Epoch Loss: 51242.9314 - Avg Loss: 162.1612\n",
            "Epoch [41/50] - Batch loss: 166.2199 - Epoch Loss: 51409.1512 - Avg Loss: 162.1740\n",
            "Epoch [41/50] - Batch loss: 169.8314 - Epoch Loss: 51578.9826 - Avg Loss: 162.1981\n",
            "Epoch [41/50] - Batch loss: 167.6667 - Epoch Loss: 51746.6493 - Avg Loss: 162.2152\n",
            "Epoch [41/50] - Batch loss: 176.5638 - Epoch Loss: 51923.2131 - Avg Loss: 162.2600\n",
            "Epoch [41/50] - Batch loss: 166.2413 - Epoch Loss: 52089.4544 - Avg Loss: 162.2724\n",
            "Epoch [41/50] - Batch loss: 168.7234 - Epoch Loss: 52258.1778 - Avg Loss: 162.2925\n",
            "Epoch [41/50] - Batch loss: 161.5056 - Epoch Loss: 52419.6833 - Avg Loss: 162.2900\n",
            "Epoch [41/50] - Batch loss: 157.6971 - Epoch Loss: 52577.3804 - Avg Loss: 162.2759\n",
            "Epoch [41/50] - Batch loss: 157.4365 - Epoch Loss: 52734.8169 - Avg Loss: 162.2610\n",
            "Epoch [41/50] - Batch loss: 166.2019 - Epoch Loss: 52901.0188 - Avg Loss: 162.2731\n",
            "Epoch [41/50] - Batch loss: 169.5980 - Epoch Loss: 53070.6167 - Avg Loss: 162.2955\n",
            "Epoch [41/50] - Batch loss: 164.1624 - Epoch Loss: 53234.7792 - Avg Loss: 162.3012\n",
            "Epoch [41/50] - Batch loss: 161.4815 - Epoch Loss: 53396.2607 - Avg Loss: 162.2987\n",
            "Epoch [41/50] - Batch loss: 159.9552 - Epoch Loss: 53556.2158 - Avg Loss: 162.2916\n",
            "Epoch [41/50] - Batch loss: 165.6649 - Epoch Loss: 53721.8808 - Avg Loss: 162.3018\n",
            "Epoch [41/50] - Batch loss: 163.9298 - Epoch Loss: 53885.8106 - Avg Loss: 162.3067\n",
            "Epoch [41/50] - Batch loss: 167.5431 - Epoch Loss: 54053.3537 - Avg Loss: 162.3224\n",
            "Epoch [41/50] - Batch loss: 161.8808 - Epoch Loss: 54215.2345 - Avg Loss: 162.3211\n",
            "Epoch [41/50] - Batch loss: 165.1534 - Epoch Loss: 54380.3880 - Avg Loss: 162.3295\n",
            "Epoch [41/50] - Batch loss: 157.2984 - Epoch Loss: 54537.6864 - Avg Loss: 162.3145\n",
            "Epoch [41/50] - Batch loss: 167.5157 - Epoch Loss: 54705.2021 - Avg Loss: 162.3300\n",
            "Epoch [41/50] - Batch loss: 155.6882 - Epoch Loss: 54860.8903 - Avg Loss: 162.3103\n",
            "Epoch [41/50] - Batch loss: 160.9125 - Epoch Loss: 55021.8028 - Avg Loss: 162.3062\n",
            "Epoch [41/50] - Batch loss: 158.7446 - Epoch Loss: 55180.5474 - Avg Loss: 162.2957\n",
            "Epoch [41/50] - Batch loss: 164.5017 - Epoch Loss: 55345.0491 - Avg Loss: 162.3022\n",
            "Epoch [41/50] - Batch loss: 159.5619 - Epoch Loss: 55504.6110 - Avg Loss: 162.2942\n",
            "Epoch [41/50] - Batch loss: 171.3327 - Epoch Loss: 55675.9436 - Avg Loss: 162.3205\n",
            "Epoch [41/50] - Batch loss: 160.2126 - Epoch Loss: 55836.1563 - Avg Loss: 162.3144\n",
            "Epoch [41/50] - Batch loss: 170.4722 - Epoch Loss: 56006.6284 - Avg Loss: 162.3381\n",
            "Epoch [41/50] - Batch loss: 163.2323 - Epoch Loss: 56169.8608 - Avg Loss: 162.3406\n",
            "Epoch [41/50] - Batch loss: 174.5255 - Epoch Loss: 56344.3863 - Avg Loss: 162.3758\n",
            "Epoch [41/50] - Batch loss: 159.5909 - Epoch Loss: 56503.9772 - Avg Loss: 162.3678\n",
            "Epoch [41/50] - Batch loss: 166.2312 - Epoch Loss: 56670.2085 - Avg Loss: 162.3788\n",
            "Epoch [41/50] - Batch loss: 162.2717 - Epoch Loss: 56832.4802 - Avg Loss: 162.3785\n",
            "Epoch [41/50] - Batch loss: 168.0934 - Epoch Loss: 57000.5735 - Avg Loss: 162.3948\n",
            "Epoch [41/50] - Batch loss: 158.6293 - Epoch Loss: 57159.2028 - Avg Loss: 162.3841\n",
            "Epoch [41/50] - Batch loss: 169.2248 - Epoch Loss: 57328.4276 - Avg Loss: 162.4035\n",
            "Epoch [41/50] - Batch loss: 164.9399 - Epoch Loss: 57493.3675 - Avg Loss: 162.4106\n",
            "Epoch [41/50] - Batch loss: 167.5484 - Epoch Loss: 57660.9159 - Avg Loss: 162.4251\n",
            "Epoch [41/50] - Batch loss: 161.2636 - Epoch Loss: 57822.1795 - Avg Loss: 162.4219\n",
            "Epoch [41/50] - Batch loss: 158.6792 - Epoch Loss: 57980.8587 - Avg Loss: 162.4114\n",
            "Epoch [41/50] - Batch loss: 168.4409 - Epoch Loss: 58149.2996 - Avg Loss: 162.4282\n",
            "Epoch [41/50] - Batch loss: 160.5831 - Epoch Loss: 58309.8828 - Avg Loss: 162.4231\n",
            "Epoch [41/50] - Batch loss: 160.1513 - Epoch Loss: 58470.0341 - Avg Loss: 162.4168\n",
            "Epoch [41/50] - Batch loss: 167.6556 - Epoch Loss: 58637.6897 - Avg Loss: 162.4313\n",
            "Epoch [41/50] - Batch loss: 167.0391 - Epoch Loss: 58804.7288 - Avg Loss: 162.4440\n",
            "Epoch [41/50] - Batch loss: 166.7061 - Epoch Loss: 58971.4349 - Avg Loss: 162.4557\n",
            "Epoch [41/50] - Batch loss: 165.8382 - Epoch Loss: 59137.2731 - Avg Loss: 162.4650\n",
            "Epoch [41/50] - Batch loss: 163.4863 - Epoch Loss: 59300.7594 - Avg Loss: 162.4678\n",
            "Epoch [41/50] - Batch loss: 170.2676 - Epoch Loss: 59471.0270 - Avg Loss: 162.4891\n",
            "Epoch [41/50] - Batch loss: 162.7909 - Epoch Loss: 59633.8179 - Avg Loss: 162.4900\n",
            "Epoch [41/50] - Batch loss: 159.1677 - Epoch Loss: 59792.9855 - Avg Loss: 162.4809\n",
            "Epoch [41/50] - Batch loss: 172.3601 - Epoch Loss: 59965.3456 - Avg Loss: 162.5077\n",
            "Epoch [41/50] - Batch loss: 173.1326 - Epoch Loss: 60138.4782 - Avg Loss: 162.5364\n",
            "Epoch [41/50] - Batch loss: 172.3469 - Epoch Loss: 60310.8251 - Avg Loss: 162.5629\n",
            "Epoch [41/50] - Batch loss: 169.4234 - Epoch Loss: 60480.2485 - Avg Loss: 162.5813\n",
            "Epoch [41/50] - Batch loss: 156.7507 - Epoch Loss: 60636.9992 - Avg Loss: 162.5657\n",
            "Epoch [41/50] - Batch loss: 167.9375 - Epoch Loss: 60804.9367 - Avg Loss: 162.5800\n",
            "Epoch [41/50] - Batch loss: 161.6012 - Epoch Loss: 60966.5379 - Avg Loss: 162.5774\n",
            "Epoch [41/50] - Batch loss: 169.2566 - Epoch Loss: 61135.7945 - Avg Loss: 162.5952\n",
            "Epoch [41/50] - Batch loss: 163.5903 - Epoch Loss: 61299.3848 - Avg Loss: 162.5978\n",
            "Epoch [41/50] - Batch loss: 165.8415 - Epoch Loss: 61465.2263 - Avg Loss: 162.6064\n",
            "Epoch [41/50] - Batch loss: 172.3775 - Epoch Loss: 61637.6037 - Avg Loss: 162.6322\n",
            "Epoch [41/50] - Batch loss: 169.3591 - Epoch Loss: 61806.9629 - Avg Loss: 162.6499\n",
            "Epoch [41/50] - Batch loss: 167.0459 - Epoch Loss: 61974.0087 - Avg Loss: 162.6614\n",
            "Epoch [41/50] - Batch loss: 171.3931 - Epoch Loss: 62145.4018 - Avg Loss: 162.6843\n",
            "Epoch [41/50] - Batch loss: 166.3980 - Epoch Loss: 62311.7997 - Avg Loss: 162.6940\n",
            "Epoch [41/50] - Batch loss: 174.9119 - Epoch Loss: 62486.7117 - Avg Loss: 162.7258\n",
            "Epoch [41/50] - Batch loss: 165.9071 - Epoch Loss: 62652.6188 - Avg Loss: 162.7341\n",
            "Epoch [41/50] - Batch loss: 189.1111 - Epoch Loss: 62841.7299 - Avg Loss: 162.8024\n",
            "Epoch [41/50] - Batch loss: 170.1629 - Epoch Loss: 63011.8927 - Avg Loss: 162.8214\n",
            "Epoch [41/50] - Batch loss: 167.1381 - Epoch Loss: 63179.0308 - Avg Loss: 162.8326\n",
            "Epoch [41/50] - Batch loss: 168.7764 - Epoch Loss: 63347.8072 - Avg Loss: 162.8478\n",
            "Epoch [41/50] - Batch loss: 167.7767 - Epoch Loss: 63515.5839 - Avg Loss: 162.8605\n",
            "Epoch [41/50] - Batch loss: 161.6409 - Epoch Loss: 63677.2248 - Avg Loss: 162.8574\n",
            "Epoch [41/50] - Batch loss: 175.6436 - Epoch Loss: 63852.8685 - Avg Loss: 162.8900\n",
            "Epoch [41/50] - Batch loss: 172.1258 - Epoch Loss: 64024.9943 - Avg Loss: 162.9135\n",
            "Epoch [41/50] - Batch loss: 160.9214 - Epoch Loss: 64185.9157 - Avg Loss: 162.9084\n",
            "Epoch [41/50] - Batch loss: 174.1651 - Epoch Loss: 64360.0808 - Avg Loss: 162.9369\n",
            "Epoch [41/50] - Batch loss: 162.4017 - Epoch Loss: 64522.4825 - Avg Loss: 162.9356\n",
            "Epoch [41/50] - Batch loss: 167.5374 - Epoch Loss: 64690.0199 - Avg Loss: 162.9472\n",
            "Epoch [41/50] - Batch loss: 173.1864 - Epoch Loss: 64863.2063 - Avg Loss: 162.9729\n",
            "Epoch [41/50] - Batch loss: 165.5542 - Epoch Loss: 65028.7605 - Avg Loss: 162.9793\n",
            "Epoch [41/50] - Batch loss: 168.0501 - Epoch Loss: 65196.8107 - Avg Loss: 162.9920\n",
            "Epoch [41/50] - Batch loss: 173.2071 - Epoch Loss: 65370.0177 - Avg Loss: 163.0175\n",
            "Epoch [41/50] - Batch loss: 165.5819 - Epoch Loss: 65535.5996 - Avg Loss: 163.0239\n",
            "Epoch [41/50] - Batch loss: 165.5117 - Epoch Loss: 65701.1113 - Avg Loss: 163.0301\n",
            "Epoch [41/50] - Batch loss: 162.3566 - Epoch Loss: 65863.4679 - Avg Loss: 163.0284\n",
            "Epoch [41/50] - Batch loss: 165.2813 - Epoch Loss: 66028.7492 - Avg Loss: 163.0339\n",
            "Epoch [41/50] - Batch loss: 171.8705 - Epoch Loss: 66200.6197 - Avg Loss: 163.0557\n",
            "Epoch [41/50] - Batch loss: 163.6377 - Epoch Loss: 66364.2574 - Avg Loss: 163.0571\n",
            "Epoch [41/50] - Batch loss: 170.7455 - Epoch Loss: 66535.0029 - Avg Loss: 163.0760\n",
            "Epoch [41/50] - Batch loss: 174.0693 - Epoch Loss: 66709.0722 - Avg Loss: 163.1029\n",
            "Epoch [41/50] - Batch loss: 166.1400 - Epoch Loss: 66875.2122 - Avg Loss: 163.1103\n",
            "Epoch [41/50] - Batch loss: 172.7549 - Epoch Loss: 67047.9671 - Avg Loss: 163.1337\n",
            "Epoch [41/50] - Batch loss: 166.1025 - Epoch Loss: 67214.0696 - Avg Loss: 163.1409\n",
            "Epoch [41/50] - Batch loss: 159.6521 - Epoch Loss: 67373.7217 - Avg Loss: 163.1325\n",
            "Epoch [41/50] - Batch loss: 164.2440 - Epoch Loss: 67537.9657 - Avg Loss: 163.1352\n",
            "Epoch [41/50] - Batch loss: 165.4114 - Epoch Loss: 67703.3772 - Avg Loss: 163.1407\n",
            "Epoch [41/50] - Batch loss: 171.7109 - Epoch Loss: 67875.0880 - Avg Loss: 163.1613\n",
            "Epoch [41/50] - Batch loss: 163.4379 - Epoch Loss: 68038.5259 - Avg Loss: 163.1619\n",
            "Epoch [41/50] - Batch loss: 167.8828 - Epoch Loss: 68206.4088 - Avg Loss: 163.1732\n",
            "Epoch [41/50] - Batch loss: 165.0799 - Epoch Loss: 68371.4887 - Avg Loss: 163.1778\n",
            "Epoch [41/50] - Batch loss: 162.0721 - Epoch Loss: 68533.5608 - Avg Loss: 163.1751\n",
            "Epoch [41/50] - Batch loss: 167.8816 - Epoch Loss: 68701.4424 - Avg Loss: 163.1863\n",
            "Epoch [41/50] - Batch loss: 168.6859 - Epoch Loss: 68870.1283 - Avg Loss: 163.1994\n",
            "Epoch [41/50] - Batch loss: 171.3277 - Epoch Loss: 69041.4559 - Avg Loss: 163.2186\n",
            "Epoch [41/50] - Batch loss: 167.2991 - Epoch Loss: 69208.7551 - Avg Loss: 163.2282\n",
            "Epoch [41/50] - Batch loss: 177.2599 - Epoch Loss: 69386.0149 - Avg Loss: 163.2612\n",
            "Epoch [41/50] - Batch loss: 165.5653 - Epoch Loss: 69551.5802 - Avg Loss: 163.2666\n",
            "Epoch [41/50] - Batch loss: 174.0265 - Epoch Loss: 69725.6068 - Avg Loss: 163.2918\n",
            "Epoch [41/50] - Batch loss: 153.3898 - Epoch Loss: 69878.9966 - Avg Loss: 163.2687\n",
            "Epoch [41/50] - Batch loss: 164.3745 - Epoch Loss: 70043.3710 - Avg Loss: 163.2713\n",
            "Epoch [41/50] - Batch loss: 162.6342 - Epoch Loss: 70206.0052 - Avg Loss: 163.2698\n",
            "Epoch [41/50] - Batch loss: 165.8214 - Epoch Loss: 70371.8266 - Avg Loss: 163.2757\n",
            "Epoch [41/50] - Batch loss: 174.5497 - Epoch Loss: 70546.3764 - Avg Loss: 163.3018\n",
            "Epoch [41/50] - Batch loss: 158.3229 - Epoch Loss: 70704.6993 - Avg Loss: 163.2903\n",
            "Epoch [41/50] - Batch loss: 159.2320 - Epoch Loss: 70863.9313 - Avg Loss: 163.2809\n",
            "Epoch [41/50] - Batch loss: 169.3240 - Epoch Loss: 71033.2553 - Avg Loss: 163.2948\n",
            "Epoch [41/50] - Batch loss: 164.8667 - Epoch Loss: 71198.1220 - Avg Loss: 163.2984\n",
            "Epoch [41/50] - Batch loss: 165.9837 - Epoch Loss: 71364.1058 - Avg Loss: 163.3046\n",
            "Epoch [41/50] - Batch loss: 173.2587 - Epoch Loss: 71537.3645 - Avg Loss: 163.3273\n",
            "Epoch [41/50] - Batch loss: 167.9237 - Epoch Loss: 71705.2882 - Avg Loss: 163.3378\n",
            "Epoch [41/50] - Batch loss: 159.1516 - Epoch Loss: 71864.4397 - Avg Loss: 163.3283\n",
            "Epoch [41/50] - Batch loss: 167.3046 - Epoch Loss: 72031.7443 - Avg Loss: 163.3373\n",
            "Epoch [41/50] - Batch loss: 157.7165 - Epoch Loss: 72189.4608 - Avg Loss: 163.3246\n",
            "Epoch [41/50] - Batch loss: 162.9676 - Epoch Loss: 72352.4285 - Avg Loss: 163.3238\n",
            "Epoch [41/50] - Batch loss: 163.3847 - Epoch Loss: 72515.8131 - Avg Loss: 163.3239\n",
            "Epoch [41/50] - Batch loss: 159.5546 - Epoch Loss: 72675.3677 - Avg Loss: 163.3154\n",
            "Epoch [41/50] - Batch loss: 162.0459 - Epoch Loss: 72837.4137 - Avg Loss: 163.3126\n",
            "Epoch [41/50] - Batch loss: 163.5117 - Epoch Loss: 73000.9254 - Avg Loss: 163.3130\n",
            "Epoch [41/50] - Batch loss: 169.6576 - Epoch Loss: 73170.5829 - Avg Loss: 163.3272\n",
            "Epoch [41/50] - Batch loss: 162.1556 - Epoch Loss: 73332.7385 - Avg Loss: 163.3246\n",
            "Epoch [41/50] - Batch loss: 165.1726 - Epoch Loss: 73497.9111 - Avg Loss: 163.3287\n",
            "Epoch [41/50] - Batch loss: 164.5644 - Epoch Loss: 73662.4755 - Avg Loss: 163.3314\n",
            "Epoch [41/50] - Batch loss: 168.3204 - Epoch Loss: 73830.7959 - Avg Loss: 163.3425\n",
            "Epoch [41/50] - Batch loss: 166.3688 - Epoch Loss: 73997.1646 - Avg Loss: 163.3491\n",
            "Epoch [41/50] - Batch loss: 161.8588 - Epoch Loss: 74159.0234 - Avg Loss: 163.3459\n",
            "Epoch [41/50] - Batch loss: 172.0315 - Epoch Loss: 74331.0549 - Avg Loss: 163.3650\n",
            "Epoch [41/50] - Batch loss: 158.5098 - Epoch Loss: 74489.5647 - Avg Loss: 163.3543\n",
            "Epoch [41/50] - Batch loss: 166.1100 - Epoch Loss: 74655.6747 - Avg Loss: 163.3603\n",
            "Epoch [41/50] - Batch loss: 166.1111 - Epoch Loss: 74821.7858 - Avg Loss: 163.3663\n",
            "Epoch [41/50] - Batch loss: 163.5811 - Epoch Loss: 74985.3669 - Avg Loss: 163.3668\n",
            "Epoch [41/50] - Batch loss: 162.2920 - Epoch Loss: 75147.6589 - Avg Loss: 163.3645\n",
            "Epoch [41/50] - Batch loss: 158.7803 - Epoch Loss: 75306.4392 - Avg Loss: 163.3545\n",
            "Epoch [41/50] - Batch loss: 160.7744 - Epoch Loss: 75467.2136 - Avg Loss: 163.3489\n",
            "Epoch [41/50] - Batch loss: 163.5721 - Epoch Loss: 75630.7857 - Avg Loss: 163.3494\n",
            "Epoch [41/50] - Batch loss: 163.7744 - Epoch Loss: 75794.5601 - Avg Loss: 163.3503\n",
            "Epoch [41/50] - Batch loss: 168.9249 - Epoch Loss: 75963.4849 - Avg Loss: 163.3623\n",
            "Epoch [41/50] - Batch loss: 160.9745 - Epoch Loss: 76124.4594 - Avg Loss: 163.3572\n",
            "Epoch [41/50] - Batch loss: 159.6694 - Epoch Loss: 76284.1288 - Avg Loss: 163.3493\n",
            "Epoch [41/50] - Batch loss: 163.5074 - Epoch Loss: 76447.6362 - Avg Loss: 163.3497\n",
            "Epoch [41/50] - Batch loss: 159.7287 - Epoch Loss: 76607.3649 - Avg Loss: 163.3419\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 42/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c18728d81227403d95338da27e0cd13c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [42/50] - Batch loss: 160.8188 - Epoch Loss: 160.8188 - Avg Loss: 160.8188\n",
            "Epoch [42/50] - Batch loss: 158.1349 - Epoch Loss: 318.9537 - Avg Loss: 159.4768\n",
            "Epoch [42/50] - Batch loss: 168.5530 - Epoch Loss: 487.5067 - Avg Loss: 162.5022\n",
            "Epoch [42/50] - Batch loss: 150.4935 - Epoch Loss: 638.0001 - Avg Loss: 159.5000\n",
            "Epoch [42/50] - Batch loss: 172.5522 - Epoch Loss: 810.5523 - Avg Loss: 162.1105\n",
            "Epoch [42/50] - Batch loss: 163.9986 - Epoch Loss: 974.5509 - Avg Loss: 162.4252\n",
            "Epoch [42/50] - Batch loss: 174.6502 - Epoch Loss: 1149.2011 - Avg Loss: 164.1716\n",
            "Epoch [42/50] - Batch loss: 156.6301 - Epoch Loss: 1305.8312 - Avg Loss: 163.2289\n",
            "Epoch [42/50] - Batch loss: 157.8983 - Epoch Loss: 1463.7294 - Avg Loss: 162.6366\n",
            "Epoch [42/50] - Batch loss: 173.6933 - Epoch Loss: 1637.4228 - Avg Loss: 163.7423\n",
            "Epoch [42/50] - Batch loss: 168.6848 - Epoch Loss: 1806.1076 - Avg Loss: 164.1916\n",
            "Epoch [42/50] - Batch loss: 157.5569 - Epoch Loss: 1963.6645 - Avg Loss: 163.6387\n",
            "Epoch [42/50] - Batch loss: 159.2453 - Epoch Loss: 2122.9098 - Avg Loss: 163.3008\n",
            "Epoch [42/50] - Batch loss: 166.7239 - Epoch Loss: 2289.6337 - Avg Loss: 163.5453\n",
            "Epoch [42/50] - Batch loss: 168.1117 - Epoch Loss: 2457.7453 - Avg Loss: 163.8497\n",
            "Epoch [42/50] - Batch loss: 169.4762 - Epoch Loss: 2627.2216 - Avg Loss: 164.2013\n",
            "Epoch [42/50] - Batch loss: 159.3453 - Epoch Loss: 2786.5669 - Avg Loss: 163.9157\n",
            "Epoch [42/50] - Batch loss: 165.2301 - Epoch Loss: 2951.7969 - Avg Loss: 163.9887\n",
            "Epoch [42/50] - Batch loss: 166.7991 - Epoch Loss: 3118.5960 - Avg Loss: 164.1366\n",
            "Epoch [42/50] - Batch loss: 162.8314 - Epoch Loss: 3281.4274 - Avg Loss: 164.0714\n",
            "Epoch [42/50] - Batch loss: 159.2905 - Epoch Loss: 3440.7179 - Avg Loss: 163.8437\n",
            "Epoch [42/50] - Batch loss: 167.3502 - Epoch Loss: 3608.0681 - Avg Loss: 164.0031\n",
            "Epoch [42/50] - Batch loss: 172.2922 - Epoch Loss: 3780.3604 - Avg Loss: 164.3635\n",
            "Epoch [42/50] - Batch loss: 156.2703 - Epoch Loss: 3936.6306 - Avg Loss: 164.0263\n",
            "Epoch [42/50] - Batch loss: 161.3356 - Epoch Loss: 4097.9662 - Avg Loss: 163.9186\n",
            "Epoch [42/50] - Batch loss: 163.7919 - Epoch Loss: 4261.7580 - Avg Loss: 163.9138\n",
            "Epoch [42/50] - Batch loss: 165.2087 - Epoch Loss: 4426.9667 - Avg Loss: 163.9617\n",
            "Epoch [42/50] - Batch loss: 165.2136 - Epoch Loss: 4592.1803 - Avg Loss: 164.0064\n",
            "Epoch [42/50] - Batch loss: 155.8468 - Epoch Loss: 4748.0271 - Avg Loss: 163.7251\n",
            "Epoch [42/50] - Batch loss: 167.5809 - Epoch Loss: 4915.6080 - Avg Loss: 163.8536\n",
            "Epoch [42/50] - Batch loss: 169.1137 - Epoch Loss: 5084.7217 - Avg Loss: 164.0233\n",
            "Epoch [42/50] - Batch loss: 159.8756 - Epoch Loss: 5244.5973 - Avg Loss: 163.8937\n",
            "Epoch [42/50] - Batch loss: 164.0789 - Epoch Loss: 5408.6762 - Avg Loss: 163.8993\n",
            "Epoch [42/50] - Batch loss: 163.3677 - Epoch Loss: 5572.0438 - Avg Loss: 163.8836\n",
            "Epoch [42/50] - Batch loss: 166.3564 - Epoch Loss: 5738.4002 - Avg Loss: 163.9543\n",
            "Epoch [42/50] - Batch loss: 164.4323 - Epoch Loss: 5902.8325 - Avg Loss: 163.9676\n",
            "Epoch [42/50] - Batch loss: 165.0603 - Epoch Loss: 6067.8929 - Avg Loss: 163.9971\n",
            "Epoch [42/50] - Batch loss: 161.8784 - Epoch Loss: 6229.7713 - Avg Loss: 163.9413\n",
            "Epoch [42/50] - Batch loss: 157.2754 - Epoch Loss: 6387.0467 - Avg Loss: 163.7704\n",
            "Epoch [42/50] - Batch loss: 160.3241 - Epoch Loss: 6547.3708 - Avg Loss: 163.6843\n",
            "Epoch [42/50] - Batch loss: 159.6453 - Epoch Loss: 6707.0161 - Avg Loss: 163.5858\n",
            "Epoch [42/50] - Batch loss: 161.4298 - Epoch Loss: 6868.4459 - Avg Loss: 163.5344\n",
            "Epoch [42/50] - Batch loss: 159.1091 - Epoch Loss: 7027.5550 - Avg Loss: 163.4315\n",
            "Epoch [42/50] - Batch loss: 166.0478 - Epoch Loss: 7193.6028 - Avg Loss: 163.4910\n",
            "Epoch [42/50] - Batch loss: 162.0536 - Epoch Loss: 7355.6564 - Avg Loss: 163.4590\n",
            "Epoch [42/50] - Batch loss: 165.9501 - Epoch Loss: 7521.6065 - Avg Loss: 163.5132\n",
            "Epoch [42/50] - Batch loss: 164.7613 - Epoch Loss: 7686.3678 - Avg Loss: 163.5397\n",
            "Epoch [42/50] - Batch loss: 158.7838 - Epoch Loss: 7845.1516 - Avg Loss: 163.4407\n",
            "Epoch [42/50] - Batch loss: 164.6532 - Epoch Loss: 8009.8048 - Avg Loss: 163.4654\n",
            "Epoch [42/50] - Batch loss: 173.0699 - Epoch Loss: 8182.8747 - Avg Loss: 163.6575\n",
            "Epoch [42/50] - Batch loss: 156.1886 - Epoch Loss: 8339.0633 - Avg Loss: 163.5110\n",
            "Epoch [42/50] - Batch loss: 163.6754 - Epoch Loss: 8502.7387 - Avg Loss: 163.5142\n",
            "Epoch [42/50] - Batch loss: 162.4477 - Epoch Loss: 8665.1864 - Avg Loss: 163.4941\n",
            "Epoch [42/50] - Batch loss: 160.0989 - Epoch Loss: 8825.2853 - Avg Loss: 163.4312\n",
            "Epoch [42/50] - Batch loss: 154.0560 - Epoch Loss: 8979.3413 - Avg Loss: 163.2608\n",
            "Epoch [42/50] - Batch loss: 161.3711 - Epoch Loss: 9140.7124 - Avg Loss: 163.2270\n",
            "Epoch [42/50] - Batch loss: 165.2956 - Epoch Loss: 9306.0080 - Avg Loss: 163.2633\n",
            "Epoch [42/50] - Batch loss: 155.3273 - Epoch Loss: 9461.3352 - Avg Loss: 163.1265\n",
            "Epoch [42/50] - Batch loss: 163.4948 - Epoch Loss: 9624.8300 - Avg Loss: 163.1327\n",
            "Epoch [42/50] - Batch loss: 157.2281 - Epoch Loss: 9782.0581 - Avg Loss: 163.0343\n",
            "Epoch [42/50] - Batch loss: 176.1329 - Epoch Loss: 9958.1909 - Avg Loss: 163.2490\n",
            "Epoch [42/50] - Batch loss: 151.4915 - Epoch Loss: 10109.6824 - Avg Loss: 163.0594\n",
            "Epoch [42/50] - Batch loss: 158.5232 - Epoch Loss: 10268.2056 - Avg Loss: 162.9874\n",
            "Epoch [42/50] - Batch loss: 160.9713 - Epoch Loss: 10429.1769 - Avg Loss: 162.9559\n",
            "Epoch [42/50] - Batch loss: 172.8898 - Epoch Loss: 10602.0667 - Avg Loss: 163.1087\n",
            "Epoch [42/50] - Batch loss: 159.2846 - Epoch Loss: 10761.3513 - Avg Loss: 163.0508\n",
            "Epoch [42/50] - Batch loss: 160.2203 - Epoch Loss: 10921.5716 - Avg Loss: 163.0085\n",
            "Epoch [42/50] - Batch loss: 173.9359 - Epoch Loss: 11095.5075 - Avg Loss: 163.1692\n",
            "Epoch [42/50] - Batch loss: 156.8262 - Epoch Loss: 11252.3337 - Avg Loss: 163.0773\n",
            "Epoch [42/50] - Batch loss: 169.6970 - Epoch Loss: 11422.0307 - Avg Loss: 163.1719\n",
            "Epoch [42/50] - Batch loss: 162.2634 - Epoch Loss: 11584.2941 - Avg Loss: 163.1591\n",
            "Epoch [42/50] - Batch loss: 161.8780 - Epoch Loss: 11746.1720 - Avg Loss: 163.1413\n",
            "Epoch [42/50] - Batch loss: 160.0346 - Epoch Loss: 11906.2066 - Avg Loss: 163.0987\n",
            "Epoch [42/50] - Batch loss: 166.3570 - Epoch Loss: 12072.5636 - Avg Loss: 163.1428\n",
            "Epoch [42/50] - Batch loss: 161.6661 - Epoch Loss: 12234.2297 - Avg Loss: 163.1231\n",
            "Epoch [42/50] - Batch loss: 164.9251 - Epoch Loss: 12399.1549 - Avg Loss: 163.1468\n",
            "Epoch [42/50] - Batch loss: 156.7022 - Epoch Loss: 12555.8571 - Avg Loss: 163.0631\n",
            "Epoch [42/50] - Batch loss: 165.5866 - Epoch Loss: 12721.4437 - Avg Loss: 163.0954\n",
            "Epoch [42/50] - Batch loss: 163.1340 - Epoch Loss: 12884.5777 - Avg Loss: 163.0959\n",
            "Epoch [42/50] - Batch loss: 165.7040 - Epoch Loss: 13050.2818 - Avg Loss: 163.1285\n",
            "Epoch [42/50] - Batch loss: 157.4911 - Epoch Loss: 13207.7728 - Avg Loss: 163.0589\n",
            "Epoch [42/50] - Batch loss: 165.9858 - Epoch Loss: 13373.7586 - Avg Loss: 163.0946\n",
            "Epoch [42/50] - Batch loss: 163.7084 - Epoch Loss: 13537.4670 - Avg Loss: 163.1020\n",
            "Epoch [42/50] - Batch loss: 167.9205 - Epoch Loss: 13705.3876 - Avg Loss: 163.1594\n",
            "Epoch [42/50] - Batch loss: 165.4901 - Epoch Loss: 13870.8777 - Avg Loss: 163.1868\n",
            "Epoch [42/50] - Batch loss: 159.6482 - Epoch Loss: 14030.5259 - Avg Loss: 163.1456\n",
            "Epoch [42/50] - Batch loss: 165.9656 - Epoch Loss: 14196.4914 - Avg Loss: 163.1781\n",
            "Epoch [42/50] - Batch loss: 160.9900 - Epoch Loss: 14357.4815 - Avg Loss: 163.1532\n",
            "Epoch [42/50] - Batch loss: 168.1210 - Epoch Loss: 14525.6024 - Avg Loss: 163.2090\n",
            "Epoch [42/50] - Batch loss: 159.4275 - Epoch Loss: 14685.0300 - Avg Loss: 163.1670\n",
            "Epoch [42/50] - Batch loss: 161.4689 - Epoch Loss: 14846.4989 - Avg Loss: 163.1483\n",
            "Epoch [42/50] - Batch loss: 162.9018 - Epoch Loss: 15009.4007 - Avg Loss: 163.1457\n",
            "Epoch [42/50] - Batch loss: 161.2743 - Epoch Loss: 15170.6750 - Avg Loss: 163.1255\n",
            "Epoch [42/50] - Batch loss: 161.1326 - Epoch Loss: 15331.8076 - Avg Loss: 163.1043\n",
            "Epoch [42/50] - Batch loss: 156.3300 - Epoch Loss: 15488.1376 - Avg Loss: 163.0330\n",
            "Epoch [42/50] - Batch loss: 153.9489 - Epoch Loss: 15642.0864 - Avg Loss: 162.9384\n",
            "Epoch [42/50] - Batch loss: 164.2141 - Epoch Loss: 15806.3005 - Avg Loss: 162.9516\n",
            "Epoch [42/50] - Batch loss: 172.7834 - Epoch Loss: 15979.0839 - Avg Loss: 163.0519\n",
            "Epoch [42/50] - Batch loss: 158.2557 - Epoch Loss: 16137.3396 - Avg Loss: 163.0034\n",
            "Epoch [42/50] - Batch loss: 161.3801 - Epoch Loss: 16298.7197 - Avg Loss: 162.9872\n",
            "Epoch [42/50] - Batch loss: 165.7535 - Epoch Loss: 16464.4733 - Avg Loss: 163.0146\n",
            "Epoch [42/50] - Batch loss: 157.5186 - Epoch Loss: 16621.9919 - Avg Loss: 162.9607\n",
            "Epoch [42/50] - Batch loss: 169.7150 - Epoch Loss: 16791.7068 - Avg Loss: 163.0263\n",
            "Epoch [42/50] - Batch loss: 165.9458 - Epoch Loss: 16957.6526 - Avg Loss: 163.0544\n",
            "Epoch [42/50] - Batch loss: 158.6473 - Epoch Loss: 17116.2999 - Avg Loss: 163.0124\n",
            "Epoch [42/50] - Batch loss: 157.2334 - Epoch Loss: 17273.5333 - Avg Loss: 162.9579\n",
            "Epoch [42/50] - Batch loss: 171.2892 - Epoch Loss: 17444.8225 - Avg Loss: 163.0357\n",
            "Epoch [42/50] - Batch loss: 169.8050 - Epoch Loss: 17614.6275 - Avg Loss: 163.0984\n",
            "Epoch [42/50] - Batch loss: 163.6789 - Epoch Loss: 17778.3064 - Avg Loss: 163.1037\n",
            "Epoch [42/50] - Batch loss: 162.1125 - Epoch Loss: 17940.4189 - Avg Loss: 163.0947\n",
            "Epoch [42/50] - Batch loss: 170.6531 - Epoch Loss: 18111.0720 - Avg Loss: 163.1628\n",
            "Epoch [42/50] - Batch loss: 167.1815 - Epoch Loss: 18278.2535 - Avg Loss: 163.1987\n",
            "Epoch [42/50] - Batch loss: 167.8589 - Epoch Loss: 18446.1125 - Avg Loss: 163.2399\n",
            "Epoch [42/50] - Batch loss: 163.3023 - Epoch Loss: 18609.4147 - Avg Loss: 163.2405\n",
            "Epoch [42/50] - Batch loss: 167.3262 - Epoch Loss: 18776.7410 - Avg Loss: 163.2760\n",
            "Epoch [42/50] - Batch loss: 156.7740 - Epoch Loss: 18933.5150 - Avg Loss: 163.2200\n",
            "Epoch [42/50] - Batch loss: 172.2394 - Epoch Loss: 19105.7544 - Avg Loss: 163.2970\n",
            "Epoch [42/50] - Batch loss: 155.5672 - Epoch Loss: 19261.3216 - Avg Loss: 163.2315\n",
            "Epoch [42/50] - Batch loss: 161.8759 - Epoch Loss: 19423.1975 - Avg Loss: 163.2201\n",
            "Epoch [42/50] - Batch loss: 163.8056 - Epoch Loss: 19587.0031 - Avg Loss: 163.2250\n",
            "Epoch [42/50] - Batch loss: 170.0499 - Epoch Loss: 19757.0531 - Avg Loss: 163.2814\n",
            "Epoch [42/50] - Batch loss: 168.2766 - Epoch Loss: 19925.3297 - Avg Loss: 163.3224\n",
            "Epoch [42/50] - Batch loss: 159.5630 - Epoch Loss: 20084.8927 - Avg Loss: 163.2918\n",
            "Epoch [42/50] - Batch loss: 162.4650 - Epoch Loss: 20247.3576 - Avg Loss: 163.2851\n",
            "Epoch [42/50] - Batch loss: 163.6081 - Epoch Loss: 20410.9657 - Avg Loss: 163.2877\n",
            "Epoch [42/50] - Batch loss: 161.5829 - Epoch Loss: 20572.5487 - Avg Loss: 163.2742\n",
            "Epoch [42/50] - Batch loss: 169.3920 - Epoch Loss: 20741.9406 - Avg Loss: 163.3224\n",
            "Epoch [42/50] - Batch loss: 156.8552 - Epoch Loss: 20898.7958 - Avg Loss: 163.2718\n",
            "Epoch [42/50] - Batch loss: 171.9007 - Epoch Loss: 21070.6965 - Avg Loss: 163.3387\n",
            "Epoch [42/50] - Batch loss: 167.7017 - Epoch Loss: 21238.3982 - Avg Loss: 163.3723\n",
            "Epoch [42/50] - Batch loss: 161.7939 - Epoch Loss: 21400.1921 - Avg Loss: 163.3602\n",
            "Epoch [42/50] - Batch loss: 163.1129 - Epoch Loss: 21563.3050 - Avg Loss: 163.3584\n",
            "Epoch [42/50] - Batch loss: 162.3765 - Epoch Loss: 21725.6815 - Avg Loss: 163.3510\n",
            "Epoch [42/50] - Batch loss: 163.4917 - Epoch Loss: 21889.1732 - Avg Loss: 163.3520\n",
            "Epoch [42/50] - Batch loss: 162.0713 - Epoch Loss: 22051.2445 - Avg Loss: 163.3426\n",
            "Epoch [42/50] - Batch loss: 166.0704 - Epoch Loss: 22217.3149 - Avg Loss: 163.3626\n",
            "Epoch [42/50] - Batch loss: 164.1025 - Epoch Loss: 22381.4174 - Avg Loss: 163.3680\n",
            "Epoch [42/50] - Batch loss: 164.7693 - Epoch Loss: 22546.1867 - Avg Loss: 163.3782\n",
            "Epoch [42/50] - Batch loss: 166.8233 - Epoch Loss: 22713.0100 - Avg Loss: 163.4029\n",
            "Epoch [42/50] - Batch loss: 163.2631 - Epoch Loss: 22876.2731 - Avg Loss: 163.4020\n",
            "Epoch [42/50] - Batch loss: 160.3767 - Epoch Loss: 23036.6498 - Avg Loss: 163.3805\n",
            "Epoch [42/50] - Batch loss: 156.2415 - Epoch Loss: 23192.8912 - Avg Loss: 163.3302\n",
            "Epoch [42/50] - Batch loss: 163.5473 - Epoch Loss: 23356.4385 - Avg Loss: 163.3317\n",
            "Epoch [42/50] - Batch loss: 161.0804 - Epoch Loss: 23517.5190 - Avg Loss: 163.3161\n",
            "Epoch [42/50] - Batch loss: 165.0787 - Epoch Loss: 23682.5977 - Avg Loss: 163.3283\n",
            "Epoch [42/50] - Batch loss: 160.2275 - Epoch Loss: 23842.8251 - Avg Loss: 163.3070\n",
            "Epoch [42/50] - Batch loss: 168.3926 - Epoch Loss: 24011.2177 - Avg Loss: 163.3416\n",
            "Epoch [42/50] - Batch loss: 159.4904 - Epoch Loss: 24170.7082 - Avg Loss: 163.3156\n",
            "Epoch [42/50] - Batch loss: 154.9251 - Epoch Loss: 24325.6333 - Avg Loss: 163.2593\n",
            "Epoch [42/50] - Batch loss: 158.0588 - Epoch Loss: 24483.6920 - Avg Loss: 163.2246\n",
            "Epoch [42/50] - Batch loss: 160.0058 - Epoch Loss: 24643.6979 - Avg Loss: 163.2033\n",
            "Epoch [42/50] - Batch loss: 160.3392 - Epoch Loss: 24804.0370 - Avg Loss: 163.1845\n",
            "Epoch [42/50] - Batch loss: 152.9210 - Epoch Loss: 24956.9580 - Avg Loss: 163.1174\n",
            "Epoch [42/50] - Batch loss: 155.3057 - Epoch Loss: 25112.2637 - Avg Loss: 163.0666\n",
            "Epoch [42/50] - Batch loss: 168.2500 - Epoch Loss: 25280.5137 - Avg Loss: 163.1001\n",
            "Epoch [42/50] - Batch loss: 156.9331 - Epoch Loss: 25437.4468 - Avg Loss: 163.0606\n",
            "Epoch [42/50] - Batch loss: 168.1390 - Epoch Loss: 25605.5858 - Avg Loss: 163.0929\n",
            "Epoch [42/50] - Batch loss: 165.8809 - Epoch Loss: 25771.4667 - Avg Loss: 163.1105\n",
            "Epoch [42/50] - Batch loss: 150.0826 - Epoch Loss: 25921.5493 - Avg Loss: 163.0286\n",
            "Epoch [42/50] - Batch loss: 159.9140 - Epoch Loss: 26081.4633 - Avg Loss: 163.0091\n",
            "Epoch [42/50] - Batch loss: 161.0829 - Epoch Loss: 26242.5462 - Avg Loss: 162.9972\n",
            "Epoch [42/50] - Batch loss: 162.5728 - Epoch Loss: 26405.1190 - Avg Loss: 162.9946\n",
            "Epoch [42/50] - Batch loss: 160.5120 - Epoch Loss: 26565.6310 - Avg Loss: 162.9793\n",
            "Epoch [42/50] - Batch loss: 168.0425 - Epoch Loss: 26733.6735 - Avg Loss: 163.0102\n",
            "Epoch [42/50] - Batch loss: 162.4730 - Epoch Loss: 26896.1465 - Avg Loss: 163.0069\n",
            "Epoch [42/50] - Batch loss: 164.8559 - Epoch Loss: 27061.0024 - Avg Loss: 163.0181\n",
            "Epoch [42/50] - Batch loss: 168.1889 - Epoch Loss: 27229.1913 - Avg Loss: 163.0490\n",
            "Epoch [42/50] - Batch loss: 156.4910 - Epoch Loss: 27385.6823 - Avg Loss: 163.0100\n",
            "Epoch [42/50] - Batch loss: 161.8635 - Epoch Loss: 27547.5459 - Avg Loss: 163.0032\n",
            "Epoch [42/50] - Batch loss: 157.7827 - Epoch Loss: 27705.3286 - Avg Loss: 162.9725\n",
            "Epoch [42/50] - Batch loss: 157.2783 - Epoch Loss: 27862.6070 - Avg Loss: 162.9392\n",
            "Epoch [42/50] - Batch loss: 163.0429 - Epoch Loss: 28025.6498 - Avg Loss: 162.9398\n",
            "Epoch [42/50] - Batch loss: 162.9768 - Epoch Loss: 28188.6267 - Avg Loss: 162.9400\n",
            "Epoch [42/50] - Batch loss: 162.6292 - Epoch Loss: 28351.2559 - Avg Loss: 162.9383\n",
            "Epoch [42/50] - Batch loss: 157.8205 - Epoch Loss: 28509.0764 - Avg Loss: 162.9090\n",
            "Epoch [42/50] - Batch loss: 163.5576 - Epoch Loss: 28672.6340 - Avg Loss: 162.9127\n",
            "Epoch [42/50] - Batch loss: 164.4373 - Epoch Loss: 28837.0714 - Avg Loss: 162.9213\n",
            "Epoch [42/50] - Batch loss: 164.5554 - Epoch Loss: 29001.6268 - Avg Loss: 162.9305\n",
            "Epoch [42/50] - Batch loss: 158.6636 - Epoch Loss: 29160.2904 - Avg Loss: 162.9067\n",
            "Epoch [42/50] - Batch loss: 162.1697 - Epoch Loss: 29322.4602 - Avg Loss: 162.9026\n",
            "Epoch [42/50] - Batch loss: 154.0282 - Epoch Loss: 29476.4884 - Avg Loss: 162.8535\n",
            "Epoch [42/50] - Batch loss: 159.5482 - Epoch Loss: 29636.0366 - Avg Loss: 162.8354\n",
            "Epoch [42/50] - Batch loss: 152.4486 - Epoch Loss: 29788.4852 - Avg Loss: 162.7786\n",
            "Epoch [42/50] - Batch loss: 159.1166 - Epoch Loss: 29947.6018 - Avg Loss: 162.7587\n",
            "Epoch [42/50] - Batch loss: 162.8380 - Epoch Loss: 30110.4398 - Avg Loss: 162.7591\n",
            "Epoch [42/50] - Batch loss: 162.7090 - Epoch Loss: 30273.1488 - Avg Loss: 162.7589\n",
            "Epoch [42/50] - Batch loss: 158.6212 - Epoch Loss: 30431.7700 - Avg Loss: 162.7367\n",
            "Epoch [42/50] - Batch loss: 161.3039 - Epoch Loss: 30593.0739 - Avg Loss: 162.7291\n",
            "Epoch [42/50] - Batch loss: 165.2670 - Epoch Loss: 30758.3409 - Avg Loss: 162.7425\n",
            "Epoch [42/50] - Batch loss: 171.8071 - Epoch Loss: 30930.1480 - Avg Loss: 162.7903\n",
            "Epoch [42/50] - Batch loss: 158.6787 - Epoch Loss: 31088.8267 - Avg Loss: 162.7687\n",
            "Epoch [42/50] - Batch loss: 153.0515 - Epoch Loss: 31241.8782 - Avg Loss: 162.7181\n",
            "Epoch [42/50] - Batch loss: 153.3311 - Epoch Loss: 31395.2093 - Avg Loss: 162.6695\n",
            "Epoch [42/50] - Batch loss: 160.3771 - Epoch Loss: 31555.5864 - Avg Loss: 162.6577\n",
            "Epoch [42/50] - Batch loss: 163.2083 - Epoch Loss: 31718.7947 - Avg Loss: 162.6605\n",
            "Epoch [42/50] - Batch loss: 158.9979 - Epoch Loss: 31877.7927 - Avg Loss: 162.6418\n",
            "Epoch [42/50] - Batch loss: 156.0320 - Epoch Loss: 32033.8246 - Avg Loss: 162.6082\n",
            "Epoch [42/50] - Batch loss: 162.5002 - Epoch Loss: 32196.3248 - Avg Loss: 162.6077\n",
            "Epoch [42/50] - Batch loss: 153.2542 - Epoch Loss: 32349.5790 - Avg Loss: 162.5607\n",
            "Epoch [42/50] - Batch loss: 158.6697 - Epoch Loss: 32508.2487 - Avg Loss: 162.5412\n",
            "Epoch [42/50] - Batch loss: 160.1243 - Epoch Loss: 32668.3730 - Avg Loss: 162.5292\n",
            "Epoch [42/50] - Batch loss: 157.5406 - Epoch Loss: 32825.9136 - Avg Loss: 162.5045\n",
            "Epoch [42/50] - Batch loss: 149.1609 - Epoch Loss: 32975.0744 - Avg Loss: 162.4388\n",
            "Epoch [42/50] - Batch loss: 161.0918 - Epoch Loss: 33136.1663 - Avg Loss: 162.4322\n",
            "Epoch [42/50] - Batch loss: 154.5365 - Epoch Loss: 33290.7028 - Avg Loss: 162.3937\n",
            "Epoch [42/50] - Batch loss: 167.3622 - Epoch Loss: 33458.0650 - Avg Loss: 162.4178\n",
            "Epoch [42/50] - Batch loss: 166.9448 - Epoch Loss: 33625.0098 - Avg Loss: 162.4397\n",
            "Epoch [42/50] - Batch loss: 161.1986 - Epoch Loss: 33786.2084 - Avg Loss: 162.4337\n",
            "Epoch [42/50] - Batch loss: 159.7115 - Epoch Loss: 33945.9199 - Avg Loss: 162.4207\n",
            "Epoch [42/50] - Batch loss: 163.8056 - Epoch Loss: 34109.7255 - Avg Loss: 162.4273\n",
            "Epoch [42/50] - Batch loss: 150.3895 - Epoch Loss: 34260.1149 - Avg Loss: 162.3702\n",
            "Epoch [42/50] - Batch loss: 156.9986 - Epoch Loss: 34417.1136 - Avg Loss: 162.3449\n",
            "Epoch [42/50] - Batch loss: 161.8813 - Epoch Loss: 34578.9949 - Avg Loss: 162.3427\n",
            "Epoch [42/50] - Batch loss: 159.7737 - Epoch Loss: 34738.7686 - Avg Loss: 162.3307\n",
            "Epoch [42/50] - Batch loss: 162.8831 - Epoch Loss: 34901.6517 - Avg Loss: 162.3333\n",
            "Epoch [42/50] - Batch loss: 165.3644 - Epoch Loss: 35067.0161 - Avg Loss: 162.3473\n",
            "Epoch [42/50] - Batch loss: 163.5196 - Epoch Loss: 35230.5357 - Avg Loss: 162.3527\n",
            "Epoch [42/50] - Batch loss: 163.8231 - Epoch Loss: 35394.3588 - Avg Loss: 162.3594\n",
            "Epoch [42/50] - Batch loss: 151.0293 - Epoch Loss: 35545.3881 - Avg Loss: 162.3077\n",
            "Epoch [42/50] - Batch loss: 148.6793 - Epoch Loss: 35694.0674 - Avg Loss: 162.2458\n",
            "Epoch [42/50] - Batch loss: 161.1972 - Epoch Loss: 35855.2646 - Avg Loss: 162.2410\n",
            "Epoch [42/50] - Batch loss: 165.3523 - Epoch Loss: 36020.6169 - Avg Loss: 162.2550\n",
            "Epoch [42/50] - Batch loss: 159.5544 - Epoch Loss: 36180.1713 - Avg Loss: 162.2429\n",
            "Epoch [42/50] - Batch loss: 162.9233 - Epoch Loss: 36343.0945 - Avg Loss: 162.2460\n",
            "Epoch [42/50] - Batch loss: 163.3393 - Epoch Loss: 36506.4339 - Avg Loss: 162.2508\n",
            "Epoch [42/50] - Batch loss: 151.9976 - Epoch Loss: 36658.4315 - Avg Loss: 162.2054\n",
            "Epoch [42/50] - Batch loss: 164.7023 - Epoch Loss: 36823.1338 - Avg Loss: 162.2164\n",
            "Epoch [42/50] - Batch loss: 160.9107 - Epoch Loss: 36984.0445 - Avg Loss: 162.2107\n",
            "Epoch [42/50] - Batch loss: 161.4789 - Epoch Loss: 37145.5234 - Avg Loss: 162.2075\n",
            "Epoch [42/50] - Batch loss: 168.8549 - Epoch Loss: 37314.3783 - Avg Loss: 162.2364\n",
            "Epoch [42/50] - Batch loss: 162.0271 - Epoch Loss: 37476.4054 - Avg Loss: 162.2355\n",
            "Epoch [42/50] - Batch loss: 152.5115 - Epoch Loss: 37628.9168 - Avg Loss: 162.1936\n",
            "Epoch [42/50] - Batch loss: 161.3095 - Epoch Loss: 37790.2263 - Avg Loss: 162.1898\n",
            "Epoch [42/50] - Batch loss: 162.4915 - Epoch Loss: 37952.7178 - Avg Loss: 162.1911\n",
            "Epoch [42/50] - Batch loss: 161.5046 - Epoch Loss: 38114.2224 - Avg Loss: 162.1882\n",
            "Epoch [42/50] - Batch loss: 155.0813 - Epoch Loss: 38269.3037 - Avg Loss: 162.1581\n",
            "Epoch [42/50] - Batch loss: 158.1889 - Epoch Loss: 38427.4927 - Avg Loss: 162.1413\n",
            "Epoch [42/50] - Batch loss: 154.6694 - Epoch Loss: 38582.1621 - Avg Loss: 162.1099\n",
            "Epoch [42/50] - Batch loss: 159.3524 - Epoch Loss: 38741.5145 - Avg Loss: 162.0984\n",
            "Epoch [42/50] - Batch loss: 159.4456 - Epoch Loss: 38900.9601 - Avg Loss: 162.0873\n",
            "Epoch [42/50] - Batch loss: 158.5530 - Epoch Loss: 39059.5132 - Avg Loss: 162.0727\n",
            "Epoch [42/50] - Batch loss: 156.9112 - Epoch Loss: 39216.4243 - Avg Loss: 162.0513\n",
            "Epoch [42/50] - Batch loss: 169.3238 - Epoch Loss: 39385.7482 - Avg Loss: 162.0813\n",
            "Epoch [42/50] - Batch loss: 158.2501 - Epoch Loss: 39543.9983 - Avg Loss: 162.0656\n",
            "Epoch [42/50] - Batch loss: 162.5643 - Epoch Loss: 39706.5627 - Avg Loss: 162.0676\n",
            "Epoch [42/50] - Batch loss: 164.5680 - Epoch Loss: 39871.1307 - Avg Loss: 162.0778\n",
            "Epoch [42/50] - Batch loss: 158.7176 - Epoch Loss: 40029.8483 - Avg Loss: 162.0642\n",
            "Epoch [42/50] - Batch loss: 163.0895 - Epoch Loss: 40192.9378 - Avg Loss: 162.0683\n",
            "Epoch [42/50] - Batch loss: 164.6174 - Epoch Loss: 40357.5552 - Avg Loss: 162.0785\n",
            "Epoch [42/50] - Batch loss: 160.8467 - Epoch Loss: 40518.4019 - Avg Loss: 162.0736\n",
            "Epoch [42/50] - Batch loss: 163.6751 - Epoch Loss: 40682.0770 - Avg Loss: 162.0800\n",
            "Epoch [42/50] - Batch loss: 156.4308 - Epoch Loss: 40838.5078 - Avg Loss: 162.0576\n",
            "Epoch [42/50] - Batch loss: 159.5195 - Epoch Loss: 40998.0273 - Avg Loss: 162.0475\n",
            "Epoch [42/50] - Batch loss: 160.3087 - Epoch Loss: 41158.3360 - Avg Loss: 162.0407\n",
            "Epoch [42/50] - Batch loss: 152.2621 - Epoch Loss: 41310.5981 - Avg Loss: 162.0023\n",
            "Epoch [42/50] - Batch loss: 158.9382 - Epoch Loss: 41469.5363 - Avg Loss: 161.9904\n",
            "Epoch [42/50] - Batch loss: 162.7292 - Epoch Loss: 41632.2655 - Avg Loss: 161.9933\n",
            "Epoch [42/50] - Batch loss: 157.6718 - Epoch Loss: 41789.9373 - Avg Loss: 161.9765\n",
            "Epoch [42/50] - Batch loss: 156.1759 - Epoch Loss: 41946.1132 - Avg Loss: 161.9541\n",
            "Epoch [42/50] - Batch loss: 155.5698 - Epoch Loss: 42101.6830 - Avg Loss: 161.9295\n",
            "Epoch [42/50] - Batch loss: 164.9332 - Epoch Loss: 42266.6162 - Avg Loss: 161.9411\n",
            "Epoch [42/50] - Batch loss: 158.3317 - Epoch Loss: 42424.9478 - Avg Loss: 161.9273\n",
            "Epoch [42/50] - Batch loss: 161.5412 - Epoch Loss: 42586.4890 - Avg Loss: 161.9258\n",
            "Epoch [42/50] - Batch loss: 160.9195 - Epoch Loss: 42747.4085 - Avg Loss: 161.9220\n",
            "Epoch [42/50] - Batch loss: 157.5916 - Epoch Loss: 42905.0001 - Avg Loss: 161.9057\n",
            "Epoch [42/50] - Batch loss: 161.9787 - Epoch Loss: 43066.9788 - Avg Loss: 161.9059\n",
            "Epoch [42/50] - Batch loss: 165.1343 - Epoch Loss: 43232.1131 - Avg Loss: 161.9180\n",
            "Epoch [42/50] - Batch loss: 154.6401 - Epoch Loss: 43386.7532 - Avg Loss: 161.8909\n",
            "Epoch [42/50] - Batch loss: 161.8374 - Epoch Loss: 43548.5906 - Avg Loss: 161.8907\n",
            "Epoch [42/50] - Batch loss: 155.5116 - Epoch Loss: 43704.1021 - Avg Loss: 161.8670\n",
            "Epoch [42/50] - Batch loss: 165.7517 - Epoch Loss: 43869.8539 - Avg Loss: 161.8814\n",
            "Epoch [42/50] - Batch loss: 166.6551 - Epoch Loss: 44036.5090 - Avg Loss: 161.8989\n",
            "Epoch [42/50] - Batch loss: 169.2677 - Epoch Loss: 44205.7767 - Avg Loss: 161.9259\n",
            "Epoch [42/50] - Batch loss: 157.2050 - Epoch Loss: 44362.9817 - Avg Loss: 161.9087\n",
            "Epoch [42/50] - Batch loss: 155.8585 - Epoch Loss: 44518.8403 - Avg Loss: 161.8867\n",
            "Epoch [42/50] - Batch loss: 167.1474 - Epoch Loss: 44685.9877 - Avg Loss: 161.9058\n",
            "Epoch [42/50] - Batch loss: 148.8611 - Epoch Loss: 44834.8487 - Avg Loss: 161.8587\n",
            "Epoch [42/50] - Batch loss: 166.2010 - Epoch Loss: 45001.0497 - Avg Loss: 161.8743\n",
            "Epoch [42/50] - Batch loss: 164.4541 - Epoch Loss: 45165.5038 - Avg Loss: 161.8835\n",
            "Epoch [42/50] - Batch loss: 163.6267 - Epoch Loss: 45329.1305 - Avg Loss: 161.8898\n",
            "Epoch [42/50] - Batch loss: 160.5836 - Epoch Loss: 45489.7141 - Avg Loss: 161.8851\n",
            "Epoch [42/50] - Batch loss: 159.9561 - Epoch Loss: 45649.6703 - Avg Loss: 161.8783\n",
            "Epoch [42/50] - Batch loss: 162.9571 - Epoch Loss: 45812.6273 - Avg Loss: 161.8821\n",
            "Epoch [42/50] - Batch loss: 152.2813 - Epoch Loss: 45964.9086 - Avg Loss: 161.8483\n",
            "Epoch [42/50] - Batch loss: 161.1070 - Epoch Loss: 46126.0157 - Avg Loss: 161.8457\n",
            "Epoch [42/50] - Batch loss: 160.1658 - Epoch Loss: 46286.1814 - Avg Loss: 161.8398\n",
            "Epoch [42/50] - Batch loss: 149.8953 - Epoch Loss: 46436.0767 - Avg Loss: 161.7982\n",
            "Epoch [42/50] - Batch loss: 158.6113 - Epoch Loss: 46594.6880 - Avg Loss: 161.7871\n",
            "Epoch [42/50] - Batch loss: 163.6311 - Epoch Loss: 46758.3192 - Avg Loss: 161.7935\n",
            "Epoch [42/50] - Batch loss: 162.5479 - Epoch Loss: 46920.8671 - Avg Loss: 161.7961\n",
            "Epoch [42/50] - Batch loss: 151.7575 - Epoch Loss: 47072.6246 - Avg Loss: 161.7616\n",
            "Epoch [42/50] - Batch loss: 163.0085 - Epoch Loss: 47235.6331 - Avg Loss: 161.7659\n",
            "Epoch [42/50] - Batch loss: 154.5727 - Epoch Loss: 47390.2058 - Avg Loss: 161.7413\n",
            "Epoch [42/50] - Batch loss: 162.0045 - Epoch Loss: 47552.2102 - Avg Loss: 161.7422\n",
            "Epoch [42/50] - Batch loss: 159.5195 - Epoch Loss: 47711.7297 - Avg Loss: 161.7347\n",
            "Epoch [42/50] - Batch loss: 162.9154 - Epoch Loss: 47874.6451 - Avg Loss: 161.7387\n",
            "Epoch [42/50] - Batch loss: 159.4420 - Epoch Loss: 48034.0872 - Avg Loss: 161.7309\n",
            "Epoch [42/50] - Batch loss: 164.1003 - Epoch Loss: 48198.1875 - Avg Loss: 161.7389\n",
            "Epoch [42/50] - Batch loss: 161.8565 - Epoch Loss: 48360.0440 - Avg Loss: 161.7393\n",
            "Epoch [42/50] - Batch loss: 161.9109 - Epoch Loss: 48521.9549 - Avg Loss: 161.7398\n",
            "Epoch [42/50] - Batch loss: 162.5300 - Epoch Loss: 48684.4848 - Avg Loss: 161.7425\n",
            "Epoch [42/50] - Batch loss: 149.0795 - Epoch Loss: 48833.5643 - Avg Loss: 161.7005\n",
            "Epoch [42/50] - Batch loss: 159.9317 - Epoch Loss: 48993.4960 - Avg Loss: 161.6947\n",
            "Epoch [42/50] - Batch loss: 158.9347 - Epoch Loss: 49152.4307 - Avg Loss: 161.6856\n",
            "Epoch [42/50] - Batch loss: 159.7833 - Epoch Loss: 49312.2139 - Avg Loss: 161.6794\n",
            "Epoch [42/50] - Batch loss: 158.6797 - Epoch Loss: 49470.8937 - Avg Loss: 161.6696\n",
            "Epoch [42/50] - Batch loss: 162.6211 - Epoch Loss: 49633.5148 - Avg Loss: 161.6727\n",
            "Epoch [42/50] - Batch loss: 165.0190 - Epoch Loss: 49798.5338 - Avg Loss: 161.6836\n",
            "Epoch [42/50] - Batch loss: 159.3267 - Epoch Loss: 49957.8604 - Avg Loss: 161.6759\n",
            "Epoch [42/50] - Batch loss: 156.8197 - Epoch Loss: 50114.6801 - Avg Loss: 161.6603\n",
            "Epoch [42/50] - Batch loss: 162.6178 - Epoch Loss: 50277.2979 - Avg Loss: 161.6633\n",
            "Epoch [42/50] - Batch loss: 168.8410 - Epoch Loss: 50446.1389 - Avg Loss: 161.6863\n",
            "Epoch [42/50] - Batch loss: 165.6321 - Epoch Loss: 50611.7709 - Avg Loss: 161.6989\n",
            "Epoch [42/50] - Batch loss: 162.3382 - Epoch Loss: 50774.1091 - Avg Loss: 161.7010\n",
            "Epoch [42/50] - Batch loss: 161.2276 - Epoch Loss: 50935.3367 - Avg Loss: 161.6995\n",
            "Epoch [42/50] - Batch loss: 160.5918 - Epoch Loss: 51095.9285 - Avg Loss: 161.6960\n",
            "Epoch [42/50] - Batch loss: 166.8368 - Epoch Loss: 51262.7654 - Avg Loss: 161.7122\n",
            "Epoch [42/50] - Batch loss: 161.2519 - Epoch Loss: 51424.0172 - Avg Loss: 161.7107\n",
            "Epoch [42/50] - Batch loss: 160.8515 - Epoch Loss: 51584.8687 - Avg Loss: 161.7081\n",
            "Epoch [42/50] - Batch loss: 164.3313 - Epoch Loss: 51749.2000 - Avg Loss: 161.7163\n",
            "Epoch [42/50] - Batch loss: 160.9971 - Epoch Loss: 51910.1972 - Avg Loss: 161.7140\n",
            "Epoch [42/50] - Batch loss: 163.3318 - Epoch Loss: 52073.5289 - Avg Loss: 161.7190\n",
            "Epoch [42/50] - Batch loss: 159.6429 - Epoch Loss: 52233.1718 - Avg Loss: 161.7126\n",
            "Epoch [42/50] - Batch loss: 168.4633 - Epoch Loss: 52401.6352 - Avg Loss: 161.7334\n",
            "Epoch [42/50] - Batch loss: 159.9533 - Epoch Loss: 52561.5884 - Avg Loss: 161.7280\n",
            "Epoch [42/50] - Batch loss: 158.5002 - Epoch Loss: 52720.0887 - Avg Loss: 161.7181\n",
            "Epoch [42/50] - Batch loss: 157.1395 - Epoch Loss: 52877.2282 - Avg Loss: 161.7041\n",
            "Epoch [42/50] - Batch loss: 157.4332 - Epoch Loss: 53034.6613 - Avg Loss: 161.6910\n",
            "Epoch [42/50] - Batch loss: 162.9299 - Epoch Loss: 53197.5912 - Avg Loss: 161.6948\n",
            "Epoch [42/50] - Batch loss: 162.3696 - Epoch Loss: 53359.9608 - Avg Loss: 161.6969\n",
            "Epoch [42/50] - Batch loss: 164.4251 - Epoch Loss: 53524.3858 - Avg Loss: 161.7051\n",
            "Epoch [42/50] - Batch loss: 150.3493 - Epoch Loss: 53674.7352 - Avg Loss: 161.6709\n",
            "Epoch [42/50] - Batch loss: 164.2868 - Epoch Loss: 53839.0220 - Avg Loss: 161.6787\n",
            "Epoch [42/50] - Batch loss: 158.7110 - Epoch Loss: 53997.7330 - Avg Loss: 161.6699\n",
            "Epoch [42/50] - Batch loss: 157.8076 - Epoch Loss: 54155.5406 - Avg Loss: 161.6583\n",
            "Epoch [42/50] - Batch loss: 158.6596 - Epoch Loss: 54314.2002 - Avg Loss: 161.6494\n",
            "Epoch [42/50] - Batch loss: 156.8911 - Epoch Loss: 54471.0913 - Avg Loss: 161.6353\n",
            "Epoch [42/50] - Batch loss: 165.8142 - Epoch Loss: 54636.9055 - Avg Loss: 161.6476\n",
            "Epoch [42/50] - Batch loss: 169.3111 - Epoch Loss: 54806.2166 - Avg Loss: 161.6703\n",
            "Epoch [42/50] - Batch loss: 155.9547 - Epoch Loss: 54962.1713 - Avg Loss: 161.6534\n",
            "Epoch [42/50] - Batch loss: 158.6443 - Epoch Loss: 55120.8156 - Avg Loss: 161.6446\n",
            "Epoch [42/50] - Batch loss: 155.7835 - Epoch Loss: 55276.5992 - Avg Loss: 161.6275\n",
            "Epoch [42/50] - Batch loss: 163.3738 - Epoch Loss: 55439.9730 - Avg Loss: 161.6326\n",
            "Epoch [42/50] - Batch loss: 172.6335 - Epoch Loss: 55612.6066 - Avg Loss: 161.6646\n",
            "Epoch [42/50] - Batch loss: 158.2964 - Epoch Loss: 55770.9029 - Avg Loss: 161.6548\n",
            "Epoch [42/50] - Batch loss: 158.5864 - Epoch Loss: 55929.4893 - Avg Loss: 161.6459\n",
            "Epoch [42/50] - Batch loss: 155.5428 - Epoch Loss: 56085.0321 - Avg Loss: 161.6283\n",
            "Epoch [42/50] - Batch loss: 154.6905 - Epoch Loss: 56239.7226 - Avg Loss: 161.6084\n",
            "Epoch [42/50] - Batch loss: 156.7784 - Epoch Loss: 56396.5010 - Avg Loss: 161.5946\n",
            "Epoch [42/50] - Batch loss: 161.4881 - Epoch Loss: 56557.9891 - Avg Loss: 161.5943\n",
            "Epoch [42/50] - Batch loss: 166.8285 - Epoch Loss: 56724.8176 - Avg Loss: 161.6092\n",
            "Epoch [42/50] - Batch loss: 152.9393 - Epoch Loss: 56877.7570 - Avg Loss: 161.5845\n",
            "Epoch [42/50] - Batch loss: 164.1412 - Epoch Loss: 57041.8982 - Avg Loss: 161.5918\n",
            "Epoch [42/50] - Batch loss: 150.5526 - Epoch Loss: 57192.4508 - Avg Loss: 161.5606\n",
            "Epoch [42/50] - Batch loss: 162.0613 - Epoch Loss: 57354.5121 - Avg Loss: 161.5620\n",
            "Epoch [42/50] - Batch loss: 159.2875 - Epoch Loss: 57513.7996 - Avg Loss: 161.5556\n",
            "Epoch [42/50] - Batch loss: 164.2505 - Epoch Loss: 57678.0500 - Avg Loss: 161.5632\n",
            "Epoch [42/50] - Batch loss: 174.5609 - Epoch Loss: 57852.6110 - Avg Loss: 161.5995\n",
            "Epoch [42/50] - Batch loss: 150.4544 - Epoch Loss: 58003.0654 - Avg Loss: 161.5684\n",
            "Epoch [42/50] - Batch loss: 162.4718 - Epoch Loss: 58165.5372 - Avg Loss: 161.5709\n",
            "Epoch [42/50] - Batch loss: 158.9216 - Epoch Loss: 58324.4588 - Avg Loss: 161.5636\n",
            "Epoch [42/50] - Batch loss: 164.6069 - Epoch Loss: 58489.0657 - Avg Loss: 161.5720\n",
            "Epoch [42/50] - Batch loss: 164.0219 - Epoch Loss: 58653.0876 - Avg Loss: 161.5788\n",
            "Epoch [42/50] - Batch loss: 159.2125 - Epoch Loss: 58812.3001 - Avg Loss: 161.5723\n",
            "Epoch [42/50] - Batch loss: 158.7476 - Epoch Loss: 58971.0477 - Avg Loss: 161.5645\n",
            "Epoch [42/50] - Batch loss: 157.7833 - Epoch Loss: 59128.8310 - Avg Loss: 161.5542\n",
            "Epoch [42/50] - Batch loss: 162.2870 - Epoch Loss: 59291.1181 - Avg Loss: 161.5562\n",
            "Epoch [42/50] - Batch loss: 164.0531 - Epoch Loss: 59455.1712 - Avg Loss: 161.5630\n",
            "Epoch [42/50] - Batch loss: 164.6169 - Epoch Loss: 59619.7881 - Avg Loss: 161.5712\n",
            "Epoch [42/50] - Batch loss: 152.6385 - Epoch Loss: 59772.4266 - Avg Loss: 161.5471\n",
            "Epoch [42/50] - Batch loss: 161.9003 - Epoch Loss: 59934.3269 - Avg Loss: 161.5481\n",
            "Epoch [42/50] - Batch loss: 163.3002 - Epoch Loss: 60097.6271 - Avg Loss: 161.5528\n",
            "Epoch [42/50] - Batch loss: 160.1156 - Epoch Loss: 60257.7427 - Avg Loss: 161.5489\n",
            "Epoch [42/50] - Batch loss: 164.8532 - Epoch Loss: 60422.5958 - Avg Loss: 161.5577\n",
            "Epoch [42/50] - Batch loss: 160.5740 - Epoch Loss: 60583.1698 - Avg Loss: 161.5551\n",
            "Epoch [42/50] - Batch loss: 151.3489 - Epoch Loss: 60734.5188 - Avg Loss: 161.5280\n",
            "Epoch [42/50] - Batch loss: 162.4264 - Epoch Loss: 60896.9451 - Avg Loss: 161.5304\n",
            "Epoch [42/50] - Batch loss: 162.3598 - Epoch Loss: 61059.3049 - Avg Loss: 161.5326\n",
            "Epoch [42/50] - Batch loss: 163.3030 - Epoch Loss: 61222.6079 - Avg Loss: 161.5372\n",
            "Epoch [42/50] - Batch loss: 164.1186 - Epoch Loss: 61386.7265 - Avg Loss: 161.5440\n",
            "Epoch [42/50] - Batch loss: 162.3612 - Epoch Loss: 61549.0877 - Avg Loss: 161.5462\n",
            "Epoch [42/50] - Batch loss: 161.5335 - Epoch Loss: 61710.6213 - Avg Loss: 161.5461\n",
            "Epoch [42/50] - Batch loss: 159.8769 - Epoch Loss: 61870.4982 - Avg Loss: 161.5418\n",
            "Epoch [42/50] - Batch loss: 159.4913 - Epoch Loss: 62029.9895 - Avg Loss: 161.5364\n",
            "Epoch [42/50] - Batch loss: 158.8707 - Epoch Loss: 62188.8601 - Avg Loss: 161.5295\n",
            "Epoch [42/50] - Batch loss: 157.7119 - Epoch Loss: 62346.5721 - Avg Loss: 161.5196\n",
            "Epoch [42/50] - Batch loss: 164.6686 - Epoch Loss: 62511.2407 - Avg Loss: 161.5278\n",
            "Epoch [42/50] - Batch loss: 152.9540 - Epoch Loss: 62664.1947 - Avg Loss: 161.5057\n",
            "Epoch [42/50] - Batch loss: 163.2468 - Epoch Loss: 62827.4415 - Avg Loss: 161.5101\n",
            "Epoch [42/50] - Batch loss: 165.8971 - Epoch Loss: 62993.3386 - Avg Loss: 161.5214\n",
            "Epoch [42/50] - Batch loss: 156.7882 - Epoch Loss: 63150.1268 - Avg Loss: 161.5093\n",
            "Epoch [42/50] - Batch loss: 159.1452 - Epoch Loss: 63309.2720 - Avg Loss: 161.5032\n",
            "Epoch [42/50] - Batch loss: 159.0487 - Epoch Loss: 63468.3207 - Avg Loss: 161.4970\n",
            "Epoch [42/50] - Batch loss: 162.4297 - Epoch Loss: 63630.7504 - Avg Loss: 161.4994\n",
            "Epoch [42/50] - Batch loss: 167.4979 - Epoch Loss: 63798.2482 - Avg Loss: 161.5146\n",
            "Epoch [42/50] - Batch loss: 157.4115 - Epoch Loss: 63955.6597 - Avg Loss: 161.5042\n",
            "Epoch [42/50] - Batch loss: 162.3238 - Epoch Loss: 64117.9835 - Avg Loss: 161.5063\n",
            "Epoch [42/50] - Batch loss: 155.2861 - Epoch Loss: 64273.2696 - Avg Loss: 161.4906\n",
            "Epoch [42/50] - Batch loss: 156.5537 - Epoch Loss: 64429.8233 - Avg Loss: 161.4783\n",
            "Epoch [42/50] - Batch loss: 162.8278 - Epoch Loss: 64592.6511 - Avg Loss: 161.4816\n",
            "Epoch [42/50] - Batch loss: 153.9156 - Epoch Loss: 64746.5667 - Avg Loss: 161.4628\n",
            "Epoch [42/50] - Batch loss: 149.0089 - Epoch Loss: 64895.5756 - Avg Loss: 161.4318\n",
            "Epoch [42/50] - Batch loss: 165.0893 - Epoch Loss: 65060.6649 - Avg Loss: 161.4409\n",
            "Epoch [42/50] - Batch loss: 158.7010 - Epoch Loss: 65219.3660 - Avg Loss: 161.4341\n",
            "Epoch [42/50] - Batch loss: 160.0103 - Epoch Loss: 65379.3763 - Avg Loss: 161.4306\n",
            "Epoch [42/50] - Batch loss: 167.9874 - Epoch Loss: 65547.3637 - Avg Loss: 161.4467\n",
            "Epoch [42/50] - Batch loss: 158.9882 - Epoch Loss: 65706.3519 - Avg Loss: 161.4407\n",
            "Epoch [42/50] - Batch loss: 148.4796 - Epoch Loss: 65854.8315 - Avg Loss: 161.4089\n",
            "Epoch [42/50] - Batch loss: 163.0979 - Epoch Loss: 66017.9294 - Avg Loss: 161.4130\n",
            "Epoch [42/50] - Batch loss: 166.1994 - Epoch Loss: 66184.1288 - Avg Loss: 161.4247\n",
            "Epoch [42/50] - Batch loss: 157.6716 - Epoch Loss: 66341.8004 - Avg Loss: 161.4156\n",
            "Epoch [42/50] - Batch loss: 154.0740 - Epoch Loss: 66495.8743 - Avg Loss: 161.3978\n",
            "Epoch [42/50] - Batch loss: 156.3455 - Epoch Loss: 66652.2198 - Avg Loss: 161.3855\n",
            "Epoch [42/50] - Batch loss: 167.0617 - Epoch Loss: 66819.2815 - Avg Loss: 161.3992\n",
            "Epoch [42/50] - Batch loss: 171.5628 - Epoch Loss: 66990.8444 - Avg Loss: 161.4237\n",
            "Epoch [42/50] - Batch loss: 164.1147 - Epoch Loss: 67154.9590 - Avg Loss: 161.4302\n",
            "Epoch [42/50] - Batch loss: 167.9180 - Epoch Loss: 67322.8771 - Avg Loss: 161.4457\n",
            "Epoch [42/50] - Batch loss: 165.8433 - Epoch Loss: 67488.7204 - Avg Loss: 161.4563\n",
            "Epoch [42/50] - Batch loss: 161.9120 - Epoch Loss: 67650.6324 - Avg Loss: 161.4574\n",
            "Epoch [42/50] - Batch loss: 162.6902 - Epoch Loss: 67813.3227 - Avg Loss: 161.4603\n",
            "Epoch [42/50] - Batch loss: 165.9908 - Epoch Loss: 67979.3135 - Avg Loss: 161.4711\n",
            "Epoch [42/50] - Batch loss: 163.7934 - Epoch Loss: 68143.1069 - Avg Loss: 161.4766\n",
            "Epoch [42/50] - Batch loss: 157.9115 - Epoch Loss: 68301.0184 - Avg Loss: 161.4681\n",
            "Epoch [42/50] - Batch loss: 158.8598 - Epoch Loss: 68459.8782 - Avg Loss: 161.4620\n",
            "Epoch [42/50] - Batch loss: 165.6090 - Epoch Loss: 68625.4872 - Avg Loss: 161.4717\n",
            "Epoch [42/50] - Batch loss: 158.3176 - Epoch Loss: 68783.8048 - Avg Loss: 161.4643\n",
            "Epoch [42/50] - Batch loss: 150.7776 - Epoch Loss: 68934.5824 - Avg Loss: 161.4393\n",
            "Epoch [42/50] - Batch loss: 155.0473 - Epoch Loss: 69089.6298 - Avg Loss: 161.4244\n",
            "Epoch [42/50] - Batch loss: 161.3270 - Epoch Loss: 69250.9568 - Avg Loss: 161.4241\n",
            "Epoch [42/50] - Batch loss: 176.4245 - Epoch Loss: 69427.3813 - Avg Loss: 161.4590\n",
            "Epoch [42/50] - Batch loss: 161.5038 - Epoch Loss: 69588.8851 - Avg Loss: 161.4591\n",
            "Epoch [42/50] - Batch loss: 159.4615 - Epoch Loss: 69748.3466 - Avg Loss: 161.4545\n",
            "Epoch [42/50] - Batch loss: 159.6196 - Epoch Loss: 69907.9662 - Avg Loss: 161.4503\n",
            "Epoch [42/50] - Batch loss: 163.1516 - Epoch Loss: 70071.1178 - Avg Loss: 161.4542\n",
            "Epoch [42/50] - Batch loss: 168.3095 - Epoch Loss: 70239.4273 - Avg Loss: 161.4699\n",
            "Epoch [42/50] - Batch loss: 160.6848 - Epoch Loss: 70400.1121 - Avg Loss: 161.4681\n",
            "Epoch [42/50] - Batch loss: 158.0202 - Epoch Loss: 70558.1323 - Avg Loss: 161.4603\n",
            "Epoch [42/50] - Batch loss: 172.3238 - Epoch Loss: 70730.4561 - Avg Loss: 161.4851\n",
            "Epoch [42/50] - Batch loss: 161.0921 - Epoch Loss: 70891.5481 - Avg Loss: 161.4842\n",
            "Epoch [42/50] - Batch loss: 156.8591 - Epoch Loss: 71048.4073 - Avg Loss: 161.4737\n",
            "Epoch [42/50] - Batch loss: 147.6265 - Epoch Loss: 71196.0337 - Avg Loss: 161.4423\n",
            "Epoch [42/50] - Batch loss: 157.6208 - Epoch Loss: 71353.6546 - Avg Loss: 161.4336\n",
            "Epoch [42/50] - Batch loss: 167.1074 - Epoch Loss: 71520.7620 - Avg Loss: 161.4464\n",
            "Epoch [42/50] - Batch loss: 161.8748 - Epoch Loss: 71682.6368 - Avg Loss: 161.4474\n",
            "Epoch [42/50] - Batch loss: 163.5248 - Epoch Loss: 71846.1616 - Avg Loss: 161.4520\n",
            "Epoch [42/50] - Batch loss: 151.8731 - Epoch Loss: 71998.0347 - Avg Loss: 161.4306\n",
            "Epoch [42/50] - Batch loss: 166.1922 - Epoch Loss: 72164.2269 - Avg Loss: 161.4412\n",
            "Epoch [42/50] - Batch loss: 164.1386 - Epoch Loss: 72328.3655 - Avg Loss: 161.4472\n",
            "Epoch [42/50] - Batch loss: 161.0147 - Epoch Loss: 72489.3803 - Avg Loss: 161.4463\n",
            "Epoch [42/50] - Batch loss: 164.9620 - Epoch Loss: 72654.3423 - Avg Loss: 161.4541\n",
            "Epoch [42/50] - Batch loss: 155.6459 - Epoch Loss: 72809.9882 - Avg Loss: 161.4412\n",
            "Epoch [42/50] - Batch loss: 163.4918 - Epoch Loss: 72973.4800 - Avg Loss: 161.4458\n",
            "Epoch [42/50] - Batch loss: 158.6833 - Epoch Loss: 73132.1632 - Avg Loss: 161.4397\n",
            "Epoch [42/50] - Batch loss: 165.2924 - Epoch Loss: 73297.4556 - Avg Loss: 161.4481\n",
            "Epoch [42/50] - Batch loss: 169.0980 - Epoch Loss: 73466.5536 - Avg Loss: 161.4650\n",
            "Epoch [42/50] - Batch loss: 156.3350 - Epoch Loss: 73622.8887 - Avg Loss: 161.4537\n",
            "Epoch [42/50] - Batch loss: 163.2454 - Epoch Loss: 73786.1340 - Avg Loss: 161.4576\n",
            "Epoch [42/50] - Batch loss: 155.9884 - Epoch Loss: 73942.1224 - Avg Loss: 161.4457\n",
            "Epoch [42/50] - Batch loss: 158.3685 - Epoch Loss: 74100.4909 - Avg Loss: 161.4390\n",
            "Epoch [42/50] - Batch loss: 157.6662 - Epoch Loss: 74258.1571 - Avg Loss: 161.4308\n",
            "Epoch [42/50] - Batch loss: 159.0945 - Epoch Loss: 74417.2516 - Avg Loss: 161.4257\n",
            "Epoch [42/50] - Batch loss: 160.2222 - Epoch Loss: 74577.4737 - Avg Loss: 161.4231\n",
            "Epoch [42/50] - Batch loss: 158.8115 - Epoch Loss: 74736.2852 - Avg Loss: 161.4175\n",
            "Epoch [42/50] - Batch loss: 155.5872 - Epoch Loss: 74891.8724 - Avg Loss: 161.4049\n",
            "Epoch [42/50] - Batch loss: 157.4695 - Epoch Loss: 75049.3418 - Avg Loss: 161.3964\n",
            "Epoch [42/50] - Batch loss: 155.5927 - Epoch Loss: 75204.9345 - Avg Loss: 161.3840\n",
            "Epoch [42/50] - Batch loss: 167.6547 - Epoch Loss: 75372.5892 - Avg Loss: 161.3974\n",
            "Epoch [42/50] - Batch loss: 163.0699 - Epoch Loss: 75535.6591 - Avg Loss: 161.4010\n",
            "Epoch [42/50] - Batch loss: 155.5547 - Epoch Loss: 75691.2138 - Avg Loss: 161.3885\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 43/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d45732bf78874e18b20b85ca77955c7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [43/50] - Batch loss: 157.1543 - Epoch Loss: 157.1543 - Avg Loss: 157.1543\n",
            "Epoch [43/50] - Batch loss: 159.0419 - Epoch Loss: 316.1962 - Avg Loss: 158.0981\n",
            "Epoch [43/50] - Batch loss: 157.7810 - Epoch Loss: 473.9772 - Avg Loss: 157.9924\n",
            "Epoch [43/50] - Batch loss: 161.3465 - Epoch Loss: 635.3236 - Avg Loss: 158.8309\n",
            "Epoch [43/50] - Batch loss: 165.2083 - Epoch Loss: 800.5319 - Avg Loss: 160.1064\n",
            "Epoch [43/50] - Batch loss: 160.1693 - Epoch Loss: 960.7012 - Avg Loss: 160.1169\n",
            "Epoch [43/50] - Batch loss: 162.8932 - Epoch Loss: 1123.5944 - Avg Loss: 160.5135\n",
            "Epoch [43/50] - Batch loss: 159.9829 - Epoch Loss: 1283.5773 - Avg Loss: 160.4472\n",
            "Epoch [43/50] - Batch loss: 160.6440 - Epoch Loss: 1444.2213 - Avg Loss: 160.4690\n",
            "Epoch [43/50] - Batch loss: 162.0448 - Epoch Loss: 1606.2662 - Avg Loss: 160.6266\n",
            "Epoch [43/50] - Batch loss: 163.7750 - Epoch Loss: 1770.0412 - Avg Loss: 160.9128\n",
            "Epoch [43/50] - Batch loss: 162.2720 - Epoch Loss: 1932.3132 - Avg Loss: 161.0261\n",
            "Epoch [43/50] - Batch loss: 163.5963 - Epoch Loss: 2095.9095 - Avg Loss: 161.2238\n",
            "Epoch [43/50] - Batch loss: 171.9715 - Epoch Loss: 2267.8810 - Avg Loss: 161.9915\n",
            "Epoch [43/50] - Batch loss: 158.9145 - Epoch Loss: 2426.7955 - Avg Loss: 161.7864\n",
            "Epoch [43/50] - Batch loss: 158.7171 - Epoch Loss: 2585.5126 - Avg Loss: 161.5945\n",
            "Epoch [43/50] - Batch loss: 169.0365 - Epoch Loss: 2754.5491 - Avg Loss: 162.0323\n",
            "Epoch [43/50] - Batch loss: 168.5339 - Epoch Loss: 2923.0829 - Avg Loss: 162.3935\n",
            "Epoch [43/50] - Batch loss: 165.0890 - Epoch Loss: 3088.1719 - Avg Loss: 162.5354\n",
            "Epoch [43/50] - Batch loss: 159.3898 - Epoch Loss: 3247.5617 - Avg Loss: 162.3781\n",
            "Epoch [43/50] - Batch loss: 169.8271 - Epoch Loss: 3417.3888 - Avg Loss: 162.7328\n",
            "Epoch [43/50] - Batch loss: 169.3982 - Epoch Loss: 3586.7870 - Avg Loss: 163.0358\n",
            "Epoch [43/50] - Batch loss: 156.8702 - Epoch Loss: 3743.6573 - Avg Loss: 162.7677\n",
            "Epoch [43/50] - Batch loss: 168.2241 - Epoch Loss: 3911.8814 - Avg Loss: 162.9951\n",
            "Epoch [43/50] - Batch loss: 168.0409 - Epoch Loss: 4079.9223 - Avg Loss: 163.1969\n",
            "Epoch [43/50] - Batch loss: 161.2940 - Epoch Loss: 4241.2163 - Avg Loss: 163.1237\n",
            "Epoch [43/50] - Batch loss: 166.5577 - Epoch Loss: 4407.7741 - Avg Loss: 163.2509\n",
            "Epoch [43/50] - Batch loss: 157.1608 - Epoch Loss: 4564.9349 - Avg Loss: 163.0334\n",
            "Epoch [43/50] - Batch loss: 157.0458 - Epoch Loss: 4721.9807 - Avg Loss: 162.8269\n",
            "Epoch [43/50] - Batch loss: 157.2672 - Epoch Loss: 4879.2479 - Avg Loss: 162.6416\n",
            "Epoch [43/50] - Batch loss: 154.5337 - Epoch Loss: 5033.7816 - Avg Loss: 162.3801\n",
            "Epoch [43/50] - Batch loss: 161.2603 - Epoch Loss: 5195.0419 - Avg Loss: 162.3451\n",
            "Epoch [43/50] - Batch loss: 154.3501 - Epoch Loss: 5349.3920 - Avg Loss: 162.1028\n",
            "Epoch [43/50] - Batch loss: 165.7970 - Epoch Loss: 5515.1890 - Avg Loss: 162.2114\n",
            "Epoch [43/50] - Batch loss: 168.5696 - Epoch Loss: 5683.7586 - Avg Loss: 162.3931\n",
            "Epoch [43/50] - Batch loss: 163.7302 - Epoch Loss: 5847.4888 - Avg Loss: 162.4302\n",
            "Epoch [43/50] - Batch loss: 169.3924 - Epoch Loss: 6016.8812 - Avg Loss: 162.6184\n",
            "Epoch [43/50] - Batch loss: 167.1575 - Epoch Loss: 6184.0387 - Avg Loss: 162.7379\n",
            "Epoch [43/50] - Batch loss: 159.1464 - Epoch Loss: 6343.1851 - Avg Loss: 162.6458\n",
            "Epoch [43/50] - Batch loss: 166.9154 - Epoch Loss: 6510.1005 - Avg Loss: 162.7525\n",
            "Epoch [43/50] - Batch loss: 163.6435 - Epoch Loss: 6673.7440 - Avg Loss: 162.7742\n",
            "Epoch [43/50] - Batch loss: 160.4563 - Epoch Loss: 6834.2004 - Avg Loss: 162.7191\n",
            "Epoch [43/50] - Batch loss: 154.6716 - Epoch Loss: 6988.8720 - Avg Loss: 162.5319\n",
            "Epoch [43/50] - Batch loss: 163.3252 - Epoch Loss: 7152.1972 - Avg Loss: 162.5499\n",
            "Epoch [43/50] - Batch loss: 166.0478 - Epoch Loss: 7318.2450 - Avg Loss: 162.6277\n",
            "Epoch [43/50] - Batch loss: 161.7535 - Epoch Loss: 7479.9985 - Avg Loss: 162.6087\n",
            "Epoch [43/50] - Batch loss: 163.9456 - Epoch Loss: 7643.9442 - Avg Loss: 162.6371\n",
            "Epoch [43/50] - Batch loss: 162.4306 - Epoch Loss: 7806.3748 - Avg Loss: 162.6328\n",
            "Epoch [43/50] - Batch loss: 167.9031 - Epoch Loss: 7974.2779 - Avg Loss: 162.7404\n",
            "Epoch [43/50] - Batch loss: 157.8883 - Epoch Loss: 8132.1662 - Avg Loss: 162.6433\n",
            "Epoch [43/50] - Batch loss: 161.0813 - Epoch Loss: 8293.2475 - Avg Loss: 162.6127\n",
            "Epoch [43/50] - Batch loss: 172.2319 - Epoch Loss: 8465.4793 - Avg Loss: 162.7977\n",
            "Epoch [43/50] - Batch loss: 166.3684 - Epoch Loss: 8631.8478 - Avg Loss: 162.8651\n",
            "Epoch [43/50] - Batch loss: 160.7010 - Epoch Loss: 8792.5488 - Avg Loss: 162.8250\n",
            "Epoch [43/50] - Batch loss: 161.2266 - Epoch Loss: 8953.7754 - Avg Loss: 162.7959\n",
            "Epoch [43/50] - Batch loss: 162.4434 - Epoch Loss: 9116.2188 - Avg Loss: 162.7896\n",
            "Epoch [43/50] - Batch loss: 162.4096 - Epoch Loss: 9278.6285 - Avg Loss: 162.7830\n",
            "Epoch [43/50] - Batch loss: 155.9797 - Epoch Loss: 9434.6082 - Avg Loss: 162.6657\n",
            "Epoch [43/50] - Batch loss: 165.5837 - Epoch Loss: 9600.1918 - Avg Loss: 162.7151\n",
            "Epoch [43/50] - Batch loss: 156.5149 - Epoch Loss: 9756.7067 - Avg Loss: 162.6118\n",
            "Epoch [43/50] - Batch loss: 160.0013 - Epoch Loss: 9916.7081 - Avg Loss: 162.5690\n",
            "Epoch [43/50] - Batch loss: 165.0015 - Epoch Loss: 10081.7096 - Avg Loss: 162.6082\n",
            "Epoch [43/50] - Batch loss: 166.5203 - Epoch Loss: 10248.2299 - Avg Loss: 162.6703\n",
            "Epoch [43/50] - Batch loss: 159.4628 - Epoch Loss: 10407.6927 - Avg Loss: 162.6202\n",
            "Epoch [43/50] - Batch loss: 162.6737 - Epoch Loss: 10570.3663 - Avg Loss: 162.6210\n",
            "Epoch [43/50] - Batch loss: 155.9888 - Epoch Loss: 10726.3551 - Avg Loss: 162.5205\n",
            "Epoch [43/50] - Batch loss: 161.5750 - Epoch Loss: 10887.9302 - Avg Loss: 162.5064\n",
            "Epoch [43/50] - Batch loss: 155.5187 - Epoch Loss: 11043.4489 - Avg Loss: 162.4037\n",
            "Epoch [43/50] - Batch loss: 159.4469 - Epoch Loss: 11202.8958 - Avg Loss: 162.3608\n",
            "Epoch [43/50] - Batch loss: 157.7186 - Epoch Loss: 11360.6144 - Avg Loss: 162.2945\n",
            "Epoch [43/50] - Batch loss: 158.8046 - Epoch Loss: 11519.4190 - Avg Loss: 162.2453\n",
            "Epoch [43/50] - Batch loss: 158.1784 - Epoch Loss: 11677.5974 - Avg Loss: 162.1889\n",
            "Epoch [43/50] - Batch loss: 160.2232 - Epoch Loss: 11837.8206 - Avg Loss: 162.1619\n",
            "Epoch [43/50] - Batch loss: 158.7884 - Epoch Loss: 11996.6089 - Avg Loss: 162.1163\n",
            "Epoch [43/50] - Batch loss: 164.8257 - Epoch Loss: 12161.4346 - Avg Loss: 162.1525\n",
            "Epoch [43/50] - Batch loss: 162.5584 - Epoch Loss: 12323.9930 - Avg Loss: 162.1578\n",
            "Epoch [43/50] - Batch loss: 168.7812 - Epoch Loss: 12492.7743 - Avg Loss: 162.2438\n",
            "Epoch [43/50] - Batch loss: 158.3664 - Epoch Loss: 12651.1407 - Avg Loss: 162.1941\n",
            "Epoch [43/50] - Batch loss: 166.1713 - Epoch Loss: 12817.3120 - Avg Loss: 162.2445\n",
            "Epoch [43/50] - Batch loss: 163.7082 - Epoch Loss: 12981.0202 - Avg Loss: 162.2628\n",
            "Epoch [43/50] - Batch loss: 163.4433 - Epoch Loss: 13144.4635 - Avg Loss: 162.2773\n",
            "Epoch [43/50] - Batch loss: 165.7950 - Epoch Loss: 13310.2585 - Avg Loss: 162.3202\n",
            "Epoch [43/50] - Batch loss: 157.1692 - Epoch Loss: 13467.4277 - Avg Loss: 162.2582\n",
            "Epoch [43/50] - Batch loss: 156.1638 - Epoch Loss: 13623.5915 - Avg Loss: 162.1856\n",
            "Epoch [43/50] - Batch loss: 163.0406 - Epoch Loss: 13786.6321 - Avg Loss: 162.1957\n",
            "Epoch [43/50] - Batch loss: 163.9606 - Epoch Loss: 13950.5927 - Avg Loss: 162.2162\n",
            "Epoch [43/50] - Batch loss: 160.1165 - Epoch Loss: 14110.7092 - Avg Loss: 162.1921\n",
            "Epoch [43/50] - Batch loss: 161.0712 - Epoch Loss: 14271.7805 - Avg Loss: 162.1793\n",
            "Epoch [43/50] - Batch loss: 160.2231 - Epoch Loss: 14432.0035 - Avg Loss: 162.1573\n",
            "Epoch [43/50] - Batch loss: 155.8271 - Epoch Loss: 14587.8306 - Avg Loss: 162.0870\n",
            "Epoch [43/50] - Batch loss: 161.8397 - Epoch Loss: 14749.6703 - Avg Loss: 162.0843\n",
            "Epoch [43/50] - Batch loss: 156.1132 - Epoch Loss: 14905.7835 - Avg Loss: 162.0194\n",
            "Epoch [43/50] - Batch loss: 161.9587 - Epoch Loss: 15067.7422 - Avg Loss: 162.0187\n",
            "Epoch [43/50] - Batch loss: 161.2804 - Epoch Loss: 15229.0226 - Avg Loss: 162.0109\n",
            "Epoch [43/50] - Batch loss: 150.2457 - Epoch Loss: 15379.2684 - Avg Loss: 161.8870\n",
            "Epoch [43/50] - Batch loss: 158.1170 - Epoch Loss: 15537.3854 - Avg Loss: 161.8478\n",
            "Epoch [43/50] - Batch loss: 158.3177 - Epoch Loss: 15695.7031 - Avg Loss: 161.8114\n",
            "Epoch [43/50] - Batch loss: 157.5965 - Epoch Loss: 15853.2996 - Avg Loss: 161.7684\n",
            "Epoch [43/50] - Batch loss: 158.5825 - Epoch Loss: 16011.8821 - Avg Loss: 161.7362\n",
            "Epoch [43/50] - Batch loss: 158.1678 - Epoch Loss: 16170.0499 - Avg Loss: 161.7005\n",
            "Epoch [43/50] - Batch loss: 156.0369 - Epoch Loss: 16326.0868 - Avg Loss: 161.6444\n",
            "Epoch [43/50] - Batch loss: 160.0790 - Epoch Loss: 16486.1657 - Avg Loss: 161.6291\n",
            "Epoch [43/50] - Batch loss: 160.8999 - Epoch Loss: 16647.0656 - Avg Loss: 161.6220\n",
            "Epoch [43/50] - Batch loss: 165.3901 - Epoch Loss: 16812.4557 - Avg Loss: 161.6582\n",
            "Epoch [43/50] - Batch loss: 159.9854 - Epoch Loss: 16972.4411 - Avg Loss: 161.6423\n",
            "Epoch [43/50] - Batch loss: 166.4012 - Epoch Loss: 17138.8424 - Avg Loss: 161.6872\n",
            "Epoch [43/50] - Batch loss: 166.4742 - Epoch Loss: 17305.3166 - Avg Loss: 161.7319\n",
            "Epoch [43/50] - Batch loss: 163.6311 - Epoch Loss: 17468.9477 - Avg Loss: 161.7495\n",
            "Epoch [43/50] - Batch loss: 152.8365 - Epoch Loss: 17621.7842 - Avg Loss: 161.6677\n",
            "Epoch [43/50] - Batch loss: 163.9094 - Epoch Loss: 17785.6936 - Avg Loss: 161.6881\n",
            "Epoch [43/50] - Batch loss: 164.9837 - Epoch Loss: 17950.6774 - Avg Loss: 161.7178\n",
            "Epoch [43/50] - Batch loss: 156.0270 - Epoch Loss: 18106.7043 - Avg Loss: 161.6670\n",
            "Epoch [43/50] - Batch loss: 165.3060 - Epoch Loss: 18272.0104 - Avg Loss: 161.6992\n",
            "Epoch [43/50] - Batch loss: 163.9801 - Epoch Loss: 18435.9904 - Avg Loss: 161.7192\n",
            "Epoch [43/50] - Batch loss: 158.4663 - Epoch Loss: 18594.4568 - Avg Loss: 161.6909\n",
            "Epoch [43/50] - Batch loss: 157.4190 - Epoch Loss: 18751.8757 - Avg Loss: 161.6541\n",
            "Epoch [43/50] - Batch loss: 169.2552 - Epoch Loss: 18921.1309 - Avg Loss: 161.7191\n",
            "Epoch [43/50] - Batch loss: 152.4047 - Epoch Loss: 19073.5356 - Avg Loss: 161.6401\n",
            "Epoch [43/50] - Batch loss: 157.7743 - Epoch Loss: 19231.3099 - Avg Loss: 161.6076\n",
            "Epoch [43/50] - Batch loss: 163.4911 - Epoch Loss: 19394.8010 - Avg Loss: 161.6233\n",
            "Epoch [43/50] - Batch loss: 154.9418 - Epoch Loss: 19549.7428 - Avg Loss: 161.5681\n",
            "Epoch [43/50] - Batch loss: 161.6111 - Epoch Loss: 19711.3539 - Avg Loss: 161.5685\n",
            "Epoch [43/50] - Batch loss: 158.8802 - Epoch Loss: 19870.2341 - Avg Loss: 161.5466\n",
            "Epoch [43/50] - Batch loss: 162.7963 - Epoch Loss: 20033.0303 - Avg Loss: 161.5567\n",
            "Epoch [43/50] - Batch loss: 151.5319 - Epoch Loss: 20184.5623 - Avg Loss: 161.4765\n",
            "Epoch [43/50] - Batch loss: 153.8428 - Epoch Loss: 20338.4051 - Avg Loss: 161.4159\n",
            "Epoch [43/50] - Batch loss: 161.7664 - Epoch Loss: 20500.1715 - Avg Loss: 161.4187\n",
            "Epoch [43/50] - Batch loss: 158.9199 - Epoch Loss: 20659.0914 - Avg Loss: 161.3992\n",
            "Epoch [43/50] - Batch loss: 157.6709 - Epoch Loss: 20816.7623 - Avg Loss: 161.3703\n",
            "Epoch [43/50] - Batch loss: 159.5100 - Epoch Loss: 20976.2723 - Avg Loss: 161.3559\n",
            "Epoch [43/50] - Batch loss: 163.8568 - Epoch Loss: 21140.1291 - Avg Loss: 161.3750\n",
            "Epoch [43/50] - Batch loss: 150.1443 - Epoch Loss: 21290.2734 - Avg Loss: 161.2899\n",
            "Epoch [43/50] - Batch loss: 159.8858 - Epoch Loss: 21450.1592 - Avg Loss: 161.2794\n",
            "Epoch [43/50] - Batch loss: 156.1738 - Epoch Loss: 21606.3330 - Avg Loss: 161.2413\n",
            "Epoch [43/50] - Batch loss: 166.9128 - Epoch Loss: 21773.2458 - Avg Loss: 161.2833\n",
            "Epoch [43/50] - Batch loss: 162.2923 - Epoch Loss: 21935.5381 - Avg Loss: 161.2907\n",
            "Epoch [43/50] - Batch loss: 161.9389 - Epoch Loss: 22097.4770 - Avg Loss: 161.2955\n",
            "Epoch [43/50] - Batch loss: 163.9977 - Epoch Loss: 22261.4746 - Avg Loss: 161.3150\n",
            "Epoch [43/50] - Batch loss: 156.0486 - Epoch Loss: 22417.5232 - Avg Loss: 161.2771\n",
            "Epoch [43/50] - Batch loss: 165.7025 - Epoch Loss: 22583.2257 - Avg Loss: 161.3088\n",
            "Epoch [43/50] - Batch loss: 164.3969 - Epoch Loss: 22747.6226 - Avg Loss: 161.3307\n",
            "Epoch [43/50] - Batch loss: 153.6522 - Epoch Loss: 22901.2748 - Avg Loss: 161.2766\n",
            "Epoch [43/50] - Batch loss: 164.3719 - Epoch Loss: 23065.6467 - Avg Loss: 161.2982\n",
            "Epoch [43/50] - Batch loss: 167.5356 - Epoch Loss: 23233.1824 - Avg Loss: 161.3415\n",
            "Epoch [43/50] - Batch loss: 160.5300 - Epoch Loss: 23393.7124 - Avg Loss: 161.3359\n",
            "Epoch [43/50] - Batch loss: 172.4697 - Epoch Loss: 23566.1820 - Avg Loss: 161.4122\n",
            "Epoch [43/50] - Batch loss: 153.4679 - Epoch Loss: 23719.6499 - Avg Loss: 161.3582\n",
            "Epoch [43/50] - Batch loss: 165.5231 - Epoch Loss: 23885.1730 - Avg Loss: 161.3863\n",
            "Epoch [43/50] - Batch loss: 155.5340 - Epoch Loss: 24040.7070 - Avg Loss: 161.3470\n",
            "Epoch [43/50] - Batch loss: 165.5094 - Epoch Loss: 24206.2164 - Avg Loss: 161.3748\n",
            "Epoch [43/50] - Batch loss: 166.5663 - Epoch Loss: 24372.7827 - Avg Loss: 161.4092\n",
            "Epoch [43/50] - Batch loss: 163.0602 - Epoch Loss: 24535.8429 - Avg Loss: 161.4200\n",
            "Epoch [43/50] - Batch loss: 154.9863 - Epoch Loss: 24690.8292 - Avg Loss: 161.3780\n",
            "Epoch [43/50] - Batch loss: 151.9264 - Epoch Loss: 24842.7556 - Avg Loss: 161.3166\n",
            "Epoch [43/50] - Batch loss: 162.3589 - Epoch Loss: 25005.1144 - Avg Loss: 161.3233\n",
            "Epoch [43/50] - Batch loss: 156.7411 - Epoch Loss: 25161.8555 - Avg Loss: 161.2939\n",
            "Epoch [43/50] - Batch loss: 159.4234 - Epoch Loss: 25321.2789 - Avg Loss: 161.2820\n",
            "Epoch [43/50] - Batch loss: 167.3027 - Epoch Loss: 25488.5816 - Avg Loss: 161.3201\n",
            "Epoch [43/50] - Batch loss: 160.4994 - Epoch Loss: 25649.0810 - Avg Loss: 161.3150\n",
            "Epoch [43/50] - Batch loss: 162.0372 - Epoch Loss: 25811.1182 - Avg Loss: 161.3195\n",
            "Epoch [43/50] - Batch loss: 162.1763 - Epoch Loss: 25973.2944 - Avg Loss: 161.3248\n",
            "Epoch [43/50] - Batch loss: 159.7896 - Epoch Loss: 26133.0840 - Avg Loss: 161.3153\n",
            "Epoch [43/50] - Batch loss: 160.0741 - Epoch Loss: 26293.1581 - Avg Loss: 161.3077\n",
            "Epoch [43/50] - Batch loss: 163.4609 - Epoch Loss: 26456.6190 - Avg Loss: 161.3208\n",
            "Epoch [43/50] - Batch loss: 154.7778 - Epoch Loss: 26611.3969 - Avg Loss: 161.2812\n",
            "Epoch [43/50] - Batch loss: 153.7746 - Epoch Loss: 26765.1715 - Avg Loss: 161.2360\n",
            "Epoch [43/50] - Batch loss: 162.3946 - Epoch Loss: 26927.5661 - Avg Loss: 161.2429\n",
            "Epoch [43/50] - Batch loss: 160.7246 - Epoch Loss: 27088.2907 - Avg Loss: 161.2398\n",
            "Epoch [43/50] - Batch loss: 168.4043 - Epoch Loss: 27256.6950 - Avg Loss: 161.2822\n",
            "Epoch [43/50] - Batch loss: 153.6209 - Epoch Loss: 27410.3159 - Avg Loss: 161.2372\n",
            "Epoch [43/50] - Batch loss: 154.8101 - Epoch Loss: 27565.1260 - Avg Loss: 161.1996\n",
            "Epoch [43/50] - Batch loss: 163.5097 - Epoch Loss: 27728.6357 - Avg Loss: 161.2130\n",
            "Epoch [43/50] - Batch loss: 155.5472 - Epoch Loss: 27884.1829 - Avg Loss: 161.1802\n",
            "Epoch [43/50] - Batch loss: 167.9898 - Epoch Loss: 28052.1728 - Avg Loss: 161.2194\n",
            "Epoch [43/50] - Batch loss: 159.2177 - Epoch Loss: 28211.3904 - Avg Loss: 161.2079\n",
            "Epoch [43/50] - Batch loss: 153.3793 - Epoch Loss: 28364.7698 - Avg Loss: 161.1635\n",
            "Epoch [43/50] - Batch loss: 154.6307 - Epoch Loss: 28519.4004 - Avg Loss: 161.1266\n",
            "Epoch [43/50] - Batch loss: 163.5502 - Epoch Loss: 28682.9507 - Avg Loss: 161.1402\n",
            "Epoch [43/50] - Batch loss: 162.2135 - Epoch Loss: 28845.1642 - Avg Loss: 161.1462\n",
            "Epoch [43/50] - Batch loss: 159.7742 - Epoch Loss: 29004.9384 - Avg Loss: 161.1385\n",
            "Epoch [43/50] - Batch loss: 159.9610 - Epoch Loss: 29164.8994 - Avg Loss: 161.1320\n",
            "Epoch [43/50] - Batch loss: 159.2612 - Epoch Loss: 29324.1606 - Avg Loss: 161.1218\n",
            "Epoch [43/50] - Batch loss: 161.8510 - Epoch Loss: 29486.0116 - Avg Loss: 161.1257\n",
            "Epoch [43/50] - Batch loss: 162.4168 - Epoch Loss: 29648.4285 - Avg Loss: 161.1328\n",
            "Epoch [43/50] - Batch loss: 165.4983 - Epoch Loss: 29813.9267 - Avg Loss: 161.1564\n",
            "Epoch [43/50] - Batch loss: 157.7422 - Epoch Loss: 29971.6689 - Avg Loss: 161.1380\n",
            "Epoch [43/50] - Batch loss: 165.6103 - Epoch Loss: 30137.2793 - Avg Loss: 161.1619\n",
            "Epoch [43/50] - Batch loss: 162.9038 - Epoch Loss: 30300.1831 - Avg Loss: 161.1712\n",
            "Epoch [43/50] - Batch loss: 164.3121 - Epoch Loss: 30464.4953 - Avg Loss: 161.1878\n",
            "Epoch [43/50] - Batch loss: 164.4830 - Epoch Loss: 30628.9783 - Avg Loss: 161.2051\n",
            "Epoch [43/50] - Batch loss: 152.1171 - Epoch Loss: 30781.0953 - Avg Loss: 161.1576\n",
            "Epoch [43/50] - Batch loss: 159.9127 - Epoch Loss: 30941.0080 - Avg Loss: 161.1511\n",
            "Epoch [43/50] - Batch loss: 167.4289 - Epoch Loss: 31108.4369 - Avg Loss: 161.1836\n",
            "Epoch [43/50] - Batch loss: 152.4318 - Epoch Loss: 31260.8687 - Avg Loss: 161.1385\n",
            "Epoch [43/50] - Batch loss: 166.4388 - Epoch Loss: 31427.3075 - Avg Loss: 161.1657\n",
            "Epoch [43/50] - Batch loss: 158.9953 - Epoch Loss: 31586.3028 - Avg Loss: 161.1546\n",
            "Epoch [43/50] - Batch loss: 163.4492 - Epoch Loss: 31749.7520 - Avg Loss: 161.1663\n",
            "Epoch [43/50] - Batch loss: 156.3682 - Epoch Loss: 31906.1202 - Avg Loss: 161.1420\n",
            "Epoch [43/50] - Batch loss: 160.7094 - Epoch Loss: 32066.8296 - Avg Loss: 161.1398\n",
            "Epoch [43/50] - Batch loss: 158.8926 - Epoch Loss: 32225.7222 - Avg Loss: 161.1286\n",
            "Epoch [43/50] - Batch loss: 163.4093 - Epoch Loss: 32389.1315 - Avg Loss: 161.1400\n",
            "Epoch [43/50] - Batch loss: 158.8469 - Epoch Loss: 32547.9784 - Avg Loss: 161.1286\n",
            "Epoch [43/50] - Batch loss: 165.0021 - Epoch Loss: 32712.9805 - Avg Loss: 161.1477\n",
            "Epoch [43/50] - Batch loss: 156.8589 - Epoch Loss: 32869.8395 - Avg Loss: 161.1267\n",
            "Epoch [43/50] - Batch loss: 162.2812 - Epoch Loss: 33032.1206 - Avg Loss: 161.1323\n",
            "Epoch [43/50] - Batch loss: 159.1752 - Epoch Loss: 33191.2959 - Avg Loss: 161.1228\n",
            "Epoch [43/50] - Batch loss: 160.1609 - Epoch Loss: 33351.4567 - Avg Loss: 161.1181\n",
            "Epoch [43/50] - Batch loss: 158.5465 - Epoch Loss: 33510.0033 - Avg Loss: 161.1058\n",
            "Epoch [43/50] - Batch loss: 159.6764 - Epoch Loss: 33669.6796 - Avg Loss: 161.0989\n",
            "Epoch [43/50] - Batch loss: 164.1012 - Epoch Loss: 33833.7808 - Avg Loss: 161.1132\n",
            "Epoch [43/50] - Batch loss: 162.9793 - Epoch Loss: 33996.7601 - Avg Loss: 161.1221\n",
            "Epoch [43/50] - Batch loss: 166.8701 - Epoch Loss: 34163.6302 - Avg Loss: 161.1492\n",
            "Epoch [43/50] - Batch loss: 165.2485 - Epoch Loss: 34328.8787 - Avg Loss: 161.1684\n",
            "Epoch [43/50] - Batch loss: 159.4353 - Epoch Loss: 34488.3140 - Avg Loss: 161.1603\n",
            "Epoch [43/50] - Batch loss: 162.4181 - Epoch Loss: 34650.7321 - Avg Loss: 161.1662\n",
            "Epoch [43/50] - Batch loss: 162.8894 - Epoch Loss: 34813.6215 - Avg Loss: 161.1742\n",
            "Epoch [43/50] - Batch loss: 157.9934 - Epoch Loss: 34971.6149 - Avg Loss: 161.1595\n",
            "Epoch [43/50] - Batch loss: 153.7177 - Epoch Loss: 35125.3326 - Avg Loss: 161.1254\n",
            "Epoch [43/50] - Batch loss: 160.2624 - Epoch Loss: 35285.5950 - Avg Loss: 161.1214\n",
            "Epoch [43/50] - Batch loss: 160.1558 - Epoch Loss: 35445.7508 - Avg Loss: 161.1170\n",
            "Epoch [43/50] - Batch loss: 154.4737 - Epoch Loss: 35600.2244 - Avg Loss: 161.0870\n",
            "Epoch [43/50] - Batch loss: 156.3772 - Epoch Loss: 35756.6017 - Avg Loss: 161.0658\n",
            "Epoch [43/50] - Batch loss: 158.8759 - Epoch Loss: 35915.4775 - Avg Loss: 161.0560\n",
            "Epoch [43/50] - Batch loss: 162.7466 - Epoch Loss: 36078.2241 - Avg Loss: 161.0635\n",
            "Epoch [43/50] - Batch loss: 157.1082 - Epoch Loss: 36235.3323 - Avg Loss: 161.0459\n",
            "Epoch [43/50] - Batch loss: 157.8634 - Epoch Loss: 36393.1957 - Avg Loss: 161.0318\n",
            "Epoch [43/50] - Batch loss: 163.8987 - Epoch Loss: 36557.0945 - Avg Loss: 161.0445\n",
            "Epoch [43/50] - Batch loss: 158.0780 - Epoch Loss: 36715.1724 - Avg Loss: 161.0315\n",
            "Epoch [43/50] - Batch loss: 162.2511 - Epoch Loss: 36877.4235 - Avg Loss: 161.0368\n",
            "Epoch [43/50] - Batch loss: 159.8270 - Epoch Loss: 37037.2505 - Avg Loss: 161.0315\n",
            "Epoch [43/50] - Batch loss: 154.8501 - Epoch Loss: 37192.1006 - Avg Loss: 161.0048\n",
            "Epoch [43/50] - Batch loss: 152.3304 - Epoch Loss: 37344.4311 - Avg Loss: 160.9674\n",
            "Epoch [43/50] - Batch loss: 170.4651 - Epoch Loss: 37514.8961 - Avg Loss: 161.0081\n",
            "Epoch [43/50] - Batch loss: 169.1682 - Epoch Loss: 37684.0643 - Avg Loss: 161.0430\n",
            "Epoch [43/50] - Batch loss: 165.9212 - Epoch Loss: 37849.9856 - Avg Loss: 161.0638\n",
            "Epoch [43/50] - Batch loss: 159.7016 - Epoch Loss: 38009.6872 - Avg Loss: 161.0580\n",
            "Epoch [43/50] - Batch loss: 171.0435 - Epoch Loss: 38180.7307 - Avg Loss: 161.1001\n",
            "Epoch [43/50] - Batch loss: 158.5352 - Epoch Loss: 38339.2659 - Avg Loss: 161.0894\n",
            "Epoch [43/50] - Batch loss: 160.5742 - Epoch Loss: 38499.8401 - Avg Loss: 161.0872\n",
            "Epoch [43/50] - Batch loss: 166.8237 - Epoch Loss: 38666.6638 - Avg Loss: 161.1111\n",
            "Epoch [43/50] - Batch loss: 161.3580 - Epoch Loss: 38828.0219 - Avg Loss: 161.1121\n",
            "Epoch [43/50] - Batch loss: 166.7471 - Epoch Loss: 38994.7689 - Avg Loss: 161.1354\n",
            "Epoch [43/50] - Batch loss: 159.7080 - Epoch Loss: 39154.4770 - Avg Loss: 161.1295\n",
            "Epoch [43/50] - Batch loss: 162.5919 - Epoch Loss: 39317.0689 - Avg Loss: 161.1355\n",
            "Epoch [43/50] - Batch loss: 157.1624 - Epoch Loss: 39474.2313 - Avg Loss: 161.1193\n",
            "Epoch [43/50] - Batch loss: 164.7409 - Epoch Loss: 39638.9722 - Avg Loss: 161.1340\n",
            "Epoch [43/50] - Batch loss: 165.3080 - Epoch Loss: 39804.2802 - Avg Loss: 161.1509\n",
            "Epoch [43/50] - Batch loss: 152.1965 - Epoch Loss: 39956.4767 - Avg Loss: 161.1148\n",
            "Epoch [43/50] - Batch loss: 163.4353 - Epoch Loss: 40119.9120 - Avg Loss: 161.1241\n",
            "Epoch [43/50] - Batch loss: 156.5107 - Epoch Loss: 40276.4227 - Avg Loss: 161.1057\n",
            "Epoch [43/50] - Batch loss: 165.2825 - Epoch Loss: 40441.7052 - Avg Loss: 161.1223\n",
            "Epoch [43/50] - Batch loss: 169.6190 - Epoch Loss: 40611.3242 - Avg Loss: 161.1560\n",
            "Epoch [43/50] - Batch loss: 164.4988 - Epoch Loss: 40775.8230 - Avg Loss: 161.1693\n",
            "Epoch [43/50] - Batch loss: 161.8987 - Epoch Loss: 40937.7218 - Avg Loss: 161.1721\n",
            "Epoch [43/50] - Batch loss: 160.0478 - Epoch Loss: 41097.7695 - Avg Loss: 161.1677\n",
            "Epoch [43/50] - Batch loss: 172.2335 - Epoch Loss: 41270.0030 - Avg Loss: 161.2109\n",
            "Epoch [43/50] - Batch loss: 160.0147 - Epoch Loss: 41430.0177 - Avg Loss: 161.2063\n",
            "Epoch [43/50] - Batch loss: 165.6537 - Epoch Loss: 41595.6714 - Avg Loss: 161.2235\n",
            "Epoch [43/50] - Batch loss: 162.0941 - Epoch Loss: 41757.7655 - Avg Loss: 161.2269\n",
            "Epoch [43/50] - Batch loss: 162.0730 - Epoch Loss: 41919.8385 - Avg Loss: 161.2301\n",
            "Epoch [43/50] - Batch loss: 161.0660 - Epoch Loss: 42080.9045 - Avg Loss: 161.2295\n",
            "Epoch [43/50] - Batch loss: 154.2591 - Epoch Loss: 42235.1635 - Avg Loss: 161.2029\n",
            "Epoch [43/50] - Batch loss: 146.3163 - Epoch Loss: 42381.4798 - Avg Loss: 161.1463\n",
            "Epoch [43/50] - Batch loss: 169.1344 - Epoch Loss: 42550.6142 - Avg Loss: 161.1766\n",
            "Epoch [43/50] - Batch loss: 160.6614 - Epoch Loss: 42711.2756 - Avg Loss: 161.1746\n",
            "Epoch [43/50] - Batch loss: 167.9109 - Epoch Loss: 42879.1865 - Avg Loss: 161.1999\n",
            "Epoch [43/50] - Batch loss: 163.9404 - Epoch Loss: 43043.1270 - Avg Loss: 161.2102\n",
            "Epoch [43/50] - Batch loss: 163.4461 - Epoch Loss: 43206.5731 - Avg Loss: 161.2186\n",
            "Epoch [43/50] - Batch loss: 165.6034 - Epoch Loss: 43372.1765 - Avg Loss: 161.2349\n",
            "Epoch [43/50] - Batch loss: 150.0204 - Epoch Loss: 43522.1969 - Avg Loss: 161.1933\n",
            "Epoch [43/50] - Batch loss: 157.3666 - Epoch Loss: 43679.5634 - Avg Loss: 161.1792\n",
            "Epoch [43/50] - Batch loss: 157.0765 - Epoch Loss: 43836.6399 - Avg Loss: 161.1641\n",
            "Epoch [43/50] - Batch loss: 161.4171 - Epoch Loss: 43998.0569 - Avg Loss: 161.1650\n",
            "Epoch [43/50] - Batch loss: 158.8324 - Epoch Loss: 44156.8893 - Avg Loss: 161.1565\n",
            "Epoch [43/50] - Batch loss: 161.3229 - Epoch Loss: 44318.2122 - Avg Loss: 161.1571\n",
            "Epoch [43/50] - Batch loss: 160.5011 - Epoch Loss: 44478.7132 - Avg Loss: 161.1548\n",
            "Epoch [43/50] - Batch loss: 154.6231 - Epoch Loss: 44633.3363 - Avg Loss: 161.1312\n",
            "Epoch [43/50] - Batch loss: 155.7928 - Epoch Loss: 44789.1291 - Avg Loss: 161.1120\n",
            "Epoch [43/50] - Batch loss: 163.7285 - Epoch Loss: 44952.8576 - Avg Loss: 161.1214\n",
            "Epoch [43/50] - Batch loss: 162.6599 - Epoch Loss: 45115.5175 - Avg Loss: 161.1268\n",
            "Epoch [43/50] - Batch loss: 164.7945 - Epoch Loss: 45280.3120 - Avg Loss: 161.1399\n",
            "Epoch [43/50] - Batch loss: 163.9643 - Epoch Loss: 45444.2763 - Avg Loss: 161.1499\n",
            "Epoch [43/50] - Batch loss: 160.6573 - Epoch Loss: 45604.9336 - Avg Loss: 161.1482\n",
            "Epoch [43/50] - Batch loss: 157.5843 - Epoch Loss: 45762.5179 - Avg Loss: 161.1356\n",
            "Epoch [43/50] - Batch loss: 155.1940 - Epoch Loss: 45917.7119 - Avg Loss: 161.1148\n",
            "Epoch [43/50] - Batch loss: 152.7743 - Epoch Loss: 46070.4862 - Avg Loss: 161.0856\n",
            "Epoch [43/50] - Batch loss: 160.9022 - Epoch Loss: 46231.3884 - Avg Loss: 161.0850\n",
            "Epoch [43/50] - Batch loss: 159.6724 - Epoch Loss: 46391.0608 - Avg Loss: 161.0801\n",
            "Epoch [43/50] - Batch loss: 150.8674 - Epoch Loss: 46541.9282 - Avg Loss: 161.0447\n",
            "Epoch [43/50] - Batch loss: 166.8005 - Epoch Loss: 46708.7287 - Avg Loss: 161.0646\n",
            "Epoch [43/50] - Batch loss: 148.6637 - Epoch Loss: 46857.3924 - Avg Loss: 161.0220\n",
            "Epoch [43/50] - Batch loss: 155.9839 - Epoch Loss: 47013.3763 - Avg Loss: 161.0047\n",
            "Epoch [43/50] - Batch loss: 154.0490 - Epoch Loss: 47167.4252 - Avg Loss: 160.9810\n",
            "Epoch [43/50] - Batch loss: 154.8454 - Epoch Loss: 47322.2707 - Avg Loss: 160.9601\n",
            "Epoch [43/50] - Batch loss: 154.8697 - Epoch Loss: 47477.1404 - Avg Loss: 160.9395\n",
            "Epoch [43/50] - Batch loss: 159.7677 - Epoch Loss: 47636.9081 - Avg Loss: 160.9355\n",
            "Epoch [43/50] - Batch loss: 160.7378 - Epoch Loss: 47797.6459 - Avg Loss: 160.9348\n",
            "Epoch [43/50] - Batch loss: 152.8738 - Epoch Loss: 47950.5197 - Avg Loss: 160.9078\n",
            "Epoch [43/50] - Batch loss: 162.5774 - Epoch Loss: 48113.0971 - Avg Loss: 160.9134\n",
            "Epoch [43/50] - Batch loss: 156.9599 - Epoch Loss: 48270.0570 - Avg Loss: 160.9002\n",
            "Epoch [43/50] - Batch loss: 157.1979 - Epoch Loss: 48427.2549 - Avg Loss: 160.8879\n",
            "Epoch [43/50] - Batch loss: 161.6352 - Epoch Loss: 48588.8900 - Avg Loss: 160.8904\n",
            "Epoch [43/50] - Batch loss: 154.8998 - Epoch Loss: 48743.7899 - Avg Loss: 160.8706\n",
            "Epoch [43/50] - Batch loss: 151.8374 - Epoch Loss: 48895.6273 - Avg Loss: 160.8409\n",
            "Epoch [43/50] - Batch loss: 160.1135 - Epoch Loss: 49055.7408 - Avg Loss: 160.8385\n",
            "Epoch [43/50] - Batch loss: 161.4992 - Epoch Loss: 49217.2401 - Avg Loss: 160.8407\n",
            "Epoch [43/50] - Batch loss: 158.2412 - Epoch Loss: 49375.4813 - Avg Loss: 160.8322\n",
            "Epoch [43/50] - Batch loss: 157.1400 - Epoch Loss: 49532.6213 - Avg Loss: 160.8202\n",
            "Epoch [43/50] - Batch loss: 161.2405 - Epoch Loss: 49693.8618 - Avg Loss: 160.8216\n",
            "Epoch [43/50] - Batch loss: 161.0621 - Epoch Loss: 49854.9239 - Avg Loss: 160.8223\n",
            "Epoch [43/50] - Batch loss: 159.6072 - Epoch Loss: 50014.5311 - Avg Loss: 160.8184\n",
            "Epoch [43/50] - Batch loss: 167.3101 - Epoch Loss: 50181.8412 - Avg Loss: 160.8392\n",
            "Epoch [43/50] - Batch loss: 161.2061 - Epoch Loss: 50343.0473 - Avg Loss: 160.8404\n",
            "Epoch [43/50] - Batch loss: 168.8816 - Epoch Loss: 50511.9289 - Avg Loss: 160.8660\n",
            "Epoch [43/50] - Batch loss: 158.3247 - Epoch Loss: 50670.2536 - Avg Loss: 160.8579\n",
            "Epoch [43/50] - Batch loss: 162.4232 - Epoch Loss: 50832.6768 - Avg Loss: 160.8629\n",
            "Epoch [43/50] - Batch loss: 150.0977 - Epoch Loss: 50982.7745 - Avg Loss: 160.8289\n",
            "Epoch [43/50] - Batch loss: 151.9541 - Epoch Loss: 51134.7285 - Avg Loss: 160.8010\n",
            "Epoch [43/50] - Batch loss: 162.7344 - Epoch Loss: 51297.4629 - Avg Loss: 160.8071\n",
            "Epoch [43/50] - Batch loss: 164.3570 - Epoch Loss: 51461.8199 - Avg Loss: 160.8182\n",
            "Epoch [43/50] - Batch loss: 166.6582 - Epoch Loss: 51628.4781 - Avg Loss: 160.8364\n",
            "Epoch [43/50] - Batch loss: 160.3910 - Epoch Loss: 51788.8690 - Avg Loss: 160.8350\n",
            "Epoch [43/50] - Batch loss: 163.1744 - Epoch Loss: 51952.0434 - Avg Loss: 160.8422\n",
            "Epoch [43/50] - Batch loss: 160.5349 - Epoch Loss: 52112.5783 - Avg Loss: 160.8413\n",
            "Epoch [43/50] - Batch loss: 160.5665 - Epoch Loss: 52273.1447 - Avg Loss: 160.8404\n",
            "Epoch [43/50] - Batch loss: 161.9946 - Epoch Loss: 52435.1393 - Avg Loss: 160.8440\n",
            "Epoch [43/50] - Batch loss: 167.6100 - Epoch Loss: 52602.7493 - Avg Loss: 160.8647\n",
            "Epoch [43/50] - Batch loss: 155.5777 - Epoch Loss: 52758.3270 - Avg Loss: 160.8486\n",
            "Epoch [43/50] - Batch loss: 167.8108 - Epoch Loss: 52926.1378 - Avg Loss: 160.8697\n",
            "Epoch [43/50] - Batch loss: 149.8488 - Epoch Loss: 53075.9865 - Avg Loss: 160.8363\n",
            "Epoch [43/50] - Batch loss: 161.2768 - Epoch Loss: 53237.2633 - Avg Loss: 160.8377\n",
            "Epoch [43/50] - Batch loss: 161.9716 - Epoch Loss: 53399.2349 - Avg Loss: 160.8411\n",
            "Epoch [43/50] - Batch loss: 158.3874 - Epoch Loss: 53557.6223 - Avg Loss: 160.8337\n",
            "Epoch [43/50] - Batch loss: 154.6489 - Epoch Loss: 53712.2712 - Avg Loss: 160.8152\n",
            "Epoch [43/50] - Batch loss: 156.9619 - Epoch Loss: 53869.2331 - Avg Loss: 160.8037\n",
            "Epoch [43/50] - Batch loss: 157.5905 - Epoch Loss: 54026.8236 - Avg Loss: 160.7941\n",
            "Epoch [43/50] - Batch loss: 168.1656 - Epoch Loss: 54194.9893 - Avg Loss: 160.8160\n",
            "Epoch [43/50] - Batch loss: 162.4578 - Epoch Loss: 54357.4471 - Avg Loss: 160.8208\n",
            "Epoch [43/50] - Batch loss: 158.0989 - Epoch Loss: 54515.5459 - Avg Loss: 160.8128\n",
            "Epoch [43/50] - Batch loss: 159.7013 - Epoch Loss: 54675.2472 - Avg Loss: 160.8096\n",
            "Epoch [43/50] - Batch loss: 158.2611 - Epoch Loss: 54833.5083 - Avg Loss: 160.8021\n",
            "Epoch [43/50] - Batch loss: 159.7738 - Epoch Loss: 54993.2820 - Avg Loss: 160.7991\n",
            "Epoch [43/50] - Batch loss: 165.2778 - Epoch Loss: 55158.5599 - Avg Loss: 160.8121\n",
            "Epoch [43/50] - Batch loss: 161.4250 - Epoch Loss: 55319.9849 - Avg Loss: 160.8139\n",
            "Epoch [43/50] - Batch loss: 165.4823 - Epoch Loss: 55485.4672 - Avg Loss: 160.8274\n",
            "Epoch [43/50] - Batch loss: 157.5082 - Epoch Loss: 55642.9754 - Avg Loss: 160.8178\n",
            "Epoch [43/50] - Batch loss: 167.1134 - Epoch Loss: 55810.0888 - Avg Loss: 160.8360\n",
            "Epoch [43/50] - Batch loss: 161.9883 - Epoch Loss: 55972.0771 - Avg Loss: 160.8393\n",
            "Epoch [43/50] - Batch loss: 169.2474 - Epoch Loss: 56141.3245 - Avg Loss: 160.8634\n",
            "Epoch [43/50] - Batch loss: 147.1082 - Epoch Loss: 56288.4327 - Avg Loss: 160.8241\n",
            "Epoch [43/50] - Batch loss: 162.3956 - Epoch Loss: 56450.8283 - Avg Loss: 160.8286\n",
            "Epoch [43/50] - Batch loss: 160.7926 - Epoch Loss: 56611.6208 - Avg Loss: 160.8285\n",
            "Epoch [43/50] - Batch loss: 155.4272 - Epoch Loss: 56767.0480 - Avg Loss: 160.8132\n",
            "Epoch [43/50] - Batch loss: 163.6361 - Epoch Loss: 56930.6841 - Avg Loss: 160.8211\n",
            "Epoch [43/50] - Batch loss: 161.7366 - Epoch Loss: 57092.4207 - Avg Loss: 160.8237\n",
            "Epoch [43/50] - Batch loss: 158.9988 - Epoch Loss: 57251.4195 - Avg Loss: 160.8186\n",
            "Epoch [43/50] - Batch loss: 157.0436 - Epoch Loss: 57408.4632 - Avg Loss: 160.8080\n",
            "Epoch [43/50] - Batch loss: 163.7452 - Epoch Loss: 57572.2083 - Avg Loss: 160.8162\n",
            "Epoch [43/50] - Batch loss: 162.7865 - Epoch Loss: 57734.9948 - Avg Loss: 160.8217\n",
            "Epoch [43/50] - Batch loss: 168.7340 - Epoch Loss: 57903.7288 - Avg Loss: 160.8437\n",
            "Epoch [43/50] - Batch loss: 163.0177 - Epoch Loss: 58066.7465 - Avg Loss: 160.8497\n",
            "Epoch [43/50] - Batch loss: 162.4286 - Epoch Loss: 58229.1752 - Avg Loss: 160.8541\n",
            "Epoch [43/50] - Batch loss: 154.6441 - Epoch Loss: 58383.8193 - Avg Loss: 160.8370\n",
            "Epoch [43/50] - Batch loss: 156.8390 - Epoch Loss: 58540.6583 - Avg Loss: 160.8260\n",
            "Epoch [43/50] - Batch loss: 158.4427 - Epoch Loss: 58699.1010 - Avg Loss: 160.8195\n",
            "Epoch [43/50] - Batch loss: 167.6599 - Epoch Loss: 58866.7609 - Avg Loss: 160.8381\n",
            "Epoch [43/50] - Batch loss: 158.0049 - Epoch Loss: 59024.7658 - Avg Loss: 160.8304\n",
            "Epoch [43/50] - Batch loss: 153.3883 - Epoch Loss: 59178.1541 - Avg Loss: 160.8102\n",
            "Epoch [43/50] - Batch loss: 155.8163 - Epoch Loss: 59333.9704 - Avg Loss: 160.7967\n",
            "Epoch [43/50] - Batch loss: 155.9062 - Epoch Loss: 59489.8766 - Avg Loss: 160.7835\n",
            "Epoch [43/50] - Batch loss: 152.9699 - Epoch Loss: 59642.8465 - Avg Loss: 160.7624\n",
            "Epoch [43/50] - Batch loss: 159.6086 - Epoch Loss: 59802.4551 - Avg Loss: 160.7593\n",
            "Epoch [43/50] - Batch loss: 155.4708 - Epoch Loss: 59957.9259 - Avg Loss: 160.7451\n",
            "Epoch [43/50] - Batch loss: 158.3502 - Epoch Loss: 60116.2761 - Avg Loss: 160.7387\n",
            "Epoch [43/50] - Batch loss: 157.4045 - Epoch Loss: 60273.6806 - Avg Loss: 160.7298\n",
            "Epoch [43/50] - Batch loss: 164.7103 - Epoch Loss: 60438.3909 - Avg Loss: 160.7404\n",
            "Epoch [43/50] - Batch loss: 159.4343 - Epoch Loss: 60597.8252 - Avg Loss: 160.7369\n",
            "Epoch [43/50] - Batch loss: 160.2216 - Epoch Loss: 60758.0468 - Avg Loss: 160.7356\n",
            "Epoch [43/50] - Batch loss: 160.3420 - Epoch Loss: 60918.3888 - Avg Loss: 160.7345\n",
            "Epoch [43/50] - Batch loss: 160.8805 - Epoch Loss: 61079.2693 - Avg Loss: 160.7349\n",
            "Epoch [43/50] - Batch loss: 163.8403 - Epoch Loss: 61243.1096 - Avg Loss: 160.7431\n",
            "Epoch [43/50] - Batch loss: 158.3832 - Epoch Loss: 61401.4928 - Avg Loss: 160.7369\n",
            "Epoch [43/50] - Batch loss: 163.8114 - Epoch Loss: 61565.3043 - Avg Loss: 160.7449\n",
            "Epoch [43/50] - Batch loss: 158.9251 - Epoch Loss: 61724.2294 - Avg Loss: 160.7402\n",
            "Epoch [43/50] - Batch loss: 161.9009 - Epoch Loss: 61886.1302 - Avg Loss: 160.7432\n",
            "Epoch [43/50] - Batch loss: 161.9119 - Epoch Loss: 62048.0422 - Avg Loss: 160.7462\n",
            "Epoch [43/50] - Batch loss: 151.8730 - Epoch Loss: 62199.9151 - Avg Loss: 160.7233\n",
            "Epoch [43/50] - Batch loss: 157.2505 - Epoch Loss: 62357.1657 - Avg Loss: 160.7143\n",
            "Epoch [43/50] - Batch loss: 156.6005 - Epoch Loss: 62513.7662 - Avg Loss: 160.7038\n",
            "Epoch [43/50] - Batch loss: 159.5305 - Epoch Loss: 62673.2967 - Avg Loss: 160.7008\n",
            "Epoch [43/50] - Batch loss: 165.1979 - Epoch Loss: 62838.4946 - Avg Loss: 160.7123\n",
            "Epoch [43/50] - Batch loss: 159.4141 - Epoch Loss: 62997.9087 - Avg Loss: 160.7090\n",
            "Epoch [43/50] - Batch loss: 156.5250 - Epoch Loss: 63154.4337 - Avg Loss: 160.6983\n",
            "Epoch [43/50] - Batch loss: 164.5799 - Epoch Loss: 63319.0136 - Avg Loss: 160.7082\n",
            "Epoch [43/50] - Batch loss: 159.4049 - Epoch Loss: 63478.4184 - Avg Loss: 160.7049\n",
            "Epoch [43/50] - Batch loss: 165.6290 - Epoch Loss: 63644.0474 - Avg Loss: 160.7173\n",
            "Epoch [43/50] - Batch loss: 156.6499 - Epoch Loss: 63800.6973 - Avg Loss: 160.7070\n",
            "Epoch [43/50] - Batch loss: 162.3405 - Epoch Loss: 63963.0378 - Avg Loss: 160.7112\n",
            "Epoch [43/50] - Batch loss: 152.5395 - Epoch Loss: 64115.5773 - Avg Loss: 160.6907\n",
            "Epoch [43/50] - Batch loss: 147.0107 - Epoch Loss: 64262.5880 - Avg Loss: 160.6565\n",
            "Epoch [43/50] - Batch loss: 163.3260 - Epoch Loss: 64425.9140 - Avg Loss: 160.6631\n",
            "Epoch [43/50] - Batch loss: 161.6802 - Epoch Loss: 64587.5942 - Avg Loss: 160.6657\n",
            "Epoch [43/50] - Batch loss: 160.7645 - Epoch Loss: 64748.3587 - Avg Loss: 160.6659\n",
            "Epoch [43/50] - Batch loss: 160.1871 - Epoch Loss: 64908.5458 - Avg Loss: 160.6647\n",
            "Epoch [43/50] - Batch loss: 156.0674 - Epoch Loss: 65064.6132 - Avg Loss: 160.6534\n",
            "Epoch [43/50] - Batch loss: 166.8064 - Epoch Loss: 65231.4196 - Avg Loss: 160.6685\n",
            "Epoch [43/50] - Batch loss: 160.3599 - Epoch Loss: 65391.7795 - Avg Loss: 160.6678\n",
            "Epoch [43/50] - Batch loss: 161.4403 - Epoch Loss: 65553.2198 - Avg Loss: 160.6697\n",
            "Epoch [43/50] - Batch loss: 156.5444 - Epoch Loss: 65709.7642 - Avg Loss: 160.6596\n",
            "Epoch [43/50] - Batch loss: 162.1968 - Epoch Loss: 65871.9610 - Avg Loss: 160.6633\n",
            "Epoch [43/50] - Batch loss: 167.2965 - Epoch Loss: 66039.2575 - Avg Loss: 160.6795\n",
            "Epoch [43/50] - Batch loss: 155.4541 - Epoch Loss: 66194.7116 - Avg Loss: 160.6668\n",
            "Epoch [43/50] - Batch loss: 160.7659 - Epoch Loss: 66355.4776 - Avg Loss: 160.6670\n",
            "Epoch [43/50] - Batch loss: 157.3879 - Epoch Loss: 66512.8654 - Avg Loss: 160.6591\n",
            "Epoch [43/50] - Batch loss: 164.0354 - Epoch Loss: 66676.9008 - Avg Loss: 160.6672\n",
            "Epoch [43/50] - Batch loss: 157.0905 - Epoch Loss: 66833.9914 - Avg Loss: 160.6586\n",
            "Epoch [43/50] - Batch loss: 156.6353 - Epoch Loss: 66990.6267 - Avg Loss: 160.6490\n",
            "Epoch [43/50] - Batch loss: 153.7904 - Epoch Loss: 67144.4171 - Avg Loss: 160.6326\n",
            "Epoch [43/50] - Batch loss: 168.4499 - Epoch Loss: 67312.8671 - Avg Loss: 160.6512\n",
            "Epoch [43/50] - Batch loss: 160.9433 - Epoch Loss: 67473.8104 - Avg Loss: 160.6519\n",
            "Epoch [43/50] - Batch loss: 158.7231 - Epoch Loss: 67632.5336 - Avg Loss: 160.6473\n",
            "Epoch [43/50] - Batch loss: 158.6332 - Epoch Loss: 67791.1667 - Avg Loss: 160.6426\n",
            "Epoch [43/50] - Batch loss: 159.9931 - Epoch Loss: 67951.1598 - Avg Loss: 160.6410\n",
            "Epoch [43/50] - Batch loss: 164.3693 - Epoch Loss: 68115.5291 - Avg Loss: 160.6498\n",
            "Epoch [43/50] - Batch loss: 161.4654 - Epoch Loss: 68276.9945 - Avg Loss: 160.6518\n",
            "Epoch [43/50] - Batch loss: 153.4557 - Epoch Loss: 68430.4502 - Avg Loss: 160.6349\n",
            "Epoch [43/50] - Batch loss: 168.8915 - Epoch Loss: 68599.3417 - Avg Loss: 160.6542\n",
            "Epoch [43/50] - Batch loss: 157.8208 - Epoch Loss: 68757.1626 - Avg Loss: 160.6476\n",
            "Epoch [43/50] - Batch loss: 163.8010 - Epoch Loss: 68920.9636 - Avg Loss: 160.6549\n",
            "Epoch [43/50] - Batch loss: 164.3755 - Epoch Loss: 69085.3391 - Avg Loss: 160.6636\n",
            "Epoch [43/50] - Batch loss: 162.5227 - Epoch Loss: 69247.8619 - Avg Loss: 160.6679\n",
            "Epoch [43/50] - Batch loss: 163.9187 - Epoch Loss: 69411.7806 - Avg Loss: 160.6754\n",
            "Epoch [43/50] - Batch loss: 158.5271 - Epoch Loss: 69570.3077 - Avg Loss: 160.6705\n",
            "Epoch [43/50] - Batch loss: 153.3544 - Epoch Loss: 69723.6621 - Avg Loss: 160.6536\n",
            "Epoch [43/50] - Batch loss: 165.1364 - Epoch Loss: 69888.7985 - Avg Loss: 160.6639\n",
            "Epoch [43/50] - Batch loss: 158.7999 - Epoch Loss: 70047.5985 - Avg Loss: 160.6596\n",
            "Epoch [43/50] - Batch loss: 171.9168 - Epoch Loss: 70219.5153 - Avg Loss: 160.6854\n",
            "Epoch [43/50] - Batch loss: 156.8141 - Epoch Loss: 70376.3294 - Avg Loss: 160.6766\n",
            "Epoch [43/50] - Batch loss: 167.2668 - Epoch Loss: 70543.5962 - Avg Loss: 160.6916\n",
            "Epoch [43/50] - Batch loss: 162.9571 - Epoch Loss: 70706.5533 - Avg Loss: 160.6967\n",
            "Epoch [43/50] - Batch loss: 162.8908 - Epoch Loss: 70869.4441 - Avg Loss: 160.7017\n",
            "Epoch [43/50] - Batch loss: 158.6489 - Epoch Loss: 71028.0930 - Avg Loss: 160.6970\n",
            "Epoch [43/50] - Batch loss: 157.8732 - Epoch Loss: 71185.9662 - Avg Loss: 160.6907\n",
            "Epoch [43/50] - Batch loss: 160.1193 - Epoch Loss: 71346.0855 - Avg Loss: 160.6894\n",
            "Epoch [43/50] - Batch loss: 158.8950 - Epoch Loss: 71504.9805 - Avg Loss: 160.6853\n",
            "Epoch [43/50] - Batch loss: 157.6671 - Epoch Loss: 71662.6476 - Avg Loss: 160.6786\n",
            "Epoch [43/50] - Batch loss: 162.0874 - Epoch Loss: 71824.7351 - Avg Loss: 160.6817\n",
            "Epoch [43/50] - Batch loss: 158.6647 - Epoch Loss: 71983.3997 - Avg Loss: 160.6772\n",
            "Epoch [43/50] - Batch loss: 162.0005 - Epoch Loss: 72145.4003 - Avg Loss: 160.6802\n",
            "Epoch [43/50] - Batch loss: 160.6606 - Epoch Loss: 72306.0609 - Avg Loss: 160.6801\n",
            "Epoch [43/50] - Batch loss: 161.3254 - Epoch Loss: 72467.3863 - Avg Loss: 160.6816\n",
            "Epoch [43/50] - Batch loss: 158.0882 - Epoch Loss: 72625.4745 - Avg Loss: 160.6758\n",
            "Epoch [43/50] - Batch loss: 160.5263 - Epoch Loss: 72786.0008 - Avg Loss: 160.6755\n",
            "Epoch [43/50] - Batch loss: 167.6868 - Epoch Loss: 72953.6876 - Avg Loss: 160.6909\n",
            "Epoch [43/50] - Batch loss: 168.4847 - Epoch Loss: 73122.1723 - Avg Loss: 160.7081\n",
            "Epoch [43/50] - Batch loss: 154.0154 - Epoch Loss: 73276.1877 - Avg Loss: 160.6934\n",
            "Epoch [43/50] - Batch loss: 156.5425 - Epoch Loss: 73432.7302 - Avg Loss: 160.6843\n",
            "Epoch [43/50] - Batch loss: 156.3742 - Epoch Loss: 73589.1044 - Avg Loss: 160.6749\n",
            "Epoch [43/50] - Batch loss: 164.8854 - Epoch Loss: 73753.9899 - Avg Loss: 160.6841\n",
            "Epoch [43/50] - Batch loss: 159.7470 - Epoch Loss: 73913.7369 - Avg Loss: 160.6820\n",
            "Epoch [43/50] - Batch loss: 161.4760 - Epoch Loss: 74075.2129 - Avg Loss: 160.6838\n",
            "Epoch [43/50] - Batch loss: 162.5022 - Epoch Loss: 74237.7151 - Avg Loss: 160.6877\n",
            "Epoch [43/50] - Batch loss: 168.4332 - Epoch Loss: 74406.1482 - Avg Loss: 160.7044\n",
            "Epoch [43/50] - Batch loss: 161.7213 - Epoch Loss: 74567.8695 - Avg Loss: 160.7066\n",
            "Epoch [43/50] - Batch loss: 160.5335 - Epoch Loss: 74728.4030 - Avg Loss: 160.7062\n",
            "Epoch [43/50] - Batch loss: 159.6575 - Epoch Loss: 74888.0604 - Avg Loss: 160.7040\n",
            "Epoch [43/50] - Batch loss: 149.9101 - Epoch Loss: 75037.9705 - Avg Loss: 160.6809\n",
            "Epoch [43/50] - Batch loss: 159.8036 - Epoch Loss: 75197.7741 - Avg Loss: 160.6790\n",
            "Epoch [43/50] - Batch loss: 171.5508 - Epoch Loss: 75369.3249 - Avg Loss: 160.7022\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 44/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebd51b28a1d447da900283d7f82eca1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [44/50] - Batch loss: 162.3035 - Epoch Loss: 162.3035 - Avg Loss: 162.3035\n",
            "Epoch [44/50] - Batch loss: 160.8574 - Epoch Loss: 323.1610 - Avg Loss: 161.5805\n",
            "Epoch [44/50] - Batch loss: 164.1297 - Epoch Loss: 487.2906 - Avg Loss: 162.4302\n",
            "Epoch [44/50] - Batch loss: 161.6141 - Epoch Loss: 648.9047 - Avg Loss: 162.2262\n",
            "Epoch [44/50] - Batch loss: 154.8161 - Epoch Loss: 803.7209 - Avg Loss: 160.7442\n",
            "Epoch [44/50] - Batch loss: 167.7445 - Epoch Loss: 971.4654 - Avg Loss: 161.9109\n",
            "Epoch [44/50] - Batch loss: 155.6499 - Epoch Loss: 1127.1153 - Avg Loss: 161.0165\n",
            "Epoch [44/50] - Batch loss: 160.5441 - Epoch Loss: 1287.6594 - Avg Loss: 160.9574\n",
            "Epoch [44/50] - Batch loss: 161.4526 - Epoch Loss: 1449.1120 - Avg Loss: 161.0124\n",
            "Epoch [44/50] - Batch loss: 158.5583 - Epoch Loss: 1607.6703 - Avg Loss: 160.7670\n",
            "Epoch [44/50] - Batch loss: 157.1818 - Epoch Loss: 1764.8521 - Avg Loss: 160.4411\n",
            "Epoch [44/50] - Batch loss: 169.7955 - Epoch Loss: 1934.6476 - Avg Loss: 161.2206\n",
            "Epoch [44/50] - Batch loss: 157.5204 - Epoch Loss: 2092.1680 - Avg Loss: 160.9360\n",
            "Epoch [44/50] - Batch loss: 159.5594 - Epoch Loss: 2251.7274 - Avg Loss: 160.8377\n",
            "Epoch [44/50] - Batch loss: 165.1176 - Epoch Loss: 2416.8450 - Avg Loss: 161.1230\n",
            "Epoch [44/50] - Batch loss: 157.6357 - Epoch Loss: 2574.4807 - Avg Loss: 160.9050\n",
            "Epoch [44/50] - Batch loss: 153.6942 - Epoch Loss: 2728.1749 - Avg Loss: 160.4809\n",
            "Epoch [44/50] - Batch loss: 153.5798 - Epoch Loss: 2881.7547 - Avg Loss: 160.0975\n",
            "Epoch [44/50] - Batch loss: 163.6825 - Epoch Loss: 3045.4372 - Avg Loss: 160.2862\n",
            "Epoch [44/50] - Batch loss: 165.8702 - Epoch Loss: 3211.3074 - Avg Loss: 160.5654\n",
            "Epoch [44/50] - Batch loss: 149.2271 - Epoch Loss: 3360.5346 - Avg Loss: 160.0255\n",
            "Epoch [44/50] - Batch loss: 152.6547 - Epoch Loss: 3513.1893 - Avg Loss: 159.6904\n",
            "Epoch [44/50] - Batch loss: 164.8535 - Epoch Loss: 3678.0427 - Avg Loss: 159.9149\n",
            "Epoch [44/50] - Batch loss: 155.8833 - Epoch Loss: 3833.9260 - Avg Loss: 159.7469\n",
            "Epoch [44/50] - Batch loss: 163.5816 - Epoch Loss: 3997.5076 - Avg Loss: 159.9003\n",
            "Epoch [44/50] - Batch loss: 157.7431 - Epoch Loss: 4155.2508 - Avg Loss: 159.8173\n",
            "Epoch [44/50] - Batch loss: 163.8368 - Epoch Loss: 4319.0876 - Avg Loss: 159.9662\n",
            "Epoch [44/50] - Batch loss: 159.5526 - Epoch Loss: 4478.6402 - Avg Loss: 159.9514\n",
            "Epoch [44/50] - Batch loss: 156.9626 - Epoch Loss: 4635.6028 - Avg Loss: 159.8484\n",
            "Epoch [44/50] - Batch loss: 157.2795 - Epoch Loss: 4792.8823 - Avg Loss: 159.7627\n",
            "Epoch [44/50] - Batch loss: 163.2072 - Epoch Loss: 4956.0895 - Avg Loss: 159.8739\n",
            "Epoch [44/50] - Batch loss: 154.2567 - Epoch Loss: 5110.3461 - Avg Loss: 159.6983\n",
            "Epoch [44/50] - Batch loss: 164.1914 - Epoch Loss: 5274.5375 - Avg Loss: 159.8345\n",
            "Epoch [44/50] - Batch loss: 161.4880 - Epoch Loss: 5436.0255 - Avg Loss: 159.8831\n",
            "Epoch [44/50] - Batch loss: 164.8996 - Epoch Loss: 5600.9251 - Avg Loss: 160.0264\n",
            "Epoch [44/50] - Batch loss: 154.8202 - Epoch Loss: 5755.7453 - Avg Loss: 159.8818\n",
            "Epoch [44/50] - Batch loss: 159.2561 - Epoch Loss: 5915.0014 - Avg Loss: 159.8649\n",
            "Epoch [44/50] - Batch loss: 159.9948 - Epoch Loss: 6074.9963 - Avg Loss: 159.8683\n",
            "Epoch [44/50] - Batch loss: 161.9029 - Epoch Loss: 6236.8991 - Avg Loss: 159.9205\n",
            "Epoch [44/50] - Batch loss: 156.9360 - Epoch Loss: 6393.8351 - Avg Loss: 159.8459\n",
            "Epoch [44/50] - Batch loss: 161.3739 - Epoch Loss: 6555.2091 - Avg Loss: 159.8831\n",
            "Epoch [44/50] - Batch loss: 157.6916 - Epoch Loss: 6712.9007 - Avg Loss: 159.8310\n",
            "Epoch [44/50] - Batch loss: 163.3055 - Epoch Loss: 6876.2062 - Avg Loss: 159.9118\n",
            "Epoch [44/50] - Batch loss: 155.9537 - Epoch Loss: 7032.1599 - Avg Loss: 159.8218\n",
            "Epoch [44/50] - Batch loss: 160.3051 - Epoch Loss: 7192.4650 - Avg Loss: 159.8326\n",
            "Epoch [44/50] - Batch loss: 168.0047 - Epoch Loss: 7360.4697 - Avg Loss: 160.0102\n",
            "Epoch [44/50] - Batch loss: 159.6304 - Epoch Loss: 7520.1001 - Avg Loss: 160.0021\n",
            "Epoch [44/50] - Batch loss: 155.4597 - Epoch Loss: 7675.5598 - Avg Loss: 159.9075\n",
            "Epoch [44/50] - Batch loss: 169.1700 - Epoch Loss: 7844.7298 - Avg Loss: 160.0965\n",
            "Epoch [44/50] - Batch loss: 161.3574 - Epoch Loss: 8006.0872 - Avg Loss: 160.1217\n",
            "Epoch [44/50] - Batch loss: 162.9703 - Epoch Loss: 8169.0575 - Avg Loss: 160.1776\n",
            "Epoch [44/50] - Batch loss: 159.5886 - Epoch Loss: 8328.6461 - Avg Loss: 160.1663\n",
            "Epoch [44/50] - Batch loss: 158.6684 - Epoch Loss: 8487.3145 - Avg Loss: 160.1380\n",
            "Epoch [44/50] - Batch loss: 158.3560 - Epoch Loss: 8645.6705 - Avg Loss: 160.1050\n",
            "Epoch [44/50] - Batch loss: 155.0585 - Epoch Loss: 8800.7290 - Avg Loss: 160.0133\n",
            "Epoch [44/50] - Batch loss: 160.7863 - Epoch Loss: 8961.5153 - Avg Loss: 160.0271\n",
            "Epoch [44/50] - Batch loss: 157.8298 - Epoch Loss: 9119.3452 - Avg Loss: 159.9885\n",
            "Epoch [44/50] - Batch loss: 163.2742 - Epoch Loss: 9282.6193 - Avg Loss: 160.0452\n",
            "Epoch [44/50] - Batch loss: 165.9509 - Epoch Loss: 9448.5703 - Avg Loss: 160.1453\n",
            "Epoch [44/50] - Batch loss: 157.5547 - Epoch Loss: 9606.1250 - Avg Loss: 160.1021\n",
            "Epoch [44/50] - Batch loss: 168.8532 - Epoch Loss: 9774.9781 - Avg Loss: 160.2455\n",
            "Epoch [44/50] - Batch loss: 157.2944 - Epoch Loss: 9932.2725 - Avg Loss: 160.1979\n",
            "Epoch [44/50] - Batch loss: 169.0050 - Epoch Loss: 10101.2775 - Avg Loss: 160.3377\n",
            "Epoch [44/50] - Batch loss: 160.5888 - Epoch Loss: 10261.8663 - Avg Loss: 160.3417\n",
            "Epoch [44/50] - Batch loss: 162.3585 - Epoch Loss: 10424.2247 - Avg Loss: 160.3727\n",
            "Epoch [44/50] - Batch loss: 162.4098 - Epoch Loss: 10586.6346 - Avg Loss: 160.4036\n",
            "Epoch [44/50] - Batch loss: 164.3079 - Epoch Loss: 10750.9424 - Avg Loss: 160.4618\n",
            "Epoch [44/50] - Batch loss: 163.0308 - Epoch Loss: 10913.9733 - Avg Loss: 160.4996\n",
            "Epoch [44/50] - Batch loss: 170.2184 - Epoch Loss: 11084.1917 - Avg Loss: 160.6405\n",
            "Epoch [44/50] - Batch loss: 165.8043 - Epoch Loss: 11249.9959 - Avg Loss: 160.7142\n",
            "Epoch [44/50] - Batch loss: 162.3273 - Epoch Loss: 11412.3232 - Avg Loss: 160.7369\n",
            "Epoch [44/50] - Batch loss: 160.7782 - Epoch Loss: 11573.1014 - Avg Loss: 160.7375\n",
            "Epoch [44/50] - Batch loss: 154.4306 - Epoch Loss: 11727.5320 - Avg Loss: 160.6511\n",
            "Epoch [44/50] - Batch loss: 151.3821 - Epoch Loss: 11878.9141 - Avg Loss: 160.5259\n",
            "Epoch [44/50] - Batch loss: 167.4856 - Epoch Loss: 12046.3997 - Avg Loss: 160.6187\n",
            "Epoch [44/50] - Batch loss: 160.7060 - Epoch Loss: 12207.1058 - Avg Loss: 160.6198\n",
            "Epoch [44/50] - Batch loss: 159.1640 - Epoch Loss: 12366.2698 - Avg Loss: 160.6009\n",
            "Epoch [44/50] - Batch loss: 158.8580 - Epoch Loss: 12525.1278 - Avg Loss: 160.5786\n",
            "Epoch [44/50] - Batch loss: 151.2603 - Epoch Loss: 12676.3881 - Avg Loss: 160.4606\n",
            "Epoch [44/50] - Batch loss: 154.7686 - Epoch Loss: 12831.1567 - Avg Loss: 160.3895\n",
            "Epoch [44/50] - Batch loss: 156.3700 - Epoch Loss: 12987.5267 - Avg Loss: 160.3398\n",
            "Epoch [44/50] - Batch loss: 161.3193 - Epoch Loss: 13148.8460 - Avg Loss: 160.3518\n",
            "Epoch [44/50] - Batch loss: 162.2906 - Epoch Loss: 13311.1366 - Avg Loss: 160.3751\n",
            "Epoch [44/50] - Batch loss: 162.7241 - Epoch Loss: 13473.8607 - Avg Loss: 160.4031\n",
            "Epoch [44/50] - Batch loss: 176.2083 - Epoch Loss: 13650.0690 - Avg Loss: 160.5890\n",
            "Epoch [44/50] - Batch loss: 163.0011 - Epoch Loss: 13813.0701 - Avg Loss: 160.6171\n",
            "Epoch [44/50] - Batch loss: 167.1776 - Epoch Loss: 13980.2477 - Avg Loss: 160.6925\n",
            "Epoch [44/50] - Batch loss: 159.4216 - Epoch Loss: 14139.6693 - Avg Loss: 160.6781\n",
            "Epoch [44/50] - Batch loss: 164.0782 - Epoch Loss: 14303.7475 - Avg Loss: 160.7163\n",
            "Epoch [44/50] - Batch loss: 157.7252 - Epoch Loss: 14461.4727 - Avg Loss: 160.6830\n",
            "Epoch [44/50] - Batch loss: 158.4920 - Epoch Loss: 14619.9647 - Avg Loss: 160.6590\n",
            "Epoch [44/50] - Batch loss: 158.9102 - Epoch Loss: 14778.8750 - Avg Loss: 160.6399\n",
            "Epoch [44/50] - Batch loss: 170.9615 - Epoch Loss: 14949.8364 - Avg Loss: 160.7509\n",
            "Epoch [44/50] - Batch loss: 169.4352 - Epoch Loss: 15119.2716 - Avg Loss: 160.8433\n",
            "Epoch [44/50] - Batch loss: 160.0610 - Epoch Loss: 15279.3326 - Avg Loss: 160.8351\n",
            "Epoch [44/50] - Batch loss: 160.3853 - Epoch Loss: 15439.7179 - Avg Loss: 160.8304\n",
            "Epoch [44/50] - Batch loss: 157.6284 - Epoch Loss: 15597.3463 - Avg Loss: 160.7974\n",
            "Epoch [44/50] - Batch loss: 161.5574 - Epoch Loss: 15758.9037 - Avg Loss: 160.8051\n",
            "Epoch [44/50] - Batch loss: 170.4045 - Epoch Loss: 15929.3082 - Avg Loss: 160.9021\n",
            "Epoch [44/50] - Batch loss: 153.5802 - Epoch Loss: 16082.8884 - Avg Loss: 160.8289\n",
            "Epoch [44/50] - Batch loss: 156.5817 - Epoch Loss: 16239.4702 - Avg Loss: 160.7868\n",
            "Epoch [44/50] - Batch loss: 165.3762 - Epoch Loss: 16404.8464 - Avg Loss: 160.8318\n",
            "Epoch [44/50] - Batch loss: 157.4131 - Epoch Loss: 16562.2595 - Avg Loss: 160.7986\n",
            "Epoch [44/50] - Batch loss: 160.5419 - Epoch Loss: 16722.8014 - Avg Loss: 160.7962\n",
            "Epoch [44/50] - Batch loss: 157.3837 - Epoch Loss: 16880.1851 - Avg Loss: 160.7637\n",
            "Epoch [44/50] - Batch loss: 162.3427 - Epoch Loss: 17042.5277 - Avg Loss: 160.7786\n",
            "Epoch [44/50] - Batch loss: 161.5449 - Epoch Loss: 17204.0726 - Avg Loss: 160.7857\n",
            "Epoch [44/50] - Batch loss: 159.1203 - Epoch Loss: 17363.1929 - Avg Loss: 160.7703\n",
            "Epoch [44/50] - Batch loss: 153.8362 - Epoch Loss: 17517.0291 - Avg Loss: 160.7067\n",
            "Epoch [44/50] - Batch loss: 165.0172 - Epoch Loss: 17682.0463 - Avg Loss: 160.7459\n",
            "Epoch [44/50] - Batch loss: 154.6732 - Epoch Loss: 17836.7195 - Avg Loss: 160.6912\n",
            "Epoch [44/50] - Batch loss: 163.0586 - Epoch Loss: 17999.7780 - Avg Loss: 160.7123\n",
            "Epoch [44/50] - Batch loss: 154.3088 - Epoch Loss: 18154.0869 - Avg Loss: 160.6556\n",
            "Epoch [44/50] - Batch loss: 153.6833 - Epoch Loss: 18307.7701 - Avg Loss: 160.5945\n",
            "Epoch [44/50] - Batch loss: 165.4445 - Epoch Loss: 18473.2146 - Avg Loss: 160.6366\n",
            "Epoch [44/50] - Batch loss: 152.3570 - Epoch Loss: 18625.5716 - Avg Loss: 160.5653\n",
            "Epoch [44/50] - Batch loss: 156.4690 - Epoch Loss: 18782.0406 - Avg Loss: 160.5303\n",
            "Epoch [44/50] - Batch loss: 158.3166 - Epoch Loss: 18940.3572 - Avg Loss: 160.5115\n",
            "Epoch [44/50] - Batch loss: 163.7368 - Epoch Loss: 19104.0940 - Avg Loss: 160.5386\n",
            "Epoch [44/50] - Batch loss: 164.3918 - Epoch Loss: 19268.4857 - Avg Loss: 160.5707\n",
            "Epoch [44/50] - Batch loss: 163.2426 - Epoch Loss: 19431.7283 - Avg Loss: 160.5928\n",
            "Epoch [44/50] - Batch loss: 160.2720 - Epoch Loss: 19592.0003 - Avg Loss: 160.5902\n",
            "Epoch [44/50] - Batch loss: 167.7144 - Epoch Loss: 19759.7147 - Avg Loss: 160.6481\n",
            "Epoch [44/50] - Batch loss: 164.8772 - Epoch Loss: 19924.5919 - Avg Loss: 160.6822\n",
            "Epoch [44/50] - Batch loss: 170.0781 - Epoch Loss: 20094.6700 - Avg Loss: 160.7574\n",
            "Epoch [44/50] - Batch loss: 164.8741 - Epoch Loss: 20259.5441 - Avg Loss: 160.7900\n",
            "Epoch [44/50] - Batch loss: 162.8138 - Epoch Loss: 20422.3579 - Avg Loss: 160.8060\n",
            "Epoch [44/50] - Batch loss: 148.1740 - Epoch Loss: 20570.5319 - Avg Loss: 160.7073\n",
            "Epoch [44/50] - Batch loss: 164.1485 - Epoch Loss: 20734.6804 - Avg Loss: 160.7340\n",
            "Epoch [44/50] - Batch loss: 155.4673 - Epoch Loss: 20890.1476 - Avg Loss: 160.6934\n",
            "Epoch [44/50] - Batch loss: 170.3015 - Epoch Loss: 21060.4491 - Avg Loss: 160.7668\n",
            "Epoch [44/50] - Batch loss: 156.6160 - Epoch Loss: 21217.0651 - Avg Loss: 160.7353\n",
            "Epoch [44/50] - Batch loss: 166.0905 - Epoch Loss: 21383.1556 - Avg Loss: 160.7756\n",
            "Epoch [44/50] - Batch loss: 151.0500 - Epoch Loss: 21534.2056 - Avg Loss: 160.7030\n",
            "Epoch [44/50] - Batch loss: 164.7803 - Epoch Loss: 21698.9859 - Avg Loss: 160.7332\n",
            "Epoch [44/50] - Batch loss: 161.2254 - Epoch Loss: 21860.2113 - Avg Loss: 160.7368\n",
            "Epoch [44/50] - Batch loss: 165.3661 - Epoch Loss: 22025.5774 - Avg Loss: 160.7706\n",
            "Epoch [44/50] - Batch loss: 162.7864 - Epoch Loss: 22188.3638 - Avg Loss: 160.7852\n",
            "Epoch [44/50] - Batch loss: 165.7746 - Epoch Loss: 22354.1384 - Avg Loss: 160.8211\n",
            "Epoch [44/50] - Batch loss: 157.2636 - Epoch Loss: 22511.4020 - Avg Loss: 160.7957\n",
            "Epoch [44/50] - Batch loss: 169.7219 - Epoch Loss: 22681.1239 - Avg Loss: 160.8590\n",
            "Epoch [44/50] - Batch loss: 155.7731 - Epoch Loss: 22836.8970 - Avg Loss: 160.8232\n",
            "Epoch [44/50] - Batch loss: 159.6962 - Epoch Loss: 22996.5933 - Avg Loss: 160.8153\n",
            "Epoch [44/50] - Batch loss: 156.7694 - Epoch Loss: 23153.3627 - Avg Loss: 160.7872\n",
            "Epoch [44/50] - Batch loss: 159.4919 - Epoch Loss: 23312.8546 - Avg Loss: 160.7783\n",
            "Epoch [44/50] - Batch loss: 155.3831 - Epoch Loss: 23468.2377 - Avg Loss: 160.7414\n",
            "Epoch [44/50] - Batch loss: 165.2882 - Epoch Loss: 23633.5259 - Avg Loss: 160.7723\n",
            "Epoch [44/50] - Batch loss: 160.8564 - Epoch Loss: 23794.3823 - Avg Loss: 160.7729\n",
            "Epoch [44/50] - Batch loss: 165.7197 - Epoch Loss: 23960.1019 - Avg Loss: 160.8061\n",
            "Epoch [44/50] - Batch loss: 167.7216 - Epoch Loss: 24127.8235 - Avg Loss: 160.8522\n",
            "Epoch [44/50] - Batch loss: 156.1266 - Epoch Loss: 24283.9501 - Avg Loss: 160.8209\n",
            "Epoch [44/50] - Batch loss: 166.3022 - Epoch Loss: 24450.2524 - Avg Loss: 160.8569\n",
            "Epoch [44/50] - Batch loss: 162.8308 - Epoch Loss: 24613.0832 - Avg Loss: 160.8698\n",
            "Epoch [44/50] - Batch loss: 163.4288 - Epoch Loss: 24776.5121 - Avg Loss: 160.8864\n",
            "Epoch [44/50] - Batch loss: 163.3342 - Epoch Loss: 24939.8463 - Avg Loss: 160.9022\n",
            "Epoch [44/50] - Batch loss: 154.7013 - Epoch Loss: 25094.5475 - Avg Loss: 160.8625\n",
            "Epoch [44/50] - Batch loss: 161.4214 - Epoch Loss: 25255.9689 - Avg Loss: 160.8660\n",
            "Epoch [44/50] - Batch loss: 169.8282 - Epoch Loss: 25425.7971 - Avg Loss: 160.9228\n",
            "Epoch [44/50] - Batch loss: 155.6555 - Epoch Loss: 25581.4526 - Avg Loss: 160.8896\n",
            "Epoch [44/50] - Batch loss: 164.6346 - Epoch Loss: 25746.0872 - Avg Loss: 160.9130\n",
            "Epoch [44/50] - Batch loss: 161.1809 - Epoch Loss: 25907.2682 - Avg Loss: 160.9147\n",
            "Epoch [44/50] - Batch loss: 157.9700 - Epoch Loss: 26065.2382 - Avg Loss: 160.8965\n",
            "Epoch [44/50] - Batch loss: 162.6958 - Epoch Loss: 26227.9339 - Avg Loss: 160.9076\n",
            "Epoch [44/50] - Batch loss: 172.8002 - Epoch Loss: 26400.7342 - Avg Loss: 160.9801\n",
            "Epoch [44/50] - Batch loss: 163.8580 - Epoch Loss: 26564.5922 - Avg Loss: 160.9975\n",
            "Epoch [44/50] - Batch loss: 163.6571 - Epoch Loss: 26728.2493 - Avg Loss: 161.0135\n",
            "Epoch [44/50] - Batch loss: 154.5320 - Epoch Loss: 26882.7813 - Avg Loss: 160.9747\n",
            "Epoch [44/50] - Batch loss: 159.3732 - Epoch Loss: 27042.1545 - Avg Loss: 160.9652\n",
            "Epoch [44/50] - Batch loss: 162.9807 - Epoch Loss: 27205.1352 - Avg Loss: 160.9771\n",
            "Epoch [44/50] - Batch loss: 165.6167 - Epoch Loss: 27370.7519 - Avg Loss: 161.0044\n",
            "Epoch [44/50] - Batch loss: 167.3423 - Epoch Loss: 27538.0942 - Avg Loss: 161.0415\n",
            "Epoch [44/50] - Batch loss: 157.0117 - Epoch Loss: 27695.1059 - Avg Loss: 161.0181\n",
            "Epoch [44/50] - Batch loss: 161.3549 - Epoch Loss: 27856.4608 - Avg Loss: 161.0200\n",
            "Epoch [44/50] - Batch loss: 161.2419 - Epoch Loss: 28017.7027 - Avg Loss: 161.0213\n",
            "Epoch [44/50] - Batch loss: 163.0155 - Epoch Loss: 28180.7182 - Avg Loss: 161.0327\n",
            "Epoch [44/50] - Batch loss: 159.8842 - Epoch Loss: 28340.6024 - Avg Loss: 161.0261\n",
            "Epoch [44/50] - Batch loss: 152.8627 - Epoch Loss: 28493.4651 - Avg Loss: 160.9800\n",
            "Epoch [44/50] - Batch loss: 167.9352 - Epoch Loss: 28661.4002 - Avg Loss: 161.0191\n",
            "Epoch [44/50] - Batch loss: 159.4553 - Epoch Loss: 28820.8555 - Avg Loss: 161.0104\n",
            "Epoch [44/50] - Batch loss: 164.2355 - Epoch Loss: 28985.0911 - Avg Loss: 161.0283\n",
            "Epoch [44/50] - Batch loss: 161.6603 - Epoch Loss: 29146.7514 - Avg Loss: 161.0318\n",
            "Epoch [44/50] - Batch loss: 156.1594 - Epoch Loss: 29302.9107 - Avg Loss: 161.0050\n",
            "Epoch [44/50] - Batch loss: 152.1186 - Epoch Loss: 29455.0293 - Avg Loss: 160.9564\n",
            "Epoch [44/50] - Batch loss: 161.9952 - Epoch Loss: 29617.0245 - Avg Loss: 160.9621\n",
            "Epoch [44/50] - Batch loss: 166.0482 - Epoch Loss: 29783.0727 - Avg Loss: 160.9896\n",
            "Epoch [44/50] - Batch loss: 157.2455 - Epoch Loss: 29940.3182 - Avg Loss: 160.9695\n",
            "Epoch [44/50] - Batch loss: 152.7585 - Epoch Loss: 30093.0767 - Avg Loss: 160.9255\n",
            "Epoch [44/50] - Batch loss: 167.2292 - Epoch Loss: 30260.3059 - Avg Loss: 160.9591\n",
            "Epoch [44/50] - Batch loss: 163.9246 - Epoch Loss: 30424.2305 - Avg Loss: 160.9748\n",
            "Epoch [44/50] - Batch loss: 160.8164 - Epoch Loss: 30585.0469 - Avg Loss: 160.9739\n",
            "Epoch [44/50] - Batch loss: 156.3521 - Epoch Loss: 30741.3990 - Avg Loss: 160.9497\n",
            "Epoch [44/50] - Batch loss: 163.6069 - Epoch Loss: 30905.0058 - Avg Loss: 160.9636\n",
            "Epoch [44/50] - Batch loss: 158.1929 - Epoch Loss: 31063.1988 - Avg Loss: 160.9492\n",
            "Epoch [44/50] - Batch loss: 159.6429 - Epoch Loss: 31222.8416 - Avg Loss: 160.9425\n",
            "Epoch [44/50] - Batch loss: 167.4391 - Epoch Loss: 31390.2807 - Avg Loss: 160.9758\n",
            "Epoch [44/50] - Batch loss: 161.7314 - Epoch Loss: 31552.0122 - Avg Loss: 160.9797\n",
            "Epoch [44/50] - Batch loss: 159.2315 - Epoch Loss: 31711.2437 - Avg Loss: 160.9708\n",
            "Epoch [44/50] - Batch loss: 173.6622 - Epoch Loss: 31884.9060 - Avg Loss: 161.0349\n",
            "Epoch [44/50] - Batch loss: 161.5242 - Epoch Loss: 32046.4302 - Avg Loss: 161.0373\n",
            "Epoch [44/50] - Batch loss: 164.8989 - Epoch Loss: 32211.3291 - Avg Loss: 161.0566\n",
            "Epoch [44/50] - Batch loss: 158.6860 - Epoch Loss: 32370.0150 - Avg Loss: 161.0449\n",
            "Epoch [44/50] - Batch loss: 155.7698 - Epoch Loss: 32525.7848 - Avg Loss: 161.0187\n",
            "Epoch [44/50] - Batch loss: 158.7206 - Epoch Loss: 32684.5054 - Avg Loss: 161.0074\n",
            "Epoch [44/50] - Batch loss: 163.1505 - Epoch Loss: 32847.6559 - Avg Loss: 161.0179\n",
            "Epoch [44/50] - Batch loss: 155.8645 - Epoch Loss: 33003.5204 - Avg Loss: 160.9928\n",
            "Epoch [44/50] - Batch loss: 161.6240 - Epoch Loss: 33165.1444 - Avg Loss: 160.9958\n",
            "Epoch [44/50] - Batch loss: 159.0687 - Epoch Loss: 33324.2131 - Avg Loss: 160.9865\n",
            "Epoch [44/50] - Batch loss: 151.8625 - Epoch Loss: 33476.0756 - Avg Loss: 160.9427\n",
            "Epoch [44/50] - Batch loss: 153.2617 - Epoch Loss: 33629.3373 - Avg Loss: 160.9059\n",
            "Epoch [44/50] - Batch loss: 170.0648 - Epoch Loss: 33799.4022 - Avg Loss: 160.9495\n",
            "Epoch [44/50] - Batch loss: 155.7321 - Epoch Loss: 33955.1342 - Avg Loss: 160.9248\n",
            "Epoch [44/50] - Batch loss: 162.6863 - Epoch Loss: 34117.8205 - Avg Loss: 160.9331\n",
            "Epoch [44/50] - Batch loss: 157.7460 - Epoch Loss: 34275.5665 - Avg Loss: 160.9182\n",
            "Epoch [44/50] - Batch loss: 163.5892 - Epoch Loss: 34439.1557 - Avg Loss: 160.9306\n",
            "Epoch [44/50] - Batch loss: 157.7060 - Epoch Loss: 34596.8618 - Avg Loss: 160.9156\n",
            "Epoch [44/50] - Batch loss: 156.3386 - Epoch Loss: 34753.2004 - Avg Loss: 160.8944\n",
            "Epoch [44/50] - Batch loss: 158.5593 - Epoch Loss: 34911.7597 - Avg Loss: 160.8837\n",
            "Epoch [44/50] - Batch loss: 161.0852 - Epoch Loss: 35072.8448 - Avg Loss: 160.8846\n",
            "Epoch [44/50] - Batch loss: 152.8777 - Epoch Loss: 35225.7226 - Avg Loss: 160.8480\n",
            "Epoch [44/50] - Batch loss: 161.4841 - Epoch Loss: 35387.2067 - Avg Loss: 160.8509\n",
            "Epoch [44/50] - Batch loss: 160.0346 - Epoch Loss: 35547.2413 - Avg Loss: 160.8472\n",
            "Epoch [44/50] - Batch loss: 158.6254 - Epoch Loss: 35705.8668 - Avg Loss: 160.8372\n",
            "Epoch [44/50] - Batch loss: 156.3054 - Epoch Loss: 35862.1722 - Avg Loss: 160.8169\n",
            "Epoch [44/50] - Batch loss: 158.4337 - Epoch Loss: 36020.6059 - Avg Loss: 160.8063\n",
            "Epoch [44/50] - Batch loss: 164.3795 - Epoch Loss: 36184.9854 - Avg Loss: 160.8222\n",
            "Epoch [44/50] - Batch loss: 164.8970 - Epoch Loss: 36349.8824 - Avg Loss: 160.8402\n",
            "Epoch [44/50] - Batch loss: 157.5115 - Epoch Loss: 36507.3939 - Avg Loss: 160.8255\n",
            "Epoch [44/50] - Batch loss: 159.0560 - Epoch Loss: 36666.4499 - Avg Loss: 160.8178\n",
            "Epoch [44/50] - Batch loss: 155.8719 - Epoch Loss: 36822.3218 - Avg Loss: 160.7962\n",
            "Epoch [44/50] - Batch loss: 163.0323 - Epoch Loss: 36985.3542 - Avg Loss: 160.8059\n",
            "Epoch [44/50] - Batch loss: 154.2502 - Epoch Loss: 37139.6043 - Avg Loss: 160.7775\n",
            "Epoch [44/50] - Batch loss: 162.7238 - Epoch Loss: 37302.3281 - Avg Loss: 160.7859\n",
            "Epoch [44/50] - Batch loss: 162.2777 - Epoch Loss: 37464.6059 - Avg Loss: 160.7923\n",
            "Epoch [44/50] - Batch loss: 156.2196 - Epoch Loss: 37620.8254 - Avg Loss: 160.7728\n",
            "Epoch [44/50] - Batch loss: 159.3719 - Epoch Loss: 37780.1973 - Avg Loss: 160.7668\n",
            "Epoch [44/50] - Batch loss: 163.3429 - Epoch Loss: 37943.5402 - Avg Loss: 160.7777\n",
            "Epoch [44/50] - Batch loss: 159.3335 - Epoch Loss: 38102.8736 - Avg Loss: 160.7716\n",
            "Epoch [44/50] - Batch loss: 163.8772 - Epoch Loss: 38266.7509 - Avg Loss: 160.7847\n",
            "Epoch [44/50] - Batch loss: 162.9759 - Epoch Loss: 38429.7268 - Avg Loss: 160.7938\n",
            "Epoch [44/50] - Batch loss: 164.0994 - Epoch Loss: 38593.8261 - Avg Loss: 160.8076\n",
            "Epoch [44/50] - Batch loss: 153.7594 - Epoch Loss: 38747.5855 - Avg Loss: 160.7784\n",
            "Epoch [44/50] - Batch loss: 156.8560 - Epoch Loss: 38904.4415 - Avg Loss: 160.7622\n",
            "Epoch [44/50] - Batch loss: 148.1685 - Epoch Loss: 39052.6100 - Avg Loss: 160.7103\n",
            "Epoch [44/50] - Batch loss: 161.9686 - Epoch Loss: 39214.5787 - Avg Loss: 160.7155\n",
            "Epoch [44/50] - Batch loss: 167.2436 - Epoch Loss: 39381.8223 - Avg Loss: 160.7421\n",
            "Epoch [44/50] - Batch loss: 157.5537 - Epoch Loss: 39539.3760 - Avg Loss: 160.7292\n",
            "Epoch [44/50] - Batch loss: 163.0864 - Epoch Loss: 39702.4624 - Avg Loss: 160.7387\n",
            "Epoch [44/50] - Batch loss: 168.3831 - Epoch Loss: 39870.8455 - Avg Loss: 160.7695\n",
            "Epoch [44/50] - Batch loss: 162.1974 - Epoch Loss: 40033.0429 - Avg Loss: 160.7753\n",
            "Epoch [44/50] - Batch loss: 157.3503 - Epoch Loss: 40190.3932 - Avg Loss: 160.7616\n",
            "Epoch [44/50] - Batch loss: 157.8708 - Epoch Loss: 40348.2640 - Avg Loss: 160.7501\n",
            "Epoch [44/50] - Batch loss: 160.3184 - Epoch Loss: 40508.5824 - Avg Loss: 160.7483\n",
            "Epoch [44/50] - Batch loss: 161.8106 - Epoch Loss: 40670.3930 - Avg Loss: 160.7525\n",
            "Epoch [44/50] - Batch loss: 160.3306 - Epoch Loss: 40830.7236 - Avg Loss: 160.7509\n",
            "Epoch [44/50] - Batch loss: 157.2372 - Epoch Loss: 40987.9609 - Avg Loss: 160.7371\n",
            "Epoch [44/50] - Batch loss: 158.5654 - Epoch Loss: 41146.5262 - Avg Loss: 160.7286\n",
            "Epoch [44/50] - Batch loss: 157.4553 - Epoch Loss: 41303.9816 - Avg Loss: 160.7159\n",
            "Epoch [44/50] - Batch loss: 150.0759 - Epoch Loss: 41454.0575 - Avg Loss: 160.6746\n",
            "Epoch [44/50] - Batch loss: 161.9672 - Epoch Loss: 41616.0247 - Avg Loss: 160.6796\n",
            "Epoch [44/50] - Batch loss: 160.2343 - Epoch Loss: 41776.2590 - Avg Loss: 160.6779\n",
            "Epoch [44/50] - Batch loss: 166.9817 - Epoch Loss: 41943.2407 - Avg Loss: 160.7021\n",
            "Epoch [44/50] - Batch loss: 157.8184 - Epoch Loss: 42101.0591 - Avg Loss: 160.6911\n",
            "Epoch [44/50] - Batch loss: 162.7645 - Epoch Loss: 42263.8236 - Avg Loss: 160.6989\n",
            "Epoch [44/50] - Batch loss: 162.5368 - Epoch Loss: 42426.3605 - Avg Loss: 160.7059\n",
            "Epoch [44/50] - Batch loss: 164.1411 - Epoch Loss: 42590.5015 - Avg Loss: 160.7189\n",
            "Epoch [44/50] - Batch loss: 155.1408 - Epoch Loss: 42745.6424 - Avg Loss: 160.6979\n",
            "Epoch [44/50] - Batch loss: 158.0303 - Epoch Loss: 42903.6727 - Avg Loss: 160.6879\n",
            "Epoch [44/50] - Batch loss: 155.4358 - Epoch Loss: 43059.1085 - Avg Loss: 160.6683\n",
            "Epoch [44/50] - Batch loss: 160.3155 - Epoch Loss: 43219.4240 - Avg Loss: 160.6670\n",
            "Epoch [44/50] - Batch loss: 164.7518 - Epoch Loss: 43384.1759 - Avg Loss: 160.6821\n",
            "Epoch [44/50] - Batch loss: 154.8389 - Epoch Loss: 43539.0148 - Avg Loss: 160.6606\n",
            "Epoch [44/50] - Batch loss: 151.0785 - Epoch Loss: 43690.0933 - Avg Loss: 160.6253\n",
            "Epoch [44/50] - Batch loss: 162.1145 - Epoch Loss: 43852.2078 - Avg Loss: 160.6308\n",
            "Epoch [44/50] - Batch loss: 155.9675 - Epoch Loss: 44008.1753 - Avg Loss: 160.6138\n",
            "Epoch [44/50] - Batch loss: 157.1636 - Epoch Loss: 44165.3389 - Avg Loss: 160.6012\n",
            "Epoch [44/50] - Batch loss: 163.0069 - Epoch Loss: 44328.3458 - Avg Loss: 160.6099\n",
            "Epoch [44/50] - Batch loss: 162.3788 - Epoch Loss: 44490.7246 - Avg Loss: 160.6163\n",
            "Epoch [44/50] - Batch loss: 157.6579 - Epoch Loss: 44648.3825 - Avg Loss: 160.6057\n",
            "Epoch [44/50] - Batch loss: 160.1190 - Epoch Loss: 44808.5015 - Avg Loss: 160.6039\n",
            "Epoch [44/50] - Batch loss: 166.5652 - Epoch Loss: 44975.0667 - Avg Loss: 160.6252\n",
            "Epoch [44/50] - Batch loss: 156.0515 - Epoch Loss: 45131.1182 - Avg Loss: 160.6090\n",
            "Epoch [44/50] - Batch loss: 149.2422 - Epoch Loss: 45280.3604 - Avg Loss: 160.5687\n",
            "Epoch [44/50] - Batch loss: 160.0058 - Epoch Loss: 45440.3661 - Avg Loss: 160.5667\n",
            "Epoch [44/50] - Batch loss: 157.7812 - Epoch Loss: 45598.1474 - Avg Loss: 160.5569\n",
            "Epoch [44/50] - Batch loss: 160.2877 - Epoch Loss: 45758.4350 - Avg Loss: 160.5559\n",
            "Epoch [44/50] - Batch loss: 155.2568 - Epoch Loss: 45913.6918 - Avg Loss: 160.5374\n",
            "Epoch [44/50] - Batch loss: 158.1217 - Epoch Loss: 46071.8135 - Avg Loss: 160.5290\n",
            "Epoch [44/50] - Batch loss: 161.4687 - Epoch Loss: 46233.2822 - Avg Loss: 160.5322\n",
            "Epoch [44/50] - Batch loss: 161.5682 - Epoch Loss: 46394.8504 - Avg Loss: 160.5358\n",
            "Epoch [44/50] - Batch loss: 157.7813 - Epoch Loss: 46552.6317 - Avg Loss: 160.5263\n",
            "Epoch [44/50] - Batch loss: 147.6010 - Epoch Loss: 46700.2327 - Avg Loss: 160.4819\n",
            "Epoch [44/50] - Batch loss: 151.3988 - Epoch Loss: 46851.6314 - Avg Loss: 160.4508\n",
            "Epoch [44/50] - Batch loss: 164.1958 - Epoch Loss: 47015.8273 - Avg Loss: 160.4636\n",
            "Epoch [44/50] - Batch loss: 155.4158 - Epoch Loss: 47171.2431 - Avg Loss: 160.4464\n",
            "Epoch [44/50] - Batch loss: 155.9321 - Epoch Loss: 47327.1752 - Avg Loss: 160.4311\n",
            "Epoch [44/50] - Batch loss: 152.9539 - Epoch Loss: 47480.1291 - Avg Loss: 160.4058\n",
            "Epoch [44/50] - Batch loss: 165.4126 - Epoch Loss: 47645.5416 - Avg Loss: 160.4227\n",
            "Epoch [44/50] - Batch loss: 163.1800 - Epoch Loss: 47808.7216 - Avg Loss: 160.4320\n",
            "Epoch [44/50] - Batch loss: 152.7495 - Epoch Loss: 47961.4711 - Avg Loss: 160.4063\n",
            "Epoch [44/50] - Batch loss: 159.7746 - Epoch Loss: 48121.2457 - Avg Loss: 160.4042\n",
            "Epoch [44/50] - Batch loss: 157.6633 - Epoch Loss: 48278.9090 - Avg Loss: 160.3950\n",
            "Epoch [44/50] - Batch loss: 165.1397 - Epoch Loss: 48444.0487 - Avg Loss: 160.4108\n",
            "Epoch [44/50] - Batch loss: 161.9720 - Epoch Loss: 48606.0206 - Avg Loss: 160.4159\n",
            "Epoch [44/50] - Batch loss: 154.0477 - Epoch Loss: 48760.0684 - Avg Loss: 160.3950\n",
            "Epoch [44/50] - Batch loss: 153.4229 - Epoch Loss: 48913.4913 - Avg Loss: 160.3721\n",
            "Epoch [44/50] - Batch loss: 156.3866 - Epoch Loss: 49069.8779 - Avg Loss: 160.3591\n",
            "Epoch [44/50] - Batch loss: 161.7010 - Epoch Loss: 49231.5790 - Avg Loss: 160.3634\n",
            "Epoch [44/50] - Batch loss: 156.6493 - Epoch Loss: 49388.2283 - Avg Loss: 160.3514\n",
            "Epoch [44/50] - Batch loss: 159.9813 - Epoch Loss: 49548.2096 - Avg Loss: 160.3502\n",
            "Epoch [44/50] - Batch loss: 159.0692 - Epoch Loss: 49707.2788 - Avg Loss: 160.3461\n",
            "Epoch [44/50] - Batch loss: 153.6459 - Epoch Loss: 49860.9247 - Avg Loss: 160.3245\n",
            "Epoch [44/50] - Batch loss: 156.8049 - Epoch Loss: 50017.7296 - Avg Loss: 160.3132\n",
            "Epoch [44/50] - Batch loss: 160.5871 - Epoch Loss: 50178.3166 - Avg Loss: 160.3141\n",
            "Epoch [44/50] - Batch loss: 161.2507 - Epoch Loss: 50339.5673 - Avg Loss: 160.3171\n",
            "Epoch [44/50] - Batch loss: 156.6454 - Epoch Loss: 50496.2127 - Avg Loss: 160.3054\n",
            "Epoch [44/50] - Batch loss: 159.7461 - Epoch Loss: 50655.9588 - Avg Loss: 160.3037\n",
            "Epoch [44/50] - Batch loss: 154.1968 - Epoch Loss: 50810.1556 - Avg Loss: 160.2844\n",
            "Epoch [44/50] - Batch loss: 159.4406 - Epoch Loss: 50969.5962 - Avg Loss: 160.2817\n",
            "Epoch [44/50] - Batch loss: 163.1764 - Epoch Loss: 51132.7726 - Avg Loss: 160.2908\n",
            "Epoch [44/50] - Batch loss: 155.0928 - Epoch Loss: 51287.8653 - Avg Loss: 160.2746\n",
            "Epoch [44/50] - Batch loss: 162.8025 - Epoch Loss: 51450.6678 - Avg Loss: 160.2825\n",
            "Epoch [44/50] - Batch loss: 153.4092 - Epoch Loss: 51604.0770 - Avg Loss: 160.2611\n",
            "Epoch [44/50] - Batch loss: 152.0740 - Epoch Loss: 51756.1510 - Avg Loss: 160.2358\n",
            "Epoch [44/50] - Batch loss: 160.9394 - Epoch Loss: 51917.0905 - Avg Loss: 160.2379\n",
            "Epoch [44/50] - Batch loss: 161.9531 - Epoch Loss: 52079.0436 - Avg Loss: 160.2432\n",
            "Epoch [44/50] - Batch loss: 152.6532 - Epoch Loss: 52231.6968 - Avg Loss: 160.2199\n",
            "Epoch [44/50] - Batch loss: 157.9454 - Epoch Loss: 52389.6422 - Avg Loss: 160.2130\n",
            "Epoch [44/50] - Batch loss: 157.1029 - Epoch Loss: 52546.7451 - Avg Loss: 160.2035\n",
            "Epoch [44/50] - Batch loss: 154.3936 - Epoch Loss: 52701.1388 - Avg Loss: 160.1858\n",
            "Epoch [44/50] - Batch loss: 158.0620 - Epoch Loss: 52859.2008 - Avg Loss: 160.1794\n",
            "Epoch [44/50] - Batch loss: 151.8396 - Epoch Loss: 53011.0404 - Avg Loss: 160.1542\n",
            "Epoch [44/50] - Batch loss: 160.7492 - Epoch Loss: 53171.7896 - Avg Loss: 160.1560\n",
            "Epoch [44/50] - Batch loss: 163.4210 - Epoch Loss: 53335.2106 - Avg Loss: 160.1658\n",
            "Epoch [44/50] - Batch loss: 164.3339 - Epoch Loss: 53499.5445 - Avg Loss: 160.1783\n",
            "Epoch [44/50] - Batch loss: 158.9838 - Epoch Loss: 53658.5283 - Avg Loss: 160.1747\n",
            "Epoch [44/50] - Batch loss: 159.2685 - Epoch Loss: 53817.7968 - Avg Loss: 160.1720\n",
            "Epoch [44/50] - Batch loss: 156.1969 - Epoch Loss: 53973.9938 - Avg Loss: 160.1602\n",
            "Epoch [44/50] - Batch loss: 163.5378 - Epoch Loss: 54137.5316 - Avg Loss: 160.1702\n",
            "Epoch [44/50] - Batch loss: 158.8883 - Epoch Loss: 54296.4200 - Avg Loss: 160.1664\n",
            "Epoch [44/50] - Batch loss: 159.8775 - Epoch Loss: 54456.2974 - Avg Loss: 160.1656\n",
            "Epoch [44/50] - Batch loss: 155.1949 - Epoch Loss: 54611.4924 - Avg Loss: 160.1510\n",
            "Epoch [44/50] - Batch loss: 162.9198 - Epoch Loss: 54774.4121 - Avg Loss: 160.1591\n",
            "Epoch [44/50] - Batch loss: 170.5085 - Epoch Loss: 54944.9206 - Avg Loss: 160.1893\n",
            "Epoch [44/50] - Batch loss: 160.3830 - Epoch Loss: 55105.3037 - Avg Loss: 160.1898\n",
            "Epoch [44/50] - Batch loss: 158.4083 - Epoch Loss: 55263.7119 - Avg Loss: 160.1847\n",
            "Epoch [44/50] - Batch loss: 155.5491 - Epoch Loss: 55419.2611 - Avg Loss: 160.1713\n",
            "Epoch [44/50] - Batch loss: 160.8365 - Epoch Loss: 55580.0976 - Avg Loss: 160.1732\n",
            "Epoch [44/50] - Batch loss: 154.3187 - Epoch Loss: 55734.4163 - Avg Loss: 160.1564\n",
            "Epoch [44/50] - Batch loss: 155.5670 - Epoch Loss: 55889.9833 - Avg Loss: 160.1432\n",
            "Epoch [44/50] - Batch loss: 158.5735 - Epoch Loss: 56048.5569 - Avg Loss: 160.1387\n",
            "Epoch [44/50] - Batch loss: 151.6945 - Epoch Loss: 56200.2514 - Avg Loss: 160.1147\n",
            "Epoch [44/50] - Batch loss: 154.9774 - Epoch Loss: 56355.2288 - Avg Loss: 160.1001\n",
            "Epoch [44/50] - Batch loss: 163.8162 - Epoch Loss: 56519.0449 - Avg Loss: 160.1106\n",
            "Epoch [44/50] - Batch loss: 162.5637 - Epoch Loss: 56681.6086 - Avg Loss: 160.1175\n",
            "Epoch [44/50] - Batch loss: 163.0614 - Epoch Loss: 56844.6700 - Avg Loss: 160.1258\n",
            "Epoch [44/50] - Batch loss: 147.4479 - Epoch Loss: 56992.1179 - Avg Loss: 160.0902\n",
            "Epoch [44/50] - Batch loss: 152.2526 - Epoch Loss: 57144.3705 - Avg Loss: 160.0683\n",
            "Epoch [44/50] - Batch loss: 151.1102 - Epoch Loss: 57295.4806 - Avg Loss: 160.0432\n",
            "Epoch [44/50] - Batch loss: 150.3475 - Epoch Loss: 57445.8281 - Avg Loss: 160.0162\n",
            "Epoch [44/50] - Batch loss: 161.5011 - Epoch Loss: 57607.3292 - Avg Loss: 160.0204\n",
            "Epoch [44/50] - Batch loss: 159.3942 - Epoch Loss: 57766.7234 - Avg Loss: 160.0186\n",
            "Epoch [44/50] - Batch loss: 151.8622 - Epoch Loss: 57918.5856 - Avg Loss: 159.9961\n",
            "Epoch [44/50] - Batch loss: 165.2122 - Epoch Loss: 58083.7978 - Avg Loss: 160.0105\n",
            "Epoch [44/50] - Batch loss: 153.1770 - Epoch Loss: 58236.9748 - Avg Loss: 159.9917\n",
            "Epoch [44/50] - Batch loss: 164.6587 - Epoch Loss: 58401.6335 - Avg Loss: 160.0045\n",
            "Epoch [44/50] - Batch loss: 161.7750 - Epoch Loss: 58563.4085 - Avg Loss: 160.0093\n",
            "Epoch [44/50] - Batch loss: 158.9718 - Epoch Loss: 58722.3803 - Avg Loss: 160.0065\n",
            "Epoch [44/50] - Batch loss: 156.9889 - Epoch Loss: 58879.3692 - Avg Loss: 159.9983\n",
            "Epoch [44/50] - Batch loss: 163.6188 - Epoch Loss: 59042.9880 - Avg Loss: 160.0081\n",
            "Epoch [44/50] - Batch loss: 160.3553 - Epoch Loss: 59203.3434 - Avg Loss: 160.0090\n",
            "Epoch [44/50] - Batch loss: 161.6766 - Epoch Loss: 59365.0200 - Avg Loss: 160.0135\n",
            "Epoch [44/50] - Batch loss: 161.6218 - Epoch Loss: 59526.6418 - Avg Loss: 160.0179\n",
            "Epoch [44/50] - Batch loss: 162.6046 - Epoch Loss: 59689.2463 - Avg Loss: 160.0248\n",
            "Epoch [44/50] - Batch loss: 155.3166 - Epoch Loss: 59844.5630 - Avg Loss: 160.0122\n",
            "Epoch [44/50] - Batch loss: 156.4973 - Epoch Loss: 60001.0602 - Avg Loss: 160.0028\n",
            "Epoch [44/50] - Batch loss: 161.2574 - Epoch Loss: 60162.3176 - Avg Loss: 160.0062\n",
            "Epoch [44/50] - Batch loss: 153.3665 - Epoch Loss: 60315.6841 - Avg Loss: 159.9886\n",
            "Epoch [44/50] - Batch loss: 156.8733 - Epoch Loss: 60472.5574 - Avg Loss: 159.9803\n",
            "Epoch [44/50] - Batch loss: 160.4876 - Epoch Loss: 60633.0450 - Avg Loss: 159.9816\n",
            "Epoch [44/50] - Batch loss: 165.1662 - Epoch Loss: 60798.2112 - Avg Loss: 159.9953\n",
            "Epoch [44/50] - Batch loss: 160.2665 - Epoch Loss: 60958.4776 - Avg Loss: 159.9960\n",
            "Epoch [44/50] - Batch loss: 153.2984 - Epoch Loss: 61111.7761 - Avg Loss: 159.9785\n",
            "Epoch [44/50] - Batch loss: 151.0475 - Epoch Loss: 61262.8236 - Avg Loss: 159.9552\n",
            "Epoch [44/50] - Batch loss: 162.4513 - Epoch Loss: 61425.2749 - Avg Loss: 159.9617\n",
            "Epoch [44/50] - Batch loss: 158.6840 - Epoch Loss: 61583.9588 - Avg Loss: 159.9583\n",
            "Epoch [44/50] - Batch loss: 156.2575 - Epoch Loss: 61740.2164 - Avg Loss: 159.9487\n",
            "Epoch [44/50] - Batch loss: 161.0674 - Epoch Loss: 61901.2838 - Avg Loss: 159.9516\n",
            "Epoch [44/50] - Batch loss: 155.9435 - Epoch Loss: 62057.2273 - Avg Loss: 159.9413\n",
            "Epoch [44/50] - Batch loss: 159.6695 - Epoch Loss: 62216.8968 - Avg Loss: 159.9406\n",
            "Epoch [44/50] - Batch loss: 158.1070 - Epoch Loss: 62375.0038 - Avg Loss: 159.9359\n",
            "Epoch [44/50] - Batch loss: 151.6858 - Epoch Loss: 62526.6896 - Avg Loss: 159.9148\n",
            "Epoch [44/50] - Batch loss: 163.4608 - Epoch Loss: 62690.1504 - Avg Loss: 159.9239\n",
            "Epoch [44/50] - Batch loss: 156.2596 - Epoch Loss: 62846.4100 - Avg Loss: 159.9145\n",
            "Epoch [44/50] - Batch loss: 154.1387 - Epoch Loss: 63000.5487 - Avg Loss: 159.8999\n",
            "Epoch [44/50] - Batch loss: 151.9164 - Epoch Loss: 63152.4651 - Avg Loss: 159.8797\n",
            "Epoch [44/50] - Batch loss: 161.8786 - Epoch Loss: 63314.3437 - Avg Loss: 159.8847\n",
            "Epoch [44/50] - Batch loss: 163.4930 - Epoch Loss: 63477.8368 - Avg Loss: 159.8938\n",
            "Epoch [44/50] - Batch loss: 162.6396 - Epoch Loss: 63640.4764 - Avg Loss: 159.9007\n",
            "Epoch [44/50] - Batch loss: 159.8713 - Epoch Loss: 63800.3477 - Avg Loss: 159.9006\n",
            "Epoch [44/50] - Batch loss: 155.6326 - Epoch Loss: 63955.9803 - Avg Loss: 159.8900\n",
            "Epoch [44/50] - Batch loss: 162.0724 - Epoch Loss: 64118.0527 - Avg Loss: 159.8954\n",
            "Epoch [44/50] - Batch loss: 154.5214 - Epoch Loss: 64272.5741 - Avg Loss: 159.8820\n",
            "Epoch [44/50] - Batch loss: 158.7675 - Epoch Loss: 64431.3416 - Avg Loss: 159.8793\n",
            "Epoch [44/50] - Batch loss: 162.4361 - Epoch Loss: 64593.7777 - Avg Loss: 159.8856\n",
            "Epoch [44/50] - Batch loss: 157.8173 - Epoch Loss: 64751.5950 - Avg Loss: 159.8805\n",
            "Epoch [44/50] - Batch loss: 158.7497 - Epoch Loss: 64910.3447 - Avg Loss: 159.8777\n",
            "Epoch [44/50] - Batch loss: 162.4705 - Epoch Loss: 65072.8151 - Avg Loss: 159.8841\n",
            "Epoch [44/50] - Batch loss: 159.0802 - Epoch Loss: 65231.8953 - Avg Loss: 159.8821\n",
            "Epoch [44/50] - Batch loss: 159.4390 - Epoch Loss: 65391.3344 - Avg Loss: 159.8810\n",
            "Epoch [44/50] - Batch loss: 159.8114 - Epoch Loss: 65551.1458 - Avg Loss: 159.8808\n",
            "Epoch [44/50] - Batch loss: 163.0976 - Epoch Loss: 65714.2434 - Avg Loss: 159.8887\n",
            "Epoch [44/50] - Batch loss: 162.6853 - Epoch Loss: 65876.9287 - Avg Loss: 159.8955\n",
            "Epoch [44/50] - Batch loss: 157.4983 - Epoch Loss: 66034.4270 - Avg Loss: 159.8897\n",
            "Epoch [44/50] - Batch loss: 157.8753 - Epoch Loss: 66192.3023 - Avg Loss: 159.8848\n",
            "Epoch [44/50] - Batch loss: 158.4136 - Epoch Loss: 66350.7159 - Avg Loss: 159.8812\n",
            "Epoch [44/50] - Batch loss: 157.9697 - Epoch Loss: 66508.6856 - Avg Loss: 159.8766\n",
            "Epoch [44/50] - Batch loss: 158.4897 - Epoch Loss: 66667.1753 - Avg Loss: 159.8733\n",
            "Epoch [44/50] - Batch loss: 160.1305 - Epoch Loss: 66827.3058 - Avg Loss: 159.8739\n",
            "Epoch [44/50] - Batch loss: 161.7888 - Epoch Loss: 66989.0946 - Avg Loss: 159.8785\n",
            "Epoch [44/50] - Batch loss: 159.1551 - Epoch Loss: 67148.2497 - Avg Loss: 159.8768\n",
            "Epoch [44/50] - Batch loss: 150.5025 - Epoch Loss: 67298.7522 - Avg Loss: 159.8545\n",
            "Epoch [44/50] - Batch loss: 155.4442 - Epoch Loss: 67454.1964 - Avg Loss: 159.8441\n",
            "Epoch [44/50] - Batch loss: 168.3164 - Epoch Loss: 67622.5127 - Avg Loss: 159.8641\n",
            "Epoch [44/50] - Batch loss: 157.1572 - Epoch Loss: 67779.6699 - Avg Loss: 159.8577\n",
            "Epoch [44/50] - Batch loss: 162.7228 - Epoch Loss: 67942.3926 - Avg Loss: 159.8645\n",
            "Epoch [44/50] - Batch loss: 157.7937 - Epoch Loss: 68100.1863 - Avg Loss: 159.8596\n",
            "Epoch [44/50] - Batch loss: 154.8113 - Epoch Loss: 68254.9976 - Avg Loss: 159.8478\n",
            "Epoch [44/50] - Batch loss: 159.2797 - Epoch Loss: 68414.2774 - Avg Loss: 159.8464\n",
            "Epoch [44/50] - Batch loss: 159.7511 - Epoch Loss: 68574.0285 - Avg Loss: 159.8462\n",
            "Epoch [44/50] - Batch loss: 155.0038 - Epoch Loss: 68729.0323 - Avg Loss: 159.8350\n",
            "Epoch [44/50] - Batch loss: 166.5939 - Epoch Loss: 68895.6263 - Avg Loss: 159.8506\n",
            "Epoch [44/50] - Batch loss: 159.9236 - Epoch Loss: 69055.5499 - Avg Loss: 159.8508\n",
            "Epoch [44/50] - Batch loss: 155.0052 - Epoch Loss: 69210.5551 - Avg Loss: 159.8396\n",
            "Epoch [44/50] - Batch loss: 157.6510 - Epoch Loss: 69368.2061 - Avg Loss: 159.8346\n",
            "Epoch [44/50] - Batch loss: 161.4588 - Epoch Loss: 69529.6649 - Avg Loss: 159.8383\n",
            "Epoch [44/50] - Batch loss: 152.9933 - Epoch Loss: 69682.6582 - Avg Loss: 159.8226\n",
            "Epoch [44/50] - Batch loss: 156.3534 - Epoch Loss: 69839.0116 - Avg Loss: 159.8147\n",
            "Epoch [44/50] - Batch loss: 163.8041 - Epoch Loss: 70002.8157 - Avg Loss: 159.8238\n",
            "Epoch [44/50] - Batch loss: 160.0242 - Epoch Loss: 70162.8399 - Avg Loss: 159.8242\n",
            "Epoch [44/50] - Batch loss: 168.1375 - Epoch Loss: 70330.9774 - Avg Loss: 159.8431\n",
            "Epoch [44/50] - Batch loss: 158.7881 - Epoch Loss: 70489.7655 - Avg Loss: 159.8407\n",
            "Epoch [44/50] - Batch loss: 153.2193 - Epoch Loss: 70642.9849 - Avg Loss: 159.8258\n",
            "Epoch [44/50] - Batch loss: 162.1131 - Epoch Loss: 70805.0979 - Avg Loss: 159.8309\n",
            "Epoch [44/50] - Batch loss: 159.9605 - Epoch Loss: 70965.0585 - Avg Loss: 159.8312\n",
            "Epoch [44/50] - Batch loss: 154.0028 - Epoch Loss: 71119.0612 - Avg Loss: 159.8181\n",
            "Epoch [44/50] - Batch loss: 157.1395 - Epoch Loss: 71276.2008 - Avg Loss: 159.8121\n",
            "Epoch [44/50] - Batch loss: 156.1528 - Epoch Loss: 71432.3536 - Avg Loss: 159.8039\n",
            "Epoch [44/50] - Batch loss: 159.8683 - Epoch Loss: 71592.2220 - Avg Loss: 159.8041\n",
            "Epoch [44/50] - Batch loss: 156.4101 - Epoch Loss: 71748.6321 - Avg Loss: 159.7965\n",
            "Epoch [44/50] - Batch loss: 160.9444 - Epoch Loss: 71909.5765 - Avg Loss: 159.7991\n",
            "Epoch [44/50] - Batch loss: 156.1274 - Epoch Loss: 72065.7039 - Avg Loss: 159.7909\n",
            "Epoch [44/50] - Batch loss: 162.3753 - Epoch Loss: 72228.0792 - Avg Loss: 159.7966\n",
            "Epoch [44/50] - Batch loss: 167.2288 - Epoch Loss: 72395.3080 - Avg Loss: 159.8130\n",
            "Epoch [44/50] - Batch loss: 174.9203 - Epoch Loss: 72570.2283 - Avg Loss: 159.8463\n",
            "Epoch [44/50] - Batch loss: 156.7420 - Epoch Loss: 72726.9704 - Avg Loss: 159.8395\n",
            "Epoch [44/50] - Batch loss: 158.9534 - Epoch Loss: 72885.9237 - Avg Loss: 159.8376\n",
            "Epoch [44/50] - Batch loss: 155.6247 - Epoch Loss: 73041.5484 - Avg Loss: 159.8283\n",
            "Epoch [44/50] - Batch loss: 163.4147 - Epoch Loss: 73204.9631 - Avg Loss: 159.8362\n",
            "Epoch [44/50] - Batch loss: 154.4550 - Epoch Loss: 73359.4181 - Avg Loss: 159.8244\n",
            "Epoch [44/50] - Batch loss: 159.4300 - Epoch Loss: 73518.8481 - Avg Loss: 159.8236\n",
            "Epoch [44/50] - Batch loss: 158.1939 - Epoch Loss: 73677.0420 - Avg Loss: 159.8200\n",
            "Epoch [44/50] - Batch loss: 163.1262 - Epoch Loss: 73840.1682 - Avg Loss: 159.8272\n",
            "Epoch [44/50] - Batch loss: 158.0079 - Epoch Loss: 73998.1761 - Avg Loss: 159.8233\n",
            "Epoch [44/50] - Batch loss: 161.1192 - Epoch Loss: 74159.2953 - Avg Loss: 159.8261\n",
            "Epoch [44/50] - Batch loss: 154.6786 - Epoch Loss: 74313.9739 - Avg Loss: 159.8150\n",
            "Epoch [44/50] - Batch loss: 157.3863 - Epoch Loss: 74471.3602 - Avg Loss: 159.8098\n",
            "Epoch [44/50] - Batch loss: 164.9493 - Epoch Loss: 74636.3095 - Avg Loss: 159.8208\n",
            "Epoch [44/50] - Batch loss: 156.5383 - Epoch Loss: 74792.8478 - Avg Loss: 159.8138\n",
            "Epoch [44/50] - Batch loss: 158.5207 - Epoch Loss: 74951.3685 - Avg Loss: 159.8110\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 45/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a22f01a80e4478f924a99e85389dfe8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [45/50] - Batch loss: 162.7211 - Epoch Loss: 162.7211 - Avg Loss: 162.7211\n",
            "Epoch [45/50] - Batch loss: 163.4750 - Epoch Loss: 326.1960 - Avg Loss: 163.0980\n",
            "Epoch [45/50] - Batch loss: 156.8129 - Epoch Loss: 483.0090 - Avg Loss: 161.0030\n",
            "Epoch [45/50] - Batch loss: 150.3564 - Epoch Loss: 633.3653 - Avg Loss: 158.3413\n",
            "Epoch [45/50] - Batch loss: 155.6528 - Epoch Loss: 789.0181 - Avg Loss: 157.8036\n",
            "Epoch [45/50] - Batch loss: 157.1046 - Epoch Loss: 946.1226 - Avg Loss: 157.6871\n",
            "Epoch [45/50] - Batch loss: 156.9249 - Epoch Loss: 1103.0475 - Avg Loss: 157.5782\n",
            "Epoch [45/50] - Batch loss: 167.1720 - Epoch Loss: 1270.2195 - Avg Loss: 158.7774\n",
            "Epoch [45/50] - Batch loss: 152.2392 - Epoch Loss: 1422.4587 - Avg Loss: 158.0510\n",
            "Epoch [45/50] - Batch loss: 146.3066 - Epoch Loss: 1568.7652 - Avg Loss: 156.8765\n",
            "Epoch [45/50] - Batch loss: 155.6216 - Epoch Loss: 1724.3868 - Avg Loss: 156.7624\n",
            "Epoch [45/50] - Batch loss: 157.1134 - Epoch Loss: 1881.5002 - Avg Loss: 156.7917\n",
            "Epoch [45/50] - Batch loss: 150.8368 - Epoch Loss: 2032.3370 - Avg Loss: 156.3336\n",
            "Epoch [45/50] - Batch loss: 165.9460 - Epoch Loss: 2198.2830 - Avg Loss: 157.0202\n",
            "Epoch [45/50] - Batch loss: 163.9833 - Epoch Loss: 2362.2663 - Avg Loss: 157.4844\n",
            "Epoch [45/50] - Batch loss: 162.7057 - Epoch Loss: 2524.9721 - Avg Loss: 157.8108\n",
            "Epoch [45/50] - Batch loss: 161.6605 - Epoch Loss: 2686.6326 - Avg Loss: 158.0372\n",
            "Epoch [45/50] - Batch loss: 161.5022 - Epoch Loss: 2848.1348 - Avg Loss: 158.2297\n",
            "Epoch [45/50] - Batch loss: 156.2153 - Epoch Loss: 3004.3502 - Avg Loss: 158.1237\n",
            "Epoch [45/50] - Batch loss: 154.0223 - Epoch Loss: 3158.3725 - Avg Loss: 157.9186\n",
            "Epoch [45/50] - Batch loss: 169.8704 - Epoch Loss: 3328.2429 - Avg Loss: 158.4878\n",
            "Epoch [45/50] - Batch loss: 159.1706 - Epoch Loss: 3487.4135 - Avg Loss: 158.5188\n",
            "Epoch [45/50] - Batch loss: 155.0749 - Epoch Loss: 3642.4884 - Avg Loss: 158.3691\n",
            "Epoch [45/50] - Batch loss: 161.2326 - Epoch Loss: 3803.7210 - Avg Loss: 158.4884\n",
            "Epoch [45/50] - Batch loss: 155.3838 - Epoch Loss: 3959.1048 - Avg Loss: 158.3642\n",
            "Epoch [45/50] - Batch loss: 160.7257 - Epoch Loss: 4119.8305 - Avg Loss: 158.4550\n",
            "Epoch [45/50] - Batch loss: 148.7665 - Epoch Loss: 4268.5970 - Avg Loss: 158.0962\n",
            "Epoch [45/50] - Batch loss: 157.0684 - Epoch Loss: 4425.6654 - Avg Loss: 158.0595\n",
            "Epoch [45/50] - Batch loss: 160.3672 - Epoch Loss: 4586.0326 - Avg Loss: 158.1391\n",
            "Epoch [45/50] - Batch loss: 156.9264 - Epoch Loss: 4742.9590 - Avg Loss: 158.0986\n",
            "Epoch [45/50] - Batch loss: 152.6508 - Epoch Loss: 4895.6098 - Avg Loss: 157.9229\n",
            "Epoch [45/50] - Batch loss: 154.9715 - Epoch Loss: 5050.5813 - Avg Loss: 157.8307\n",
            "Epoch [45/50] - Batch loss: 157.0363 - Epoch Loss: 5207.6177 - Avg Loss: 157.8066\n",
            "Epoch [45/50] - Batch loss: 158.6403 - Epoch Loss: 5366.2579 - Avg Loss: 157.8311\n",
            "Epoch [45/50] - Batch loss: 160.4764 - Epoch Loss: 5526.7344 - Avg Loss: 157.9067\n",
            "Epoch [45/50] - Batch loss: 170.3435 - Epoch Loss: 5697.0779 - Avg Loss: 158.2522\n",
            "Epoch [45/50] - Batch loss: 152.4125 - Epoch Loss: 5849.4904 - Avg Loss: 158.0943\n",
            "Epoch [45/50] - Batch loss: 154.6313 - Epoch Loss: 6004.1216 - Avg Loss: 158.0032\n",
            "Epoch [45/50] - Batch loss: 161.9813 - Epoch Loss: 6166.1030 - Avg Loss: 158.1052\n",
            "Epoch [45/50] - Batch loss: 163.4330 - Epoch Loss: 6329.5360 - Avg Loss: 158.2384\n",
            "Epoch [45/50] - Batch loss: 154.6736 - Epoch Loss: 6484.2095 - Avg Loss: 158.1515\n",
            "Epoch [45/50] - Batch loss: 155.3910 - Epoch Loss: 6639.6006 - Avg Loss: 158.0857\n",
            "Epoch [45/50] - Batch loss: 161.1735 - Epoch Loss: 6800.7741 - Avg Loss: 158.1575\n",
            "Epoch [45/50] - Batch loss: 164.9580 - Epoch Loss: 6965.7321 - Avg Loss: 158.3121\n",
            "Epoch [45/50] - Batch loss: 150.9040 - Epoch Loss: 7116.6360 - Avg Loss: 158.1475\n",
            "Epoch [45/50] - Batch loss: 159.4909 - Epoch Loss: 7276.1269 - Avg Loss: 158.1767\n",
            "Epoch [45/50] - Batch loss: 157.8472 - Epoch Loss: 7433.9742 - Avg Loss: 158.1697\n",
            "Epoch [45/50] - Batch loss: 154.9615 - Epoch Loss: 7588.9357 - Avg Loss: 158.1028\n",
            "Epoch [45/50] - Batch loss: 159.9765 - Epoch Loss: 7748.9122 - Avg Loss: 158.1411\n",
            "Epoch [45/50] - Batch loss: 163.7465 - Epoch Loss: 7912.6587 - Avg Loss: 158.2532\n",
            "Epoch [45/50] - Batch loss: 156.0634 - Epoch Loss: 8068.7221 - Avg Loss: 158.2102\n",
            "Epoch [45/50] - Batch loss: 153.6918 - Epoch Loss: 8222.4138 - Avg Loss: 158.1233\n",
            "Epoch [45/50] - Batch loss: 163.0101 - Epoch Loss: 8385.4240 - Avg Loss: 158.2155\n",
            "Epoch [45/50] - Batch loss: 161.1335 - Epoch Loss: 8546.5575 - Avg Loss: 158.2696\n",
            "Epoch [45/50] - Batch loss: 159.6100 - Epoch Loss: 8706.1675 - Avg Loss: 158.2940\n",
            "Epoch [45/50] - Batch loss: 164.8186 - Epoch Loss: 8870.9861 - Avg Loss: 158.4105\n",
            "Epoch [45/50] - Batch loss: 157.1066 - Epoch Loss: 9028.0928 - Avg Loss: 158.3876\n",
            "Epoch [45/50] - Batch loss: 158.7623 - Epoch Loss: 9186.8550 - Avg Loss: 158.3941\n",
            "Epoch [45/50] - Batch loss: 163.5936 - Epoch Loss: 9350.4486 - Avg Loss: 158.4822\n",
            "Epoch [45/50] - Batch loss: 161.0898 - Epoch Loss: 9511.5384 - Avg Loss: 158.5256\n",
            "Epoch [45/50] - Batch loss: 155.3892 - Epoch Loss: 9666.9276 - Avg Loss: 158.4742\n",
            "Epoch [45/50] - Batch loss: 159.3916 - Epoch Loss: 9826.3193 - Avg Loss: 158.4890\n",
            "Epoch [45/50] - Batch loss: 153.1399 - Epoch Loss: 9979.4592 - Avg Loss: 158.4041\n",
            "Epoch [45/50] - Batch loss: 162.0260 - Epoch Loss: 10141.4852 - Avg Loss: 158.4607\n",
            "Epoch [45/50] - Batch loss: 155.6881 - Epoch Loss: 10297.1733 - Avg Loss: 158.4181\n",
            "Epoch [45/50] - Batch loss: 157.5812 - Epoch Loss: 10454.7545 - Avg Loss: 158.4054\n",
            "Epoch [45/50] - Batch loss: 160.1966 - Epoch Loss: 10614.9511 - Avg Loss: 158.4321\n",
            "Epoch [45/50] - Batch loss: 165.2992 - Epoch Loss: 10780.2503 - Avg Loss: 158.5331\n",
            "Epoch [45/50] - Batch loss: 161.0448 - Epoch Loss: 10941.2951 - Avg Loss: 158.5695\n",
            "Epoch [45/50] - Batch loss: 160.8728 - Epoch Loss: 11102.1679 - Avg Loss: 158.6024\n",
            "Epoch [45/50] - Batch loss: 154.4790 - Epoch Loss: 11256.6469 - Avg Loss: 158.5443\n",
            "Epoch [45/50] - Batch loss: 154.9528 - Epoch Loss: 11411.5996 - Avg Loss: 158.4944\n",
            "Epoch [45/50] - Batch loss: 162.3758 - Epoch Loss: 11573.9755 - Avg Loss: 158.5476\n",
            "Epoch [45/50] - Batch loss: 150.2136 - Epoch Loss: 11724.1890 - Avg Loss: 158.4350\n",
            "Epoch [45/50] - Batch loss: 154.7389 - Epoch Loss: 11878.9280 - Avg Loss: 158.3857\n",
            "Epoch [45/50] - Batch loss: 166.0809 - Epoch Loss: 12045.0089 - Avg Loss: 158.4870\n",
            "Epoch [45/50] - Batch loss: 157.5204 - Epoch Loss: 12202.5293 - Avg Loss: 158.4744\n",
            "Epoch [45/50] - Batch loss: 161.8504 - Epoch Loss: 12364.3796 - Avg Loss: 158.5177\n",
            "Epoch [45/50] - Batch loss: 158.6324 - Epoch Loss: 12523.0120 - Avg Loss: 158.5191\n",
            "Epoch [45/50] - Batch loss: 152.7991 - Epoch Loss: 12675.8111 - Avg Loss: 158.4476\n",
            "Epoch [45/50] - Batch loss: 157.1912 - Epoch Loss: 12833.0023 - Avg Loss: 158.4321\n",
            "Epoch [45/50] - Batch loss: 161.8237 - Epoch Loss: 12994.8261 - Avg Loss: 158.4735\n",
            "Epoch [45/50] - Batch loss: 156.8468 - Epoch Loss: 13151.6729 - Avg Loss: 158.4539\n",
            "Epoch [45/50] - Batch loss: 162.6249 - Epoch Loss: 13314.2978 - Avg Loss: 158.5035\n",
            "Epoch [45/50] - Batch loss: 158.4056 - Epoch Loss: 13472.7033 - Avg Loss: 158.5024\n",
            "Epoch [45/50] - Batch loss: 151.5921 - Epoch Loss: 13624.2954 - Avg Loss: 158.4220\n",
            "Epoch [45/50] - Batch loss: 154.9071 - Epoch Loss: 13779.2024 - Avg Loss: 158.3816\n",
            "Epoch [45/50] - Batch loss: 153.7587 - Epoch Loss: 13932.9611 - Avg Loss: 158.3291\n",
            "Epoch [45/50] - Batch loss: 164.1573 - Epoch Loss: 14097.1185 - Avg Loss: 158.3946\n",
            "Epoch [45/50] - Batch loss: 160.2903 - Epoch Loss: 14257.4087 - Avg Loss: 158.4157\n",
            "Epoch [45/50] - Batch loss: 165.2515 - Epoch Loss: 14422.6602 - Avg Loss: 158.4908\n",
            "Epoch [45/50] - Batch loss: 159.9299 - Epoch Loss: 14582.5901 - Avg Loss: 158.5064\n",
            "Epoch [45/50] - Batch loss: 172.2020 - Epoch Loss: 14754.7921 - Avg Loss: 158.6537\n",
            "Epoch [45/50] - Batch loss: 161.4941 - Epoch Loss: 14916.2862 - Avg Loss: 158.6839\n",
            "Epoch [45/50] - Batch loss: 159.0686 - Epoch Loss: 15075.3548 - Avg Loss: 158.6879\n",
            "Epoch [45/50] - Batch loss: 147.4320 - Epoch Loss: 15222.7868 - Avg Loss: 158.5707\n",
            "Epoch [45/50] - Batch loss: 159.5109 - Epoch Loss: 15382.2977 - Avg Loss: 158.5804\n",
            "Epoch [45/50] - Batch loss: 161.1258 - Epoch Loss: 15543.4235 - Avg Loss: 158.6064\n",
            "Epoch [45/50] - Batch loss: 156.8831 - Epoch Loss: 15700.3066 - Avg Loss: 158.5890\n",
            "Epoch [45/50] - Batch loss: 156.6567 - Epoch Loss: 15856.9633 - Avg Loss: 158.5696\n",
            "Epoch [45/50] - Batch loss: 162.7304 - Epoch Loss: 16019.6937 - Avg Loss: 158.6108\n",
            "Epoch [45/50] - Batch loss: 169.5561 - Epoch Loss: 16189.2498 - Avg Loss: 158.7181\n",
            "Epoch [45/50] - Batch loss: 174.5071 - Epoch Loss: 16363.7570 - Avg Loss: 158.8714\n",
            "Epoch [45/50] - Batch loss: 164.5579 - Epoch Loss: 16528.3148 - Avg Loss: 158.9261\n",
            "Epoch [45/50] - Batch loss: 161.4766 - Epoch Loss: 16689.7914 - Avg Loss: 158.9504\n",
            "Epoch [45/50] - Batch loss: 165.2912 - Epoch Loss: 16855.0826 - Avg Loss: 159.0102\n",
            "Epoch [45/50] - Batch loss: 156.9913 - Epoch Loss: 17012.0739 - Avg Loss: 158.9913\n",
            "Epoch [45/50] - Batch loss: 160.5135 - Epoch Loss: 17172.5874 - Avg Loss: 159.0054\n",
            "Epoch [45/50] - Batch loss: 161.3051 - Epoch Loss: 17333.8925 - Avg Loss: 159.0265\n",
            "Epoch [45/50] - Batch loss: 163.3066 - Epoch Loss: 17497.1991 - Avg Loss: 159.0654\n",
            "Epoch [45/50] - Batch loss: 155.9572 - Epoch Loss: 17653.1563 - Avg Loss: 159.0374\n",
            "Epoch [45/50] - Batch loss: 157.7328 - Epoch Loss: 17810.8892 - Avg Loss: 159.0258\n",
            "Epoch [45/50] - Batch loss: 164.8773 - Epoch Loss: 17975.7664 - Avg Loss: 159.0776\n",
            "Epoch [45/50] - Batch loss: 157.0876 - Epoch Loss: 18132.8540 - Avg Loss: 159.0601\n",
            "Epoch [45/50] - Batch loss: 166.3077 - Epoch Loss: 18299.1617 - Avg Loss: 159.1231\n",
            "Epoch [45/50] - Batch loss: 155.0119 - Epoch Loss: 18454.1736 - Avg Loss: 159.0877\n",
            "Epoch [45/50] - Batch loss: 155.1661 - Epoch Loss: 18609.3397 - Avg Loss: 159.0542\n",
            "Epoch [45/50] - Batch loss: 157.9236 - Epoch Loss: 18767.2632 - Avg Loss: 159.0446\n",
            "Epoch [45/50] - Batch loss: 160.9783 - Epoch Loss: 18928.2415 - Avg Loss: 159.0609\n",
            "Epoch [45/50] - Batch loss: 151.9290 - Epoch Loss: 19080.1706 - Avg Loss: 159.0014\n",
            "Epoch [45/50] - Batch loss: 156.5754 - Epoch Loss: 19236.7460 - Avg Loss: 158.9814\n",
            "Epoch [45/50] - Batch loss: 161.5332 - Epoch Loss: 19398.2791 - Avg Loss: 159.0023\n",
            "Epoch [45/50] - Batch loss: 162.3027 - Epoch Loss: 19560.5818 - Avg Loss: 159.0291\n",
            "Epoch [45/50] - Batch loss: 161.0076 - Epoch Loss: 19721.5895 - Avg Loss: 159.0451\n",
            "Epoch [45/50] - Batch loss: 165.0363 - Epoch Loss: 19886.6257 - Avg Loss: 159.0930\n",
            "Epoch [45/50] - Batch loss: 152.9857 - Epoch Loss: 20039.6114 - Avg Loss: 159.0445\n",
            "Epoch [45/50] - Batch loss: 160.4264 - Epoch Loss: 20200.0378 - Avg Loss: 159.0554\n",
            "Epoch [45/50] - Batch loss: 158.9916 - Epoch Loss: 20359.0295 - Avg Loss: 159.0549\n",
            "Epoch [45/50] - Batch loss: 165.0787 - Epoch Loss: 20524.1081 - Avg Loss: 159.1016\n",
            "Epoch [45/50] - Batch loss: 158.1597 - Epoch Loss: 20682.2679 - Avg Loss: 159.0944\n",
            "Epoch [45/50] - Batch loss: 155.6751 - Epoch Loss: 20837.9430 - Avg Loss: 159.0683\n",
            "Epoch [45/50] - Batch loss: 155.4480 - Epoch Loss: 20993.3909 - Avg Loss: 159.0408\n",
            "Epoch [45/50] - Batch loss: 152.3316 - Epoch Loss: 21145.7225 - Avg Loss: 158.9904\n",
            "Epoch [45/50] - Batch loss: 159.8980 - Epoch Loss: 21305.6205 - Avg Loss: 158.9972\n",
            "Epoch [45/50] - Batch loss: 157.2936 - Epoch Loss: 21462.9141 - Avg Loss: 158.9845\n",
            "Epoch [45/50] - Batch loss: 159.1432 - Epoch Loss: 21622.0573 - Avg Loss: 158.9857\n",
            "Epoch [45/50] - Batch loss: 160.9413 - Epoch Loss: 21782.9986 - Avg Loss: 159.0000\n",
            "Epoch [45/50] - Batch loss: 162.8003 - Epoch Loss: 21945.7989 - Avg Loss: 159.0275\n",
            "Epoch [45/50] - Batch loss: 152.9799 - Epoch Loss: 22098.7788 - Avg Loss: 158.9840\n",
            "Epoch [45/50] - Batch loss: 159.1641 - Epoch Loss: 22257.9429 - Avg Loss: 158.9853\n",
            "Epoch [45/50] - Batch loss: 156.1087 - Epoch Loss: 22414.0516 - Avg Loss: 158.9649\n",
            "Epoch [45/50] - Batch loss: 169.2191 - Epoch Loss: 22583.2707 - Avg Loss: 159.0371\n",
            "Epoch [45/50] - Batch loss: 156.4193 - Epoch Loss: 22739.6900 - Avg Loss: 159.0188\n",
            "Epoch [45/50] - Batch loss: 156.7805 - Epoch Loss: 22896.4705 - Avg Loss: 159.0033\n",
            "Epoch [45/50] - Batch loss: 159.8533 - Epoch Loss: 23056.3238 - Avg Loss: 159.0091\n",
            "Epoch [45/50] - Batch loss: 161.1275 - Epoch Loss: 23217.4514 - Avg Loss: 159.0236\n",
            "Epoch [45/50] - Batch loss: 155.4931 - Epoch Loss: 23372.9445 - Avg Loss: 158.9996\n",
            "Epoch [45/50] - Batch loss: 159.3025 - Epoch Loss: 23532.2470 - Avg Loss: 159.0017\n",
            "Epoch [45/50] - Batch loss: 164.0758 - Epoch Loss: 23696.3228 - Avg Loss: 159.0357\n",
            "Epoch [45/50] - Batch loss: 169.3440 - Epoch Loss: 23865.6668 - Avg Loss: 159.1044\n",
            "Epoch [45/50] - Batch loss: 148.1027 - Epoch Loss: 24013.7695 - Avg Loss: 159.0316\n",
            "Epoch [45/50] - Batch loss: 159.9302 - Epoch Loss: 24173.6996 - Avg Loss: 159.0375\n",
            "Epoch [45/50] - Batch loss: 150.5835 - Epoch Loss: 24324.2831 - Avg Loss: 158.9822\n",
            "Epoch [45/50] - Batch loss: 165.0574 - Epoch Loss: 24489.3405 - Avg Loss: 159.0217\n",
            "Epoch [45/50] - Batch loss: 158.7299 - Epoch Loss: 24648.0705 - Avg Loss: 159.0198\n",
            "Epoch [45/50] - Batch loss: 165.4997 - Epoch Loss: 24813.5702 - Avg Loss: 159.0613\n",
            "Epoch [45/50] - Batch loss: 168.5436 - Epoch Loss: 24982.1138 - Avg Loss: 159.1217\n",
            "Epoch [45/50] - Batch loss: 156.8927 - Epoch Loss: 25139.0065 - Avg Loss: 159.1076\n",
            "Epoch [45/50] - Batch loss: 157.6313 - Epoch Loss: 25296.6378 - Avg Loss: 159.0984\n",
            "Epoch [45/50] - Batch loss: 168.0961 - Epoch Loss: 25464.7339 - Avg Loss: 159.1546\n",
            "Epoch [45/50] - Batch loss: 158.7603 - Epoch Loss: 25623.4942 - Avg Loss: 159.1521\n",
            "Epoch [45/50] - Batch loss: 164.2515 - Epoch Loss: 25787.7457 - Avg Loss: 159.1836\n",
            "Epoch [45/50] - Batch loss: 159.7934 - Epoch Loss: 25947.5391 - Avg Loss: 159.1874\n",
            "Epoch [45/50] - Batch loss: 161.9809 - Epoch Loss: 26109.5200 - Avg Loss: 159.2044\n",
            "Epoch [45/50] - Batch loss: 154.3066 - Epoch Loss: 26263.8266 - Avg Loss: 159.1747\n",
            "Epoch [45/50] - Batch loss: 161.7697 - Epoch Loss: 26425.5963 - Avg Loss: 159.1903\n",
            "Epoch [45/50] - Batch loss: 152.1569 - Epoch Loss: 26577.7532 - Avg Loss: 159.1482\n",
            "Epoch [45/50] - Batch loss: 159.3521 - Epoch Loss: 26737.1053 - Avg Loss: 159.1494\n",
            "Epoch [45/50] - Batch loss: 158.0298 - Epoch Loss: 26895.1351 - Avg Loss: 159.1428\n",
            "Epoch [45/50] - Batch loss: 161.3074 - Epoch Loss: 27056.4425 - Avg Loss: 159.1555\n",
            "Epoch [45/50] - Batch loss: 156.7693 - Epoch Loss: 27213.2117 - Avg Loss: 159.1416\n",
            "Epoch [45/50] - Batch loss: 160.0281 - Epoch Loss: 27373.2398 - Avg Loss: 159.1467\n",
            "Epoch [45/50] - Batch loss: 162.5934 - Epoch Loss: 27535.8333 - Avg Loss: 159.1667\n",
            "Epoch [45/50] - Batch loss: 167.3656 - Epoch Loss: 27703.1989 - Avg Loss: 159.2138\n",
            "Epoch [45/50] - Batch loss: 163.4666 - Epoch Loss: 27866.6655 - Avg Loss: 159.2381\n",
            "Epoch [45/50] - Batch loss: 165.8848 - Epoch Loss: 28032.5502 - Avg Loss: 159.2759\n",
            "Epoch [45/50] - Batch loss: 157.9913 - Epoch Loss: 28190.5416 - Avg Loss: 159.2686\n",
            "Epoch [45/50] - Batch loss: 161.5103 - Epoch Loss: 28352.0519 - Avg Loss: 159.2812\n",
            "Epoch [45/50] - Batch loss: 159.7619 - Epoch Loss: 28511.8137 - Avg Loss: 159.2839\n",
            "Epoch [45/50] - Batch loss: 161.0459 - Epoch Loss: 28672.8596 - Avg Loss: 159.2937\n",
            "Epoch [45/50] - Batch loss: 162.2233 - Epoch Loss: 28835.0829 - Avg Loss: 159.3099\n",
            "Epoch [45/50] - Batch loss: 160.1660 - Epoch Loss: 28995.2489 - Avg Loss: 159.3146\n",
            "Epoch [45/50] - Batch loss: 163.9349 - Epoch Loss: 29159.1839 - Avg Loss: 159.3398\n",
            "Epoch [45/50] - Batch loss: 165.1187 - Epoch Loss: 29324.3026 - Avg Loss: 159.3712\n",
            "Epoch [45/50] - Batch loss: 154.2132 - Epoch Loss: 29478.5158 - Avg Loss: 159.3433\n",
            "Epoch [45/50] - Batch loss: 161.6529 - Epoch Loss: 29640.1687 - Avg Loss: 159.3557\n",
            "Epoch [45/50] - Batch loss: 152.2126 - Epoch Loss: 29792.3813 - Avg Loss: 159.3175\n",
            "Epoch [45/50] - Batch loss: 155.5254 - Epoch Loss: 29947.9067 - Avg Loss: 159.2974\n",
            "Epoch [45/50] - Batch loss: 159.2248 - Epoch Loss: 30107.1315 - Avg Loss: 159.2970\n",
            "Epoch [45/50] - Batch loss: 163.3130 - Epoch Loss: 30270.4445 - Avg Loss: 159.3181\n",
            "Epoch [45/50] - Batch loss: 158.9305 - Epoch Loss: 30429.3750 - Avg Loss: 159.3161\n",
            "Epoch [45/50] - Batch loss: 161.5125 - Epoch Loss: 30590.8875 - Avg Loss: 159.3275\n",
            "Epoch [45/50] - Batch loss: 159.7804 - Epoch Loss: 30750.6680 - Avg Loss: 159.3299\n",
            "Epoch [45/50] - Batch loss: 156.6798 - Epoch Loss: 30907.3477 - Avg Loss: 159.3162\n",
            "Epoch [45/50] - Batch loss: 161.2534 - Epoch Loss: 31068.6012 - Avg Loss: 159.3262\n",
            "Epoch [45/50] - Batch loss: 160.3764 - Epoch Loss: 31228.9776 - Avg Loss: 159.3315\n",
            "Epoch [45/50] - Batch loss: 155.6927 - Epoch Loss: 31384.6703 - Avg Loss: 159.3130\n",
            "Epoch [45/50] - Batch loss: 156.6293 - Epoch Loss: 31541.2996 - Avg Loss: 159.2995\n",
            "Epoch [45/50] - Batch loss: 150.3191 - Epoch Loss: 31691.6187 - Avg Loss: 159.2544\n",
            "Epoch [45/50] - Batch loss: 157.6599 - Epoch Loss: 31849.2786 - Avg Loss: 159.2464\n",
            "Epoch [45/50] - Batch loss: 162.1836 - Epoch Loss: 32011.4622 - Avg Loss: 159.2610\n",
            "Epoch [45/50] - Batch loss: 158.7182 - Epoch Loss: 32170.1803 - Avg Loss: 159.2583\n",
            "Epoch [45/50] - Batch loss: 159.4078 - Epoch Loss: 32329.5881 - Avg Loss: 159.2591\n",
            "Epoch [45/50] - Batch loss: 155.6597 - Epoch Loss: 32485.2479 - Avg Loss: 159.2414\n",
            "Epoch [45/50] - Batch loss: 154.0670 - Epoch Loss: 32639.3149 - Avg Loss: 159.2162\n",
            "Epoch [45/50] - Batch loss: 145.5531 - Epoch Loss: 32784.8680 - Avg Loss: 159.1498\n",
            "Epoch [45/50] - Batch loss: 164.9866 - Epoch Loss: 32949.8546 - Avg Loss: 159.1780\n",
            "Epoch [45/50] - Batch loss: 158.6605 - Epoch Loss: 33108.5151 - Avg Loss: 159.1756\n",
            "Epoch [45/50] - Batch loss: 153.5836 - Epoch Loss: 33262.0986 - Avg Loss: 159.1488\n",
            "Epoch [45/50] - Batch loss: 161.9472 - Epoch Loss: 33424.0459 - Avg Loss: 159.1621\n",
            "Epoch [45/50] - Batch loss: 159.9251 - Epoch Loss: 33583.9710 - Avg Loss: 159.1657\n",
            "Epoch [45/50] - Batch loss: 161.4345 - Epoch Loss: 33745.4055 - Avg Loss: 159.1764\n",
            "Epoch [45/50] - Batch loss: 162.7442 - Epoch Loss: 33908.1497 - Avg Loss: 159.1932\n",
            "Epoch [45/50] - Batch loss: 157.5076 - Epoch Loss: 34065.6573 - Avg Loss: 159.1853\n",
            "Epoch [45/50] - Batch loss: 158.6017 - Epoch Loss: 34224.2590 - Avg Loss: 159.1826\n",
            "Epoch [45/50] - Batch loss: 152.3694 - Epoch Loss: 34376.6284 - Avg Loss: 159.1511\n",
            "Epoch [45/50] - Batch loss: 151.6594 - Epoch Loss: 34528.2878 - Avg Loss: 159.1165\n",
            "Epoch [45/50] - Batch loss: 151.3273 - Epoch Loss: 34679.6151 - Avg Loss: 159.0808\n",
            "Epoch [45/50] - Batch loss: 163.0988 - Epoch Loss: 34842.7139 - Avg Loss: 159.0992\n",
            "Epoch [45/50] - Batch loss: 158.9983 - Epoch Loss: 35001.7122 - Avg Loss: 159.0987\n",
            "Epoch [45/50] - Batch loss: 159.4197 - Epoch Loss: 35161.1318 - Avg Loss: 159.1001\n",
            "Epoch [45/50] - Batch loss: 157.1543 - Epoch Loss: 35318.2861 - Avg Loss: 159.0914\n",
            "Epoch [45/50] - Batch loss: 158.3991 - Epoch Loss: 35476.6853 - Avg Loss: 159.0883\n",
            "Epoch [45/50] - Batch loss: 156.7837 - Epoch Loss: 35633.4690 - Avg Loss: 159.0780\n",
            "Epoch [45/50] - Batch loss: 168.0890 - Epoch Loss: 35801.5580 - Avg Loss: 159.1180\n",
            "Epoch [45/50] - Batch loss: 167.0142 - Epoch Loss: 35968.5723 - Avg Loss: 159.1530\n",
            "Epoch [45/50] - Batch loss: 164.5094 - Epoch Loss: 36133.0816 - Avg Loss: 159.1766\n",
            "Epoch [45/50] - Batch loss: 152.1516 - Epoch Loss: 36285.2332 - Avg Loss: 159.1458\n",
            "Epoch [45/50] - Batch loss: 158.8245 - Epoch Loss: 36444.0577 - Avg Loss: 159.1444\n",
            "Epoch [45/50] - Batch loss: 159.2459 - Epoch Loss: 36603.3035 - Avg Loss: 159.1448\n",
            "Epoch [45/50] - Batch loss: 152.0347 - Epoch Loss: 36755.3382 - Avg Loss: 159.1140\n",
            "Epoch [45/50] - Batch loss: 157.0568 - Epoch Loss: 36912.3951 - Avg Loss: 159.1052\n",
            "Epoch [45/50] - Batch loss: 161.3183 - Epoch Loss: 37073.7134 - Avg Loss: 159.1146\n",
            "Epoch [45/50] - Batch loss: 154.0710 - Epoch Loss: 37227.7844 - Avg Loss: 159.0931\n",
            "Epoch [45/50] - Batch loss: 165.7512 - Epoch Loss: 37393.5356 - Avg Loss: 159.1214\n",
            "Epoch [45/50] - Batch loss: 163.1244 - Epoch Loss: 37556.6600 - Avg Loss: 159.1384\n",
            "Epoch [45/50] - Batch loss: 157.2729 - Epoch Loss: 37713.9328 - Avg Loss: 159.1305\n",
            "Epoch [45/50] - Batch loss: 158.3021 - Epoch Loss: 37872.2350 - Avg Loss: 159.1270\n",
            "Epoch [45/50] - Batch loss: 170.1805 - Epoch Loss: 38042.4155 - Avg Loss: 159.1733\n",
            "Epoch [45/50] - Batch loss: 155.5172 - Epoch Loss: 38197.9327 - Avg Loss: 159.1581\n",
            "Epoch [45/50] - Batch loss: 154.9578 - Epoch Loss: 38352.8905 - Avg Loss: 159.1406\n",
            "Epoch [45/50] - Batch loss: 159.7495 - Epoch Loss: 38512.6400 - Avg Loss: 159.1431\n",
            "Epoch [45/50] - Batch loss: 159.7840 - Epoch Loss: 38672.4240 - Avg Loss: 159.1458\n",
            "Epoch [45/50] - Batch loss: 159.7368 - Epoch Loss: 38832.1608 - Avg Loss: 159.1482\n",
            "Epoch [45/50] - Batch loss: 167.2442 - Epoch Loss: 38999.4050 - Avg Loss: 159.1812\n",
            "Epoch [45/50] - Batch loss: 163.2689 - Epoch Loss: 39162.6740 - Avg Loss: 159.1979\n",
            "Epoch [45/50] - Batch loss: 152.1787 - Epoch Loss: 39314.8527 - Avg Loss: 159.1694\n",
            "Epoch [45/50] - Batch loss: 156.9795 - Epoch Loss: 39471.8322 - Avg Loss: 159.1606\n",
            "Epoch [45/50] - Batch loss: 152.8863 - Epoch Loss: 39624.7185 - Avg Loss: 159.1354\n",
            "Epoch [45/50] - Batch loss: 155.3386 - Epoch Loss: 39780.0571 - Avg Loss: 159.1202\n",
            "Epoch [45/50] - Batch loss: 159.9925 - Epoch Loss: 39940.0496 - Avg Loss: 159.1237\n",
            "Epoch [45/50] - Batch loss: 161.3499 - Epoch Loss: 40101.3995 - Avg Loss: 159.1325\n",
            "Epoch [45/50] - Batch loss: 161.7369 - Epoch Loss: 40263.1364 - Avg Loss: 159.1428\n",
            "Epoch [45/50] - Batch loss: 155.0839 - Epoch Loss: 40418.2204 - Avg Loss: 159.1269\n",
            "Epoch [45/50] - Batch loss: 162.6380 - Epoch Loss: 40580.8583 - Avg Loss: 159.1406\n",
            "Epoch [45/50] - Batch loss: 158.6919 - Epoch Loss: 40739.5503 - Avg Loss: 159.1389\n",
            "Epoch [45/50] - Batch loss: 157.8183 - Epoch Loss: 40897.3686 - Avg Loss: 159.1337\n",
            "Epoch [45/50] - Batch loss: 157.5094 - Epoch Loss: 41054.8780 - Avg Loss: 159.1274\n",
            "Epoch [45/50] - Batch loss: 156.4681 - Epoch Loss: 41211.3461 - Avg Loss: 159.1172\n",
            "Epoch [45/50] - Batch loss: 158.6892 - Epoch Loss: 41370.0353 - Avg Loss: 159.1155\n",
            "Epoch [45/50] - Batch loss: 147.2423 - Epoch Loss: 41517.2776 - Avg Loss: 159.0700\n",
            "Epoch [45/50] - Batch loss: 158.0937 - Epoch Loss: 41675.3713 - Avg Loss: 159.0663\n",
            "Epoch [45/50] - Batch loss: 157.3871 - Epoch Loss: 41832.7584 - Avg Loss: 159.0599\n",
            "Epoch [45/50] - Batch loss: 161.0507 - Epoch Loss: 41993.8091 - Avg Loss: 159.0675\n",
            "Epoch [45/50] - Batch loss: 160.2309 - Epoch Loss: 42154.0400 - Avg Loss: 159.0718\n",
            "Epoch [45/50] - Batch loss: 166.1544 - Epoch Loss: 42320.1943 - Avg Loss: 159.0985\n",
            "Epoch [45/50] - Batch loss: 169.5453 - Epoch Loss: 42489.7396 - Avg Loss: 159.1376\n",
            "Epoch [45/50] - Batch loss: 154.2379 - Epoch Loss: 42643.9774 - Avg Loss: 159.1193\n",
            "Epoch [45/50] - Batch loss: 152.9314 - Epoch Loss: 42796.9089 - Avg Loss: 159.0963\n",
            "Epoch [45/50] - Batch loss: 162.9117 - Epoch Loss: 42959.8205 - Avg Loss: 159.1104\n",
            "Epoch [45/50] - Batch loss: 155.4882 - Epoch Loss: 43115.3088 - Avg Loss: 159.0971\n",
            "Epoch [45/50] - Batch loss: 160.2829 - Epoch Loss: 43275.5916 - Avg Loss: 159.1014\n",
            "Epoch [45/50] - Batch loss: 162.3192 - Epoch Loss: 43437.9108 - Avg Loss: 159.1132\n",
            "Epoch [45/50] - Batch loss: 173.0036 - Epoch Loss: 43610.9144 - Avg Loss: 159.1639\n",
            "Epoch [45/50] - Batch loss: 158.5096 - Epoch Loss: 43769.4240 - Avg Loss: 159.1615\n",
            "Epoch [45/50] - Batch loss: 154.2515 - Epoch Loss: 43923.6755 - Avg Loss: 159.1438\n",
            "Epoch [45/50] - Batch loss: 157.2119 - Epoch Loss: 44080.8874 - Avg Loss: 159.1368\n",
            "Epoch [45/50] - Batch loss: 156.4154 - Epoch Loss: 44237.3028 - Avg Loss: 159.1270\n",
            "Epoch [45/50] - Batch loss: 167.4765 - Epoch Loss: 44404.7793 - Avg Loss: 159.1569\n",
            "Epoch [45/50] - Batch loss: 166.1713 - Epoch Loss: 44570.9506 - Avg Loss: 159.1820\n",
            "Epoch [45/50] - Batch loss: 165.4922 - Epoch Loss: 44736.4429 - Avg Loss: 159.2044\n",
            "Epoch [45/50] - Batch loss: 169.0814 - Epoch Loss: 44905.5243 - Avg Loss: 159.2394\n",
            "Epoch [45/50] - Batch loss: 162.8298 - Epoch Loss: 45068.3541 - Avg Loss: 159.2521\n",
            "Epoch [45/50] - Batch loss: 164.5579 - Epoch Loss: 45232.9120 - Avg Loss: 159.2708\n",
            "Epoch [45/50] - Batch loss: 164.0975 - Epoch Loss: 45397.0096 - Avg Loss: 159.2878\n",
            "Epoch [45/50] - Batch loss: 166.4349 - Epoch Loss: 45563.4445 - Avg Loss: 159.3127\n",
            "Epoch [45/50] - Batch loss: 165.2216 - Epoch Loss: 45728.6662 - Avg Loss: 159.3333\n",
            "Epoch [45/50] - Batch loss: 160.7363 - Epoch Loss: 45889.4025 - Avg Loss: 159.3382\n",
            "Epoch [45/50] - Batch loss: 157.3861 - Epoch Loss: 46046.7886 - Avg Loss: 159.3314\n",
            "Epoch [45/50] - Batch loss: 165.7720 - Epoch Loss: 46212.5605 - Avg Loss: 159.3537\n",
            "Epoch [45/50] - Batch loss: 163.1671 - Epoch Loss: 46375.7276 - Avg Loss: 159.3668\n",
            "Epoch [45/50] - Batch loss: 158.7229 - Epoch Loss: 46534.4505 - Avg Loss: 159.3646\n",
            "Epoch [45/50] - Batch loss: 157.6946 - Epoch Loss: 46692.1451 - Avg Loss: 159.3589\n",
            "Epoch [45/50] - Batch loss: 161.8412 - Epoch Loss: 46853.9863 - Avg Loss: 159.3673\n",
            "Epoch [45/50] - Batch loss: 146.7376 - Epoch Loss: 47000.7239 - Avg Loss: 159.3245\n",
            "Epoch [45/50] - Batch loss: 160.8723 - Epoch Loss: 47161.5962 - Avg Loss: 159.3297\n",
            "Epoch [45/50] - Batch loss: 163.8737 - Epoch Loss: 47325.4698 - Avg Loss: 159.3450\n",
            "Epoch [45/50] - Batch loss: 153.8008 - Epoch Loss: 47479.2706 - Avg Loss: 159.3264\n",
            "Epoch [45/50] - Batch loss: 152.5099 - Epoch Loss: 47631.7805 - Avg Loss: 159.3036\n",
            "Epoch [45/50] - Batch loss: 162.6549 - Epoch Loss: 47794.4354 - Avg Loss: 159.3148\n",
            "Epoch [45/50] - Batch loss: 156.6429 - Epoch Loss: 47951.0783 - Avg Loss: 159.3059\n",
            "Epoch [45/50] - Batch loss: 161.3017 - Epoch Loss: 48112.3800 - Avg Loss: 159.3125\n",
            "Epoch [45/50] - Batch loss: 157.2022 - Epoch Loss: 48269.5822 - Avg Loss: 159.3056\n",
            "Epoch [45/50] - Batch loss: 159.1517 - Epoch Loss: 48428.7339 - Avg Loss: 159.3050\n",
            "Epoch [45/50] - Batch loss: 153.9522 - Epoch Loss: 48582.6862 - Avg Loss: 159.2875\n",
            "Epoch [45/50] - Batch loss: 158.1841 - Epoch Loss: 48740.8703 - Avg Loss: 159.2839\n",
            "Epoch [45/50] - Batch loss: 159.4874 - Epoch Loss: 48900.3577 - Avg Loss: 159.2846\n",
            "Epoch [45/50] - Batch loss: 164.3430 - Epoch Loss: 49064.7007 - Avg Loss: 159.3010\n",
            "Epoch [45/50] - Batch loss: 155.7328 - Epoch Loss: 49220.4335 - Avg Loss: 159.2894\n",
            "Epoch [45/50] - Batch loss: 157.4441 - Epoch Loss: 49377.8776 - Avg Loss: 159.2835\n",
            "Epoch [45/50] - Batch loss: 170.1475 - Epoch Loss: 49548.0251 - Avg Loss: 159.3184\n",
            "Epoch [45/50] - Batch loss: 160.8713 - Epoch Loss: 49708.8964 - Avg Loss: 159.3234\n",
            "Epoch [45/50] - Batch loss: 160.0666 - Epoch Loss: 49868.9630 - Avg Loss: 159.3258\n",
            "Epoch [45/50] - Batch loss: 156.2697 - Epoch Loss: 50025.2327 - Avg Loss: 159.3160\n",
            "Epoch [45/50] - Batch loss: 159.7381 - Epoch Loss: 50184.9709 - Avg Loss: 159.3174\n",
            "Epoch [45/50] - Batch loss: 160.9388 - Epoch Loss: 50345.9097 - Avg Loss: 159.3225\n",
            "Epoch [45/50] - Batch loss: 153.1284 - Epoch Loss: 50499.0381 - Avg Loss: 159.3030\n",
            "Epoch [45/50] - Batch loss: 159.5493 - Epoch Loss: 50658.5874 - Avg Loss: 159.3037\n",
            "Epoch [45/50] - Batch loss: 158.8268 - Epoch Loss: 50817.4143 - Avg Loss: 159.3022\n",
            "Epoch [45/50] - Batch loss: 157.9962 - Epoch Loss: 50975.4105 - Avg Loss: 159.2982\n",
            "Epoch [45/50] - Batch loss: 160.3818 - Epoch Loss: 51135.7923 - Avg Loss: 159.3015\n",
            "Epoch [45/50] - Batch loss: 158.6010 - Epoch Loss: 51294.3932 - Avg Loss: 159.2994\n",
            "Epoch [45/50] - Batch loss: 157.0171 - Epoch Loss: 51451.4103 - Avg Loss: 159.2923\n",
            "Epoch [45/50] - Batch loss: 168.3894 - Epoch Loss: 51619.7997 - Avg Loss: 159.3204\n",
            "Epoch [45/50] - Batch loss: 158.5301 - Epoch Loss: 51778.3298 - Avg Loss: 159.3179\n",
            "Epoch [45/50] - Batch loss: 152.3829 - Epoch Loss: 51930.7127 - Avg Loss: 159.2967\n",
            "Epoch [45/50] - Batch loss: 160.6613 - Epoch Loss: 52091.3740 - Avg Loss: 159.3008\n",
            "Epoch [45/50] - Batch loss: 158.9249 - Epoch Loss: 52250.2988 - Avg Loss: 159.2997\n",
            "Epoch [45/50] - Batch loss: 165.2770 - Epoch Loss: 52415.5758 - Avg Loss: 159.3179\n",
            "Epoch [45/50] - Batch loss: 166.0449 - Epoch Loss: 52581.6207 - Avg Loss: 159.3382\n",
            "Epoch [45/50] - Batch loss: 149.6258 - Epoch Loss: 52731.2465 - Avg Loss: 159.3089\n",
            "Epoch [45/50] - Batch loss: 156.7702 - Epoch Loss: 52888.0167 - Avg Loss: 159.3013\n",
            "Epoch [45/50] - Batch loss: 162.9241 - Epoch Loss: 53050.9408 - Avg Loss: 159.3121\n",
            "Epoch [45/50] - Batch loss: 156.8124 - Epoch Loss: 53207.7532 - Avg Loss: 159.3047\n",
            "Epoch [45/50] - Batch loss: 161.3957 - Epoch Loss: 53369.1489 - Avg Loss: 159.3109\n",
            "Epoch [45/50] - Batch loss: 164.5453 - Epoch Loss: 53533.6942 - Avg Loss: 159.3265\n",
            "Epoch [45/50] - Batch loss: 157.4811 - Epoch Loss: 53691.1753 - Avg Loss: 159.3210\n",
            "Epoch [45/50] - Batch loss: 163.0170 - Epoch Loss: 53854.1923 - Avg Loss: 159.3319\n",
            "Epoch [45/50] - Batch loss: 153.3157 - Epoch Loss: 54007.5080 - Avg Loss: 159.3142\n",
            "Epoch [45/50] - Batch loss: 160.0527 - Epoch Loss: 54167.5607 - Avg Loss: 159.3164\n",
            "Epoch [45/50] - Batch loss: 152.8949 - Epoch Loss: 54320.4555 - Avg Loss: 159.2975\n",
            "Epoch [45/50] - Batch loss: 162.4466 - Epoch Loss: 54482.9021 - Avg Loss: 159.3067\n",
            "Epoch [45/50] - Batch loss: 161.7842 - Epoch Loss: 54644.6864 - Avg Loss: 159.3140\n",
            "Epoch [45/50] - Batch loss: 157.6458 - Epoch Loss: 54802.3322 - Avg Loss: 159.3091\n",
            "Epoch [45/50] - Batch loss: 158.0780 - Epoch Loss: 54960.4102 - Avg Loss: 159.3055\n",
            "Epoch [45/50] - Batch loss: 173.7426 - Epoch Loss: 55134.1528 - Avg Loss: 159.3473\n",
            "Epoch [45/50] - Batch loss: 165.0666 - Epoch Loss: 55299.2194 - Avg Loss: 159.3637\n",
            "Epoch [45/50] - Batch loss: 163.7373 - Epoch Loss: 55462.9567 - Avg Loss: 159.3763\n",
            "Epoch [45/50] - Batch loss: 160.5816 - Epoch Loss: 55623.5383 - Avg Loss: 159.3798\n",
            "Epoch [45/50] - Batch loss: 158.8195 - Epoch Loss: 55782.3578 - Avg Loss: 159.3782\n",
            "Epoch [45/50] - Batch loss: 161.3517 - Epoch Loss: 55943.7095 - Avg Loss: 159.3838\n",
            "Epoch [45/50] - Batch loss: 154.5706 - Epoch Loss: 56098.2801 - Avg Loss: 159.3701\n",
            "Epoch [45/50] - Batch loss: 156.3020 - Epoch Loss: 56254.5821 - Avg Loss: 159.3614\n",
            "Epoch [45/50] - Batch loss: 151.1185 - Epoch Loss: 56405.7006 - Avg Loss: 159.3381\n",
            "Epoch [45/50] - Batch loss: 152.9332 - Epoch Loss: 56558.6338 - Avg Loss: 159.3201\n",
            "Epoch [45/50] - Batch loss: 151.5811 - Epoch Loss: 56710.2149 - Avg Loss: 159.2984\n",
            "Epoch [45/50] - Batch loss: 160.0110 - Epoch Loss: 56870.2260 - Avg Loss: 159.3004\n",
            "Epoch [45/50] - Batch loss: 157.8254 - Epoch Loss: 57028.0513 - Avg Loss: 159.2962\n",
            "Epoch [45/50] - Batch loss: 156.7499 - Epoch Loss: 57184.8013 - Avg Loss: 159.2891\n",
            "Epoch [45/50] - Batch loss: 168.6714 - Epoch Loss: 57353.4727 - Avg Loss: 159.3152\n",
            "Epoch [45/50] - Batch loss: 161.8985 - Epoch Loss: 57515.3712 - Avg Loss: 159.3224\n",
            "Epoch [45/50] - Batch loss: 170.2305 - Epoch Loss: 57685.6016 - Avg Loss: 159.3525\n",
            "Epoch [45/50] - Batch loss: 156.5628 - Epoch Loss: 57842.1644 - Avg Loss: 159.3448\n",
            "Epoch [45/50] - Batch loss: 163.5643 - Epoch Loss: 58005.7287 - Avg Loss: 159.3564\n",
            "Epoch [45/50] - Batch loss: 155.5865 - Epoch Loss: 58161.3152 - Avg Loss: 159.3461\n",
            "Epoch [45/50] - Batch loss: 154.9588 - Epoch Loss: 58316.2740 - Avg Loss: 159.3341\n",
            "Epoch [45/50] - Batch loss: 168.1906 - Epoch Loss: 58484.4646 - Avg Loss: 159.3582\n",
            "Epoch [45/50] - Batch loss: 155.6868 - Epoch Loss: 58640.1514 - Avg Loss: 159.3482\n",
            "Epoch [45/50] - Batch loss: 160.4016 - Epoch Loss: 58800.5531 - Avg Loss: 159.3511\n",
            "Epoch [45/50] - Batch loss: 158.8315 - Epoch Loss: 58959.3846 - Avg Loss: 159.3497\n",
            "Epoch [45/50] - Batch loss: 154.4732 - Epoch Loss: 59113.8578 - Avg Loss: 159.3365\n",
            "Epoch [45/50] - Batch loss: 162.8685 - Epoch Loss: 59276.7263 - Avg Loss: 159.3460\n",
            "Epoch [45/50] - Batch loss: 170.4449 - Epoch Loss: 59447.1712 - Avg Loss: 159.3758\n",
            "Epoch [45/50] - Batch loss: 159.5656 - Epoch Loss: 59606.7369 - Avg Loss: 159.3763\n",
            "Epoch [45/50] - Batch loss: 162.5731 - Epoch Loss: 59769.3100 - Avg Loss: 159.3848\n",
            "Epoch [45/50] - Batch loss: 167.2713 - Epoch Loss: 59936.5813 - Avg Loss: 159.4058\n",
            "Epoch [45/50] - Batch loss: 161.3514 - Epoch Loss: 60097.9327 - Avg Loss: 159.4110\n",
            "Epoch [45/50] - Batch loss: 164.2514 - Epoch Loss: 60262.1841 - Avg Loss: 159.4238\n",
            "Epoch [45/50] - Batch loss: 161.6750 - Epoch Loss: 60423.8590 - Avg Loss: 159.4297\n",
            "Epoch [45/50] - Batch loss: 162.4200 - Epoch Loss: 60586.2790 - Avg Loss: 159.4376\n",
            "Epoch [45/50] - Batch loss: 152.7260 - Epoch Loss: 60739.0050 - Avg Loss: 159.4200\n",
            "Epoch [45/50] - Batch loss: 157.5654 - Epoch Loss: 60896.5704 - Avg Loss: 159.4151\n",
            "Epoch [45/50] - Batch loss: 168.4779 - Epoch Loss: 61065.0483 - Avg Loss: 159.4388\n",
            "Epoch [45/50] - Batch loss: 165.4254 - Epoch Loss: 61230.4737 - Avg Loss: 159.4544\n",
            "Epoch [45/50] - Batch loss: 158.7955 - Epoch Loss: 61389.2692 - Avg Loss: 159.4526\n",
            "Epoch [45/50] - Batch loss: 157.0253 - Epoch Loss: 61546.2945 - Avg Loss: 159.4464\n",
            "Epoch [45/50] - Batch loss: 164.8251 - Epoch Loss: 61711.1196 - Avg Loss: 159.4603\n",
            "Epoch [45/50] - Batch loss: 154.0649 - Epoch Loss: 61865.1846 - Avg Loss: 159.4464\n",
            "Epoch [45/50] - Batch loss: 161.5787 - Epoch Loss: 62026.7633 - Avg Loss: 159.4518\n",
            "Epoch [45/50] - Batch loss: 162.1107 - Epoch Loss: 62188.8740 - Avg Loss: 159.4587\n",
            "Epoch [45/50] - Batch loss: 160.6514 - Epoch Loss: 62349.5254 - Avg Loss: 159.4617\n",
            "Epoch [45/50] - Batch loss: 155.2023 - Epoch Loss: 62504.7277 - Avg Loss: 159.4508\n",
            "Epoch [45/50] - Batch loss: 167.8569 - Epoch Loss: 62672.5846 - Avg Loss: 159.4722\n",
            "Epoch [45/50] - Batch loss: 160.0902 - Epoch Loss: 62832.6748 - Avg Loss: 159.4738\n",
            "Epoch [45/50] - Batch loss: 159.4142 - Epoch Loss: 62992.0890 - Avg Loss: 159.4736\n",
            "Epoch [45/50] - Batch loss: 164.1597 - Epoch Loss: 63156.2487 - Avg Loss: 159.4855\n",
            "Epoch [45/50] - Batch loss: 161.5419 - Epoch Loss: 63317.7906 - Avg Loss: 159.4907\n",
            "Epoch [45/50] - Batch loss: 164.4262 - Epoch Loss: 63482.2168 - Avg Loss: 159.5031\n",
            "Epoch [45/50] - Batch loss: 159.0510 - Epoch Loss: 63641.2678 - Avg Loss: 159.5019\n",
            "Epoch [45/50] - Batch loss: 157.1407 - Epoch Loss: 63798.4085 - Avg Loss: 159.4960\n",
            "Epoch [45/50] - Batch loss: 155.9539 - Epoch Loss: 63954.3625 - Avg Loss: 159.4872\n",
            "Epoch [45/50] - Batch loss: 154.5339 - Epoch Loss: 64108.8964 - Avg Loss: 159.4749\n",
            "Epoch [45/50] - Batch loss: 164.0680 - Epoch Loss: 64272.9644 - Avg Loss: 159.4863\n",
            "Epoch [45/50] - Batch loss: 159.5442 - Epoch Loss: 64432.5086 - Avg Loss: 159.4864\n",
            "Epoch [45/50] - Batch loss: 155.0527 - Epoch Loss: 64587.5613 - Avg Loss: 159.4755\n",
            "Epoch [45/50] - Batch loss: 152.8960 - Epoch Loss: 64740.4573 - Avg Loss: 159.4593\n",
            "Epoch [45/50] - Batch loss: 157.7195 - Epoch Loss: 64898.1768 - Avg Loss: 159.4550\n",
            "Epoch [45/50] - Batch loss: 160.2551 - Epoch Loss: 65058.4319 - Avg Loss: 159.4569\n",
            "Epoch [45/50] - Batch loss: 156.4399 - Epoch Loss: 65214.8718 - Avg Loss: 159.4496\n",
            "Epoch [45/50] - Batch loss: 164.8807 - Epoch Loss: 65379.7525 - Avg Loss: 159.4628\n",
            "Epoch [45/50] - Batch loss: 153.5540 - Epoch Loss: 65533.3064 - Avg Loss: 159.4484\n",
            "Epoch [45/50] - Batch loss: 163.9534 - Epoch Loss: 65697.2599 - Avg Loss: 159.4594\n",
            "Epoch [45/50] - Batch loss: 165.2085 - Epoch Loss: 65862.4684 - Avg Loss: 159.4733\n",
            "Epoch [45/50] - Batch loss: 159.0274 - Epoch Loss: 66021.4958 - Avg Loss: 159.4722\n",
            "Epoch [45/50] - Batch loss: 163.9816 - Epoch Loss: 66185.4774 - Avg Loss: 159.4831\n",
            "Epoch [45/50] - Batch loss: 159.7790 - Epoch Loss: 66345.2564 - Avg Loss: 159.4838\n",
            "Epoch [45/50] - Batch loss: 158.6408 - Epoch Loss: 66503.8972 - Avg Loss: 159.4818\n",
            "Epoch [45/50] - Batch loss: 170.2889 - Epoch Loss: 66674.1861 - Avg Loss: 159.5076\n",
            "Epoch [45/50] - Batch loss: 157.7030 - Epoch Loss: 66831.8891 - Avg Loss: 159.5033\n",
            "Epoch [45/50] - Batch loss: 159.5482 - Epoch Loss: 66991.4373 - Avg Loss: 159.5034\n",
            "Epoch [45/50] - Batch loss: 156.6743 - Epoch Loss: 67148.1115 - Avg Loss: 159.4967\n",
            "Epoch [45/50] - Batch loss: 164.0845 - Epoch Loss: 67312.1961 - Avg Loss: 159.5076\n",
            "Epoch [45/50] - Batch loss: 153.7518 - Epoch Loss: 67465.9478 - Avg Loss: 159.4940\n",
            "Epoch [45/50] - Batch loss: 159.1141 - Epoch Loss: 67625.0620 - Avg Loss: 159.4931\n",
            "Epoch [45/50] - Batch loss: 161.7496 - Epoch Loss: 67786.8116 - Avg Loss: 159.4984\n",
            "Epoch [45/50] - Batch loss: 162.1772 - Epoch Loss: 67948.9888 - Avg Loss: 159.5047\n",
            "Epoch [45/50] - Batch loss: 158.6597 - Epoch Loss: 68107.6485 - Avg Loss: 159.5027\n",
            "Epoch [45/50] - Batch loss: 158.3082 - Epoch Loss: 68265.9566 - Avg Loss: 159.4999\n",
            "Epoch [45/50] - Batch loss: 164.0252 - Epoch Loss: 68429.9818 - Avg Loss: 159.5104\n",
            "Epoch [45/50] - Batch loss: 156.1770 - Epoch Loss: 68586.1588 - Avg Loss: 159.5027\n",
            "Epoch [45/50] - Batch loss: 158.2491 - Epoch Loss: 68744.4080 - Avg Loss: 159.4998\n",
            "Epoch [45/50] - Batch loss: 160.2422 - Epoch Loss: 68904.6502 - Avg Loss: 159.5015\n",
            "Epoch [45/50] - Batch loss: 156.5760 - Epoch Loss: 69061.2263 - Avg Loss: 159.4947\n",
            "Epoch [45/50] - Batch loss: 153.8559 - Epoch Loss: 69215.0822 - Avg Loss: 159.4818\n",
            "Epoch [45/50] - Batch loss: 165.0315 - Epoch Loss: 69380.1136 - Avg Loss: 159.4945\n",
            "Epoch [45/50] - Batch loss: 164.1127 - Epoch Loss: 69544.2263 - Avg Loss: 159.5051\n",
            "Epoch [45/50] - Batch loss: 162.4404 - Epoch Loss: 69706.6667 - Avg Loss: 159.5118\n",
            "Epoch [45/50] - Batch loss: 163.6650 - Epoch Loss: 69870.3317 - Avg Loss: 159.5213\n",
            "Epoch [45/50] - Batch loss: 161.4476 - Epoch Loss: 70031.7793 - Avg Loss: 159.5257\n",
            "Epoch [45/50] - Batch loss: 160.4326 - Epoch Loss: 70192.2119 - Avg Loss: 159.5278\n",
            "Epoch [45/50] - Batch loss: 161.0290 - Epoch Loss: 70353.2409 - Avg Loss: 159.5312\n",
            "Epoch [45/50] - Batch loss: 161.8510 - Epoch Loss: 70515.0919 - Avg Loss: 159.5364\n",
            "Epoch [45/50] - Batch loss: 155.8947 - Epoch Loss: 70670.9866 - Avg Loss: 159.5282\n",
            "Epoch [45/50] - Batch loss: 162.2701 - Epoch Loss: 70833.2567 - Avg Loss: 159.5344\n",
            "Epoch [45/50] - Batch loss: 161.7078 - Epoch Loss: 70994.9645 - Avg Loss: 159.5392\n",
            "Epoch [45/50] - Batch loss: 155.9355 - Epoch Loss: 71150.9000 - Avg Loss: 159.5312\n",
            "Epoch [45/50] - Batch loss: 156.6398 - Epoch Loss: 71307.5399 - Avg Loss: 159.5247\n",
            "Epoch [45/50] - Batch loss: 155.1007 - Epoch Loss: 71462.6406 - Avg Loss: 159.5148\n",
            "Epoch [45/50] - Batch loss: 162.3430 - Epoch Loss: 71624.9836 - Avg Loss: 159.5211\n",
            "Epoch [45/50] - Batch loss: 160.8718 - Epoch Loss: 71785.8554 - Avg Loss: 159.5241\n",
            "Epoch [45/50] - Batch loss: 157.2256 - Epoch Loss: 71943.0810 - Avg Loss: 159.5190\n",
            "Epoch [45/50] - Batch loss: 163.8483 - Epoch Loss: 72106.9293 - Avg Loss: 159.5286\n",
            "Epoch [45/50] - Batch loss: 151.2804 - Epoch Loss: 72258.2097 - Avg Loss: 159.5104\n",
            "Epoch [45/50] - Batch loss: 150.7936 - Epoch Loss: 72409.0033 - Avg Loss: 159.4912\n",
            "Epoch [45/50] - Batch loss: 156.2083 - Epoch Loss: 72565.2116 - Avg Loss: 159.4840\n",
            "Epoch [45/50] - Batch loss: 157.7180 - Epoch Loss: 72722.9297 - Avg Loss: 159.4801\n",
            "Epoch [45/50] - Batch loss: 158.3485 - Epoch Loss: 72881.2782 - Avg Loss: 159.4776\n",
            "Epoch [45/50] - Batch loss: 156.2641 - Epoch Loss: 73037.5423 - Avg Loss: 159.4706\n",
            "Epoch [45/50] - Batch loss: 154.2685 - Epoch Loss: 73191.8108 - Avg Loss: 159.4593\n",
            "Epoch [45/50] - Batch loss: 151.2537 - Epoch Loss: 73343.0645 - Avg Loss: 159.4414\n",
            "Epoch [45/50] - Batch loss: 162.7472 - Epoch Loss: 73505.8117 - Avg Loss: 159.4486\n",
            "Epoch [45/50] - Batch loss: 158.6540 - Epoch Loss: 73664.4657 - Avg Loss: 159.4469\n",
            "Epoch [45/50] - Batch loss: 164.2806 - Epoch Loss: 73828.7463 - Avg Loss: 159.4573\n",
            "Epoch [45/50] - Batch loss: 160.5477 - Epoch Loss: 73989.2941 - Avg Loss: 159.4597\n",
            "Epoch [45/50] - Batch loss: 153.8291 - Epoch Loss: 74143.1231 - Avg Loss: 159.4476\n",
            "Epoch [45/50] - Batch loss: 165.8739 - Epoch Loss: 74308.9970 - Avg Loss: 159.4614\n",
            "Epoch [45/50] - Batch loss: 162.4298 - Epoch Loss: 74471.4268 - Avg Loss: 159.4677\n",
            "Epoch [45/50] - Batch loss: 160.0060 - Epoch Loss: 74631.4328 - Avg Loss: 159.4689\n",
            "Epoch [45/50] - Batch loss: 155.3916 - Epoch Loss: 74786.8244 - Avg Loss: 159.4602\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 46/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "919bdf3d6f384f92a2808220e6b095bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [46/50] - Batch loss: 153.7722 - Epoch Loss: 153.7722 - Avg Loss: 153.7722\n",
            "Epoch [46/50] - Batch loss: 157.5390 - Epoch Loss: 311.3113 - Avg Loss: 155.6556\n",
            "Epoch [46/50] - Batch loss: 163.3401 - Epoch Loss: 474.6514 - Avg Loss: 158.2171\n",
            "Epoch [46/50] - Batch loss: 155.8609 - Epoch Loss: 630.5122 - Avg Loss: 157.6281\n",
            "Epoch [46/50] - Batch loss: 159.6401 - Epoch Loss: 790.1523 - Avg Loss: 158.0305\n",
            "Epoch [46/50] - Batch loss: 162.9183 - Epoch Loss: 953.0706 - Avg Loss: 158.8451\n",
            "Epoch [46/50] - Batch loss: 168.7677 - Epoch Loss: 1121.8383 - Avg Loss: 160.2626\n",
            "Epoch [46/50] - Batch loss: 154.1742 - Epoch Loss: 1276.0125 - Avg Loss: 159.5016\n",
            "Epoch [46/50] - Batch loss: 156.0396 - Epoch Loss: 1432.0521 - Avg Loss: 159.1169\n",
            "Epoch [46/50] - Batch loss: 156.7239 - Epoch Loss: 1588.7760 - Avg Loss: 158.8776\n",
            "Epoch [46/50] - Batch loss: 160.6540 - Epoch Loss: 1749.4300 - Avg Loss: 159.0391\n",
            "Epoch [46/50] - Batch loss: 157.2661 - Epoch Loss: 1906.6961 - Avg Loss: 158.8913\n",
            "Epoch [46/50] - Batch loss: 161.5312 - Epoch Loss: 2068.2273 - Avg Loss: 159.0944\n",
            "Epoch [46/50] - Batch loss: 159.7008 - Epoch Loss: 2227.9281 - Avg Loss: 159.1377\n",
            "Epoch [46/50] - Batch loss: 158.4680 - Epoch Loss: 2386.3961 - Avg Loss: 159.0931\n",
            "Epoch [46/50] - Batch loss: 166.5109 - Epoch Loss: 2552.9070 - Avg Loss: 159.5567\n",
            "Epoch [46/50] - Batch loss: 163.5742 - Epoch Loss: 2716.4812 - Avg Loss: 159.7930\n",
            "Epoch [46/50] - Batch loss: 157.6303 - Epoch Loss: 2874.1115 - Avg Loss: 159.6729\n",
            "Epoch [46/50] - Batch loss: 158.1458 - Epoch Loss: 3032.2573 - Avg Loss: 159.5925\n",
            "Epoch [46/50] - Batch loss: 163.5899 - Epoch Loss: 3195.8472 - Avg Loss: 159.7924\n",
            "Epoch [46/50] - Batch loss: 156.9491 - Epoch Loss: 3352.7963 - Avg Loss: 159.6570\n",
            "Epoch [46/50] - Batch loss: 163.4619 - Epoch Loss: 3516.2582 - Avg Loss: 159.8299\n",
            "Epoch [46/50] - Batch loss: 155.6745 - Epoch Loss: 3671.9327 - Avg Loss: 159.6492\n",
            "Epoch [46/50] - Batch loss: 164.2751 - Epoch Loss: 3836.2077 - Avg Loss: 159.8420\n",
            "Epoch [46/50] - Batch loss: 159.3477 - Epoch Loss: 3995.5554 - Avg Loss: 159.8222\n",
            "Epoch [46/50] - Batch loss: 162.2541 - Epoch Loss: 4157.8095 - Avg Loss: 159.9157\n",
            "Epoch [46/50] - Batch loss: 155.7347 - Epoch Loss: 4313.5442 - Avg Loss: 159.7609\n",
            "Epoch [46/50] - Batch loss: 153.6556 - Epoch Loss: 4467.1998 - Avg Loss: 159.5428\n",
            "Epoch [46/50] - Batch loss: 161.1609 - Epoch Loss: 4628.3607 - Avg Loss: 159.5986\n",
            "Epoch [46/50] - Batch loss: 162.5914 - Epoch Loss: 4790.9521 - Avg Loss: 159.6984\n",
            "Epoch [46/50] - Batch loss: 160.7489 - Epoch Loss: 4951.7009 - Avg Loss: 159.7323\n",
            "Epoch [46/50] - Batch loss: 162.3946 - Epoch Loss: 5114.0955 - Avg Loss: 159.8155\n",
            "Epoch [46/50] - Batch loss: 158.3608 - Epoch Loss: 5272.4563 - Avg Loss: 159.7714\n",
            "Epoch [46/50] - Batch loss: 158.6418 - Epoch Loss: 5431.0982 - Avg Loss: 159.7382\n",
            "Epoch [46/50] - Batch loss: 161.9509 - Epoch Loss: 5593.0491 - Avg Loss: 159.8014\n",
            "Epoch [46/50] - Batch loss: 146.2530 - Epoch Loss: 5739.3020 - Avg Loss: 159.4251\n",
            "Epoch [46/50] - Batch loss: 160.7841 - Epoch Loss: 5900.0861 - Avg Loss: 159.4618\n",
            "Epoch [46/50] - Batch loss: 162.0211 - Epoch Loss: 6062.1073 - Avg Loss: 159.5291\n",
            "Epoch [46/50] - Batch loss: 158.7241 - Epoch Loss: 6220.8314 - Avg Loss: 159.5085\n",
            "Epoch [46/50] - Batch loss: 153.7095 - Epoch Loss: 6374.5409 - Avg Loss: 159.3635\n",
            "Epoch [46/50] - Batch loss: 167.5522 - Epoch Loss: 6542.0931 - Avg Loss: 159.5632\n",
            "Epoch [46/50] - Batch loss: 162.2556 - Epoch Loss: 6704.3487 - Avg Loss: 159.6273\n",
            "Epoch [46/50] - Batch loss: 161.8888 - Epoch Loss: 6866.2375 - Avg Loss: 159.6799\n",
            "Epoch [46/50] - Batch loss: 159.2936 - Epoch Loss: 7025.5311 - Avg Loss: 159.6712\n",
            "Epoch [46/50] - Batch loss: 159.7812 - Epoch Loss: 7185.3123 - Avg Loss: 159.6736\n",
            "Epoch [46/50] - Batch loss: 161.4454 - Epoch Loss: 7346.7577 - Avg Loss: 159.7121\n",
            "Epoch [46/50] - Batch loss: 159.2063 - Epoch Loss: 7505.9640 - Avg Loss: 159.7014\n",
            "Epoch [46/50] - Batch loss: 161.3358 - Epoch Loss: 7667.2998 - Avg Loss: 159.7354\n",
            "Epoch [46/50] - Batch loss: 168.1730 - Epoch Loss: 7835.4728 - Avg Loss: 159.9076\n",
            "Epoch [46/50] - Batch loss: 160.8945 - Epoch Loss: 7996.3673 - Avg Loss: 159.9273\n",
            "Epoch [46/50] - Batch loss: 154.9331 - Epoch Loss: 8151.3005 - Avg Loss: 159.8294\n",
            "Epoch [46/50] - Batch loss: 157.2238 - Epoch Loss: 8308.5242 - Avg Loss: 159.7793\n",
            "Epoch [46/50] - Batch loss: 170.9897 - Epoch Loss: 8479.5139 - Avg Loss: 159.9908\n",
            "Epoch [46/50] - Batch loss: 164.5014 - Epoch Loss: 8644.0154 - Avg Loss: 160.0744\n",
            "Epoch [46/50] - Batch loss: 159.3822 - Epoch Loss: 8803.3976 - Avg Loss: 160.0618\n",
            "Epoch [46/50] - Batch loss: 153.6685 - Epoch Loss: 8957.0660 - Avg Loss: 159.9476\n",
            "Epoch [46/50] - Batch loss: 158.8282 - Epoch Loss: 9115.8942 - Avg Loss: 159.9280\n",
            "Epoch [46/50] - Batch loss: 157.2085 - Epoch Loss: 9273.1027 - Avg Loss: 159.8811\n",
            "Epoch [46/50] - Batch loss: 154.7840 - Epoch Loss: 9427.8867 - Avg Loss: 159.7947\n",
            "Epoch [46/50] - Batch loss: 164.1022 - Epoch Loss: 9591.9889 - Avg Loss: 159.8665\n",
            "Epoch [46/50] - Batch loss: 158.7051 - Epoch Loss: 9750.6939 - Avg Loss: 159.8474\n",
            "Epoch [46/50] - Batch loss: 161.3452 - Epoch Loss: 9912.0391 - Avg Loss: 159.8716\n",
            "Epoch [46/50] - Batch loss: 159.9389 - Epoch Loss: 10071.9780 - Avg Loss: 159.8727\n",
            "Epoch [46/50] - Batch loss: 150.3954 - Epoch Loss: 10222.3734 - Avg Loss: 159.7246\n",
            "Epoch [46/50] - Batch loss: 150.7649 - Epoch Loss: 10373.1383 - Avg Loss: 159.5867\n",
            "Epoch [46/50] - Batch loss: 165.5095 - Epoch Loss: 10538.6478 - Avg Loss: 159.6765\n",
            "Epoch [46/50] - Batch loss: 159.3214 - Epoch Loss: 10697.9693 - Avg Loss: 159.6712\n",
            "Epoch [46/50] - Batch loss: 163.0402 - Epoch Loss: 10861.0094 - Avg Loss: 159.7207\n",
            "Epoch [46/50] - Batch loss: 150.8123 - Epoch Loss: 11011.8218 - Avg Loss: 159.5916\n",
            "Epoch [46/50] - Batch loss: 160.2837 - Epoch Loss: 11172.1054 - Avg Loss: 159.6015\n",
            "Epoch [46/50] - Batch loss: 164.4843 - Epoch Loss: 11336.5898 - Avg Loss: 159.6703\n",
            "Epoch [46/50] - Batch loss: 165.9985 - Epoch Loss: 11502.5882 - Avg Loss: 159.7582\n",
            "Epoch [46/50] - Batch loss: 163.6285 - Epoch Loss: 11666.2168 - Avg Loss: 159.8112\n",
            "Epoch [46/50] - Batch loss: 165.9111 - Epoch Loss: 11832.1279 - Avg Loss: 159.8936\n",
            "Epoch [46/50] - Batch loss: 151.9214 - Epoch Loss: 11984.0492 - Avg Loss: 159.7873\n",
            "Epoch [46/50] - Batch loss: 160.4406 - Epoch Loss: 12144.4898 - Avg Loss: 159.7959\n",
            "Epoch [46/50] - Batch loss: 155.7504 - Epoch Loss: 12300.2403 - Avg Loss: 159.7434\n",
            "Epoch [46/50] - Batch loss: 150.6966 - Epoch Loss: 12450.9369 - Avg Loss: 159.6274\n",
            "Epoch [46/50] - Batch loss: 158.1066 - Epoch Loss: 12609.0435 - Avg Loss: 159.6081\n",
            "Epoch [46/50] - Batch loss: 158.7018 - Epoch Loss: 12767.7453 - Avg Loss: 159.5968\n",
            "Epoch [46/50] - Batch loss: 168.5970 - Epoch Loss: 12936.3423 - Avg Loss: 159.7079\n",
            "Epoch [46/50] - Batch loss: 157.0936 - Epoch Loss: 13093.4359 - Avg Loss: 159.6760\n",
            "Epoch [46/50] - Batch loss: 166.8397 - Epoch Loss: 13260.2756 - Avg Loss: 159.7624\n",
            "Epoch [46/50] - Batch loss: 154.3735 - Epoch Loss: 13414.6490 - Avg Loss: 159.6982\n",
            "Epoch [46/50] - Batch loss: 159.5258 - Epoch Loss: 13574.1748 - Avg Loss: 159.6962\n",
            "Epoch [46/50] - Batch loss: 157.6346 - Epoch Loss: 13731.8094 - Avg Loss: 159.6722\n",
            "Epoch [46/50] - Batch loss: 159.7450 - Epoch Loss: 13891.5544 - Avg Loss: 159.6730\n",
            "Epoch [46/50] - Batch loss: 160.5554 - Epoch Loss: 14052.1098 - Avg Loss: 159.6831\n",
            "Epoch [46/50] - Batch loss: 158.6799 - Epoch Loss: 14210.7897 - Avg Loss: 159.6718\n",
            "Epoch [46/50] - Batch loss: 165.5376 - Epoch Loss: 14376.3273 - Avg Loss: 159.7370\n",
            "Epoch [46/50] - Batch loss: 159.8082 - Epoch Loss: 14536.1355 - Avg Loss: 159.7378\n",
            "Epoch [46/50] - Batch loss: 156.8402 - Epoch Loss: 14692.9758 - Avg Loss: 159.7063\n",
            "Epoch [46/50] - Batch loss: 159.9224 - Epoch Loss: 14852.8982 - Avg Loss: 159.7086\n",
            "Epoch [46/50] - Batch loss: 155.8610 - Epoch Loss: 15008.7592 - Avg Loss: 159.6677\n",
            "Epoch [46/50] - Batch loss: 166.1310 - Epoch Loss: 15174.8902 - Avg Loss: 159.7357\n",
            "Epoch [46/50] - Batch loss: 164.3368 - Epoch Loss: 15339.2270 - Avg Loss: 159.7836\n",
            "Epoch [46/50] - Batch loss: 161.0692 - Epoch Loss: 15500.2962 - Avg Loss: 159.7969\n",
            "Epoch [46/50] - Batch loss: 165.1433 - Epoch Loss: 15665.4395 - Avg Loss: 159.8514\n",
            "Epoch [46/50] - Batch loss: 166.3412 - Epoch Loss: 15831.7807 - Avg Loss: 159.9170\n",
            "Epoch [46/50] - Batch loss: 172.2069 - Epoch Loss: 16003.9876 - Avg Loss: 160.0399\n",
            "Epoch [46/50] - Batch loss: 160.5723 - Epoch Loss: 16164.5599 - Avg Loss: 160.0451\n",
            "Epoch [46/50] - Batch loss: 170.2851 - Epoch Loss: 16334.8451 - Avg Loss: 160.1455\n",
            "Epoch [46/50] - Batch loss: 171.0753 - Epoch Loss: 16505.9203 - Avg Loss: 160.2517\n",
            "Epoch [46/50] - Batch loss: 153.5516 - Epoch Loss: 16659.4719 - Avg Loss: 160.1872\n",
            "Epoch [46/50] - Batch loss: 159.9550 - Epoch Loss: 16819.4269 - Avg Loss: 160.1850\n",
            "Epoch [46/50] - Batch loss: 168.9576 - Epoch Loss: 16988.3845 - Avg Loss: 160.2678\n",
            "Epoch [46/50] - Batch loss: 162.8478 - Epoch Loss: 17151.2323 - Avg Loss: 160.2919\n",
            "Epoch [46/50] - Batch loss: 157.5173 - Epoch Loss: 17308.7496 - Avg Loss: 160.2662\n",
            "Epoch [46/50] - Batch loss: 159.5166 - Epoch Loss: 17468.2662 - Avg Loss: 160.2593\n",
            "Epoch [46/50] - Batch loss: 166.9720 - Epoch Loss: 17635.2382 - Avg Loss: 160.3203\n",
            "Epoch [46/50] - Batch loss: 166.0358 - Epoch Loss: 17801.2740 - Avg Loss: 160.3718\n",
            "Epoch [46/50] - Batch loss: 163.0490 - Epoch Loss: 17964.3229 - Avg Loss: 160.3957\n",
            "Epoch [46/50] - Batch loss: 154.0724 - Epoch Loss: 18118.3954 - Avg Loss: 160.3398\n",
            "Epoch [46/50] - Batch loss: 152.7516 - Epoch Loss: 18271.1469 - Avg Loss: 160.2732\n",
            "Epoch [46/50] - Batch loss: 166.4303 - Epoch Loss: 18437.5772 - Avg Loss: 160.3268\n",
            "Epoch [46/50] - Batch loss: 148.9113 - Epoch Loss: 18586.4885 - Avg Loss: 160.2283\n",
            "Epoch [46/50] - Batch loss: 163.4158 - Epoch Loss: 18749.9043 - Avg Loss: 160.2556\n",
            "Epoch [46/50] - Batch loss: 160.4184 - Epoch Loss: 18910.3227 - Avg Loss: 160.2570\n",
            "Epoch [46/50] - Batch loss: 154.2982 - Epoch Loss: 19064.6209 - Avg Loss: 160.2069\n",
            "Epoch [46/50] - Batch loss: 165.4430 - Epoch Loss: 19230.0639 - Avg Loss: 160.2505\n",
            "Epoch [46/50] - Batch loss: 162.0009 - Epoch Loss: 19392.0648 - Avg Loss: 160.2650\n",
            "Epoch [46/50] - Batch loss: 156.8359 - Epoch Loss: 19548.9007 - Avg Loss: 160.2369\n",
            "Epoch [46/50] - Batch loss: 161.5231 - Epoch Loss: 19710.4238 - Avg Loss: 160.2473\n",
            "Epoch [46/50] - Batch loss: 159.4289 - Epoch Loss: 19869.8527 - Avg Loss: 160.2407\n",
            "Epoch [46/50] - Batch loss: 163.7720 - Epoch Loss: 20033.6247 - Avg Loss: 160.2690\n",
            "Epoch [46/50] - Batch loss: 163.8868 - Epoch Loss: 20197.5115 - Avg Loss: 160.2977\n",
            "Epoch [46/50] - Batch loss: 166.8250 - Epoch Loss: 20364.3366 - Avg Loss: 160.3491\n",
            "Epoch [46/50] - Batch loss: 164.9560 - Epoch Loss: 20529.2926 - Avg Loss: 160.3851\n",
            "Epoch [46/50] - Batch loss: 160.8916 - Epoch Loss: 20690.1842 - Avg Loss: 160.3890\n",
            "Epoch [46/50] - Batch loss: 159.4079 - Epoch Loss: 20849.5921 - Avg Loss: 160.3815\n",
            "Epoch [46/50] - Batch loss: 154.5548 - Epoch Loss: 21004.1469 - Avg Loss: 160.3370\n",
            "Epoch [46/50] - Batch loss: 161.5683 - Epoch Loss: 21165.7152 - Avg Loss: 160.3463\n",
            "Epoch [46/50] - Batch loss: 157.7101 - Epoch Loss: 21323.4253 - Avg Loss: 160.3265\n",
            "Epoch [46/50] - Batch loss: 160.9678 - Epoch Loss: 21484.3931 - Avg Loss: 160.3313\n",
            "Epoch [46/50] - Batch loss: 160.5004 - Epoch Loss: 21644.8935 - Avg Loss: 160.3325\n",
            "Epoch [46/50] - Batch loss: 155.3022 - Epoch Loss: 21800.1956 - Avg Loss: 160.2956\n",
            "Epoch [46/50] - Batch loss: 160.2158 - Epoch Loss: 21960.4114 - Avg Loss: 160.2950\n",
            "Epoch [46/50] - Batch loss: 162.5695 - Epoch Loss: 22122.9809 - Avg Loss: 160.3115\n",
            "Epoch [46/50] - Batch loss: 156.9510 - Epoch Loss: 22279.9319 - Avg Loss: 160.2873\n",
            "Epoch [46/50] - Batch loss: 156.5371 - Epoch Loss: 22436.4690 - Avg Loss: 160.2605\n",
            "Epoch [46/50] - Batch loss: 167.0586 - Epoch Loss: 22603.5276 - Avg Loss: 160.3087\n",
            "Epoch [46/50] - Batch loss: 162.0439 - Epoch Loss: 22765.5715 - Avg Loss: 160.3209\n",
            "Epoch [46/50] - Batch loss: 164.5520 - Epoch Loss: 22930.1236 - Avg Loss: 160.3505\n",
            "Epoch [46/50] - Batch loss: 165.6767 - Epoch Loss: 23095.8003 - Avg Loss: 160.3875\n",
            "Epoch [46/50] - Batch loss: 167.6596 - Epoch Loss: 23263.4599 - Avg Loss: 160.4377\n",
            "Epoch [46/50] - Batch loss: 156.7883 - Epoch Loss: 23420.2482 - Avg Loss: 160.4127\n",
            "Epoch [46/50] - Batch loss: 155.1135 - Epoch Loss: 23575.3617 - Avg Loss: 160.3766\n",
            "Epoch [46/50] - Batch loss: 162.9902 - Epoch Loss: 23738.3518 - Avg Loss: 160.3943\n",
            "Epoch [46/50] - Batch loss: 160.8437 - Epoch Loss: 23899.1956 - Avg Loss: 160.3973\n",
            "Epoch [46/50] - Batch loss: 162.6379 - Epoch Loss: 24061.8334 - Avg Loss: 160.4122\n",
            "Epoch [46/50] - Batch loss: 162.5626 - Epoch Loss: 24224.3961 - Avg Loss: 160.4265\n",
            "Epoch [46/50] - Batch loss: 164.7128 - Epoch Loss: 24389.1088 - Avg Loss: 160.4547\n",
            "Epoch [46/50] - Batch loss: 164.0829 - Epoch Loss: 24553.1917 - Avg Loss: 160.4784\n",
            "Epoch [46/50] - Batch loss: 157.9358 - Epoch Loss: 24711.1275 - Avg Loss: 160.4619\n",
            "Epoch [46/50] - Batch loss: 159.7740 - Epoch Loss: 24870.9015 - Avg Loss: 160.4574\n",
            "Epoch [46/50] - Batch loss: 155.6901 - Epoch Loss: 25026.5916 - Avg Loss: 160.4269\n",
            "Epoch [46/50] - Batch loss: 160.4236 - Epoch Loss: 25187.0153 - Avg Loss: 160.4268\n",
            "Epoch [46/50] - Batch loss: 157.8844 - Epoch Loss: 25344.8996 - Avg Loss: 160.4108\n",
            "Epoch [46/50] - Batch loss: 166.7980 - Epoch Loss: 25511.6976 - Avg Loss: 160.4509\n",
            "Epoch [46/50] - Batch loss: 157.6199 - Epoch Loss: 25669.3175 - Avg Loss: 160.4332\n",
            "Epoch [46/50] - Batch loss: 167.2711 - Epoch Loss: 25836.5886 - Avg Loss: 160.4757\n",
            "Epoch [46/50] - Batch loss: 164.4178 - Epoch Loss: 26001.0064 - Avg Loss: 160.5000\n",
            "Epoch [46/50] - Batch loss: 159.6928 - Epoch Loss: 26160.6991 - Avg Loss: 160.4951\n",
            "Epoch [46/50] - Batch loss: 159.6774 - Epoch Loss: 26320.3765 - Avg Loss: 160.4901\n",
            "Epoch [46/50] - Batch loss: 158.5217 - Epoch Loss: 26478.8982 - Avg Loss: 160.4782\n",
            "Epoch [46/50] - Batch loss: 170.5694 - Epoch Loss: 26649.4676 - Avg Loss: 160.5390\n",
            "Epoch [46/50] - Batch loss: 163.0385 - Epoch Loss: 26812.5061 - Avg Loss: 160.5539\n",
            "Epoch [46/50] - Batch loss: 159.6863 - Epoch Loss: 26972.1925 - Avg Loss: 160.5488\n",
            "Epoch [46/50] - Batch loss: 160.3283 - Epoch Loss: 27132.5207 - Avg Loss: 160.5475\n",
            "Epoch [46/50] - Batch loss: 166.6520 - Epoch Loss: 27299.1727 - Avg Loss: 160.5834\n",
            "Epoch [46/50] - Batch loss: 144.9336 - Epoch Loss: 27444.1063 - Avg Loss: 160.4918\n",
            "Epoch [46/50] - Batch loss: 157.3709 - Epoch Loss: 27601.4772 - Avg Loss: 160.4737\n",
            "Epoch [46/50] - Batch loss: 162.0275 - Epoch Loss: 27763.5047 - Avg Loss: 160.4827\n",
            "Epoch [46/50] - Batch loss: 168.2818 - Epoch Loss: 27931.7865 - Avg Loss: 160.5275\n",
            "Epoch [46/50] - Batch loss: 163.6902 - Epoch Loss: 28095.4768 - Avg Loss: 160.5456\n",
            "Epoch [46/50] - Batch loss: 157.9221 - Epoch Loss: 28253.3988 - Avg Loss: 160.5307\n",
            "Epoch [46/50] - Batch loss: 160.0233 - Epoch Loss: 28413.4222 - Avg Loss: 160.5278\n",
            "Epoch [46/50] - Batch loss: 171.5687 - Epoch Loss: 28584.9909 - Avg Loss: 160.5898\n",
            "Epoch [46/50] - Batch loss: 163.5979 - Epoch Loss: 28748.5888 - Avg Loss: 160.6066\n",
            "Epoch [46/50] - Batch loss: 170.0900 - Epoch Loss: 28918.6788 - Avg Loss: 160.6593\n",
            "Epoch [46/50] - Batch loss: 161.4728 - Epoch Loss: 29080.1517 - Avg Loss: 160.6638\n",
            "Epoch [46/50] - Batch loss: 157.2456 - Epoch Loss: 29237.3973 - Avg Loss: 160.6450\n",
            "Epoch [46/50] - Batch loss: 163.0018 - Epoch Loss: 29400.3991 - Avg Loss: 160.6579\n",
            "Epoch [46/50] - Batch loss: 160.5543 - Epoch Loss: 29560.9535 - Avg Loss: 160.6574\n",
            "Epoch [46/50] - Batch loss: 154.5426 - Epoch Loss: 29715.4960 - Avg Loss: 160.6243\n",
            "Epoch [46/50] - Batch loss: 159.6507 - Epoch Loss: 29875.1467 - Avg Loss: 160.6191\n",
            "Epoch [46/50] - Batch loss: 157.3332 - Epoch Loss: 30032.4799 - Avg Loss: 160.6015\n",
            "Epoch [46/50] - Batch loss: 161.7867 - Epoch Loss: 30194.2665 - Avg Loss: 160.6078\n",
            "Epoch [46/50] - Batch loss: 160.8208 - Epoch Loss: 30355.0873 - Avg Loss: 160.6089\n",
            "Epoch [46/50] - Batch loss: 169.0707 - Epoch Loss: 30524.1580 - Avg Loss: 160.6535\n",
            "Epoch [46/50] - Batch loss: 157.6860 - Epoch Loss: 30681.8440 - Avg Loss: 160.6379\n",
            "Epoch [46/50] - Batch loss: 161.5467 - Epoch Loss: 30843.3907 - Avg Loss: 160.6427\n",
            "Epoch [46/50] - Batch loss: 159.6102 - Epoch Loss: 31003.0009 - Avg Loss: 160.6373\n",
            "Epoch [46/50] - Batch loss: 157.7197 - Epoch Loss: 31160.7206 - Avg Loss: 160.6223\n",
            "Epoch [46/50] - Batch loss: 157.4652 - Epoch Loss: 31318.1858 - Avg Loss: 160.6061\n",
            "Epoch [46/50] - Batch loss: 165.1482 - Epoch Loss: 31483.3340 - Avg Loss: 160.6293\n",
            "Epoch [46/50] - Batch loss: 154.8277 - Epoch Loss: 31638.1617 - Avg Loss: 160.5998\n",
            "Epoch [46/50] - Batch loss: 159.1367 - Epoch Loss: 31797.2984 - Avg Loss: 160.5924\n",
            "Epoch [46/50] - Batch loss: 161.8059 - Epoch Loss: 31959.1043 - Avg Loss: 160.5985\n",
            "Epoch [46/50] - Batch loss: 163.3351 - Epoch Loss: 32122.4394 - Avg Loss: 160.6122\n",
            "Epoch [46/50] - Batch loss: 154.9583 - Epoch Loss: 32277.3977 - Avg Loss: 160.5841\n",
            "Epoch [46/50] - Batch loss: 164.9955 - Epoch Loss: 32442.3931 - Avg Loss: 160.6059\n",
            "Epoch [46/50] - Batch loss: 161.7717 - Epoch Loss: 32604.1649 - Avg Loss: 160.6116\n",
            "Epoch [46/50] - Batch loss: 165.3406 - Epoch Loss: 32769.5054 - Avg Loss: 160.6348\n",
            "Epoch [46/50] - Batch loss: 163.3238 - Epoch Loss: 32932.8292 - Avg Loss: 160.6479\n",
            "Epoch [46/50] - Batch loss: 155.1019 - Epoch Loss: 33087.9311 - Avg Loss: 160.6210\n",
            "Epoch [46/50] - Batch loss: 156.1719 - Epoch Loss: 33244.1030 - Avg Loss: 160.5995\n",
            "Epoch [46/50] - Batch loss: 154.7688 - Epoch Loss: 33398.8718 - Avg Loss: 160.5715\n",
            "Epoch [46/50] - Batch loss: 166.5099 - Epoch Loss: 33565.3817 - Avg Loss: 160.5999\n",
            "Epoch [46/50] - Batch loss: 167.3147 - Epoch Loss: 33732.6964 - Avg Loss: 160.6319\n",
            "Epoch [46/50] - Batch loss: 168.4956 - Epoch Loss: 33901.1920 - Avg Loss: 160.6692\n",
            "Epoch [46/50] - Batch loss: 160.9182 - Epoch Loss: 34062.1103 - Avg Loss: 160.6703\n",
            "Epoch [46/50] - Batch loss: 160.0367 - Epoch Loss: 34222.1469 - Avg Loss: 160.6674\n",
            "Epoch [46/50] - Batch loss: 159.4429 - Epoch Loss: 34381.5899 - Avg Loss: 160.6616\n",
            "Epoch [46/50] - Batch loss: 163.6275 - Epoch Loss: 34545.2174 - Avg Loss: 160.6754\n",
            "Epoch [46/50] - Batch loss: 158.0814 - Epoch Loss: 34703.2988 - Avg Loss: 160.6634\n",
            "Epoch [46/50] - Batch loss: 158.9088 - Epoch Loss: 34862.2076 - Avg Loss: 160.6553\n",
            "Epoch [46/50] - Batch loss: 156.9745 - Epoch Loss: 35019.1821 - Avg Loss: 160.6384\n",
            "Epoch [46/50] - Batch loss: 155.4058 - Epoch Loss: 35174.5879 - Avg Loss: 160.6146\n",
            "Epoch [46/50] - Batch loss: 155.1412 - Epoch Loss: 35329.7291 - Avg Loss: 160.5897\n",
            "Epoch [46/50] - Batch loss: 159.9921 - Epoch Loss: 35489.7212 - Avg Loss: 160.5870\n",
            "Epoch [46/50] - Batch loss: 168.0202 - Epoch Loss: 35657.7414 - Avg Loss: 160.6205\n",
            "Epoch [46/50] - Batch loss: 167.5380 - Epoch Loss: 35825.2794 - Avg Loss: 160.6515\n",
            "Epoch [46/50] - Batch loss: 164.0918 - Epoch Loss: 35989.3711 - Avg Loss: 160.6668\n",
            "Epoch [46/50] - Batch loss: 161.4453 - Epoch Loss: 36150.8164 - Avg Loss: 160.6703\n",
            "Epoch [46/50] - Batch loss: 161.6065 - Epoch Loss: 36312.4229 - Avg Loss: 160.6744\n",
            "Epoch [46/50] - Batch loss: 159.4351 - Epoch Loss: 36471.8580 - Avg Loss: 160.6690\n",
            "Epoch [46/50] - Batch loss: 159.3396 - Epoch Loss: 36631.1976 - Avg Loss: 160.6631\n",
            "Epoch [46/50] - Batch loss: 157.5180 - Epoch Loss: 36788.7156 - Avg Loss: 160.6494\n",
            "Epoch [46/50] - Batch loss: 162.4557 - Epoch Loss: 36951.1713 - Avg Loss: 160.6573\n",
            "Epoch [46/50] - Batch loss: 161.6635 - Epoch Loss: 37112.8348 - Avg Loss: 160.6616\n",
            "Epoch [46/50] - Batch loss: 162.4539 - Epoch Loss: 37275.2887 - Avg Loss: 160.6693\n",
            "Epoch [46/50] - Batch loss: 155.3973 - Epoch Loss: 37430.6860 - Avg Loss: 160.6467\n",
            "Epoch [46/50] - Batch loss: 159.3915 - Epoch Loss: 37590.0774 - Avg Loss: 160.6414\n",
            "Epoch [46/50] - Batch loss: 159.7197 - Epoch Loss: 37749.7971 - Avg Loss: 160.6374\n",
            "Epoch [46/50] - Batch loss: 156.4690 - Epoch Loss: 37906.2661 - Avg Loss: 160.6198\n",
            "Epoch [46/50] - Batch loss: 168.2011 - Epoch Loss: 38074.4672 - Avg Loss: 160.6518\n",
            "Epoch [46/50] - Batch loss: 160.0834 - Epoch Loss: 38234.5506 - Avg Loss: 160.6494\n",
            "Epoch [46/50] - Batch loss: 161.8622 - Epoch Loss: 38396.4128 - Avg Loss: 160.6544\n",
            "Epoch [46/50] - Batch loss: 152.2032 - Epoch Loss: 38548.6159 - Avg Loss: 160.6192\n",
            "Epoch [46/50] - Batch loss: 154.2025 - Epoch Loss: 38702.8184 - Avg Loss: 160.5926\n",
            "Epoch [46/50] - Batch loss: 156.9579 - Epoch Loss: 38859.7763 - Avg Loss: 160.5776\n",
            "Epoch [46/50] - Batch loss: 165.8579 - Epoch Loss: 39025.6341 - Avg Loss: 160.5993\n",
            "Epoch [46/50] - Batch loss: 156.2261 - Epoch Loss: 39181.8602 - Avg Loss: 160.5814\n",
            "Epoch [46/50] - Batch loss: 165.0136 - Epoch Loss: 39346.8738 - Avg Loss: 160.5995\n",
            "Epoch [46/50] - Batch loss: 158.4843 - Epoch Loss: 39505.3581 - Avg Loss: 160.5909\n",
            "Epoch [46/50] - Batch loss: 162.9846 - Epoch Loss: 39668.3427 - Avg Loss: 160.6006\n",
            "Epoch [46/50] - Batch loss: 167.2370 - Epoch Loss: 39835.5797 - Avg Loss: 160.6273\n",
            "Epoch [46/50] - Batch loss: 159.8458 - Epoch Loss: 39995.4256 - Avg Loss: 160.6242\n",
            "Epoch [46/50] - Batch loss: 159.8537 - Epoch Loss: 40155.2792 - Avg Loss: 160.6211\n",
            "Epoch [46/50] - Batch loss: 155.9553 - Epoch Loss: 40311.2345 - Avg Loss: 160.6025\n",
            "Epoch [46/50] - Batch loss: 170.2835 - Epoch Loss: 40481.5180 - Avg Loss: 160.6409\n",
            "Epoch [46/50] - Batch loss: 162.0388 - Epoch Loss: 40643.5568 - Avg Loss: 160.6465\n",
            "Epoch [46/50] - Batch loss: 156.9464 - Epoch Loss: 40800.5031 - Avg Loss: 160.6319\n",
            "Epoch [46/50] - Batch loss: 160.3447 - Epoch Loss: 40960.8478 - Avg Loss: 160.6308\n",
            "Epoch [46/50] - Batch loss: 161.9892 - Epoch Loss: 41122.8370 - Avg Loss: 160.6361\n",
            "Epoch [46/50] - Batch loss: 155.9388 - Epoch Loss: 41278.7757 - Avg Loss: 160.6178\n",
            "Epoch [46/50] - Batch loss: 174.5414 - Epoch Loss: 41453.3172 - Avg Loss: 160.6718\n",
            "Epoch [46/50] - Batch loss: 158.2801 - Epoch Loss: 41611.5972 - Avg Loss: 160.6625\n",
            "Epoch [46/50] - Batch loss: 151.6134 - Epoch Loss: 41763.2107 - Avg Loss: 160.6277\n",
            "Epoch [46/50] - Batch loss: 156.9896 - Epoch Loss: 41920.2003 - Avg Loss: 160.6138\n",
            "Epoch [46/50] - Batch loss: 163.9290 - Epoch Loss: 42084.1292 - Avg Loss: 160.6264\n",
            "Epoch [46/50] - Batch loss: 167.9031 - Epoch Loss: 42252.0323 - Avg Loss: 160.6541\n",
            "Epoch [46/50] - Batch loss: 167.3531 - Epoch Loss: 42419.3854 - Avg Loss: 160.6795\n",
            "Epoch [46/50] - Batch loss: 162.6382 - Epoch Loss: 42582.0237 - Avg Loss: 160.6869\n",
            "Epoch [46/50] - Batch loss: 161.2733 - Epoch Loss: 42743.2969 - Avg Loss: 160.6891\n",
            "Epoch [46/50] - Batch loss: 168.4021 - Epoch Loss: 42911.6990 - Avg Loss: 160.7180\n",
            "Epoch [46/50] - Batch loss: 167.8164 - Epoch Loss: 43079.5154 - Avg Loss: 160.7445\n",
            "Epoch [46/50] - Batch loss: 156.5178 - Epoch Loss: 43236.0332 - Avg Loss: 160.7287\n",
            "Epoch [46/50] - Batch loss: 170.0896 - Epoch Loss: 43406.1229 - Avg Loss: 160.7634\n",
            "Epoch [46/50] - Batch loss: 169.1392 - Epoch Loss: 43575.2621 - Avg Loss: 160.7943\n",
            "Epoch [46/50] - Batch loss: 158.0088 - Epoch Loss: 43733.2709 - Avg Loss: 160.7841\n",
            "Epoch [46/50] - Batch loss: 168.5818 - Epoch Loss: 43901.8527 - Avg Loss: 160.8126\n",
            "Epoch [46/50] - Batch loss: 161.0204 - Epoch Loss: 44062.8731 - Avg Loss: 160.8134\n",
            "Epoch [46/50] - Batch loss: 167.4230 - Epoch Loss: 44230.2961 - Avg Loss: 160.8374\n",
            "Epoch [46/50] - Batch loss: 170.1211 - Epoch Loss: 44400.4171 - Avg Loss: 160.8711\n",
            "Epoch [46/50] - Batch loss: 151.4120 - Epoch Loss: 44551.8291 - Avg Loss: 160.8369\n",
            "Epoch [46/50] - Batch loss: 161.4403 - Epoch Loss: 44713.2694 - Avg Loss: 160.8391\n",
            "Epoch [46/50] - Batch loss: 158.4236 - Epoch Loss: 44871.6930 - Avg Loss: 160.8304\n",
            "Epoch [46/50] - Batch loss: 165.3490 - Epoch Loss: 45037.0420 - Avg Loss: 160.8466\n",
            "Epoch [46/50] - Batch loss: 157.6356 - Epoch Loss: 45194.6775 - Avg Loss: 160.8352\n",
            "Epoch [46/50] - Batch loss: 162.3657 - Epoch Loss: 45357.0432 - Avg Loss: 160.8406\n",
            "Epoch [46/50] - Batch loss: 158.5889 - Epoch Loss: 45515.6322 - Avg Loss: 160.8326\n",
            "Epoch [46/50] - Batch loss: 156.7972 - Epoch Loss: 45672.4294 - Avg Loss: 160.8184\n",
            "Epoch [46/50] - Batch loss: 159.9327 - Epoch Loss: 45832.3621 - Avg Loss: 160.8153\n",
            "Epoch [46/50] - Batch loss: 147.8371 - Epoch Loss: 45980.1992 - Avg Loss: 160.7699\n",
            "Epoch [46/50] - Batch loss: 164.1601 - Epoch Loss: 46144.3593 - Avg Loss: 160.7817\n",
            "Epoch [46/50] - Batch loss: 161.9468 - Epoch Loss: 46306.3061 - Avg Loss: 160.7858\n",
            "Epoch [46/50] - Batch loss: 152.7995 - Epoch Loss: 46459.1056 - Avg Loss: 160.7582\n",
            "Epoch [46/50] - Batch loss: 158.4240 - Epoch Loss: 46617.5296 - Avg Loss: 160.7501\n",
            "Epoch [46/50] - Batch loss: 159.7785 - Epoch Loss: 46777.3081 - Avg Loss: 160.7468\n",
            "Epoch [46/50] - Batch loss: 165.8052 - Epoch Loss: 46943.1133 - Avg Loss: 160.7641\n",
            "Epoch [46/50] - Batch loss: 161.4049 - Epoch Loss: 47104.5181 - Avg Loss: 160.7663\n",
            "Epoch [46/50] - Batch loss: 164.4053 - Epoch Loss: 47268.9234 - Avg Loss: 160.7787\n",
            "Epoch [46/50] - Batch loss: 156.2381 - Epoch Loss: 47425.1615 - Avg Loss: 160.7633\n",
            "Epoch [46/50] - Batch loss: 163.3588 - Epoch Loss: 47588.5203 - Avg Loss: 160.7720\n",
            "Epoch [46/50] - Batch loss: 159.6605 - Epoch Loss: 47748.1808 - Avg Loss: 160.7683\n",
            "Epoch [46/50] - Batch loss: 157.9617 - Epoch Loss: 47906.1425 - Avg Loss: 160.7589\n",
            "Epoch [46/50] - Batch loss: 161.1543 - Epoch Loss: 48067.2968 - Avg Loss: 160.7602\n",
            "Epoch [46/50] - Batch loss: 162.1601 - Epoch Loss: 48229.4569 - Avg Loss: 160.7649\n",
            "Epoch [46/50] - Batch loss: 164.9467 - Epoch Loss: 48394.4036 - Avg Loss: 160.7787\n",
            "Epoch [46/50] - Batch loss: 158.2928 - Epoch Loss: 48552.6964 - Avg Loss: 160.7705\n",
            "Epoch [46/50] - Batch loss: 159.4395 - Epoch Loss: 48712.1359 - Avg Loss: 160.7661\n",
            "Epoch [46/50] - Batch loss: 166.4626 - Epoch Loss: 48878.5985 - Avg Loss: 160.7849\n",
            "Epoch [46/50] - Batch loss: 165.8267 - Epoch Loss: 49044.4252 - Avg Loss: 160.8014\n",
            "Epoch [46/50] - Batch loss: 164.9277 - Epoch Loss: 49209.3529 - Avg Loss: 160.8149\n",
            "Epoch [46/50] - Batch loss: 163.2448 - Epoch Loss: 49372.5978 - Avg Loss: 160.8228\n",
            "Epoch [46/50] - Batch loss: 167.5507 - Epoch Loss: 49540.1485 - Avg Loss: 160.8446\n",
            "Epoch [46/50] - Batch loss: 169.6950 - Epoch Loss: 49709.8435 - Avg Loss: 160.8733\n",
            "Epoch [46/50] - Batch loss: 160.5539 - Epoch Loss: 49870.3974 - Avg Loss: 160.8722\n",
            "Epoch [46/50] - Batch loss: 163.9509 - Epoch Loss: 50034.3483 - Avg Loss: 160.8821\n",
            "Epoch [46/50] - Batch loss: 155.0308 - Epoch Loss: 50189.3791 - Avg Loss: 160.8634\n",
            "Epoch [46/50] - Batch loss: 160.9929 - Epoch Loss: 50350.3719 - Avg Loss: 160.8638\n",
            "Epoch [46/50] - Batch loss: 166.4380 - Epoch Loss: 50516.8100 - Avg Loss: 160.8816\n",
            "Epoch [46/50] - Batch loss: 161.9184 - Epoch Loss: 50678.7283 - Avg Loss: 160.8849\n",
            "Epoch [46/50] - Batch loss: 161.2361 - Epoch Loss: 50839.9644 - Avg Loss: 160.8860\n",
            "Epoch [46/50] - Batch loss: 159.7248 - Epoch Loss: 50999.6893 - Avg Loss: 160.8823\n",
            "Epoch [46/50] - Batch loss: 169.1594 - Epoch Loss: 51168.8486 - Avg Loss: 160.9083\n",
            "Epoch [46/50] - Batch loss: 152.8990 - Epoch Loss: 51321.7477 - Avg Loss: 160.8832\n",
            "Epoch [46/50] - Batch loss: 164.7398 - Epoch Loss: 51486.4875 - Avg Loss: 160.8953\n",
            "Epoch [46/50] - Batch loss: 162.3064 - Epoch Loss: 51648.7938 - Avg Loss: 160.8997\n",
            "Epoch [46/50] - Batch loss: 155.8801 - Epoch Loss: 51804.6740 - Avg Loss: 160.8841\n",
            "Epoch [46/50] - Batch loss: 164.4813 - Epoch Loss: 51969.1553 - Avg Loss: 160.8952\n",
            "Epoch [46/50] - Batch loss: 156.0288 - Epoch Loss: 52125.1841 - Avg Loss: 160.8802\n",
            "Epoch [46/50] - Batch loss: 164.4753 - Epoch Loss: 52289.6594 - Avg Loss: 160.8913\n",
            "Epoch [46/50] - Batch loss: 156.3068 - Epoch Loss: 52445.9662 - Avg Loss: 160.8772\n",
            "Epoch [46/50] - Batch loss: 159.3671 - Epoch Loss: 52605.3333 - Avg Loss: 160.8726\n",
            "Epoch [46/50] - Batch loss: 162.4534 - Epoch Loss: 52767.7866 - Avg Loss: 160.8774\n",
            "Epoch [46/50] - Batch loss: 159.3896 - Epoch Loss: 52927.1763 - Avg Loss: 160.8729\n",
            "Epoch [46/50] - Batch loss: 160.1425 - Epoch Loss: 53087.3188 - Avg Loss: 160.8707\n",
            "Epoch [46/50] - Batch loss: 161.2282 - Epoch Loss: 53248.5470 - Avg Loss: 160.8717\n",
            "Epoch [46/50] - Batch loss: 156.3595 - Epoch Loss: 53404.9065 - Avg Loss: 160.8582\n",
            "Epoch [46/50] - Batch loss: 157.9321 - Epoch Loss: 53562.8386 - Avg Loss: 160.8494\n",
            "Epoch [46/50] - Batch loss: 162.8147 - Epoch Loss: 53725.6533 - Avg Loss: 160.8552\n",
            "Epoch [46/50] - Batch loss: 164.0792 - Epoch Loss: 53889.7325 - Avg Loss: 160.8649\n",
            "Epoch [46/50] - Batch loss: 163.0998 - Epoch Loss: 54052.8323 - Avg Loss: 160.8715\n",
            "Epoch [46/50] - Batch loss: 155.5005 - Epoch Loss: 54208.3328 - Avg Loss: 160.8556\n",
            "Epoch [46/50] - Batch loss: 159.2957 - Epoch Loss: 54367.6286 - Avg Loss: 160.8510\n",
            "Epoch [46/50] - Batch loss: 164.2480 - Epoch Loss: 54531.8766 - Avg Loss: 160.8610\n",
            "Epoch [46/50] - Batch loss: 163.4189 - Epoch Loss: 54695.2955 - Avg Loss: 160.8685\n",
            "Epoch [46/50] - Batch loss: 166.5594 - Epoch Loss: 54861.8549 - Avg Loss: 160.8852\n",
            "Epoch [46/50] - Batch loss: 156.9733 - Epoch Loss: 55018.8283 - Avg Loss: 160.8738\n",
            "Epoch [46/50] - Batch loss: 153.2846 - Epoch Loss: 55172.1129 - Avg Loss: 160.8516\n",
            "Epoch [46/50] - Batch loss: 162.9888 - Epoch Loss: 55335.1017 - Avg Loss: 160.8579\n",
            "Epoch [46/50] - Batch loss: 162.0383 - Epoch Loss: 55497.1400 - Avg Loss: 160.8613\n",
            "Epoch [46/50] - Batch loss: 162.6566 - Epoch Loss: 55659.7966 - Avg Loss: 160.8665\n",
            "Epoch [46/50] - Batch loss: 154.6554 - Epoch Loss: 55814.4520 - Avg Loss: 160.8486\n",
            "Epoch [46/50] - Batch loss: 161.4087 - Epoch Loss: 55975.8607 - Avg Loss: 160.8502\n",
            "Epoch [46/50] - Batch loss: 159.1805 - Epoch Loss: 56135.0412 - Avg Loss: 160.8454\n",
            "Epoch [46/50] - Batch loss: 159.9423 - Epoch Loss: 56294.9835 - Avg Loss: 160.8428\n",
            "Epoch [46/50] - Batch loss: 153.8893 - Epoch Loss: 56448.8728 - Avg Loss: 160.8230\n",
            "Epoch [46/50] - Batch loss: 164.7217 - Epoch Loss: 56613.5944 - Avg Loss: 160.8341\n",
            "Epoch [46/50] - Batch loss: 153.7671 - Epoch Loss: 56767.3615 - Avg Loss: 160.8141\n",
            "Epoch [46/50] - Batch loss: 161.9825 - Epoch Loss: 56929.3441 - Avg Loss: 160.8174\n",
            "Epoch [46/50] - Batch loss: 161.9847 - Epoch Loss: 57091.3288 - Avg Loss: 160.8206\n",
            "Epoch [46/50] - Batch loss: 156.3045 - Epoch Loss: 57247.6333 - Avg Loss: 160.8080\n",
            "Epoch [46/50] - Batch loss: 167.8701 - Epoch Loss: 57415.5034 - Avg Loss: 160.8277\n",
            "Epoch [46/50] - Batch loss: 160.7701 - Epoch Loss: 57576.2735 - Avg Loss: 160.8276\n",
            "Epoch [46/50] - Batch loss: 159.8298 - Epoch Loss: 57736.1034 - Avg Loss: 160.8248\n",
            "Epoch [46/50] - Batch loss: 158.1681 - Epoch Loss: 57894.2715 - Avg Loss: 160.8174\n",
            "Epoch [46/50] - Batch loss: 164.3898 - Epoch Loss: 58058.6613 - Avg Loss: 160.8273\n",
            "Epoch [46/50] - Batch loss: 164.3898 - Epoch Loss: 58223.0511 - Avg Loss: 160.8372\n",
            "Epoch [46/50] - Batch loss: 160.8055 - Epoch Loss: 58383.8566 - Avg Loss: 160.8371\n",
            "Epoch [46/50] - Batch loss: 168.6298 - Epoch Loss: 58552.4864 - Avg Loss: 160.8585\n",
            "Epoch [46/50] - Batch loss: 164.4367 - Epoch Loss: 58716.9231 - Avg Loss: 160.8683\n",
            "Epoch [46/50] - Batch loss: 160.5779 - Epoch Loss: 58877.5010 - Avg Loss: 160.8675\n",
            "Epoch [46/50] - Batch loss: 162.1223 - Epoch Loss: 59039.6233 - Avg Loss: 160.8709\n",
            "Epoch [46/50] - Batch loss: 166.1123 - Epoch Loss: 59205.7357 - Avg Loss: 160.8852\n",
            "Epoch [46/50] - Batch loss: 158.0206 - Epoch Loss: 59363.7563 - Avg Loss: 160.8774\n",
            "Epoch [46/50] - Batch loss: 156.9427 - Epoch Loss: 59520.6990 - Avg Loss: 160.8668\n",
            "Epoch [46/50] - Batch loss: 166.6633 - Epoch Loss: 59687.3623 - Avg Loss: 160.8824\n",
            "Epoch [46/50] - Batch loss: 163.1459 - Epoch Loss: 59850.5082 - Avg Loss: 160.8885\n",
            "Epoch [46/50] - Batch loss: 165.4955 - Epoch Loss: 60016.0037 - Avg Loss: 160.9008\n",
            "Epoch [46/50] - Batch loss: 162.8443 - Epoch Loss: 60178.8480 - Avg Loss: 160.9060\n",
            "Epoch [46/50] - Batch loss: 164.3169 - Epoch Loss: 60343.1649 - Avg Loss: 160.9151\n",
            "Epoch [46/50] - Batch loss: 168.0586 - Epoch Loss: 60511.2235 - Avg Loss: 160.9341\n",
            "Epoch [46/50] - Batch loss: 161.0732 - Epoch Loss: 60672.2968 - Avg Loss: 160.9345\n",
            "Epoch [46/50] - Batch loss: 152.5394 - Epoch Loss: 60824.8361 - Avg Loss: 160.9123\n",
            "Epoch [46/50] - Batch loss: 154.4408 - Epoch Loss: 60979.2769 - Avg Loss: 160.8952\n",
            "Epoch [46/50] - Batch loss: 160.1420 - Epoch Loss: 61139.4189 - Avg Loss: 160.8932\n",
            "Epoch [46/50] - Batch loss: 164.9070 - Epoch Loss: 61304.3259 - Avg Loss: 160.9037\n",
            "Epoch [46/50] - Batch loss: 165.1715 - Epoch Loss: 61469.4974 - Avg Loss: 160.9149\n",
            "Epoch [46/50] - Batch loss: 161.9295 - Epoch Loss: 61631.4269 - Avg Loss: 160.9176\n",
            "Epoch [46/50] - Batch loss: 156.4362 - Epoch Loss: 61787.8631 - Avg Loss: 160.9059\n",
            "Epoch [46/50] - Batch loss: 163.1254 - Epoch Loss: 61950.9885 - Avg Loss: 160.9117\n",
            "Epoch [46/50] - Batch loss: 156.0490 - Epoch Loss: 62107.0375 - Avg Loss: 160.8991\n",
            "Epoch [46/50] - Batch loss: 159.5669 - Epoch Loss: 62266.6044 - Avg Loss: 160.8956\n",
            "Epoch [46/50] - Batch loss: 162.3375 - Epoch Loss: 62428.9419 - Avg Loss: 160.8993\n",
            "Epoch [46/50] - Batch loss: 154.7360 - Epoch Loss: 62583.6779 - Avg Loss: 160.8835\n",
            "Epoch [46/50] - Batch loss: 159.7500 - Epoch Loss: 62743.4279 - Avg Loss: 160.8806\n",
            "Epoch [46/50] - Batch loss: 152.6503 - Epoch Loss: 62896.0782 - Avg Loss: 160.8595\n",
            "Epoch [46/50] - Batch loss: 149.2797 - Epoch Loss: 63045.3579 - Avg Loss: 160.8300\n",
            "Epoch [46/50] - Batch loss: 154.4612 - Epoch Loss: 63199.8192 - Avg Loss: 160.8138\n",
            "Epoch [46/50] - Batch loss: 165.0547 - Epoch Loss: 63364.8738 - Avg Loss: 160.8246\n",
            "Epoch [46/50] - Batch loss: 166.6732 - Epoch Loss: 63531.5471 - Avg Loss: 160.8394\n",
            "Epoch [46/50] - Batch loss: 161.9200 - Epoch Loss: 63693.4671 - Avg Loss: 160.8421\n",
            "Epoch [46/50] - Batch loss: 164.3410 - Epoch Loss: 63857.8081 - Avg Loss: 160.8509\n",
            "Epoch [46/50] - Batch loss: 157.1884 - Epoch Loss: 64014.9965 - Avg Loss: 160.8417\n",
            "Epoch [46/50] - Batch loss: 170.5028 - Epoch Loss: 64185.4993 - Avg Loss: 160.8659\n",
            "Epoch [46/50] - Batch loss: 155.6566 - Epoch Loss: 64341.1559 - Avg Loss: 160.8529\n",
            "Epoch [46/50] - Batch loss: 161.7232 - Epoch Loss: 64502.8791 - Avg Loss: 160.8551\n",
            "Epoch [46/50] - Batch loss: 157.5059 - Epoch Loss: 64660.3849 - Avg Loss: 160.8467\n",
            "Epoch [46/50] - Batch loss: 153.8309 - Epoch Loss: 64814.2159 - Avg Loss: 160.8293\n",
            "Epoch [46/50] - Batch loss: 160.9146 - Epoch Loss: 64975.1305 - Avg Loss: 160.8295\n",
            "Epoch [46/50] - Batch loss: 165.5078 - Epoch Loss: 65140.6383 - Avg Loss: 160.8411\n",
            "Epoch [46/50] - Batch loss: 162.7995 - Epoch Loss: 65303.4379 - Avg Loss: 160.8459\n",
            "Epoch [46/50] - Batch loss: 170.8672 - Epoch Loss: 65474.3051 - Avg Loss: 160.8705\n",
            "Epoch [46/50] - Batch loss: 159.1338 - Epoch Loss: 65633.4389 - Avg Loss: 160.8663\n",
            "Epoch [46/50] - Batch loss: 162.3246 - Epoch Loss: 65795.7634 - Avg Loss: 160.8698\n",
            "Epoch [46/50] - Batch loss: 158.4575 - Epoch Loss: 65954.2210 - Avg Loss: 160.8640\n",
            "Epoch [46/50] - Batch loss: 168.7416 - Epoch Loss: 66122.9626 - Avg Loss: 160.8831\n",
            "Epoch [46/50] - Batch loss: 152.6338 - Epoch Loss: 66275.5964 - Avg Loss: 160.8631\n",
            "Epoch [46/50] - Batch loss: 166.3219 - Epoch Loss: 66441.9183 - Avg Loss: 160.8763\n",
            "Epoch [46/50] - Batch loss: 157.7884 - Epoch Loss: 66599.7068 - Avg Loss: 160.8689\n",
            "Epoch [46/50] - Batch loss: 163.1226 - Epoch Loss: 66762.8294 - Avg Loss: 160.8743\n",
            "Epoch [46/50] - Batch loss: 162.1145 - Epoch Loss: 66924.9439 - Avg Loss: 160.8773\n",
            "Epoch [46/50] - Batch loss: 157.9021 - Epoch Loss: 67082.8459 - Avg Loss: 160.8701\n",
            "Epoch [46/50] - Batch loss: 164.5889 - Epoch Loss: 67247.4349 - Avg Loss: 160.8790\n",
            "Epoch [46/50] - Batch loss: 162.3296 - Epoch Loss: 67409.7645 - Avg Loss: 160.8825\n",
            "Epoch [46/50] - Batch loss: 150.9357 - Epoch Loss: 67560.7002 - Avg Loss: 160.8588\n",
            "Epoch [46/50] - Batch loss: 167.1886 - Epoch Loss: 67727.8888 - Avg Loss: 160.8738\n",
            "Epoch [46/50] - Batch loss: 162.8510 - Epoch Loss: 67890.7398 - Avg Loss: 160.8785\n",
            "Epoch [46/50] - Batch loss: 169.1093 - Epoch Loss: 68059.8490 - Avg Loss: 160.8980\n",
            "Epoch [46/50] - Batch loss: 165.2731 - Epoch Loss: 68225.1221 - Avg Loss: 160.9083\n",
            "Epoch [46/50] - Batch loss: 156.9690 - Epoch Loss: 68382.0912 - Avg Loss: 160.8990\n",
            "Epoch [46/50] - Batch loss: 157.7959 - Epoch Loss: 68539.8871 - Avg Loss: 160.8918\n",
            "Epoch [46/50] - Batch loss: 167.3749 - Epoch Loss: 68707.2620 - Avg Loss: 160.9069\n",
            "Epoch [46/50] - Batch loss: 151.6706 - Epoch Loss: 68858.9325 - Avg Loss: 160.8854\n",
            "Epoch [46/50] - Batch loss: 171.1904 - Epoch Loss: 69030.1229 - Avg Loss: 160.9094\n",
            "Epoch [46/50] - Batch loss: 160.0638 - Epoch Loss: 69190.1867 - Avg Loss: 160.9074\n",
            "Epoch [46/50] - Batch loss: 158.2354 - Epoch Loss: 69348.4221 - Avg Loss: 160.9012\n",
            "Epoch [46/50] - Batch loss: 163.7378 - Epoch Loss: 69512.1599 - Avg Loss: 160.9078\n",
            "Epoch [46/50] - Batch loss: 158.4701 - Epoch Loss: 69670.6300 - Avg Loss: 160.9021\n",
            "Epoch [46/50] - Batch loss: 170.6994 - Epoch Loss: 69841.3294 - Avg Loss: 160.9247\n",
            "Epoch [46/50] - Batch loss: 165.1957 - Epoch Loss: 70006.5251 - Avg Loss: 160.9345\n",
            "Epoch [46/50] - Batch loss: 155.6651 - Epoch Loss: 70162.1902 - Avg Loss: 160.9225\n",
            "Epoch [46/50] - Batch loss: 156.1126 - Epoch Loss: 70318.3028 - Avg Loss: 160.9114\n",
            "Epoch [46/50] - Batch loss: 155.7524 - Epoch Loss: 70474.0553 - Avg Loss: 160.8997\n",
            "Epoch [46/50] - Batch loss: 165.2919 - Epoch Loss: 70639.3472 - Avg Loss: 160.9097\n",
            "Epoch [46/50] - Batch loss: 167.0421 - Epoch Loss: 70806.3893 - Avg Loss: 160.9236\n",
            "Epoch [46/50] - Batch loss: 159.0913 - Epoch Loss: 70965.4805 - Avg Loss: 160.9195\n",
            "Epoch [46/50] - Batch loss: 162.6109 - Epoch Loss: 71128.0915 - Avg Loss: 160.9233\n",
            "Epoch [46/50] - Batch loss: 166.5213 - Epoch Loss: 71294.6128 - Avg Loss: 160.9359\n",
            "Epoch [46/50] - Batch loss: 158.3132 - Epoch Loss: 71452.9260 - Avg Loss: 160.9300\n",
            "Epoch [46/50] - Batch loss: 159.8521 - Epoch Loss: 71612.7781 - Avg Loss: 160.9276\n",
            "Epoch [46/50] - Batch loss: 171.1797 - Epoch Loss: 71783.9579 - Avg Loss: 160.9506\n",
            "Epoch [46/50] - Batch loss: 159.6569 - Epoch Loss: 71943.6148 - Avg Loss: 160.9477\n",
            "Epoch [46/50] - Batch loss: 157.6753 - Epoch Loss: 72101.2901 - Avg Loss: 160.9404\n",
            "Epoch [46/50] - Batch loss: 165.0511 - Epoch Loss: 72266.3412 - Avg Loss: 160.9495\n",
            "Epoch [46/50] - Batch loss: 157.4390 - Epoch Loss: 72423.7802 - Avg Loss: 160.9417\n",
            "Epoch [46/50] - Batch loss: 163.4114 - Epoch Loss: 72587.1916 - Avg Loss: 160.9472\n",
            "Epoch [46/50] - Batch loss: 160.9427 - Epoch Loss: 72748.1342 - Avg Loss: 160.9472\n",
            "Epoch [46/50] - Batch loss: 162.7060 - Epoch Loss: 72910.8402 - Avg Loss: 160.9511\n",
            "Epoch [46/50] - Batch loss: 169.2597 - Epoch Loss: 73080.0999 - Avg Loss: 160.9694\n",
            "Epoch [46/50] - Batch loss: 168.4631 - Epoch Loss: 73248.5630 - Avg Loss: 160.9859\n",
            "Epoch [46/50] - Batch loss: 172.1949 - Epoch Loss: 73420.7578 - Avg Loss: 161.0104\n",
            "Epoch [46/50] - Batch loss: 159.9600 - Epoch Loss: 73580.7178 - Avg Loss: 161.0081\n",
            "Epoch [46/50] - Batch loss: 165.8940 - Epoch Loss: 73746.6118 - Avg Loss: 161.0188\n",
            "Epoch [46/50] - Batch loss: 162.3226 - Epoch Loss: 73908.9344 - Avg Loss: 161.0216\n",
            "Epoch [46/50] - Batch loss: 153.9040 - Epoch Loss: 74062.8384 - Avg Loss: 161.0062\n",
            "Epoch [46/50] - Batch loss: 163.2725 - Epoch Loss: 74226.1109 - Avg Loss: 161.0111\n",
            "Epoch [46/50] - Batch loss: 166.7607 - Epoch Loss: 74392.8716 - Avg Loss: 161.0235\n",
            "Epoch [46/50] - Batch loss: 166.5100 - Epoch Loss: 74559.3816 - Avg Loss: 161.0354\n",
            "Epoch [46/50] - Batch loss: 168.5281 - Epoch Loss: 74727.9097 - Avg Loss: 161.0515\n",
            "Epoch [46/50] - Batch loss: 155.8678 - Epoch Loss: 74883.7775 - Avg Loss: 161.0404\n",
            "Epoch [46/50] - Batch loss: 166.2141 - Epoch Loss: 75049.9916 - Avg Loss: 161.0515\n",
            "Epoch [46/50] - Batch loss: 160.2788 - Epoch Loss: 75210.2704 - Avg Loss: 161.0498\n",
            "Epoch [46/50] - Batch loss: 163.9595 - Epoch Loss: 75374.2299 - Avg Loss: 161.0560\n",
            "Epoch [46/50] - Batch loss: 161.2979 - Epoch Loss: 75535.5279 - Avg Loss: 161.0566\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 47/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88fd28b3894145b5bcde9a18c355cda4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [47/50] - Batch loss: 159.1003 - Epoch Loss: 159.1003 - Avg Loss: 159.1003\n",
            "Epoch [47/50] - Batch loss: 163.0360 - Epoch Loss: 322.1363 - Avg Loss: 161.0682\n",
            "Epoch [47/50] - Batch loss: 159.8079 - Epoch Loss: 481.9442 - Avg Loss: 160.6481\n",
            "Epoch [47/50] - Batch loss: 165.1145 - Epoch Loss: 647.0587 - Avg Loss: 161.7647\n",
            "Epoch [47/50] - Batch loss: 162.1611 - Epoch Loss: 809.2198 - Avg Loss: 161.8440\n",
            "Epoch [47/50] - Batch loss: 154.5985 - Epoch Loss: 963.8183 - Avg Loss: 160.6364\n",
            "Epoch [47/50] - Batch loss: 162.3631 - Epoch Loss: 1126.1814 - Avg Loss: 160.8831\n",
            "Epoch [47/50] - Batch loss: 155.5101 - Epoch Loss: 1281.6915 - Avg Loss: 160.2114\n",
            "Epoch [47/50] - Batch loss: 155.5566 - Epoch Loss: 1437.2480 - Avg Loss: 159.6942\n",
            "Epoch [47/50] - Batch loss: 161.0757 - Epoch Loss: 1598.3238 - Avg Loss: 159.8324\n",
            "Epoch [47/50] - Batch loss: 162.6898 - Epoch Loss: 1761.0136 - Avg Loss: 160.0921\n",
            "Epoch [47/50] - Batch loss: 162.8135 - Epoch Loss: 1923.8271 - Avg Loss: 160.3189\n",
            "Epoch [47/50] - Batch loss: 162.3087 - Epoch Loss: 2086.1358 - Avg Loss: 160.4720\n",
            "Epoch [47/50] - Batch loss: 163.9118 - Epoch Loss: 2250.0477 - Avg Loss: 160.7177\n",
            "Epoch [47/50] - Batch loss: 158.2456 - Epoch Loss: 2408.2932 - Avg Loss: 160.5529\n",
            "Epoch [47/50] - Batch loss: 162.7352 - Epoch Loss: 2571.0284 - Avg Loss: 160.6893\n",
            "Epoch [47/50] - Batch loss: 164.2175 - Epoch Loss: 2735.2459 - Avg Loss: 160.8968\n",
            "Epoch [47/50] - Batch loss: 173.3428 - Epoch Loss: 2908.5887 - Avg Loss: 161.5883\n",
            "Epoch [47/50] - Batch loss: 162.2542 - Epoch Loss: 3070.8429 - Avg Loss: 161.6233\n",
            "Epoch [47/50] - Batch loss: 156.5013 - Epoch Loss: 3227.3442 - Avg Loss: 161.3672\n",
            "Epoch [47/50] - Batch loss: 165.1436 - Epoch Loss: 3392.4879 - Avg Loss: 161.5470\n",
            "Epoch [47/50] - Batch loss: 147.1946 - Epoch Loss: 3539.6825 - Avg Loss: 160.8947\n",
            "Epoch [47/50] - Batch loss: 162.9727 - Epoch Loss: 3702.6552 - Avg Loss: 160.9850\n",
            "Epoch [47/50] - Batch loss: 155.9068 - Epoch Loss: 3858.5620 - Avg Loss: 160.7734\n",
            "Epoch [47/50] - Batch loss: 151.6541 - Epoch Loss: 4010.2161 - Avg Loss: 160.4086\n",
            "Epoch [47/50] - Batch loss: 149.9127 - Epoch Loss: 4160.1288 - Avg Loss: 160.0050\n",
            "Epoch [47/50] - Batch loss: 160.8767 - Epoch Loss: 4321.0055 - Avg Loss: 160.0372\n",
            "Epoch [47/50] - Batch loss: 157.4695 - Epoch Loss: 4478.4750 - Avg Loss: 159.9455\n",
            "Epoch [47/50] - Batch loss: 158.9948 - Epoch Loss: 4637.4699 - Avg Loss: 159.9128\n",
            "Epoch [47/50] - Batch loss: 158.7453 - Epoch Loss: 4796.2151 - Avg Loss: 159.8738\n",
            "Epoch [47/50] - Batch loss: 158.5985 - Epoch Loss: 4954.8136 - Avg Loss: 159.8327\n",
            "Epoch [47/50] - Batch loss: 152.9710 - Epoch Loss: 5107.7847 - Avg Loss: 159.6183\n",
            "Epoch [47/50] - Batch loss: 167.8757 - Epoch Loss: 5275.6603 - Avg Loss: 159.8685\n",
            "Epoch [47/50] - Batch loss: 157.3362 - Epoch Loss: 5432.9965 - Avg Loss: 159.7940\n",
            "Epoch [47/50] - Batch loss: 159.1183 - Epoch Loss: 5592.1148 - Avg Loss: 159.7747\n",
            "Epoch [47/50] - Batch loss: 159.4865 - Epoch Loss: 5751.6012 - Avg Loss: 159.7667\n",
            "Epoch [47/50] - Batch loss: 161.4051 - Epoch Loss: 5913.0063 - Avg Loss: 159.8110\n",
            "Epoch [47/50] - Batch loss: 161.3735 - Epoch Loss: 6074.3798 - Avg Loss: 159.8521\n",
            "Epoch [47/50] - Batch loss: 162.9775 - Epoch Loss: 6237.3573 - Avg Loss: 159.9322\n",
            "Epoch [47/50] - Batch loss: 169.2668 - Epoch Loss: 6406.6241 - Avg Loss: 160.1656\n",
            "Epoch [47/50] - Batch loss: 161.7395 - Epoch Loss: 6568.3636 - Avg Loss: 160.2040\n",
            "Epoch [47/50] - Batch loss: 163.3152 - Epoch Loss: 6731.6788 - Avg Loss: 160.2781\n",
            "Epoch [47/50] - Batch loss: 161.6534 - Epoch Loss: 6893.3323 - Avg Loss: 160.3101\n",
            "Epoch [47/50] - Batch loss: 160.5509 - Epoch Loss: 7053.8831 - Avg Loss: 160.3155\n",
            "Epoch [47/50] - Batch loss: 154.1838 - Epoch Loss: 7208.0670 - Avg Loss: 160.1793\n",
            "Epoch [47/50] - Batch loss: 162.3335 - Epoch Loss: 7370.4005 - Avg Loss: 160.2261\n",
            "Epoch [47/50] - Batch loss: 160.2044 - Epoch Loss: 7530.6049 - Avg Loss: 160.2256\n",
            "Epoch [47/50] - Batch loss: 163.0705 - Epoch Loss: 7693.6754 - Avg Loss: 160.2849\n",
            "Epoch [47/50] - Batch loss: 168.2898 - Epoch Loss: 7861.9652 - Avg Loss: 160.4483\n",
            "Epoch [47/50] - Batch loss: 162.3616 - Epoch Loss: 8024.3268 - Avg Loss: 160.4865\n",
            "Epoch [47/50] - Batch loss: 149.8339 - Epoch Loss: 8174.1607 - Avg Loss: 160.2777\n",
            "Epoch [47/50] - Batch loss: 160.6600 - Epoch Loss: 8334.8208 - Avg Loss: 160.2850\n",
            "Epoch [47/50] - Batch loss: 160.9410 - Epoch Loss: 8495.7617 - Avg Loss: 160.2974\n",
            "Epoch [47/50] - Batch loss: 165.3897 - Epoch Loss: 8661.1514 - Avg Loss: 160.3917\n",
            "Epoch [47/50] - Batch loss: 159.5849 - Epoch Loss: 8820.7363 - Avg Loss: 160.3770\n",
            "Epoch [47/50] - Batch loss: 154.1262 - Epoch Loss: 8974.8625 - Avg Loss: 160.2654\n",
            "Epoch [47/50] - Batch loss: 155.3880 - Epoch Loss: 9130.2505 - Avg Loss: 160.1798\n",
            "Epoch [47/50] - Batch loss: 160.3474 - Epoch Loss: 9290.5980 - Avg Loss: 160.1827\n",
            "Epoch [47/50] - Batch loss: 158.6013 - Epoch Loss: 9449.1993 - Avg Loss: 160.1559\n",
            "Epoch [47/50] - Batch loss: 165.6597 - Epoch Loss: 9614.8590 - Avg Loss: 160.2477\n",
            "Epoch [47/50] - Batch loss: 150.2375 - Epoch Loss: 9765.0965 - Avg Loss: 160.0835\n",
            "Epoch [47/50] - Batch loss: 158.2310 - Epoch Loss: 9923.3275 - Avg Loss: 160.0537\n",
            "Epoch [47/50] - Batch loss: 158.0143 - Epoch Loss: 10081.3418 - Avg Loss: 160.0213\n",
            "Epoch [47/50] - Batch loss: 171.0510 - Epoch Loss: 10252.3928 - Avg Loss: 160.1936\n",
            "Epoch [47/50] - Batch loss: 160.9878 - Epoch Loss: 10413.3805 - Avg Loss: 160.2059\n",
            "Epoch [47/50] - Batch loss: 165.3856 - Epoch Loss: 10578.7661 - Avg Loss: 160.2843\n",
            "Epoch [47/50] - Batch loss: 168.8424 - Epoch Loss: 10747.6086 - Avg Loss: 160.4121\n",
            "Epoch [47/50] - Batch loss: 163.9030 - Epoch Loss: 10911.5116 - Avg Loss: 160.4634\n",
            "Epoch [47/50] - Batch loss: 158.6014 - Epoch Loss: 11070.1130 - Avg Loss: 160.4364\n",
            "Epoch [47/50] - Batch loss: 162.8088 - Epoch Loss: 11232.9218 - Avg Loss: 160.4703\n",
            "Epoch [47/50] - Batch loss: 163.1661 - Epoch Loss: 11396.0879 - Avg Loss: 160.5083\n",
            "Epoch [47/50] - Batch loss: 158.8454 - Epoch Loss: 11554.9332 - Avg Loss: 160.4852\n",
            "Epoch [47/50] - Batch loss: 160.9904 - Epoch Loss: 11715.9236 - Avg Loss: 160.4921\n",
            "Epoch [47/50] - Batch loss: 162.5305 - Epoch Loss: 11878.4542 - Avg Loss: 160.5197\n",
            "Epoch [47/50] - Batch loss: 158.8363 - Epoch Loss: 12037.2905 - Avg Loss: 160.4972\n",
            "Epoch [47/50] - Batch loss: 168.7217 - Epoch Loss: 12206.0121 - Avg Loss: 160.6054\n",
            "Epoch [47/50] - Batch loss: 166.6787 - Epoch Loss: 12372.6908 - Avg Loss: 160.6843\n",
            "Epoch [47/50] - Batch loss: 166.1916 - Epoch Loss: 12538.8825 - Avg Loss: 160.7549\n",
            "Epoch [47/50] - Batch loss: 157.6160 - Epoch Loss: 12696.4985 - Avg Loss: 160.7152\n",
            "Epoch [47/50] - Batch loss: 166.9507 - Epoch Loss: 12863.4492 - Avg Loss: 160.7931\n",
            "Epoch [47/50] - Batch loss: 161.8851 - Epoch Loss: 13025.3343 - Avg Loss: 160.8066\n",
            "Epoch [47/50] - Batch loss: 165.3248 - Epoch Loss: 13190.6591 - Avg Loss: 160.8617\n",
            "Epoch [47/50] - Batch loss: 165.5506 - Epoch Loss: 13356.2096 - Avg Loss: 160.9182\n",
            "Epoch [47/50] - Batch loss: 172.6986 - Epoch Loss: 13528.9082 - Avg Loss: 161.0584\n",
            "Epoch [47/50] - Batch loss: 168.3242 - Epoch Loss: 13697.2325 - Avg Loss: 161.1439\n",
            "Epoch [47/50] - Batch loss: 170.8334 - Epoch Loss: 13868.0659 - Avg Loss: 161.2566\n",
            "Epoch [47/50] - Batch loss: 167.8680 - Epoch Loss: 14035.9339 - Avg Loss: 161.3326\n",
            "Epoch [47/50] - Batch loss: 168.6006 - Epoch Loss: 14204.5344 - Avg Loss: 161.4152\n",
            "Epoch [47/50] - Batch loss: 157.3685 - Epoch Loss: 14361.9030 - Avg Loss: 161.3697\n",
            "Epoch [47/50] - Batch loss: 155.4634 - Epoch Loss: 14517.3664 - Avg Loss: 161.3041\n",
            "Epoch [47/50] - Batch loss: 169.3054 - Epoch Loss: 14686.6718 - Avg Loss: 161.3920\n",
            "Epoch [47/50] - Batch loss: 160.9653 - Epoch Loss: 14847.6370 - Avg Loss: 161.3874\n",
            "Epoch [47/50] - Batch loss: 170.8890 - Epoch Loss: 15018.5260 - Avg Loss: 161.4895\n",
            "Epoch [47/50] - Batch loss: 163.0992 - Epoch Loss: 15181.6253 - Avg Loss: 161.5067\n",
            "Epoch [47/50] - Batch loss: 163.1889 - Epoch Loss: 15344.8142 - Avg Loss: 161.5244\n",
            "Epoch [47/50] - Batch loss: 160.2001 - Epoch Loss: 15505.0143 - Avg Loss: 161.5106\n",
            "Epoch [47/50] - Batch loss: 169.4671 - Epoch Loss: 15674.4814 - Avg Loss: 161.5926\n",
            "Epoch [47/50] - Batch loss: 170.3022 - Epoch Loss: 15844.7835 - Avg Loss: 161.6815\n",
            "Epoch [47/50] - Batch loss: 170.4453 - Epoch Loss: 16015.2289 - Avg Loss: 161.7700\n",
            "Epoch [47/50] - Batch loss: 167.2848 - Epoch Loss: 16182.5136 - Avg Loss: 161.8251\n",
            "Epoch [47/50] - Batch loss: 160.2589 - Epoch Loss: 16342.7726 - Avg Loss: 161.8096\n",
            "Epoch [47/50] - Batch loss: 166.4167 - Epoch Loss: 16509.1893 - Avg Loss: 161.8548\n",
            "Epoch [47/50] - Batch loss: 162.8186 - Epoch Loss: 16672.0079 - Avg Loss: 161.8642\n",
            "Epoch [47/50] - Batch loss: 170.1416 - Epoch Loss: 16842.1494 - Avg Loss: 161.9437\n",
            "Epoch [47/50] - Batch loss: 164.1924 - Epoch Loss: 17006.3418 - Avg Loss: 161.9652\n",
            "Epoch [47/50] - Batch loss: 170.8775 - Epoch Loss: 17177.2193 - Avg Loss: 162.0492\n",
            "Epoch [47/50] - Batch loss: 176.5406 - Epoch Loss: 17353.7599 - Avg Loss: 162.1847\n",
            "Epoch [47/50] - Batch loss: 180.3873 - Epoch Loss: 17534.1472 - Avg Loss: 162.3532\n",
            "Epoch [47/50] - Batch loss: 170.0455 - Epoch Loss: 17704.1927 - Avg Loss: 162.4238\n",
            "Epoch [47/50] - Batch loss: 168.3214 - Epoch Loss: 17872.5142 - Avg Loss: 162.4774\n",
            "Epoch [47/50] - Batch loss: 162.8913 - Epoch Loss: 18035.4055 - Avg Loss: 162.4811\n",
            "Epoch [47/50] - Batch loss: 172.2760 - Epoch Loss: 18207.6815 - Avg Loss: 162.5686\n",
            "Epoch [47/50] - Batch loss: 165.0115 - Epoch Loss: 18372.6930 - Avg Loss: 162.5902\n",
            "Epoch [47/50] - Batch loss: 172.9374 - Epoch Loss: 18545.6304 - Avg Loss: 162.6810\n",
            "Epoch [47/50] - Batch loss: 162.5190 - Epoch Loss: 18708.1494 - Avg Loss: 162.6796\n",
            "Epoch [47/50] - Batch loss: 168.5945 - Epoch Loss: 18876.7439 - Avg Loss: 162.7306\n",
            "Epoch [47/50] - Batch loss: 169.7121 - Epoch Loss: 19046.4560 - Avg Loss: 162.7902\n",
            "Epoch [47/50] - Batch loss: 165.4622 - Epoch Loss: 19211.9182 - Avg Loss: 162.8129\n",
            "Epoch [47/50] - Batch loss: 171.5974 - Epoch Loss: 19383.5156 - Avg Loss: 162.8867\n",
            "Epoch [47/50] - Batch loss: 172.3518 - Epoch Loss: 19555.8674 - Avg Loss: 162.9656\n",
            "Epoch [47/50] - Batch loss: 177.7045 - Epoch Loss: 19733.5719 - Avg Loss: 163.0874\n",
            "Epoch [47/50] - Batch loss: 171.9260 - Epoch Loss: 19905.4979 - Avg Loss: 163.1598\n",
            "Epoch [47/50] - Batch loss: 167.7476 - Epoch Loss: 20073.2455 - Avg Loss: 163.1971\n",
            "Epoch [47/50] - Batch loss: 165.9448 - Epoch Loss: 20239.1903 - Avg Loss: 163.2193\n",
            "Epoch [47/50] - Batch loss: 165.2757 - Epoch Loss: 20404.4660 - Avg Loss: 163.2357\n",
            "Epoch [47/50] - Batch loss: 168.5614 - Epoch Loss: 20573.0274 - Avg Loss: 163.2780\n",
            "Epoch [47/50] - Batch loss: 161.3973 - Epoch Loss: 20734.4247 - Avg Loss: 163.2632\n",
            "Epoch [47/50] - Batch loss: 163.5202 - Epoch Loss: 20897.9449 - Avg Loss: 163.2652\n",
            "Epoch [47/50] - Batch loss: 168.5879 - Epoch Loss: 21066.5328 - Avg Loss: 163.3065\n",
            "Epoch [47/50] - Batch loss: 167.7636 - Epoch Loss: 21234.2963 - Avg Loss: 163.3407\n",
            "Epoch [47/50] - Batch loss: 170.8748 - Epoch Loss: 21405.1711 - Avg Loss: 163.3983\n",
            "Epoch [47/50] - Batch loss: 161.1150 - Epoch Loss: 21566.2861 - Avg Loss: 163.3810\n",
            "Epoch [47/50] - Batch loss: 158.0461 - Epoch Loss: 21724.3322 - Avg Loss: 163.3408\n",
            "Epoch [47/50] - Batch loss: 159.1959 - Epoch Loss: 21883.5281 - Avg Loss: 163.3099\n",
            "Epoch [47/50] - Batch loss: 165.0303 - Epoch Loss: 22048.5584 - Avg Loss: 163.3227\n",
            "Epoch [47/50] - Batch loss: 173.0160 - Epoch Loss: 22221.5744 - Avg Loss: 163.3939\n",
            "Epoch [47/50] - Batch loss: 171.1201 - Epoch Loss: 22392.6945 - Avg Loss: 163.4503\n",
            "Epoch [47/50] - Batch loss: 166.3146 - Epoch Loss: 22559.0091 - Avg Loss: 163.4711\n",
            "Epoch [47/50] - Batch loss: 171.3059 - Epoch Loss: 22730.3150 - Avg Loss: 163.5274\n",
            "Epoch [47/50] - Batch loss: 167.7162 - Epoch Loss: 22898.0312 - Avg Loss: 163.5574\n",
            "Epoch [47/50] - Batch loss: 172.1489 - Epoch Loss: 23070.1801 - Avg Loss: 163.6183\n",
            "Epoch [47/50] - Batch loss: 170.9496 - Epoch Loss: 23241.1297 - Avg Loss: 163.6699\n",
            "Epoch [47/50] - Batch loss: 160.3083 - Epoch Loss: 23401.4380 - Avg Loss: 163.6464\n",
            "Epoch [47/50] - Batch loss: 171.7576 - Epoch Loss: 23573.1955 - Avg Loss: 163.7027\n",
            "Epoch [47/50] - Batch loss: 175.8079 - Epoch Loss: 23749.0034 - Avg Loss: 163.7862\n",
            "Epoch [47/50] - Batch loss: 163.5516 - Epoch Loss: 23912.5550 - Avg Loss: 163.7846\n",
            "Epoch [47/50] - Batch loss: 168.0956 - Epoch Loss: 24080.6506 - Avg Loss: 163.8139\n",
            "Epoch [47/50] - Batch loss: 168.0927 - Epoch Loss: 24248.7433 - Avg Loss: 163.8429\n",
            "Epoch [47/50] - Batch loss: 172.1567 - Epoch Loss: 24420.9000 - Avg Loss: 163.8987\n",
            "Epoch [47/50] - Batch loss: 164.1700 - Epoch Loss: 24585.0700 - Avg Loss: 163.9005\n",
            "Epoch [47/50] - Batch loss: 173.9089 - Epoch Loss: 24758.9789 - Avg Loss: 163.9667\n",
            "Epoch [47/50] - Batch loss: 159.4975 - Epoch Loss: 24918.4764 - Avg Loss: 163.9373\n",
            "Epoch [47/50] - Batch loss: 176.0664 - Epoch Loss: 25094.5428 - Avg Loss: 164.0166\n",
            "Epoch [47/50] - Batch loss: 168.7641 - Epoch Loss: 25263.3069 - Avg Loss: 164.0474\n",
            "Epoch [47/50] - Batch loss: 165.8686 - Epoch Loss: 25429.1755 - Avg Loss: 164.0592\n",
            "Epoch [47/50] - Batch loss: 170.5493 - Epoch Loss: 25599.7248 - Avg Loss: 164.1008\n",
            "Epoch [47/50] - Batch loss: 167.9149 - Epoch Loss: 25767.6398 - Avg Loss: 164.1251\n",
            "Epoch [47/50] - Batch loss: 164.7489 - Epoch Loss: 25932.3886 - Avg Loss: 164.1290\n",
            "Epoch [47/50] - Batch loss: 165.1311 - Epoch Loss: 26097.5197 - Avg Loss: 164.1353\n",
            "Epoch [47/50] - Batch loss: 159.9512 - Epoch Loss: 26257.4709 - Avg Loss: 164.1092\n",
            "Epoch [47/50] - Batch loss: 166.4201 - Epoch Loss: 26423.8910 - Avg Loss: 164.1235\n",
            "Epoch [47/50] - Batch loss: 172.0407 - Epoch Loss: 26595.9317 - Avg Loss: 164.1724\n",
            "Epoch [47/50] - Batch loss: 175.5834 - Epoch Loss: 26771.5151 - Avg Loss: 164.2424\n",
            "Epoch [47/50] - Batch loss: 158.6774 - Epoch Loss: 26930.1925 - Avg Loss: 164.2085\n",
            "Epoch [47/50] - Batch loss: 173.7288 - Epoch Loss: 27103.9213 - Avg Loss: 164.2662\n",
            "Epoch [47/50] - Batch loss: 165.0236 - Epoch Loss: 27268.9450 - Avg Loss: 164.2708\n",
            "Epoch [47/50] - Batch loss: 163.0463 - Epoch Loss: 27431.9913 - Avg Loss: 164.2634\n",
            "Epoch [47/50] - Batch loss: 174.9014 - Epoch Loss: 27606.8927 - Avg Loss: 164.3267\n",
            "Epoch [47/50] - Batch loss: 174.0733 - Epoch Loss: 27780.9660 - Avg Loss: 164.3844\n",
            "Epoch [47/50] - Batch loss: 174.7997 - Epoch Loss: 27955.7656 - Avg Loss: 164.4457\n",
            "Epoch [47/50] - Batch loss: 166.5695 - Epoch Loss: 28122.3351 - Avg Loss: 164.4581\n",
            "Epoch [47/50] - Batch loss: 174.7032 - Epoch Loss: 28297.0383 - Avg Loss: 164.5177\n",
            "Epoch [47/50] - Batch loss: 175.0381 - Epoch Loss: 28472.0764 - Avg Loss: 164.5785\n",
            "Epoch [47/50] - Batch loss: 162.3687 - Epoch Loss: 28634.4451 - Avg Loss: 164.5658\n",
            "Epoch [47/50] - Batch loss: 163.8334 - Epoch Loss: 28798.2785 - Avg Loss: 164.5616\n",
            "Epoch [47/50] - Batch loss: 167.7441 - Epoch Loss: 28966.0226 - Avg Loss: 164.5797\n",
            "Epoch [47/50] - Batch loss: 170.5074 - Epoch Loss: 29136.5299 - Avg Loss: 164.6132\n",
            "Epoch [47/50] - Batch loss: 165.8415 - Epoch Loss: 29302.3714 - Avg Loss: 164.6201\n",
            "Epoch [47/50] - Batch loss: 159.0331 - Epoch Loss: 29461.4045 - Avg Loss: 164.5889\n",
            "Epoch [47/50] - Batch loss: 173.4483 - Epoch Loss: 29634.8529 - Avg Loss: 164.6381\n",
            "Epoch [47/50] - Batch loss: 167.3820 - Epoch Loss: 29802.2349 - Avg Loss: 164.6532\n",
            "Epoch [47/50] - Batch loss: 170.7096 - Epoch Loss: 29972.9445 - Avg Loss: 164.6865\n",
            "Epoch [47/50] - Batch loss: 168.0987 - Epoch Loss: 30141.0432 - Avg Loss: 164.7052\n",
            "Epoch [47/50] - Batch loss: 159.3207 - Epoch Loss: 30300.3639 - Avg Loss: 164.6759\n",
            "Epoch [47/50] - Batch loss: 171.2528 - Epoch Loss: 30471.6167 - Avg Loss: 164.7114\n",
            "Epoch [47/50] - Batch loss: 163.9483 - Epoch Loss: 30635.5650 - Avg Loss: 164.7073\n",
            "Epoch [47/50] - Batch loss: 162.7637 - Epoch Loss: 30798.3287 - Avg Loss: 164.6969\n",
            "Epoch [47/50] - Batch loss: 163.6167 - Epoch Loss: 30961.9454 - Avg Loss: 164.6912\n",
            "Epoch [47/50] - Batch loss: 161.6333 - Epoch Loss: 31123.5787 - Avg Loss: 164.6750\n",
            "Epoch [47/50] - Batch loss: 167.0123 - Epoch Loss: 31290.5910 - Avg Loss: 164.6873\n",
            "Epoch [47/50] - Batch loss: 159.8380 - Epoch Loss: 31450.4290 - Avg Loss: 164.6619\n",
            "Epoch [47/50] - Batch loss: 160.7354 - Epoch Loss: 31611.1644 - Avg Loss: 164.6415\n",
            "Epoch [47/50] - Batch loss: 167.0701 - Epoch Loss: 31778.2345 - Avg Loss: 164.6541\n",
            "Epoch [47/50] - Batch loss: 168.0030 - Epoch Loss: 31946.2375 - Avg Loss: 164.6713\n",
            "Epoch [47/50] - Batch loss: 167.9720 - Epoch Loss: 32114.2095 - Avg Loss: 164.6883\n",
            "Epoch [47/50] - Batch loss: 172.5710 - Epoch Loss: 32286.7805 - Avg Loss: 164.7285\n",
            "Epoch [47/50] - Batch loss: 165.6912 - Epoch Loss: 32452.4717 - Avg Loss: 164.7334\n",
            "Epoch [47/50] - Batch loss: 170.0594 - Epoch Loss: 32622.5311 - Avg Loss: 164.7603\n",
            "Epoch [47/50] - Batch loss: 174.8724 - Epoch Loss: 32797.4035 - Avg Loss: 164.8111\n",
            "Epoch [47/50] - Batch loss: 166.5191 - Epoch Loss: 32963.9225 - Avg Loss: 164.8196\n",
            "Epoch [47/50] - Batch loss: 169.4160 - Epoch Loss: 33133.3386 - Avg Loss: 164.8425\n",
            "Epoch [47/50] - Batch loss: 170.4093 - Epoch Loss: 33303.7479 - Avg Loss: 164.8700\n",
            "Epoch [47/50] - Batch loss: 164.3756 - Epoch Loss: 33468.1235 - Avg Loss: 164.8676\n",
            "Epoch [47/50] - Batch loss: 168.7228 - Epoch Loss: 33636.8462 - Avg Loss: 164.8865\n",
            "Epoch [47/50] - Batch loss: 167.8127 - Epoch Loss: 33804.6589 - Avg Loss: 164.9008\n",
            "Epoch [47/50] - Batch loss: 169.8106 - Epoch Loss: 33974.4695 - Avg Loss: 164.9246\n",
            "Epoch [47/50] - Batch loss: 162.3946 - Epoch Loss: 34136.8641 - Avg Loss: 164.9124\n",
            "Epoch [47/50] - Batch loss: 169.2867 - Epoch Loss: 34306.1508 - Avg Loss: 164.9334\n",
            "Epoch [47/50] - Batch loss: 168.9438 - Epoch Loss: 34475.0947 - Avg Loss: 164.9526\n",
            "Epoch [47/50] - Batch loss: 159.7128 - Epoch Loss: 34634.8075 - Avg Loss: 164.9277\n",
            "Epoch [47/50] - Batch loss: 173.1156 - Epoch Loss: 34807.9231 - Avg Loss: 164.9665\n",
            "Epoch [47/50] - Batch loss: 166.1545 - Epoch Loss: 34974.0777 - Avg Loss: 164.9721\n",
            "Epoch [47/50] - Batch loss: 170.1124 - Epoch Loss: 35144.1901 - Avg Loss: 164.9962\n",
            "Epoch [47/50] - Batch loss: 173.2050 - Epoch Loss: 35317.3952 - Avg Loss: 165.0346\n",
            "Epoch [47/50] - Batch loss: 177.0741 - Epoch Loss: 35494.4693 - Avg Loss: 165.0906\n",
            "Epoch [47/50] - Batch loss: 164.4622 - Epoch Loss: 35658.9315 - Avg Loss: 165.0876\n",
            "Epoch [47/50] - Batch loss: 173.0251 - Epoch Loss: 35831.9565 - Avg Loss: 165.1242\n",
            "Epoch [47/50] - Batch loss: 180.6120 - Epoch Loss: 36012.5686 - Avg Loss: 165.1953\n",
            "Epoch [47/50] - Batch loss: 168.2560 - Epoch Loss: 36180.8246 - Avg Loss: 165.2092\n",
            "Epoch [47/50] - Batch loss: 172.8385 - Epoch Loss: 36353.6631 - Avg Loss: 165.2439\n",
            "Epoch [47/50] - Batch loss: 162.7749 - Epoch Loss: 36516.4380 - Avg Loss: 165.2328\n",
            "Epoch [47/50] - Batch loss: 165.3712 - Epoch Loss: 36681.8092 - Avg Loss: 165.2334\n",
            "Epoch [47/50] - Batch loss: 156.4738 - Epoch Loss: 36838.2830 - Avg Loss: 165.1941\n",
            "Epoch [47/50] - Batch loss: 165.5676 - Epoch Loss: 37003.8506 - Avg Loss: 165.1958\n",
            "Epoch [47/50] - Batch loss: 168.6737 - Epoch Loss: 37172.5243 - Avg Loss: 165.2112\n",
            "Epoch [47/50] - Batch loss: 173.7543 - Epoch Loss: 37346.2786 - Avg Loss: 165.2490\n",
            "Epoch [47/50] - Batch loss: 169.7837 - Epoch Loss: 37516.0623 - Avg Loss: 165.2690\n",
            "Epoch [47/50] - Batch loss: 162.0112 - Epoch Loss: 37678.0735 - Avg Loss: 165.2547\n",
            "Epoch [47/50] - Batch loss: 161.6284 - Epoch Loss: 37839.7019 - Avg Loss: 165.2389\n",
            "Epoch [47/50] - Batch loss: 167.3762 - Epoch Loss: 38007.0781 - Avg Loss: 165.2482\n",
            "Epoch [47/50] - Batch loss: 163.4775 - Epoch Loss: 38170.5557 - Avg Loss: 165.2405\n",
            "Epoch [47/50] - Batch loss: 169.0057 - Epoch Loss: 38339.5614 - Avg Loss: 165.2567\n",
            "Epoch [47/50] - Batch loss: 164.1904 - Epoch Loss: 38503.7518 - Avg Loss: 165.2522\n",
            "Epoch [47/50] - Batch loss: 176.6718 - Epoch Loss: 38680.4237 - Avg Loss: 165.3010\n",
            "Epoch [47/50] - Batch loss: 166.0406 - Epoch Loss: 38846.4643 - Avg Loss: 165.3041\n",
            "Epoch [47/50] - Batch loss: 164.4402 - Epoch Loss: 39010.9045 - Avg Loss: 165.3004\n",
            "Epoch [47/50] - Batch loss: 178.9758 - Epoch Loss: 39189.8803 - Avg Loss: 165.3581\n",
            "Epoch [47/50] - Batch loss: 161.9086 - Epoch Loss: 39351.7888 - Avg Loss: 165.3437\n",
            "Epoch [47/50] - Batch loss: 172.5879 - Epoch Loss: 39524.3767 - Avg Loss: 165.3740\n",
            "Epoch [47/50] - Batch loss: 163.8127 - Epoch Loss: 39688.1894 - Avg Loss: 165.3675\n",
            "Epoch [47/50] - Batch loss: 170.5843 - Epoch Loss: 39858.7737 - Avg Loss: 165.3891\n",
            "Epoch [47/50] - Batch loss: 174.5394 - Epoch Loss: 40033.3132 - Avg Loss: 165.4269\n",
            "Epoch [47/50] - Batch loss: 166.9960 - Epoch Loss: 40200.3092 - Avg Loss: 165.4334\n",
            "Epoch [47/50] - Batch loss: 157.6655 - Epoch Loss: 40357.9746 - Avg Loss: 165.4015\n",
            "Epoch [47/50] - Batch loss: 157.8236 - Epoch Loss: 40515.7982 - Avg Loss: 165.3706\n",
            "Epoch [47/50] - Batch loss: 165.5931 - Epoch Loss: 40681.3913 - Avg Loss: 165.3715\n",
            "Epoch [47/50] - Batch loss: 160.2136 - Epoch Loss: 40841.6049 - Avg Loss: 165.3506\n",
            "Epoch [47/50] - Batch loss: 155.7219 - Epoch Loss: 40997.3268 - Avg Loss: 165.3118\n",
            "Epoch [47/50] - Batch loss: 168.0470 - Epoch Loss: 41165.3739 - Avg Loss: 165.3228\n",
            "Epoch [47/50] - Batch loss: 163.0148 - Epoch Loss: 41328.3887 - Avg Loss: 165.3136\n",
            "Epoch [47/50] - Batch loss: 169.8513 - Epoch Loss: 41498.2400 - Avg Loss: 165.3316\n",
            "Epoch [47/50] - Batch loss: 162.0807 - Epoch Loss: 41660.3207 - Avg Loss: 165.3187\n",
            "Epoch [47/50] - Batch loss: 177.2166 - Epoch Loss: 41837.5373 - Avg Loss: 165.3658\n",
            "Epoch [47/50] - Batch loss: 169.5896 - Epoch Loss: 42007.1270 - Avg Loss: 165.3824\n",
            "Epoch [47/50] - Batch loss: 172.9869 - Epoch Loss: 42180.1139 - Avg Loss: 165.4122\n",
            "Epoch [47/50] - Batch loss: 171.1926 - Epoch Loss: 42351.3065 - Avg Loss: 165.4348\n",
            "Epoch [47/50] - Batch loss: 166.0161 - Epoch Loss: 42517.3227 - Avg Loss: 165.4371\n",
            "Epoch [47/50] - Batch loss: 179.7601 - Epoch Loss: 42697.0827 - Avg Loss: 165.4926\n",
            "Epoch [47/50] - Batch loss: 174.2047 - Epoch Loss: 42871.2874 - Avg Loss: 165.5262\n",
            "Epoch [47/50] - Batch loss: 170.2986 - Epoch Loss: 43041.5859 - Avg Loss: 165.5446\n",
            "Epoch [47/50] - Batch loss: 174.8374 - Epoch Loss: 43216.4233 - Avg Loss: 165.5802\n",
            "Epoch [47/50] - Batch loss: 176.6447 - Epoch Loss: 43393.0680 - Avg Loss: 165.6224\n",
            "Epoch [47/50] - Batch loss: 178.5444 - Epoch Loss: 43571.6124 - Avg Loss: 165.6715\n",
            "Epoch [47/50] - Batch loss: 166.3362 - Epoch Loss: 43737.9486 - Avg Loss: 165.6740\n",
            "Epoch [47/50] - Batch loss: 160.8238 - Epoch Loss: 43898.7724 - Avg Loss: 165.6557\n",
            "Epoch [47/50] - Batch loss: 177.5816 - Epoch Loss: 44076.3540 - Avg Loss: 165.7006\n",
            "Epoch [47/50] - Batch loss: 166.0241 - Epoch Loss: 44242.3781 - Avg Loss: 165.7018\n",
            "Epoch [47/50] - Batch loss: 173.0347 - Epoch Loss: 44415.4128 - Avg Loss: 165.7292\n",
            "Epoch [47/50] - Batch loss: 161.2146 - Epoch Loss: 44576.6273 - Avg Loss: 165.7124\n",
            "Epoch [47/50] - Batch loss: 159.9758 - Epoch Loss: 44736.6031 - Avg Loss: 165.6911\n",
            "Epoch [47/50] - Batch loss: 166.2819 - Epoch Loss: 44902.8850 - Avg Loss: 165.6933\n",
            "Epoch [47/50] - Batch loss: 177.6606 - Epoch Loss: 45080.5456 - Avg Loss: 165.7373\n",
            "Epoch [47/50] - Batch loss: 156.5512 - Epoch Loss: 45237.0969 - Avg Loss: 165.7037\n",
            "Epoch [47/50] - Batch loss: 162.0408 - Epoch Loss: 45399.1377 - Avg Loss: 165.6903\n",
            "Epoch [47/50] - Batch loss: 154.9876 - Epoch Loss: 45554.1252 - Avg Loss: 165.6514\n",
            "Epoch [47/50] - Batch loss: 165.7154 - Epoch Loss: 45719.8406 - Avg Loss: 165.6516\n",
            "Epoch [47/50] - Batch loss: 173.5443 - Epoch Loss: 45893.3850 - Avg Loss: 165.6801\n",
            "Epoch [47/50] - Batch loss: 160.9873 - Epoch Loss: 46054.3723 - Avg Loss: 165.6632\n",
            "Epoch [47/50] - Batch loss: 171.2084 - Epoch Loss: 46225.5806 - Avg Loss: 165.6831\n",
            "Epoch [47/50] - Batch loss: 173.9424 - Epoch Loss: 46399.5231 - Avg Loss: 165.7126\n",
            "Epoch [47/50] - Batch loss: 168.1773 - Epoch Loss: 46567.7004 - Avg Loss: 165.7214\n",
            "Epoch [47/50] - Batch loss: 165.1092 - Epoch Loss: 46732.8096 - Avg Loss: 165.7192\n",
            "Epoch [47/50] - Batch loss: 172.5192 - Epoch Loss: 46905.3288 - Avg Loss: 165.7432\n",
            "Epoch [47/50] - Batch loss: 161.1764 - Epoch Loss: 47066.5052 - Avg Loss: 165.7271\n",
            "Epoch [47/50] - Batch loss: 163.7651 - Epoch Loss: 47230.2703 - Avg Loss: 165.7202\n",
            "Epoch [47/50] - Batch loss: 168.3251 - Epoch Loss: 47398.5954 - Avg Loss: 165.7294\n",
            "Epoch [47/50] - Batch loss: 160.0499 - Epoch Loss: 47558.6454 - Avg Loss: 165.7096\n",
            "Epoch [47/50] - Batch loss: 162.8140 - Epoch Loss: 47721.4593 - Avg Loss: 165.6995\n",
            "Epoch [47/50] - Batch loss: 170.8864 - Epoch Loss: 47892.3457 - Avg Loss: 165.7175\n",
            "Epoch [47/50] - Batch loss: 161.6442 - Epoch Loss: 48053.9899 - Avg Loss: 165.7034\n",
            "Epoch [47/50] - Batch loss: 169.2848 - Epoch Loss: 48223.2748 - Avg Loss: 165.7157\n",
            "Epoch [47/50] - Batch loss: 174.0133 - Epoch Loss: 48397.2880 - Avg Loss: 165.7441\n",
            "Epoch [47/50] - Batch loss: 159.8606 - Epoch Loss: 48557.1486 - Avg Loss: 165.7241\n",
            "Epoch [47/50] - Batch loss: 153.5312 - Epoch Loss: 48710.6798 - Avg Loss: 165.6826\n",
            "Epoch [47/50] - Batch loss: 163.6310 - Epoch Loss: 48874.3108 - Avg Loss: 165.6756\n",
            "Epoch [47/50] - Batch loss: 164.3335 - Epoch Loss: 49038.6443 - Avg Loss: 165.6711\n",
            "Epoch [47/50] - Batch loss: 172.4086 - Epoch Loss: 49211.0529 - Avg Loss: 165.6938\n",
            "Epoch [47/50] - Batch loss: 170.4089 - Epoch Loss: 49381.4619 - Avg Loss: 165.7096\n",
            "Epoch [47/50] - Batch loss: 159.3794 - Epoch Loss: 49540.8413 - Avg Loss: 165.6884\n",
            "Epoch [47/50] - Batch loss: 171.9898 - Epoch Loss: 49712.8311 - Avg Loss: 165.7094\n",
            "Epoch [47/50] - Batch loss: 162.8611 - Epoch Loss: 49875.6922 - Avg Loss: 165.7000\n",
            "Epoch [47/50] - Batch loss: 171.8360 - Epoch Loss: 50047.5282 - Avg Loss: 165.7203\n",
            "Epoch [47/50] - Batch loss: 159.4494 - Epoch Loss: 50206.9775 - Avg Loss: 165.6996\n",
            "Epoch [47/50] - Batch loss: 164.7840 - Epoch Loss: 50371.7615 - Avg Loss: 165.6966\n",
            "Epoch [47/50] - Batch loss: 161.9672 - Epoch Loss: 50533.7287 - Avg Loss: 165.6844\n",
            "Epoch [47/50] - Batch loss: 169.7188 - Epoch Loss: 50703.4474 - Avg Loss: 165.6975\n",
            "Epoch [47/50] - Batch loss: 165.2099 - Epoch Loss: 50868.6574 - Avg Loss: 165.6960\n",
            "Epoch [47/50] - Batch loss: 175.0335 - Epoch Loss: 51043.6909 - Avg Loss: 165.7263\n",
            "Epoch [47/50] - Batch loss: 160.5515 - Epoch Loss: 51204.2424 - Avg Loss: 165.7095\n",
            "Epoch [47/50] - Batch loss: 165.1234 - Epoch Loss: 51369.3659 - Avg Loss: 165.7076\n",
            "Epoch [47/50] - Batch loss: 164.0356 - Epoch Loss: 51533.4015 - Avg Loss: 165.7023\n",
            "Epoch [47/50] - Batch loss: 167.6594 - Epoch Loss: 51701.0609 - Avg Loss: 165.7085\n",
            "Epoch [47/50] - Batch loss: 160.8783 - Epoch Loss: 51861.9392 - Avg Loss: 165.6931\n",
            "Epoch [47/50] - Batch loss: 162.2900 - Epoch Loss: 52024.2293 - Avg Loss: 165.6823\n",
            "Epoch [47/50] - Batch loss: 164.7478 - Epoch Loss: 52188.9771 - Avg Loss: 165.6793\n",
            "Epoch [47/50] - Batch loss: 172.7825 - Epoch Loss: 52361.7595 - Avg Loss: 165.7018\n",
            "Epoch [47/50] - Batch loss: 158.6864 - Epoch Loss: 52520.4459 - Avg Loss: 165.6796\n",
            "Epoch [47/50] - Batch loss: 164.6119 - Epoch Loss: 52685.0578 - Avg Loss: 165.6763\n",
            "Epoch [47/50] - Batch loss: 165.8324 - Epoch Loss: 52850.8902 - Avg Loss: 165.6768\n",
            "Epoch [47/50] - Batch loss: 165.9003 - Epoch Loss: 53016.7904 - Avg Loss: 165.6775\n",
            "Epoch [47/50] - Batch loss: 166.3263 - Epoch Loss: 53183.1168 - Avg Loss: 165.6795\n",
            "Epoch [47/50] - Batch loss: 165.1039 - Epoch Loss: 53348.2206 - Avg Loss: 165.6777\n",
            "Epoch [47/50] - Batch loss: 165.2005 - Epoch Loss: 53513.4211 - Avg Loss: 165.6762\n",
            "Epoch [47/50] - Batch loss: 162.4039 - Epoch Loss: 53675.8249 - Avg Loss: 165.6661\n",
            "Epoch [47/50] - Batch loss: 174.2282 - Epoch Loss: 53850.0531 - Avg Loss: 165.6925\n",
            "Epoch [47/50] - Batch loss: 163.6875 - Epoch Loss: 54013.7406 - Avg Loss: 165.6863\n",
            "Epoch [47/50] - Batch loss: 161.6181 - Epoch Loss: 54175.3587 - Avg Loss: 165.6739\n",
            "Epoch [47/50] - Batch loss: 166.6572 - Epoch Loss: 54342.0159 - Avg Loss: 165.6769\n",
            "Epoch [47/50] - Batch loss: 172.1805 - Epoch Loss: 54514.1964 - Avg Loss: 165.6966\n",
            "Epoch [47/50] - Batch loss: 160.2646 - Epoch Loss: 54674.4610 - Avg Loss: 165.6802\n",
            "Epoch [47/50] - Batch loss: 174.7983 - Epoch Loss: 54849.2593 - Avg Loss: 165.7077\n",
            "Epoch [47/50] - Batch loss: 163.3401 - Epoch Loss: 55012.5994 - Avg Loss: 165.7006\n",
            "Epoch [47/50] - Batch loss: 170.0776 - Epoch Loss: 55182.6770 - Avg Loss: 165.7137\n",
            "Epoch [47/50] - Batch loss: 160.6692 - Epoch Loss: 55343.3462 - Avg Loss: 165.6986\n",
            "Epoch [47/50] - Batch loss: 164.2942 - Epoch Loss: 55507.6404 - Avg Loss: 165.6944\n",
            "Epoch [47/50] - Batch loss: 171.6305 - Epoch Loss: 55679.2710 - Avg Loss: 165.7121\n",
            "Epoch [47/50] - Batch loss: 170.9758 - Epoch Loss: 55850.2467 - Avg Loss: 165.7277\n",
            "Epoch [47/50] - Batch loss: 170.3490 - Epoch Loss: 56020.5957 - Avg Loss: 165.7414\n",
            "Epoch [47/50] - Batch loss: 168.1804 - Epoch Loss: 56188.7761 - Avg Loss: 165.7486\n",
            "Epoch [47/50] - Batch loss: 165.8397 - Epoch Loss: 56354.6158 - Avg Loss: 165.7489\n",
            "Epoch [47/50] - Batch loss: 169.3683 - Epoch Loss: 56523.9841 - Avg Loss: 165.7595\n",
            "Epoch [47/50] - Batch loss: 168.9774 - Epoch Loss: 56692.9615 - Avg Loss: 165.7689\n",
            "Epoch [47/50] - Batch loss: 159.9241 - Epoch Loss: 56852.8856 - Avg Loss: 165.7519\n",
            "Epoch [47/50] - Batch loss: 176.6499 - Epoch Loss: 57029.5356 - Avg Loss: 165.7835\n",
            "Epoch [47/50] - Batch loss: 167.1718 - Epoch Loss: 57196.7074 - Avg Loss: 165.7876\n",
            "Epoch [47/50] - Batch loss: 164.5672 - Epoch Loss: 57361.2746 - Avg Loss: 165.7840\n",
            "Epoch [47/50] - Batch loss: 165.2778 - Epoch Loss: 57526.5523 - Avg Loss: 165.7826\n",
            "Epoch [47/50] - Batch loss: 166.0900 - Epoch Loss: 57692.6423 - Avg Loss: 165.7835\n",
            "Epoch [47/50] - Batch loss: 159.6736 - Epoch Loss: 57852.3158 - Avg Loss: 165.7659\n",
            "Epoch [47/50] - Batch loss: 165.2620 - Epoch Loss: 58017.5778 - Avg Loss: 165.7645\n",
            "Epoch [47/50] - Batch loss: 173.2515 - Epoch Loss: 58190.8293 - Avg Loss: 165.7858\n",
            "Epoch [47/50] - Batch loss: 171.5919 - Epoch Loss: 58362.4212 - Avg Loss: 165.8023\n",
            "Epoch [47/50] - Batch loss: 166.2354 - Epoch Loss: 58528.6566 - Avg Loss: 165.8036\n",
            "Epoch [47/50] - Batch loss: 160.6205 - Epoch Loss: 58689.2771 - Avg Loss: 165.7889\n",
            "Epoch [47/50] - Batch loss: 168.9374 - Epoch Loss: 58858.2145 - Avg Loss: 165.7978\n",
            "Epoch [47/50] - Batch loss: 167.8434 - Epoch Loss: 59026.0579 - Avg Loss: 165.8035\n",
            "Epoch [47/50] - Batch loss: 156.7207 - Epoch Loss: 59182.7786 - Avg Loss: 165.7781\n",
            "Epoch [47/50] - Batch loss: 158.9732 - Epoch Loss: 59341.7518 - Avg Loss: 165.7591\n",
            "Epoch [47/50] - Batch loss: 163.1980 - Epoch Loss: 59504.9498 - Avg Loss: 165.7519\n",
            "Epoch [47/50] - Batch loss: 166.6600 - Epoch Loss: 59671.6098 - Avg Loss: 165.7545\n",
            "Epoch [47/50] - Batch loss: 166.8184 - Epoch Loss: 59838.4282 - Avg Loss: 165.7574\n",
            "Epoch [47/50] - Batch loss: 166.7499 - Epoch Loss: 60005.1781 - Avg Loss: 165.7602\n",
            "Epoch [47/50] - Batch loss: 163.4858 - Epoch Loss: 60168.6640 - Avg Loss: 165.7539\n",
            "Epoch [47/50] - Batch loss: 158.0209 - Epoch Loss: 60326.6848 - Avg Loss: 165.7327\n",
            "Epoch [47/50] - Batch loss: 161.0016 - Epoch Loss: 60487.6864 - Avg Loss: 165.7197\n",
            "Epoch [47/50] - Batch loss: 165.1361 - Epoch Loss: 60652.8225 - Avg Loss: 165.7181\n",
            "Epoch [47/50] - Batch loss: 168.8738 - Epoch Loss: 60821.6963 - Avg Loss: 165.7267\n",
            "Epoch [47/50] - Batch loss: 158.1711 - Epoch Loss: 60979.8674 - Avg Loss: 165.7062\n",
            "Epoch [47/50] - Batch loss: 165.3220 - Epoch Loss: 61145.1894 - Avg Loss: 165.7051\n",
            "Epoch [47/50] - Batch loss: 167.9489 - Epoch Loss: 61313.1383 - Avg Loss: 165.7112\n",
            "Epoch [47/50] - Batch loss: 167.5216 - Epoch Loss: 61480.6599 - Avg Loss: 165.7161\n",
            "Epoch [47/50] - Batch loss: 159.7585 - Epoch Loss: 61640.4184 - Avg Loss: 165.7000\n",
            "Epoch [47/50] - Batch loss: 168.4893 - Epoch Loss: 61808.9076 - Avg Loss: 165.7075\n",
            "Epoch [47/50] - Batch loss: 167.2024 - Epoch Loss: 61976.1100 - Avg Loss: 165.7115\n",
            "Epoch [47/50] - Batch loss: 164.9168 - Epoch Loss: 62141.0268 - Avg Loss: 165.7094\n",
            "Epoch [47/50] - Batch loss: 167.5763 - Epoch Loss: 62308.6031 - Avg Loss: 165.7144\n",
            "Epoch [47/50] - Batch loss: 164.6350 - Epoch Loss: 62473.2380 - Avg Loss: 165.7115\n",
            "Epoch [47/50] - Batch loss: 164.1183 - Epoch Loss: 62637.3563 - Avg Loss: 165.7073\n",
            "Epoch [47/50] - Batch loss: 158.8069 - Epoch Loss: 62796.1632 - Avg Loss: 165.6891\n",
            "Epoch [47/50] - Batch loss: 166.4893 - Epoch Loss: 62962.6525 - Avg Loss: 165.6912\n",
            "Epoch [47/50] - Batch loss: 167.3101 - Epoch Loss: 63129.9626 - Avg Loss: 165.6954\n",
            "Epoch [47/50] - Batch loss: 157.4248 - Epoch Loss: 63287.3874 - Avg Loss: 165.6738\n",
            "Epoch [47/50] - Batch loss: 165.2270 - Epoch Loss: 63452.6144 - Avg Loss: 165.6726\n",
            "Epoch [47/50] - Batch loss: 159.5036 - Epoch Loss: 63612.1180 - Avg Loss: 165.6566\n",
            "Epoch [47/50] - Batch loss: 170.4444 - Epoch Loss: 63782.5623 - Avg Loss: 165.6690\n",
            "Epoch [47/50] - Batch loss: 159.3987 - Epoch Loss: 63941.9610 - Avg Loss: 165.6527\n",
            "Epoch [47/50] - Batch loss: 167.2070 - Epoch Loss: 64109.1680 - Avg Loss: 165.6568\n",
            "Epoch [47/50] - Batch loss: 159.2231 - Epoch Loss: 64268.3911 - Avg Loss: 165.6402\n",
            "Epoch [47/50] - Batch loss: 163.1800 - Epoch Loss: 64431.5712 - Avg Loss: 165.6339\n",
            "Epoch [47/50] - Batch loss: 174.5128 - Epoch Loss: 64606.0839 - Avg Loss: 165.6566\n",
            "Epoch [47/50] - Batch loss: 172.4413 - Epoch Loss: 64778.5252 - Avg Loss: 165.6740\n",
            "Epoch [47/50] - Batch loss: 166.6328 - Epoch Loss: 64945.1581 - Avg Loss: 165.6764\n",
            "Epoch [47/50] - Batch loss: 168.9964 - Epoch Loss: 65114.1545 - Avg Loss: 165.6849\n",
            "Epoch [47/50] - Batch loss: 168.8392 - Epoch Loss: 65282.9937 - Avg Loss: 165.6929\n",
            "Epoch [47/50] - Batch loss: 161.5092 - Epoch Loss: 65444.5029 - Avg Loss: 165.6823\n",
            "Epoch [47/50] - Batch loss: 163.2336 - Epoch Loss: 65607.7365 - Avg Loss: 165.6761\n",
            "Epoch [47/50] - Batch loss: 164.6076 - Epoch Loss: 65772.3441 - Avg Loss: 165.6734\n",
            "Epoch [47/50] - Batch loss: 167.5732 - Epoch Loss: 65939.9173 - Avg Loss: 165.6782\n",
            "Epoch [47/50] - Batch loss: 170.9687 - Epoch Loss: 66110.8860 - Avg Loss: 165.6914\n",
            "Epoch [47/50] - Batch loss: 163.6004 - Epoch Loss: 66274.4865 - Avg Loss: 165.6862\n",
            "Epoch [47/50] - Batch loss: 166.1952 - Epoch Loss: 66440.6817 - Avg Loss: 165.6875\n",
            "Epoch [47/50] - Batch loss: 164.6775 - Epoch Loss: 66605.3592 - Avg Loss: 165.6850\n",
            "Epoch [47/50] - Batch loss: 165.4851 - Epoch Loss: 66770.8443 - Avg Loss: 165.6845\n",
            "Epoch [47/50] - Batch loss: 167.2451 - Epoch Loss: 66938.0894 - Avg Loss: 165.6883\n",
            "Epoch [47/50] - Batch loss: 168.1957 - Epoch Loss: 67106.2851 - Avg Loss: 165.6945\n",
            "Epoch [47/50] - Batch loss: 167.8176 - Epoch Loss: 67274.1027 - Avg Loss: 165.6998\n",
            "Epoch [47/50] - Batch loss: 168.4259 - Epoch Loss: 67442.5286 - Avg Loss: 165.7065\n",
            "Epoch [47/50] - Batch loss: 168.7832 - Epoch Loss: 67611.3118 - Avg Loss: 165.7140\n",
            "Epoch [47/50] - Batch loss: 168.5303 - Epoch Loss: 67779.8422 - Avg Loss: 165.7209\n",
            "Epoch [47/50] - Batch loss: 168.2292 - Epoch Loss: 67948.0713 - Avg Loss: 165.7270\n",
            "Epoch [47/50] - Batch loss: 171.8422 - Epoch Loss: 68119.9136 - Avg Loss: 165.7419\n",
            "Epoch [47/50] - Batch loss: 164.5158 - Epoch Loss: 68284.4294 - Avg Loss: 165.7389\n",
            "Epoch [47/50] - Batch loss: 160.8144 - Epoch Loss: 68445.2438 - Avg Loss: 165.7270\n",
            "Epoch [47/50] - Batch loss: 165.8150 - Epoch Loss: 68611.0588 - Avg Loss: 165.7272\n",
            "Epoch [47/50] - Batch loss: 174.3576 - Epoch Loss: 68785.4164 - Avg Loss: 165.7480\n",
            "Epoch [47/50] - Batch loss: 164.8170 - Epoch Loss: 68950.2333 - Avg Loss: 165.7458\n",
            "Epoch [47/50] - Batch loss: 177.0568 - Epoch Loss: 69127.2901 - Avg Loss: 165.7729\n",
            "Epoch [47/50] - Batch loss: 164.6016 - Epoch Loss: 69291.8917 - Avg Loss: 165.7701\n",
            "Epoch [47/50] - Batch loss: 164.9677 - Epoch Loss: 69456.8594 - Avg Loss: 165.7682\n",
            "Epoch [47/50] - Batch loss: 167.3864 - Epoch Loss: 69624.2458 - Avg Loss: 165.7720\n",
            "Epoch [47/50] - Batch loss: 166.0644 - Epoch Loss: 69790.3102 - Avg Loss: 165.7727\n",
            "Epoch [47/50] - Batch loss: 168.3644 - Epoch Loss: 69958.6746 - Avg Loss: 165.7788\n",
            "Epoch [47/50] - Batch loss: 175.4633 - Epoch Loss: 70134.1379 - Avg Loss: 165.8017\n",
            "Epoch [47/50] - Batch loss: 157.0276 - Epoch Loss: 70291.1656 - Avg Loss: 165.7811\n",
            "Epoch [47/50] - Batch loss: 169.2827 - Epoch Loss: 70460.4483 - Avg Loss: 165.7893\n",
            "Epoch [47/50] - Batch loss: 165.5875 - Epoch Loss: 70626.0358 - Avg Loss: 165.7888\n",
            "Epoch [47/50] - Batch loss: 162.3905 - Epoch Loss: 70788.4263 - Avg Loss: 165.7809\n",
            "Epoch [47/50] - Batch loss: 162.1280 - Epoch Loss: 70950.5543 - Avg Loss: 165.7723\n",
            "Epoch [47/50] - Batch loss: 169.8985 - Epoch Loss: 71120.4528 - Avg Loss: 165.7819\n",
            "Epoch [47/50] - Batch loss: 168.2530 - Epoch Loss: 71288.7057 - Avg Loss: 165.7877\n",
            "Epoch [47/50] - Batch loss: 171.7335 - Epoch Loss: 71460.4392 - Avg Loss: 165.8015\n",
            "Epoch [47/50] - Batch loss: 164.8444 - Epoch Loss: 71625.2836 - Avg Loss: 165.7993\n",
            "Epoch [47/50] - Batch loss: 175.4901 - Epoch Loss: 71800.7737 - Avg Loss: 165.8216\n",
            "Epoch [47/50] - Batch loss: 162.0221 - Epoch Loss: 71962.7959 - Avg Loss: 165.8129\n",
            "Epoch [47/50] - Batch loss: 172.4063 - Epoch Loss: 72135.2022 - Avg Loss: 165.8281\n",
            "Epoch [47/50] - Batch loss: 175.0130 - Epoch Loss: 72310.2151 - Avg Loss: 165.8491\n",
            "Epoch [47/50] - Batch loss: 158.7999 - Epoch Loss: 72469.0150 - Avg Loss: 165.8330\n",
            "Epoch [47/50] - Batch loss: 159.6820 - Epoch Loss: 72628.6970 - Avg Loss: 165.8189\n",
            "Epoch [47/50] - Batch loss: 165.1190 - Epoch Loss: 72793.8160 - Avg Loss: 165.8173\n",
            "Epoch [47/50] - Batch loss: 150.9649 - Epoch Loss: 72944.7809 - Avg Loss: 165.7836\n",
            "Epoch [47/50] - Batch loss: 166.8475 - Epoch Loss: 73111.6284 - Avg Loss: 165.7860\n",
            "Epoch [47/50] - Batch loss: 167.0811 - Epoch Loss: 73278.7095 - Avg Loss: 165.7889\n",
            "Epoch [47/50] - Batch loss: 170.7704 - Epoch Loss: 73449.4799 - Avg Loss: 165.8002\n",
            "Epoch [47/50] - Batch loss: 160.7610 - Epoch Loss: 73610.2409 - Avg Loss: 165.7888\n",
            "Epoch [47/50] - Batch loss: 165.5643 - Epoch Loss: 73775.8052 - Avg Loss: 165.7883\n",
            "Epoch [47/50] - Batch loss: 164.5648 - Epoch Loss: 73940.3700 - Avg Loss: 165.7856\n",
            "Epoch [47/50] - Batch loss: 164.5534 - Epoch Loss: 74104.9234 - Avg Loss: 165.7828\n",
            "Epoch [47/50] - Batch loss: 164.8851 - Epoch Loss: 74269.8085 - Avg Loss: 165.7808\n",
            "Epoch [47/50] - Batch loss: 160.8112 - Epoch Loss: 74430.6197 - Avg Loss: 165.7698\n",
            "Epoch [47/50] - Batch loss: 159.6003 - Epoch Loss: 74590.2200 - Avg Loss: 165.7560\n",
            "Epoch [47/50] - Batch loss: 162.4832 - Epoch Loss: 74752.7032 - Avg Loss: 165.7488\n",
            "Epoch [47/50] - Batch loss: 167.8760 - Epoch Loss: 74920.5792 - Avg Loss: 165.7535\n",
            "Epoch [47/50] - Batch loss: 167.0745 - Epoch Loss: 75087.6537 - Avg Loss: 165.7564\n",
            "Epoch [47/50] - Batch loss: 154.1020 - Epoch Loss: 75241.7557 - Avg Loss: 165.7307\n",
            "Epoch [47/50] - Batch loss: 154.3703 - Epoch Loss: 75396.1260 - Avg Loss: 165.7058\n",
            "Epoch [47/50] - Batch loss: 160.3885 - Epoch Loss: 75556.5145 - Avg Loss: 165.6941\n",
            "Epoch [47/50] - Batch loss: 161.9679 - Epoch Loss: 75718.4824 - Avg Loss: 165.6860\n",
            "Epoch [47/50] - Batch loss: 162.5687 - Epoch Loss: 75881.0511 - Avg Loss: 165.6792\n",
            "Epoch [47/50] - Batch loss: 154.3147 - Epoch Loss: 76035.3658 - Avg Loss: 165.6544\n",
            "Epoch [47/50] - Batch loss: 160.0440 - Epoch Loss: 76195.4098 - Avg Loss: 165.6422\n",
            "Epoch [47/50] - Batch loss: 170.3827 - Epoch Loss: 76365.7925 - Avg Loss: 165.6525\n",
            "Epoch [47/50] - Batch loss: 158.8885 - Epoch Loss: 76524.6810 - Avg Loss: 165.6378\n",
            "Epoch [47/50] - Batch loss: 159.7096 - Epoch Loss: 76684.3905 - Avg Loss: 165.6250\n",
            "Epoch [47/50] - Batch loss: 159.6784 - Epoch Loss: 76844.0690 - Avg Loss: 165.6122\n",
            "Epoch [47/50] - Batch loss: 158.4144 - Epoch Loss: 77002.4834 - Avg Loss: 165.5967\n",
            "Epoch [47/50] - Batch loss: 161.0261 - Epoch Loss: 77163.5096 - Avg Loss: 165.5869\n",
            "Epoch [47/50] - Batch loss: 169.5599 - Epoch Loss: 77333.0694 - Avg Loss: 165.5954\n",
            "Epoch [47/50] - Batch loss: 164.3100 - Epoch Loss: 77497.3794 - Avg Loss: 165.5927\n",
            "Epoch [47/50] - Batch loss: 154.4713 - Epoch Loss: 77651.8507 - Avg Loss: 165.5690\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 48/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c4e3ec93808490595a38fea46627185"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [48/50] - Batch loss: 158.5071 - Epoch Loss: 158.5071 - Avg Loss: 158.5071\n",
            "Epoch [48/50] - Batch loss: 161.6040 - Epoch Loss: 320.1111 - Avg Loss: 160.0555\n",
            "Epoch [48/50] - Batch loss: 158.9691 - Epoch Loss: 479.0802 - Avg Loss: 159.6934\n",
            "Epoch [48/50] - Batch loss: 161.9844 - Epoch Loss: 641.0647 - Avg Loss: 160.2662\n",
            "Epoch [48/50] - Batch loss: 162.3461 - Epoch Loss: 803.4108 - Avg Loss: 160.6822\n",
            "Epoch [48/50] - Batch loss: 170.6546 - Epoch Loss: 974.0654 - Avg Loss: 162.3442\n",
            "Epoch [48/50] - Batch loss: 167.4651 - Epoch Loss: 1141.5306 - Avg Loss: 163.0758\n",
            "Epoch [48/50] - Batch loss: 164.0457 - Epoch Loss: 1305.5762 - Avg Loss: 163.1970\n",
            "Epoch [48/50] - Batch loss: 160.7853 - Epoch Loss: 1466.3615 - Avg Loss: 162.9291\n",
            "Epoch [48/50] - Batch loss: 160.8531 - Epoch Loss: 1627.2146 - Avg Loss: 162.7215\n",
            "Epoch [48/50] - Batch loss: 159.3993 - Epoch Loss: 1786.6140 - Avg Loss: 162.4195\n",
            "Epoch [48/50] - Batch loss: 166.2373 - Epoch Loss: 1952.8513 - Avg Loss: 162.7376\n",
            "Epoch [48/50] - Batch loss: 163.1174 - Epoch Loss: 2115.9687 - Avg Loss: 162.7668\n",
            "Epoch [48/50] - Batch loss: 162.9781 - Epoch Loss: 2278.9468 - Avg Loss: 162.7819\n",
            "Epoch [48/50] - Batch loss: 159.5726 - Epoch Loss: 2438.5194 - Avg Loss: 162.5680\n",
            "Epoch [48/50] - Batch loss: 166.2333 - Epoch Loss: 2604.7527 - Avg Loss: 162.7970\n",
            "Epoch [48/50] - Batch loss: 161.0603 - Epoch Loss: 2765.8130 - Avg Loss: 162.6949\n",
            "Epoch [48/50] - Batch loss: 167.5806 - Epoch Loss: 2933.3935 - Avg Loss: 162.9663\n",
            "Epoch [48/50] - Batch loss: 165.3949 - Epoch Loss: 3098.7885 - Avg Loss: 163.0941\n",
            "Epoch [48/50] - Batch loss: 155.9380 - Epoch Loss: 3254.7265 - Avg Loss: 162.7363\n",
            "Epoch [48/50] - Batch loss: 154.6030 - Epoch Loss: 3409.3294 - Avg Loss: 162.3490\n",
            "Epoch [48/50] - Batch loss: 165.5131 - Epoch Loss: 3574.8426 - Avg Loss: 162.4928\n",
            "Epoch [48/50] - Batch loss: 171.8839 - Epoch Loss: 3746.7265 - Avg Loss: 162.9012\n",
            "Epoch [48/50] - Batch loss: 158.4160 - Epoch Loss: 3905.1425 - Avg Loss: 162.7143\n",
            "Epoch [48/50] - Batch loss: 159.5811 - Epoch Loss: 4064.7236 - Avg Loss: 162.5889\n",
            "Epoch [48/50] - Batch loss: 159.9454 - Epoch Loss: 4224.6690 - Avg Loss: 162.4873\n",
            "Epoch [48/50] - Batch loss: 158.7205 - Epoch Loss: 4383.3895 - Avg Loss: 162.3478\n",
            "Epoch [48/50] - Batch loss: 173.4943 - Epoch Loss: 4556.8838 - Avg Loss: 162.7459\n",
            "Epoch [48/50] - Batch loss: 161.0264 - Epoch Loss: 4717.9102 - Avg Loss: 162.6866\n",
            "Epoch [48/50] - Batch loss: 161.8502 - Epoch Loss: 4879.7604 - Avg Loss: 162.6587\n",
            "Epoch [48/50] - Batch loss: 158.7558 - Epoch Loss: 5038.5163 - Avg Loss: 162.5328\n",
            "Epoch [48/50] - Batch loss: 155.4450 - Epoch Loss: 5193.9612 - Avg Loss: 162.3113\n",
            "Epoch [48/50] - Batch loss: 163.0113 - Epoch Loss: 5356.9726 - Avg Loss: 162.3325\n",
            "Epoch [48/50] - Batch loss: 164.3692 - Epoch Loss: 5521.3417 - Avg Loss: 162.3924\n",
            "Epoch [48/50] - Batch loss: 155.6786 - Epoch Loss: 5677.0203 - Avg Loss: 162.2006\n",
            "Epoch [48/50] - Batch loss: 170.4981 - Epoch Loss: 5847.5184 - Avg Loss: 162.4311\n",
            "Epoch [48/50] - Batch loss: 160.5350 - Epoch Loss: 6008.0534 - Avg Loss: 162.3798\n",
            "Epoch [48/50] - Batch loss: 151.1468 - Epoch Loss: 6159.2002 - Avg Loss: 162.0842\n",
            "Epoch [48/50] - Batch loss: 164.6984 - Epoch Loss: 6323.8986 - Avg Loss: 162.1512\n",
            "Epoch [48/50] - Batch loss: 156.6464 - Epoch Loss: 6480.5450 - Avg Loss: 162.0136\n",
            "Epoch [48/50] - Batch loss: 157.6247 - Epoch Loss: 6638.1698 - Avg Loss: 161.9066\n",
            "Epoch [48/50] - Batch loss: 157.4389 - Epoch Loss: 6795.6087 - Avg Loss: 161.8002\n",
            "Epoch [48/50] - Batch loss: 160.0715 - Epoch Loss: 6955.6801 - Avg Loss: 161.7600\n",
            "Epoch [48/50] - Batch loss: 168.7374 - Epoch Loss: 7124.4176 - Avg Loss: 161.9186\n",
            "Epoch [48/50] - Batch loss: 157.7726 - Epoch Loss: 7282.1902 - Avg Loss: 161.8264\n",
            "Epoch [48/50] - Batch loss: 163.1395 - Epoch Loss: 7445.3296 - Avg Loss: 161.8550\n",
            "Epoch [48/50] - Batch loss: 170.6331 - Epoch Loss: 7615.9627 - Avg Loss: 162.0418\n",
            "Epoch [48/50] - Batch loss: 169.8800 - Epoch Loss: 7785.8427 - Avg Loss: 162.2051\n",
            "Epoch [48/50] - Batch loss: 167.6732 - Epoch Loss: 7953.5159 - Avg Loss: 162.3167\n",
            "Epoch [48/50] - Batch loss: 154.7866 - Epoch Loss: 8108.3025 - Avg Loss: 162.1660\n",
            "Epoch [48/50] - Batch loss: 156.1735 - Epoch Loss: 8264.4760 - Avg Loss: 162.0485\n",
            "Epoch [48/50] - Batch loss: 157.6513 - Epoch Loss: 8422.1272 - Avg Loss: 161.9640\n",
            "Epoch [48/50] - Batch loss: 154.3139 - Epoch Loss: 8576.4412 - Avg Loss: 161.8196\n",
            "Epoch [48/50] - Batch loss: 165.9782 - Epoch Loss: 8742.4194 - Avg Loss: 161.8967\n",
            "Epoch [48/50] - Batch loss: 167.2602 - Epoch Loss: 8909.6796 - Avg Loss: 161.9942\n",
            "Epoch [48/50] - Batch loss: 171.8341 - Epoch Loss: 9081.5137 - Avg Loss: 162.1699\n",
            "Epoch [48/50] - Batch loss: 157.2025 - Epoch Loss: 9238.7162 - Avg Loss: 162.0827\n",
            "Epoch [48/50] - Batch loss: 164.6746 - Epoch Loss: 9403.3908 - Avg Loss: 162.1274\n",
            "Epoch [48/50] - Batch loss: 168.0533 - Epoch Loss: 9571.4442 - Avg Loss: 162.2279\n",
            "Epoch [48/50] - Batch loss: 170.8564 - Epoch Loss: 9742.3005 - Avg Loss: 162.3717\n",
            "Epoch [48/50] - Batch loss: 166.1478 - Epoch Loss: 9908.4483 - Avg Loss: 162.4336\n",
            "Epoch [48/50] - Batch loss: 162.9728 - Epoch Loss: 10071.4211 - Avg Loss: 162.4423\n",
            "Epoch [48/50] - Batch loss: 161.2481 - Epoch Loss: 10232.6692 - Avg Loss: 162.4233\n",
            "Epoch [48/50] - Batch loss: 164.2029 - Epoch Loss: 10396.8721 - Avg Loss: 162.4511\n",
            "Epoch [48/50] - Batch loss: 158.2588 - Epoch Loss: 10555.1308 - Avg Loss: 162.3866\n",
            "Epoch [48/50] - Batch loss: 165.4162 - Epoch Loss: 10720.5470 - Avg Loss: 162.4325\n",
            "Epoch [48/50] - Batch loss: 171.5799 - Epoch Loss: 10892.1269 - Avg Loss: 162.5691\n",
            "Epoch [48/50] - Batch loss: 172.9146 - Epoch Loss: 11065.0415 - Avg Loss: 162.7212\n",
            "Epoch [48/50] - Batch loss: 153.4039 - Epoch Loss: 11218.4454 - Avg Loss: 162.5862\n",
            "Epoch [48/50] - Batch loss: 168.3671 - Epoch Loss: 11386.8126 - Avg Loss: 162.6688\n",
            "Epoch [48/50] - Batch loss: 170.3714 - Epoch Loss: 11557.1840 - Avg Loss: 162.7772\n",
            "Epoch [48/50] - Batch loss: 161.6674 - Epoch Loss: 11718.8514 - Avg Loss: 162.7618\n",
            "Epoch [48/50] - Batch loss: 161.2142 - Epoch Loss: 11880.0656 - Avg Loss: 162.7406\n",
            "Epoch [48/50] - Batch loss: 154.5177 - Epoch Loss: 12034.5833 - Avg Loss: 162.6295\n",
            "Epoch [48/50] - Batch loss: 168.3005 - Epoch Loss: 12202.8838 - Avg Loss: 162.7051\n",
            "Epoch [48/50] - Batch loss: 171.1806 - Epoch Loss: 12374.0643 - Avg Loss: 162.8166\n",
            "Epoch [48/50] - Batch loss: 158.9576 - Epoch Loss: 12533.0220 - Avg Loss: 162.7665\n",
            "Epoch [48/50] - Batch loss: 167.3579 - Epoch Loss: 12700.3799 - Avg Loss: 162.8254\n",
            "Epoch [48/50] - Batch loss: 158.5292 - Epoch Loss: 12858.9091 - Avg Loss: 162.7710\n",
            "Epoch [48/50] - Batch loss: 161.2236 - Epoch Loss: 13020.1327 - Avg Loss: 162.7517\n",
            "Epoch [48/50] - Batch loss: 166.5846 - Epoch Loss: 13186.7173 - Avg Loss: 162.7990\n",
            "Epoch [48/50] - Batch loss: 169.2936 - Epoch Loss: 13356.0110 - Avg Loss: 162.8782\n",
            "Epoch [48/50] - Batch loss: 165.5926 - Epoch Loss: 13521.6036 - Avg Loss: 162.9109\n",
            "Epoch [48/50] - Batch loss: 164.8960 - Epoch Loss: 13686.4996 - Avg Loss: 162.9345\n",
            "Epoch [48/50] - Batch loss: 162.6881 - Epoch Loss: 13849.1877 - Avg Loss: 162.9316\n",
            "Epoch [48/50] - Batch loss: 157.4499 - Epoch Loss: 14006.6376 - Avg Loss: 162.8679\n",
            "Epoch [48/50] - Batch loss: 170.2226 - Epoch Loss: 14176.8602 - Avg Loss: 162.9524\n",
            "Epoch [48/50] - Batch loss: 164.9812 - Epoch Loss: 14341.8414 - Avg Loss: 162.9755\n",
            "Epoch [48/50] - Batch loss: 158.7184 - Epoch Loss: 14500.5598 - Avg Loss: 162.9276\n",
            "Epoch [48/50] - Batch loss: 153.3181 - Epoch Loss: 14653.8779 - Avg Loss: 162.8209\n",
            "Epoch [48/50] - Batch loss: 168.9336 - Epoch Loss: 14822.8115 - Avg Loss: 162.8880\n",
            "Epoch [48/50] - Batch loss: 164.1096 - Epoch Loss: 14986.9211 - Avg Loss: 162.9013\n",
            "Epoch [48/50] - Batch loss: 161.7450 - Epoch Loss: 15148.6661 - Avg Loss: 162.8889\n",
            "Epoch [48/50] - Batch loss: 167.1933 - Epoch Loss: 15315.8594 - Avg Loss: 162.9347\n",
            "Epoch [48/50] - Batch loss: 165.1167 - Epoch Loss: 15480.9761 - Avg Loss: 162.9576\n",
            "Epoch [48/50] - Batch loss: 165.4950 - Epoch Loss: 15646.4711 - Avg Loss: 162.9841\n",
            "Epoch [48/50] - Batch loss: 161.5706 - Epoch Loss: 15808.0417 - Avg Loss: 162.9695\n",
            "Epoch [48/50] - Batch loss: 159.3384 - Epoch Loss: 15967.3802 - Avg Loss: 162.9325\n",
            "Epoch [48/50] - Batch loss: 166.4668 - Epoch Loss: 16133.8469 - Avg Loss: 162.9682\n",
            "Epoch [48/50] - Batch loss: 164.2996 - Epoch Loss: 16298.1465 - Avg Loss: 162.9815\n",
            "Epoch [48/50] - Batch loss: 169.9798 - Epoch Loss: 16468.1263 - Avg Loss: 163.0508\n",
            "Epoch [48/50] - Batch loss: 162.7222 - Epoch Loss: 16630.8485 - Avg Loss: 163.0475\n",
            "Epoch [48/50] - Batch loss: 168.2725 - Epoch Loss: 16799.1211 - Avg Loss: 163.0983\n",
            "Epoch [48/50] - Batch loss: 163.0165 - Epoch Loss: 16962.1376 - Avg Loss: 163.0975\n",
            "Epoch [48/50] - Batch loss: 159.9792 - Epoch Loss: 17122.1168 - Avg Loss: 163.0678\n",
            "Epoch [48/50] - Batch loss: 160.6242 - Epoch Loss: 17282.7410 - Avg Loss: 163.0447\n",
            "Epoch [48/50] - Batch loss: 171.8848 - Epoch Loss: 17454.6258 - Avg Loss: 163.1273\n",
            "Epoch [48/50] - Batch loss: 153.2788 - Epoch Loss: 17607.9046 - Avg Loss: 163.0362\n",
            "Epoch [48/50] - Batch loss: 167.0159 - Epoch Loss: 17774.9205 - Avg Loss: 163.0727\n",
            "Epoch [48/50] - Batch loss: 159.6589 - Epoch Loss: 17934.5794 - Avg Loss: 163.0416\n",
            "Epoch [48/50] - Batch loss: 168.8143 - Epoch Loss: 18103.3937 - Avg Loss: 163.0936\n",
            "Epoch [48/50] - Batch loss: 167.6013 - Epoch Loss: 18270.9950 - Avg Loss: 163.1339\n",
            "Epoch [48/50] - Batch loss: 166.5886 - Epoch Loss: 18437.5836 - Avg Loss: 163.1645\n",
            "Epoch [48/50] - Batch loss: 163.2537 - Epoch Loss: 18600.8372 - Avg Loss: 163.1652\n",
            "Epoch [48/50] - Batch loss: 167.0274 - Epoch Loss: 18767.8647 - Avg Loss: 163.1988\n",
            "Epoch [48/50] - Batch loss: 162.2670 - Epoch Loss: 18930.1317 - Avg Loss: 163.1908\n",
            "Epoch [48/50] - Batch loss: 159.8730 - Epoch Loss: 19090.0047 - Avg Loss: 163.1624\n",
            "Epoch [48/50] - Batch loss: 167.9006 - Epoch Loss: 19257.9053 - Avg Loss: 163.2026\n",
            "Epoch [48/50] - Batch loss: 161.6749 - Epoch Loss: 19419.5802 - Avg Loss: 163.1897\n",
            "Epoch [48/50] - Batch loss: 164.6928 - Epoch Loss: 19584.2730 - Avg Loss: 163.2023\n",
            "Epoch [48/50] - Batch loss: 162.5189 - Epoch Loss: 19746.7919 - Avg Loss: 163.1966\n",
            "Epoch [48/50] - Batch loss: 166.3917 - Epoch Loss: 19913.1836 - Avg Loss: 163.2228\n",
            "Epoch [48/50] - Batch loss: 160.7443 - Epoch Loss: 20073.9279 - Avg Loss: 163.2027\n",
            "Epoch [48/50] - Batch loss: 161.7902 - Epoch Loss: 20235.7181 - Avg Loss: 163.1913\n",
            "Epoch [48/50] - Batch loss: 171.3852 - Epoch Loss: 20407.1032 - Avg Loss: 163.2568\n",
            "Epoch [48/50] - Batch loss: 162.4943 - Epoch Loss: 20569.5976 - Avg Loss: 163.2508\n",
            "Epoch [48/50] - Batch loss: 159.3213 - Epoch Loss: 20728.9189 - Avg Loss: 163.2198\n",
            "Epoch [48/50] - Batch loss: 169.9457 - Epoch Loss: 20898.8646 - Avg Loss: 163.2724\n",
            "Epoch [48/50] - Batch loss: 161.7778 - Epoch Loss: 21060.6424 - Avg Loss: 163.2608\n",
            "Epoch [48/50] - Batch loss: 164.9644 - Epoch Loss: 21225.6069 - Avg Loss: 163.2739\n",
            "Epoch [48/50] - Batch loss: 155.4907 - Epoch Loss: 21381.0976 - Avg Loss: 163.2145\n",
            "Epoch [48/50] - Batch loss: 166.3268 - Epoch Loss: 21547.4243 - Avg Loss: 163.2381\n",
            "Epoch [48/50] - Batch loss: 180.9557 - Epoch Loss: 21728.3801 - Avg Loss: 163.3713\n",
            "Epoch [48/50] - Batch loss: 164.2369 - Epoch Loss: 21892.6170 - Avg Loss: 163.3777\n",
            "Epoch [48/50] - Batch loss: 167.4191 - Epoch Loss: 22060.0360 - Avg Loss: 163.4077\n",
            "Epoch [48/50] - Batch loss: 161.4652 - Epoch Loss: 22221.5013 - Avg Loss: 163.3934\n",
            "Epoch [48/50] - Batch loss: 158.5057 - Epoch Loss: 22380.0070 - Avg Loss: 163.3577\n",
            "Epoch [48/50] - Batch loss: 162.0849 - Epoch Loss: 22542.0919 - Avg Loss: 163.3485\n",
            "Epoch [48/50] - Batch loss: 167.9725 - Epoch Loss: 22710.0644 - Avg Loss: 163.3818\n",
            "Epoch [48/50] - Batch loss: 151.1089 - Epoch Loss: 22861.1733 - Avg Loss: 163.2941\n",
            "Epoch [48/50] - Batch loss: 160.7391 - Epoch Loss: 23021.9124 - Avg Loss: 163.2760\n",
            "Epoch [48/50] - Batch loss: 164.8169 - Epoch Loss: 23186.7294 - Avg Loss: 163.2868\n",
            "Epoch [48/50] - Batch loss: 168.7572 - Epoch Loss: 23355.4866 - Avg Loss: 163.3251\n",
            "Epoch [48/50] - Batch loss: 160.6550 - Epoch Loss: 23516.1416 - Avg Loss: 163.3065\n",
            "Epoch [48/50] - Batch loss: 159.8685 - Epoch Loss: 23676.0100 - Avg Loss: 163.2828\n",
            "Epoch [48/50] - Batch loss: 166.9493 - Epoch Loss: 23842.9593 - Avg Loss: 163.3079\n",
            "Epoch [48/50] - Batch loss: 162.7076 - Epoch Loss: 24005.6669 - Avg Loss: 163.3039\n",
            "Epoch [48/50] - Batch loss: 163.9002 - Epoch Loss: 24169.5671 - Avg Loss: 163.3079\n",
            "Epoch [48/50] - Batch loss: 171.8255 - Epoch Loss: 24341.3926 - Avg Loss: 163.3651\n",
            "Epoch [48/50] - Batch loss: 158.0436 - Epoch Loss: 24499.4362 - Avg Loss: 163.3296\n",
            "Epoch [48/50] - Batch loss: 162.9595 - Epoch Loss: 24662.3957 - Avg Loss: 163.3271\n",
            "Epoch [48/50] - Batch loss: 164.3214 - Epoch Loss: 24826.7171 - Avg Loss: 163.3337\n",
            "Epoch [48/50] - Batch loss: 166.9437 - Epoch Loss: 24993.6608 - Avg Loss: 163.3573\n",
            "Epoch [48/50] - Batch loss: 165.9904 - Epoch Loss: 25159.6512 - Avg Loss: 163.3744\n",
            "Epoch [48/50] - Batch loss: 163.5102 - Epoch Loss: 25323.1614 - Avg Loss: 163.3752\n",
            "Epoch [48/50] - Batch loss: 164.4178 - Epoch Loss: 25487.5792 - Avg Loss: 163.3819\n",
            "Epoch [48/50] - Batch loss: 168.9555 - Epoch Loss: 25656.5347 - Avg Loss: 163.4174\n",
            "Epoch [48/50] - Batch loss: 168.4533 - Epoch Loss: 25824.9880 - Avg Loss: 163.4493\n",
            "Epoch [48/50] - Batch loss: 162.7444 - Epoch Loss: 25987.7324 - Avg Loss: 163.4449\n",
            "Epoch [48/50] - Batch loss: 160.2610 - Epoch Loss: 26147.9934 - Avg Loss: 163.4250\n",
            "Epoch [48/50] - Batch loss: 160.5449 - Epoch Loss: 26308.5383 - Avg Loss: 163.4071\n",
            "Epoch [48/50] - Batch loss: 162.2306 - Epoch Loss: 26470.7689 - Avg Loss: 163.3998\n",
            "Epoch [48/50] - Batch loss: 180.2878 - Epoch Loss: 26651.0567 - Avg Loss: 163.5034\n",
            "Epoch [48/50] - Batch loss: 164.6541 - Epoch Loss: 26815.7108 - Avg Loss: 163.5104\n",
            "Epoch [48/50] - Batch loss: 157.6658 - Epoch Loss: 26973.3767 - Avg Loss: 163.4750\n",
            "Epoch [48/50] - Batch loss: 165.5521 - Epoch Loss: 27138.9288 - Avg Loss: 163.4875\n",
            "Epoch [48/50] - Batch loss: 164.5884 - Epoch Loss: 27303.5171 - Avg Loss: 163.4941\n",
            "Epoch [48/50] - Batch loss: 157.4992 - Epoch Loss: 27461.0163 - Avg Loss: 163.4584\n",
            "Epoch [48/50] - Batch loss: 158.5741 - Epoch Loss: 27619.5904 - Avg Loss: 163.4295\n",
            "Epoch [48/50] - Batch loss: 166.7316 - Epoch Loss: 27786.3221 - Avg Loss: 163.4490\n",
            "Epoch [48/50] - Batch loss: 170.7829 - Epoch Loss: 27957.1050 - Avg Loss: 163.4918\n",
            "Epoch [48/50] - Batch loss: 158.0509 - Epoch Loss: 28115.1560 - Avg Loss: 163.4602\n",
            "Epoch [48/50] - Batch loss: 162.5449 - Epoch Loss: 28277.7008 - Avg Loss: 163.4549\n",
            "Epoch [48/50] - Batch loss: 167.4551 - Epoch Loss: 28445.1560 - Avg Loss: 163.4779\n",
            "Epoch [48/50] - Batch loss: 164.9113 - Epoch Loss: 28610.0672 - Avg Loss: 163.4861\n",
            "Epoch [48/50] - Batch loss: 165.8555 - Epoch Loss: 28775.9228 - Avg Loss: 163.4996\n",
            "Epoch [48/50] - Batch loss: 162.8352 - Epoch Loss: 28938.7579 - Avg Loss: 163.4958\n",
            "Epoch [48/50] - Batch loss: 160.3567 - Epoch Loss: 29099.1146 - Avg Loss: 163.4782\n",
            "Epoch [48/50] - Batch loss: 172.2340 - Epoch Loss: 29271.3486 - Avg Loss: 163.5271\n",
            "Epoch [48/50] - Batch loss: 158.7459 - Epoch Loss: 29430.0945 - Avg Loss: 163.5005\n",
            "Epoch [48/50] - Batch loss: 168.4856 - Epoch Loss: 29598.5801 - Avg Loss: 163.5281\n",
            "Epoch [48/50] - Batch loss: 165.2836 - Epoch Loss: 29763.8637 - Avg Loss: 163.5377\n",
            "Epoch [48/50] - Batch loss: 167.4252 - Epoch Loss: 29931.2888 - Avg Loss: 163.5590\n",
            "Epoch [48/50] - Batch loss: 166.0599 - Epoch Loss: 30097.3488 - Avg Loss: 163.5725\n",
            "Epoch [48/50] - Batch loss: 166.3950 - Epoch Loss: 30263.7438 - Avg Loss: 163.5878\n",
            "Epoch [48/50] - Batch loss: 161.1680 - Epoch Loss: 30424.9118 - Avg Loss: 163.5748\n",
            "Epoch [48/50] - Batch loss: 164.1705 - Epoch Loss: 30589.0823 - Avg Loss: 163.5780\n",
            "Epoch [48/50] - Batch loss: 163.7458 - Epoch Loss: 30752.8281 - Avg Loss: 163.5789\n",
            "Epoch [48/50] - Batch loss: 171.2795 - Epoch Loss: 30924.1076 - Avg Loss: 163.6196\n",
            "Epoch [48/50] - Batch loss: 173.7672 - Epoch Loss: 31097.8748 - Avg Loss: 163.6730\n",
            "Epoch [48/50] - Batch loss: 165.5132 - Epoch Loss: 31263.3880 - Avg Loss: 163.6827\n",
            "Epoch [48/50] - Batch loss: 155.5883 - Epoch Loss: 31418.9763 - Avg Loss: 163.6405\n",
            "Epoch [48/50] - Batch loss: 171.7132 - Epoch Loss: 31590.6895 - Avg Loss: 163.6823\n",
            "Epoch [48/50] - Batch loss: 163.5685 - Epoch Loss: 31754.2580 - Avg Loss: 163.6817\n",
            "Epoch [48/50] - Batch loss: 165.7595 - Epoch Loss: 31920.0176 - Avg Loss: 163.6924\n",
            "Epoch [48/50] - Batch loss: 170.8135 - Epoch Loss: 32090.8310 - Avg Loss: 163.7287\n",
            "Epoch [48/50] - Batch loss: 163.3497 - Epoch Loss: 32254.1808 - Avg Loss: 163.7268\n",
            "Epoch [48/50] - Batch loss: 159.8945 - Epoch Loss: 32414.0752 - Avg Loss: 163.7075\n",
            "Epoch [48/50] - Batch loss: 169.5596 - Epoch Loss: 32583.6348 - Avg Loss: 163.7369\n",
            "Epoch [48/50] - Batch loss: 162.6375 - Epoch Loss: 32746.2723 - Avg Loss: 163.7314\n",
            "Epoch [48/50] - Batch loss: 170.6870 - Epoch Loss: 32916.9593 - Avg Loss: 163.7660\n",
            "Epoch [48/50] - Batch loss: 174.5520 - Epoch Loss: 33091.5113 - Avg Loss: 163.8194\n",
            "Epoch [48/50] - Batch loss: 168.9183 - Epoch Loss: 33260.4296 - Avg Loss: 163.8445\n",
            "Epoch [48/50] - Batch loss: 169.0014 - Epoch Loss: 33429.4310 - Avg Loss: 163.8698\n",
            "Epoch [48/50] - Batch loss: 155.1272 - Epoch Loss: 33584.5582 - Avg Loss: 163.8271\n",
            "Epoch [48/50] - Batch loss: 172.4220 - Epoch Loss: 33756.9802 - Avg Loss: 163.8688\n",
            "Epoch [48/50] - Batch loss: 158.6976 - Epoch Loss: 33915.6779 - Avg Loss: 163.8439\n",
            "Epoch [48/50] - Batch loss: 152.7609 - Epoch Loss: 34068.4388 - Avg Loss: 163.7906\n",
            "Epoch [48/50] - Batch loss: 161.2306 - Epoch Loss: 34229.6694 - Avg Loss: 163.7783\n",
            "Epoch [48/50] - Batch loss: 171.3126 - Epoch Loss: 34400.9820 - Avg Loss: 163.8142\n",
            "Epoch [48/50] - Batch loss: 156.4251 - Epoch Loss: 34557.4072 - Avg Loss: 163.7792\n",
            "Epoch [48/50] - Batch loss: 170.4890 - Epoch Loss: 34727.8962 - Avg Loss: 163.8108\n",
            "Epoch [48/50] - Batch loss: 158.5125 - Epoch Loss: 34886.4086 - Avg Loss: 163.7860\n",
            "Epoch [48/50] - Batch loss: 161.2515 - Epoch Loss: 35047.6601 - Avg Loss: 163.7741\n",
            "Epoch [48/50] - Batch loss: 168.4363 - Epoch Loss: 35216.0964 - Avg Loss: 163.7958\n",
            "Epoch [48/50] - Batch loss: 167.8457 - Epoch Loss: 35383.9421 - Avg Loss: 163.8145\n",
            "Epoch [48/50] - Batch loss: 167.5628 - Epoch Loss: 35551.5050 - Avg Loss: 163.8318\n",
            "Epoch [48/50] - Batch loss: 164.6897 - Epoch Loss: 35716.1947 - Avg Loss: 163.8358\n",
            "Epoch [48/50] - Batch loss: 159.3270 - Epoch Loss: 35875.5217 - Avg Loss: 163.8152\n",
            "Epoch [48/50] - Batch loss: 168.8490 - Epoch Loss: 36044.3707 - Avg Loss: 163.8380\n",
            "Epoch [48/50] - Batch loss: 156.5692 - Epoch Loss: 36200.9398 - Avg Loss: 163.8052\n",
            "Epoch [48/50] - Batch loss: 167.6991 - Epoch Loss: 36368.6390 - Avg Loss: 163.8227\n",
            "Epoch [48/50] - Batch loss: 163.9416 - Epoch Loss: 36532.5806 - Avg Loss: 163.8232\n",
            "Epoch [48/50] - Batch loss: 162.4488 - Epoch Loss: 36695.0294 - Avg Loss: 163.8171\n",
            "Epoch [48/50] - Batch loss: 166.1534 - Epoch Loss: 36861.1827 - Avg Loss: 163.8275\n",
            "Epoch [48/50] - Batch loss: 159.8523 - Epoch Loss: 37021.0350 - Avg Loss: 163.8099\n",
            "Epoch [48/50] - Batch loss: 161.8658 - Epoch Loss: 37182.9008 - Avg Loss: 163.8013\n",
            "Epoch [48/50] - Batch loss: 162.0661 - Epoch Loss: 37344.9669 - Avg Loss: 163.7937\n",
            "Epoch [48/50] - Batch loss: 168.6252 - Epoch Loss: 37513.5921 - Avg Loss: 163.8148\n",
            "Epoch [48/50] - Batch loss: 164.4994 - Epoch Loss: 37678.0915 - Avg Loss: 163.8178\n",
            "Epoch [48/50] - Batch loss: 166.0568 - Epoch Loss: 37844.1483 - Avg Loss: 163.8275\n",
            "Epoch [48/50] - Batch loss: 159.0050 - Epoch Loss: 38003.1533 - Avg Loss: 163.8067\n",
            "Epoch [48/50] - Batch loss: 163.0198 - Epoch Loss: 38166.1731 - Avg Loss: 163.8033\n",
            "Epoch [48/50] - Batch loss: 168.3995 - Epoch Loss: 38334.5726 - Avg Loss: 163.8230\n",
            "Epoch [48/50] - Batch loss: 158.9523 - Epoch Loss: 38493.5249 - Avg Loss: 163.8022\n",
            "Epoch [48/50] - Batch loss: 163.3465 - Epoch Loss: 38656.8714 - Avg Loss: 163.8003\n",
            "Epoch [48/50] - Batch loss: 164.1875 - Epoch Loss: 38821.0589 - Avg Loss: 163.8019\n",
            "Epoch [48/50] - Batch loss: 169.2217 - Epoch Loss: 38990.2806 - Avg Loss: 163.8247\n",
            "Epoch [48/50] - Batch loss: 159.1633 - Epoch Loss: 39149.4439 - Avg Loss: 163.8052\n",
            "Epoch [48/50] - Batch loss: 163.4623 - Epoch Loss: 39312.9062 - Avg Loss: 163.8038\n",
            "Epoch [48/50] - Batch loss: 171.2224 - Epoch Loss: 39484.1286 - Avg Loss: 163.8346\n",
            "Epoch [48/50] - Batch loss: 161.1750 - Epoch Loss: 39645.3036 - Avg Loss: 163.8236\n",
            "Epoch [48/50] - Batch loss: 157.3713 - Epoch Loss: 39802.6749 - Avg Loss: 163.7970\n",
            "Epoch [48/50] - Batch loss: 161.0279 - Epoch Loss: 39963.7028 - Avg Loss: 163.7857\n",
            "Epoch [48/50] - Batch loss: 164.0326 - Epoch Loss: 40127.7354 - Avg Loss: 163.7867\n",
            "Epoch [48/50] - Batch loss: 169.8469 - Epoch Loss: 40297.5824 - Avg Loss: 163.8113\n",
            "Epoch [48/50] - Batch loss: 164.5965 - Epoch Loss: 40462.1789 - Avg Loss: 163.8145\n",
            "Epoch [48/50] - Batch loss: 165.1576 - Epoch Loss: 40627.3365 - Avg Loss: 163.8199\n",
            "Epoch [48/50] - Batch loss: 164.4072 - Epoch Loss: 40791.7437 - Avg Loss: 163.8223\n",
            "Epoch [48/50] - Batch loss: 157.9735 - Epoch Loss: 40949.7172 - Avg Loss: 163.7989\n",
            "Epoch [48/50] - Batch loss: 159.9940 - Epoch Loss: 41109.7112 - Avg Loss: 163.7837\n",
            "Epoch [48/50] - Batch loss: 153.5921 - Epoch Loss: 41263.3032 - Avg Loss: 163.7433\n",
            "Epoch [48/50] - Batch loss: 156.4828 - Epoch Loss: 41419.7861 - Avg Loss: 163.7146\n",
            "Epoch [48/50] - Batch loss: 161.1448 - Epoch Loss: 41580.9308 - Avg Loss: 163.7045\n",
            "Epoch [48/50] - Batch loss: 155.7708 - Epoch Loss: 41736.7016 - Avg Loss: 163.6733\n",
            "Epoch [48/50] - Batch loss: 157.2621 - Epoch Loss: 41893.9637 - Avg Loss: 163.6483\n",
            "Epoch [48/50] - Batch loss: 162.9352 - Epoch Loss: 42056.8989 - Avg Loss: 163.6455\n",
            "Epoch [48/50] - Batch loss: 160.3098 - Epoch Loss: 42217.2087 - Avg Loss: 163.6326\n",
            "Epoch [48/50] - Batch loss: 170.0008 - Epoch Loss: 42387.2094 - Avg Loss: 163.6572\n",
            "Epoch [48/50] - Batch loss: 154.4738 - Epoch Loss: 42541.6832 - Avg Loss: 163.6219\n",
            "Epoch [48/50] - Batch loss: 160.8447 - Epoch Loss: 42702.5279 - Avg Loss: 163.6112\n",
            "Epoch [48/50] - Batch loss: 162.7015 - Epoch Loss: 42865.2294 - Avg Loss: 163.6077\n",
            "Epoch [48/50] - Batch loss: 147.0879 - Epoch Loss: 43012.3173 - Avg Loss: 163.5449\n",
            "Epoch [48/50] - Batch loss: 160.1210 - Epoch Loss: 43172.4382 - Avg Loss: 163.5320\n",
            "Epoch [48/50] - Batch loss: 162.3464 - Epoch Loss: 43334.7847 - Avg Loss: 163.5275\n",
            "Epoch [48/50] - Batch loss: 152.7979 - Epoch Loss: 43487.5825 - Avg Loss: 163.4872\n",
            "Epoch [48/50] - Batch loss: 153.8466 - Epoch Loss: 43641.4291 - Avg Loss: 163.4510\n",
            "Epoch [48/50] - Batch loss: 157.5995 - Epoch Loss: 43799.0286 - Avg Loss: 163.4292\n",
            "Epoch [48/50] - Batch loss: 162.2465 - Epoch Loss: 43961.2751 - Avg Loss: 163.4248\n",
            "Epoch [48/50] - Batch loss: 156.6394 - Epoch Loss: 44117.9145 - Avg Loss: 163.3997\n",
            "Epoch [48/50] - Batch loss: 160.4772 - Epoch Loss: 44278.3916 - Avg Loss: 163.3889\n",
            "Epoch [48/50] - Batch loss: 160.8008 - Epoch Loss: 44439.1925 - Avg Loss: 163.3794\n",
            "Epoch [48/50] - Batch loss: 167.4597 - Epoch Loss: 44606.6522 - Avg Loss: 163.3943\n",
            "Epoch [48/50] - Batch loss: 155.2661 - Epoch Loss: 44761.9183 - Avg Loss: 163.3647\n",
            "Epoch [48/50] - Batch loss: 169.9992 - Epoch Loss: 44931.9175 - Avg Loss: 163.3888\n",
            "Epoch [48/50] - Batch loss: 161.5761 - Epoch Loss: 45093.4936 - Avg Loss: 163.3822\n",
            "Epoch [48/50] - Batch loss: 152.2477 - Epoch Loss: 45245.7412 - Avg Loss: 163.3420\n",
            "Epoch [48/50] - Batch loss: 157.3788 - Epoch Loss: 45403.1200 - Avg Loss: 163.3206\n",
            "Epoch [48/50] - Batch loss: 158.5862 - Epoch Loss: 45561.7062 - Avg Loss: 163.3036\n",
            "Epoch [48/50] - Batch loss: 156.0802 - Epoch Loss: 45717.7864 - Avg Loss: 163.2778\n",
            "Epoch [48/50] - Batch loss: 162.2982 - Epoch Loss: 45880.0846 - Avg Loss: 163.2743\n",
            "Epoch [48/50] - Batch loss: 157.5979 - Epoch Loss: 46037.6825 - Avg Loss: 163.2542\n",
            "Epoch [48/50] - Batch loss: 159.5771 - Epoch Loss: 46197.2596 - Avg Loss: 163.2412\n",
            "Epoch [48/50] - Batch loss: 154.7086 - Epoch Loss: 46351.9682 - Avg Loss: 163.2112\n",
            "Epoch [48/50] - Batch loss: 162.7150 - Epoch Loss: 46514.6832 - Avg Loss: 163.2094\n",
            "Epoch [48/50] - Batch loss: 159.5756 - Epoch Loss: 46674.2588 - Avg Loss: 163.1967\n",
            "Epoch [48/50] - Batch loss: 165.6484 - Epoch Loss: 46839.9072 - Avg Loss: 163.2053\n",
            "Epoch [48/50] - Batch loss: 161.7627 - Epoch Loss: 47001.6699 - Avg Loss: 163.2002\n",
            "Epoch [48/50] - Batch loss: 157.7103 - Epoch Loss: 47159.3802 - Avg Loss: 163.1812\n",
            "Epoch [48/50] - Batch loss: 155.7184 - Epoch Loss: 47315.0987 - Avg Loss: 163.1555\n",
            "Epoch [48/50] - Batch loss: 152.1525 - Epoch Loss: 47467.2512 - Avg Loss: 163.1177\n",
            "Epoch [48/50] - Batch loss: 163.3117 - Epoch Loss: 47630.5629 - Avg Loss: 163.1184\n",
            "Epoch [48/50] - Batch loss: 164.3300 - Epoch Loss: 47794.8930 - Avg Loss: 163.1225\n",
            "Epoch [48/50] - Batch loss: 162.5032 - Epoch Loss: 47957.3962 - Avg Loss: 163.1204\n",
            "Epoch [48/50] - Batch loss: 154.2566 - Epoch Loss: 48111.6528 - Avg Loss: 163.0903\n",
            "Epoch [48/50] - Batch loss: 161.8340 - Epoch Loss: 48273.4868 - Avg Loss: 163.0861\n",
            "Epoch [48/50] - Batch loss: 157.3949 - Epoch Loss: 48430.8817 - Avg Loss: 163.0669\n",
            "Epoch [48/50] - Batch loss: 164.9228 - Epoch Loss: 48595.8045 - Avg Loss: 163.0732\n",
            "Epoch [48/50] - Batch loss: 159.2747 - Epoch Loss: 48755.0792 - Avg Loss: 163.0605\n",
            "Epoch [48/50] - Batch loss: 153.7959 - Epoch Loss: 48908.8751 - Avg Loss: 163.0296\n",
            "Epoch [48/50] - Batch loss: 154.3261 - Epoch Loss: 49063.2012 - Avg Loss: 163.0007\n",
            "Epoch [48/50] - Batch loss: 165.4346 - Epoch Loss: 49228.6357 - Avg Loss: 163.0087\n",
            "Epoch [48/50] - Batch loss: 166.2130 - Epoch Loss: 49394.8488 - Avg Loss: 163.0193\n",
            "Epoch [48/50] - Batch loss: 158.7997 - Epoch Loss: 49553.6485 - Avg Loss: 163.0054\n",
            "Epoch [48/50] - Batch loss: 164.5167 - Epoch Loss: 49718.1652 - Avg Loss: 163.0104\n",
            "Epoch [48/50] - Batch loss: 165.9427 - Epoch Loss: 49884.1079 - Avg Loss: 163.0200\n",
            "Epoch [48/50] - Batch loss: 156.8636 - Epoch Loss: 50040.9716 - Avg Loss: 162.9999\n",
            "Epoch [48/50] - Batch loss: 159.8861 - Epoch Loss: 50200.8577 - Avg Loss: 162.9898\n",
            "Epoch [48/50] - Batch loss: 164.6479 - Epoch Loss: 50365.5056 - Avg Loss: 162.9952\n",
            "Epoch [48/50] - Batch loss: 166.3824 - Epoch Loss: 50531.8880 - Avg Loss: 163.0061\n",
            "Epoch [48/50] - Batch loss: 160.4341 - Epoch Loss: 50692.3220 - Avg Loss: 162.9978\n",
            "Epoch [48/50] - Batch loss: 168.3059 - Epoch Loss: 50860.6279 - Avg Loss: 163.0148\n",
            "Epoch [48/50] - Batch loss: 162.9754 - Epoch Loss: 51023.6034 - Avg Loss: 163.0147\n",
            "Epoch [48/50] - Batch loss: 164.5876 - Epoch Loss: 51188.1910 - Avg Loss: 163.0197\n",
            "Epoch [48/50] - Batch loss: 156.7968 - Epoch Loss: 51344.9878 - Avg Loss: 163.0000\n",
            "Epoch [48/50] - Batch loss: 162.1278 - Epoch Loss: 51507.1155 - Avg Loss: 162.9972\n",
            "Epoch [48/50] - Batch loss: 157.8558 - Epoch Loss: 51664.9713 - Avg Loss: 162.9810\n",
            "Epoch [48/50] - Batch loss: 163.9332 - Epoch Loss: 51828.9045 - Avg Loss: 162.9840\n",
            "Epoch [48/50] - Batch loss: 154.2306 - Epoch Loss: 51983.1351 - Avg Loss: 162.9565\n",
            "Epoch [48/50] - Batch loss: 163.1211 - Epoch Loss: 52146.2562 - Avg Loss: 162.9571\n",
            "Epoch [48/50] - Batch loss: 158.7817 - Epoch Loss: 52305.0379 - Avg Loss: 162.9440\n",
            "Epoch [48/50] - Batch loss: 164.9635 - Epoch Loss: 52470.0014 - Avg Loss: 162.9503\n",
            "Epoch [48/50] - Batch loss: 161.3397 - Epoch Loss: 52631.3411 - Avg Loss: 162.9453\n",
            "Epoch [48/50] - Batch loss: 166.3014 - Epoch Loss: 52797.6425 - Avg Loss: 162.9557\n",
            "Epoch [48/50] - Batch loss: 154.6525 - Epoch Loss: 52952.2950 - Avg Loss: 162.9301\n",
            "Epoch [48/50] - Batch loss: 162.9246 - Epoch Loss: 53115.2196 - Avg Loss: 162.9301\n",
            "Epoch [48/50] - Batch loss: 164.2216 - Epoch Loss: 53279.4413 - Avg Loss: 162.9341\n",
            "Epoch [48/50] - Batch loss: 161.0671 - Epoch Loss: 53440.5083 - Avg Loss: 162.9284\n",
            "Epoch [48/50] - Batch loss: 171.9906 - Epoch Loss: 53612.4989 - Avg Loss: 162.9559\n",
            "Epoch [48/50] - Batch loss: 162.4207 - Epoch Loss: 53774.9196 - Avg Loss: 162.9543\n",
            "Epoch [48/50] - Batch loss: 166.6728 - Epoch Loss: 53941.5924 - Avg Loss: 162.9655\n",
            "Epoch [48/50] - Batch loss: 153.8717 - Epoch Loss: 54095.4641 - Avg Loss: 162.9381\n",
            "Epoch [48/50] - Batch loss: 163.2079 - Epoch Loss: 54258.6720 - Avg Loss: 162.9390\n",
            "Epoch [48/50] - Batch loss: 159.5384 - Epoch Loss: 54418.2104 - Avg Loss: 162.9288\n",
            "Epoch [48/50] - Batch loss: 161.5322 - Epoch Loss: 54579.7426 - Avg Loss: 162.9246\n",
            "Epoch [48/50] - Batch loss: 164.4157 - Epoch Loss: 54744.1582 - Avg Loss: 162.9290\n",
            "Epoch [48/50] - Batch loss: 156.4116 - Epoch Loss: 54900.5699 - Avg Loss: 162.9097\n",
            "Epoch [48/50] - Batch loss: 162.8165 - Epoch Loss: 55063.3864 - Avg Loss: 162.9094\n",
            "Epoch [48/50] - Batch loss: 153.1571 - Epoch Loss: 55216.5435 - Avg Loss: 162.8807\n",
            "Epoch [48/50] - Batch loss: 165.3446 - Epoch Loss: 55381.8881 - Avg Loss: 162.8879\n",
            "Epoch [48/50] - Batch loss: 168.2010 - Epoch Loss: 55550.0891 - Avg Loss: 162.9035\n",
            "Epoch [48/50] - Batch loss: 158.8599 - Epoch Loss: 55708.9490 - Avg Loss: 162.8917\n",
            "Epoch [48/50] - Batch loss: 165.3185 - Epoch Loss: 55874.2675 - Avg Loss: 162.8987\n",
            "Epoch [48/50] - Batch loss: 160.1647 - Epoch Loss: 56034.4322 - Avg Loss: 162.8908\n",
            "Epoch [48/50] - Batch loss: 154.4039 - Epoch Loss: 56188.8361 - Avg Loss: 162.8662\n",
            "Epoch [48/50] - Batch loss: 166.1523 - Epoch Loss: 56354.9884 - Avg Loss: 162.8757\n",
            "Epoch [48/50] - Batch loss: 159.6967 - Epoch Loss: 56514.6852 - Avg Loss: 162.8665\n",
            "Epoch [48/50] - Batch loss: 160.3627 - Epoch Loss: 56675.0479 - Avg Loss: 162.8593\n",
            "Epoch [48/50] - Batch loss: 156.8333 - Epoch Loss: 56831.8812 - Avg Loss: 162.8421\n",
            "Epoch [48/50] - Batch loss: 160.8382 - Epoch Loss: 56992.7194 - Avg Loss: 162.8363\n",
            "Epoch [48/50] - Batch loss: 168.7287 - Epoch Loss: 57161.4482 - Avg Loss: 162.8531\n",
            "Epoch [48/50] - Batch loss: 157.7126 - Epoch Loss: 57319.1607 - Avg Loss: 162.8385\n",
            "Epoch [48/50] - Batch loss: 156.5321 - Epoch Loss: 57475.6928 - Avg Loss: 162.8207\n",
            "Epoch [48/50] - Batch loss: 166.3275 - Epoch Loss: 57642.0203 - Avg Loss: 162.8306\n",
            "Epoch [48/50] - Batch loss: 159.6496 - Epoch Loss: 57801.6699 - Avg Loss: 162.8216\n",
            "Epoch [48/50] - Batch loss: 160.7919 - Epoch Loss: 57962.4618 - Avg Loss: 162.8159\n",
            "Epoch [48/50] - Batch loss: 165.2701 - Epoch Loss: 58127.7319 - Avg Loss: 162.8228\n",
            "Epoch [48/50] - Batch loss: 155.6973 - Epoch Loss: 58283.4292 - Avg Loss: 162.8029\n",
            "Epoch [48/50] - Batch loss: 168.8525 - Epoch Loss: 58452.2816 - Avg Loss: 162.8197\n",
            "Epoch [48/50] - Batch loss: 161.9303 - Epoch Loss: 58614.2119 - Avg Loss: 162.8173\n",
            "Epoch [48/50] - Batch loss: 161.7004 - Epoch Loss: 58775.9123 - Avg Loss: 162.8142\n",
            "Epoch [48/50] - Batch loss: 153.0094 - Epoch Loss: 58928.9217 - Avg Loss: 162.7871\n",
            "Epoch [48/50] - Batch loss: 159.9688 - Epoch Loss: 59088.8905 - Avg Loss: 162.7793\n",
            "Epoch [48/50] - Batch loss: 160.3844 - Epoch Loss: 59249.2749 - Avg Loss: 162.7727\n",
            "Epoch [48/50] - Batch loss: 161.0770 - Epoch Loss: 59410.3520 - Avg Loss: 162.7681\n",
            "Epoch [48/50] - Batch loss: 164.8901 - Epoch Loss: 59575.2421 - Avg Loss: 162.7739\n",
            "Epoch [48/50] - Batch loss: 154.7922 - Epoch Loss: 59730.0343 - Avg Loss: 162.7521\n",
            "Epoch [48/50] - Batch loss: 162.1629 - Epoch Loss: 59892.1972 - Avg Loss: 162.7505\n",
            "Epoch [48/50] - Batch loss: 164.0373 - Epoch Loss: 60056.2344 - Avg Loss: 162.7540\n",
            "Epoch [48/50] - Batch loss: 160.5742 - Epoch Loss: 60216.8086 - Avg Loss: 162.7481\n",
            "Epoch [48/50] - Batch loss: 157.7910 - Epoch Loss: 60374.5996 - Avg Loss: 162.7348\n",
            "Epoch [48/50] - Batch loss: 159.2021 - Epoch Loss: 60533.8018 - Avg Loss: 162.7253\n",
            "Epoch [48/50] - Batch loss: 162.9429 - Epoch Loss: 60696.7447 - Avg Loss: 162.7259\n",
            "Epoch [48/50] - Batch loss: 164.9246 - Epoch Loss: 60861.6693 - Avg Loss: 162.7317\n",
            "Epoch [48/50] - Batch loss: 172.7684 - Epoch Loss: 61034.4377 - Avg Loss: 162.7585\n",
            "Epoch [48/50] - Batch loss: 156.4544 - Epoch Loss: 61190.8921 - Avg Loss: 162.7417\n",
            "Epoch [48/50] - Batch loss: 158.6055 - Epoch Loss: 61349.4976 - Avg Loss: 162.7308\n",
            "Epoch [48/50] - Batch loss: 158.5537 - Epoch Loss: 61508.0513 - Avg Loss: 162.7197\n",
            "Epoch [48/50] - Batch loss: 154.6328 - Epoch Loss: 61662.6841 - Avg Loss: 162.6984\n",
            "Epoch [48/50] - Batch loss: 165.0782 - Epoch Loss: 61827.7623 - Avg Loss: 162.7046\n",
            "Epoch [48/50] - Batch loss: 154.2484 - Epoch Loss: 61982.0106 - Avg Loss: 162.6824\n",
            "Epoch [48/50] - Batch loss: 160.9304 - Epoch Loss: 62142.9411 - Avg Loss: 162.6779\n",
            "Epoch [48/50] - Batch loss: 155.2939 - Epoch Loss: 62298.2350 - Avg Loss: 162.6586\n",
            "Epoch [48/50] - Batch loss: 171.7213 - Epoch Loss: 62469.9563 - Avg Loss: 162.6822\n",
            "Epoch [48/50] - Batch loss: 161.9264 - Epoch Loss: 62631.8826 - Avg Loss: 162.6802\n",
            "Epoch [48/50] - Batch loss: 162.0316 - Epoch Loss: 62793.9142 - Avg Loss: 162.6785\n",
            "Epoch [48/50] - Batch loss: 166.0400 - Epoch Loss: 62959.9543 - Avg Loss: 162.6872\n",
            "Epoch [48/50] - Batch loss: 156.8828 - Epoch Loss: 63116.8371 - Avg Loss: 162.6723\n",
            "Epoch [48/50] - Batch loss: 156.1203 - Epoch Loss: 63272.9573 - Avg Loss: 162.6554\n",
            "Epoch [48/50] - Batch loss: 159.7660 - Epoch Loss: 63432.7233 - Avg Loss: 162.6480\n",
            "Epoch [48/50] - Batch loss: 162.0330 - Epoch Loss: 63594.7563 - Avg Loss: 162.6464\n",
            "Epoch [48/50] - Batch loss: 152.0911 - Epoch Loss: 63746.8474 - Avg Loss: 162.6195\n",
            "Epoch [48/50] - Batch loss: 157.1878 - Epoch Loss: 63904.0352 - Avg Loss: 162.6057\n",
            "Epoch [48/50] - Batch loss: 164.7395 - Epoch Loss: 64068.7747 - Avg Loss: 162.6111\n",
            "Epoch [48/50] - Batch loss: 165.0263 - Epoch Loss: 64233.8010 - Avg Loss: 162.6172\n",
            "Epoch [48/50] - Batch loss: 159.0855 - Epoch Loss: 64392.8866 - Avg Loss: 162.6083\n",
            "Epoch [48/50] - Batch loss: 154.8921 - Epoch Loss: 64547.7787 - Avg Loss: 162.5889\n",
            "Epoch [48/50] - Batch loss: 155.1826 - Epoch Loss: 64702.9613 - Avg Loss: 162.5703\n",
            "Epoch [48/50] - Batch loss: 157.9522 - Epoch Loss: 64860.9136 - Avg Loss: 162.5587\n",
            "Epoch [48/50] - Batch loss: 161.5684 - Epoch Loss: 65022.4820 - Avg Loss: 162.5562\n",
            "Epoch [48/50] - Batch loss: 157.3642 - Epoch Loss: 65179.8462 - Avg Loss: 162.5433\n",
            "Epoch [48/50] - Batch loss: 162.6354 - Epoch Loss: 65342.4816 - Avg Loss: 162.5435\n",
            "Epoch [48/50] - Batch loss: 162.9376 - Epoch Loss: 65505.4192 - Avg Loss: 162.5445\n",
            "Epoch [48/50] - Batch loss: 159.1516 - Epoch Loss: 65664.5708 - Avg Loss: 162.5361\n",
            "Epoch [48/50] - Batch loss: 157.4077 - Epoch Loss: 65821.9786 - Avg Loss: 162.5234\n",
            "Epoch [48/50] - Batch loss: 173.2473 - Epoch Loss: 65995.2259 - Avg Loss: 162.5498\n",
            "Epoch [48/50] - Batch loss: 163.8066 - Epoch Loss: 66159.0325 - Avg Loss: 162.5529\n",
            "Epoch [48/50] - Batch loss: 154.0820 - Epoch Loss: 66313.1145 - Avg Loss: 162.5321\n",
            "Epoch [48/50] - Batch loss: 157.8659 - Epoch Loss: 66470.9803 - Avg Loss: 162.5207\n",
            "Epoch [48/50] - Batch loss: 164.9852 - Epoch Loss: 66635.9656 - Avg Loss: 162.5267\n",
            "Epoch [48/50] - Batch loss: 159.0244 - Epoch Loss: 66794.9900 - Avg Loss: 162.5182\n",
            "Epoch [48/50] - Batch loss: 159.8014 - Epoch Loss: 66954.7914 - Avg Loss: 162.5116\n",
            "Epoch [48/50] - Batch loss: 162.6309 - Epoch Loss: 67117.4223 - Avg Loss: 162.5119\n",
            "Epoch [48/50] - Batch loss: 162.3481 - Epoch Loss: 67279.7704 - Avg Loss: 162.5115\n",
            "Epoch [48/50] - Batch loss: 148.2439 - Epoch Loss: 67428.0143 - Avg Loss: 162.4771\n",
            "Epoch [48/50] - Batch loss: 160.7211 - Epoch Loss: 67588.7355 - Avg Loss: 162.4729\n",
            "Epoch [48/50] - Batch loss: 156.0725 - Epoch Loss: 67744.8080 - Avg Loss: 162.4576\n",
            "Epoch [48/50] - Batch loss: 161.9026 - Epoch Loss: 67906.7106 - Avg Loss: 162.4562\n",
            "Epoch [48/50] - Batch loss: 164.7973 - Epoch Loss: 68071.5078 - Avg Loss: 162.4618\n",
            "Epoch [48/50] - Batch loss: 160.0945 - Epoch Loss: 68231.6023 - Avg Loss: 162.4562\n",
            "Epoch [48/50] - Batch loss: 168.9201 - Epoch Loss: 68400.5224 - Avg Loss: 162.4715\n",
            "Epoch [48/50] - Batch loss: 157.4180 - Epoch Loss: 68557.9404 - Avg Loss: 162.4596\n",
            "Epoch [48/50] - Batch loss: 161.4165 - Epoch Loss: 68719.3569 - Avg Loss: 162.4571\n",
            "Epoch [48/50] - Batch loss: 165.1910 - Epoch Loss: 68884.5478 - Avg Loss: 162.4636\n",
            "Epoch [48/50] - Batch loss: 157.5226 - Epoch Loss: 69042.0704 - Avg Loss: 162.4519\n",
            "Epoch [48/50] - Batch loss: 162.3037 - Epoch Loss: 69204.3741 - Avg Loss: 162.4516\n",
            "Epoch [48/50] - Batch loss: 161.5944 - Epoch Loss: 69365.9685 - Avg Loss: 162.4496\n",
            "Epoch [48/50] - Batch loss: 161.2096 - Epoch Loss: 69527.1781 - Avg Loss: 162.4467\n",
            "Epoch [48/50] - Batch loss: 156.0648 - Epoch Loss: 69683.2429 - Avg Loss: 162.4318\n",
            "Epoch [48/50] - Batch loss: 159.2567 - Epoch Loss: 69842.4996 - Avg Loss: 162.4244\n",
            "Epoch [48/50] - Batch loss: 166.0266 - Epoch Loss: 70008.5261 - Avg Loss: 162.4328\n",
            "Epoch [48/50] - Batch loss: 156.3029 - Epoch Loss: 70164.8291 - Avg Loss: 162.4186\n",
            "Epoch [48/50] - Batch loss: 162.7381 - Epoch Loss: 70327.5672 - Avg Loss: 162.4193\n",
            "Epoch [48/50] - Batch loss: 157.4531 - Epoch Loss: 70485.0203 - Avg Loss: 162.4079\n",
            "Epoch [48/50] - Batch loss: 152.9771 - Epoch Loss: 70637.9974 - Avg Loss: 162.3862\n",
            "Epoch [48/50] - Batch loss: 158.4538 - Epoch Loss: 70796.4512 - Avg Loss: 162.3772\n",
            "Epoch [48/50] - Batch loss: 164.7328 - Epoch Loss: 70961.1840 - Avg Loss: 162.3826\n",
            "Epoch [48/50] - Batch loss: 160.5839 - Epoch Loss: 71121.7679 - Avg Loss: 162.3785\n",
            "Epoch [48/50] - Batch loss: 155.3028 - Epoch Loss: 71277.0706 - Avg Loss: 162.3623\n",
            "Epoch [48/50] - Batch loss: 169.2911 - Epoch Loss: 71446.3617 - Avg Loss: 162.3781\n",
            "Epoch [48/50] - Batch loss: 160.6307 - Epoch Loss: 71606.9924 - Avg Loss: 162.3741\n",
            "Epoch [48/50] - Batch loss: 155.8622 - Epoch Loss: 71762.8546 - Avg Loss: 162.3594\n",
            "Epoch [48/50] - Batch loss: 159.7187 - Epoch Loss: 71922.5733 - Avg Loss: 162.3534\n",
            "Epoch [48/50] - Batch loss: 165.6960 - Epoch Loss: 72088.2693 - Avg Loss: 162.3610\n",
            "Epoch [48/50] - Batch loss: 158.9318 - Epoch Loss: 72247.2010 - Avg Loss: 162.3533\n",
            "Epoch [48/50] - Batch loss: 161.6987 - Epoch Loss: 72408.8997 - Avg Loss: 162.3518\n",
            "Epoch [48/50] - Batch loss: 160.5766 - Epoch Loss: 72569.4763 - Avg Loss: 162.3478\n",
            "Epoch [48/50] - Batch loss: 161.7899 - Epoch Loss: 72731.2663 - Avg Loss: 162.3466\n",
            "Epoch [48/50] - Batch loss: 167.4101 - Epoch Loss: 72898.6764 - Avg Loss: 162.3579\n",
            "Epoch [48/50] - Batch loss: 161.2894 - Epoch Loss: 73059.9658 - Avg Loss: 162.3555\n",
            "Epoch [48/50] - Batch loss: 173.3091 - Epoch Loss: 73233.2749 - Avg Loss: 162.3798\n",
            "Epoch [48/50] - Batch loss: 164.7649 - Epoch Loss: 73398.0398 - Avg Loss: 162.3850\n",
            "Epoch [48/50] - Batch loss: 165.3281 - Epoch Loss: 73563.3679 - Avg Loss: 162.3915\n",
            "Epoch [48/50] - Batch loss: 158.5165 - Epoch Loss: 73721.8844 - Avg Loss: 162.3830\n",
            "Epoch [48/50] - Batch loss: 157.0193 - Epoch Loss: 73878.9037 - Avg Loss: 162.3712\n",
            "Epoch [48/50] - Batch loss: 159.2976 - Epoch Loss: 74038.2013 - Avg Loss: 162.3645\n",
            "Epoch [48/50] - Batch loss: 167.0199 - Epoch Loss: 74205.2211 - Avg Loss: 162.3747\n",
            "Epoch [48/50] - Batch loss: 165.5305 - Epoch Loss: 74370.7516 - Avg Loss: 162.3816\n",
            "Epoch [48/50] - Batch loss: 152.1744 - Epoch Loss: 74522.9261 - Avg Loss: 162.3593\n",
            "Epoch [48/50] - Batch loss: 166.2458 - Epoch Loss: 74689.1719 - Avg Loss: 162.3678\n",
            "Epoch [48/50] - Batch loss: 159.3177 - Epoch Loss: 74848.4896 - Avg Loss: 162.3611\n",
            "Epoch [48/50] - Batch loss: 166.8703 - Epoch Loss: 75015.3598 - Avg Loss: 162.3709\n",
            "Epoch [48/50] - Batch loss: 164.6694 - Epoch Loss: 75180.0293 - Avg Loss: 162.3759\n",
            "Epoch [48/50] - Batch loss: 162.8531 - Epoch Loss: 75342.8824 - Avg Loss: 162.3769\n",
            "Epoch [48/50] - Batch loss: 158.4465 - Epoch Loss: 75501.3289 - Avg Loss: 162.3684\n",
            "Epoch [48/50] - Batch loss: 149.5440 - Epoch Loss: 75650.8729 - Avg Loss: 162.3409\n",
            "Epoch [48/50] - Batch loss: 157.2980 - Epoch Loss: 75808.1710 - Avg Loss: 162.3301\n",
            "Epoch [48/50] - Batch loss: 164.9749 - Epoch Loss: 75973.1458 - Avg Loss: 162.3358\n",
            "Epoch [48/50] - Batch loss: 159.1954 - Epoch Loss: 76132.3412 - Avg Loss: 162.3291\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 49/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32a45f3155ef461080b101d2a7744d47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [49/50] - Batch loss: 166.9552 - Epoch Loss: 166.9552 - Avg Loss: 166.9552\n",
            "Epoch [49/50] - Batch loss: 156.5035 - Epoch Loss: 323.4586 - Avg Loss: 161.7293\n",
            "Epoch [49/50] - Batch loss: 158.9341 - Epoch Loss: 482.3927 - Avg Loss: 160.7976\n",
            "Epoch [49/50] - Batch loss: 167.3316 - Epoch Loss: 649.7243 - Avg Loss: 162.4311\n",
            "Epoch [49/50] - Batch loss: 162.1740 - Epoch Loss: 811.8983 - Avg Loss: 162.3797\n",
            "Epoch [49/50] - Batch loss: 155.4570 - Epoch Loss: 967.3552 - Avg Loss: 161.2259\n",
            "Epoch [49/50] - Batch loss: 176.4648 - Epoch Loss: 1143.8200 - Avg Loss: 163.4029\n",
            "Epoch [49/50] - Batch loss: 158.5021 - Epoch Loss: 1302.3221 - Avg Loss: 162.7903\n",
            "Epoch [49/50] - Batch loss: 162.8607 - Epoch Loss: 1465.1827 - Avg Loss: 162.7981\n",
            "Epoch [49/50] - Batch loss: 169.9493 - Epoch Loss: 1635.1320 - Avg Loss: 163.5132\n",
            "Epoch [49/50] - Batch loss: 165.1246 - Epoch Loss: 1800.2566 - Avg Loss: 163.6597\n",
            "Epoch [49/50] - Batch loss: 163.5304 - Epoch Loss: 1963.7869 - Avg Loss: 163.6489\n",
            "Epoch [49/50] - Batch loss: 163.7389 - Epoch Loss: 2127.5259 - Avg Loss: 163.6558\n",
            "Epoch [49/50] - Batch loss: 164.0258 - Epoch Loss: 2291.5517 - Avg Loss: 163.6823\n",
            "Epoch [49/50] - Batch loss: 158.9577 - Epoch Loss: 2450.5093 - Avg Loss: 163.3673\n",
            "Epoch [49/50] - Batch loss: 158.6296 - Epoch Loss: 2609.1389 - Avg Loss: 163.0712\n",
            "Epoch [49/50] - Batch loss: 167.7775 - Epoch Loss: 2776.9164 - Avg Loss: 163.3480\n",
            "Epoch [49/50] - Batch loss: 171.1568 - Epoch Loss: 2948.0732 - Avg Loss: 163.7818\n",
            "Epoch [49/50] - Batch loss: 164.8321 - Epoch Loss: 3112.9053 - Avg Loss: 163.8371\n",
            "Epoch [49/50] - Batch loss: 165.1099 - Epoch Loss: 3278.0151 - Avg Loss: 163.9008\n",
            "Epoch [49/50] - Batch loss: 162.2041 - Epoch Loss: 3440.2192 - Avg Loss: 163.8200\n",
            "Epoch [49/50] - Batch loss: 178.5842 - Epoch Loss: 3618.8035 - Avg Loss: 164.4911\n",
            "Epoch [49/50] - Batch loss: 170.1988 - Epoch Loss: 3789.0023 - Avg Loss: 164.7392\n",
            "Epoch [49/50] - Batch loss: 166.1866 - Epoch Loss: 3955.1889 - Avg Loss: 164.7995\n",
            "Epoch [49/50] - Batch loss: 167.2267 - Epoch Loss: 4122.4156 - Avg Loss: 164.8966\n",
            "Epoch [49/50] - Batch loss: 174.0861 - Epoch Loss: 4296.5017 - Avg Loss: 165.2501\n",
            "Epoch [49/50] - Batch loss: 162.9648 - Epoch Loss: 4459.4665 - Avg Loss: 165.1654\n",
            "Epoch [49/50] - Batch loss: 165.9823 - Epoch Loss: 4625.4489 - Avg Loss: 165.1946\n",
            "Epoch [49/50] - Batch loss: 170.2290 - Epoch Loss: 4795.6779 - Avg Loss: 165.3682\n",
            "Epoch [49/50] - Batch loss: 162.3674 - Epoch Loss: 4958.0453 - Avg Loss: 165.2682\n",
            "Epoch [49/50] - Batch loss: 174.0883 - Epoch Loss: 5132.1336 - Avg Loss: 165.5527\n",
            "Epoch [49/50] - Batch loss: 167.4048 - Epoch Loss: 5299.5385 - Avg Loss: 165.6106\n",
            "Epoch [49/50] - Batch loss: 160.4612 - Epoch Loss: 5459.9997 - Avg Loss: 165.4545\n",
            "Epoch [49/50] - Batch loss: 164.3509 - Epoch Loss: 5624.3505 - Avg Loss: 165.4221\n",
            "Epoch [49/50] - Batch loss: 162.5042 - Epoch Loss: 5786.8548 - Avg Loss: 165.3387\n",
            "Epoch [49/50] - Batch loss: 170.7025 - Epoch Loss: 5957.5573 - Avg Loss: 165.4877\n",
            "Epoch [49/50] - Batch loss: 163.3694 - Epoch Loss: 6120.9267 - Avg Loss: 165.4305\n",
            "Epoch [49/50] - Batch loss: 167.1592 - Epoch Loss: 6288.0859 - Avg Loss: 165.4759\n",
            "Epoch [49/50] - Batch loss: 166.7703 - Epoch Loss: 6454.8562 - Avg Loss: 165.5091\n",
            "Epoch [49/50] - Batch loss: 159.1972 - Epoch Loss: 6614.0534 - Avg Loss: 165.3513\n",
            "Epoch [49/50] - Batch loss: 167.1151 - Epoch Loss: 6781.1685 - Avg Loss: 165.3944\n",
            "Epoch [49/50] - Batch loss: 160.3590 - Epoch Loss: 6941.5275 - Avg Loss: 165.2745\n",
            "Epoch [49/50] - Batch loss: 167.6561 - Epoch Loss: 7109.1835 - Avg Loss: 165.3298\n",
            "Epoch [49/50] - Batch loss: 162.9204 - Epoch Loss: 7272.1039 - Avg Loss: 165.2751\n",
            "Epoch [49/50] - Batch loss: 160.2296 - Epoch Loss: 7432.3335 - Avg Loss: 165.1630\n",
            "Epoch [49/50] - Batch loss: 168.5211 - Epoch Loss: 7600.8546 - Avg Loss: 165.2360\n",
            "Epoch [49/50] - Batch loss: 166.6505 - Epoch Loss: 7767.5051 - Avg Loss: 165.2661\n",
            "Epoch [49/50] - Batch loss: 164.9400 - Epoch Loss: 7932.4451 - Avg Loss: 165.2593\n",
            "Epoch [49/50] - Batch loss: 158.1407 - Epoch Loss: 8090.5858 - Avg Loss: 165.1140\n",
            "Epoch [49/50] - Batch loss: 156.2710 - Epoch Loss: 8246.8568 - Avg Loss: 164.9371\n",
            "Epoch [49/50] - Batch loss: 158.7881 - Epoch Loss: 8405.6448 - Avg Loss: 164.8166\n",
            "Epoch [49/50] - Batch loss: 158.6012 - Epoch Loss: 8564.2461 - Avg Loss: 164.6970\n",
            "Epoch [49/50] - Batch loss: 161.4186 - Epoch Loss: 8725.6647 - Avg Loss: 164.6352\n",
            "Epoch [49/50] - Batch loss: 170.7729 - Epoch Loss: 8896.4376 - Avg Loss: 164.7488\n",
            "Epoch [49/50] - Batch loss: 165.4790 - Epoch Loss: 9061.9166 - Avg Loss: 164.7621\n",
            "Epoch [49/50] - Batch loss: 158.1483 - Epoch Loss: 9220.0648 - Avg Loss: 164.6440\n",
            "Epoch [49/50] - Batch loss: 157.5784 - Epoch Loss: 9377.6432 - Avg Loss: 164.5201\n",
            "Epoch [49/50] - Batch loss: 168.2442 - Epoch Loss: 9545.8874 - Avg Loss: 164.5843\n",
            "Epoch [49/50] - Batch loss: 160.6839 - Epoch Loss: 9706.5713 - Avg Loss: 164.5182\n",
            "Epoch [49/50] - Batch loss: 161.5766 - Epoch Loss: 9868.1479 - Avg Loss: 164.4691\n",
            "Epoch [49/50] - Batch loss: 162.5413 - Epoch Loss: 10030.6892 - Avg Loss: 164.4375\n",
            "Epoch [49/50] - Batch loss: 165.8565 - Epoch Loss: 10196.5458 - Avg Loss: 164.4604\n",
            "Epoch [49/50] - Batch loss: 169.6872 - Epoch Loss: 10366.2330 - Avg Loss: 164.5434\n",
            "Epoch [49/50] - Batch loss: 169.0167 - Epoch Loss: 10535.2497 - Avg Loss: 164.6133\n",
            "Epoch [49/50] - Batch loss: 166.9128 - Epoch Loss: 10702.1626 - Avg Loss: 164.6487\n",
            "Epoch [49/50] - Batch loss: 166.1946 - Epoch Loss: 10868.3571 - Avg Loss: 164.6721\n",
            "Epoch [49/50] - Batch loss: 171.3110 - Epoch Loss: 11039.6681 - Avg Loss: 164.7712\n",
            "Epoch [49/50] - Batch loss: 159.4598 - Epoch Loss: 11199.1279 - Avg Loss: 164.6931\n",
            "Epoch [49/50] - Batch loss: 166.2250 - Epoch Loss: 11365.3529 - Avg Loss: 164.7153\n",
            "Epoch [49/50] - Batch loss: 168.0196 - Epoch Loss: 11533.3725 - Avg Loss: 164.7625\n",
            "Epoch [49/50] - Batch loss: 175.0900 - Epoch Loss: 11708.4625 - Avg Loss: 164.9079\n",
            "Epoch [49/50] - Batch loss: 161.5802 - Epoch Loss: 11870.0427 - Avg Loss: 164.8617\n",
            "Epoch [49/50] - Batch loss: 150.0547 - Epoch Loss: 12020.0974 - Avg Loss: 164.6589\n",
            "Epoch [49/50] - Batch loss: 160.6825 - Epoch Loss: 12180.7800 - Avg Loss: 164.6051\n",
            "Epoch [49/50] - Batch loss: 158.6308 - Epoch Loss: 12339.4108 - Avg Loss: 164.5255\n",
            "Epoch [49/50] - Batch loss: 161.5597 - Epoch Loss: 12500.9705 - Avg Loss: 164.4865\n",
            "Epoch [49/50] - Batch loss: 163.3451 - Epoch Loss: 12664.3156 - Avg Loss: 164.4716\n",
            "Epoch [49/50] - Batch loss: 159.8681 - Epoch Loss: 12824.1836 - Avg Loss: 164.4126\n",
            "Epoch [49/50] - Batch loss: 155.8911 - Epoch Loss: 12980.0747 - Avg Loss: 164.3047\n",
            "Epoch [49/50] - Batch loss: 164.0538 - Epoch Loss: 13144.1286 - Avg Loss: 164.3016\n",
            "Epoch [49/50] - Batch loss: 163.2552 - Epoch Loss: 13307.3838 - Avg Loss: 164.2887\n",
            "Epoch [49/50] - Batch loss: 164.2845 - Epoch Loss: 13471.6683 - Avg Loss: 164.2886\n",
            "Epoch [49/50] - Batch loss: 165.9357 - Epoch Loss: 13637.6040 - Avg Loss: 164.3085\n",
            "Epoch [49/50] - Batch loss: 163.0581 - Epoch Loss: 13800.6621 - Avg Loss: 164.2936\n",
            "Epoch [49/50] - Batch loss: 162.1631 - Epoch Loss: 13962.8252 - Avg Loss: 164.2685\n",
            "Epoch [49/50] - Batch loss: 158.8508 - Epoch Loss: 14121.6760 - Avg Loss: 164.2055\n",
            "Epoch [49/50] - Batch loss: 163.5394 - Epoch Loss: 14285.2154 - Avg Loss: 164.1979\n",
            "Epoch [49/50] - Batch loss: 158.1408 - Epoch Loss: 14443.3562 - Avg Loss: 164.1290\n",
            "Epoch [49/50] - Batch loss: 166.9632 - Epoch Loss: 14610.3194 - Avg Loss: 164.1609\n",
            "Epoch [49/50] - Batch loss: 160.6437 - Epoch Loss: 14770.9631 - Avg Loss: 164.1218\n",
            "Epoch [49/50] - Batch loss: 151.5988 - Epoch Loss: 14922.5618 - Avg Loss: 163.9842\n",
            "Epoch [49/50] - Batch loss: 161.1596 - Epoch Loss: 15083.7214 - Avg Loss: 163.9535\n",
            "Epoch [49/50] - Batch loss: 160.1751 - Epoch Loss: 15243.8965 - Avg Loss: 163.9129\n",
            "Epoch [49/50] - Batch loss: 161.8903 - Epoch Loss: 15405.7869 - Avg Loss: 163.8913\n",
            "Epoch [49/50] - Batch loss: 163.5039 - Epoch Loss: 15569.2908 - Avg Loss: 163.8873\n",
            "Epoch [49/50] - Batch loss: 164.8838 - Epoch Loss: 15734.1746 - Avg Loss: 163.8977\n",
            "Epoch [49/50] - Batch loss: 158.8481 - Epoch Loss: 15893.0227 - Avg Loss: 163.8456\n",
            "Epoch [49/50] - Batch loss: 157.6805 - Epoch Loss: 16050.7032 - Avg Loss: 163.7827\n",
            "Epoch [49/50] - Batch loss: 155.1027 - Epoch Loss: 16205.8059 - Avg Loss: 163.6950\n",
            "Epoch [49/50] - Batch loss: 169.1241 - Epoch Loss: 16374.9299 - Avg Loss: 163.7493\n",
            "Epoch [49/50] - Batch loss: 166.4969 - Epoch Loss: 16541.4268 - Avg Loss: 163.7765\n",
            "Epoch [49/50] - Batch loss: 170.4840 - Epoch Loss: 16711.9108 - Avg Loss: 163.8423\n",
            "Epoch [49/50] - Batch loss: 163.8306 - Epoch Loss: 16875.7414 - Avg Loss: 163.8421\n",
            "Epoch [49/50] - Batch loss: 161.3724 - Epoch Loss: 17037.1138 - Avg Loss: 163.8184\n",
            "Epoch [49/50] - Batch loss: 150.6285 - Epoch Loss: 17187.7424 - Avg Loss: 163.6928\n",
            "Epoch [49/50] - Batch loss: 168.4836 - Epoch Loss: 17356.2259 - Avg Loss: 163.7380\n",
            "Epoch [49/50] - Batch loss: 168.9202 - Epoch Loss: 17525.1461 - Avg Loss: 163.7864\n",
            "Epoch [49/50] - Batch loss: 156.3424 - Epoch Loss: 17681.4885 - Avg Loss: 163.7175\n",
            "Epoch [49/50] - Batch loss: 168.4614 - Epoch Loss: 17849.9499 - Avg Loss: 163.7610\n",
            "Epoch [49/50] - Batch loss: 165.1515 - Epoch Loss: 18015.1015 - Avg Loss: 163.7736\n",
            "Epoch [49/50] - Batch loss: 157.4009 - Epoch Loss: 18172.5024 - Avg Loss: 163.7162\n",
            "Epoch [49/50] - Batch loss: 165.6131 - Epoch Loss: 18338.1155 - Avg Loss: 163.7332\n",
            "Epoch [49/50] - Batch loss: 162.9024 - Epoch Loss: 18501.0179 - Avg Loss: 163.7258\n",
            "Epoch [49/50] - Batch loss: 169.9824 - Epoch Loss: 18671.0003 - Avg Loss: 163.7807\n",
            "Epoch [49/50] - Batch loss: 148.9706 - Epoch Loss: 18819.9709 - Avg Loss: 163.6519\n",
            "Epoch [49/50] - Batch loss: 163.2450 - Epoch Loss: 18983.2159 - Avg Loss: 163.6484\n",
            "Epoch [49/50] - Batch loss: 160.4043 - Epoch Loss: 19143.6202 - Avg Loss: 163.6207\n",
            "Epoch [49/50] - Batch loss: 165.8958 - Epoch Loss: 19309.5161 - Avg Loss: 163.6400\n",
            "Epoch [49/50] - Batch loss: 163.1246 - Epoch Loss: 19472.6406 - Avg Loss: 163.6356\n",
            "Epoch [49/50] - Batch loss: 168.0487 - Epoch Loss: 19640.6893 - Avg Loss: 163.6724\n",
            "Epoch [49/50] - Batch loss: 154.5499 - Epoch Loss: 19795.2392 - Avg Loss: 163.5970\n",
            "Epoch [49/50] - Batch loss: 168.0157 - Epoch Loss: 19963.2549 - Avg Loss: 163.6332\n",
            "Epoch [49/50] - Batch loss: 169.8315 - Epoch Loss: 20133.0865 - Avg Loss: 163.6836\n",
            "Epoch [49/50] - Batch loss: 165.1694 - Epoch Loss: 20298.2559 - Avg Loss: 163.6956\n",
            "Epoch [49/50] - Batch loss: 162.2833 - Epoch Loss: 20460.5392 - Avg Loss: 163.6843\n",
            "Epoch [49/50] - Batch loss: 162.7444 - Epoch Loss: 20623.2836 - Avg Loss: 163.6769\n",
            "Epoch [49/50] - Batch loss: 162.8832 - Epoch Loss: 20786.1668 - Avg Loss: 163.6706\n",
            "Epoch [49/50] - Batch loss: 162.7842 - Epoch Loss: 20948.9510 - Avg Loss: 163.6637\n",
            "Epoch [49/50] - Batch loss: 159.8989 - Epoch Loss: 21108.8498 - Avg Loss: 163.6345\n",
            "Epoch [49/50] - Batch loss: 162.4528 - Epoch Loss: 21271.3026 - Avg Loss: 163.6254\n",
            "Epoch [49/50] - Batch loss: 154.1218 - Epoch Loss: 21425.4244 - Avg Loss: 163.5529\n",
            "Epoch [49/50] - Batch loss: 158.1059 - Epoch Loss: 21583.5303 - Avg Loss: 163.5116\n",
            "Epoch [49/50] - Batch loss: 153.2778 - Epoch Loss: 21736.8082 - Avg Loss: 163.4346\n",
            "Epoch [49/50] - Batch loss: 160.3592 - Epoch Loss: 21897.1674 - Avg Loss: 163.4117\n",
            "Epoch [49/50] - Batch loss: 157.5913 - Epoch Loss: 22054.7587 - Avg Loss: 163.3686\n",
            "Epoch [49/50] - Batch loss: 157.8712 - Epoch Loss: 22212.6299 - Avg Loss: 163.3282\n",
            "Epoch [49/50] - Batch loss: 160.5295 - Epoch Loss: 22373.1594 - Avg Loss: 163.3077\n",
            "Epoch [49/50] - Batch loss: 155.2160 - Epoch Loss: 22528.3754 - Avg Loss: 163.2491\n",
            "Epoch [49/50] - Batch loss: 154.8132 - Epoch Loss: 22683.1886 - Avg Loss: 163.1884\n",
            "Epoch [49/50] - Batch loss: 154.7569 - Epoch Loss: 22837.9455 - Avg Loss: 163.1282\n",
            "Epoch [49/50] - Batch loss: 161.1033 - Epoch Loss: 22999.0488 - Avg Loss: 163.1138\n",
            "Epoch [49/50] - Batch loss: 162.6452 - Epoch Loss: 23161.6940 - Avg Loss: 163.1105\n",
            "Epoch [49/50] - Batch loss: 150.1528 - Epoch Loss: 23311.8468 - Avg Loss: 163.0199\n",
            "Epoch [49/50] - Batch loss: 163.5313 - Epoch Loss: 23475.3781 - Avg Loss: 163.0235\n",
            "Epoch [49/50] - Batch loss: 160.0947 - Epoch Loss: 23635.4727 - Avg Loss: 163.0033\n",
            "Epoch [49/50] - Batch loss: 160.6319 - Epoch Loss: 23796.1046 - Avg Loss: 162.9870\n",
            "Epoch [49/50] - Batch loss: 159.5244 - Epoch Loss: 23955.6291 - Avg Loss: 162.9635\n",
            "Epoch [49/50] - Batch loss: 163.2487 - Epoch Loss: 24118.8778 - Avg Loss: 162.9654\n",
            "Epoch [49/50] - Batch loss: 154.4760 - Epoch Loss: 24273.3538 - Avg Loss: 162.9084\n",
            "Epoch [49/50] - Batch loss: 156.9407 - Epoch Loss: 24430.2944 - Avg Loss: 162.8686\n",
            "Epoch [49/50] - Batch loss: 159.8890 - Epoch Loss: 24590.1835 - Avg Loss: 162.8489\n",
            "Epoch [49/50] - Batch loss: 162.9444 - Epoch Loss: 24753.1278 - Avg Loss: 162.8495\n",
            "Epoch [49/50] - Batch loss: 161.3044 - Epoch Loss: 24914.4323 - Avg Loss: 162.8394\n",
            "Epoch [49/50] - Batch loss: 160.2437 - Epoch Loss: 25074.6760 - Avg Loss: 162.8226\n",
            "Epoch [49/50] - Batch loss: 156.1244 - Epoch Loss: 25230.8004 - Avg Loss: 162.7794\n",
            "Epoch [49/50] - Batch loss: 159.5776 - Epoch Loss: 25390.3780 - Avg Loss: 162.7588\n",
            "Epoch [49/50] - Batch loss: 156.2851 - Epoch Loss: 25546.6631 - Avg Loss: 162.7176\n",
            "Epoch [49/50] - Batch loss: 163.0066 - Epoch Loss: 25709.6697 - Avg Loss: 162.7194\n",
            "Epoch [49/50] - Batch loss: 156.6374 - Epoch Loss: 25866.3071 - Avg Loss: 162.6812\n",
            "Epoch [49/50] - Batch loss: 161.8233 - Epoch Loss: 26028.1305 - Avg Loss: 162.6758\n",
            "Epoch [49/50] - Batch loss: 159.8939 - Epoch Loss: 26188.0244 - Avg Loss: 162.6585\n",
            "Epoch [49/50] - Batch loss: 156.2566 - Epoch Loss: 26344.2809 - Avg Loss: 162.6190\n",
            "Epoch [49/50] - Batch loss: 160.6483 - Epoch Loss: 26504.9292 - Avg Loss: 162.6069\n",
            "Epoch [49/50] - Batch loss: 158.8473 - Epoch Loss: 26663.7765 - Avg Loss: 162.5840\n",
            "Epoch [49/50] - Batch loss: 158.9838 - Epoch Loss: 26822.7603 - Avg Loss: 162.5622\n",
            "Epoch [49/50] - Batch loss: 171.3393 - Epoch Loss: 26994.0996 - Avg Loss: 162.6151\n",
            "Epoch [49/50] - Batch loss: 154.7244 - Epoch Loss: 27148.8240 - Avg Loss: 162.5678\n",
            "Epoch [49/50] - Batch loss: 164.6818 - Epoch Loss: 27313.5058 - Avg Loss: 162.5804\n",
            "Epoch [49/50] - Batch loss: 162.8990 - Epoch Loss: 27476.4048 - Avg Loss: 162.5823\n",
            "Epoch [49/50] - Batch loss: 154.9722 - Epoch Loss: 27631.3770 - Avg Loss: 162.5375\n",
            "Epoch [49/50] - Batch loss: 158.2475 - Epoch Loss: 27789.6244 - Avg Loss: 162.5124\n",
            "Epoch [49/50] - Batch loss: 159.8000 - Epoch Loss: 27949.4244 - Avg Loss: 162.4967\n",
            "Epoch [49/50] - Batch loss: 162.6066 - Epoch Loss: 28112.0309 - Avg Loss: 162.4973\n",
            "Epoch [49/50] - Batch loss: 161.9983 - Epoch Loss: 28274.0293 - Avg Loss: 162.4944\n",
            "Epoch [49/50] - Batch loss: 159.2675 - Epoch Loss: 28433.2968 - Avg Loss: 162.4760\n",
            "Epoch [49/50] - Batch loss: 154.4796 - Epoch Loss: 28587.7763 - Avg Loss: 162.4305\n",
            "Epoch [49/50] - Batch loss: 154.3687 - Epoch Loss: 28742.1450 - Avg Loss: 162.3850\n",
            "Epoch [49/50] - Batch loss: 160.9710 - Epoch Loss: 28903.1160 - Avg Loss: 162.3771\n",
            "Epoch [49/50] - Batch loss: 160.6987 - Epoch Loss: 29063.8147 - Avg Loss: 162.3677\n",
            "Epoch [49/50] - Batch loss: 152.8070 - Epoch Loss: 29216.6217 - Avg Loss: 162.3146\n",
            "Epoch [49/50] - Batch loss: 160.4254 - Epoch Loss: 29377.0471 - Avg Loss: 162.3041\n",
            "Epoch [49/50] - Batch loss: 160.1362 - Epoch Loss: 29537.1833 - Avg Loss: 162.2922\n",
            "Epoch [49/50] - Batch loss: 166.1956 - Epoch Loss: 29703.3790 - Avg Loss: 162.3135\n",
            "Epoch [49/50] - Batch loss: 158.5296 - Epoch Loss: 29861.9086 - Avg Loss: 162.2930\n",
            "Epoch [49/50] - Batch loss: 152.1625 - Epoch Loss: 30014.0711 - Avg Loss: 162.2382\n",
            "Epoch [49/50] - Batch loss: 156.6402 - Epoch Loss: 30170.7113 - Avg Loss: 162.2081\n",
            "Epoch [49/50] - Batch loss: 157.0785 - Epoch Loss: 30327.7898 - Avg Loss: 162.1807\n",
            "Epoch [49/50] - Batch loss: 163.8773 - Epoch Loss: 30491.6670 - Avg Loss: 162.1897\n",
            "Epoch [49/50] - Batch loss: 152.9440 - Epoch Loss: 30644.6110 - Avg Loss: 162.1408\n",
            "Epoch [49/50] - Batch loss: 159.5533 - Epoch Loss: 30804.1643 - Avg Loss: 162.1272\n",
            "Epoch [49/50] - Batch loss: 156.3492 - Epoch Loss: 30960.5135 - Avg Loss: 162.0969\n",
            "Epoch [49/50] - Batch loss: 155.4652 - Epoch Loss: 31115.9787 - Avg Loss: 162.0624\n",
            "Epoch [49/50] - Batch loss: 155.6758 - Epoch Loss: 31271.6545 - Avg Loss: 162.0293\n",
            "Epoch [49/50] - Batch loss: 152.2200 - Epoch Loss: 31423.8745 - Avg Loss: 161.9787\n",
            "Epoch [49/50] - Batch loss: 162.2176 - Epoch Loss: 31586.0921 - Avg Loss: 161.9800\n",
            "Epoch [49/50] - Batch loss: 155.7362 - Epoch Loss: 31741.8283 - Avg Loss: 161.9481\n",
            "Epoch [49/50] - Batch loss: 156.6435 - Epoch Loss: 31898.4718 - Avg Loss: 161.9212\n",
            "Epoch [49/50] - Batch loss: 162.3386 - Epoch Loss: 32060.8104 - Avg Loss: 161.9233\n",
            "Epoch [49/50] - Batch loss: 162.9620 - Epoch Loss: 32223.7724 - Avg Loss: 161.9285\n",
            "Epoch [49/50] - Batch loss: 158.1487 - Epoch Loss: 32381.9211 - Avg Loss: 161.9096\n",
            "Epoch [49/50] - Batch loss: 155.3454 - Epoch Loss: 32537.2665 - Avg Loss: 161.8769\n",
            "Epoch [49/50] - Batch loss: 154.8420 - Epoch Loss: 32692.1085 - Avg Loss: 161.8421\n",
            "Epoch [49/50] - Batch loss: 156.7293 - Epoch Loss: 32848.8378 - Avg Loss: 161.8169\n",
            "Epoch [49/50] - Batch loss: 158.8240 - Epoch Loss: 33007.6618 - Avg Loss: 161.8023\n",
            "Epoch [49/50] - Batch loss: 156.8882 - Epoch Loss: 33164.5501 - Avg Loss: 161.7783\n",
            "Epoch [49/50] - Batch loss: 161.3832 - Epoch Loss: 33325.9333 - Avg Loss: 161.7764\n",
            "Epoch [49/50] - Batch loss: 161.1374 - Epoch Loss: 33487.0706 - Avg Loss: 161.7733\n",
            "Epoch [49/50] - Batch loss: 157.8071 - Epoch Loss: 33644.8778 - Avg Loss: 161.7542\n",
            "Epoch [49/50] - Batch loss: 161.5003 - Epoch Loss: 33806.3780 - Avg Loss: 161.7530\n",
            "Epoch [49/50] - Batch loss: 164.5780 - Epoch Loss: 33970.9561 - Avg Loss: 161.7665\n",
            "Epoch [49/50] - Batch loss: 160.5919 - Epoch Loss: 34131.5480 - Avg Loss: 161.7609\n",
            "Epoch [49/50] - Batch loss: 158.7842 - Epoch Loss: 34290.3322 - Avg Loss: 161.7468\n",
            "Epoch [49/50] - Batch loss: 152.5620 - Epoch Loss: 34442.8941 - Avg Loss: 161.7037\n",
            "Epoch [49/50] - Batch loss: 164.0103 - Epoch Loss: 34606.9045 - Avg Loss: 161.7145\n",
            "Epoch [49/50] - Batch loss: 163.6041 - Epoch Loss: 34770.5086 - Avg Loss: 161.7233\n",
            "Epoch [49/50] - Batch loss: 163.9091 - Epoch Loss: 34934.4177 - Avg Loss: 161.7334\n",
            "Epoch [49/50] - Batch loss: 160.3988 - Epoch Loss: 35094.8165 - Avg Loss: 161.7273\n",
            "Epoch [49/50] - Batch loss: 164.3146 - Epoch Loss: 35259.1311 - Avg Loss: 161.7391\n",
            "Epoch [49/50] - Batch loss: 160.2875 - Epoch Loss: 35419.4186 - Avg Loss: 161.7325\n",
            "Epoch [49/50] - Batch loss: 159.6230 - Epoch Loss: 35579.0416 - Avg Loss: 161.7229\n",
            "Epoch [49/50] - Batch loss: 161.2160 - Epoch Loss: 35740.2576 - Avg Loss: 161.7206\n",
            "Epoch [49/50] - Batch loss: 167.9610 - Epoch Loss: 35908.2186 - Avg Loss: 161.7487\n",
            "Epoch [49/50] - Batch loss: 157.7713 - Epoch Loss: 36065.9899 - Avg Loss: 161.7309\n",
            "Epoch [49/50] - Batch loss: 161.9749 - Epoch Loss: 36227.9648 - Avg Loss: 161.7320\n",
            "Epoch [49/50] - Batch loss: 155.2628 - Epoch Loss: 36383.2276 - Avg Loss: 161.7032\n",
            "Epoch [49/50] - Batch loss: 165.6667 - Epoch Loss: 36548.8942 - Avg Loss: 161.7208\n",
            "Epoch [49/50] - Batch loss: 158.7946 - Epoch Loss: 36707.6888 - Avg Loss: 161.7079\n",
            "Epoch [49/50] - Batch loss: 160.3641 - Epoch Loss: 36868.0529 - Avg Loss: 161.7020\n",
            "Epoch [49/50] - Batch loss: 161.8627 - Epoch Loss: 37029.9156 - Avg Loss: 161.7027\n",
            "Epoch [49/50] - Batch loss: 154.0490 - Epoch Loss: 37183.9646 - Avg Loss: 161.6694\n",
            "Epoch [49/50] - Batch loss: 165.6870 - Epoch Loss: 37349.6516 - Avg Loss: 161.6868\n",
            "Epoch [49/50] - Batch loss: 163.6541 - Epoch Loss: 37513.3057 - Avg Loss: 161.6953\n",
            "Epoch [49/50] - Batch loss: 146.0744 - Epoch Loss: 37659.3801 - Avg Loss: 161.6282\n",
            "Epoch [49/50] - Batch loss: 164.1751 - Epoch Loss: 37823.5552 - Avg Loss: 161.6391\n",
            "Epoch [49/50] - Batch loss: 166.7946 - Epoch Loss: 37990.3498 - Avg Loss: 161.6611\n",
            "Epoch [49/50] - Batch loss: 155.9233 - Epoch Loss: 38146.2731 - Avg Loss: 161.6368\n",
            "Epoch [49/50] - Batch loss: 156.8443 - Epoch Loss: 38303.1174 - Avg Loss: 161.6165\n",
            "Epoch [49/50] - Batch loss: 161.8739 - Epoch Loss: 38464.9913 - Avg Loss: 161.6176\n",
            "Epoch [49/50] - Batch loss: 155.8932 - Epoch Loss: 38620.8845 - Avg Loss: 161.5937\n",
            "Epoch [49/50] - Batch loss: 156.7290 - Epoch Loss: 38777.6135 - Avg Loss: 161.5734\n",
            "Epoch [49/50] - Batch loss: 156.7666 - Epoch Loss: 38934.3800 - Avg Loss: 161.5534\n",
            "Epoch [49/50] - Batch loss: 156.3327 - Epoch Loss: 39090.7127 - Avg Loss: 161.5319\n",
            "Epoch [49/50] - Batch loss: 156.3562 - Epoch Loss: 39247.0690 - Avg Loss: 161.5106\n",
            "Epoch [49/50] - Batch loss: 162.9542 - Epoch Loss: 39410.0231 - Avg Loss: 161.5165\n",
            "Epoch [49/50] - Batch loss: 160.9013 - Epoch Loss: 39570.9244 - Avg Loss: 161.5140\n",
            "Epoch [49/50] - Batch loss: 156.6098 - Epoch Loss: 39727.5342 - Avg Loss: 161.4940\n",
            "Epoch [49/50] - Batch loss: 158.8486 - Epoch Loss: 39886.3828 - Avg Loss: 161.4833\n",
            "Epoch [49/50] - Batch loss: 156.0034 - Epoch Loss: 40042.3862 - Avg Loss: 161.4612\n",
            "Epoch [49/50] - Batch loss: 166.2202 - Epoch Loss: 40208.6064 - Avg Loss: 161.4803\n",
            "Epoch [49/50] - Batch loss: 155.0481 - Epoch Loss: 40363.6545 - Avg Loss: 161.4546\n",
            "Epoch [49/50] - Batch loss: 157.3956 - Epoch Loss: 40521.0501 - Avg Loss: 161.4384\n",
            "Epoch [49/50] - Batch loss: 154.9301 - Epoch Loss: 40675.9803 - Avg Loss: 161.4126\n",
            "Epoch [49/50] - Batch loss: 157.0165 - Epoch Loss: 40832.9968 - Avg Loss: 161.3952\n",
            "Epoch [49/50] - Batch loss: 155.1454 - Epoch Loss: 40988.1422 - Avg Loss: 161.3706\n",
            "Epoch [49/50] - Batch loss: 161.7789 - Epoch Loss: 41149.9211 - Avg Loss: 161.3722\n",
            "Epoch [49/50] - Batch loss: 158.6259 - Epoch Loss: 41308.5470 - Avg Loss: 161.3615\n",
            "Epoch [49/50] - Batch loss: 155.8726 - Epoch Loss: 41464.4195 - Avg Loss: 161.3402\n",
            "Epoch [49/50] - Batch loss: 167.9740 - Epoch Loss: 41632.3935 - Avg Loss: 161.3659\n",
            "Epoch [49/50] - Batch loss: 153.2394 - Epoch Loss: 41785.6329 - Avg Loss: 161.3345\n",
            "Epoch [49/50] - Batch loss: 153.9191 - Epoch Loss: 41939.5520 - Avg Loss: 161.3060\n",
            "Epoch [49/50] - Batch loss: 166.7102 - Epoch Loss: 42106.2622 - Avg Loss: 161.3267\n",
            "Epoch [49/50] - Batch loss: 163.0724 - Epoch Loss: 42269.3347 - Avg Loss: 161.3333\n",
            "Epoch [49/50] - Batch loss: 164.9823 - Epoch Loss: 42434.3170 - Avg Loss: 161.3472\n",
            "Epoch [49/50] - Batch loss: 160.2957 - Epoch Loss: 42594.6127 - Avg Loss: 161.3432\n",
            "Epoch [49/50] - Batch loss: 162.5019 - Epoch Loss: 42757.1145 - Avg Loss: 161.3476\n",
            "Epoch [49/50] - Batch loss: 151.5157 - Epoch Loss: 42908.6303 - Avg Loss: 161.3106\n",
            "Epoch [49/50] - Batch loss: 162.0505 - Epoch Loss: 43070.6808 - Avg Loss: 161.3134\n",
            "Epoch [49/50] - Batch loss: 156.0159 - Epoch Loss: 43226.6966 - Avg Loss: 161.2936\n",
            "Epoch [49/50] - Batch loss: 163.3251 - Epoch Loss: 43390.0218 - Avg Loss: 161.3012\n",
            "Epoch [49/50] - Batch loss: 162.6208 - Epoch Loss: 43552.6425 - Avg Loss: 161.3061\n",
            "Epoch [49/50] - Batch loss: 164.5039 - Epoch Loss: 43717.1464 - Avg Loss: 161.3179\n",
            "Epoch [49/50] - Batch loss: 159.5777 - Epoch Loss: 43876.7241 - Avg Loss: 161.3115\n",
            "Epoch [49/50] - Batch loss: 157.0516 - Epoch Loss: 44033.7757 - Avg Loss: 161.2959\n",
            "Epoch [49/50] - Batch loss: 160.4825 - Epoch Loss: 44194.2582 - Avg Loss: 161.2929\n",
            "Epoch [49/50] - Batch loss: 163.8805 - Epoch Loss: 44358.1386 - Avg Loss: 161.3023\n",
            "Epoch [49/50] - Batch loss: 162.4390 - Epoch Loss: 44520.5777 - Avg Loss: 161.3064\n",
            "Epoch [49/50] - Batch loss: 159.5966 - Epoch Loss: 44680.1743 - Avg Loss: 161.3003\n",
            "Epoch [49/50] - Batch loss: 161.8391 - Epoch Loss: 44842.0134 - Avg Loss: 161.3022\n",
            "Epoch [49/50] - Batch loss: 165.4417 - Epoch Loss: 45007.4551 - Avg Loss: 161.3170\n",
            "Epoch [49/50] - Batch loss: 159.7705 - Epoch Loss: 45167.2255 - Avg Loss: 161.3115\n",
            "Epoch [49/50] - Batch loss: 154.0149 - Epoch Loss: 45321.2404 - Avg Loss: 161.2856\n",
            "Epoch [49/50] - Batch loss: 163.5470 - Epoch Loss: 45484.7875 - Avg Loss: 161.2936\n",
            "Epoch [49/50] - Batch loss: 158.3216 - Epoch Loss: 45643.1091 - Avg Loss: 161.2831\n",
            "Epoch [49/50] - Batch loss: 155.3201 - Epoch Loss: 45798.4292 - Avg Loss: 161.2621\n",
            "Epoch [49/50] - Batch loss: 159.5369 - Epoch Loss: 45957.9661 - Avg Loss: 161.2560\n",
            "Epoch [49/50] - Batch loss: 166.5729 - Epoch Loss: 46124.5390 - Avg Loss: 161.2746\n",
            "Epoch [49/50] - Batch loss: 162.0578 - Epoch Loss: 46286.5968 - Avg Loss: 161.2773\n",
            "Epoch [49/50] - Batch loss: 167.9150 - Epoch Loss: 46454.5119 - Avg Loss: 161.3004\n",
            "Epoch [49/50] - Batch loss: 154.8088 - Epoch Loss: 46609.3207 - Avg Loss: 161.2779\n",
            "Epoch [49/50] - Batch loss: 164.5110 - Epoch Loss: 46773.8317 - Avg Loss: 161.2891\n",
            "Epoch [49/50] - Batch loss: 163.7392 - Epoch Loss: 46937.5710 - Avg Loss: 161.2975\n",
            "Epoch [49/50] - Batch loss: 161.1049 - Epoch Loss: 47098.6758 - Avg Loss: 161.2968\n",
            "Epoch [49/50] - Batch loss: 163.4547 - Epoch Loss: 47262.1305 - Avg Loss: 161.3042\n",
            "Epoch [49/50] - Batch loss: 162.2811 - Epoch Loss: 47424.4116 - Avg Loss: 161.3075\n",
            "Epoch [49/50] - Batch loss: 165.3938 - Epoch Loss: 47589.8054 - Avg Loss: 161.3214\n",
            "Epoch [49/50] - Batch loss: 162.0259 - Epoch Loss: 47751.8313 - Avg Loss: 161.3238\n",
            "Epoch [49/50] - Batch loss: 154.1439 - Epoch Loss: 47905.9751 - Avg Loss: 161.2996\n",
            "Epoch [49/50] - Batch loss: 159.0334 - Epoch Loss: 48065.0085 - Avg Loss: 161.2920\n",
            "Epoch [49/50] - Batch loss: 162.1220 - Epoch Loss: 48227.1306 - Avg Loss: 161.2948\n",
            "Epoch [49/50] - Batch loss: 157.5986 - Epoch Loss: 48384.7292 - Avg Loss: 161.2824\n",
            "Epoch [49/50] - Batch loss: 154.9958 - Epoch Loss: 48539.7250 - Avg Loss: 161.2615\n",
            "Epoch [49/50] - Batch loss: 155.1163 - Epoch Loss: 48694.8414 - Avg Loss: 161.2412\n",
            "Epoch [49/50] - Batch loss: 156.7079 - Epoch Loss: 48851.5492 - Avg Loss: 161.2262\n",
            "Epoch [49/50] - Batch loss: 159.6689 - Epoch Loss: 49011.2182 - Avg Loss: 161.2211\n",
            "Epoch [49/50] - Batch loss: 159.5412 - Epoch Loss: 49170.7594 - Avg Loss: 161.2156\n",
            "Epoch [49/50] - Batch loss: 155.1096 - Epoch Loss: 49325.8690 - Avg Loss: 161.1957\n",
            "Epoch [49/50] - Batch loss: 160.3376 - Epoch Loss: 49486.2067 - Avg Loss: 161.1929\n",
            "Epoch [49/50] - Batch loss: 161.2869 - Epoch Loss: 49647.4936 - Avg Loss: 161.1932\n",
            "Epoch [49/50] - Batch loss: 163.6681 - Epoch Loss: 49811.1617 - Avg Loss: 161.2012\n",
            "Epoch [49/50] - Batch loss: 154.7251 - Epoch Loss: 49965.8868 - Avg Loss: 161.1803\n",
            "Epoch [49/50] - Batch loss: 162.9679 - Epoch Loss: 50128.8547 - Avg Loss: 161.1860\n",
            "Epoch [49/50] - Batch loss: 155.2941 - Epoch Loss: 50284.1488 - Avg Loss: 161.1671\n",
            "Epoch [49/50] - Batch loss: 155.1616 - Epoch Loss: 50439.3104 - Avg Loss: 161.1480\n",
            "Epoch [49/50] - Batch loss: 165.5123 - Epoch Loss: 50604.8227 - Avg Loss: 161.1619\n",
            "Epoch [49/50] - Batch loss: 160.4809 - Epoch Loss: 50765.3036 - Avg Loss: 161.1597\n",
            "Epoch [49/50] - Batch loss: 167.2126 - Epoch Loss: 50932.5162 - Avg Loss: 161.1788\n",
            "Epoch [49/50] - Batch loss: 154.0609 - Epoch Loss: 51086.5770 - Avg Loss: 161.1564\n",
            "Epoch [49/50] - Batch loss: 159.7991 - Epoch Loss: 51246.3762 - Avg Loss: 161.1521\n",
            "Epoch [49/50] - Batch loss: 167.3962 - Epoch Loss: 51413.7724 - Avg Loss: 161.1717\n",
            "Epoch [49/50] - Batch loss: 162.7676 - Epoch Loss: 51576.5400 - Avg Loss: 161.1767\n",
            "Epoch [49/50] - Batch loss: 156.4404 - Epoch Loss: 51732.9804 - Avg Loss: 161.1619\n",
            "Epoch [49/50] - Batch loss: 164.8815 - Epoch Loss: 51897.8619 - Avg Loss: 161.1735\n",
            "Epoch [49/50] - Batch loss: 167.2688 - Epoch Loss: 52065.1307 - Avg Loss: 161.1924\n",
            "Epoch [49/50] - Batch loss: 155.1786 - Epoch Loss: 52220.3093 - Avg Loss: 161.1738\n",
            "Epoch [49/50] - Batch loss: 161.8683 - Epoch Loss: 52382.1776 - Avg Loss: 161.1759\n",
            "Epoch [49/50] - Batch loss: 167.6262 - Epoch Loss: 52549.8038 - Avg Loss: 161.1957\n",
            "Epoch [49/50] - Batch loss: 162.6618 - Epoch Loss: 52712.4656 - Avg Loss: 161.2002\n",
            "Epoch [49/50] - Batch loss: 165.9065 - Epoch Loss: 52878.3721 - Avg Loss: 161.2145\n",
            "Epoch [49/50] - Batch loss: 167.8805 - Epoch Loss: 53046.2526 - Avg Loss: 161.2348\n",
            "Epoch [49/50] - Batch loss: 165.1739 - Epoch Loss: 53211.4265 - Avg Loss: 161.2467\n",
            "Epoch [49/50] - Batch loss: 160.8885 - Epoch Loss: 53372.3150 - Avg Loss: 161.2457\n",
            "Epoch [49/50] - Batch loss: 162.2925 - Epoch Loss: 53534.6075 - Avg Loss: 161.2488\n",
            "Epoch [49/50] - Batch loss: 157.0976 - Epoch Loss: 53691.7051 - Avg Loss: 161.2364\n",
            "Epoch [49/50] - Batch loss: 159.4482 - Epoch Loss: 53851.1533 - Avg Loss: 161.2310\n",
            "Epoch [49/50] - Batch loss: 156.4078 - Epoch Loss: 54007.5611 - Avg Loss: 161.2166\n",
            "Epoch [49/50] - Batch loss: 165.5766 - Epoch Loss: 54173.1376 - Avg Loss: 161.2296\n",
            "Epoch [49/50] - Batch loss: 167.6619 - Epoch Loss: 54340.7995 - Avg Loss: 161.2487\n",
            "Epoch [49/50] - Batch loss: 169.5787 - Epoch Loss: 54510.3782 - Avg Loss: 161.2733\n",
            "Epoch [49/50] - Batch loss: 157.6787 - Epoch Loss: 54668.0569 - Avg Loss: 161.2627\n",
            "Epoch [49/50] - Batch loss: 163.1144 - Epoch Loss: 54831.1713 - Avg Loss: 161.2682\n",
            "Epoch [49/50] - Batch loss: 158.8065 - Epoch Loss: 54989.9778 - Avg Loss: 161.2609\n",
            "Epoch [49/50] - Batch loss: 159.4852 - Epoch Loss: 55149.4631 - Avg Loss: 161.2557\n",
            "Epoch [49/50] - Batch loss: 159.9273 - Epoch Loss: 55309.3904 - Avg Loss: 161.2519\n",
            "Epoch [49/50] - Batch loss: 169.3981 - Epoch Loss: 55478.7885 - Avg Loss: 161.2755\n",
            "Epoch [49/50] - Batch loss: 164.6192 - Epoch Loss: 55643.4076 - Avg Loss: 161.2852\n",
            "Epoch [49/50] - Batch loss: 155.8896 - Epoch Loss: 55799.2972 - Avg Loss: 161.2696\n",
            "Epoch [49/50] - Batch loss: 161.2553 - Epoch Loss: 55960.5525 - Avg Loss: 161.2696\n",
            "Epoch [49/50] - Batch loss: 151.9078 - Epoch Loss: 56112.4603 - Avg Loss: 161.2427\n",
            "Epoch [49/50] - Batch loss: 162.7417 - Epoch Loss: 56275.2020 - Avg Loss: 161.2470\n",
            "Epoch [49/50] - Batch loss: 164.4050 - Epoch Loss: 56439.6070 - Avg Loss: 161.2560\n",
            "Epoch [49/50] - Batch loss: 176.6035 - Epoch Loss: 56616.2105 - Avg Loss: 161.2997\n",
            "Epoch [49/50] - Batch loss: 162.1212 - Epoch Loss: 56778.3317 - Avg Loss: 161.3021\n",
            "Epoch [49/50] - Batch loss: 166.7161 - Epoch Loss: 56945.0478 - Avg Loss: 161.3174\n",
            "Epoch [49/50] - Batch loss: 172.7712 - Epoch Loss: 57117.8190 - Avg Loss: 161.3498\n",
            "Epoch [49/50] - Batch loss: 168.2081 - Epoch Loss: 57286.0271 - Avg Loss: 161.3691\n",
            "Epoch [49/50] - Batch loss: 181.1656 - Epoch Loss: 57467.1927 - Avg Loss: 161.4247\n",
            "Epoch [49/50] - Batch loss: 181.7480 - Epoch Loss: 57648.9407 - Avg Loss: 161.4816\n",
            "Epoch [49/50] - Batch loss: 173.8110 - Epoch Loss: 57822.7516 - Avg Loss: 161.5161\n",
            "Epoch [49/50] - Batch loss: 160.7340 - Epoch Loss: 57983.4857 - Avg Loss: 161.5139\n",
            "Epoch [49/50] - Batch loss: 162.0393 - Epoch Loss: 58145.5250 - Avg Loss: 161.5153\n",
            "Epoch [49/50] - Batch loss: 172.7327 - Epoch Loss: 58318.2577 - Avg Loss: 161.5464\n",
            "Epoch [49/50] - Batch loss: 162.7424 - Epoch Loss: 58481.0001 - Avg Loss: 161.5497\n",
            "Epoch [49/50] - Batch loss: 166.2809 - Epoch Loss: 58647.2811 - Avg Loss: 161.5628\n",
            "Epoch [49/50] - Batch loss: 164.4235 - Epoch Loss: 58811.7045 - Avg Loss: 161.5706\n",
            "Epoch [49/50] - Batch loss: 161.3459 - Epoch Loss: 58973.0505 - Avg Loss: 161.5700\n",
            "Epoch [49/50] - Batch loss: 169.2594 - Epoch Loss: 59142.3099 - Avg Loss: 161.5910\n",
            "Epoch [49/50] - Batch loss: 170.2997 - Epoch Loss: 59312.6096 - Avg Loss: 161.6147\n",
            "Epoch [49/50] - Batch loss: 168.9335 - Epoch Loss: 59481.5431 - Avg Loss: 161.6346\n",
            "Epoch [49/50] - Batch loss: 157.8219 - Epoch Loss: 59639.3651 - Avg Loss: 161.6243\n",
            "Epoch [49/50] - Batch loss: 169.5428 - Epoch Loss: 59808.9079 - Avg Loss: 161.6457\n",
            "Epoch [49/50] - Batch loss: 159.1366 - Epoch Loss: 59968.0444 - Avg Loss: 161.6389\n",
            "Epoch [49/50] - Batch loss: 161.3347 - Epoch Loss: 60129.3792 - Avg Loss: 161.6381\n",
            "Epoch [49/50] - Batch loss: 164.0051 - Epoch Loss: 60293.3842 - Avg Loss: 161.6445\n",
            "Epoch [49/50] - Batch loss: 161.2744 - Epoch Loss: 60454.6586 - Avg Loss: 161.6435\n",
            "Epoch [49/50] - Batch loss: 157.9443 - Epoch Loss: 60612.6028 - Avg Loss: 161.6336\n",
            "Epoch [49/50] - Batch loss: 156.1687 - Epoch Loss: 60768.7715 - Avg Loss: 161.6191\n",
            "Epoch [49/50] - Batch loss: 167.1305 - Epoch Loss: 60935.9020 - Avg Loss: 161.6337\n",
            "Epoch [49/50] - Batch loss: 166.7194 - Epoch Loss: 61102.6214 - Avg Loss: 161.6471\n",
            "Epoch [49/50] - Batch loss: 155.3125 - Epoch Loss: 61257.9339 - Avg Loss: 161.6304\n",
            "Epoch [49/50] - Batch loss: 158.7522 - Epoch Loss: 61416.6861 - Avg Loss: 161.6229\n",
            "Epoch [49/50] - Batch loss: 167.8493 - Epoch Loss: 61584.5354 - Avg Loss: 161.6392\n",
            "Epoch [49/50] - Batch loss: 167.8678 - Epoch Loss: 61752.4032 - Avg Loss: 161.6555\n",
            "Epoch [49/50] - Batch loss: 162.6333 - Epoch Loss: 61915.0365 - Avg Loss: 161.6581\n",
            "Epoch [49/50] - Batch loss: 155.6783 - Epoch Loss: 62070.7149 - Avg Loss: 161.6425\n",
            "Epoch [49/50] - Batch loss: 164.9037 - Epoch Loss: 62235.6186 - Avg Loss: 161.6510\n",
            "Epoch [49/50] - Batch loss: 161.7108 - Epoch Loss: 62397.3294 - Avg Loss: 161.6511\n",
            "Epoch [49/50] - Batch loss: 160.6760 - Epoch Loss: 62558.0053 - Avg Loss: 161.6486\n",
            "Epoch [49/50] - Batch loss: 168.0667 - Epoch Loss: 62726.0721 - Avg Loss: 161.6651\n",
            "Epoch [49/50] - Batch loss: 159.0188 - Epoch Loss: 62885.0909 - Avg Loss: 161.6583\n",
            "Epoch [49/50] - Batch loss: 157.9501 - Epoch Loss: 63043.0410 - Avg Loss: 161.6488\n",
            "Epoch [49/50] - Batch loss: 155.1553 - Epoch Loss: 63198.1963 - Avg Loss: 161.6322\n",
            "Epoch [49/50] - Batch loss: 156.3080 - Epoch Loss: 63354.5043 - Avg Loss: 161.6186\n",
            "Epoch [49/50] - Batch loss: 165.8302 - Epoch Loss: 63520.3344 - Avg Loss: 161.6293\n",
            "Epoch [49/50] - Batch loss: 166.3989 - Epoch Loss: 63686.7333 - Avg Loss: 161.6415\n",
            "Epoch [49/50] - Batch loss: 160.9857 - Epoch Loss: 63847.7189 - Avg Loss: 161.6398\n",
            "Epoch [49/50] - Batch loss: 163.0611 - Epoch Loss: 64010.7801 - Avg Loss: 161.6434\n",
            "Epoch [49/50] - Batch loss: 160.6736 - Epoch Loss: 64171.4537 - Avg Loss: 161.6409\n",
            "Epoch [49/50] - Batch loss: 161.0672 - Epoch Loss: 64332.5209 - Avg Loss: 161.6395\n",
            "Epoch [49/50] - Batch loss: 161.6241 - Epoch Loss: 64494.1450 - Avg Loss: 161.6395\n",
            "Epoch [49/50] - Batch loss: 161.0702 - Epoch Loss: 64655.2151 - Avg Loss: 161.6380\n",
            "Epoch [49/50] - Batch loss: 155.5879 - Epoch Loss: 64810.8030 - Avg Loss: 161.6230\n",
            "Epoch [49/50] - Batch loss: 162.2315 - Epoch Loss: 64973.0345 - Avg Loss: 161.6245\n",
            "Epoch [49/50] - Batch loss: 169.1142 - Epoch Loss: 65142.1486 - Avg Loss: 161.6430\n",
            "Epoch [49/50] - Batch loss: 159.2550 - Epoch Loss: 65301.4037 - Avg Loss: 161.6371\n",
            "Epoch [49/50] - Batch loss: 150.7572 - Epoch Loss: 65452.1609 - Avg Loss: 161.6103\n",
            "Epoch [49/50] - Batch loss: 165.9877 - Epoch Loss: 65618.1486 - Avg Loss: 161.6211\n",
            "Epoch [49/50] - Batch loss: 163.3846 - Epoch Loss: 65781.5332 - Avg Loss: 161.6254\n",
            "Epoch [49/50] - Batch loss: 161.1010 - Epoch Loss: 65942.6343 - Avg Loss: 161.6241\n",
            "Epoch [49/50] - Batch loss: 165.6018 - Epoch Loss: 66108.2360 - Avg Loss: 161.6338\n",
            "Epoch [49/50] - Batch loss: 163.2561 - Epoch Loss: 66271.4921 - Avg Loss: 161.6378\n",
            "Epoch [49/50] - Batch loss: 156.2959 - Epoch Loss: 66427.7881 - Avg Loss: 161.6248\n",
            "Epoch [49/50] - Batch loss: 164.7817 - Epoch Loss: 66592.5697 - Avg Loss: 161.6325\n",
            "Epoch [49/50] - Batch loss: 163.7348 - Epoch Loss: 66756.3045 - Avg Loss: 161.6375\n",
            "Epoch [49/50] - Batch loss: 163.2940 - Epoch Loss: 66919.5985 - Avg Loss: 161.6415\n",
            "Epoch [49/50] - Batch loss: 165.4276 - Epoch Loss: 67085.0260 - Avg Loss: 161.6507\n",
            "Epoch [49/50] - Batch loss: 155.8564 - Epoch Loss: 67240.8824 - Avg Loss: 161.6367\n",
            "Epoch [49/50] - Batch loss: 159.3963 - Epoch Loss: 67400.2787 - Avg Loss: 161.6314\n",
            "Epoch [49/50] - Batch loss: 166.3434 - Epoch Loss: 67566.6220 - Avg Loss: 161.6426\n",
            "Epoch [49/50] - Batch loss: 162.0779 - Epoch Loss: 67728.7000 - Avg Loss: 161.6437\n",
            "Epoch [49/50] - Batch loss: 153.9624 - Epoch Loss: 67882.6624 - Avg Loss: 161.6254\n",
            "Epoch [49/50] - Batch loss: 159.2528 - Epoch Loss: 68041.9152 - Avg Loss: 161.6198\n",
            "Epoch [49/50] - Batch loss: 160.4045 - Epoch Loss: 68202.3196 - Avg Loss: 161.6169\n",
            "Epoch [49/50] - Batch loss: 153.8453 - Epoch Loss: 68356.1649 - Avg Loss: 161.5985\n",
            "Epoch [49/50] - Batch loss: 163.6989 - Epoch Loss: 68519.8639 - Avg Loss: 161.6035\n",
            "Epoch [49/50] - Batch loss: 168.3576 - Epoch Loss: 68688.2215 - Avg Loss: 161.6193\n",
            "Epoch [49/50] - Batch loss: 156.3596 - Epoch Loss: 68844.5811 - Avg Loss: 161.6070\n",
            "Epoch [49/50] - Batch loss: 163.4576 - Epoch Loss: 69008.0387 - Avg Loss: 161.6113\n",
            "Epoch [49/50] - Batch loss: 152.7841 - Epoch Loss: 69160.8228 - Avg Loss: 161.5907\n",
            "Epoch [49/50] - Batch loss: 154.0610 - Epoch Loss: 69314.8838 - Avg Loss: 161.5732\n",
            "Epoch [49/50] - Batch loss: 169.3819 - Epoch Loss: 69484.2656 - Avg Loss: 161.5913\n",
            "Epoch [49/50] - Batch loss: 165.1658 - Epoch Loss: 69649.4314 - Avg Loss: 161.5996\n",
            "Epoch [49/50] - Batch loss: 163.6850 - Epoch Loss: 69813.1165 - Avg Loss: 161.6044\n",
            "Epoch [49/50] - Batch loss: 162.8465 - Epoch Loss: 69975.9629 - Avg Loss: 161.6073\n",
            "Epoch [49/50] - Batch loss: 165.1693 - Epoch Loss: 70141.1322 - Avg Loss: 161.6155\n",
            "Epoch [49/50] - Batch loss: 161.3884 - Epoch Loss: 70302.5206 - Avg Loss: 161.6150\n",
            "Epoch [49/50] - Batch loss: 155.6962 - Epoch Loss: 70458.2168 - Avg Loss: 161.6014\n",
            "Epoch [49/50] - Batch loss: 156.2246 - Epoch Loss: 70614.4414 - Avg Loss: 161.5891\n",
            "Epoch [49/50] - Batch loss: 161.3702 - Epoch Loss: 70775.8116 - Avg Loss: 161.5886\n",
            "Epoch [49/50] - Batch loss: 160.5928 - Epoch Loss: 70936.4044 - Avg Loss: 161.5863\n",
            "Epoch [49/50] - Batch loss: 162.9072 - Epoch Loss: 71099.3116 - Avg Loss: 161.5893\n",
            "Epoch [49/50] - Batch loss: 161.9286 - Epoch Loss: 71261.2402 - Avg Loss: 161.5901\n",
            "Epoch [49/50] - Batch loss: 154.6972 - Epoch Loss: 71415.9374 - Avg Loss: 161.5745\n",
            "Epoch [49/50] - Batch loss: 167.8010 - Epoch Loss: 71583.7384 - Avg Loss: 161.5886\n",
            "Epoch [49/50] - Batch loss: 160.6633 - Epoch Loss: 71744.4017 - Avg Loss: 161.5865\n",
            "Epoch [49/50] - Batch loss: 157.0105 - Epoch Loss: 71901.4121 - Avg Loss: 161.5762\n",
            "Epoch [49/50] - Batch loss: 157.4242 - Epoch Loss: 72058.8363 - Avg Loss: 161.5669\n",
            "Epoch [49/50] - Batch loss: 163.5910 - Epoch Loss: 72222.4274 - Avg Loss: 161.5714\n",
            "Epoch [49/50] - Batch loss: 164.7475 - Epoch Loss: 72387.1749 - Avg Loss: 161.5785\n",
            "Epoch [49/50] - Batch loss: 157.2948 - Epoch Loss: 72544.4696 - Avg Loss: 161.5690\n",
            "Epoch [49/50] - Batch loss: 160.1583 - Epoch Loss: 72704.6279 - Avg Loss: 161.5658\n",
            "Epoch [49/50] - Batch loss: 159.6553 - Epoch Loss: 72864.2832 - Avg Loss: 161.5616\n",
            "Epoch [49/50] - Batch loss: 160.8126 - Epoch Loss: 73025.0959 - Avg Loss: 161.5599\n",
            "Epoch [49/50] - Batch loss: 157.7283 - Epoch Loss: 73182.8242 - Avg Loss: 161.5515\n",
            "Epoch [49/50] - Batch loss: 162.6941 - Epoch Loss: 73345.5183 - Avg Loss: 161.5540\n",
            "Epoch [49/50] - Batch loss: 162.5078 - Epoch Loss: 73508.0261 - Avg Loss: 161.5561\n",
            "Epoch [49/50] - Batch loss: 154.1846 - Epoch Loss: 73662.2107 - Avg Loss: 161.5399\n",
            "Epoch [49/50] - Batch loss: 158.5655 - Epoch Loss: 73820.7762 - Avg Loss: 161.5334\n",
            "Epoch [49/50] - Batch loss: 162.8613 - Epoch Loss: 73983.6376 - Avg Loss: 161.5363\n",
            "Epoch [49/50] - Batch loss: 151.4636 - Epoch Loss: 74135.1012 - Avg Loss: 161.5144\n",
            "Epoch [49/50] - Batch loss: 168.6996 - Epoch Loss: 74303.8007 - Avg Loss: 161.5300\n",
            "Epoch [49/50] - Batch loss: 163.1826 - Epoch Loss: 74466.9834 - Avg Loss: 161.5336\n",
            "Epoch [49/50] - Batch loss: 157.1986 - Epoch Loss: 74624.1819 - Avg Loss: 161.5242\n",
            "Epoch [49/50] - Batch loss: 160.1488 - Epoch Loss: 74784.3308 - Avg Loss: 161.5212\n",
            "Epoch [49/50] - Batch loss: 166.4723 - Epoch Loss: 74950.8031 - Avg Loss: 161.5319\n",
            "Epoch [49/50] - Batch loss: 168.5695 - Epoch Loss: 75119.3725 - Avg Loss: 161.5470\n",
            "Epoch [49/50] - Batch loss: 158.1201 - Epoch Loss: 75277.4926 - Avg Loss: 161.5397\n",
            "Epoch [49/50] - Batch loss: 157.7528 - Epoch Loss: 75435.2454 - Avg Loss: 161.5316\n",
            "Epoch [49/50] - Batch loss: 162.8568 - Epoch Loss: 75598.1022 - Avg Loss: 161.5344\n",
            "Epoch [49/50] - Batch loss: 154.0680 - Epoch Loss: 75752.1703 - Avg Loss: 161.5185\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 50/50:   0%|          | 0/469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb7ec754b5fa4f0ea6ea6e24167a2d23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/50] - Batch loss: 163.5560 - Epoch Loss: 163.5560 - Avg Loss: 163.5560\n",
            "Epoch [50/50] - Batch loss: 163.6533 - Epoch Loss: 327.2093 - Avg Loss: 163.6047\n",
            "Epoch [50/50] - Batch loss: 155.6115 - Epoch Loss: 482.8208 - Avg Loss: 160.9403\n",
            "Epoch [50/50] - Batch loss: 162.3163 - Epoch Loss: 645.1371 - Avg Loss: 161.2843\n",
            "Epoch [50/50] - Batch loss: 156.9595 - Epoch Loss: 802.0966 - Avg Loss: 160.4193\n",
            "Epoch [50/50] - Batch loss: 170.4737 - Epoch Loss: 972.5703 - Avg Loss: 162.0950\n",
            "Epoch [50/50] - Batch loss: 157.3401 - Epoch Loss: 1129.9103 - Avg Loss: 161.4158\n",
            "Epoch [50/50] - Batch loss: 162.9554 - Epoch Loss: 1292.8657 - Avg Loss: 161.6082\n",
            "Epoch [50/50] - Batch loss: 157.5095 - Epoch Loss: 1450.3752 - Avg Loss: 161.1528\n",
            "Epoch [50/50] - Batch loss: 165.7350 - Epoch Loss: 1616.1102 - Avg Loss: 161.6110\n",
            "Epoch [50/50] - Batch loss: 158.2775 - Epoch Loss: 1774.3876 - Avg Loss: 161.3080\n",
            "Epoch [50/50] - Batch loss: 159.0066 - Epoch Loss: 1933.3942 - Avg Loss: 161.1162\n",
            "Epoch [50/50] - Batch loss: 155.6928 - Epoch Loss: 2089.0870 - Avg Loss: 160.6990\n",
            "Epoch [50/50] - Batch loss: 163.1995 - Epoch Loss: 2252.2865 - Avg Loss: 160.8776\n",
            "Epoch [50/50] - Batch loss: 152.7572 - Epoch Loss: 2405.0437 - Avg Loss: 160.3362\n",
            "Epoch [50/50] - Batch loss: 155.5346 - Epoch Loss: 2560.5784 - Avg Loss: 160.0361\n",
            "Epoch [50/50] - Batch loss: 154.2521 - Epoch Loss: 2714.8305 - Avg Loss: 159.6959\n",
            "Epoch [50/50] - Batch loss: 161.4735 - Epoch Loss: 2876.3040 - Avg Loss: 159.7947\n",
            "Epoch [50/50] - Batch loss: 160.7351 - Epoch Loss: 3037.0391 - Avg Loss: 159.8442\n",
            "Epoch [50/50] - Batch loss: 156.9167 - Epoch Loss: 3193.9559 - Avg Loss: 159.6978\n",
            "Epoch [50/50] - Batch loss: 158.2329 - Epoch Loss: 3352.1887 - Avg Loss: 159.6280\n",
            "Epoch [50/50] - Batch loss: 162.9922 - Epoch Loss: 3515.1809 - Avg Loss: 159.7810\n",
            "Epoch [50/50] - Batch loss: 160.4440 - Epoch Loss: 3675.6250 - Avg Loss: 159.8098\n",
            "Epoch [50/50] - Batch loss: 160.2021 - Epoch Loss: 3835.8271 - Avg Loss: 159.8261\n",
            "Epoch [50/50] - Batch loss: 155.0061 - Epoch Loss: 3990.8332 - Avg Loss: 159.6333\n",
            "Epoch [50/50] - Batch loss: 162.2103 - Epoch Loss: 4153.0435 - Avg Loss: 159.7324\n",
            "Epoch [50/50] - Batch loss: 168.0609 - Epoch Loss: 4321.1043 - Avg Loss: 160.0409\n",
            "Epoch [50/50] - Batch loss: 159.9069 - Epoch Loss: 4481.0113 - Avg Loss: 160.0361\n",
            "Epoch [50/50] - Batch loss: 156.6271 - Epoch Loss: 4637.6384 - Avg Loss: 159.9186\n",
            "Epoch [50/50] - Batch loss: 159.4346 - Epoch Loss: 4797.0730 - Avg Loss: 159.9024\n",
            "Epoch [50/50] - Batch loss: 164.9782 - Epoch Loss: 4962.0513 - Avg Loss: 160.0662\n",
            "Epoch [50/50] - Batch loss: 155.1553 - Epoch Loss: 5117.2065 - Avg Loss: 159.9127\n",
            "Epoch [50/50] - Batch loss: 162.0591 - Epoch Loss: 5279.2656 - Avg Loss: 159.9777\n",
            "Epoch [50/50] - Batch loss: 155.2219 - Epoch Loss: 5434.4875 - Avg Loss: 159.8379\n",
            "Epoch [50/50] - Batch loss: 157.8094 - Epoch Loss: 5592.2969 - Avg Loss: 159.7799\n",
            "Epoch [50/50] - Batch loss: 159.3715 - Epoch Loss: 5751.6684 - Avg Loss: 159.7686\n",
            "Epoch [50/50] - Batch loss: 160.1689 - Epoch Loss: 5911.8372 - Avg Loss: 159.7794\n",
            "Epoch [50/50] - Batch loss: 161.5260 - Epoch Loss: 6073.3632 - Avg Loss: 159.8253\n",
            "Epoch [50/50] - Batch loss: 152.8248 - Epoch Loss: 6226.1880 - Avg Loss: 159.6458\n",
            "Epoch [50/50] - Batch loss: 163.7969 - Epoch Loss: 6389.9849 - Avg Loss: 159.7496\n",
            "Epoch [50/50] - Batch loss: 153.7086 - Epoch Loss: 6543.6936 - Avg Loss: 159.6023\n",
            "Epoch [50/50] - Batch loss: 164.0998 - Epoch Loss: 6707.7934 - Avg Loss: 159.7094\n",
            "Epoch [50/50] - Batch loss: 160.2640 - Epoch Loss: 6868.0574 - Avg Loss: 159.7223\n",
            "Epoch [50/50] - Batch loss: 158.5050 - Epoch Loss: 7026.5624 - Avg Loss: 159.6946\n",
            "Epoch [50/50] - Batch loss: 158.6281 - Epoch Loss: 7185.1905 - Avg Loss: 159.6709\n",
            "Epoch [50/50] - Batch loss: 149.3165 - Epoch Loss: 7334.5071 - Avg Loss: 159.4458\n",
            "Epoch [50/50] - Batch loss: 158.1485 - Epoch Loss: 7492.6556 - Avg Loss: 159.4182\n",
            "Epoch [50/50] - Batch loss: 170.3025 - Epoch Loss: 7662.9581 - Avg Loss: 159.6450\n",
            "Epoch [50/50] - Batch loss: 162.0207 - Epoch Loss: 7824.9788 - Avg Loss: 159.6934\n",
            "Epoch [50/50] - Batch loss: 163.7697 - Epoch Loss: 7988.7485 - Avg Loss: 159.7750\n",
            "Epoch [50/50] - Batch loss: 153.9530 - Epoch Loss: 8142.7015 - Avg Loss: 159.6608\n",
            "Epoch [50/50] - Batch loss: 158.9222 - Epoch Loss: 8301.6236 - Avg Loss: 159.6466\n",
            "Epoch [50/50] - Batch loss: 157.3793 - Epoch Loss: 8459.0029 - Avg Loss: 159.6038\n",
            "Epoch [50/50] - Batch loss: 160.2968 - Epoch Loss: 8619.2997 - Avg Loss: 159.6167\n",
            "Epoch [50/50] - Batch loss: 156.6777 - Epoch Loss: 8775.9775 - Avg Loss: 159.5632\n",
            "Epoch [50/50] - Batch loss: 152.7985 - Epoch Loss: 8928.7759 - Avg Loss: 159.4424\n",
            "Epoch [50/50] - Batch loss: 152.5724 - Epoch Loss: 9081.3484 - Avg Loss: 159.3219\n",
            "Epoch [50/50] - Batch loss: 165.6875 - Epoch Loss: 9247.0359 - Avg Loss: 159.4317\n",
            "Epoch [50/50] - Batch loss: 161.2632 - Epoch Loss: 9408.2991 - Avg Loss: 159.4627\n",
            "Epoch [50/50] - Batch loss: 161.3996 - Epoch Loss: 9569.6987 - Avg Loss: 159.4950\n",
            "Epoch [50/50] - Batch loss: 151.5983 - Epoch Loss: 9721.2969 - Avg Loss: 159.3655\n",
            "Epoch [50/50] - Batch loss: 160.9012 - Epoch Loss: 9882.1981 - Avg Loss: 159.3903\n",
            "Epoch [50/50] - Batch loss: 157.7867 - Epoch Loss: 10039.9848 - Avg Loss: 159.3648\n",
            "Epoch [50/50] - Batch loss: 163.9300 - Epoch Loss: 10203.9147 - Avg Loss: 159.4362\n",
            "Epoch [50/50] - Batch loss: 159.3799 - Epoch Loss: 10363.2946 - Avg Loss: 159.4353\n",
            "Epoch [50/50] - Batch loss: 158.7141 - Epoch Loss: 10522.0087 - Avg Loss: 159.4244\n",
            "Epoch [50/50] - Batch loss: 154.8604 - Epoch Loss: 10676.8691 - Avg Loss: 159.3563\n",
            "Epoch [50/50] - Batch loss: 149.3209 - Epoch Loss: 10826.1900 - Avg Loss: 159.2087\n",
            "Epoch [50/50] - Batch loss: 162.5703 - Epoch Loss: 10988.7603 - Avg Loss: 159.2574\n",
            "Epoch [50/50] - Batch loss: 156.5909 - Epoch Loss: 11145.3512 - Avg Loss: 159.2193\n",
            "Epoch [50/50] - Batch loss: 160.1913 - Epoch Loss: 11305.5424 - Avg Loss: 159.2330\n",
            "Epoch [50/50] - Batch loss: 156.5103 - Epoch Loss: 11462.0527 - Avg Loss: 159.1952\n",
            "Epoch [50/50] - Batch loss: 161.6272 - Epoch Loss: 11623.6799 - Avg Loss: 159.2285\n",
            "Epoch [50/50] - Batch loss: 157.4105 - Epoch Loss: 11781.0904 - Avg Loss: 159.2039\n",
            "Epoch [50/50] - Batch loss: 156.2618 - Epoch Loss: 11937.3522 - Avg Loss: 159.1647\n",
            "Epoch [50/50] - Batch loss: 157.1868 - Epoch Loss: 12094.5389 - Avg Loss: 159.1387\n",
            "Epoch [50/50] - Batch loss: 156.8188 - Epoch Loss: 12251.3577 - Avg Loss: 159.1085\n",
            "Epoch [50/50] - Batch loss: 153.8070 - Epoch Loss: 12405.1647 - Avg Loss: 159.0406\n",
            "Epoch [50/50] - Batch loss: 157.9715 - Epoch Loss: 12563.1362 - Avg Loss: 159.0270\n",
            "Epoch [50/50] - Batch loss: 162.9279 - Epoch Loss: 12726.0641 - Avg Loss: 159.0758\n",
            "Epoch [50/50] - Batch loss: 165.2902 - Epoch Loss: 12891.3544 - Avg Loss: 159.1525\n",
            "Epoch [50/50] - Batch loss: 162.0978 - Epoch Loss: 13053.4522 - Avg Loss: 159.1884\n",
            "Epoch [50/50] - Batch loss: 160.7186 - Epoch Loss: 13214.1707 - Avg Loss: 159.2069\n",
            "Epoch [50/50] - Batch loss: 164.0369 - Epoch Loss: 13378.2077 - Avg Loss: 159.2644\n",
            "Epoch [50/50] - Batch loss: 159.5614 - Epoch Loss: 13537.7690 - Avg Loss: 159.2679\n",
            "Epoch [50/50] - Batch loss: 155.9636 - Epoch Loss: 13693.7326 - Avg Loss: 159.2294\n",
            "Epoch [50/50] - Batch loss: 164.5934 - Epoch Loss: 13858.3261 - Avg Loss: 159.2911\n",
            "Epoch [50/50] - Batch loss: 158.7081 - Epoch Loss: 14017.0342 - Avg Loss: 159.2845\n",
            "Epoch [50/50] - Batch loss: 159.0523 - Epoch Loss: 14176.0865 - Avg Loss: 159.2819\n",
            "Epoch [50/50] - Batch loss: 163.5996 - Epoch Loss: 14339.6860 - Avg Loss: 159.3298\n",
            "Epoch [50/50] - Batch loss: 161.2254 - Epoch Loss: 14500.9115 - Avg Loss: 159.3507\n",
            "Epoch [50/50] - Batch loss: 160.0059 - Epoch Loss: 14660.9174 - Avg Loss: 159.3578\n",
            "Epoch [50/50] - Batch loss: 151.5141 - Epoch Loss: 14812.4315 - Avg Loss: 159.2735\n",
            "Epoch [50/50] - Batch loss: 152.7967 - Epoch Loss: 14965.2282 - Avg Loss: 159.2046\n",
            "Epoch [50/50] - Batch loss: 160.2585 - Epoch Loss: 15125.4868 - Avg Loss: 159.2157\n",
            "Epoch [50/50] - Batch loss: 158.1252 - Epoch Loss: 15283.6120 - Avg Loss: 159.2043\n",
            "Epoch [50/50] - Batch loss: 154.7382 - Epoch Loss: 15438.3502 - Avg Loss: 159.1582\n",
            "Epoch [50/50] - Batch loss: 164.6736 - Epoch Loss: 15603.0238 - Avg Loss: 159.2145\n",
            "Epoch [50/50] - Batch loss: 161.7092 - Epoch Loss: 15764.7330 - Avg Loss: 159.2397\n",
            "Epoch [50/50] - Batch loss: 151.1314 - Epoch Loss: 15915.8644 - Avg Loss: 159.1586\n",
            "Epoch [50/50] - Batch loss: 155.0593 - Epoch Loss: 16070.9237 - Avg Loss: 159.1181\n",
            "Epoch [50/50] - Batch loss: 158.1863 - Epoch Loss: 16229.1100 - Avg Loss: 159.1089\n",
            "Epoch [50/50] - Batch loss: 158.3490 - Epoch Loss: 16387.4589 - Avg Loss: 159.1015\n",
            "Epoch [50/50] - Batch loss: 167.9263 - Epoch Loss: 16555.3853 - Avg Loss: 159.1864\n",
            "Epoch [50/50] - Batch loss: 153.2544 - Epoch Loss: 16708.6397 - Avg Loss: 159.1299\n",
            "Epoch [50/50] - Batch loss: 158.9804 - Epoch Loss: 16867.6201 - Avg Loss: 159.1285\n",
            "Epoch [50/50] - Batch loss: 165.2817 - Epoch Loss: 17032.9019 - Avg Loss: 159.1860\n",
            "Epoch [50/50] - Batch loss: 160.0820 - Epoch Loss: 17192.9838 - Avg Loss: 159.1943\n",
            "Epoch [50/50] - Batch loss: 168.4197 - Epoch Loss: 17361.4035 - Avg Loss: 159.2789\n",
            "Epoch [50/50] - Batch loss: 158.4656 - Epoch Loss: 17519.8691 - Avg Loss: 159.2715\n",
            "Epoch [50/50] - Batch loss: 160.4854 - Epoch Loss: 17680.3545 - Avg Loss: 159.2825\n",
            "Epoch [50/50] - Batch loss: 155.3965 - Epoch Loss: 17835.7510 - Avg Loss: 159.2478\n",
            "Epoch [50/50] - Batch loss: 157.7345 - Epoch Loss: 17993.4855 - Avg Loss: 159.2344\n",
            "Epoch [50/50] - Batch loss: 162.4412 - Epoch Loss: 18155.9268 - Avg Loss: 159.2625\n",
            "Epoch [50/50] - Batch loss: 154.9937 - Epoch Loss: 18310.9205 - Avg Loss: 159.2254\n",
            "Epoch [50/50] - Batch loss: 156.0866 - Epoch Loss: 18467.0071 - Avg Loss: 159.1983\n",
            "Epoch [50/50] - Batch loss: 152.0176 - Epoch Loss: 18619.0247 - Avg Loss: 159.1370\n",
            "Epoch [50/50] - Batch loss: 155.6688 - Epoch Loss: 18774.6935 - Avg Loss: 159.1076\n",
            "Epoch [50/50] - Batch loss: 154.1479 - Epoch Loss: 18928.8414 - Avg Loss: 159.0659\n",
            "Epoch [50/50] - Batch loss: 162.2500 - Epoch Loss: 19091.0915 - Avg Loss: 159.0924\n",
            "Epoch [50/50] - Batch loss: 153.4641 - Epoch Loss: 19244.5556 - Avg Loss: 159.0459\n",
            "Epoch [50/50] - Batch loss: 152.6031 - Epoch Loss: 19397.1587 - Avg Loss: 158.9931\n",
            "Epoch [50/50] - Batch loss: 161.1743 - Epoch Loss: 19558.3330 - Avg Loss: 159.0108\n",
            "Epoch [50/50] - Batch loss: 157.6556 - Epoch Loss: 19715.9886 - Avg Loss: 158.9999\n",
            "Epoch [50/50] - Batch loss: 161.9004 - Epoch Loss: 19877.8890 - Avg Loss: 159.0231\n",
            "Epoch [50/50] - Batch loss: 157.9402 - Epoch Loss: 20035.8293 - Avg Loss: 159.0145\n",
            "Epoch [50/50] - Batch loss: 153.4143 - Epoch Loss: 20189.2435 - Avg Loss: 158.9704\n",
            "Epoch [50/50] - Batch loss: 156.3012 - Epoch Loss: 20345.5447 - Avg Loss: 158.9496\n",
            "Epoch [50/50] - Batch loss: 145.8356 - Epoch Loss: 20491.3803 - Avg Loss: 158.8479\n",
            "Epoch [50/50] - Batch loss: 157.7384 - Epoch Loss: 20649.1187 - Avg Loss: 158.8394\n",
            "Epoch [50/50] - Batch loss: 161.8884 - Epoch Loss: 20811.0070 - Avg Loss: 158.8626\n",
            "Epoch [50/50] - Batch loss: 159.2560 - Epoch Loss: 20970.2630 - Avg Loss: 158.8656\n",
            "Epoch [50/50] - Batch loss: 153.9449 - Epoch Loss: 21124.2079 - Avg Loss: 158.8286\n",
            "Epoch [50/50] - Batch loss: 160.2979 - Epoch Loss: 21284.5058 - Avg Loss: 158.8396\n",
            "Epoch [50/50] - Batch loss: 158.9388 - Epoch Loss: 21443.4446 - Avg Loss: 158.8403\n",
            "Epoch [50/50] - Batch loss: 154.0202 - Epoch Loss: 21597.4647 - Avg Loss: 158.8049\n",
            "Epoch [50/50] - Batch loss: 163.0063 - Epoch Loss: 21760.4710 - Avg Loss: 158.8356\n",
            "Epoch [50/50] - Batch loss: 157.3852 - Epoch Loss: 21917.8562 - Avg Loss: 158.8250\n",
            "Epoch [50/50] - Batch loss: 164.7591 - Epoch Loss: 22082.6153 - Avg Loss: 158.8677\n",
            "Epoch [50/50] - Batch loss: 156.6233 - Epoch Loss: 22239.2386 - Avg Loss: 158.8517\n",
            "Epoch [50/50] - Batch loss: 162.1928 - Epoch Loss: 22401.4314 - Avg Loss: 158.8754\n",
            "Epoch [50/50] - Batch loss: 154.6542 - Epoch Loss: 22556.0856 - Avg Loss: 158.8457\n",
            "Epoch [50/50] - Batch loss: 142.8340 - Epoch Loss: 22698.9196 - Avg Loss: 158.7337\n",
            "Epoch [50/50] - Batch loss: 156.1754 - Epoch Loss: 22855.0951 - Avg Loss: 158.7159\n",
            "Epoch [50/50] - Batch loss: 167.6329 - Epoch Loss: 23022.7280 - Avg Loss: 158.7774\n",
            "Epoch [50/50] - Batch loss: 160.1500 - Epoch Loss: 23182.8780 - Avg Loss: 158.7868\n",
            "Epoch [50/50] - Batch loss: 158.5278 - Epoch Loss: 23341.4058 - Avg Loss: 158.7851\n",
            "Epoch [50/50] - Batch loss: 165.4583 - Epoch Loss: 23506.8640 - Avg Loss: 158.8302\n",
            "Epoch [50/50] - Batch loss: 160.3706 - Epoch Loss: 23667.2346 - Avg Loss: 158.8405\n",
            "Epoch [50/50] - Batch loss: 165.2187 - Epoch Loss: 23832.4533 - Avg Loss: 158.8830\n",
            "Epoch [50/50] - Batch loss: 165.4294 - Epoch Loss: 23997.8827 - Avg Loss: 158.9264\n",
            "Epoch [50/50] - Batch loss: 146.1777 - Epoch Loss: 24144.0605 - Avg Loss: 158.8425\n",
            "Epoch [50/50] - Batch loss: 144.2559 - Epoch Loss: 24288.3164 - Avg Loss: 158.7472\n",
            "Epoch [50/50] - Batch loss: 151.4960 - Epoch Loss: 24439.8124 - Avg Loss: 158.7001\n",
            "Epoch [50/50] - Batch loss: 165.1730 - Epoch Loss: 24604.9855 - Avg Loss: 158.7418\n",
            "Epoch [50/50] - Batch loss: 167.7807 - Epoch Loss: 24772.7661 - Avg Loss: 158.7998\n",
            "Epoch [50/50] - Batch loss: 156.0794 - Epoch Loss: 24928.8455 - Avg Loss: 158.7825\n",
            "Epoch [50/50] - Batch loss: 161.1403 - Epoch Loss: 25089.9858 - Avg Loss: 158.7974\n",
            "Epoch [50/50] - Batch loss: 161.9017 - Epoch Loss: 25251.8875 - Avg Loss: 158.8169\n",
            "Epoch [50/50] - Batch loss: 161.3804 - Epoch Loss: 25413.2679 - Avg Loss: 158.8329\n",
            "Epoch [50/50] - Batch loss: 162.3369 - Epoch Loss: 25575.6048 - Avg Loss: 158.8547\n",
            "Epoch [50/50] - Batch loss: 152.9180 - Epoch Loss: 25728.5228 - Avg Loss: 158.8180\n",
            "Epoch [50/50] - Batch loss: 153.8219 - Epoch Loss: 25882.3448 - Avg Loss: 158.7874\n",
            "Epoch [50/50] - Batch loss: 166.7262 - Epoch Loss: 26049.0709 - Avg Loss: 158.8358\n",
            "Epoch [50/50] - Batch loss: 162.4343 - Epoch Loss: 26211.5053 - Avg Loss: 158.8576\n",
            "Epoch [50/50] - Batch loss: 155.7726 - Epoch Loss: 26367.2779 - Avg Loss: 158.8390\n",
            "Epoch [50/50] - Batch loss: 157.6709 - Epoch Loss: 26524.9488 - Avg Loss: 158.8320\n",
            "Epoch [50/50] - Batch loss: 169.4858 - Epoch Loss: 26694.4346 - Avg Loss: 158.8954\n",
            "Epoch [50/50] - Batch loss: 163.3566 - Epoch Loss: 26857.7912 - Avg Loss: 158.9218\n",
            "Epoch [50/50] - Batch loss: 160.2833 - Epoch Loss: 27018.0745 - Avg Loss: 158.9298\n",
            "Epoch [50/50] - Batch loss: 155.5723 - Epoch Loss: 27173.6467 - Avg Loss: 158.9102\n",
            "Epoch [50/50] - Batch loss: 157.8595 - Epoch Loss: 27331.5062 - Avg Loss: 158.9041\n",
            "Epoch [50/50] - Batch loss: 162.2034 - Epoch Loss: 27493.7095 - Avg Loss: 158.9232\n",
            "Epoch [50/50] - Batch loss: 157.1223 - Epoch Loss: 27650.8318 - Avg Loss: 158.9128\n",
            "Epoch [50/50] - Batch loss: 161.7803 - Epoch Loss: 27812.6121 - Avg Loss: 158.9292\n",
            "Epoch [50/50] - Batch loss: 154.6977 - Epoch Loss: 27967.3098 - Avg Loss: 158.9052\n",
            "Epoch [50/50] - Batch loss: 160.3670 - Epoch Loss: 28127.6768 - Avg Loss: 158.9134\n",
            "Epoch [50/50] - Batch loss: 155.8120 - Epoch Loss: 28283.4888 - Avg Loss: 158.8960\n",
            "Epoch [50/50] - Batch loss: 160.4881 - Epoch Loss: 28443.9769 - Avg Loss: 158.9049\n",
            "Epoch [50/50] - Batch loss: 158.1824 - Epoch Loss: 28602.1593 - Avg Loss: 158.9009\n",
            "Epoch [50/50] - Batch loss: 150.9526 - Epoch Loss: 28753.1120 - Avg Loss: 158.8570\n",
            "Epoch [50/50] - Batch loss: 160.3582 - Epoch Loss: 28913.4702 - Avg Loss: 158.8652\n",
            "Epoch [50/50] - Batch loss: 161.0117 - Epoch Loss: 29074.4818 - Avg Loss: 158.8769\n",
            "Epoch [50/50] - Batch loss: 164.8194 - Epoch Loss: 29239.3012 - Avg Loss: 158.9092\n",
            "Epoch [50/50] - Batch loss: 162.4117 - Epoch Loss: 29401.7130 - Avg Loss: 158.9282\n",
            "Epoch [50/50] - Batch loss: 160.5424 - Epoch Loss: 29562.2554 - Avg Loss: 158.9369\n",
            "Epoch [50/50] - Batch loss: 154.3021 - Epoch Loss: 29716.5575 - Avg Loss: 158.9121\n",
            "Epoch [50/50] - Batch loss: 162.8757 - Epoch Loss: 29879.4333 - Avg Loss: 158.9332\n",
            "Epoch [50/50] - Batch loss: 162.1043 - Epoch Loss: 30041.5376 - Avg Loss: 158.9499\n",
            "Epoch [50/50] - Batch loss: 161.4946 - Epoch Loss: 30203.0323 - Avg Loss: 158.9633\n",
            "Epoch [50/50] - Batch loss: 152.1716 - Epoch Loss: 30355.2039 - Avg Loss: 158.9278\n",
            "Epoch [50/50] - Batch loss: 157.7484 - Epoch Loss: 30512.9523 - Avg Loss: 158.9216\n",
            "Epoch [50/50] - Batch loss: 162.3007 - Epoch Loss: 30675.2530 - Avg Loss: 158.9391\n",
            "Epoch [50/50] - Batch loss: 163.8529 - Epoch Loss: 30839.1059 - Avg Loss: 158.9645\n",
            "Epoch [50/50] - Batch loss: 151.0941 - Epoch Loss: 30990.2000 - Avg Loss: 158.9241\n",
            "Epoch [50/50] - Batch loss: 166.5757 - Epoch Loss: 31156.7757 - Avg Loss: 158.9631\n",
            "Epoch [50/50] - Batch loss: 154.6262 - Epoch Loss: 31311.4019 - Avg Loss: 158.9411\n",
            "Epoch [50/50] - Batch loss: 155.0764 - Epoch Loss: 31466.4783 - Avg Loss: 158.9216\n",
            "Epoch [50/50] - Batch loss: 161.7819 - Epoch Loss: 31628.2602 - Avg Loss: 158.9360\n",
            "Epoch [50/50] - Batch loss: 162.2243 - Epoch Loss: 31790.4845 - Avg Loss: 158.9524\n",
            "Epoch [50/50] - Batch loss: 162.3480 - Epoch Loss: 31952.8326 - Avg Loss: 158.9693\n",
            "Epoch [50/50] - Batch loss: 158.0490 - Epoch Loss: 32110.8816 - Avg Loss: 158.9648\n",
            "Epoch [50/50] - Batch loss: 153.5998 - Epoch Loss: 32264.4814 - Avg Loss: 158.9383\n",
            "Epoch [50/50] - Batch loss: 166.9593 - Epoch Loss: 32431.4407 - Avg Loss: 158.9777\n",
            "Epoch [50/50] - Batch loss: 157.8741 - Epoch Loss: 32589.3148 - Avg Loss: 158.9723\n",
            "Epoch [50/50] - Batch loss: 155.0614 - Epoch Loss: 32744.3763 - Avg Loss: 158.9533\n",
            "Epoch [50/50] - Batch loss: 170.3605 - Epoch Loss: 32914.7367 - Avg Loss: 159.0084\n",
            "Epoch [50/50] - Batch loss: 160.3076 - Epoch Loss: 33075.0443 - Avg Loss: 159.0146\n",
            "Epoch [50/50] - Batch loss: 160.4630 - Epoch Loss: 33235.5073 - Avg Loss: 159.0216\n",
            "Epoch [50/50] - Batch loss: 161.0168 - Epoch Loss: 33396.5242 - Avg Loss: 159.0311\n",
            "Epoch [50/50] - Batch loss: 155.9263 - Epoch Loss: 33552.4504 - Avg Loss: 159.0164\n",
            "Epoch [50/50] - Batch loss: 161.1748 - Epoch Loss: 33713.6252 - Avg Loss: 159.0265\n",
            "Epoch [50/50] - Batch loss: 152.4402 - Epoch Loss: 33866.0654 - Avg Loss: 158.9956\n",
            "Epoch [50/50] - Batch loss: 158.2973 - Epoch Loss: 34024.3626 - Avg Loss: 158.9923\n",
            "Epoch [50/50] - Batch loss: 157.4318 - Epoch Loss: 34181.7945 - Avg Loss: 158.9851\n",
            "Epoch [50/50] - Batch loss: 161.9297 - Epoch Loss: 34343.7242 - Avg Loss: 158.9987\n",
            "Epoch [50/50] - Batch loss: 161.7107 - Epoch Loss: 34505.4350 - Avg Loss: 159.0112\n",
            "Epoch [50/50] - Batch loss: 153.2632 - Epoch Loss: 34658.6982 - Avg Loss: 158.9849\n",
            "Epoch [50/50] - Batch loss: 157.1893 - Epoch Loss: 34815.8875 - Avg Loss: 158.9767\n",
            "Epoch [50/50] - Batch loss: 158.0871 - Epoch Loss: 34973.9746 - Avg Loss: 158.9726\n",
            "Epoch [50/50] - Batch loss: 158.9821 - Epoch Loss: 35132.9567 - Avg Loss: 158.9727\n",
            "Epoch [50/50] - Batch loss: 162.7171 - Epoch Loss: 35295.6738 - Avg Loss: 158.9895\n",
            "Epoch [50/50] - Batch loss: 151.6624 - Epoch Loss: 35447.3362 - Avg Loss: 158.9567\n",
            "Epoch [50/50] - Batch loss: 162.7621 - Epoch Loss: 35610.0982 - Avg Loss: 158.9737\n",
            "Epoch [50/50] - Batch loss: 153.7944 - Epoch Loss: 35763.8926 - Avg Loss: 158.9506\n",
            "Epoch [50/50] - Batch loss: 152.6369 - Epoch Loss: 35916.5295 - Avg Loss: 158.9227\n",
            "Epoch [50/50] - Batch loss: 163.1548 - Epoch Loss: 36079.6843 - Avg Loss: 158.9413\n",
            "Epoch [50/50] - Batch loss: 155.8976 - Epoch Loss: 36235.5820 - Avg Loss: 158.9280\n",
            "Epoch [50/50] - Batch loss: 159.7268 - Epoch Loss: 36395.3087 - Avg Loss: 158.9315\n",
            "Epoch [50/50] - Batch loss: 164.2156 - Epoch Loss: 36559.5243 - Avg Loss: 158.9545\n",
            "Epoch [50/50] - Batch loss: 165.0420 - Epoch Loss: 36724.5664 - Avg Loss: 158.9808\n",
            "Epoch [50/50] - Batch loss: 161.3838 - Epoch Loss: 36885.9502 - Avg Loss: 158.9912\n",
            "Epoch [50/50] - Batch loss: 155.2079 - Epoch Loss: 37041.1581 - Avg Loss: 158.9749\n",
            "Epoch [50/50] - Batch loss: 157.9887 - Epoch Loss: 37199.1468 - Avg Loss: 158.9707\n",
            "Epoch [50/50] - Batch loss: 161.6892 - Epoch Loss: 37360.8360 - Avg Loss: 158.9823\n",
            "Epoch [50/50] - Batch loss: 160.5464 - Epoch Loss: 37521.3823 - Avg Loss: 158.9889\n",
            "Epoch [50/50] - Batch loss: 159.1334 - Epoch Loss: 37680.5157 - Avg Loss: 158.9895\n",
            "Epoch [50/50] - Batch loss: 159.6339 - Epoch Loss: 37840.1496 - Avg Loss: 158.9922\n",
            "Epoch [50/50] - Batch loss: 159.5019 - Epoch Loss: 37999.6514 - Avg Loss: 158.9944\n",
            "Epoch [50/50] - Batch loss: 151.8813 - Epoch Loss: 38151.5327 - Avg Loss: 158.9647\n",
            "Epoch [50/50] - Batch loss: 153.7463 - Epoch Loss: 38305.2791 - Avg Loss: 158.9431\n",
            "Epoch [50/50] - Batch loss: 158.5889 - Epoch Loss: 38463.8679 - Avg Loss: 158.9416\n",
            "Epoch [50/50] - Batch loss: 160.5570 - Epoch Loss: 38624.4249 - Avg Loss: 158.9483\n",
            "Epoch [50/50] - Batch loss: 160.0798 - Epoch Loss: 38784.5048 - Avg Loss: 158.9529\n",
            "Epoch [50/50] - Batch loss: 152.0252 - Epoch Loss: 38936.5300 - Avg Loss: 158.9246\n",
            "Epoch [50/50] - Batch loss: 158.0574 - Epoch Loss: 39094.5874 - Avg Loss: 158.9211\n",
            "Epoch [50/50] - Batch loss: 159.6251 - Epoch Loss: 39254.2125 - Avg Loss: 158.9239\n",
            "Epoch [50/50] - Batch loss: 160.4616 - Epoch Loss: 39414.6741 - Avg Loss: 158.9301\n",
            "Epoch [50/50] - Batch loss: 160.6716 - Epoch Loss: 39575.3457 - Avg Loss: 158.9371\n",
            "Epoch [50/50] - Batch loss: 163.5396 - Epoch Loss: 39738.8853 - Avg Loss: 158.9555\n",
            "Epoch [50/50] - Batch loss: 156.0948 - Epoch Loss: 39894.9801 - Avg Loss: 158.9441\n",
            "Epoch [50/50] - Batch loss: 154.0564 - Epoch Loss: 40049.0365 - Avg Loss: 158.9247\n",
            "Epoch [50/50] - Batch loss: 165.6729 - Epoch Loss: 40214.7094 - Avg Loss: 158.9514\n",
            "Epoch [50/50] - Batch loss: 162.6810 - Epoch Loss: 40377.3903 - Avg Loss: 158.9661\n",
            "Epoch [50/50] - Batch loss: 162.1303 - Epoch Loss: 40539.5206 - Avg Loss: 158.9785\n",
            "Epoch [50/50] - Batch loss: 161.8365 - Epoch Loss: 40701.3571 - Avg Loss: 158.9897\n",
            "Epoch [50/50] - Batch loss: 154.2960 - Epoch Loss: 40855.6530 - Avg Loss: 158.9714\n",
            "Epoch [50/50] - Batch loss: 156.4953 - Epoch Loss: 41012.1484 - Avg Loss: 158.9618\n",
            "Epoch [50/50] - Batch loss: 164.0463 - Epoch Loss: 41176.1946 - Avg Loss: 158.9814\n",
            "Epoch [50/50] - Batch loss: 160.7868 - Epoch Loss: 41336.9815 - Avg Loss: 158.9884\n",
            "Epoch [50/50] - Batch loss: 157.5737 - Epoch Loss: 41494.5552 - Avg Loss: 158.9830\n",
            "Epoch [50/50] - Batch loss: 159.8432 - Epoch Loss: 41654.3983 - Avg Loss: 158.9863\n",
            "Epoch [50/50] - Batch loss: 155.3726 - Epoch Loss: 41809.7710 - Avg Loss: 158.9725\n",
            "Epoch [50/50] - Batch loss: 162.8869 - Epoch Loss: 41972.6579 - Avg Loss: 158.9873\n",
            "Epoch [50/50] - Batch loss: 154.5222 - Epoch Loss: 42127.1800 - Avg Loss: 158.9705\n",
            "Epoch [50/50] - Batch loss: 153.0987 - Epoch Loss: 42280.2787 - Avg Loss: 158.9484\n",
            "Epoch [50/50] - Batch loss: 162.5878 - Epoch Loss: 42442.8665 - Avg Loss: 158.9620\n",
            "Epoch [50/50] - Batch loss: 166.5168 - Epoch Loss: 42609.3833 - Avg Loss: 158.9902\n",
            "Epoch [50/50] - Batch loss: 160.6705 - Epoch Loss: 42770.0537 - Avg Loss: 158.9965\n",
            "Epoch [50/50] - Batch loss: 157.1647 - Epoch Loss: 42927.2184 - Avg Loss: 158.9897\n",
            "Epoch [50/50] - Batch loss: 160.1685 - Epoch Loss: 43087.3870 - Avg Loss: 158.9940\n",
            "Epoch [50/50] - Batch loss: 159.6211 - Epoch Loss: 43247.0081 - Avg Loss: 158.9964\n",
            "Epoch [50/50] - Batch loss: 167.4939 - Epoch Loss: 43414.5020 - Avg Loss: 159.0275\n",
            "Epoch [50/50] - Batch loss: 155.6226 - Epoch Loss: 43570.1246 - Avg Loss: 159.0151\n",
            "Epoch [50/50] - Batch loss: 155.9653 - Epoch Loss: 43726.0899 - Avg Loss: 159.0040\n",
            "Epoch [50/50] - Batch loss: 150.2040 - Epoch Loss: 43876.2939 - Avg Loss: 158.9721\n",
            "Epoch [50/50] - Batch loss: 170.0134 - Epoch Loss: 44046.3073 - Avg Loss: 159.0119\n",
            "Epoch [50/50] - Batch loss: 155.5596 - Epoch Loss: 44201.8669 - Avg Loss: 158.9995\n",
            "Epoch [50/50] - Batch loss: 152.5904 - Epoch Loss: 44354.4572 - Avg Loss: 158.9765\n",
            "Epoch [50/50] - Batch loss: 168.7980 - Epoch Loss: 44523.2552 - Avg Loss: 159.0116\n",
            "Epoch [50/50] - Batch loss: 165.4694 - Epoch Loss: 44688.7246 - Avg Loss: 159.0346\n",
            "Epoch [50/50] - Batch loss: 155.1746 - Epoch Loss: 44843.8992 - Avg Loss: 159.0209\n",
            "Epoch [50/50] - Batch loss: 160.0177 - Epoch Loss: 45003.9169 - Avg Loss: 159.0244\n",
            "Epoch [50/50] - Batch loss: 170.5804 - Epoch Loss: 45174.4973 - Avg Loss: 159.0651\n",
            "Epoch [50/50] - Batch loss: 163.2192 - Epoch Loss: 45337.7165 - Avg Loss: 159.0797\n",
            "Epoch [50/50] - Batch loss: 159.7778 - Epoch Loss: 45497.4943 - Avg Loss: 159.0821\n",
            "Epoch [50/50] - Batch loss: 155.9784 - Epoch Loss: 45653.4727 - Avg Loss: 159.0713\n",
            "Epoch [50/50] - Batch loss: 157.3220 - Epoch Loss: 45810.7946 - Avg Loss: 159.0653\n",
            "Epoch [50/50] - Batch loss: 159.5898 - Epoch Loss: 45970.3844 - Avg Loss: 159.0671\n",
            "Epoch [50/50] - Batch loss: 155.7938 - Epoch Loss: 46126.1782 - Avg Loss: 159.0558\n",
            "Epoch [50/50] - Batch loss: 156.3957 - Epoch Loss: 46282.5739 - Avg Loss: 159.0466\n",
            "Epoch [50/50] - Batch loss: 161.2200 - Epoch Loss: 46443.7939 - Avg Loss: 159.0541\n",
            "Epoch [50/50] - Batch loss: 161.4991 - Epoch Loss: 46605.2930 - Avg Loss: 159.0624\n",
            "Epoch [50/50] - Batch loss: 162.4478 - Epoch Loss: 46767.7408 - Avg Loss: 159.0739\n",
            "Epoch [50/50] - Batch loss: 158.5478 - Epoch Loss: 46926.2886 - Avg Loss: 159.0722\n",
            "Epoch [50/50] - Batch loss: 155.1115 - Epoch Loss: 47081.4001 - Avg Loss: 159.0588\n",
            "Epoch [50/50] - Batch loss: 157.0745 - Epoch Loss: 47238.4746 - Avg Loss: 159.0521\n",
            "Epoch [50/50] - Batch loss: 154.4631 - Epoch Loss: 47392.9377 - Avg Loss: 159.0367\n",
            "Epoch [50/50] - Batch loss: 156.1221 - Epoch Loss: 47549.0599 - Avg Loss: 159.0270\n",
            "Epoch [50/50] - Batch loss: 164.4694 - Epoch Loss: 47713.5293 - Avg Loss: 159.0451\n",
            "Epoch [50/50] - Batch loss: 157.8693 - Epoch Loss: 47871.3986 - Avg Loss: 159.0412\n",
            "Epoch [50/50] - Batch loss: 157.7923 - Epoch Loss: 48029.1908 - Avg Loss: 159.0371\n",
            "Epoch [50/50] - Batch loss: 161.9619 - Epoch Loss: 48191.1528 - Avg Loss: 159.0467\n",
            "Epoch [50/50] - Batch loss: 160.4858 - Epoch Loss: 48351.6385 - Avg Loss: 159.0514\n",
            "Epoch [50/50] - Batch loss: 164.7541 - Epoch Loss: 48516.3927 - Avg Loss: 159.0701\n",
            "Epoch [50/50] - Batch loss: 162.5033 - Epoch Loss: 48678.8960 - Avg Loss: 159.0814\n",
            "Epoch [50/50] - Batch loss: 161.2682 - Epoch Loss: 48840.1642 - Avg Loss: 159.0885\n",
            "Epoch [50/50] - Batch loss: 162.0987 - Epoch Loss: 49002.2629 - Avg Loss: 159.0983\n",
            "Epoch [50/50] - Batch loss: 157.2827 - Epoch Loss: 49159.5457 - Avg Loss: 159.0924\n",
            "Epoch [50/50] - Batch loss: 161.5855 - Epoch Loss: 49321.1312 - Avg Loss: 159.1004\n",
            "Epoch [50/50] - Batch loss: 155.8919 - Epoch Loss: 49477.0231 - Avg Loss: 159.0901\n",
            "Epoch [50/50] - Batch loss: 157.8948 - Epoch Loss: 49634.9178 - Avg Loss: 159.0863\n",
            "Epoch [50/50] - Batch loss: 163.6921 - Epoch Loss: 49798.6099 - Avg Loss: 159.1010\n",
            "Epoch [50/50] - Batch loss: 163.4993 - Epoch Loss: 49962.1092 - Avg Loss: 159.1150\n",
            "Epoch [50/50] - Batch loss: 165.1045 - Epoch Loss: 50127.2137 - Avg Loss: 159.1340\n",
            "Epoch [50/50] - Batch loss: 154.7812 - Epoch Loss: 50281.9948 - Avg Loss: 159.1202\n",
            "Epoch [50/50] - Batch loss: 164.4369 - Epoch Loss: 50446.4317 - Avg Loss: 159.1370\n",
            "Epoch [50/50] - Batch loss: 152.4684 - Epoch Loss: 50598.9001 - Avg Loss: 159.1160\n",
            "Epoch [50/50] - Batch loss: 161.5175 - Epoch Loss: 50760.4177 - Avg Loss: 159.1236\n",
            "Epoch [50/50] - Batch loss: 154.6548 - Epoch Loss: 50915.0724 - Avg Loss: 159.1096\n",
            "Epoch [50/50] - Batch loss: 160.6111 - Epoch Loss: 51075.6836 - Avg Loss: 159.1143\n",
            "Epoch [50/50] - Batch loss: 156.8389 - Epoch Loss: 51232.5225 - Avg Loss: 159.1072\n",
            "Epoch [50/50] - Batch loss: 166.9058 - Epoch Loss: 51399.4283 - Avg Loss: 159.1314\n",
            "Epoch [50/50] - Batch loss: 157.7150 - Epoch Loss: 51557.1432 - Avg Loss: 159.1270\n",
            "Epoch [50/50] - Batch loss: 155.9184 - Epoch Loss: 51713.0616 - Avg Loss: 159.1171\n",
            "Epoch [50/50] - Batch loss: 157.9703 - Epoch Loss: 51871.0319 - Avg Loss: 159.1136\n",
            "Epoch [50/50] - Batch loss: 160.9442 - Epoch Loss: 52031.9761 - Avg Loss: 159.1192\n",
            "Epoch [50/50] - Batch loss: 158.7715 - Epoch Loss: 52190.7476 - Avg Loss: 159.1181\n",
            "Epoch [50/50] - Batch loss: 153.7089 - Epoch Loss: 52344.4565 - Avg Loss: 159.1017\n",
            "Epoch [50/50] - Batch loss: 160.8563 - Epoch Loss: 52505.3129 - Avg Loss: 159.1070\n",
            "Epoch [50/50] - Batch loss: 160.1595 - Epoch Loss: 52665.4724 - Avg Loss: 159.1102\n",
            "Epoch [50/50] - Batch loss: 161.0887 - Epoch Loss: 52826.5611 - Avg Loss: 159.1161\n",
            "Epoch [50/50] - Batch loss: 159.6688 - Epoch Loss: 52986.2298 - Avg Loss: 159.1178\n",
            "Epoch [50/50] - Batch loss: 160.8869 - Epoch Loss: 53147.1168 - Avg Loss: 159.1231\n",
            "Epoch [50/50] - Batch loss: 164.8529 - Epoch Loss: 53311.9697 - Avg Loss: 159.1402\n",
            "Epoch [50/50] - Batch loss: 163.9362 - Epoch Loss: 53475.9060 - Avg Loss: 159.1545\n",
            "Epoch [50/50] - Batch loss: 159.5422 - Epoch Loss: 53635.4482 - Avg Loss: 159.1556\n",
            "Epoch [50/50] - Batch loss: 154.9405 - Epoch Loss: 53790.3886 - Avg Loss: 159.1432\n",
            "Epoch [50/50] - Batch loss: 166.2931 - Epoch Loss: 53956.6817 - Avg Loss: 159.1643\n",
            "Epoch [50/50] - Batch loss: 161.1300 - Epoch Loss: 54117.8117 - Avg Loss: 159.1700\n",
            "Epoch [50/50] - Batch loss: 158.5647 - Epoch Loss: 54276.3763 - Avg Loss: 159.1683\n",
            "Epoch [50/50] - Batch loss: 156.3727 - Epoch Loss: 54432.7490 - Avg Loss: 159.1601\n",
            "Epoch [50/50] - Batch loss: 154.8589 - Epoch Loss: 54587.6079 - Avg Loss: 159.1475\n",
            "Epoch [50/50] - Batch loss: 158.5901 - Epoch Loss: 54746.1980 - Avg Loss: 159.1459\n",
            "Epoch [50/50] - Batch loss: 152.5784 - Epoch Loss: 54898.7764 - Avg Loss: 159.1269\n",
            "Epoch [50/50] - Batch loss: 170.9180 - Epoch Loss: 55069.6943 - Avg Loss: 159.1610\n",
            "Epoch [50/50] - Batch loss: 163.7537 - Epoch Loss: 55233.4480 - Avg Loss: 159.1742\n",
            "Epoch [50/50] - Batch loss: 155.0960 - Epoch Loss: 55388.5440 - Avg Loss: 159.1625\n",
            "Epoch [50/50] - Batch loss: 156.5751 - Epoch Loss: 55545.1191 - Avg Loss: 159.1551\n",
            "Epoch [50/50] - Batch loss: 151.4337 - Epoch Loss: 55696.5528 - Avg Loss: 159.1330\n",
            "Epoch [50/50] - Batch loss: 158.4431 - Epoch Loss: 55854.9960 - Avg Loss: 159.1310\n",
            "Epoch [50/50] - Batch loss: 159.8945 - Epoch Loss: 56014.8905 - Avg Loss: 159.1332\n",
            "Epoch [50/50] - Batch loss: 160.9522 - Epoch Loss: 56175.8427 - Avg Loss: 159.1384\n",
            "Epoch [50/50] - Batch loss: 159.9928 - Epoch Loss: 56335.8354 - Avg Loss: 159.1408\n",
            "Epoch [50/50] - Batch loss: 159.3913 - Epoch Loss: 56495.2267 - Avg Loss: 159.1415\n",
            "Epoch [50/50] - Batch loss: 156.7814 - Epoch Loss: 56652.0082 - Avg Loss: 159.1349\n",
            "Epoch [50/50] - Batch loss: 161.2614 - Epoch Loss: 56813.2695 - Avg Loss: 159.1408\n",
            "Epoch [50/50] - Batch loss: 163.3564 - Epoch Loss: 56976.6259 - Avg Loss: 159.1526\n",
            "Epoch [50/50] - Batch loss: 156.8799 - Epoch Loss: 57133.5058 - Avg Loss: 159.1463\n",
            "Epoch [50/50] - Batch loss: 161.5444 - Epoch Loss: 57295.0502 - Avg Loss: 159.1529\n",
            "Epoch [50/50] - Batch loss: 165.6700 - Epoch Loss: 57460.7202 - Avg Loss: 159.1710\n",
            "Epoch [50/50] - Batch loss: 155.1424 - Epoch Loss: 57615.8626 - Avg Loss: 159.1598\n",
            "Epoch [50/50] - Batch loss: 152.2549 - Epoch Loss: 57768.1175 - Avg Loss: 159.1408\n",
            "Epoch [50/50] - Batch loss: 167.6031 - Epoch Loss: 57935.7206 - Avg Loss: 159.1641\n",
            "Epoch [50/50] - Batch loss: 157.1446 - Epoch Loss: 58092.8652 - Avg Loss: 159.1585\n",
            "Epoch [50/50] - Batch loss: 157.5992 - Epoch Loss: 58250.4643 - Avg Loss: 159.1543\n",
            "Epoch [50/50] - Batch loss: 154.7186 - Epoch Loss: 58405.1830 - Avg Loss: 159.1422\n",
            "Epoch [50/50] - Batch loss: 153.6585 - Epoch Loss: 58558.8414 - Avg Loss: 159.1273\n",
            "Epoch [50/50] - Batch loss: 157.4606 - Epoch Loss: 58716.3020 - Avg Loss: 159.1228\n",
            "Epoch [50/50] - Batch loss: 161.0452 - Epoch Loss: 58877.3472 - Avg Loss: 159.1280\n",
            "Epoch [50/50] - Batch loss: 156.3266 - Epoch Loss: 59033.6738 - Avg Loss: 159.1204\n",
            "Epoch [50/50] - Batch loss: 154.6571 - Epoch Loss: 59188.3309 - Avg Loss: 159.1084\n",
            "Epoch [50/50] - Batch loss: 153.6852 - Epoch Loss: 59342.0162 - Avg Loss: 159.0939\n",
            "Epoch [50/50] - Batch loss: 167.8347 - Epoch Loss: 59509.8509 - Avg Loss: 159.1172\n",
            "Epoch [50/50] - Batch loss: 160.8807 - Epoch Loss: 59670.7316 - Avg Loss: 159.1220\n",
            "Epoch [50/50] - Batch loss: 160.5310 - Epoch Loss: 59831.2626 - Avg Loss: 159.1257\n",
            "Epoch [50/50] - Batch loss: 162.6742 - Epoch Loss: 59993.9367 - Avg Loss: 159.1351\n",
            "Epoch [50/50] - Batch loss: 155.9012 - Epoch Loss: 60149.8380 - Avg Loss: 159.1266\n",
            "Epoch [50/50] - Batch loss: 158.1893 - Epoch Loss: 60308.0273 - Avg Loss: 159.1241\n",
            "Epoch [50/50] - Batch loss: 161.2503 - Epoch Loss: 60469.2775 - Avg Loss: 159.1297\n",
            "Epoch [50/50] - Batch loss: 156.4037 - Epoch Loss: 60625.6812 - Avg Loss: 159.1225\n",
            "Epoch [50/50] - Batch loss: 151.9954 - Epoch Loss: 60777.6767 - Avg Loss: 159.1039\n",
            "Epoch [50/50] - Batch loss: 166.4433 - Epoch Loss: 60944.1200 - Avg Loss: 159.1230\n",
            "Epoch [50/50] - Batch loss: 162.7996 - Epoch Loss: 61106.9196 - Avg Loss: 159.1326\n",
            "Epoch [50/50] - Batch loss: 158.0779 - Epoch Loss: 61264.9975 - Avg Loss: 159.1299\n",
            "Epoch [50/50] - Batch loss: 162.1196 - Epoch Loss: 61427.1170 - Avg Loss: 159.1376\n",
            "Epoch [50/50] - Batch loss: 162.0474 - Epoch Loss: 61589.1645 - Avg Loss: 159.1451\n",
            "Epoch [50/50] - Batch loss: 159.3061 - Epoch Loss: 61748.4705 - Avg Loss: 159.1455\n",
            "Epoch [50/50] - Batch loss: 164.4223 - Epoch Loss: 61912.8929 - Avg Loss: 159.1591\n",
            "Epoch [50/50] - Batch loss: 150.7451 - Epoch Loss: 62063.6379 - Avg Loss: 159.1375\n",
            "Epoch [50/50] - Batch loss: 159.5018 - Epoch Loss: 62223.1397 - Avg Loss: 159.1385\n",
            "Epoch [50/50] - Batch loss: 165.2999 - Epoch Loss: 62388.4396 - Avg Loss: 159.1542\n",
            "Epoch [50/50] - Batch loss: 156.6238 - Epoch Loss: 62545.0635 - Avg Loss: 159.1477\n",
            "Epoch [50/50] - Batch loss: 161.1869 - Epoch Loss: 62706.2503 - Avg Loss: 159.1529\n",
            "Epoch [50/50] - Batch loss: 164.1403 - Epoch Loss: 62870.3906 - Avg Loss: 159.1655\n",
            "Epoch [50/50] - Batch loss: 159.7813 - Epoch Loss: 63030.1719 - Avg Loss: 159.1671\n",
            "Epoch [50/50] - Batch loss: 153.8175 - Epoch Loss: 63183.9894 - Avg Loss: 159.1536\n",
            "Epoch [50/50] - Batch loss: 161.9639 - Epoch Loss: 63345.9533 - Avg Loss: 159.1607\n",
            "Epoch [50/50] - Batch loss: 165.1828 - Epoch Loss: 63511.1361 - Avg Loss: 159.1758\n",
            "Epoch [50/50] - Batch loss: 156.1617 - Epoch Loss: 63667.2978 - Avg Loss: 159.1682\n",
            "Epoch [50/50] - Batch loss: 167.7017 - Epoch Loss: 63834.9995 - Avg Loss: 159.1895\n",
            "Epoch [50/50] - Batch loss: 155.5378 - Epoch Loss: 63990.5373 - Avg Loss: 159.1804\n",
            "Epoch [50/50] - Batch loss: 168.5245 - Epoch Loss: 64159.0618 - Avg Loss: 159.2036\n",
            "Epoch [50/50] - Batch loss: 164.1160 - Epoch Loss: 64323.1778 - Avg Loss: 159.2158\n",
            "Epoch [50/50] - Batch loss: 158.0703 - Epoch Loss: 64481.2481 - Avg Loss: 159.2130\n",
            "Epoch [50/50] - Batch loss: 151.9544 - Epoch Loss: 64633.2025 - Avg Loss: 159.1951\n",
            "Epoch [50/50] - Batch loss: 166.5097 - Epoch Loss: 64799.7122 - Avg Loss: 159.2131\n",
            "Epoch [50/50] - Batch loss: 161.8997 - Epoch Loss: 64961.6119 - Avg Loss: 159.2196\n",
            "Epoch [50/50] - Batch loss: 153.7791 - Epoch Loss: 65115.3910 - Avg Loss: 159.2063\n",
            "Epoch [50/50] - Batch loss: 167.8006 - Epoch Loss: 65283.1915 - Avg Loss: 159.2273\n",
            "Epoch [50/50] - Batch loss: 159.8597 - Epoch Loss: 65443.0513 - Avg Loss: 159.2288\n",
            "Epoch [50/50] - Batch loss: 162.9097 - Epoch Loss: 65605.9609 - Avg Loss: 159.2378\n",
            "Epoch [50/50] - Batch loss: 161.0807 - Epoch Loss: 65767.0416 - Avg Loss: 159.2422\n",
            "Epoch [50/50] - Batch loss: 161.3225 - Epoch Loss: 65928.3641 - Avg Loss: 159.2473\n",
            "Epoch [50/50] - Batch loss: 158.7500 - Epoch Loss: 66087.1141 - Avg Loss: 159.2461\n",
            "Epoch [50/50] - Batch loss: 165.8862 - Epoch Loss: 66253.0003 - Avg Loss: 159.2620\n",
            "Epoch [50/50] - Batch loss: 166.2712 - Epoch Loss: 66419.2715 - Avg Loss: 159.2788\n",
            "Epoch [50/50] - Batch loss: 163.8937 - Epoch Loss: 66583.1652 - Avg Loss: 159.2899\n",
            "Epoch [50/50] - Batch loss: 161.6160 - Epoch Loss: 66744.7812 - Avg Loss: 159.2954\n",
            "Epoch [50/50] - Batch loss: 158.7200 - Epoch Loss: 66903.5013 - Avg Loss: 159.2941\n",
            "Epoch [50/50] - Batch loss: 153.7760 - Epoch Loss: 67057.2773 - Avg Loss: 159.2809\n",
            "Epoch [50/50] - Batch loss: 164.7304 - Epoch Loss: 67222.0077 - Avg Loss: 159.2939\n",
            "Epoch [50/50] - Batch loss: 161.6742 - Epoch Loss: 67383.6819 - Avg Loss: 159.2995\n",
            "Epoch [50/50] - Batch loss: 155.5442 - Epoch Loss: 67539.2261 - Avg Loss: 159.2906\n",
            "Epoch [50/50] - Batch loss: 164.2289 - Epoch Loss: 67703.4551 - Avg Loss: 159.3022\n",
            "Epoch [50/50] - Batch loss: 161.5889 - Epoch Loss: 67865.0440 - Avg Loss: 159.3076\n",
            "Epoch [50/50] - Batch loss: 157.5477 - Epoch Loss: 68022.5917 - Avg Loss: 159.3035\n",
            "Epoch [50/50] - Batch loss: 165.7098 - Epoch Loss: 68188.3015 - Avg Loss: 159.3185\n",
            "Epoch [50/50] - Batch loss: 160.5567 - Epoch Loss: 68348.8582 - Avg Loss: 159.3213\n",
            "Epoch [50/50] - Batch loss: 155.1825 - Epoch Loss: 68504.0407 - Avg Loss: 159.3117\n",
            "Epoch [50/50] - Batch loss: 152.9073 - Epoch Loss: 68656.9480 - Avg Loss: 159.2969\n",
            "Epoch [50/50] - Batch loss: 155.8578 - Epoch Loss: 68812.8058 - Avg Loss: 159.2889\n",
            "Epoch [50/50] - Batch loss: 165.9493 - Epoch Loss: 68978.7551 - Avg Loss: 159.3043\n",
            "Epoch [50/50] - Batch loss: 163.6068 - Epoch Loss: 69142.3619 - Avg Loss: 159.3142\n",
            "Epoch [50/50] - Batch loss: 151.9785 - Epoch Loss: 69294.3404 - Avg Loss: 159.2973\n",
            "Epoch [50/50] - Batch loss: 161.6707 - Epoch Loss: 69456.0111 - Avg Loss: 159.3028\n",
            "Epoch [50/50] - Batch loss: 149.7308 - Epoch Loss: 69605.7419 - Avg Loss: 159.2809\n",
            "Epoch [50/50] - Batch loss: 159.7589 - Epoch Loss: 69765.5007 - Avg Loss: 159.2820\n",
            "Epoch [50/50] - Batch loss: 152.7483 - Epoch Loss: 69918.2490 - Avg Loss: 159.2671\n",
            "Epoch [50/50] - Batch loss: 154.7917 - Epoch Loss: 70073.0407 - Avg Loss: 159.2569\n",
            "Epoch [50/50] - Batch loss: 161.5575 - Epoch Loss: 70234.5982 - Avg Loss: 159.2621\n",
            "Epoch [50/50] - Batch loss: 149.8308 - Epoch Loss: 70384.4290 - Avg Loss: 159.2408\n",
            "Epoch [50/50] - Batch loss: 162.6395 - Epoch Loss: 70547.0685 - Avg Loss: 159.2485\n",
            "Epoch [50/50] - Batch loss: 160.5787 - Epoch Loss: 70707.6472 - Avg Loss: 159.2515\n",
            "Epoch [50/50] - Batch loss: 155.3533 - Epoch Loss: 70863.0005 - Avg Loss: 159.2427\n",
            "Epoch [50/50] - Batch loss: 153.5080 - Epoch Loss: 71016.5085 - Avg Loss: 159.2298\n",
            "Epoch [50/50] - Batch loss: 160.4867 - Epoch Loss: 71176.9952 - Avg Loss: 159.2327\n",
            "Epoch [50/50] - Batch loss: 168.5366 - Epoch Loss: 71345.5318 - Avg Loss: 159.2534\n",
            "Epoch [50/50] - Batch loss: 155.2496 - Epoch Loss: 71500.7814 - Avg Loss: 159.2445\n",
            "Epoch [50/50] - Batch loss: 164.5227 - Epoch Loss: 71665.3041 - Avg Loss: 159.2562\n",
            "Epoch [50/50] - Batch loss: 156.8470 - Epoch Loss: 71822.1511 - Avg Loss: 159.2509\n",
            "Epoch [50/50] - Batch loss: 148.0188 - Epoch Loss: 71970.1699 - Avg Loss: 159.2260\n",
            "Epoch [50/50] - Batch loss: 159.2663 - Epoch Loss: 72129.4362 - Avg Loss: 159.2261\n",
            "Epoch [50/50] - Batch loss: 152.3249 - Epoch Loss: 72281.7611 - Avg Loss: 159.2109\n",
            "Epoch [50/50] - Batch loss: 161.5045 - Epoch Loss: 72443.2656 - Avg Loss: 159.2160\n",
            "Epoch [50/50] - Batch loss: 152.0626 - Epoch Loss: 72595.3283 - Avg Loss: 159.2003\n",
            "Epoch [50/50] - Batch loss: 167.9378 - Epoch Loss: 72763.2660 - Avg Loss: 159.2194\n",
            "Epoch [50/50] - Batch loss: 157.4041 - Epoch Loss: 72920.6701 - Avg Loss: 159.2154\n",
            "Epoch [50/50] - Batch loss: 163.3260 - Epoch Loss: 73083.9962 - Avg Loss: 159.2244\n",
            "Epoch [50/50] - Batch loss: 162.5754 - Epoch Loss: 73246.5715 - Avg Loss: 159.2317\n",
            "Epoch [50/50] - Batch loss: 163.2557 - Epoch Loss: 73409.8272 - Avg Loss: 159.2404\n",
            "Epoch [50/50] - Batch loss: 157.1647 - Epoch Loss: 73566.9919 - Avg Loss: 159.2359\n",
            "Epoch [50/50] - Batch loss: 154.9068 - Epoch Loss: 73721.8987 - Avg Loss: 159.2266\n",
            "Epoch [50/50] - Batch loss: 167.7204 - Epoch Loss: 73889.6191 - Avg Loss: 159.2449\n",
            "Epoch [50/50] - Batch loss: 160.5078 - Epoch Loss: 74050.1269 - Avg Loss: 159.2476\n",
            "Epoch [50/50] - Batch loss: 158.6790 - Epoch Loss: 74208.8059 - Avg Loss: 159.2464\n",
            "Epoch [50/50] - Batch loss: 160.7852 - Epoch Loss: 74369.5910 - Avg Loss: 159.2497\n",
            "Epoch [50/50] - Batch loss: 156.0876 - Epoch Loss: 74525.6787 - Avg Loss: 159.2429\n",
            "Epoch [50/50] - Batch loss: 160.4079 - Epoch Loss: 74686.0866 - Avg Loss: 159.2454\n",
            "Model saved to: .model/MNIST/VAE_20250421073911.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "!zip -r data.zip ./data\n",
        "files.download('data.zip')\n",
        "\n",
        "!zip -r models.zip ./models\n",
        "files.download('models.zip')\n",
        "\n",
        "!zip -r logs.zip ./runs\n",
        "files.download('logs.zip')\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "txElLt13Rlji",
        "outputId": "85d3bf3f-5cc6-4834-f542-81b6bbddc4d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: models/ (stored 0%)\n",
            "  adding: models/MNIST/ (stored 0%)\n",
            "  adding: models/MNIST/VAE_20250421073911.pt (deflated 7%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_973c0c70-b99e-47df-8e5f-4b523ec1f371\", \"models.zip\", 3569437)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}