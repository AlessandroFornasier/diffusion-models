{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlessandroFornasier/diffusion-models/blob/main/autoencoders/vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "0kwHzd90uOsj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Optional\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class AutoencoderState:\n",
        "  \"\"\"\n",
        "  Autoencoder state.\n",
        "\n",
        "  Attributes:\n",
        "   - x (Optional[torch.Tensor]): Input data\n",
        "   - z (Optional[torch.Tensor]): Latent space sample\n",
        "   - x_hat (Optional[torch.Tensor]): Reconstructed data\n",
        "  \"\"\"\n",
        "  x : Optional[torch.Tensor] = None                         # Input\n",
        "  z : Optional[torch.Tensor] = None                         # Latent space sample\n",
        "  x_hat : Optional[torch.Tensor] = None                     # Reconstructed input\n",
        "\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "  \"\"\"\n",
        "  Autoencoder class.\n",
        "\n",
        "  Args:\n",
        "    dims (List[int]): Dimensions of the layers.\n",
        "    binary (bool): Flag to indicate binary data [0, 1]\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, dims : List[int], binary : bool = True) -> None:\n",
        "    super(Autoencoder, self).__init__()\n",
        "\n",
        "    self.binary = binary\n",
        "\n",
        "    \"\"\"\n",
        "    Encoder\n",
        "\n",
        "    Activation function:\n",
        "      SiLU\n",
        "\n",
        "    Note:\n",
        "      Latent space has no activation function\n",
        "    \"\"\"\n",
        "    layers = []\n",
        "    for idim, odim in zip(dims[:-2], dims[1:-1]):\n",
        "      layers.append(nn.Linear(idim, odim))\n",
        "      layers.append(nn.SiLU())\n",
        "    layers.append(nn.Linear(dims[-2], dims[-1]))\n",
        "    self.encoder = nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Decoder\n",
        "\n",
        "    Activation function for hidden layers:\n",
        "      SiLU\n",
        "\n",
        "    Note:\n",
        "      If the autoencoder is binary the activation function for output layer is a sigmoid, which normalizes to (0, 1)\n",
        "    \"\"\"\n",
        "    layers = []\n",
        "    for idim, odim in zip(dims[-1:1:-1], dims[-2:0:-1]):\n",
        "      layers.append(nn.Linear(idim, odim))\n",
        "      layers.append(nn.SiLU())\n",
        "    layers.append(nn.Linear(dims[1], dims[0]))\n",
        "    if self.binary:\n",
        "      layers.append(nn.Sigmoid())\n",
        "    self.decoder = nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "    def encode(self, x) -> torch.Tensor:\n",
        "      \"\"\"\n",
        "      Encodes the input data into the latent space.\n",
        "\n",
        "      Args:\n",
        "        x (torch.Tensor): Input data.\n",
        "\n",
        "      Returns:\n",
        "        z (torch.Tensor): Encoded data, latent space.\n",
        "      \"\"\"\n",
        "      return self.encoder(x)\n",
        "\n",
        "    def decode(self, z) -> torch.Tensor:\n",
        "      \"\"\"\n",
        "      Decodes the latent space data.\n",
        "\n",
        "      Args:\n",
        "        z (torch.Tensor): Latent space data.\n",
        "\n",
        "      Returns:\n",
        "        x_hat (torch.Tensor): Decoded data, output space.\n",
        "      \"\"\"\n",
        "      return self.decoder(z)\n",
        "\n",
        "    def forward(self, x) -> torch.Tensor:\n",
        "      \"\"\"\n",
        "      Forward pass of the autoencoder\n",
        "      \"\"\"\n",
        "      state = AutoencoderState(x)\n",
        "      state.z = self.encode(x)\n",
        "      state.x_hat = self.decode(state.z)\n",
        "      return state\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class VAEState(AutoencoderState):\n",
        "  \"\"\"\n",
        "  Variational autoencoder state.\n",
        "\n",
        "  Attributes:\n",
        "   - x (Optional[torch.Tensor]): Input data\n",
        "   - z (Optional[torch.Tensor]): Latent space sample\n",
        "   - x_hat (Optional[torch.Tensor]): Reconstructed data\n",
        "   - dist (Optional[torch.distributions.Distribution]): Encoder Gaussian distribution\n",
        "  \"\"\"\n",
        "  dist : Optional[torch.distributions.Distribution] = None  # Latent space distribution\n",
        "\n",
        "\n",
        "class VAE(Autoencoder):\n",
        "  \"\"\"\n",
        "  Variational autoencoder class.\n",
        "\n",
        "  Args:\n",
        "    dims (List[int]): Dimensions of the layers.\n",
        "    binary (bool): Flag to indicate binary data [0, 1]\n",
        "\n",
        "  Note:\n",
        "    A VAE is trained by maximizing ELBO:\n",
        "    - Reconstruction loss (MSE ~ cross entropy)\n",
        "    - KL divergence\n",
        "\n",
        "  Refernce:\n",
        "    - https://hunterheidenreich.com/posts/modern-variational-autoencoder-in-pytorch/\n",
        "    - https://github.com/pytorch/examples/blob/main/vae/main.py\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, dims : List[int], binary : bool = True) -> None:\n",
        "    dims[-1] *= 2 # Mean and variance\n",
        "    super().__init__(dims, binary)\n",
        "\n",
        "    self.softplus = nn.Softplus()\n",
        "\n",
        "  def encode(self, x, eps: float = 1e-6) -> torch.distributions.Distribution:\n",
        "    \"\"\"\n",
        "    Encodes the input data into the latent space.\n",
        "\n",
        "    Args:\n",
        "      x (torch.Tensor): Input data.\n",
        "      eps (float): Small value to avoid numerical instability.\n",
        "\n",
        "    Returns:\n",
        "      dist (torch.distributions.MultivariateNormal): Normal distribution of the encoded data.\n",
        "\n",
        "    Note:\n",
        "      Learning logvar improves numerical stability since var is smaller than zero and tipically smaller than once. Hence logvar is within (-inf, log(1)).\n",
        "      Softplus + epsilon (softplus(x) = \\log(1 + \\exp(x))) is used to get sigma instead of directly exponentiating while ensuring numerical stability\n",
        "    \"\"\"\n",
        "    x = self.encoder(x)\n",
        "    mu, logvar = torch.tensor_split(x, 2, dim=-1)\n",
        "    var = self.softplus(logvar) + eps\n",
        "    return torch.distributions.MultivariateNormal(mu, scale_tril=torch.diag_embed(var)) # Use scale_tril as it is more efficient\n",
        "\n",
        "\n",
        "  def reparametrize(self, dist) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Perform sampling via the reparametrization trick\n",
        "\n",
        "    Args:\n",
        "      dist (torch.distributions.MultivariateNormal): Normal distribution of the encoded data.\n",
        "\n",
        "    Returns:\n",
        "      z (torch.Tensor): Sampled data from the latent space z = mu + sigma * epsilon. With epsilon ~ N(0,I)\n",
        "    \"\"\"\n",
        "    return dist.rsample()\n",
        "\n",
        "  def decode(self, z) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Decodes the data from the latent space to the original input space.\n",
        "\n",
        "    Args:\n",
        "      z (torch.Tensor): Data in the latent space.\n",
        "\n",
        "    Returns:\n",
        "      x_hat (torch.Tensor): Reconstructed data in the original input space.\n",
        "    \"\"\"\n",
        "    return self.decoder(z)\n",
        "\n",
        "  def forward(self, x) -> VAEState:\n",
        "    \"\"\"\n",
        "    Performs a forward pass of the VAE.\n",
        "\n",
        "    Args:\n",
        "      x (torch.Tensor): Input data.\n",
        "\n",
        "    Returns:\n",
        "      state (VAEState): state of the VAE.\n",
        "    \"\"\"\n",
        "    state = VAEState(x)\n",
        "    state.dist = self.encode(state.x)\n",
        "    state.z = self.reparametrize(state.dist)\n",
        "    state.x_hat = self.decode(state.z)\n",
        "    return state"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from torch.optim import Optimizer\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from typing import Callable, Dict\n",
        "\n",
        "class AutoencoderTrainer:\n",
        "  \"\"\"\n",
        "  Trainer class for training an autoencoder model.\n",
        "\n",
        "  Args:\n",
        "    device (torch.device): The device (CPU or GPU) to run the model on.\n",
        "    model (nn.Module): The autoencoder model to be trained.\n",
        "    loss (Callable[[AutoencoderState], Dict[torch.Tensor]]): A callable loss function that takes the model's state and returns a scalar loss value.\n",
        "    optimizer (Optimizer): The optimizer for training the model.\n",
        "    epochs (int): Number of epochs\n",
        "    writer (Optional[SummaryWriter]): Optional TensorBoard writer for logging training metrics.\n",
        "  \"\"\"\n",
        "  def __init__(\n",
        "    self,\n",
        "    device: torch.device,\n",
        "    model: nn.Module,\n",
        "    loss: Callable[[AutoencoderState], Dict[str, torch.Tensor]],\n",
        "    optimizer: Optimizer,\n",
        "    epochs: int,\n",
        "    writer: Optional[SummaryWriter] = None,\n",
        "  ) -> None:\n",
        "    self.device = device\n",
        "    self.model = model.to(self.device)\n",
        "    self.loss = loss\n",
        "    self.optimizer = optimizer\n",
        "    self.epochs = epochs\n",
        "    self.writer = writer\n",
        "\n",
        "  def train(self, dataloader: DataLoader) -> None:\n",
        "    \"\"\"\n",
        "    Trains the autoencoder model on the given dataset.\n",
        "\n",
        "    Args:\n",
        "      dataloader (DataLoader): The DataLoader for loading training data.\n",
        "    \"\"\"\n",
        "    self.model.train()\n",
        "\n",
        "    step = 0\n",
        "    for epoch in range(self.epochs):\n",
        "      epoch_loss = 0.0\n",
        "      progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "      for data, _ in progress_bar:\n",
        "        data = data.to(self.device)\n",
        "\n",
        "        state = self.model(data)\n",
        "        losses = self.loss(state, self.model.binary)\n",
        "\n",
        "        loss = sum(losses.values())\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        epoch_loss += batch_loss\n",
        "        average_loss = epoch_loss / len(dataloader)\n",
        "        progress_bar.set_postfix(loss=batch_loss)\n",
        "\n",
        "        if self.writer:\n",
        "          self.writer.add_scalar(\"Train/Loss/Batch\", batch_loss, step)\n",
        "          self.writer.add_scalar(\"Train/Loss/Epoch\", average_loss, step)\n",
        "          for name, loss in losses.items():\n",
        "            self.writer.add_scalar(f\"Train/Loss/{name}\", loss, step)\n",
        "\n",
        "        step += 1\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] \\| Batch loss: {batch_loss:.4f} \\| Epoch Loss: {epoch_loss:.4f} \\| Avg Loss: {average_loss:.4f}\")\n",
        "\n",
        "  def test(self, dataloader: DataLoader) -> None:\n",
        "    \"\"\"\n",
        "    Test the autoencoder model on the given dataset.\n",
        "\n",
        "    Args:\n",
        "      dataloader (DataLoader): The DataLoader for loading training data.\n",
        "    \"\"\"\n",
        "    self.model.eval()\n",
        "\n",
        "    average_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "      for data, _ in tqdm(dataloader, desc=\"Testing\"):\n",
        "        data = data.to(self.device)\n",
        "\n",
        "        state = self.model(data)\n",
        "        losses = self.loss(state, self.model.binary)\n",
        "        loss = sum(losses.values())\n",
        "\n",
        "        average_loss += loss.item()\n",
        "\n",
        "    average_loss /= len(dataloader)\n",
        "    if self.writer:\n",
        "      self.writer.add_scalar(\"Test/Loss/Average\", average_loss)\n",
        "      for name, loss in losses.items():\n",
        "        self.writer.add_scalar(f\"Test/Loss/Average/{name}\", loss / len(dataloader))\n",
        "\n",
        "    print(f\"Average test loss: {average_loss:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "class VAETrainer(AutoencoderTrainer):\n",
        "  \"\"\"\n",
        "  Trainer class for training a VAE model.\n",
        "\n",
        "  Args:\n",
        "    device (torch.device): The device (CPU or GPU) to run the model on.\n",
        "    model (nn.Module): The autoencoder model to be trained.\n",
        "    loss (Callable[[VAEState], Dict[torch.Tensor]]): A callable loss function that takes the model's state and returns a scalar loss value.\n",
        "    optimizer (Optimizer): The optimizer for training the model.\n",
        "    epochs (int): Number of epochs\n",
        "    writer (Optional[SummaryWriter]): Optional TensorBoard writer for logging training metrics.\n",
        "  \"\"\"\n",
        "  def __init__(\n",
        "    self,\n",
        "    device: torch.device,\n",
        "    model: nn.Module,\n",
        "    loss: Callable[[VAEState], Dict[str, torch.Tensor]],\n",
        "    optimizer: Optimizer,\n",
        "    epochs: int,\n",
        "    writer: Optional[SummaryWriter] = None,\n",
        "  ) -> None:\n",
        "    super().__init__(\n",
        "      device,\n",
        "      model,\n",
        "      loss,\n",
        "      optimizer,\n",
        "      epochs,\n",
        "      writer\n",
        "    )"
      ],
      "metadata": {
        "id": "NuK8mHFr97Pm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "class MNISTLoader:\n",
        "  \"\"\"\n",
        "  A utility class for loading and preprocessing the MNIST dataset using a custom transformation pipeline.\n",
        "\n",
        "  The transformation pipeline includes:\n",
        "    - Conversion to a PyTorch image tensor.\n",
        "    - Scaling pixel values from [0, 255] to [0.0, 1.0].\n",
        "    - Flattening the image into a 1D tensor and shifting the values to [-0.5, 0.5].\n",
        "\n",
        "  Args:\n",
        "    batch_size (int): Number of samples per batch in the DataLoader.\n",
        "  \"\"\"\n",
        "  def __init__(self, batch_size: int) -> None:\n",
        "    self.batch_size = batch_size\n",
        "    self.transform = v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True), v2.Lambda(lambda x: x.view(-1) - 0.5)])\n",
        "\n",
        "  def get_dataloader(self, train: bool) -> DataLoader:\n",
        "    data = datasets.MNIST('./data/MNIST', download=True, train=train, transform=self.transform)\n",
        "    return DataLoader(data, batch_size=self.batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "i6JIAu-jN0A4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as Func\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "class VAELoss:\n",
        "  \"\"\"\n",
        "  VAE Loss callable class. The VAE loss is given by the ELBO,\n",
        "  which is the the sum of the reconstruction loss and the KL divergence loss\n",
        "  \"\"\"\n",
        "  def __binary_vae_loss(self, state: VAEState) -> Dict[str, torch.Tensor]:\n",
        "    rl = Func.binary_cross_entropy(state.x_hat, state.x, reduction='none').sum(-1).mean() # Reconstruction loss\n",
        "    target_dist = torch.distributions.MultivariateNormal(\n",
        "      torch.zeros_like(state.z, device=state.z.device),\n",
        "      scale_tril=torch.eye(state.z.shape[-1], device=state.z.device).unsqueeze(0).expand(state.z.shape[0], -1, -1),\n",
        "    )\n",
        "    kll = torch.distributions.kl.kl_divergence(state.dist, target_dist).mean() # KL loss\n",
        "    return rl + kll\n",
        "\n",
        "  def __call__(self, state: VAEState, binary: bool) -> Dict[str, torch.Tensor]:\n",
        "    if binary:\n",
        "      return self.__binary_vae_loss(self, state)\n",
        "    else:\n",
        "      raise NotImplementedError\n",
        "\n",
        "\n",
        "dims = [28*28, 512, 128, 64, 24, 12, 4]\n",
        "learning_rate = 1e-3\n",
        "weight_decay = 1e-2\n",
        "epochs = 50\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = VAE(dims=dims, binary=True)\n",
        "loss = VAELoss\n",
        "dataloader = MNISTLoader(batch_size=128)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "writer = SummaryWriter(f'./runs/MNIST/VAE_{datetime.now().strftime(\"%Y%m%d%H%M%S\")}')\n",
        "trainer = VAETrainer(device=device, model=model, loss=loss, optimizer=optimizer, epochs=epochs, writer=writer)\n",
        "\n",
        "trainer.train(dataloader.get_dataloader(train=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "sxYh4haZSKNh",
        "outputId": "1e38d440-22bb-4d64-9965-448a6300f707"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoder layers: [Linear(in_features=8, out_features=12, bias=True), SiLU(), Linear(in_features=12, out_features=24, bias=True), SiLU(), Linear(in_features=24, out_features=64, bias=True), SiLU(), Linear(in_features=64, out_features=128, bias=True), SiLU(), Linear(in_features=128, out_features=512, bias=True), SiLU(), Linear(in_features=512, out_features=784, bias=True), Sigmoid()]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/50:   0%|          | 0/469 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (128x4 and 8x12)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-e740fc23f010>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAETrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-5fe0a2d809fb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-9bbc4811778b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparametrize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-9bbc4811778b>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m    187\u001b[0m       \u001b[0mx_hat\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mReconstructed\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0minput\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \"\"\"\n\u001b[0;32m--> 189\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mVAEState\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (128x4 and 8x12)"
          ]
        }
      ]
    }
  ]
}